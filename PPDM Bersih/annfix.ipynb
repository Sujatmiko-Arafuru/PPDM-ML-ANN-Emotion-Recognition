{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "37puETfgRzzg"
      },
      "source": [
        "# ANN From Scratch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EoRP98MpR-qj"
      },
      "source": [
        "## Setup Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "N-qiINBQSK2g"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import time\n",
        "import joblib\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Implementasi ANN\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "class NeuralNetwork:\n",
        "    def __init__(self, input_size, hidden_layers, output_size, activation='relu'):\n",
        "        \"\"\"\n",
        "        Initialize Neural Network Architecture\n",
        "        \n",
        "        Parameters:\n",
        "        -----------\n",
        "        input_size : int\n",
        "            Number of neurons in input layer (number of features)\n",
        "        hidden_layers : list\n",
        "            List containing number of neurons for each hidden layer\n",
        "        output_size : int\n",
        "            Number of neurons in output layer (number of classes)\n",
        "        activation : str\n",
        "            Activation function to use ('relu' or 'tanh')\n",
        "        \"\"\"\n",
        "        self.input_size = input_size\n",
        "        self.hidden_layers = hidden_layers\n",
        "        self.output_size = output_size\n",
        "        self.activation = activation\n",
        "        \n",
        "        # Layer sizes (including input and output)\n",
        "        self.layer_sizes = [input_size] + hidden_layers + [output_size]\n",
        "        \n",
        "        # Initialize weights and biases\n",
        "        self.weights = []\n",
        "        self.biases = []\n",
        "        \n",
        "        # He initialization for ReLU, Xavier/Glorot for tanh\n",
        "        for i in range(len(self.layer_sizes) - 1):\n",
        "            if activation == 'relu' and i < len(self.layer_sizes) - 2:  # ReLU for hidden layers\n",
        "                scale = np.sqrt(2 / self.layer_sizes[i])  # He initialization\n",
        "            else:  # tanh or output layer\n",
        "                scale = np.sqrt(1 / self.layer_sizes[i])  # Xavier initialization\n",
        "                \n",
        "            w = np.random.randn(self.layer_sizes[i], self.layer_sizes[i+1]) * scale\n",
        "            b = np.zeros((1, self.layer_sizes[i+1]))\n",
        "            \n",
        "            self.weights.append(w)\n",
        "            self.biases.append(b)\n",
        "        \n",
        "        # Store activation and pre-activation values for backprop\n",
        "        self.z_values = []  # pre-activation\n",
        "        self.a_values = []  # activation\n",
        "        \n",
        "    # Activation functions\n",
        "    def relu(self, x):\n",
        "        \"\"\"ReLU activation function\"\"\"\n",
        "        return np.maximum(0, x)\n",
        "    \n",
        "    def relu_derivative(self, x):\n",
        "        \"\"\"Derivative of ReLU activation function\"\"\"\n",
        "        return np.where(x > 0, 1, 0)\n",
        "    \n",
        "    def tanh(self, x):\n",
        "        \"\"\"tanh activation function\"\"\"\n",
        "        return np.tanh(x)\n",
        "    \n",
        "    def tanh_derivative(self, x):\n",
        "        \"\"\"Derivative of tanh activation function\"\"\"\n",
        "        return 1 - np.tanh(x)**2\n",
        "    \n",
        "    def softmax(self, x):\n",
        "        \"\"\"Softmax activation function for output layer\"\"\"\n",
        "        exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))  # Numerical stability\n",
        "        return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
        "    \n",
        "    # Forward propagation\n",
        "    def forward(self, X):\n",
        "        \"\"\"\n",
        "        Forward propagation\n",
        "        \n",
        "        Parameters:\n",
        "        -----------\n",
        "        X : numpy.ndarray\n",
        "            Input data with shape (n_samples, input_size)\n",
        "            \n",
        "        Returns:\n",
        "        --------\n",
        "        numpy.ndarray\n",
        "            Network output, probabilities for each class\n",
        "        \"\"\"\n",
        "        self.z_values = []\n",
        "        self.a_values = [X]  # Input layer activation\n",
        "        \n",
        "        # Propagate through hidden layers\n",
        "        for i in range(len(self.weights) - 1):\n",
        "            z = np.dot(self.a_values[-1], self.weights[i]) + self.biases[i]\n",
        "            self.z_values.append(z)\n",
        "            \n",
        "            # Activation with selected function\n",
        "            if self.activation == 'relu':\n",
        "                a = self.relu(z)\n",
        "            else:  # 'tanh'\n",
        "                a = self.tanh(z)\n",
        "                \n",
        "            self.a_values.append(a)\n",
        "        \n",
        "        # Output layer with softmax\n",
        "        z_out = np.dot(self.a_values[-1], self.weights[-1]) + self.biases[-1]\n",
        "        self.z_values.append(z_out)\n",
        "        \n",
        "        # Softmax activation for output layer\n",
        "        output = self.softmax(z_out)\n",
        "        self.a_values.append(output)\n",
        "        \n",
        "        return output\n",
        "    \n",
        "    # Loss function\n",
        "    def categorical_crossentropy(self, y_true, y_pred):\n",
        "        \"\"\"\n",
        "        Categorical Crossentropy Loss\n",
        "        \n",
        "        Parameters:\n",
        "        -----------\n",
        "        y_true : numpy.ndarray\n",
        "            One-hot encoded true labels\n",
        "        y_pred : numpy.ndarray\n",
        "            Predicted probabilities\n",
        "            \n",
        "        Returns:\n",
        "        --------\n",
        "        float\n",
        "            Mean loss value\n",
        "        \"\"\"\n",
        "        # Clip values to prevent log(0)\n",
        "        y_pred = np.clip(y_pred, 1e-15, 1 - 1e-15)\n",
        "        \n",
        "        # Calculate cross-entropy\n",
        "        loss = -np.sum(y_true * np.log(y_pred)) / y_true.shape[0]\n",
        "        return loss\n",
        "    \n",
        "    # Backward propagation\n",
        "    def backward(self, X, y):\n",
        "        \"\"\"\n",
        "        Backward propagation to calculate gradients\n",
        "        \n",
        "        Parameters:\n",
        "        -----------\n",
        "        X : numpy.ndarray\n",
        "            Input data\n",
        "        y : numpy.ndarray\n",
        "            One-hot encoded true labels\n",
        "            \n",
        "        Returns:\n",
        "        --------\n",
        "        list, list\n",
        "            Gradients for weights and biases\n",
        "        \"\"\"\n",
        "        m = X.shape[0]  # Number of samples\n",
        "        \n",
        "        # Initialize dw and db\n",
        "        dw = [np.zeros_like(w) for w in self.weights]\n",
        "        db = [np.zeros_like(b) for b in self.biases]\n",
        "        \n",
        "        # Output layer error (derivative of softmax+crossentropy)\n",
        "        delta = self.a_values[-1] - y  # Simplified from softmax + crossentropy backprop\n",
        "        \n",
        "        # Backprop for output layer\n",
        "        dw[-1] = np.dot(self.a_values[-2].T, delta) / m\n",
        "        db[-1] = np.sum(delta, axis=0, keepdims=True) / m\n",
        "        \n",
        "        # Backprop for hidden layers\n",
        "        for l in range(len(self.weights) - 2, -1, -1):\n",
        "            # Propagate error\n",
        "            delta = np.dot(delta, self.weights[l+1].T)\n",
        "            \n",
        "            # Apply activation derivative\n",
        "            if self.activation == 'relu':\n",
        "                delta *= self.relu_derivative(self.z_values[l])\n",
        "            else:  # 'tanh'\n",
        "                delta *= self.tanh_derivative(self.z_values[l])\n",
        "            \n",
        "            # Calculate gradients\n",
        "            dw[l] = np.dot(self.a_values[l].T, delta) / m\n",
        "            db[l] = np.sum(delta, axis=0, keepdims=True) / m\n",
        "        \n",
        "        return dw, db\n",
        "    \n",
        "    # Update weights and biases\n",
        "    def update_params(self, dw, db, learning_rate):\n",
        "        \"\"\"\n",
        "        Update parameters with gradient descent\n",
        "        \n",
        "        Parameters:\n",
        "        -----------\n",
        "        dw : list\n",
        "            Gradients for weights\n",
        "        db : list\n",
        "            Gradients for biases\n",
        "        learning_rate : float\n",
        "            Learning rate\n",
        "        \"\"\"\n",
        "        for i in range(len(self.weights)):\n",
        "            self.weights[i] -= learning_rate * dw[i]\n",
        "            self.biases[i] -= learning_rate * db[i]\n",
        "    \n",
        "    # Predict function\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Make predictions\n",
        "        \n",
        "        Parameters:\n",
        "        -----------\n",
        "        X : numpy.ndarray\n",
        "            Input data\n",
        "            \n",
        "        Returns:\n",
        "        --------\n",
        "        numpy.ndarray\n",
        "            Predicted class indices\n",
        "        \"\"\"\n",
        "        output = self.forward(X)\n",
        "        return np.argmax(output, axis=1)\n",
        "    \n",
        "    # Save and load model\n",
        "    def save_model(self, filepath):\n",
        "        \"\"\"Save model parameters to file\"\"\"\n",
        "        model_params = {\n",
        "            'weights': self.weights,\n",
        "            'biases': self.biases,\n",
        "            'layer_sizes': self.layer_sizes,\n",
        "            'activation': self.activation\n",
        "        }\n",
        "        np.save(filepath, model_params)\n",
        "        print(f\"Model saved to {filepath}\")\n",
        "        \n",
        "    def load_model(self, filepath):\n",
        "        \"\"\"Load model parameters from file\"\"\"\n",
        "        model_params = np.load(filepath, allow_pickle=True).item()\n",
        "        self.weights = model_params['weights']\n",
        "        self.biases = model_params['biases']\n",
        "        self.layer_sizes = model_params['layer_sizes']\n",
        "        self.activation = model_params['activation']\n",
        "        print(f\"Model loaded from {filepath}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RopL7tUZSQkT"
      },
      "source": [
        "## Training and Evaluation "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train(model, X_train, y_train, X_val, y_val, epochs, batch_size, learning_rate):\n",
        "    \"\"\"\n",
        "    Function to train model\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    model : NeuralNetwork\n",
        "        Neural network model\n",
        "    X_train : numpy.ndarray\n",
        "        Training features\n",
        "    y_train : numpy.ndarray\n",
        "        Training labels (one-hot encoded)\n",
        "    X_val : numpy.ndarray\n",
        "        Validation features\n",
        "    y_val : numpy.ndarray\n",
        "        Validation labels (one-hot encoded)\n",
        "    epochs : int\n",
        "        Number of epochs\n",
        "    batch_size : int\n",
        "        Batch size\n",
        "    learning_rate : float\n",
        "        Learning rate\n",
        "        \n",
        "    Returns:\n",
        "    --------\n",
        "    dict\n",
        "        Training history (loss and accuracy)\n",
        "    \"\"\"\n",
        "    n_samples = X_train.shape[0]\n",
        "    train_losses = []\n",
        "    train_accuracies = []\n",
        "    val_losses = []\n",
        "    val_accuracies = []\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        epoch_start_time = time.time()\n",
        "        \n",
        "        # Shuffle training data\n",
        "        indices = np.random.permutation(n_samples)\n",
        "        X_shuffled = X_train[indices]\n",
        "        y_shuffled = y_train[indices]\n",
        "        \n",
        "        # Mini-batch training\n",
        "        for i in range(0, n_samples, batch_size):\n",
        "            X_batch = X_shuffled[i:i+batch_size]\n",
        "            y_batch = y_shuffled[i:i+batch_size]\n",
        "            \n",
        "            # Forward pass\n",
        "            output = model.forward(X_batch)\n",
        "            \n",
        "            # Backward pass\n",
        "            dw, db = model.backward(X_batch, y_batch)\n",
        "            \n",
        "            # Update parameters\n",
        "            model.update_params(dw, db, learning_rate)\n",
        "        \n",
        "        # Calculate loss and accuracy for training data\n",
        "        train_output = model.forward(X_train)\n",
        "        train_loss = model.categorical_crossentropy(y_train, train_output)\n",
        "        train_pred = np.argmax(train_output, axis=1)\n",
        "        train_true = np.argmax(y_train, axis=1)\n",
        "        train_acc = accuracy_score(train_true, train_pred)\n",
        "        \n",
        "        # Calculate loss and accuracy for validation data\n",
        "        val_output = model.forward(X_val)\n",
        "        val_loss = model.categorical_crossentropy(y_val, val_output)\n",
        "        val_pred = np.argmax(val_output, axis=1)\n",
        "        val_true = np.argmax(y_val, axis=1)\n",
        "        val_acc = accuracy_score(val_true, val_pred)\n",
        "        \n",
        "        # Store metrics\n",
        "        train_losses.append(train_loss)\n",
        "        train_accuracies.append(train_acc)\n",
        "        val_losses.append(val_loss)\n",
        "        val_accuracies.append(val_acc)\n",
        "        \n",
        "        epoch_time = time.time() - epoch_start_time\n",
        "        \n",
        "        # Print progress\n",
        "        print(f\"Epoch {epoch+1}/{epochs} - {epoch_time:.2f}s - \"\n",
        "              f\"loss: {train_loss:.4f} - acc: {train_acc:.4f} - \"\n",
        "              f\"val_loss: {val_loss:.4f} - val_acc: {val_acc:.4f}\")\n",
        "    \n",
        "    history = {\n",
        "        'train_loss': train_losses,\n",
        "        'train_acc': train_accuracies,\n",
        "        'val_loss': val_losses,\n",
        "        'val_acc': val_accuracies\n",
        "    }\n",
        "    \n",
        "    return history\n",
        "\n",
        "def evaluate_model(model, X_test, y_test, class_names=None):\n",
        "    \"\"\"\n",
        "    Evaluate model with metrics\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    model : NeuralNetwork\n",
        "        Neural network model\n",
        "    X_test : numpy.ndarray\n",
        "        Test features\n",
        "    y_test : numpy.ndarray\n",
        "        Test labels (one-hot encoded)\n",
        "    class_names : list\n",
        "        Class names for confusion matrix\n",
        "        \n",
        "    Returns:\n",
        "    --------\n",
        "    dict\n",
        "        Evaluation metrics\n",
        "    \"\"\"\n",
        "    # Predictions\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_true = np.argmax(y_test, axis=1)\n",
        "    \n",
        "    # Accuracy\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    print(f\"Test Accuracy: {acc:.4f}\")\n",
        "    \n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    \n",
        "    # Classification Report\n",
        "    if class_names is None:\n",
        "        class_names = [f\"Class {i}\" for i in range(model.output_size)]\n",
        "    \n",
        "    cr = classification_report(y_true, y_pred, target_names=class_names, output_dict=True)\n",
        "    print(\"\\nClassification Report:\")\n",
        "    cr_df = pd.DataFrame(cr).transpose()\n",
        "    print(cr_df)\n",
        "    \n",
        "    # Plot Confusion Matrix\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(class_names))\n",
        "    plt.xticks(tick_marks, class_names, rotation=45)\n",
        "    plt.yticks(tick_marks, class_names)\n",
        "    \n",
        "    # Label with counts\n",
        "    thresh = cm.max() / 2\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            plt.text(j, i, format(cm[i, j], 'd'),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.savefig('confusion_matrix.png')\n",
        "    plt.close()\n",
        "    \n",
        "    # Return metrics\n",
        "    metrics = {\n",
        "        'accuracy': acc,\n",
        "        'confusion_matrix': cm,\n",
        "        'classification_report': cr\n",
        "    }\n",
        "    \n",
        "    return metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AhSpdQWeSsFh"
      },
      "source": [
        "## Hyperparameter Tuning with Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def grid_search(X_train, y_train, X_val, y_val, X_test, y_test, param_grid):\n",
        "    \"\"\"\n",
        "    Grid search for hyperparameter tuning\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    X_train : numpy.ndarray\n",
        "        Training features\n",
        "    y_train : numpy.ndarray\n",
        "        Training labels (one-hot encoded)\n",
        "    X_val : numpy.ndarray\n",
        "        Validation features\n",
        "    y_val : numpy.ndarray\n",
        "        Validation labels (one-hot encoded)\n",
        "    X_test : numpy.ndarray\n",
        "        Test features\n",
        "    y_test : numpy.ndarray\n",
        "        Test labels (one-hot encoded)\n",
        "    param_grid : dict\n",
        "        Parameter grid for tuning\n",
        "        \n",
        "    Returns:\n",
        "    --------\n",
        "    dict\n",
        "        Best parameters and model\n",
        "    \"\"\"\n",
        "    input_size = X_train.shape[1]\n",
        "    output_size = y_train.shape[1]\n",
        "    \n",
        "    results = []\n",
        "    best_val_acc = 0\n",
        "    best_params = None\n",
        "    best_model = None\n",
        "    \n",
        "    # All hyperparameter combinations\n",
        "    hidden_layers_options = param_grid['hidden_layers']\n",
        "    activations = param_grid['activation']\n",
        "    learning_rates = param_grid['learning_rate']\n",
        "    batch_sizes = param_grid['batch_size']\n",
        "    epochs_options = param_grid['epochs']\n",
        "    \n",
        "    total_combinations = (len(hidden_layers_options) * len(activations) * \n",
        "                         len(learning_rates) * len(batch_sizes) * len(epochs_options))\n",
        "    \n",
        "    print(f\"Total combinations to try: {total_combinations}\")\n",
        "    \n",
        "    combination_count = 0\n",
        "    start_time = time.time()\n",
        "    \n",
        "    # Iterate through all combinations\n",
        "    for hidden_layers in hidden_layers_options:\n",
        "        for activation in activations:\n",
        "            for learning_rate in learning_rates:\n",
        "                for batch_size in batch_sizes:\n",
        "                    for epochs in epochs_options:\n",
        "                        combination_count += 1\n",
        "                        print(f\"\\nCombination {combination_count}/{total_combinations}:\")\n",
        "                        print(f\"Hidden Layers: {hidden_layers}, Activation: {activation}, \"\n",
        "                              f\"Learning Rate: {learning_rate}, Batch Size: {batch_size}, Epochs: {epochs}\")\n",
        "                        \n",
        "                        # Initialize model\n",
        "                        model = NeuralNetwork(input_size, hidden_layers, output_size, activation)\n",
        "                        \n",
        "                        # Train model\n",
        "                        history = train(model, X_train, y_train, X_val, y_val, \n",
        "                                       epochs, batch_size, learning_rate)\n",
        "                        \n",
        "                        # Get validation accuracy\n",
        "                        val_acc = history['val_acc'][-1]\n",
        "                        \n",
        "                        # Evaluate on test set\n",
        "                        test_pred = model.predict(X_test)\n",
        "                        test_true = np.argmax(y_test, axis=1)\n",
        "                        test_acc = accuracy_score(test_true, test_pred)\n",
        "                        \n",
        "                        # Store results\n",
        "                        params_dict = {\n",
        "                            'hidden_layers': hidden_layers,\n",
        "                            'activation': activation,\n",
        "                            'learning_rate': learning_rate,\n",
        "                            'batch_size': batch_size,\n",
        "                            'epochs': epochs,\n",
        "                            'val_accuracy': val_acc,\n",
        "                            'test_accuracy': test_acc\n",
        "                        }\n",
        "                        \n",
        "                        results.append(params_dict)\n",
        "                        \n",
        "                        # Check if this is the best model so far\n",
        "                        if val_acc > best_val_acc:\n",
        "                            best_val_acc = val_acc\n",
        "                            best_params = params_dict\n",
        "                            best_model = model\n",
        "                            \n",
        "                            # Save best model\n",
        "                            model.save_model('models/best_model.npy')\n",
        "                            \n",
        "                            print(f\"New best model found! Validation accuracy: {best_val_acc:.4f}\")\n",
        "    \n",
        "    total_time = time.time() - start_time\n",
        "    print(f\"\\nGrid search completed in {total_time:.2f} seconds.\")\n",
        "    \n",
        "    # Sort results by validation accuracy\n",
        "    results_df = pd.DataFrame(results)\n",
        "    results_df = results_df.sort_values('val_accuracy', ascending=False)\n",
        "    results_df.to_csv('hyperparameter_tuning_results.csv', index=False)\n",
        "    \n",
        "    print(\"\\nTop 5 Parameter Combinations:\")\n",
        "    print(results_df.head(5))\n",
        "    \n",
        "    return {\n",
        "        'best_params': best_params,\n",
        "        'best_model': best_model,\n",
        "        'results_df': results_df\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qb_vcgm3qZKW"
      },
      "source": [
        "## Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def main():\n",
        "    print(\"Loading data...\")\n",
        "    # Load data\n",
        "    X_train = np.load('result/X_train.npy')\n",
        "    X_test = np.load('result/X_test.npy')\n",
        "    y_train = np.load('result/y_train.npy')\n",
        "    y_test = np.load('result/y_test.npy')\n",
        "    \n",
        "    print(f\"Data loaded - X_train: {X_train.shape}, y_train: {y_train.shape}, X_test: {X_test.shape}, y_test: {y_test.shape}\")\n",
        "    \n",
        "    # Load OneHotEncoder to get class names\n",
        "    encoder = joblib.load('result/onehot_encoder.pkl')\n",
        "    class_names = encoder.categories_[0]\n",
        "    \n",
        "    # Split training data into train and validation sets\n",
        "    np.random.seed(42)\n",
        "    validation_split = 0.1  # 10% of training data for validation\n",
        "    n_train = X_train.shape[0]\n",
        "    indices = np.random.permutation(n_train)\n",
        "    n_val = int(n_train * validation_split)\n",
        "    \n",
        "    X_val = X_train[indices[:n_val]]\n",
        "    y_val = y_train[indices[:n_val]]\n",
        "    X_train_new = X_train[indices[n_val:]]\n",
        "    y_train_new = y_train[indices[n_val:]]\n",
        "    \n",
        "    print(f\"Train-validation split - X_train: {X_train_new.shape}, X_val: {X_val.shape}\")\n",
        "    \n",
        "    # Define parameter grid\n",
        "    param_grid = {\n",
        "        'hidden_layers': [\n",
        "            [64, 32],\n",
        "            [128, 64],\n",
        "            [128, 128],\n",
        "            [256, 128],\n",
        "            [128, 64, 32],\n",
        "            [256, 128, 64],\n",
        "            [512, 256, 128]\n",
        "        ],\n",
        "        'activation': ['relu', 'tanh'],\n",
        "        'learning_rate': [0.01, 0.001, 0.0001],\n",
        "        'batch_size': [32, 64],\n",
        "        'epochs': [50, 100, 150]\n",
        "    }\n",
        "    \n",
        "    print(\"\\nStarting hyperparameter tuning...\")\n",
        "    tuning_results = grid_search(X_train_new, y_train_new, X_val, y_val, X_test, y_test, param_grid)\n",
        "    \n",
        "    print(\"\\nBest parameters:\")\n",
        "    for key, value in tuning_results['best_params'].items():\n",
        "        print(f\"{key}: {value}\")\n",
        "    \n",
        "    # Final evaluation of best model\n",
        "    best_model = tuning_results['best_model']\n",
        "    print(\"\\nFinal evaluation of best model on test set:\")\n",
        "    metrics = evaluate_model(best_model, X_test, y_test, class_names)\n",
        "    \n",
        "    # Plot training history\n",
        "    print(\"\\nTraining completed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run the Main Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            "Data loaded - X_train: (4940, 289), y_train: (4940, 3), X_test: (1235, 289), y_test: (1235, 3)\n",
            "Train-validation split - X_train: (4446, 289), X_val: (494, 289)\n",
            "\n",
            "Starting hyperparameter tuning...\n",
            "Total combinations to try: 252\n",
            "\n",
            "Combination 1/252:\n",
            "Hidden Layers: [64, 32], Activation: relu, Learning Rate: 0.01, Batch Size: 32, Epochs: 50\n",
            "Epoch 1/50 - 0.04s - loss: 1.0823 - acc: 0.4339 - val_loss: 1.0880 - val_acc: 0.3684\n",
            "Epoch 2/50 - 0.04s - loss: 1.0709 - acc: 0.4447 - val_loss: 1.0798 - val_acc: 0.4231\n",
            "Epoch 3/50 - 0.04s - loss: 1.0618 - acc: 0.4537 - val_loss: 1.0762 - val_acc: 0.4028\n",
            "Epoch 4/50 - 0.04s - loss: 1.0547 - acc: 0.4638 - val_loss: 1.0719 - val_acc: 0.4049\n",
            "Epoch 5/50 - 0.05s - loss: 1.0478 - acc: 0.4843 - val_loss: 1.0660 - val_acc: 0.4494\n",
            "Epoch 6/50 - 0.04s - loss: 1.0419 - acc: 0.4843 - val_loss: 1.0624 - val_acc: 0.4453\n",
            "Epoch 7/50 - 0.04s - loss: 1.0369 - acc: 0.4861 - val_loss: 1.0606 - val_acc: 0.4453\n",
            "Epoch 8/50 - 0.05s - loss: 1.0312 - acc: 0.4870 - val_loss: 1.0570 - val_acc: 0.4433\n",
            "Epoch 9/50 - 0.04s - loss: 1.0259 - acc: 0.4964 - val_loss: 1.0519 - val_acc: 0.4656\n",
            "Epoch 10/50 - 0.05s - loss: 1.0210 - acc: 0.4991 - val_loss: 1.0503 - val_acc: 0.4534\n",
            "Epoch 11/50 - 0.04s - loss: 1.0180 - acc: 0.4903 - val_loss: 1.0455 - val_acc: 0.4798\n",
            "Epoch 12/50 - 0.05s - loss: 1.0105 - acc: 0.5036 - val_loss: 1.0420 - val_acc: 0.4717\n",
            "Epoch 13/50 - 0.04s - loss: 1.0054 - acc: 0.5119 - val_loss: 1.0370 - val_acc: 0.4818\n",
            "Epoch 14/50 - 0.04s - loss: 1.0003 - acc: 0.5137 - val_loss: 1.0331 - val_acc: 0.4879\n",
            "Epoch 15/50 - 0.05s - loss: 0.9966 - acc: 0.5146 - val_loss: 1.0346 - val_acc: 0.4595\n",
            "Epoch 16/50 - 0.04s - loss: 0.9898 - acc: 0.5229 - val_loss: 1.0273 - val_acc: 0.4737\n",
            "Epoch 17/50 - 0.04s - loss: 0.9852 - acc: 0.5245 - val_loss: 1.0215 - val_acc: 0.4960\n",
            "Epoch 18/50 - 0.04s - loss: 0.9794 - acc: 0.5274 - val_loss: 1.0172 - val_acc: 0.5142\n",
            "Epoch 19/50 - 0.04s - loss: 0.9738 - acc: 0.5290 - val_loss: 1.0132 - val_acc: 0.5020\n",
            "Epoch 20/50 - 0.05s - loss: 0.9691 - acc: 0.5331 - val_loss: 1.0076 - val_acc: 0.5121\n",
            "Epoch 21/50 - 0.04s - loss: 0.9644 - acc: 0.5367 - val_loss: 1.0059 - val_acc: 0.5162\n",
            "Epoch 22/50 - 0.04s - loss: 0.9596 - acc: 0.5385 - val_loss: 1.0000 - val_acc: 0.5182\n",
            "Epoch 23/50 - 0.04s - loss: 0.9576 - acc: 0.5405 - val_loss: 1.0018 - val_acc: 0.5121\n",
            "Epoch 24/50 - 0.05s - loss: 0.9505 - acc: 0.5445 - val_loss: 0.9928 - val_acc: 0.5385\n",
            "Epoch 25/50 - 0.05s - loss: 0.9486 - acc: 0.5459 - val_loss: 0.9890 - val_acc: 0.5263\n",
            "Epoch 26/50 - 0.05s - loss: 0.9510 - acc: 0.5463 - val_loss: 0.9904 - val_acc: 0.5283\n",
            "Epoch 27/50 - 0.05s - loss: 0.9394 - acc: 0.5495 - val_loss: 0.9848 - val_acc: 0.5385\n",
            "Epoch 28/50 - 0.04s - loss: 0.9356 - acc: 0.5515 - val_loss: 0.9810 - val_acc: 0.5344\n",
            "Epoch 29/50 - 0.05s - loss: 0.9318 - acc: 0.5529 - val_loss: 0.9801 - val_acc: 0.5425\n",
            "Epoch 30/50 - 0.05s - loss: 0.9314 - acc: 0.5605 - val_loss: 0.9738 - val_acc: 0.5385\n",
            "Epoch 31/50 - 0.05s - loss: 0.9243 - acc: 0.5596 - val_loss: 0.9707 - val_acc: 0.5445\n",
            "Epoch 32/50 - 0.04s - loss: 0.9269 - acc: 0.5607 - val_loss: 0.9694 - val_acc: 0.5445\n",
            "Epoch 33/50 - 0.04s - loss: 0.9174 - acc: 0.5610 - val_loss: 0.9701 - val_acc: 0.5526\n",
            "Epoch 34/50 - 0.04s - loss: 0.9140 - acc: 0.5675 - val_loss: 0.9617 - val_acc: 0.5445\n",
            "Epoch 35/50 - 0.05s - loss: 0.9198 - acc: 0.5634 - val_loss: 0.9752 - val_acc: 0.5142\n",
            "Epoch 36/50 - 0.04s - loss: 0.9070 - acc: 0.5702 - val_loss: 0.9620 - val_acc: 0.5466\n",
            "Epoch 37/50 - 0.04s - loss: 0.9044 - acc: 0.5726 - val_loss: 0.9597 - val_acc: 0.5486\n",
            "Epoch 38/50 - 0.04s - loss: 0.9075 - acc: 0.5722 - val_loss: 0.9624 - val_acc: 0.5466\n",
            "Epoch 39/50 - 0.04s - loss: 0.9114 - acc: 0.5731 - val_loss: 0.9613 - val_acc: 0.5607\n",
            "Epoch 40/50 - 0.04s - loss: 0.8970 - acc: 0.5801 - val_loss: 0.9570 - val_acc: 0.5445\n",
            "Epoch 41/50 - 0.05s - loss: 0.9004 - acc: 0.5771 - val_loss: 0.9528 - val_acc: 0.5749\n",
            "Epoch 42/50 - 0.04s - loss: 0.9019 - acc: 0.5726 - val_loss: 0.9699 - val_acc: 0.5202\n",
            "Epoch 43/50 - 0.04s - loss: 0.9044 - acc: 0.5706 - val_loss: 0.9558 - val_acc: 0.5668\n",
            "Epoch 44/50 - 0.04s - loss: 0.8842 - acc: 0.5866 - val_loss: 0.9505 - val_acc: 0.5425\n",
            "Epoch 45/50 - 0.04s - loss: 0.8827 - acc: 0.5888 - val_loss: 0.9468 - val_acc: 0.5648\n",
            "Epoch 46/50 - 0.04s - loss: 0.8801 - acc: 0.5938 - val_loss: 0.9447 - val_acc: 0.5587\n",
            "Epoch 47/50 - 0.04s - loss: 0.8868 - acc: 0.5816 - val_loss: 0.9662 - val_acc: 0.5162\n",
            "Epoch 48/50 - 0.04s - loss: 0.8757 - acc: 0.5972 - val_loss: 0.9440 - val_acc: 0.5668\n",
            "Epoch 49/50 - 0.04s - loss: 0.8898 - acc: 0.5794 - val_loss: 0.9512 - val_acc: 0.5709\n",
            "Epoch 50/50 - 0.04s - loss: 0.8921 - acc: 0.5819 - val_loss: 0.9543 - val_acc: 0.5769\n",
            "Model saved to models/best_model.npy\n",
            "New best model found! Validation accuracy: 0.5769\n",
            "\n",
            "Combination 2/252:\n",
            "Hidden Layers: [64, 32], Activation: relu, Learning Rate: 0.01, Batch Size: 32, Epochs: 100\n",
            "Epoch 1/100 - 0.04s - loss: 1.0807 - acc: 0.4031 - val_loss: 1.0862 - val_acc: 0.3887\n",
            "Epoch 2/100 - 0.05s - loss: 1.0672 - acc: 0.4413 - val_loss: 1.0756 - val_acc: 0.4028\n",
            "Epoch 3/100 - 0.05s - loss: 1.0573 - acc: 0.4548 - val_loss: 1.0670 - val_acc: 0.4494\n",
            "Epoch 4/100 - 0.04s - loss: 1.0498 - acc: 0.4600 - val_loss: 1.0617 - val_acc: 0.4413\n",
            "Epoch 5/100 - 0.04s - loss: 1.0422 - acc: 0.4667 - val_loss: 1.0547 - val_acc: 0.4615\n",
            "Epoch 6/100 - 0.04s - loss: 1.0356 - acc: 0.4728 - val_loss: 1.0504 - val_acc: 0.4737\n",
            "Epoch 7/100 - 0.04s - loss: 1.0315 - acc: 0.4829 - val_loss: 1.0466 - val_acc: 0.4696\n",
            "Epoch 8/100 - 0.04s - loss: 1.0242 - acc: 0.4773 - val_loss: 1.0415 - val_acc: 0.4737\n",
            "Epoch 9/100 - 0.04s - loss: 1.0146 - acc: 0.4885 - val_loss: 1.0344 - val_acc: 0.4777\n",
            "Epoch 10/100 - 0.04s - loss: 1.0069 - acc: 0.4996 - val_loss: 1.0294 - val_acc: 0.5182\n",
            "Epoch 11/100 - 0.04s - loss: 1.0029 - acc: 0.5137 - val_loss: 1.0253 - val_acc: 0.5101\n",
            "Epoch 12/100 - 0.04s - loss: 0.9949 - acc: 0.5178 - val_loss: 1.0196 - val_acc: 0.5142\n",
            "Epoch 13/100 - 0.04s - loss: 0.9879 - acc: 0.5164 - val_loss: 1.0158 - val_acc: 0.5263\n",
            "Epoch 14/100 - 0.04s - loss: 0.9812 - acc: 0.5250 - val_loss: 1.0101 - val_acc: 0.5304\n",
            "Epoch 15/100 - 0.04s - loss: 0.9768 - acc: 0.5340 - val_loss: 1.0056 - val_acc: 0.5243\n",
            "Epoch 16/100 - 0.04s - loss: 0.9711 - acc: 0.5337 - val_loss: 1.0020 - val_acc: 0.5304\n",
            "Epoch 17/100 - 0.04s - loss: 0.9649 - acc: 0.5340 - val_loss: 0.9982 - val_acc: 0.5405\n",
            "Epoch 18/100 - 0.04s - loss: 0.9621 - acc: 0.5403 - val_loss: 0.9950 - val_acc: 0.5283\n",
            "Epoch 19/100 - 0.04s - loss: 0.9635 - acc: 0.5403 - val_loss: 0.9959 - val_acc: 0.5445\n",
            "Epoch 20/100 - 0.04s - loss: 0.9675 - acc: 0.5265 - val_loss: 1.0033 - val_acc: 0.5101\n",
            "Epoch 21/100 - 0.04s - loss: 0.9583 - acc: 0.5382 - val_loss: 0.9931 - val_acc: 0.5101\n",
            "Epoch 22/100 - 0.04s - loss: 0.9518 - acc: 0.5407 - val_loss: 0.9885 - val_acc: 0.5263\n",
            "Epoch 23/100 - 0.04s - loss: 0.9381 - acc: 0.5585 - val_loss: 0.9746 - val_acc: 0.5506\n",
            "Epoch 24/100 - 0.04s - loss: 0.9410 - acc: 0.5486 - val_loss: 0.9788 - val_acc: 0.5304\n",
            "Epoch 25/100 - 0.04s - loss: 0.9375 - acc: 0.5502 - val_loss: 0.9805 - val_acc: 0.5425\n",
            "Epoch 26/100 - 0.04s - loss: 0.9344 - acc: 0.5569 - val_loss: 0.9742 - val_acc: 0.5567\n",
            "Epoch 27/100 - 0.04s - loss: 0.9241 - acc: 0.5616 - val_loss: 0.9673 - val_acc: 0.5587\n",
            "Epoch 28/100 - 0.04s - loss: 0.9263 - acc: 0.5652 - val_loss: 0.9729 - val_acc: 0.5486\n",
            "Epoch 29/100 - 0.04s - loss: 0.9168 - acc: 0.5697 - val_loss: 0.9606 - val_acc: 0.5607\n",
            "Epoch 30/100 - 0.04s - loss: 0.9140 - acc: 0.5668 - val_loss: 0.9612 - val_acc: 0.5628\n",
            "Epoch 31/100 - 0.04s - loss: 0.9146 - acc: 0.5715 - val_loss: 0.9668 - val_acc: 0.5587\n",
            "Epoch 32/100 - 0.04s - loss: 0.9133 - acc: 0.5729 - val_loss: 0.9664 - val_acc: 0.5526\n",
            "Epoch 33/100 - 0.04s - loss: 0.9042 - acc: 0.5731 - val_loss: 0.9586 - val_acc: 0.5587\n",
            "Epoch 34/100 - 0.05s - loss: 0.9089 - acc: 0.5695 - val_loss: 0.9641 - val_acc: 0.5466\n",
            "Epoch 35/100 - 0.04s - loss: 0.9039 - acc: 0.5753 - val_loss: 0.9608 - val_acc: 0.5486\n",
            "Epoch 36/100 - 0.04s - loss: 0.8987 - acc: 0.5758 - val_loss: 0.9561 - val_acc: 0.5526\n",
            "Epoch 37/100 - 0.04s - loss: 0.8919 - acc: 0.5805 - val_loss: 0.9539 - val_acc: 0.5607\n",
            "Epoch 38/100 - 0.04s - loss: 0.8931 - acc: 0.5823 - val_loss: 0.9594 - val_acc: 0.5466\n",
            "Epoch 39/100 - 0.04s - loss: 0.8874 - acc: 0.5807 - val_loss: 0.9515 - val_acc: 0.5486\n",
            "Epoch 40/100 - 0.04s - loss: 0.8818 - acc: 0.5850 - val_loss: 0.9474 - val_acc: 0.5628\n",
            "Epoch 41/100 - 0.04s - loss: 0.9096 - acc: 0.5733 - val_loss: 0.9845 - val_acc: 0.5142\n",
            "Epoch 42/100 - 0.04s - loss: 0.8800 - acc: 0.5888 - val_loss: 0.9528 - val_acc: 0.5607\n",
            "Epoch 43/100 - 0.04s - loss: 0.8732 - acc: 0.5904 - val_loss: 0.9467 - val_acc: 0.5547\n",
            "Epoch 44/100 - 0.05s - loss: 0.8702 - acc: 0.5942 - val_loss: 0.9446 - val_acc: 0.5688\n",
            "Epoch 45/100 - 0.05s - loss: 0.8716 - acc: 0.5920 - val_loss: 0.9499 - val_acc: 0.5506\n",
            "Epoch 46/100 - 0.04s - loss: 0.8718 - acc: 0.5868 - val_loss: 0.9458 - val_acc: 0.5709\n",
            "Epoch 47/100 - 0.04s - loss: 0.8726 - acc: 0.5965 - val_loss: 0.9566 - val_acc: 0.5405\n",
            "Epoch 48/100 - 0.04s - loss: 0.8600 - acc: 0.5987 - val_loss: 0.9419 - val_acc: 0.5668\n",
            "Epoch 49/100 - 0.05s - loss: 0.8693 - acc: 0.5909 - val_loss: 0.9455 - val_acc: 0.5789\n",
            "Epoch 50/100 - 0.05s - loss: 0.8787 - acc: 0.5825 - val_loss: 0.9668 - val_acc: 0.5202\n",
            "Epoch 51/100 - 0.05s - loss: 0.8636 - acc: 0.6010 - val_loss: 0.9551 - val_acc: 0.5405\n",
            "Epoch 52/100 - 0.05s - loss: 0.8510 - acc: 0.6050 - val_loss: 0.9432 - val_acc: 0.5789\n",
            "Epoch 53/100 - 0.04s - loss: 0.8704 - acc: 0.5882 - val_loss: 0.9521 - val_acc: 0.5587\n",
            "Epoch 54/100 - 0.05s - loss: 0.8732 - acc: 0.5884 - val_loss: 0.9580 - val_acc: 0.5547\n",
            "Epoch 55/100 - 0.04s - loss: 0.8456 - acc: 0.6019 - val_loss: 0.9424 - val_acc: 0.5547\n",
            "Epoch 56/100 - 0.05s - loss: 0.8427 - acc: 0.6102 - val_loss: 0.9455 - val_acc: 0.5668\n",
            "Epoch 57/100 - 0.04s - loss: 0.8451 - acc: 0.6041 - val_loss: 0.9452 - val_acc: 0.5486\n",
            "Epoch 58/100 - 0.04s - loss: 0.8349 - acc: 0.6138 - val_loss: 0.9369 - val_acc: 0.5709\n",
            "Epoch 59/100 - 0.05s - loss: 0.8514 - acc: 0.6100 - val_loss: 0.9503 - val_acc: 0.5547\n",
            "Epoch 60/100 - 0.05s - loss: 0.8333 - acc: 0.6158 - val_loss: 0.9430 - val_acc: 0.5648\n",
            "Epoch 61/100 - 0.05s - loss: 0.8339 - acc: 0.6140 - val_loss: 0.9476 - val_acc: 0.5567\n",
            "Epoch 62/100 - 0.04s - loss: 0.8430 - acc: 0.6107 - val_loss: 0.9674 - val_acc: 0.5405\n",
            "Epoch 63/100 - 0.04s - loss: 0.8330 - acc: 0.6233 - val_loss: 0.9504 - val_acc: 0.5425\n",
            "Epoch 64/100 - 0.04s - loss: 0.8624 - acc: 0.5960 - val_loss: 0.9948 - val_acc: 0.5162\n",
            "Epoch 65/100 - 0.04s - loss: 0.8233 - acc: 0.6199 - val_loss: 0.9421 - val_acc: 0.5567\n",
            "Epoch 66/100 - 0.04s - loss: 0.8237 - acc: 0.6224 - val_loss: 0.9478 - val_acc: 0.5628\n",
            "Epoch 67/100 - 0.04s - loss: 0.8275 - acc: 0.6194 - val_loss: 0.9618 - val_acc: 0.5547\n",
            "Epoch 68/100 - 0.04s - loss: 0.8151 - acc: 0.6300 - val_loss: 0.9451 - val_acc: 0.5607\n",
            "Epoch 69/100 - 0.04s - loss: 0.8328 - acc: 0.6172 - val_loss: 0.9548 - val_acc: 0.5628\n",
            "Epoch 70/100 - 0.04s - loss: 0.8185 - acc: 0.6253 - val_loss: 0.9539 - val_acc: 0.5769\n",
            "Epoch 71/100 - 0.04s - loss: 0.8249 - acc: 0.6224 - val_loss: 0.9590 - val_acc: 0.5587\n",
            "Epoch 72/100 - 0.05s - loss: 0.8063 - acc: 0.6327 - val_loss: 0.9487 - val_acc: 0.5607\n",
            "Epoch 73/100 - 0.04s - loss: 0.8107 - acc: 0.6273 - val_loss: 0.9419 - val_acc: 0.5668\n",
            "Epoch 74/100 - 0.04s - loss: 0.8045 - acc: 0.6345 - val_loss: 0.9538 - val_acc: 0.5628\n",
            "Epoch 75/100 - 0.05s - loss: 0.8140 - acc: 0.6314 - val_loss: 0.9557 - val_acc: 0.5648\n",
            "Epoch 76/100 - 0.04s - loss: 0.8043 - acc: 0.6381 - val_loss: 0.9596 - val_acc: 0.5567\n",
            "Epoch 77/100 - 0.04s - loss: 0.8066 - acc: 0.6395 - val_loss: 0.9671 - val_acc: 0.5466\n",
            "Epoch 78/100 - 0.04s - loss: 0.7951 - acc: 0.6377 - val_loss: 0.9425 - val_acc: 0.5688\n",
            "Epoch 79/100 - 0.04s - loss: 0.8009 - acc: 0.6406 - val_loss: 0.9578 - val_acc: 0.5547\n",
            "Epoch 80/100 - 0.05s - loss: 0.7867 - acc: 0.6451 - val_loss: 0.9402 - val_acc: 0.5729\n",
            "Epoch 81/100 - 0.04s - loss: 0.7902 - acc: 0.6466 - val_loss: 0.9505 - val_acc: 0.5567\n",
            "Epoch 82/100 - 0.04s - loss: 0.7821 - acc: 0.6473 - val_loss: 0.9426 - val_acc: 0.5506\n",
            "Epoch 83/100 - 0.04s - loss: 0.8242 - acc: 0.6264 - val_loss: 0.9785 - val_acc: 0.5445\n",
            "Epoch 84/100 - 0.04s - loss: 0.8138 - acc: 0.6262 - val_loss: 0.9669 - val_acc: 0.5486\n",
            "Epoch 85/100 - 0.04s - loss: 0.7902 - acc: 0.6482 - val_loss: 0.9698 - val_acc: 0.5526\n",
            "Epoch 86/100 - 0.04s - loss: 0.7756 - acc: 0.6581 - val_loss: 0.9500 - val_acc: 0.5729\n",
            "Epoch 87/100 - 0.04s - loss: 0.7841 - acc: 0.6502 - val_loss: 0.9604 - val_acc: 0.5709\n",
            "Epoch 88/100 - 0.04s - loss: 0.7882 - acc: 0.6446 - val_loss: 0.9797 - val_acc: 0.5182\n",
            "Epoch 89/100 - 0.04s - loss: 0.7687 - acc: 0.6631 - val_loss: 0.9516 - val_acc: 0.5648\n",
            "Epoch 90/100 - 0.04s - loss: 0.7624 - acc: 0.6673 - val_loss: 0.9495 - val_acc: 0.5567\n",
            "Epoch 91/100 - 0.04s - loss: 0.7662 - acc: 0.6631 - val_loss: 0.9536 - val_acc: 0.5547\n",
            "Epoch 92/100 - 0.04s - loss: 0.7728 - acc: 0.6550 - val_loss: 0.9520 - val_acc: 0.5668\n",
            "Epoch 93/100 - 0.04s - loss: 0.7706 - acc: 0.6613 - val_loss: 0.9733 - val_acc: 0.5364\n",
            "Epoch 94/100 - 0.04s - loss: 0.7780 - acc: 0.6595 - val_loss: 0.9816 - val_acc: 0.5304\n",
            "Epoch 95/100 - 0.04s - loss: 0.7565 - acc: 0.6714 - val_loss: 0.9543 - val_acc: 0.5607\n",
            "Epoch 96/100 - 0.04s - loss: 0.7578 - acc: 0.6743 - val_loss: 0.9504 - val_acc: 0.5648\n",
            "Epoch 97/100 - 0.04s - loss: 0.7598 - acc: 0.6655 - val_loss: 0.9662 - val_acc: 0.5607\n",
            "Epoch 98/100 - 0.04s - loss: 0.7721 - acc: 0.6473 - val_loss: 0.9590 - val_acc: 0.5688\n",
            "Epoch 99/100 - 0.04s - loss: 0.7679 - acc: 0.6511 - val_loss: 0.9631 - val_acc: 0.5628\n",
            "Epoch 100/100 - 0.04s - loss: 0.7607 - acc: 0.6610 - val_loss: 0.9768 - val_acc: 0.5526\n",
            "\n",
            "Combination 3/252:\n",
            "Hidden Layers: [64, 32], Activation: relu, Learning Rate: 0.01, Batch Size: 32, Epochs: 150\n",
            "Epoch 1/150 - 0.04s - loss: 1.0904 - acc: 0.3855 - val_loss: 1.0909 - val_acc: 0.3664\n",
            "Epoch 2/150 - 0.04s - loss: 1.0810 - acc: 0.4114 - val_loss: 1.0864 - val_acc: 0.3806\n",
            "Epoch 3/150 - 0.04s - loss: 1.0706 - acc: 0.4424 - val_loss: 1.0794 - val_acc: 0.4008\n",
            "Epoch 4/150 - 0.04s - loss: 1.0638 - acc: 0.4384 - val_loss: 1.0775 - val_acc: 0.3968\n",
            "Epoch 5/150 - 0.04s - loss: 1.0534 - acc: 0.4681 - val_loss: 1.0686 - val_acc: 0.4251\n",
            "Epoch 6/150 - 0.04s - loss: 1.0462 - acc: 0.4735 - val_loss: 1.0626 - val_acc: 0.4413\n",
            "Epoch 7/150 - 0.05s - loss: 1.0392 - acc: 0.4723 - val_loss: 1.0581 - val_acc: 0.4514\n",
            "Epoch 8/150 - 0.04s - loss: 1.0348 - acc: 0.4685 - val_loss: 1.0553 - val_acc: 0.4534\n",
            "Epoch 9/150 - 0.04s - loss: 1.0296 - acc: 0.4723 - val_loss: 1.0528 - val_acc: 0.4575\n",
            "Epoch 10/150 - 0.04s - loss: 1.0189 - acc: 0.4973 - val_loss: 1.0446 - val_acc: 0.4656\n",
            "Epoch 11/150 - 0.04s - loss: 1.0159 - acc: 0.5009 - val_loss: 1.0423 - val_acc: 0.4717\n",
            "Epoch 12/150 - 0.04s - loss: 1.0087 - acc: 0.5031 - val_loss: 1.0369 - val_acc: 0.4838\n",
            "Epoch 13/150 - 0.04s - loss: 1.0004 - acc: 0.5081 - val_loss: 1.0307 - val_acc: 0.4919\n",
            "Epoch 14/150 - 0.04s - loss: 0.9950 - acc: 0.5097 - val_loss: 1.0260 - val_acc: 0.4939\n",
            "Epoch 15/150 - 0.04s - loss: 0.9925 - acc: 0.5094 - val_loss: 1.0264 - val_acc: 0.4717\n",
            "Epoch 16/150 - 0.04s - loss: 0.9878 - acc: 0.5119 - val_loss: 1.0258 - val_acc: 0.4798\n",
            "Epoch 17/150 - 0.05s - loss: 0.9781 - acc: 0.5247 - val_loss: 1.0145 - val_acc: 0.5243\n",
            "Epoch 18/150 - 0.05s - loss: 0.9765 - acc: 0.5241 - val_loss: 1.0113 - val_acc: 0.5121\n",
            "Epoch 19/150 - 0.05s - loss: 0.9693 - acc: 0.5326 - val_loss: 1.0065 - val_acc: 0.5263\n",
            "Epoch 20/150 - 0.05s - loss: 0.9632 - acc: 0.5360 - val_loss: 1.0036 - val_acc: 0.5324\n",
            "Epoch 21/150 - 0.05s - loss: 0.9590 - acc: 0.5369 - val_loss: 0.9983 - val_acc: 0.5263\n",
            "Epoch 22/150 - 0.05s - loss: 0.9589 - acc: 0.5382 - val_loss: 0.9976 - val_acc: 0.5324\n",
            "Epoch 23/150 - 0.05s - loss: 0.9542 - acc: 0.5414 - val_loss: 0.9990 - val_acc: 0.5344\n",
            "Epoch 24/150 - 0.05s - loss: 0.9464 - acc: 0.5468 - val_loss: 0.9907 - val_acc: 0.5506\n",
            "Epoch 25/150 - 0.04s - loss: 0.9567 - acc: 0.5342 - val_loss: 1.0041 - val_acc: 0.5142\n",
            "Epoch 26/150 - 0.04s - loss: 0.9555 - acc: 0.5493 - val_loss: 0.9972 - val_acc: 0.5364\n",
            "Epoch 27/150 - 0.04s - loss: 0.9341 - acc: 0.5569 - val_loss: 0.9817 - val_acc: 0.5607\n",
            "Epoch 28/150 - 0.04s - loss: 0.9307 - acc: 0.5553 - val_loss: 0.9801 - val_acc: 0.5607\n",
            "Epoch 29/150 - 0.05s - loss: 0.9466 - acc: 0.5526 - val_loss: 0.9911 - val_acc: 0.5466\n",
            "Epoch 30/150 - 0.05s - loss: 0.9285 - acc: 0.5544 - val_loss: 0.9797 - val_acc: 0.5506\n",
            "Epoch 31/150 - 0.05s - loss: 0.9300 - acc: 0.5632 - val_loss: 0.9772 - val_acc: 0.5567\n",
            "Epoch 32/150 - 0.04s - loss: 0.9300 - acc: 0.5648 - val_loss: 0.9788 - val_acc: 0.5466\n",
            "Epoch 33/150 - 0.04s - loss: 0.9234 - acc: 0.5578 - val_loss: 0.9725 - val_acc: 0.5526\n",
            "Epoch 34/150 - 0.05s - loss: 0.9122 - acc: 0.5706 - val_loss: 0.9672 - val_acc: 0.5587\n",
            "Epoch 35/150 - 0.04s - loss: 0.9098 - acc: 0.5679 - val_loss: 0.9631 - val_acc: 0.5668\n",
            "Epoch 36/150 - 0.05s - loss: 0.9104 - acc: 0.5661 - val_loss: 0.9669 - val_acc: 0.5547\n",
            "Epoch 37/150 - 0.04s - loss: 0.9077 - acc: 0.5637 - val_loss: 0.9637 - val_acc: 0.5628\n",
            "Epoch 38/150 - 0.04s - loss: 0.9016 - acc: 0.5751 - val_loss: 0.9644 - val_acc: 0.5607\n",
            "Epoch 39/150 - 0.05s - loss: 0.8981 - acc: 0.5724 - val_loss: 0.9589 - val_acc: 0.5668\n",
            "Epoch 40/150 - 0.04s - loss: 0.8947 - acc: 0.5798 - val_loss: 0.9570 - val_acc: 0.5587\n",
            "Epoch 41/150 - 0.04s - loss: 0.8956 - acc: 0.5783 - val_loss: 0.9636 - val_acc: 0.5445\n",
            "Epoch 42/150 - 0.05s - loss: 0.8950 - acc: 0.5812 - val_loss: 0.9575 - val_acc: 0.5587\n",
            "Epoch 43/150 - 0.04s - loss: 0.8935 - acc: 0.5765 - val_loss: 0.9628 - val_acc: 0.5405\n",
            "Epoch 44/150 - 0.08s - loss: 0.8844 - acc: 0.5819 - val_loss: 0.9517 - val_acc: 0.5709\n",
            "Epoch 45/150 - 0.05s - loss: 0.8878 - acc: 0.5807 - val_loss: 0.9616 - val_acc: 0.5587\n",
            "Epoch 46/150 - 0.05s - loss: 0.8904 - acc: 0.5909 - val_loss: 0.9585 - val_acc: 0.5567\n",
            "Epoch 47/150 - 0.05s - loss: 0.8792 - acc: 0.5875 - val_loss: 0.9491 - val_acc: 0.5648\n",
            "Epoch 48/150 - 0.05s - loss: 0.8991 - acc: 0.5747 - val_loss: 0.9782 - val_acc: 0.5142\n",
            "Epoch 49/150 - 0.05s - loss: 0.8834 - acc: 0.5861 - val_loss: 0.9634 - val_acc: 0.5385\n",
            "Epoch 50/150 - 0.04s - loss: 0.8718 - acc: 0.5857 - val_loss: 0.9468 - val_acc: 0.5769\n",
            "Epoch 51/150 - 0.04s - loss: 0.8927 - acc: 0.5911 - val_loss: 0.9681 - val_acc: 0.5648\n",
            "Epoch 52/150 - 0.04s - loss: 0.8742 - acc: 0.5911 - val_loss: 0.9593 - val_acc: 0.5466\n",
            "Epoch 53/150 - 0.04s - loss: 0.8670 - acc: 0.5974 - val_loss: 0.9521 - val_acc: 0.5405\n",
            "Epoch 54/150 - 0.04s - loss: 0.8602 - acc: 0.5969 - val_loss: 0.9428 - val_acc: 0.5688\n",
            "Epoch 55/150 - 0.05s - loss: 0.8603 - acc: 0.5969 - val_loss: 0.9518 - val_acc: 0.5567\n",
            "Epoch 56/150 - 0.04s - loss: 0.8572 - acc: 0.6003 - val_loss: 0.9468 - val_acc: 0.5709\n",
            "Epoch 57/150 - 0.05s - loss: 0.8637 - acc: 0.5990 - val_loss: 0.9548 - val_acc: 0.5405\n",
            "Epoch 58/150 - 0.05s - loss: 0.8516 - acc: 0.6019 - val_loss: 0.9430 - val_acc: 0.5810\n",
            "Epoch 59/150 - 0.05s - loss: 0.8517 - acc: 0.6053 - val_loss: 0.9516 - val_acc: 0.5567\n",
            "Epoch 60/150 - 0.05s - loss: 0.8517 - acc: 0.6077 - val_loss: 0.9491 - val_acc: 0.5547\n",
            "Epoch 61/150 - 0.05s - loss: 0.8607 - acc: 0.6073 - val_loss: 0.9524 - val_acc: 0.5830\n",
            "Epoch 62/150 - 0.05s - loss: 0.8509 - acc: 0.6064 - val_loss: 0.9537 - val_acc: 0.5587\n",
            "Epoch 63/150 - 0.05s - loss: 0.8467 - acc: 0.6026 - val_loss: 0.9510 - val_acc: 0.5405\n",
            "Epoch 64/150 - 0.05s - loss: 0.8381 - acc: 0.6145 - val_loss: 0.9419 - val_acc: 0.5830\n",
            "Epoch 65/150 - 0.05s - loss: 0.8483 - acc: 0.6134 - val_loss: 0.9475 - val_acc: 0.5870\n",
            "Epoch 66/150 - 0.04s - loss: 0.8368 - acc: 0.6122 - val_loss: 0.9516 - val_acc: 0.5486\n",
            "Epoch 67/150 - 0.05s - loss: 0.8290 - acc: 0.6161 - val_loss: 0.9426 - val_acc: 0.5749\n",
            "Epoch 68/150 - 0.05s - loss: 0.8351 - acc: 0.6118 - val_loss: 0.9390 - val_acc: 0.5587\n",
            "Epoch 69/150 - 0.05s - loss: 0.8300 - acc: 0.6181 - val_loss: 0.9468 - val_acc: 0.5648\n",
            "Epoch 70/150 - 0.05s - loss: 0.8234 - acc: 0.6188 - val_loss: 0.9374 - val_acc: 0.5547\n",
            "Epoch 71/150 - 0.05s - loss: 0.8227 - acc: 0.6248 - val_loss: 0.9418 - val_acc: 0.5668\n",
            "Epoch 72/150 - 0.05s - loss: 0.8206 - acc: 0.6208 - val_loss: 0.9392 - val_acc: 0.5911\n",
            "Epoch 73/150 - 0.05s - loss: 0.8167 - acc: 0.6208 - val_loss: 0.9406 - val_acc: 0.5668\n",
            "Epoch 74/150 - 0.04s - loss: 0.8248 - acc: 0.6221 - val_loss: 0.9393 - val_acc: 0.5628\n",
            "Epoch 75/150 - 0.05s - loss: 0.8174 - acc: 0.6275 - val_loss: 0.9461 - val_acc: 0.5628\n",
            "Epoch 76/150 - 0.04s - loss: 0.8260 - acc: 0.6217 - val_loss: 0.9522 - val_acc: 0.5688\n",
            "Epoch 77/150 - 0.04s - loss: 0.8160 - acc: 0.6197 - val_loss: 0.9550 - val_acc: 0.5486\n",
            "Epoch 78/150 - 0.04s - loss: 0.8156 - acc: 0.6280 - val_loss: 0.9598 - val_acc: 0.5506\n",
            "Epoch 79/150 - 0.04s - loss: 0.8044 - acc: 0.6293 - val_loss: 0.9424 - val_acc: 0.5749\n",
            "Epoch 80/150 - 0.04s - loss: 0.8151 - acc: 0.6237 - val_loss: 0.9618 - val_acc: 0.5445\n",
            "Epoch 81/150 - 0.04s - loss: 0.8275 - acc: 0.6192 - val_loss: 0.9502 - val_acc: 0.5587\n",
            "Epoch 82/150 - 0.04s - loss: 0.8008 - acc: 0.6404 - val_loss: 0.9332 - val_acc: 0.5729\n",
            "Epoch 83/150 - 0.04s - loss: 0.8118 - acc: 0.6293 - val_loss: 0.9640 - val_acc: 0.5385\n",
            "Epoch 84/150 - 0.05s - loss: 0.8679 - acc: 0.5873 - val_loss: 1.0130 - val_acc: 0.5101\n",
            "Epoch 85/150 - 0.05s - loss: 0.8064 - acc: 0.6343 - val_loss: 0.9483 - val_acc: 0.5709\n",
            "Epoch 86/150 - 0.05s - loss: 0.7907 - acc: 0.6406 - val_loss: 0.9423 - val_acc: 0.5668\n",
            "Epoch 87/150 - 0.05s - loss: 0.7923 - acc: 0.6399 - val_loss: 0.9530 - val_acc: 0.5709\n",
            "Epoch 88/150 - 0.05s - loss: 0.8059 - acc: 0.6343 - val_loss: 0.9492 - val_acc: 0.5567\n",
            "Epoch 89/150 - 0.04s - loss: 0.7848 - acc: 0.6422 - val_loss: 0.9395 - val_acc: 0.5628\n",
            "Epoch 90/150 - 0.05s - loss: 0.8029 - acc: 0.6260 - val_loss: 0.9661 - val_acc: 0.5364\n",
            "Epoch 91/150 - 0.05s - loss: 0.7839 - acc: 0.6404 - val_loss: 0.9493 - val_acc: 0.5547\n",
            "Epoch 92/150 - 0.05s - loss: 0.7785 - acc: 0.6520 - val_loss: 0.9388 - val_acc: 0.5668\n",
            "Epoch 93/150 - 0.05s - loss: 0.7895 - acc: 0.6482 - val_loss: 0.9490 - val_acc: 0.5607\n",
            "Epoch 94/150 - 0.05s - loss: 0.7757 - acc: 0.6550 - val_loss: 0.9442 - val_acc: 0.5668\n",
            "Epoch 95/150 - 0.05s - loss: 0.7941 - acc: 0.6345 - val_loss: 0.9665 - val_acc: 0.5304\n",
            "Epoch 96/150 - 0.04s - loss: 0.7777 - acc: 0.6586 - val_loss: 0.9389 - val_acc: 0.5789\n",
            "Epoch 97/150 - 0.05s - loss: 0.7678 - acc: 0.6523 - val_loss: 0.9395 - val_acc: 0.5547\n",
            "Epoch 98/150 - 0.05s - loss: 0.7648 - acc: 0.6574 - val_loss: 0.9396 - val_acc: 0.5789\n",
            "Epoch 99/150 - 0.04s - loss: 0.7634 - acc: 0.6559 - val_loss: 0.9385 - val_acc: 0.5567\n",
            "Epoch 100/150 - 0.05s - loss: 0.7611 - acc: 0.6586 - val_loss: 0.9444 - val_acc: 0.5668\n",
            "Epoch 101/150 - 0.04s - loss: 0.7662 - acc: 0.6633 - val_loss: 0.9377 - val_acc: 0.5810\n",
            "Epoch 102/150 - 0.04s - loss: 0.7609 - acc: 0.6577 - val_loss: 0.9507 - val_acc: 0.5587\n",
            "Epoch 103/150 - 0.04s - loss: 0.7585 - acc: 0.6615 - val_loss: 0.9451 - val_acc: 0.5769\n",
            "Epoch 104/150 - 0.04s - loss: 0.7893 - acc: 0.6363 - val_loss: 0.9917 - val_acc: 0.5425\n",
            "Epoch 105/150 - 0.05s - loss: 0.7684 - acc: 0.6687 - val_loss: 0.9488 - val_acc: 0.5830\n",
            "Epoch 106/150 - 0.04s - loss: 0.7634 - acc: 0.6622 - val_loss: 0.9498 - val_acc: 0.5891\n",
            "Epoch 107/150 - 0.04s - loss: 0.7683 - acc: 0.6529 - val_loss: 0.9711 - val_acc: 0.5466\n",
            "Epoch 108/150 - 0.05s - loss: 0.7501 - acc: 0.6721 - val_loss: 0.9481 - val_acc: 0.5709\n",
            "Epoch 109/150 - 0.05s - loss: 0.7619 - acc: 0.6568 - val_loss: 0.9595 - val_acc: 0.5547\n",
            "Epoch 110/150 - 0.05s - loss: 0.7422 - acc: 0.6761 - val_loss: 0.9405 - val_acc: 0.5668\n",
            "Epoch 111/150 - 0.05s - loss: 0.8617 - acc: 0.5972 - val_loss: 1.0973 - val_acc: 0.5061\n",
            "Epoch 112/150 - 0.04s - loss: 0.7486 - acc: 0.6709 - val_loss: 0.9518 - val_acc: 0.5668\n",
            "Epoch 113/150 - 0.04s - loss: 0.7414 - acc: 0.6772 - val_loss: 0.9406 - val_acc: 0.5749\n",
            "Epoch 114/150 - 0.05s - loss: 0.7342 - acc: 0.6799 - val_loss: 0.9487 - val_acc: 0.5628\n",
            "Epoch 115/150 - 0.04s - loss: 0.7628 - acc: 0.6685 - val_loss: 0.9567 - val_acc: 0.5789\n",
            "Epoch 116/150 - 0.04s - loss: 0.7358 - acc: 0.6781 - val_loss: 0.9558 - val_acc: 0.5749\n",
            "Epoch 117/150 - 0.04s - loss: 0.7913 - acc: 0.6507 - val_loss: 0.9983 - val_acc: 0.5587\n",
            "Epoch 118/150 - 0.04s - loss: 0.7422 - acc: 0.6716 - val_loss: 0.9634 - val_acc: 0.5567\n",
            "Epoch 119/150 - 0.04s - loss: 0.7267 - acc: 0.6874 - val_loss: 0.9453 - val_acc: 0.5789\n",
            "Epoch 120/150 - 0.05s - loss: 0.7257 - acc: 0.6862 - val_loss: 0.9424 - val_acc: 0.5668\n",
            "Epoch 121/150 - 0.04s - loss: 0.7230 - acc: 0.6869 - val_loss: 0.9530 - val_acc: 0.5668\n",
            "Epoch 122/150 - 0.04s - loss: 0.7276 - acc: 0.6770 - val_loss: 0.9614 - val_acc: 0.5729\n",
            "Epoch 123/150 - 0.04s - loss: 0.7153 - acc: 0.6932 - val_loss: 0.9379 - val_acc: 0.5769\n",
            "Epoch 124/150 - 0.04s - loss: 0.7156 - acc: 0.6910 - val_loss: 0.9431 - val_acc: 0.5648\n",
            "Epoch 125/150 - 0.04s - loss: 0.7324 - acc: 0.6718 - val_loss: 0.9692 - val_acc: 0.5547\n",
            "Epoch 126/150 - 0.04s - loss: 0.7092 - acc: 0.6943 - val_loss: 0.9480 - val_acc: 0.5668\n",
            "Epoch 127/150 - 0.05s - loss: 0.7327 - acc: 0.6694 - val_loss: 0.9568 - val_acc: 0.5648\n",
            "Epoch 128/150 - 0.05s - loss: 0.7079 - acc: 0.7051 - val_loss: 0.9410 - val_acc: 0.5648\n",
            "Epoch 129/150 - 0.05s - loss: 0.7355 - acc: 0.6700 - val_loss: 0.9805 - val_acc: 0.5729\n",
            "Epoch 130/150 - 0.05s - loss: 0.7028 - acc: 0.6995 - val_loss: 0.9450 - val_acc: 0.5729\n",
            "Epoch 131/150 - 0.05s - loss: 0.7008 - acc: 0.7040 - val_loss: 0.9413 - val_acc: 0.5668\n",
            "Epoch 132/150 - 0.05s - loss: 0.7117 - acc: 0.6842 - val_loss: 0.9681 - val_acc: 0.5486\n",
            "Epoch 133/150 - 0.05s - loss: 0.7362 - acc: 0.6786 - val_loss: 0.9708 - val_acc: 0.5648\n",
            "Epoch 134/150 - 0.05s - loss: 0.7050 - acc: 0.6939 - val_loss: 0.9546 - val_acc: 0.5607\n",
            "Epoch 135/150 - 0.05s - loss: 0.6962 - acc: 0.7067 - val_loss: 0.9501 - val_acc: 0.5729\n",
            "Epoch 136/150 - 0.05s - loss: 0.6996 - acc: 0.7063 - val_loss: 0.9520 - val_acc: 0.5688\n",
            "Epoch 137/150 - 0.05s - loss: 0.7203 - acc: 0.6896 - val_loss: 0.9674 - val_acc: 0.5607\n",
            "Epoch 138/150 - 0.04s - loss: 0.6968 - acc: 0.7085 - val_loss: 0.9483 - val_acc: 0.5688\n",
            "Epoch 139/150 - 0.05s - loss: 0.7033 - acc: 0.6941 - val_loss: 0.9450 - val_acc: 0.5628\n",
            "Epoch 140/150 - 0.05s - loss: 0.6826 - acc: 0.7184 - val_loss: 0.9475 - val_acc: 0.5607\n",
            "Epoch 141/150 - 0.05s - loss: 0.6850 - acc: 0.7166 - val_loss: 0.9374 - val_acc: 0.5668\n",
            "Epoch 142/150 - 0.04s - loss: 0.6805 - acc: 0.7096 - val_loss: 0.9495 - val_acc: 0.5850\n",
            "Epoch 143/150 - 0.04s - loss: 0.6800 - acc: 0.7126 - val_loss: 0.9368 - val_acc: 0.5587\n",
            "Epoch 144/150 - 0.04s - loss: 0.6793 - acc: 0.7148 - val_loss: 0.9433 - val_acc: 0.5789\n",
            "Epoch 145/150 - 0.05s - loss: 0.6777 - acc: 0.7128 - val_loss: 0.9471 - val_acc: 0.5709\n",
            "Epoch 146/150 - 0.04s - loss: 0.6655 - acc: 0.7251 - val_loss: 0.9440 - val_acc: 0.5506\n",
            "Epoch 147/150 - 0.04s - loss: 0.7455 - acc: 0.6552 - val_loss: 0.9801 - val_acc: 0.5526\n",
            "Epoch 148/150 - 0.04s - loss: 0.6673 - acc: 0.7206 - val_loss: 0.9457 - val_acc: 0.5688\n",
            "Epoch 149/150 - 0.05s - loss: 0.6964 - acc: 0.6970 - val_loss: 0.9893 - val_acc: 0.5688\n",
            "Epoch 150/150 - 0.05s - loss: 0.6573 - acc: 0.7341 - val_loss: 0.9418 - val_acc: 0.5729\n",
            "\n",
            "Combination 4/252:\n",
            "Hidden Layers: [64, 32], Activation: relu, Learning Rate: 0.01, Batch Size: 64, Epochs: 50\n",
            "Epoch 1/50 - 0.03s - loss: 1.0877 - acc: 0.3862 - val_loss: 1.0931 - val_acc: 0.3704\n",
            "Epoch 2/50 - 0.03s - loss: 1.0825 - acc: 0.4118 - val_loss: 1.0894 - val_acc: 0.3947\n",
            "Epoch 3/50 - 0.03s - loss: 1.0779 - acc: 0.4211 - val_loss: 1.0863 - val_acc: 0.4211\n",
            "Epoch 4/50 - 0.03s - loss: 1.0741 - acc: 0.4233 - val_loss: 1.0839 - val_acc: 0.4170\n",
            "Epoch 5/50 - 0.03s - loss: 1.0704 - acc: 0.4406 - val_loss: 1.0801 - val_acc: 0.4352\n",
            "Epoch 6/50 - 0.03s - loss: 1.0670 - acc: 0.4444 - val_loss: 1.0770 - val_acc: 0.4474\n",
            "Epoch 7/50 - 0.03s - loss: 1.0635 - acc: 0.4534 - val_loss: 1.0729 - val_acc: 0.4413\n",
            "Epoch 8/50 - 0.03s - loss: 1.0603 - acc: 0.4548 - val_loss: 1.0702 - val_acc: 0.4413\n",
            "Epoch 9/50 - 0.04s - loss: 1.0565 - acc: 0.4613 - val_loss: 1.0675 - val_acc: 0.4514\n",
            "Epoch 10/50 - 0.04s - loss: 1.0534 - acc: 0.4694 - val_loss: 1.0655 - val_acc: 0.4555\n",
            "Epoch 11/50 - 0.03s - loss: 1.0502 - acc: 0.4712 - val_loss: 1.0628 - val_acc: 0.4474\n",
            "Epoch 12/50 - 0.03s - loss: 1.0468 - acc: 0.4775 - val_loss: 1.0597 - val_acc: 0.4656\n",
            "Epoch 13/50 - 0.03s - loss: 1.0435 - acc: 0.4807 - val_loss: 1.0574 - val_acc: 0.4656\n",
            "Epoch 14/50 - 0.03s - loss: 1.0404 - acc: 0.4719 - val_loss: 1.0536 - val_acc: 0.4514\n",
            "Epoch 15/50 - 0.03s - loss: 1.0374 - acc: 0.4836 - val_loss: 1.0527 - val_acc: 0.4777\n",
            "Epoch 16/50 - 0.03s - loss: 1.0351 - acc: 0.4717 - val_loss: 1.0487 - val_acc: 0.4474\n",
            "Epoch 17/50 - 0.03s - loss: 1.0301 - acc: 0.4948 - val_loss: 1.0460 - val_acc: 0.4858\n",
            "Epoch 18/50 - 0.03s - loss: 1.0270 - acc: 0.4888 - val_loss: 1.0439 - val_acc: 0.4615\n",
            "Epoch 19/50 - 0.03s - loss: 1.0238 - acc: 0.4903 - val_loss: 1.0411 - val_acc: 0.4717\n",
            "Epoch 20/50 - 0.03s - loss: 1.0216 - acc: 0.5007 - val_loss: 1.0405 - val_acc: 0.4858\n",
            "Epoch 21/50 - 0.03s - loss: 1.0170 - acc: 0.5081 - val_loss: 1.0364 - val_acc: 0.4879\n",
            "Epoch 22/50 - 0.03s - loss: 1.0145 - acc: 0.4978 - val_loss: 1.0353 - val_acc: 0.4858\n",
            "Epoch 23/50 - 0.03s - loss: 1.0129 - acc: 0.5040 - val_loss: 1.0341 - val_acc: 0.4818\n",
            "Epoch 24/50 - 0.03s - loss: 1.0078 - acc: 0.5061 - val_loss: 1.0294 - val_acc: 0.5000\n",
            "Epoch 25/50 - 0.03s - loss: 1.0050 - acc: 0.5027 - val_loss: 1.0270 - val_acc: 0.4899\n",
            "Epoch 26/50 - 0.03s - loss: 1.0015 - acc: 0.5079 - val_loss: 1.0236 - val_acc: 0.4960\n",
            "Epoch 27/50 - 0.03s - loss: 0.9986 - acc: 0.5119 - val_loss: 1.0209 - val_acc: 0.4939\n",
            "Epoch 28/50 - 0.03s - loss: 0.9973 - acc: 0.5090 - val_loss: 1.0200 - val_acc: 0.5040\n",
            "Epoch 29/50 - 0.03s - loss: 0.9956 - acc: 0.5103 - val_loss: 1.0209 - val_acc: 0.4879\n",
            "Epoch 30/50 - 0.03s - loss: 0.9908 - acc: 0.5211 - val_loss: 1.0149 - val_acc: 0.5020\n",
            "Epoch 31/50 - 0.03s - loss: 0.9877 - acc: 0.5207 - val_loss: 1.0130 - val_acc: 0.4980\n",
            "Epoch 32/50 - 0.03s - loss: 0.9846 - acc: 0.5229 - val_loss: 1.0093 - val_acc: 0.5081\n",
            "Epoch 33/50 - 0.03s - loss: 0.9826 - acc: 0.5227 - val_loss: 1.0084 - val_acc: 0.5142\n",
            "Epoch 34/50 - 0.03s - loss: 0.9834 - acc: 0.5234 - val_loss: 1.0093 - val_acc: 0.5020\n",
            "Epoch 35/50 - 0.03s - loss: 0.9816 - acc: 0.5209 - val_loss: 1.0083 - val_acc: 0.4960\n",
            "Epoch 36/50 - 0.03s - loss: 0.9758 - acc: 0.5292 - val_loss: 1.0012 - val_acc: 0.5020\n",
            "Epoch 37/50 - 0.03s - loss: 0.9716 - acc: 0.5319 - val_loss: 0.9990 - val_acc: 0.5020\n",
            "Epoch 38/50 - 0.03s - loss: 0.9706 - acc: 0.5313 - val_loss: 0.9989 - val_acc: 0.5101\n",
            "Epoch 39/50 - 0.03s - loss: 0.9679 - acc: 0.5346 - val_loss: 0.9948 - val_acc: 0.5142\n",
            "Epoch 40/50 - 0.03s - loss: 0.9648 - acc: 0.5358 - val_loss: 0.9942 - val_acc: 0.5040\n",
            "Epoch 41/50 - 0.03s - loss: 0.9645 - acc: 0.5340 - val_loss: 0.9951 - val_acc: 0.5162\n",
            "Epoch 42/50 - 0.03s - loss: 0.9602 - acc: 0.5418 - val_loss: 0.9904 - val_acc: 0.5182\n",
            "Epoch 43/50 - 0.04s - loss: 0.9613 - acc: 0.5412 - val_loss: 0.9913 - val_acc: 0.5162\n",
            "Epoch 44/50 - 0.04s - loss: 0.9587 - acc: 0.5342 - val_loss: 0.9912 - val_acc: 0.5101\n",
            "Epoch 45/50 - 0.04s - loss: 0.9540 - acc: 0.5418 - val_loss: 0.9869 - val_acc: 0.5162\n",
            "Epoch 46/50 - 0.04s - loss: 0.9521 - acc: 0.5466 - val_loss: 0.9835 - val_acc: 0.5304\n",
            "Epoch 47/50 - 0.03s - loss: 0.9488 - acc: 0.5508 - val_loss: 0.9814 - val_acc: 0.5263\n",
            "Epoch 48/50 - 0.04s - loss: 0.9469 - acc: 0.5481 - val_loss: 0.9807 - val_acc: 0.5223\n",
            "Epoch 49/50 - 0.03s - loss: 0.9470 - acc: 0.5515 - val_loss: 0.9833 - val_acc: 0.5344\n",
            "Epoch 50/50 - 0.03s - loss: 0.9430 - acc: 0.5574 - val_loss: 0.9775 - val_acc: 0.5364\n",
            "\n",
            "Combination 5/252:\n",
            "Hidden Layers: [64, 32], Activation: relu, Learning Rate: 0.01, Batch Size: 64, Epochs: 100\n",
            "Epoch 1/100 - 0.03s - loss: 1.1041 - acc: 0.3228 - val_loss: 1.1007 - val_acc: 0.3158\n",
            "Epoch 2/100 - 0.03s - loss: 1.0979 - acc: 0.3345 - val_loss: 1.0962 - val_acc: 0.3259\n",
            "Epoch 3/100 - 0.03s - loss: 1.0940 - acc: 0.3635 - val_loss: 1.0942 - val_acc: 0.3583\n",
            "Epoch 4/100 - 0.03s - loss: 1.0908 - acc: 0.3808 - val_loss: 1.0919 - val_acc: 0.3704\n",
            "Epoch 5/100 - 0.03s - loss: 1.0879 - acc: 0.4049 - val_loss: 1.0896 - val_acc: 0.3866\n",
            "Epoch 6/100 - 0.03s - loss: 1.0854 - acc: 0.4145 - val_loss: 1.0881 - val_acc: 0.3887\n",
            "Epoch 7/100 - 0.03s - loss: 1.0828 - acc: 0.4287 - val_loss: 1.0856 - val_acc: 0.4130\n",
            "Epoch 8/100 - 0.03s - loss: 1.0805 - acc: 0.4424 - val_loss: 1.0834 - val_acc: 0.4089\n",
            "Epoch 9/100 - 0.03s - loss: 1.0780 - acc: 0.4451 - val_loss: 1.0814 - val_acc: 0.4211\n",
            "Epoch 10/100 - 0.03s - loss: 1.0753 - acc: 0.4575 - val_loss: 1.0785 - val_acc: 0.4271\n",
            "Epoch 11/100 - 0.03s - loss: 1.0723 - acc: 0.4613 - val_loss: 1.0761 - val_acc: 0.4352\n",
            "Epoch 12/100 - 0.03s - loss: 1.0689 - acc: 0.4600 - val_loss: 1.0739 - val_acc: 0.4332\n",
            "Epoch 13/100 - 0.04s - loss: 1.0655 - acc: 0.4660 - val_loss: 1.0711 - val_acc: 0.4312\n",
            "Epoch 14/100 - 0.03s - loss: 1.0620 - acc: 0.4719 - val_loss: 1.0686 - val_acc: 0.4433\n",
            "Epoch 15/100 - 0.03s - loss: 1.0584 - acc: 0.4703 - val_loss: 1.0667 - val_acc: 0.4413\n",
            "Epoch 16/100 - 0.03s - loss: 1.0544 - acc: 0.4699 - val_loss: 1.0649 - val_acc: 0.4453\n",
            "Epoch 17/100 - 0.03s - loss: 1.0506 - acc: 0.4757 - val_loss: 1.0622 - val_acc: 0.4433\n",
            "Epoch 18/100 - 0.04s - loss: 1.0479 - acc: 0.4739 - val_loss: 1.0604 - val_acc: 0.4595\n",
            "Epoch 19/100 - 0.04s - loss: 1.0440 - acc: 0.4766 - val_loss: 1.0582 - val_acc: 0.4595\n",
            "Epoch 20/100 - 0.05s - loss: 1.0395 - acc: 0.4858 - val_loss: 1.0556 - val_acc: 0.4696\n",
            "Epoch 21/100 - 0.03s - loss: 1.0356 - acc: 0.4867 - val_loss: 1.0532 - val_acc: 0.4717\n",
            "Epoch 22/100 - 0.03s - loss: 1.0325 - acc: 0.4876 - val_loss: 1.0510 - val_acc: 0.4879\n",
            "Epoch 23/100 - 0.03s - loss: 1.0298 - acc: 0.4836 - val_loss: 1.0502 - val_acc: 0.4555\n",
            "Epoch 24/100 - 0.03s - loss: 1.0288 - acc: 0.4829 - val_loss: 1.0501 - val_acc: 0.4514\n",
            "Epoch 25/100 - 0.03s - loss: 1.0234 - acc: 0.4888 - val_loss: 1.0460 - val_acc: 0.4676\n",
            "Epoch 26/100 - 0.03s - loss: 1.0220 - acc: 0.4874 - val_loss: 1.0460 - val_acc: 0.4514\n",
            "Epoch 27/100 - 0.03s - loss: 1.0185 - acc: 0.4910 - val_loss: 1.0440 - val_acc: 0.4555\n",
            "Epoch 28/100 - 0.03s - loss: 1.0141 - acc: 0.4991 - val_loss: 1.0404 - val_acc: 0.4818\n",
            "Epoch 29/100 - 0.04s - loss: 1.0112 - acc: 0.4980 - val_loss: 1.0380 - val_acc: 0.5061\n",
            "Epoch 30/100 - 0.03s - loss: 1.0115 - acc: 0.4980 - val_loss: 1.0388 - val_acc: 0.4899\n",
            "Epoch 31/100 - 0.03s - loss: 1.0058 - acc: 0.5036 - val_loss: 1.0342 - val_acc: 0.5081\n",
            "Epoch 32/100 - 0.03s - loss: 1.0041 - acc: 0.5040 - val_loss: 1.0333 - val_acc: 0.5061\n",
            "Epoch 33/100 - 0.03s - loss: 1.0007 - acc: 0.5076 - val_loss: 1.0308 - val_acc: 0.5162\n",
            "Epoch 34/100 - 0.03s - loss: 1.0027 - acc: 0.5025 - val_loss: 1.0357 - val_acc: 0.4676\n",
            "Epoch 35/100 - 0.03s - loss: 0.9949 - acc: 0.5135 - val_loss: 1.0274 - val_acc: 0.5040\n",
            "Epoch 36/100 - 0.03s - loss: 0.9925 - acc: 0.5130 - val_loss: 1.0258 - val_acc: 0.5000\n",
            "Epoch 37/100 - 0.03s - loss: 0.9903 - acc: 0.5162 - val_loss: 1.0238 - val_acc: 0.5182\n",
            "Epoch 38/100 - 0.03s - loss: 0.9876 - acc: 0.5214 - val_loss: 1.0222 - val_acc: 0.5202\n",
            "Epoch 39/100 - 0.03s - loss: 0.9860 - acc: 0.5218 - val_loss: 1.0214 - val_acc: 0.5101\n",
            "Epoch 40/100 - 0.03s - loss: 0.9838 - acc: 0.5193 - val_loss: 1.0210 - val_acc: 0.5000\n",
            "Epoch 41/100 - 0.03s - loss: 0.9807 - acc: 0.5196 - val_loss: 1.0178 - val_acc: 0.5000\n",
            "Epoch 42/100 - 0.03s - loss: 0.9783 - acc: 0.5281 - val_loss: 1.0152 - val_acc: 0.5202\n",
            "Epoch 43/100 - 0.03s - loss: 0.9758 - acc: 0.5252 - val_loss: 1.0135 - val_acc: 0.5121\n",
            "Epoch 44/100 - 0.03s - loss: 0.9741 - acc: 0.5243 - val_loss: 1.0128 - val_acc: 0.5121\n",
            "Epoch 45/100 - 0.03s - loss: 0.9717 - acc: 0.5322 - val_loss: 1.0118 - val_acc: 0.5081\n",
            "Epoch 46/100 - 0.03s - loss: 0.9702 - acc: 0.5337 - val_loss: 1.0103 - val_acc: 0.5081\n",
            "Epoch 47/100 - 0.03s - loss: 0.9716 - acc: 0.5308 - val_loss: 1.0140 - val_acc: 0.4919\n",
            "Epoch 48/100 - 0.03s - loss: 0.9658 - acc: 0.5355 - val_loss: 1.0071 - val_acc: 0.5202\n",
            "Epoch 49/100 - 0.03s - loss: 0.9635 - acc: 0.5385 - val_loss: 1.0050 - val_acc: 0.5182\n",
            "Epoch 50/100 - 0.03s - loss: 0.9675 - acc: 0.5261 - val_loss: 1.0109 - val_acc: 0.4879\n",
            "Epoch 51/100 - 0.03s - loss: 0.9592 - acc: 0.5376 - val_loss: 1.0013 - val_acc: 0.5304\n",
            "Epoch 52/100 - 0.03s - loss: 0.9665 - acc: 0.5268 - val_loss: 1.0123 - val_acc: 0.4919\n",
            "Epoch 53/100 - 0.03s - loss: 0.9552 - acc: 0.5418 - val_loss: 0.9992 - val_acc: 0.5304\n",
            "Epoch 54/100 - 0.03s - loss: 0.9675 - acc: 0.5353 - val_loss: 1.0087 - val_acc: 0.5324\n",
            "Epoch 55/100 - 0.03s - loss: 0.9535 - acc: 0.5403 - val_loss: 0.9968 - val_acc: 0.5202\n",
            "Epoch 56/100 - 0.03s - loss: 0.9501 - acc: 0.5443 - val_loss: 0.9949 - val_acc: 0.5304\n",
            "Epoch 57/100 - 0.04s - loss: 0.9480 - acc: 0.5450 - val_loss: 0.9928 - val_acc: 0.5324\n",
            "Epoch 58/100 - 0.03s - loss: 0.9479 - acc: 0.5459 - val_loss: 0.9928 - val_acc: 0.5364\n",
            "Epoch 59/100 - 0.03s - loss: 0.9489 - acc: 0.5443 - val_loss: 0.9931 - val_acc: 0.5304\n",
            "Epoch 60/100 - 0.03s - loss: 0.9447 - acc: 0.5529 - val_loss: 0.9928 - val_acc: 0.5182\n",
            "Epoch 61/100 - 0.03s - loss: 0.9423 - acc: 0.5461 - val_loss: 0.9887 - val_acc: 0.5344\n",
            "Epoch 62/100 - 0.03s - loss: 0.9428 - acc: 0.5450 - val_loss: 0.9890 - val_acc: 0.5304\n",
            "Epoch 63/100 - 0.03s - loss: 0.9384 - acc: 0.5533 - val_loss: 0.9875 - val_acc: 0.5364\n",
            "Epoch 64/100 - 0.03s - loss: 0.9383 - acc: 0.5502 - val_loss: 0.9864 - val_acc: 0.5425\n",
            "Epoch 65/100 - 0.03s - loss: 0.9357 - acc: 0.5511 - val_loss: 0.9875 - val_acc: 0.5263\n",
            "Epoch 66/100 - 0.03s - loss: 0.9420 - acc: 0.5486 - val_loss: 0.9962 - val_acc: 0.4919\n",
            "Epoch 67/100 - 0.03s - loss: 0.9305 - acc: 0.5592 - val_loss: 0.9820 - val_acc: 0.5466\n",
            "Epoch 68/100 - 0.03s - loss: 0.9349 - acc: 0.5535 - val_loss: 0.9883 - val_acc: 0.5040\n",
            "Epoch 69/100 - 0.03s - loss: 0.9397 - acc: 0.5484 - val_loss: 0.9878 - val_acc: 0.5263\n",
            "Epoch 70/100 - 0.03s - loss: 0.9297 - acc: 0.5560 - val_loss: 0.9805 - val_acc: 0.5385\n",
            "Epoch 71/100 - 0.03s - loss: 0.9261 - acc: 0.5576 - val_loss: 0.9809 - val_acc: 0.5283\n",
            "Epoch 72/100 - 0.03s - loss: 0.9249 - acc: 0.5643 - val_loss: 0.9812 - val_acc: 0.5385\n",
            "Epoch 73/100 - 0.03s - loss: 0.9220 - acc: 0.5605 - val_loss: 0.9761 - val_acc: 0.5364\n",
            "Epoch 74/100 - 0.03s - loss: 0.9225 - acc: 0.5596 - val_loss: 0.9758 - val_acc: 0.5385\n",
            "Epoch 75/100 - 0.03s - loss: 0.9182 - acc: 0.5641 - val_loss: 0.9742 - val_acc: 0.5385\n",
            "Epoch 76/100 - 0.03s - loss: 0.9354 - acc: 0.5517 - val_loss: 0.9971 - val_acc: 0.4838\n",
            "Epoch 77/100 - 0.03s - loss: 0.9271 - acc: 0.5619 - val_loss: 0.9805 - val_acc: 0.5405\n",
            "Epoch 78/100 - 0.03s - loss: 0.9362 - acc: 0.5583 - val_loss: 0.9884 - val_acc: 0.5405\n",
            "Epoch 79/100 - 0.03s - loss: 0.9137 - acc: 0.5668 - val_loss: 0.9719 - val_acc: 0.5344\n",
            "Epoch 80/100 - 0.03s - loss: 0.9222 - acc: 0.5630 - val_loss: 0.9861 - val_acc: 0.5182\n",
            "Epoch 81/100 - 0.03s - loss: 0.9118 - acc: 0.5691 - val_loss: 0.9749 - val_acc: 0.5364\n",
            "Epoch 82/100 - 0.03s - loss: 0.9105 - acc: 0.5655 - val_loss: 0.9696 - val_acc: 0.5385\n",
            "Epoch 83/100 - 0.03s - loss: 0.9086 - acc: 0.5684 - val_loss: 0.9699 - val_acc: 0.5405\n",
            "Epoch 84/100 - 0.03s - loss: 0.9118 - acc: 0.5684 - val_loss: 0.9710 - val_acc: 0.5405\n",
            "Epoch 85/100 - 0.03s - loss: 0.9068 - acc: 0.5767 - val_loss: 0.9685 - val_acc: 0.5405\n",
            "Epoch 86/100 - 0.03s - loss: 0.9159 - acc: 0.5774 - val_loss: 0.9760 - val_acc: 0.5466\n",
            "Epoch 87/100 - 0.03s - loss: 0.9022 - acc: 0.5747 - val_loss: 0.9670 - val_acc: 0.5385\n",
            "Epoch 88/100 - 0.03s - loss: 0.9015 - acc: 0.5756 - val_loss: 0.9689 - val_acc: 0.5405\n",
            "Epoch 89/100 - 0.03s - loss: 0.8989 - acc: 0.5794 - val_loss: 0.9657 - val_acc: 0.5425\n",
            "Epoch 90/100 - 0.03s - loss: 0.8997 - acc: 0.5762 - val_loss: 0.9708 - val_acc: 0.5324\n",
            "Epoch 91/100 - 0.03s - loss: 0.8967 - acc: 0.5814 - val_loss: 0.9664 - val_acc: 0.5445\n",
            "Epoch 92/100 - 0.03s - loss: 0.9166 - acc: 0.5614 - val_loss: 0.9906 - val_acc: 0.4980\n",
            "Epoch 93/100 - 0.03s - loss: 0.8936 - acc: 0.5814 - val_loss: 0.9646 - val_acc: 0.5385\n",
            "Epoch 94/100 - 0.04s - loss: 0.9014 - acc: 0.5760 - val_loss: 0.9770 - val_acc: 0.5182\n",
            "Epoch 95/100 - 0.04s - loss: 0.8925 - acc: 0.5848 - val_loss: 0.9634 - val_acc: 0.5405\n",
            "Epoch 96/100 - 0.04s - loss: 0.8979 - acc: 0.5852 - val_loss: 0.9677 - val_acc: 0.5486\n",
            "Epoch 97/100 - 0.03s - loss: 0.9197 - acc: 0.5709 - val_loss: 0.9847 - val_acc: 0.5486\n",
            "Epoch 98/100 - 0.03s - loss: 0.8874 - acc: 0.5855 - val_loss: 0.9630 - val_acc: 0.5385\n",
            "Epoch 99/100 - 0.03s - loss: 0.8866 - acc: 0.5823 - val_loss: 0.9609 - val_acc: 0.5425\n",
            "Epoch 100/100 - 0.03s - loss: 0.8880 - acc: 0.5825 - val_loss: 0.9668 - val_acc: 0.5324\n",
            "\n",
            "Combination 6/252:\n",
            "Hidden Layers: [64, 32], Activation: relu, Learning Rate: 0.01, Batch Size: 64, Epochs: 150\n",
            "Epoch 1/150 - 0.03s - loss: 1.0902 - acc: 0.3806 - val_loss: 1.0966 - val_acc: 0.3421\n",
            "Epoch 2/150 - 0.03s - loss: 1.0840 - acc: 0.4024 - val_loss: 1.0914 - val_acc: 0.3826\n",
            "Epoch 3/150 - 0.03s - loss: 1.0790 - acc: 0.4179 - val_loss: 1.0874 - val_acc: 0.3907\n",
            "Epoch 4/150 - 0.03s - loss: 1.0745 - acc: 0.4229 - val_loss: 1.0843 - val_acc: 0.3927\n",
            "Epoch 5/150 - 0.03s - loss: 1.0702 - acc: 0.4503 - val_loss: 1.0804 - val_acc: 0.4352\n",
            "Epoch 6/150 - 0.03s - loss: 1.0654 - acc: 0.4494 - val_loss: 1.0772 - val_acc: 0.4312\n",
            "Epoch 7/150 - 0.03s - loss: 1.0612 - acc: 0.4548 - val_loss: 1.0745 - val_acc: 0.4453\n",
            "Epoch 8/150 - 0.03s - loss: 1.0572 - acc: 0.4674 - val_loss: 1.0713 - val_acc: 0.4494\n",
            "Epoch 9/150 - 0.03s - loss: 1.0530 - acc: 0.4692 - val_loss: 1.0687 - val_acc: 0.4656\n",
            "Epoch 10/150 - 0.03s - loss: 1.0499 - acc: 0.4654 - val_loss: 1.0663 - val_acc: 0.4534\n",
            "Epoch 11/150 - 0.03s - loss: 1.0455 - acc: 0.4712 - val_loss: 1.0642 - val_acc: 0.4676\n",
            "Epoch 12/150 - 0.03s - loss: 1.0426 - acc: 0.4723 - val_loss: 1.0625 - val_acc: 0.4636\n",
            "Epoch 13/150 - 0.03s - loss: 1.0394 - acc: 0.4730 - val_loss: 1.0627 - val_acc: 0.4575\n",
            "Epoch 14/150 - 0.03s - loss: 1.0357 - acc: 0.4766 - val_loss: 1.0602 - val_acc: 0.4636\n",
            "Epoch 15/150 - 0.03s - loss: 1.0326 - acc: 0.4816 - val_loss: 1.0576 - val_acc: 0.4737\n",
            "Epoch 16/150 - 0.03s - loss: 1.0303 - acc: 0.4811 - val_loss: 1.0576 - val_acc: 0.4676\n",
            "Epoch 17/150 - 0.03s - loss: 1.0285 - acc: 0.4773 - val_loss: 1.0556 - val_acc: 0.4696\n",
            "Epoch 18/150 - 0.03s - loss: 1.0241 - acc: 0.4885 - val_loss: 1.0527 - val_acc: 0.4777\n",
            "Epoch 19/150 - 0.03s - loss: 1.0215 - acc: 0.4894 - val_loss: 1.0514 - val_acc: 0.4717\n",
            "Epoch 20/150 - 0.03s - loss: 1.0187 - acc: 0.4921 - val_loss: 1.0495 - val_acc: 0.4798\n",
            "Epoch 21/150 - 0.03s - loss: 1.0170 - acc: 0.4930 - val_loss: 1.0475 - val_acc: 0.4798\n",
            "Epoch 22/150 - 0.03s - loss: 1.0134 - acc: 0.4989 - val_loss: 1.0465 - val_acc: 0.4899\n",
            "Epoch 23/150 - 0.03s - loss: 1.0106 - acc: 0.4993 - val_loss: 1.0447 - val_acc: 0.4838\n",
            "Epoch 24/150 - 0.03s - loss: 1.0088 - acc: 0.4993 - val_loss: 1.0442 - val_acc: 0.4818\n",
            "Epoch 25/150 - 0.04s - loss: 1.0074 - acc: 0.5047 - val_loss: 1.0425 - val_acc: 0.4919\n",
            "Epoch 26/150 - 0.04s - loss: 1.0109 - acc: 0.4984 - val_loss: 1.0490 - val_acc: 0.4636\n",
            "Epoch 27/150 - 0.04s - loss: 1.0016 - acc: 0.5027 - val_loss: 1.0381 - val_acc: 0.4960\n",
            "Epoch 28/150 - 0.04s - loss: 0.9988 - acc: 0.5112 - val_loss: 1.0371 - val_acc: 0.4960\n",
            "Epoch 29/150 - 0.04s - loss: 0.9950 - acc: 0.5108 - val_loss: 1.0335 - val_acc: 0.5142\n",
            "Epoch 30/150 - 0.03s - loss: 0.9929 - acc: 0.5126 - val_loss: 1.0327 - val_acc: 0.5081\n",
            "Epoch 31/150 - 0.03s - loss: 0.9896 - acc: 0.5142 - val_loss: 1.0300 - val_acc: 0.5223\n",
            "Epoch 32/150 - 0.03s - loss: 0.9898 - acc: 0.5144 - val_loss: 1.0297 - val_acc: 0.5142\n",
            "Epoch 33/150 - 0.03s - loss: 0.9868 - acc: 0.5180 - val_loss: 1.0289 - val_acc: 0.5121\n",
            "Epoch 34/150 - 0.04s - loss: 0.9845 - acc: 0.5187 - val_loss: 1.0277 - val_acc: 0.5081\n",
            "Epoch 35/150 - 0.04s - loss: 0.9805 - acc: 0.5218 - val_loss: 1.0250 - val_acc: 0.5243\n",
            "Epoch 36/150 - 0.03s - loss: 0.9796 - acc: 0.5223 - val_loss: 1.0224 - val_acc: 0.5263\n",
            "Epoch 37/150 - 0.03s - loss: 0.9768 - acc: 0.5245 - val_loss: 1.0213 - val_acc: 0.5162\n",
            "Epoch 38/150 - 0.03s - loss: 0.9739 - acc: 0.5324 - val_loss: 1.0174 - val_acc: 0.5344\n",
            "Epoch 39/150 - 0.03s - loss: 0.9700 - acc: 0.5306 - val_loss: 1.0156 - val_acc: 0.5344\n",
            "Epoch 40/150 - 0.03s - loss: 0.9667 - acc: 0.5349 - val_loss: 1.0129 - val_acc: 0.5324\n",
            "Epoch 41/150 - 0.03s - loss: 0.9664 - acc: 0.5360 - val_loss: 1.0113 - val_acc: 0.5324\n",
            "Epoch 42/150 - 0.03s - loss: 0.9625 - acc: 0.5355 - val_loss: 1.0094 - val_acc: 0.5304\n",
            "Epoch 43/150 - 0.03s - loss: 0.9603 - acc: 0.5400 - val_loss: 1.0071 - val_acc: 0.5364\n",
            "Epoch 44/150 - 0.03s - loss: 0.9571 - acc: 0.5371 - val_loss: 1.0058 - val_acc: 0.5405\n",
            "Epoch 45/150 - 0.03s - loss: 0.9555 - acc: 0.5414 - val_loss: 1.0052 - val_acc: 0.5263\n",
            "Epoch 46/150 - 0.03s - loss: 0.9567 - acc: 0.5436 - val_loss: 1.0054 - val_acc: 0.5486\n",
            "Epoch 47/150 - 0.03s - loss: 0.9516 - acc: 0.5450 - val_loss: 1.0028 - val_acc: 0.5182\n",
            "Epoch 48/150 - 0.03s - loss: 0.9482 - acc: 0.5466 - val_loss: 0.9990 - val_acc: 0.5324\n",
            "Epoch 49/150 - 0.03s - loss: 0.9467 - acc: 0.5506 - val_loss: 0.9971 - val_acc: 0.5425\n",
            "Epoch 50/150 - 0.03s - loss: 0.9438 - acc: 0.5504 - val_loss: 0.9965 - val_acc: 0.5263\n",
            "Epoch 51/150 - 0.03s - loss: 0.9419 - acc: 0.5499 - val_loss: 0.9943 - val_acc: 0.5324\n",
            "Epoch 52/150 - 0.03s - loss: 0.9404 - acc: 0.5495 - val_loss: 0.9944 - val_acc: 0.5283\n",
            "Epoch 53/150 - 0.03s - loss: 0.9417 - acc: 0.5486 - val_loss: 0.9966 - val_acc: 0.5142\n",
            "Epoch 54/150 - 0.03s - loss: 0.9357 - acc: 0.5556 - val_loss: 0.9894 - val_acc: 0.5324\n",
            "Epoch 55/150 - 0.03s - loss: 0.9338 - acc: 0.5583 - val_loss: 0.9882 - val_acc: 0.5405\n",
            "Epoch 56/150 - 0.04s - loss: 0.9396 - acc: 0.5504 - val_loss: 0.9997 - val_acc: 0.5101\n",
            "Epoch 57/150 - 0.03s - loss: 0.9368 - acc: 0.5619 - val_loss: 0.9910 - val_acc: 0.5445\n",
            "Epoch 58/150 - 0.03s - loss: 0.9323 - acc: 0.5616 - val_loss: 0.9869 - val_acc: 0.5425\n",
            "Epoch 59/150 - 0.03s - loss: 0.9258 - acc: 0.5632 - val_loss: 0.9832 - val_acc: 0.5425\n",
            "Epoch 60/150 - 0.03s - loss: 0.9307 - acc: 0.5625 - val_loss: 0.9911 - val_acc: 0.5283\n",
            "Epoch 61/150 - 0.03s - loss: 0.9289 - acc: 0.5612 - val_loss: 0.9862 - val_acc: 0.5405\n",
            "Epoch 62/150 - 0.03s - loss: 0.9277 - acc: 0.5580 - val_loss: 0.9926 - val_acc: 0.5283\n",
            "Epoch 63/150 - 0.03s - loss: 0.9210 - acc: 0.5661 - val_loss: 0.9812 - val_acc: 0.5364\n",
            "Epoch 64/150 - 0.03s - loss: 0.9182 - acc: 0.5715 - val_loss: 0.9792 - val_acc: 0.5486\n",
            "Epoch 65/150 - 0.03s - loss: 0.9151 - acc: 0.5684 - val_loss: 0.9799 - val_acc: 0.5304\n",
            "Epoch 66/150 - 0.03s - loss: 0.9153 - acc: 0.5733 - val_loss: 0.9811 - val_acc: 0.5364\n",
            "Epoch 67/150 - 0.03s - loss: 0.9118 - acc: 0.5702 - val_loss: 0.9793 - val_acc: 0.5425\n",
            "Epoch 68/150 - 0.03s - loss: 0.9098 - acc: 0.5684 - val_loss: 0.9769 - val_acc: 0.5364\n",
            "Epoch 69/150 - 0.03s - loss: 0.9088 - acc: 0.5713 - val_loss: 0.9783 - val_acc: 0.5364\n",
            "Epoch 70/150 - 0.03s - loss: 0.9120 - acc: 0.5726 - val_loss: 0.9758 - val_acc: 0.5385\n",
            "Epoch 71/150 - 0.03s - loss: 0.9048 - acc: 0.5758 - val_loss: 0.9723 - val_acc: 0.5466\n",
            "Epoch 72/150 - 0.03s - loss: 0.9105 - acc: 0.5709 - val_loss: 0.9765 - val_acc: 0.5526\n",
            "Epoch 73/150 - 0.03s - loss: 0.9013 - acc: 0.5805 - val_loss: 0.9753 - val_acc: 0.5385\n",
            "Epoch 74/150 - 0.03s - loss: 0.9003 - acc: 0.5735 - val_loss: 0.9737 - val_acc: 0.5425\n",
            "Epoch 75/150 - 0.03s - loss: 0.8986 - acc: 0.5814 - val_loss: 0.9715 - val_acc: 0.5466\n",
            "Epoch 76/150 - 0.03s - loss: 0.9005 - acc: 0.5798 - val_loss: 0.9742 - val_acc: 0.5344\n",
            "Epoch 77/150 - 0.03s - loss: 0.8940 - acc: 0.5830 - val_loss: 0.9678 - val_acc: 0.5526\n",
            "Epoch 78/150 - 0.03s - loss: 0.8982 - acc: 0.5747 - val_loss: 0.9778 - val_acc: 0.5445\n",
            "Epoch 79/150 - 0.03s - loss: 0.8958 - acc: 0.5816 - val_loss: 0.9717 - val_acc: 0.5364\n",
            "Epoch 80/150 - 0.03s - loss: 0.8999 - acc: 0.5807 - val_loss: 0.9746 - val_acc: 0.5486\n",
            "Epoch 81/150 - 0.03s - loss: 0.8985 - acc: 0.5794 - val_loss: 0.9815 - val_acc: 0.5182\n",
            "Epoch 82/150 - 0.03s - loss: 0.8856 - acc: 0.5888 - val_loss: 0.9693 - val_acc: 0.5486\n",
            "Epoch 83/150 - 0.03s - loss: 0.8894 - acc: 0.5906 - val_loss: 0.9725 - val_acc: 0.5324\n",
            "Epoch 84/150 - 0.03s - loss: 0.8896 - acc: 0.5792 - val_loss: 0.9763 - val_acc: 0.5385\n",
            "Epoch 85/150 - 0.03s - loss: 0.8811 - acc: 0.5949 - val_loss: 0.9663 - val_acc: 0.5466\n",
            "Epoch 86/150 - 0.03s - loss: 0.8874 - acc: 0.5897 - val_loss: 0.9730 - val_acc: 0.5385\n",
            "Epoch 87/150 - 0.03s - loss: 0.8850 - acc: 0.5830 - val_loss: 0.9752 - val_acc: 0.5425\n",
            "Epoch 88/150 - 0.03s - loss: 0.8931 - acc: 0.5738 - val_loss: 0.9797 - val_acc: 0.5263\n",
            "Epoch 89/150 - 0.03s - loss: 0.8761 - acc: 0.5954 - val_loss: 0.9629 - val_acc: 0.5567\n",
            "Epoch 90/150 - 0.03s - loss: 0.8780 - acc: 0.5906 - val_loss: 0.9728 - val_acc: 0.5466\n",
            "Epoch 91/150 - 0.03s - loss: 0.8800 - acc: 0.5942 - val_loss: 0.9680 - val_acc: 0.5405\n",
            "Epoch 92/150 - 0.03s - loss: 0.8839 - acc: 0.5929 - val_loss: 0.9679 - val_acc: 0.5405\n",
            "Epoch 93/150 - 0.03s - loss: 0.8743 - acc: 0.5985 - val_loss: 0.9635 - val_acc: 0.5567\n",
            "Epoch 94/150 - 0.03s - loss: 0.8691 - acc: 0.5996 - val_loss: 0.9617 - val_acc: 0.5668\n",
            "Epoch 95/150 - 0.03s - loss: 0.8647 - acc: 0.6044 - val_loss: 0.9606 - val_acc: 0.5628\n",
            "Epoch 96/150 - 0.03s - loss: 0.8733 - acc: 0.5990 - val_loss: 0.9740 - val_acc: 0.5142\n",
            "Epoch 97/150 - 0.03s - loss: 0.8684 - acc: 0.5963 - val_loss: 0.9660 - val_acc: 0.5587\n",
            "Epoch 98/150 - 0.03s - loss: 0.8700 - acc: 0.6023 - val_loss: 0.9632 - val_acc: 0.5567\n",
            "Epoch 99/150 - 0.03s - loss: 0.8723 - acc: 0.5996 - val_loss: 0.9683 - val_acc: 0.5547\n",
            "Epoch 100/150 - 0.03s - loss: 0.8803 - acc: 0.5801 - val_loss: 0.9914 - val_acc: 0.5162\n",
            "Epoch 101/150 - 0.03s - loss: 0.8584 - acc: 0.6073 - val_loss: 0.9593 - val_acc: 0.5607\n",
            "Epoch 102/150 - 0.03s - loss: 0.8800 - acc: 0.5834 - val_loss: 0.9937 - val_acc: 0.5020\n",
            "Epoch 103/150 - 0.03s - loss: 0.8641 - acc: 0.5994 - val_loss: 0.9643 - val_acc: 0.5486\n",
            "Epoch 104/150 - 0.03s - loss: 0.8580 - acc: 0.6120 - val_loss: 0.9639 - val_acc: 0.5405\n",
            "Epoch 105/150 - 0.03s - loss: 0.8728 - acc: 0.5848 - val_loss: 0.9897 - val_acc: 0.5223\n",
            "Epoch 106/150 - 0.03s - loss: 0.8493 - acc: 0.6167 - val_loss: 0.9599 - val_acc: 0.5445\n",
            "Epoch 107/150 - 0.03s - loss: 0.8480 - acc: 0.6154 - val_loss: 0.9600 - val_acc: 0.5486\n",
            "Epoch 108/150 - 0.03s - loss: 0.8574 - acc: 0.5999 - val_loss: 0.9735 - val_acc: 0.5405\n",
            "Epoch 109/150 - 0.04s - loss: 0.8749 - acc: 0.5805 - val_loss: 0.9786 - val_acc: 0.5304\n",
            "Epoch 110/150 - 0.04s - loss: 0.8567 - acc: 0.6118 - val_loss: 0.9721 - val_acc: 0.5385\n",
            "Epoch 111/150 - 0.04s - loss: 0.8444 - acc: 0.6161 - val_loss: 0.9587 - val_acc: 0.5466\n",
            "Epoch 112/150 - 0.05s - loss: 0.8477 - acc: 0.6174 - val_loss: 0.9689 - val_acc: 0.5364\n",
            "Epoch 113/150 - 0.03s - loss: 0.8408 - acc: 0.6226 - val_loss: 0.9606 - val_acc: 0.5526\n",
            "Epoch 114/150 - 0.03s - loss: 0.8672 - acc: 0.5933 - val_loss: 0.9762 - val_acc: 0.5425\n",
            "Epoch 115/150 - 0.03s - loss: 0.8393 - acc: 0.6185 - val_loss: 0.9629 - val_acc: 0.5526\n",
            "Epoch 116/150 - 0.03s - loss: 0.8376 - acc: 0.6219 - val_loss: 0.9633 - val_acc: 0.5466\n",
            "Epoch 117/150 - 0.03s - loss: 0.8547 - acc: 0.5994 - val_loss: 0.9697 - val_acc: 0.5466\n",
            "Epoch 118/150 - 0.03s - loss: 0.8947 - acc: 0.5695 - val_loss: 1.0283 - val_acc: 0.5101\n",
            "Epoch 119/150 - 0.03s - loss: 0.8393 - acc: 0.6242 - val_loss: 0.9617 - val_acc: 0.5445\n",
            "Epoch 120/150 - 0.03s - loss: 0.8469 - acc: 0.6084 - val_loss: 0.9759 - val_acc: 0.5445\n",
            "Epoch 121/150 - 0.03s - loss: 0.8691 - acc: 0.6035 - val_loss: 0.9874 - val_acc: 0.5547\n",
            "Epoch 122/150 - 0.03s - loss: 0.8405 - acc: 0.6242 - val_loss: 0.9687 - val_acc: 0.5425\n",
            "Epoch 123/150 - 0.03s - loss: 0.8535 - acc: 0.5985 - val_loss: 0.9877 - val_acc: 0.5283\n",
            "Epoch 124/150 - 0.03s - loss: 0.8457 - acc: 0.6122 - val_loss: 0.9878 - val_acc: 0.5223\n",
            "Epoch 125/150 - 0.03s - loss: 0.8372 - acc: 0.6156 - val_loss: 0.9761 - val_acc: 0.5385\n",
            "Epoch 126/150 - 0.03s - loss: 0.8319 - acc: 0.6217 - val_loss: 0.9713 - val_acc: 0.5526\n",
            "Epoch 127/150 - 0.03s - loss: 0.8363 - acc: 0.6199 - val_loss: 0.9810 - val_acc: 0.5344\n",
            "Epoch 128/150 - 0.03s - loss: 0.8369 - acc: 0.6100 - val_loss: 0.9755 - val_acc: 0.5506\n",
            "Epoch 129/150 - 0.03s - loss: 0.8292 - acc: 0.6188 - val_loss: 0.9710 - val_acc: 0.5445\n",
            "Epoch 130/150 - 0.03s - loss: 0.8354 - acc: 0.6163 - val_loss: 0.9846 - val_acc: 0.5263\n",
            "Epoch 131/150 - 0.03s - loss: 0.8341 - acc: 0.6176 - val_loss: 0.9842 - val_acc: 0.5263\n",
            "Epoch 132/150 - 0.03s - loss: 0.8170 - acc: 0.6300 - val_loss: 0.9602 - val_acc: 0.5628\n",
            "Epoch 133/150 - 0.03s - loss: 0.8234 - acc: 0.6302 - val_loss: 0.9645 - val_acc: 0.5628\n",
            "Epoch 134/150 - 0.03s - loss: 0.8181 - acc: 0.6347 - val_loss: 0.9642 - val_acc: 0.5466\n",
            "Epoch 135/150 - 0.03s - loss: 0.8311 - acc: 0.6208 - val_loss: 0.9688 - val_acc: 0.5526\n",
            "Epoch 136/150 - 0.03s - loss: 0.8450 - acc: 0.6077 - val_loss: 1.0020 - val_acc: 0.5283\n",
            "Epoch 137/150 - 0.03s - loss: 0.8218 - acc: 0.6287 - val_loss: 0.9786 - val_acc: 0.5223\n",
            "Epoch 138/150 - 0.03s - loss: 0.8171 - acc: 0.6289 - val_loss: 0.9737 - val_acc: 0.5445\n",
            "Epoch 139/150 - 0.03s - loss: 0.8723 - acc: 0.5873 - val_loss: 1.0428 - val_acc: 0.4980\n",
            "Epoch 140/150 - 0.03s - loss: 0.8184 - acc: 0.6302 - val_loss: 0.9712 - val_acc: 0.5526\n",
            "Epoch 141/150 - 0.03s - loss: 0.8085 - acc: 0.6381 - val_loss: 0.9658 - val_acc: 0.5526\n",
            "Epoch 142/150 - 0.03s - loss: 0.8168 - acc: 0.6323 - val_loss: 0.9677 - val_acc: 0.5607\n",
            "Epoch 143/150 - 0.03s - loss: 0.8074 - acc: 0.6363 - val_loss: 0.9670 - val_acc: 0.5587\n",
            "Epoch 144/150 - 0.03s - loss: 0.8539 - acc: 0.6046 - val_loss: 1.0124 - val_acc: 0.5121\n",
            "Epoch 145/150 - 0.03s - loss: 0.8342 - acc: 0.6073 - val_loss: 0.9809 - val_acc: 0.5405\n",
            "Epoch 146/150 - 0.03s - loss: 0.8173 - acc: 0.6300 - val_loss: 0.9711 - val_acc: 0.5506\n",
            "Epoch 147/150 - 0.03s - loss: 0.8099 - acc: 0.6370 - val_loss: 0.9673 - val_acc: 0.5526\n",
            "Epoch 148/150 - 0.03s - loss: 0.8099 - acc: 0.6345 - val_loss: 0.9674 - val_acc: 0.5587\n",
            "Epoch 149/150 - 0.03s - loss: 0.8101 - acc: 0.6397 - val_loss: 0.9700 - val_acc: 0.5607\n",
            "Epoch 150/150 - 0.03s - loss: 0.8371 - acc: 0.6073 - val_loss: 1.0088 - val_acc: 0.5385\n",
            "\n",
            "Combination 7/252:\n",
            "Hidden Layers: [64, 32], Activation: relu, Learning Rate: 0.001, Batch Size: 32, Epochs: 50\n",
            "Epoch 1/50 - 0.05s - loss: 1.1124 - acc: 0.3394 - val_loss: 1.1151 - val_acc: 0.3239\n",
            "Epoch 2/50 - 0.05s - loss: 1.1092 - acc: 0.3365 - val_loss: 1.1128 - val_acc: 0.3016\n",
            "Epoch 3/50 - 0.05s - loss: 1.1070 - acc: 0.3381 - val_loss: 1.1111 - val_acc: 0.3198\n",
            "Epoch 4/50 - 0.05s - loss: 1.1052 - acc: 0.3367 - val_loss: 1.1097 - val_acc: 0.3016\n",
            "Epoch 5/50 - 0.04s - loss: 1.1036 - acc: 0.3345 - val_loss: 1.1082 - val_acc: 0.3036\n",
            "Epoch 6/50 - 0.04s - loss: 1.1021 - acc: 0.3401 - val_loss: 1.1068 - val_acc: 0.3097\n",
            "Epoch 7/50 - 0.05s - loss: 1.1008 - acc: 0.3480 - val_loss: 1.1055 - val_acc: 0.3158\n",
            "Epoch 8/50 - 0.05s - loss: 1.0995 - acc: 0.3590 - val_loss: 1.1043 - val_acc: 0.3198\n",
            "Epoch 9/50 - 0.05s - loss: 1.0983 - acc: 0.3621 - val_loss: 1.1031 - val_acc: 0.3219\n",
            "Epoch 10/50 - 0.04s - loss: 1.0971 - acc: 0.3677 - val_loss: 1.1019 - val_acc: 0.3178\n",
            "Epoch 11/50 - 0.04s - loss: 1.0959 - acc: 0.3700 - val_loss: 1.1008 - val_acc: 0.3300\n",
            "Epoch 12/50 - 0.04s - loss: 1.0947 - acc: 0.3734 - val_loss: 1.0999 - val_acc: 0.3320\n",
            "Epoch 13/50 - 0.05s - loss: 1.0935 - acc: 0.3783 - val_loss: 1.0989 - val_acc: 0.3360\n",
            "Epoch 14/50 - 0.04s - loss: 1.0924 - acc: 0.3803 - val_loss: 1.0979 - val_acc: 0.3381\n",
            "Epoch 15/50 - 0.04s - loss: 1.0913 - acc: 0.3846 - val_loss: 1.0970 - val_acc: 0.3401\n",
            "Epoch 16/50 - 0.05s - loss: 1.0902 - acc: 0.3862 - val_loss: 1.0960 - val_acc: 0.3421\n",
            "Epoch 17/50 - 0.05s - loss: 1.0892 - acc: 0.3873 - val_loss: 1.0951 - val_acc: 0.3441\n",
            "Epoch 18/50 - 0.05s - loss: 1.0882 - acc: 0.3878 - val_loss: 1.0943 - val_acc: 0.3482\n",
            "Epoch 19/50 - 0.06s - loss: 1.0872 - acc: 0.3907 - val_loss: 1.0935 - val_acc: 0.3522\n",
            "Epoch 20/50 - 0.05s - loss: 1.0862 - acc: 0.3945 - val_loss: 1.0926 - val_acc: 0.3603\n",
            "Epoch 21/50 - 0.06s - loss: 1.0852 - acc: 0.3992 - val_loss: 1.0918 - val_acc: 0.3704\n",
            "Epoch 22/50 - 0.05s - loss: 1.0842 - acc: 0.4015 - val_loss: 1.0911 - val_acc: 0.3684\n",
            "Epoch 23/50 - 0.05s - loss: 1.0832 - acc: 0.4037 - val_loss: 1.0903 - val_acc: 0.3765\n",
            "Epoch 24/50 - 0.05s - loss: 1.0822 - acc: 0.4076 - val_loss: 1.0896 - val_acc: 0.3765\n",
            "Epoch 25/50 - 0.05s - loss: 1.0812 - acc: 0.4121 - val_loss: 1.0888 - val_acc: 0.3785\n",
            "Epoch 26/50 - 0.05s - loss: 1.0803 - acc: 0.4145 - val_loss: 1.0881 - val_acc: 0.3907\n",
            "Epoch 27/50 - 0.04s - loss: 1.0794 - acc: 0.4161 - val_loss: 1.0874 - val_acc: 0.3907\n",
            "Epoch 28/50 - 0.04s - loss: 1.0785 - acc: 0.4190 - val_loss: 1.0866 - val_acc: 0.3968\n",
            "Epoch 29/50 - 0.04s - loss: 1.0777 - acc: 0.4233 - val_loss: 1.0859 - val_acc: 0.4049\n",
            "Epoch 30/50 - 0.04s - loss: 1.0769 - acc: 0.4226 - val_loss: 1.0852 - val_acc: 0.4049\n",
            "Epoch 31/50 - 0.05s - loss: 1.0762 - acc: 0.4240 - val_loss: 1.0845 - val_acc: 0.4089\n",
            "Epoch 32/50 - 0.05s - loss: 1.0755 - acc: 0.4235 - val_loss: 1.0839 - val_acc: 0.4150\n",
            "Epoch 33/50 - 0.04s - loss: 1.0747 - acc: 0.4258 - val_loss: 1.0834 - val_acc: 0.4150\n",
            "Epoch 34/50 - 0.05s - loss: 1.0740 - acc: 0.4269 - val_loss: 1.0828 - val_acc: 0.4190\n",
            "Epoch 35/50 - 0.05s - loss: 1.0733 - acc: 0.4276 - val_loss: 1.0822 - val_acc: 0.4170\n",
            "Epoch 36/50 - 0.05s - loss: 1.0727 - acc: 0.4307 - val_loss: 1.0817 - val_acc: 0.4170\n",
            "Epoch 37/50 - 0.05s - loss: 1.0720 - acc: 0.4343 - val_loss: 1.0811 - val_acc: 0.4130\n",
            "Epoch 38/50 - 0.05s - loss: 1.0713 - acc: 0.4363 - val_loss: 1.0805 - val_acc: 0.4170\n",
            "Epoch 39/50 - 0.05s - loss: 1.0707 - acc: 0.4406 - val_loss: 1.0800 - val_acc: 0.4190\n",
            "Epoch 40/50 - 0.04s - loss: 1.0700 - acc: 0.4422 - val_loss: 1.0795 - val_acc: 0.4211\n",
            "Epoch 41/50 - 0.05s - loss: 1.0694 - acc: 0.4435 - val_loss: 1.0789 - val_acc: 0.4211\n",
            "Epoch 42/50 - 0.04s - loss: 1.0687 - acc: 0.4440 - val_loss: 1.0784 - val_acc: 0.4130\n",
            "Epoch 43/50 - 0.04s - loss: 1.0680 - acc: 0.4458 - val_loss: 1.0780 - val_acc: 0.4190\n",
            "Epoch 44/50 - 0.04s - loss: 1.0674 - acc: 0.4449 - val_loss: 1.0775 - val_acc: 0.4150\n",
            "Epoch 45/50 - 0.04s - loss: 1.0667 - acc: 0.4476 - val_loss: 1.0770 - val_acc: 0.4170\n",
            "Epoch 46/50 - 0.04s - loss: 1.0660 - acc: 0.4469 - val_loss: 1.0765 - val_acc: 0.4190\n",
            "Epoch 47/50 - 0.05s - loss: 1.0653 - acc: 0.4505 - val_loss: 1.0760 - val_acc: 0.4231\n",
            "Epoch 48/50 - 0.05s - loss: 1.0646 - acc: 0.4505 - val_loss: 1.0755 - val_acc: 0.4251\n",
            "Epoch 49/50 - 0.05s - loss: 1.0640 - acc: 0.4541 - val_loss: 1.0751 - val_acc: 0.4251\n",
            "Epoch 50/50 - 0.05s - loss: 1.0633 - acc: 0.4539 - val_loss: 1.0745 - val_acc: 0.4291\n",
            "\n",
            "Combination 8/252:\n",
            "Hidden Layers: [64, 32], Activation: relu, Learning Rate: 0.001, Batch Size: 32, Epochs: 100\n",
            "Epoch 1/100 - 0.05s - loss: 1.1018 - acc: 0.3342 - val_loss: 1.1031 - val_acc: 0.3138\n",
            "Epoch 2/100 - 0.05s - loss: 1.0983 - acc: 0.3324 - val_loss: 1.0999 - val_acc: 0.3279\n",
            "Epoch 3/100 - 0.05s - loss: 1.0960 - acc: 0.3453 - val_loss: 1.0977 - val_acc: 0.3563\n",
            "Epoch 4/100 - 0.05s - loss: 1.0942 - acc: 0.3610 - val_loss: 1.0961 - val_acc: 0.3684\n",
            "Epoch 5/100 - 0.05s - loss: 1.0926 - acc: 0.3653 - val_loss: 1.0948 - val_acc: 0.3563\n",
            "Epoch 6/100 - 0.05s - loss: 1.0912 - acc: 0.3718 - val_loss: 1.0936 - val_acc: 0.3684\n",
            "Epoch 7/100 - 0.05s - loss: 1.0899 - acc: 0.3765 - val_loss: 1.0924 - val_acc: 0.3664\n",
            "Epoch 8/100 - 0.05s - loss: 1.0886 - acc: 0.3808 - val_loss: 1.0914 - val_acc: 0.3826\n",
            "Epoch 9/100 - 0.05s - loss: 1.0874 - acc: 0.3844 - val_loss: 1.0903 - val_acc: 0.3806\n",
            "Epoch 10/100 - 0.04s - loss: 1.0863 - acc: 0.3887 - val_loss: 1.0893 - val_acc: 0.3806\n",
            "Epoch 11/100 - 0.05s - loss: 1.0852 - acc: 0.3927 - val_loss: 1.0882 - val_acc: 0.3887\n",
            "Epoch 12/100 - 0.05s - loss: 1.0842 - acc: 0.3950 - val_loss: 1.0871 - val_acc: 0.3988\n",
            "Epoch 13/100 - 0.05s - loss: 1.0831 - acc: 0.3965 - val_loss: 1.0862 - val_acc: 0.3947\n",
            "Epoch 14/100 - 0.04s - loss: 1.0822 - acc: 0.3974 - val_loss: 1.0854 - val_acc: 0.3988\n",
            "Epoch 15/100 - 0.05s - loss: 1.0814 - acc: 0.3983 - val_loss: 1.0845 - val_acc: 0.4028\n",
            "Epoch 16/100 - 0.05s - loss: 1.0805 - acc: 0.4010 - val_loss: 1.0837 - val_acc: 0.3988\n",
            "Epoch 17/100 - 0.05s - loss: 1.0797 - acc: 0.4028 - val_loss: 1.0829 - val_acc: 0.4008\n",
            "Epoch 18/100 - 0.05s - loss: 1.0789 - acc: 0.4028 - val_loss: 1.0821 - val_acc: 0.3968\n",
            "Epoch 19/100 - 0.05s - loss: 1.0781 - acc: 0.4031 - val_loss: 1.0813 - val_acc: 0.3968\n",
            "Epoch 20/100 - 0.05s - loss: 1.0773 - acc: 0.4067 - val_loss: 1.0805 - val_acc: 0.4008\n",
            "Epoch 21/100 - 0.05s - loss: 1.0766 - acc: 0.4098 - val_loss: 1.0797 - val_acc: 0.4049\n",
            "Epoch 22/100 - 0.04s - loss: 1.0758 - acc: 0.4103 - val_loss: 1.0789 - val_acc: 0.4069\n",
            "Epoch 23/100 - 0.04s - loss: 1.0751 - acc: 0.4116 - val_loss: 1.0782 - val_acc: 0.4170\n",
            "Epoch 24/100 - 0.04s - loss: 1.0744 - acc: 0.4121 - val_loss: 1.0774 - val_acc: 0.4190\n",
            "Epoch 25/100 - 0.04s - loss: 1.0736 - acc: 0.4130 - val_loss: 1.0767 - val_acc: 0.4211\n",
            "Epoch 26/100 - 0.04s - loss: 1.0729 - acc: 0.4168 - val_loss: 1.0760 - val_acc: 0.4251\n",
            "Epoch 27/100 - 0.05s - loss: 1.0722 - acc: 0.4190 - val_loss: 1.0753 - val_acc: 0.4271\n",
            "Epoch 28/100 - 0.04s - loss: 1.0716 - acc: 0.4213 - val_loss: 1.0746 - val_acc: 0.4271\n",
            "Epoch 29/100 - 0.04s - loss: 1.0709 - acc: 0.4217 - val_loss: 1.0739 - val_acc: 0.4231\n",
            "Epoch 30/100 - 0.04s - loss: 1.0702 - acc: 0.4220 - val_loss: 1.0732 - val_acc: 0.4271\n",
            "Epoch 31/100 - 0.04s - loss: 1.0695 - acc: 0.4224 - val_loss: 1.0725 - val_acc: 0.4271\n",
            "Epoch 32/100 - 0.05s - loss: 1.0689 - acc: 0.4238 - val_loss: 1.0718 - val_acc: 0.4251\n",
            "Epoch 33/100 - 0.04s - loss: 1.0682 - acc: 0.4265 - val_loss: 1.0712 - val_acc: 0.4291\n",
            "Epoch 34/100 - 0.04s - loss: 1.0676 - acc: 0.4262 - val_loss: 1.0707 - val_acc: 0.4312\n",
            "Epoch 35/100 - 0.04s - loss: 1.0669 - acc: 0.4265 - val_loss: 1.0701 - val_acc: 0.4312\n",
            "Epoch 36/100 - 0.04s - loss: 1.0663 - acc: 0.4285 - val_loss: 1.0695 - val_acc: 0.4291\n",
            "Epoch 37/100 - 0.05s - loss: 1.0657 - acc: 0.4307 - val_loss: 1.0690 - val_acc: 0.4271\n",
            "Epoch 38/100 - 0.04s - loss: 1.0651 - acc: 0.4316 - val_loss: 1.0684 - val_acc: 0.4271\n",
            "Epoch 39/100 - 0.04s - loss: 1.0644 - acc: 0.4327 - val_loss: 1.0679 - val_acc: 0.4251\n",
            "Epoch 40/100 - 0.04s - loss: 1.0638 - acc: 0.4332 - val_loss: 1.0674 - val_acc: 0.4312\n",
            "Epoch 41/100 - 0.04s - loss: 1.0632 - acc: 0.4348 - val_loss: 1.0669 - val_acc: 0.4332\n",
            "Epoch 42/100 - 0.05s - loss: 1.0626 - acc: 0.4357 - val_loss: 1.0664 - val_acc: 0.4352\n",
            "Epoch 43/100 - 0.05s - loss: 1.0620 - acc: 0.4368 - val_loss: 1.0659 - val_acc: 0.4372\n",
            "Epoch 44/100 - 0.05s - loss: 1.0614 - acc: 0.4368 - val_loss: 1.0655 - val_acc: 0.4393\n",
            "Epoch 45/100 - 0.05s - loss: 1.0608 - acc: 0.4388 - val_loss: 1.0650 - val_acc: 0.4433\n",
            "Epoch 46/100 - 0.05s - loss: 1.0602 - acc: 0.4411 - val_loss: 1.0646 - val_acc: 0.4453\n",
            "Epoch 47/100 - 0.04s - loss: 1.0597 - acc: 0.4417 - val_loss: 1.0642 - val_acc: 0.4474\n",
            "Epoch 48/100 - 0.04s - loss: 1.0591 - acc: 0.4429 - val_loss: 1.0638 - val_acc: 0.4534\n",
            "Epoch 49/100 - 0.04s - loss: 1.0585 - acc: 0.4420 - val_loss: 1.0633 - val_acc: 0.4474\n",
            "Epoch 50/100 - 0.04s - loss: 1.0579 - acc: 0.4444 - val_loss: 1.0628 - val_acc: 0.4453\n",
            "Epoch 51/100 - 0.04s - loss: 1.0573 - acc: 0.4442 - val_loss: 1.0625 - val_acc: 0.4494\n",
            "Epoch 52/100 - 0.05s - loss: 1.0568 - acc: 0.4458 - val_loss: 1.0620 - val_acc: 0.4494\n",
            "Epoch 53/100 - 0.04s - loss: 1.0562 - acc: 0.4458 - val_loss: 1.0617 - val_acc: 0.4555\n",
            "Epoch 54/100 - 0.04s - loss: 1.0556 - acc: 0.4480 - val_loss: 1.0612 - val_acc: 0.4453\n",
            "Epoch 55/100 - 0.04s - loss: 1.0551 - acc: 0.4480 - val_loss: 1.0607 - val_acc: 0.4494\n",
            "Epoch 56/100 - 0.04s - loss: 1.0545 - acc: 0.4480 - val_loss: 1.0604 - val_acc: 0.4514\n",
            "Epoch 57/100 - 0.05s - loss: 1.0540 - acc: 0.4480 - val_loss: 1.0600 - val_acc: 0.4575\n",
            "Epoch 58/100 - 0.05s - loss: 1.0534 - acc: 0.4501 - val_loss: 1.0595 - val_acc: 0.4514\n",
            "Epoch 59/100 - 0.04s - loss: 1.0529 - acc: 0.4494 - val_loss: 1.0590 - val_acc: 0.4534\n",
            "Epoch 60/100 - 0.04s - loss: 1.0523 - acc: 0.4514 - val_loss: 1.0587 - val_acc: 0.4595\n",
            "Epoch 61/100 - 0.04s - loss: 1.0518 - acc: 0.4496 - val_loss: 1.0582 - val_acc: 0.4575\n",
            "Epoch 62/100 - 0.04s - loss: 1.0512 - acc: 0.4514 - val_loss: 1.0579 - val_acc: 0.4555\n",
            "Epoch 63/100 - 0.04s - loss: 1.0507 - acc: 0.4525 - val_loss: 1.0576 - val_acc: 0.4595\n",
            "Epoch 64/100 - 0.05s - loss: 1.0501 - acc: 0.4541 - val_loss: 1.0572 - val_acc: 0.4595\n",
            "Epoch 65/100 - 0.05s - loss: 1.0496 - acc: 0.4510 - val_loss: 1.0567 - val_acc: 0.4555\n",
            "Epoch 66/100 - 0.05s - loss: 1.0490 - acc: 0.4523 - val_loss: 1.0564 - val_acc: 0.4615\n",
            "Epoch 67/100 - 0.05s - loss: 1.0485 - acc: 0.4552 - val_loss: 1.0561 - val_acc: 0.4615\n",
            "Epoch 68/100 - 0.04s - loss: 1.0480 - acc: 0.4561 - val_loss: 1.0556 - val_acc: 0.4676\n",
            "Epoch 69/100 - 0.04s - loss: 1.0474 - acc: 0.4548 - val_loss: 1.0553 - val_acc: 0.4676\n",
            "Epoch 70/100 - 0.05s - loss: 1.0469 - acc: 0.4568 - val_loss: 1.0549 - val_acc: 0.4676\n",
            "Epoch 71/100 - 0.04s - loss: 1.0464 - acc: 0.4566 - val_loss: 1.0545 - val_acc: 0.4656\n",
            "Epoch 72/100 - 0.05s - loss: 1.0458 - acc: 0.4584 - val_loss: 1.0542 - val_acc: 0.4656\n",
            "Epoch 73/100 - 0.04s - loss: 1.0453 - acc: 0.4582 - val_loss: 1.0538 - val_acc: 0.4656\n",
            "Epoch 74/100 - 0.04s - loss: 1.0448 - acc: 0.4600 - val_loss: 1.0536 - val_acc: 0.4717\n",
            "Epoch 75/100 - 0.04s - loss: 1.0442 - acc: 0.4613 - val_loss: 1.0532 - val_acc: 0.4696\n",
            "Epoch 76/100 - 0.04s - loss: 1.0437 - acc: 0.4597 - val_loss: 1.0529 - val_acc: 0.4717\n",
            "Epoch 77/100 - 0.05s - loss: 1.0432 - acc: 0.4604 - val_loss: 1.0525 - val_acc: 0.4696\n",
            "Epoch 78/100 - 0.04s - loss: 1.0427 - acc: 0.4618 - val_loss: 1.0521 - val_acc: 0.4717\n",
            "Epoch 79/100 - 0.05s - loss: 1.0421 - acc: 0.4629 - val_loss: 1.0518 - val_acc: 0.4737\n",
            "Epoch 80/100 - 0.05s - loss: 1.0416 - acc: 0.4640 - val_loss: 1.0514 - val_acc: 0.4737\n",
            "Epoch 81/100 - 0.04s - loss: 1.0411 - acc: 0.4636 - val_loss: 1.0510 - val_acc: 0.4676\n",
            "Epoch 82/100 - 0.05s - loss: 1.0406 - acc: 0.4656 - val_loss: 1.0507 - val_acc: 0.4757\n",
            "Epoch 83/100 - 0.04s - loss: 1.0400 - acc: 0.4649 - val_loss: 1.0504 - val_acc: 0.4737\n",
            "Epoch 84/100 - 0.04s - loss: 1.0395 - acc: 0.4647 - val_loss: 1.0500 - val_acc: 0.4777\n",
            "Epoch 85/100 - 0.04s - loss: 1.0390 - acc: 0.4660 - val_loss: 1.0497 - val_acc: 0.4757\n",
            "Epoch 86/100 - 0.04s - loss: 1.0385 - acc: 0.4667 - val_loss: 1.0494 - val_acc: 0.4777\n",
            "Epoch 87/100 - 0.04s - loss: 1.0380 - acc: 0.4681 - val_loss: 1.0490 - val_acc: 0.4818\n",
            "Epoch 88/100 - 0.04s - loss: 1.0375 - acc: 0.4692 - val_loss: 1.0486 - val_acc: 0.4798\n",
            "Epoch 89/100 - 0.04s - loss: 1.0369 - acc: 0.4699 - val_loss: 1.0484 - val_acc: 0.4798\n",
            "Epoch 90/100 - 0.05s - loss: 1.0364 - acc: 0.4708 - val_loss: 1.0480 - val_acc: 0.4798\n",
            "Epoch 91/100 - 0.05s - loss: 1.0359 - acc: 0.4714 - val_loss: 1.0476 - val_acc: 0.4838\n",
            "Epoch 92/100 - 0.05s - loss: 1.0354 - acc: 0.4721 - val_loss: 1.0473 - val_acc: 0.4838\n",
            "Epoch 93/100 - 0.04s - loss: 1.0349 - acc: 0.4712 - val_loss: 1.0470 - val_acc: 0.4818\n",
            "Epoch 94/100 - 0.04s - loss: 1.0343 - acc: 0.4717 - val_loss: 1.0467 - val_acc: 0.4798\n",
            "Epoch 95/100 - 0.04s - loss: 1.0338 - acc: 0.4739 - val_loss: 1.0464 - val_acc: 0.4798\n",
            "Epoch 96/100 - 0.04s - loss: 1.0333 - acc: 0.4741 - val_loss: 1.0463 - val_acc: 0.4818\n",
            "Epoch 97/100 - 0.04s - loss: 1.0328 - acc: 0.4755 - val_loss: 1.0459 - val_acc: 0.4838\n",
            "Epoch 98/100 - 0.04s - loss: 1.0322 - acc: 0.4757 - val_loss: 1.0453 - val_acc: 0.4777\n",
            "Epoch 99/100 - 0.05s - loss: 1.0317 - acc: 0.4775 - val_loss: 1.0449 - val_acc: 0.4798\n",
            "Epoch 100/100 - 0.04s - loss: 1.0312 - acc: 0.4786 - val_loss: 1.0446 - val_acc: 0.4757\n",
            "\n",
            "Combination 9/252:\n",
            "Hidden Layers: [64, 32], Activation: relu, Learning Rate: 0.001, Batch Size: 32, Epochs: 150\n",
            "Epoch 1/150 - 0.05s - loss: 1.1044 - acc: 0.3502 - val_loss: 1.1009 - val_acc: 0.3421\n",
            "Epoch 2/150 - 0.04s - loss: 1.1002 - acc: 0.3608 - val_loss: 1.0978 - val_acc: 0.3623\n",
            "Epoch 3/150 - 0.04s - loss: 1.0975 - acc: 0.3657 - val_loss: 1.0961 - val_acc: 0.3725\n",
            "Epoch 4/150 - 0.05s - loss: 1.0956 - acc: 0.3783 - val_loss: 1.0949 - val_acc: 0.3826\n",
            "Epoch 5/150 - 0.05s - loss: 1.0941 - acc: 0.3844 - val_loss: 1.0939 - val_acc: 0.3846\n",
            "Epoch 6/150 - 0.04s - loss: 1.0929 - acc: 0.3871 - val_loss: 1.0931 - val_acc: 0.3806\n",
            "Epoch 7/150 - 0.04s - loss: 1.0919 - acc: 0.3875 - val_loss: 1.0923 - val_acc: 0.3785\n",
            "Epoch 8/150 - 0.04s - loss: 1.0909 - acc: 0.3914 - val_loss: 1.0915 - val_acc: 0.3866\n",
            "Epoch 9/150 - 0.04s - loss: 1.0900 - acc: 0.3943 - val_loss: 1.0907 - val_acc: 0.3927\n",
            "Epoch 10/150 - 0.04s - loss: 1.0891 - acc: 0.3968 - val_loss: 1.0900 - val_acc: 0.4028\n",
            "Epoch 11/150 - 0.04s - loss: 1.0882 - acc: 0.3995 - val_loss: 1.0893 - val_acc: 0.4069\n",
            "Epoch 12/150 - 0.04s - loss: 1.0873 - acc: 0.4024 - val_loss: 1.0886 - val_acc: 0.4130\n",
            "Epoch 13/150 - 0.04s - loss: 1.0864 - acc: 0.4040 - val_loss: 1.0878 - val_acc: 0.4109\n",
            "Epoch 14/150 - 0.04s - loss: 1.0855 - acc: 0.4058 - val_loss: 1.0872 - val_acc: 0.4130\n",
            "Epoch 15/150 - 0.04s - loss: 1.0847 - acc: 0.4082 - val_loss: 1.0865 - val_acc: 0.4190\n",
            "Epoch 16/150 - 0.05s - loss: 1.0839 - acc: 0.4114 - val_loss: 1.0858 - val_acc: 0.4312\n",
            "Epoch 17/150 - 0.05s - loss: 1.0831 - acc: 0.4139 - val_loss: 1.0851 - val_acc: 0.4352\n",
            "Epoch 18/150 - 0.05s - loss: 1.0823 - acc: 0.4188 - val_loss: 1.0845 - val_acc: 0.4413\n",
            "Epoch 19/150 - 0.05s - loss: 1.0815 - acc: 0.4229 - val_loss: 1.0839 - val_acc: 0.4453\n",
            "Epoch 20/150 - 0.04s - loss: 1.0808 - acc: 0.4249 - val_loss: 1.0833 - val_acc: 0.4494\n",
            "Epoch 21/150 - 0.05s - loss: 1.0801 - acc: 0.4247 - val_loss: 1.0826 - val_acc: 0.4534\n",
            "Epoch 22/150 - 0.05s - loss: 1.0793 - acc: 0.4296 - val_loss: 1.0821 - val_acc: 0.4534\n",
            "Epoch 23/150 - 0.05s - loss: 1.0786 - acc: 0.4300 - val_loss: 1.0815 - val_acc: 0.4514\n",
            "Epoch 24/150 - 0.05s - loss: 1.0779 - acc: 0.4289 - val_loss: 1.0809 - val_acc: 0.4494\n",
            "Epoch 25/150 - 0.05s - loss: 1.0772 - acc: 0.4305 - val_loss: 1.0803 - val_acc: 0.4494\n",
            "Epoch 26/150 - 0.05s - loss: 1.0765 - acc: 0.4307 - val_loss: 1.0798 - val_acc: 0.4514\n",
            "Epoch 27/150 - 0.05s - loss: 1.0758 - acc: 0.4296 - val_loss: 1.0793 - val_acc: 0.4534\n",
            "Epoch 28/150 - 0.05s - loss: 1.0752 - acc: 0.4332 - val_loss: 1.0787 - val_acc: 0.4555\n",
            "Epoch 29/150 - 0.05s - loss: 1.0745 - acc: 0.4325 - val_loss: 1.0782 - val_acc: 0.4575\n",
            "Epoch 30/150 - 0.05s - loss: 1.0739 - acc: 0.4332 - val_loss: 1.0776 - val_acc: 0.4575\n",
            "Epoch 31/150 - 0.05s - loss: 1.0732 - acc: 0.4345 - val_loss: 1.0771 - val_acc: 0.4555\n",
            "Epoch 32/150 - 0.05s - loss: 1.0726 - acc: 0.4370 - val_loss: 1.0766 - val_acc: 0.4494\n",
            "Epoch 33/150 - 0.04s - loss: 1.0719 - acc: 0.4406 - val_loss: 1.0760 - val_acc: 0.4474\n",
            "Epoch 34/150 - 0.05s - loss: 1.0713 - acc: 0.4424 - val_loss: 1.0756 - val_acc: 0.4494\n",
            "Epoch 35/150 - 0.05s - loss: 1.0707 - acc: 0.4440 - val_loss: 1.0750 - val_acc: 0.4534\n",
            "Epoch 36/150 - 0.05s - loss: 1.0700 - acc: 0.4444 - val_loss: 1.0745 - val_acc: 0.4555\n",
            "Epoch 37/150 - 0.04s - loss: 1.0694 - acc: 0.4447 - val_loss: 1.0740 - val_acc: 0.4575\n",
            "Epoch 38/150 - 0.04s - loss: 1.0688 - acc: 0.4440 - val_loss: 1.0735 - val_acc: 0.4534\n",
            "Epoch 39/150 - 0.05s - loss: 1.0682 - acc: 0.4442 - val_loss: 1.0730 - val_acc: 0.4534\n",
            "Epoch 40/150 - 0.05s - loss: 1.0676 - acc: 0.4429 - val_loss: 1.0725 - val_acc: 0.4514\n",
            "Epoch 41/150 - 0.05s - loss: 1.0670 - acc: 0.4456 - val_loss: 1.0720 - val_acc: 0.4514\n",
            "Epoch 42/150 - 0.05s - loss: 1.0663 - acc: 0.4453 - val_loss: 1.0716 - val_acc: 0.4534\n",
            "Epoch 43/150 - 0.04s - loss: 1.0657 - acc: 0.4456 - val_loss: 1.0711 - val_acc: 0.4514\n",
            "Epoch 44/150 - 0.04s - loss: 1.0651 - acc: 0.4483 - val_loss: 1.0707 - val_acc: 0.4534\n",
            "Epoch 45/150 - 0.05s - loss: 1.0645 - acc: 0.4476 - val_loss: 1.0702 - val_acc: 0.4555\n",
            "Epoch 46/150 - 0.05s - loss: 1.0639 - acc: 0.4485 - val_loss: 1.0697 - val_acc: 0.4595\n",
            "Epoch 47/150 - 0.05s - loss: 1.0633 - acc: 0.4483 - val_loss: 1.0693 - val_acc: 0.4534\n",
            "Epoch 48/150 - 0.05s - loss: 1.0627 - acc: 0.4496 - val_loss: 1.0689 - val_acc: 0.4555\n",
            "Epoch 49/150 - 0.05s - loss: 1.0621 - acc: 0.4510 - val_loss: 1.0684 - val_acc: 0.4555\n",
            "Epoch 50/150 - 0.05s - loss: 1.0615 - acc: 0.4514 - val_loss: 1.0680 - val_acc: 0.4575\n",
            "Epoch 51/150 - 0.05s - loss: 1.0609 - acc: 0.4530 - val_loss: 1.0677 - val_acc: 0.4595\n",
            "Epoch 52/150 - 0.05s - loss: 1.0603 - acc: 0.4543 - val_loss: 1.0673 - val_acc: 0.4575\n",
            "Epoch 53/150 - 0.05s - loss: 1.0597 - acc: 0.4546 - val_loss: 1.0669 - val_acc: 0.4615\n",
            "Epoch 54/150 - 0.05s - loss: 1.0592 - acc: 0.4557 - val_loss: 1.0664 - val_acc: 0.4575\n",
            "Epoch 55/150 - 0.05s - loss: 1.0586 - acc: 0.4552 - val_loss: 1.0661 - val_acc: 0.4555\n",
            "Epoch 56/150 - 0.05s - loss: 1.0580 - acc: 0.4577 - val_loss: 1.0656 - val_acc: 0.4494\n",
            "Epoch 57/150 - 0.05s - loss: 1.0574 - acc: 0.4584 - val_loss: 1.0652 - val_acc: 0.4555\n",
            "Epoch 58/150 - 0.05s - loss: 1.0569 - acc: 0.4597 - val_loss: 1.0649 - val_acc: 0.4555\n",
            "Epoch 59/150 - 0.05s - loss: 1.0563 - acc: 0.4591 - val_loss: 1.0645 - val_acc: 0.4534\n",
            "Epoch 60/150 - 0.04s - loss: 1.0557 - acc: 0.4586 - val_loss: 1.0641 - val_acc: 0.4534\n",
            "Epoch 61/150 - 0.05s - loss: 1.0551 - acc: 0.4611 - val_loss: 1.0638 - val_acc: 0.4575\n",
            "Epoch 62/150 - 0.05s - loss: 1.0546 - acc: 0.4606 - val_loss: 1.0634 - val_acc: 0.4555\n",
            "Epoch 63/150 - 0.05s - loss: 1.0540 - acc: 0.4606 - val_loss: 1.0630 - val_acc: 0.4555\n",
            "Epoch 64/150 - 0.05s - loss: 1.0534 - acc: 0.4611 - val_loss: 1.0626 - val_acc: 0.4555\n",
            "Epoch 65/150 - 0.05s - loss: 1.0528 - acc: 0.4627 - val_loss: 1.0623 - val_acc: 0.4575\n",
            "Epoch 66/150 - 0.05s - loss: 1.0523 - acc: 0.4600 - val_loss: 1.0618 - val_acc: 0.4575\n",
            "Epoch 67/150 - 0.04s - loss: 1.0517 - acc: 0.4595 - val_loss: 1.0614 - val_acc: 0.4595\n",
            "Epoch 68/150 - 0.05s - loss: 1.0511 - acc: 0.4606 - val_loss: 1.0610 - val_acc: 0.4595\n",
            "Epoch 69/150 - 0.05s - loss: 1.0505 - acc: 0.4631 - val_loss: 1.0607 - val_acc: 0.4595\n",
            "Epoch 70/150 - 0.05s - loss: 1.0500 - acc: 0.4640 - val_loss: 1.0604 - val_acc: 0.4595\n",
            "Epoch 71/150 - 0.05s - loss: 1.0494 - acc: 0.4627 - val_loss: 1.0599 - val_acc: 0.4595\n",
            "Epoch 72/150 - 0.05s - loss: 1.0488 - acc: 0.4636 - val_loss: 1.0596 - val_acc: 0.4575\n",
            "Epoch 73/150 - 0.05s - loss: 1.0483 - acc: 0.4629 - val_loss: 1.0592 - val_acc: 0.4555\n",
            "Epoch 74/150 - 0.05s - loss: 1.0477 - acc: 0.4642 - val_loss: 1.0590 - val_acc: 0.4555\n",
            "Epoch 75/150 - 0.05s - loss: 1.0471 - acc: 0.4658 - val_loss: 1.0586 - val_acc: 0.4534\n",
            "Epoch 76/150 - 0.05s - loss: 1.0465 - acc: 0.4663 - val_loss: 1.0582 - val_acc: 0.4575\n",
            "Epoch 77/150 - 0.05s - loss: 1.0460 - acc: 0.4667 - val_loss: 1.0580 - val_acc: 0.4595\n",
            "Epoch 78/150 - 0.05s - loss: 1.0454 - acc: 0.4674 - val_loss: 1.0575 - val_acc: 0.4575\n",
            "Epoch 79/150 - 0.04s - loss: 1.0449 - acc: 0.4717 - val_loss: 1.0574 - val_acc: 0.4534\n",
            "Epoch 80/150 - 0.05s - loss: 1.0443 - acc: 0.4694 - val_loss: 1.0568 - val_acc: 0.4575\n",
            "Epoch 81/150 - 0.05s - loss: 1.0437 - acc: 0.4737 - val_loss: 1.0566 - val_acc: 0.4575\n",
            "Epoch 82/150 - 0.05s - loss: 1.0431 - acc: 0.4719 - val_loss: 1.0562 - val_acc: 0.4575\n",
            "Epoch 83/150 - 0.05s - loss: 1.0426 - acc: 0.4717 - val_loss: 1.0557 - val_acc: 0.4575\n",
            "Epoch 84/150 - 0.05s - loss: 1.0420 - acc: 0.4728 - val_loss: 1.0554 - val_acc: 0.4555\n",
            "Epoch 85/150 - 0.05s - loss: 1.0414 - acc: 0.4744 - val_loss: 1.0550 - val_acc: 0.4555\n",
            "Epoch 86/150 - 0.05s - loss: 1.0409 - acc: 0.4750 - val_loss: 1.0546 - val_acc: 0.4514\n",
            "Epoch 87/150 - 0.05s - loss: 1.0403 - acc: 0.4753 - val_loss: 1.0542 - val_acc: 0.4514\n",
            "Epoch 88/150 - 0.05s - loss: 1.0398 - acc: 0.4737 - val_loss: 1.0538 - val_acc: 0.4514\n",
            "Epoch 89/150 - 0.05s - loss: 1.0392 - acc: 0.4777 - val_loss: 1.0536 - val_acc: 0.4555\n",
            "Epoch 90/150 - 0.05s - loss: 1.0386 - acc: 0.4784 - val_loss: 1.0533 - val_acc: 0.4555\n",
            "Epoch 91/150 - 0.05s - loss: 1.0381 - acc: 0.4789 - val_loss: 1.0529 - val_acc: 0.4534\n",
            "Epoch 92/150 - 0.05s - loss: 1.0375 - acc: 0.4789 - val_loss: 1.0525 - val_acc: 0.4514\n",
            "Epoch 93/150 - 0.05s - loss: 1.0369 - acc: 0.4800 - val_loss: 1.0523 - val_acc: 0.4555\n",
            "Epoch 94/150 - 0.05s - loss: 1.0364 - acc: 0.4809 - val_loss: 1.0520 - val_acc: 0.4534\n",
            "Epoch 95/150 - 0.05s - loss: 1.0359 - acc: 0.4798 - val_loss: 1.0515 - val_acc: 0.4575\n",
            "Epoch 96/150 - 0.05s - loss: 1.0353 - acc: 0.4813 - val_loss: 1.0512 - val_acc: 0.4575\n",
            "Epoch 97/150 - 0.05s - loss: 1.0347 - acc: 0.4818 - val_loss: 1.0508 - val_acc: 0.4575\n",
            "Epoch 98/150 - 0.05s - loss: 1.0342 - acc: 0.4831 - val_loss: 1.0507 - val_acc: 0.4636\n",
            "Epoch 99/150 - 0.05s - loss: 1.0336 - acc: 0.4829 - val_loss: 1.0503 - val_acc: 0.4636\n",
            "Epoch 100/150 - 0.05s - loss: 1.0331 - acc: 0.4840 - val_loss: 1.0500 - val_acc: 0.4656\n",
            "Epoch 101/150 - 0.05s - loss: 1.0325 - acc: 0.4849 - val_loss: 1.0496 - val_acc: 0.4636\n",
            "Epoch 102/150 - 0.05s - loss: 1.0320 - acc: 0.4847 - val_loss: 1.0492 - val_acc: 0.4595\n",
            "Epoch 103/150 - 0.05s - loss: 1.0314 - acc: 0.4854 - val_loss: 1.0488 - val_acc: 0.4636\n",
            "Epoch 104/150 - 0.05s - loss: 1.0308 - acc: 0.4861 - val_loss: 1.0486 - val_acc: 0.4676\n",
            "Epoch 105/150 - 0.05s - loss: 1.0303 - acc: 0.4863 - val_loss: 1.0484 - val_acc: 0.4737\n",
            "Epoch 106/150 - 0.05s - loss: 1.0297 - acc: 0.4865 - val_loss: 1.0478 - val_acc: 0.4656\n",
            "Epoch 107/150 - 0.05s - loss: 1.0292 - acc: 0.4867 - val_loss: 1.0477 - val_acc: 0.4737\n",
            "Epoch 108/150 - 0.05s - loss: 1.0286 - acc: 0.4883 - val_loss: 1.0472 - val_acc: 0.4696\n",
            "Epoch 109/150 - 0.05s - loss: 1.0281 - acc: 0.4890 - val_loss: 1.0467 - val_acc: 0.4696\n",
            "Epoch 110/150 - 0.05s - loss: 1.0276 - acc: 0.4881 - val_loss: 1.0468 - val_acc: 0.4757\n",
            "Epoch 111/150 - 0.05s - loss: 1.0271 - acc: 0.4876 - val_loss: 1.0465 - val_acc: 0.4757\n",
            "Epoch 112/150 - 0.05s - loss: 1.0266 - acc: 0.4867 - val_loss: 1.0463 - val_acc: 0.4777\n",
            "Epoch 113/150 - 0.05s - loss: 1.0259 - acc: 0.4901 - val_loss: 1.0455 - val_acc: 0.4757\n",
            "Epoch 114/150 - 0.06s - loss: 1.0254 - acc: 0.4919 - val_loss: 1.0450 - val_acc: 0.4737\n",
            "Epoch 115/150 - 0.05s - loss: 1.0248 - acc: 0.4915 - val_loss: 1.0448 - val_acc: 0.4798\n",
            "Epoch 116/150 - 0.05s - loss: 1.0242 - acc: 0.4921 - val_loss: 1.0443 - val_acc: 0.4818\n",
            "Epoch 117/150 - 0.05s - loss: 1.0237 - acc: 0.4924 - val_loss: 1.0442 - val_acc: 0.4798\n",
            "Epoch 118/150 - 0.05s - loss: 1.0231 - acc: 0.4939 - val_loss: 1.0438 - val_acc: 0.4818\n",
            "Epoch 119/150 - 0.05s - loss: 1.0226 - acc: 0.4946 - val_loss: 1.0435 - val_acc: 0.4818\n",
            "Epoch 120/150 - 0.05s - loss: 1.0220 - acc: 0.4948 - val_loss: 1.0431 - val_acc: 0.4858\n",
            "Epoch 121/150 - 0.05s - loss: 1.0215 - acc: 0.4960 - val_loss: 1.0428 - val_acc: 0.4818\n",
            "Epoch 122/150 - 0.05s - loss: 1.0209 - acc: 0.4962 - val_loss: 1.0422 - val_acc: 0.4798\n",
            "Epoch 123/150 - 0.05s - loss: 1.0204 - acc: 0.4973 - val_loss: 1.0419 - val_acc: 0.4818\n",
            "Epoch 124/150 - 0.05s - loss: 1.0198 - acc: 0.4973 - val_loss: 1.0416 - val_acc: 0.4818\n",
            "Epoch 125/150 - 0.05s - loss: 1.0193 - acc: 0.4975 - val_loss: 1.0414 - val_acc: 0.4838\n",
            "Epoch 126/150 - 0.05s - loss: 1.0187 - acc: 0.4987 - val_loss: 1.0410 - val_acc: 0.4838\n",
            "Epoch 127/150 - 0.05s - loss: 1.0182 - acc: 0.4996 - val_loss: 1.0409 - val_acc: 0.4818\n",
            "Epoch 128/150 - 0.04s - loss: 1.0176 - acc: 0.4996 - val_loss: 1.0403 - val_acc: 0.4879\n",
            "Epoch 129/150 - 0.05s - loss: 1.0171 - acc: 0.5013 - val_loss: 1.0397 - val_acc: 0.4818\n",
            "Epoch 130/150 - 0.05s - loss: 1.0165 - acc: 0.5009 - val_loss: 1.0397 - val_acc: 0.4818\n",
            "Epoch 131/150 - 0.05s - loss: 1.0159 - acc: 0.5018 - val_loss: 1.0390 - val_acc: 0.4818\n",
            "Epoch 132/150 - 0.05s - loss: 1.0154 - acc: 0.5025 - val_loss: 1.0389 - val_acc: 0.4858\n",
            "Epoch 133/150 - 0.05s - loss: 1.0149 - acc: 0.5043 - val_loss: 1.0386 - val_acc: 0.4838\n",
            "Epoch 134/150 - 0.05s - loss: 1.0143 - acc: 0.5018 - val_loss: 1.0378 - val_acc: 0.4798\n",
            "Epoch 135/150 - 0.04s - loss: 1.0137 - acc: 0.5052 - val_loss: 1.0378 - val_acc: 0.4777\n",
            "Epoch 136/150 - 0.04s - loss: 1.0132 - acc: 0.5067 - val_loss: 1.0374 - val_acc: 0.4798\n",
            "Epoch 137/150 - 0.05s - loss: 1.0127 - acc: 0.5043 - val_loss: 1.0367 - val_acc: 0.4777\n",
            "Epoch 138/150 - 0.05s - loss: 1.0121 - acc: 0.5045 - val_loss: 1.0363 - val_acc: 0.4798\n",
            "Epoch 139/150 - 0.05s - loss: 1.0115 - acc: 0.5067 - val_loss: 1.0360 - val_acc: 0.4858\n",
            "Epoch 140/150 - 0.05s - loss: 1.0110 - acc: 0.5076 - val_loss: 1.0358 - val_acc: 0.4838\n",
            "Epoch 141/150 - 0.05s - loss: 1.0104 - acc: 0.5081 - val_loss: 1.0355 - val_acc: 0.4798\n",
            "Epoch 142/150 - 0.05s - loss: 1.0099 - acc: 0.5081 - val_loss: 1.0348 - val_acc: 0.4858\n",
            "Epoch 143/150 - 0.04s - loss: 1.0093 - acc: 0.5094 - val_loss: 1.0346 - val_acc: 0.4798\n",
            "Epoch 144/150 - 0.05s - loss: 1.0088 - acc: 0.5110 - val_loss: 1.0341 - val_acc: 0.4818\n",
            "Epoch 145/150 - 0.05s - loss: 1.0082 - acc: 0.5112 - val_loss: 1.0338 - val_acc: 0.4798\n",
            "Epoch 146/150 - 0.04s - loss: 1.0077 - acc: 0.5110 - val_loss: 1.0333 - val_acc: 0.4838\n",
            "Epoch 147/150 - 0.04s - loss: 1.0072 - acc: 0.5124 - val_loss: 1.0329 - val_acc: 0.4838\n",
            "Epoch 148/150 - 0.05s - loss: 1.0066 - acc: 0.5135 - val_loss: 1.0328 - val_acc: 0.4879\n",
            "Epoch 149/150 - 0.04s - loss: 1.0060 - acc: 0.5135 - val_loss: 1.0322 - val_acc: 0.4838\n",
            "Epoch 150/150 - 0.04s - loss: 1.0055 - acc: 0.5146 - val_loss: 1.0318 - val_acc: 0.4879\n",
            "\n",
            "Combination 10/252:\n",
            "Hidden Layers: [64, 32], Activation: relu, Learning Rate: 0.001, Batch Size: 64, Epochs: 50\n",
            "Epoch 1/50 - 0.03s - loss: 1.1026 - acc: 0.3484 - val_loss: 1.0991 - val_acc: 0.3543\n",
            "Epoch 2/50 - 0.03s - loss: 1.0999 - acc: 0.3583 - val_loss: 1.0967 - val_acc: 0.3563\n",
            "Epoch 3/50 - 0.03s - loss: 1.0977 - acc: 0.3653 - val_loss: 1.0950 - val_acc: 0.3603\n",
            "Epoch 4/50 - 0.03s - loss: 1.0959 - acc: 0.3731 - val_loss: 1.0936 - val_acc: 0.3806\n",
            "Epoch 5/50 - 0.03s - loss: 1.0944 - acc: 0.3790 - val_loss: 1.0923 - val_acc: 0.3785\n",
            "Epoch 6/50 - 0.03s - loss: 1.0931 - acc: 0.3837 - val_loss: 1.0912 - val_acc: 0.3826\n",
            "Epoch 7/50 - 0.03s - loss: 1.0919 - acc: 0.3866 - val_loss: 1.0903 - val_acc: 0.3927\n",
            "Epoch 8/50 - 0.03s - loss: 1.0908 - acc: 0.3896 - val_loss: 1.0893 - val_acc: 0.3968\n",
            "Epoch 9/50 - 0.03s - loss: 1.0898 - acc: 0.3884 - val_loss: 1.0884 - val_acc: 0.4049\n",
            "Epoch 10/50 - 0.03s - loss: 1.0888 - acc: 0.3853 - val_loss: 1.0876 - val_acc: 0.4049\n",
            "Epoch 11/50 - 0.03s - loss: 1.0879 - acc: 0.3846 - val_loss: 1.0868 - val_acc: 0.4069\n",
            "Epoch 12/50 - 0.03s - loss: 1.0871 - acc: 0.3887 - val_loss: 1.0860 - val_acc: 0.4109\n",
            "Epoch 13/50 - 0.03s - loss: 1.0863 - acc: 0.3880 - val_loss: 1.0853 - val_acc: 0.4049\n",
            "Epoch 14/50 - 0.03s - loss: 1.0855 - acc: 0.3900 - val_loss: 1.0845 - val_acc: 0.4130\n",
            "Epoch 15/50 - 0.03s - loss: 1.0847 - acc: 0.3929 - val_loss: 1.0838 - val_acc: 0.4008\n",
            "Epoch 16/50 - 0.03s - loss: 1.0839 - acc: 0.3923 - val_loss: 1.0831 - val_acc: 0.3968\n",
            "Epoch 17/50 - 0.03s - loss: 1.0832 - acc: 0.3963 - val_loss: 1.0825 - val_acc: 0.3927\n",
            "Epoch 18/50 - 0.03s - loss: 1.0825 - acc: 0.3963 - val_loss: 1.0818 - val_acc: 0.3988\n",
            "Epoch 19/50 - 0.03s - loss: 1.0818 - acc: 0.3970 - val_loss: 1.0812 - val_acc: 0.4049\n",
            "Epoch 20/50 - 0.04s - loss: 1.0812 - acc: 0.3979 - val_loss: 1.0806 - val_acc: 0.4069\n",
            "Epoch 21/50 - 0.03s - loss: 1.0805 - acc: 0.4015 - val_loss: 1.0801 - val_acc: 0.4028\n",
            "Epoch 22/50 - 0.03s - loss: 1.0799 - acc: 0.4055 - val_loss: 1.0795 - val_acc: 0.4049\n",
            "Epoch 23/50 - 0.03s - loss: 1.0793 - acc: 0.4078 - val_loss: 1.0790 - val_acc: 0.4109\n",
            "Epoch 24/50 - 0.03s - loss: 1.0787 - acc: 0.4100 - val_loss: 1.0784 - val_acc: 0.4109\n",
            "Epoch 25/50 - 0.03s - loss: 1.0781 - acc: 0.4134 - val_loss: 1.0779 - val_acc: 0.4130\n",
            "Epoch 26/50 - 0.03s - loss: 1.0775 - acc: 0.4166 - val_loss: 1.0774 - val_acc: 0.4170\n",
            "Epoch 27/50 - 0.03s - loss: 1.0770 - acc: 0.4177 - val_loss: 1.0769 - val_acc: 0.4150\n",
            "Epoch 28/50 - 0.03s - loss: 1.0764 - acc: 0.4188 - val_loss: 1.0764 - val_acc: 0.4150\n",
            "Epoch 29/50 - 0.03s - loss: 1.0759 - acc: 0.4202 - val_loss: 1.0759 - val_acc: 0.4190\n",
            "Epoch 30/50 - 0.03s - loss: 1.0753 - acc: 0.4211 - val_loss: 1.0754 - val_acc: 0.4231\n",
            "Epoch 31/50 - 0.03s - loss: 1.0748 - acc: 0.4233 - val_loss: 1.0750 - val_acc: 0.4251\n",
            "Epoch 32/50 - 0.03s - loss: 1.0743 - acc: 0.4249 - val_loss: 1.0746 - val_acc: 0.4291\n",
            "Epoch 33/50 - 0.03s - loss: 1.0738 - acc: 0.4269 - val_loss: 1.0741 - val_acc: 0.4332\n",
            "Epoch 34/50 - 0.03s - loss: 1.0733 - acc: 0.4305 - val_loss: 1.0737 - val_acc: 0.4352\n",
            "Epoch 35/50 - 0.03s - loss: 1.0729 - acc: 0.4341 - val_loss: 1.0733 - val_acc: 0.4393\n",
            "Epoch 36/50 - 0.03s - loss: 1.0724 - acc: 0.4339 - val_loss: 1.0728 - val_acc: 0.4413\n",
            "Epoch 37/50 - 0.03s - loss: 1.0719 - acc: 0.4357 - val_loss: 1.0724 - val_acc: 0.4474\n",
            "Epoch 38/50 - 0.03s - loss: 1.0715 - acc: 0.4359 - val_loss: 1.0721 - val_acc: 0.4393\n",
            "Epoch 39/50 - 0.03s - loss: 1.0710 - acc: 0.4379 - val_loss: 1.0717 - val_acc: 0.4413\n",
            "Epoch 40/50 - 0.03s - loss: 1.0706 - acc: 0.4395 - val_loss: 1.0713 - val_acc: 0.4352\n",
            "Epoch 41/50 - 0.03s - loss: 1.0702 - acc: 0.4417 - val_loss: 1.0709 - val_acc: 0.4393\n",
            "Epoch 42/50 - 0.03s - loss: 1.0697 - acc: 0.4408 - val_loss: 1.0705 - val_acc: 0.4413\n",
            "Epoch 43/50 - 0.03s - loss: 1.0693 - acc: 0.4426 - val_loss: 1.0702 - val_acc: 0.4393\n",
            "Epoch 44/50 - 0.03s - loss: 1.0689 - acc: 0.4440 - val_loss: 1.0698 - val_acc: 0.4393\n",
            "Epoch 45/50 - 0.03s - loss: 1.0684 - acc: 0.4435 - val_loss: 1.0695 - val_acc: 0.4413\n",
            "Epoch 46/50 - 0.03s - loss: 1.0680 - acc: 0.4440 - val_loss: 1.0691 - val_acc: 0.4393\n",
            "Epoch 47/50 - 0.03s - loss: 1.0676 - acc: 0.4453 - val_loss: 1.0687 - val_acc: 0.4393\n",
            "Epoch 48/50 - 0.03s - loss: 1.0671 - acc: 0.4467 - val_loss: 1.0684 - val_acc: 0.4372\n",
            "Epoch 49/50 - 0.03s - loss: 1.0667 - acc: 0.4480 - val_loss: 1.0680 - val_acc: 0.4433\n",
            "Epoch 50/50 - 0.03s - loss: 1.0663 - acc: 0.4501 - val_loss: 1.0676 - val_acc: 0.4372\n",
            "\n",
            "Combination 11/252:\n",
            "Hidden Layers: [64, 32], Activation: relu, Learning Rate: 0.001, Batch Size: 64, Epochs: 100\n",
            "Epoch 1/100 - 0.03s - loss: 1.1128 - acc: 0.3417 - val_loss: 1.1202 - val_acc: 0.3198\n",
            "Epoch 2/100 - 0.03s - loss: 1.1077 - acc: 0.3423 - val_loss: 1.1146 - val_acc: 0.3259\n",
            "Epoch 3/100 - 0.03s - loss: 1.1040 - acc: 0.3439 - val_loss: 1.1104 - val_acc: 0.3219\n",
            "Epoch 4/100 - 0.03s - loss: 1.1011 - acc: 0.3453 - val_loss: 1.1072 - val_acc: 0.3300\n",
            "Epoch 5/100 - 0.03s - loss: 1.0989 - acc: 0.3450 - val_loss: 1.1046 - val_acc: 0.3381\n",
            "Epoch 6/100 - 0.04s - loss: 1.0971 - acc: 0.3473 - val_loss: 1.1025 - val_acc: 0.3441\n",
            "Epoch 7/100 - 0.03s - loss: 1.0956 - acc: 0.3493 - val_loss: 1.1008 - val_acc: 0.3401\n",
            "Epoch 8/100 - 0.03s - loss: 1.0944 - acc: 0.3504 - val_loss: 1.0994 - val_acc: 0.3421\n",
            "Epoch 9/100 - 0.03s - loss: 1.0934 - acc: 0.3525 - val_loss: 1.0982 - val_acc: 0.3441\n",
            "Epoch 10/100 - 0.03s - loss: 1.0926 - acc: 0.3531 - val_loss: 1.0972 - val_acc: 0.3522\n",
            "Epoch 11/100 - 0.03s - loss: 1.0918 - acc: 0.3583 - val_loss: 1.0963 - val_acc: 0.3543\n",
            "Epoch 12/100 - 0.04s - loss: 1.0911 - acc: 0.3608 - val_loss: 1.0955 - val_acc: 0.3522\n",
            "Epoch 13/100 - 0.03s - loss: 1.0905 - acc: 0.3626 - val_loss: 1.0947 - val_acc: 0.3583\n",
            "Epoch 14/100 - 0.03s - loss: 1.0899 - acc: 0.3704 - val_loss: 1.0941 - val_acc: 0.3583\n",
            "Epoch 15/100 - 0.03s - loss: 1.0894 - acc: 0.3720 - val_loss: 1.0935 - val_acc: 0.3603\n",
            "Epoch 16/100 - 0.04s - loss: 1.0889 - acc: 0.3716 - val_loss: 1.0929 - val_acc: 0.3664\n",
            "Epoch 17/100 - 0.03s - loss: 1.0884 - acc: 0.3749 - val_loss: 1.0924 - val_acc: 0.3725\n",
            "Epoch 18/100 - 0.03s - loss: 1.0880 - acc: 0.3763 - val_loss: 1.0919 - val_acc: 0.3725\n",
            "Epoch 19/100 - 0.03s - loss: 1.0875 - acc: 0.3772 - val_loss: 1.0915 - val_acc: 0.3785\n",
            "Epoch 20/100 - 0.03s - loss: 1.0871 - acc: 0.3783 - val_loss: 1.0911 - val_acc: 0.3846\n",
            "Epoch 21/100 - 0.03s - loss: 1.0867 - acc: 0.3783 - val_loss: 1.0907 - val_acc: 0.3826\n",
            "Epoch 22/100 - 0.03s - loss: 1.0863 - acc: 0.3830 - val_loss: 1.0903 - val_acc: 0.3866\n",
            "Epoch 23/100 - 0.03s - loss: 1.0859 - acc: 0.3866 - val_loss: 1.0899 - val_acc: 0.3887\n",
            "Epoch 24/100 - 0.03s - loss: 1.0856 - acc: 0.3900 - val_loss: 1.0896 - val_acc: 0.3907\n",
            "Epoch 25/100 - 0.03s - loss: 1.0852 - acc: 0.3911 - val_loss: 1.0893 - val_acc: 0.3947\n",
            "Epoch 26/100 - 0.03s - loss: 1.0848 - acc: 0.3934 - val_loss: 1.0890 - val_acc: 0.3927\n",
            "Epoch 27/100 - 0.03s - loss: 1.0845 - acc: 0.3952 - val_loss: 1.0886 - val_acc: 0.3907\n",
            "Epoch 28/100 - 0.04s - loss: 1.0841 - acc: 0.3981 - val_loss: 1.0883 - val_acc: 0.3887\n",
            "Epoch 29/100 - 0.03s - loss: 1.0838 - acc: 0.3988 - val_loss: 1.0880 - val_acc: 0.3907\n",
            "Epoch 30/100 - 0.03s - loss: 1.0834 - acc: 0.3999 - val_loss: 1.0877 - val_acc: 0.3887\n",
            "Epoch 31/100 - 0.03s - loss: 1.0831 - acc: 0.4008 - val_loss: 1.0874 - val_acc: 0.3927\n",
            "Epoch 32/100 - 0.03s - loss: 1.0828 - acc: 0.4031 - val_loss: 1.0871 - val_acc: 0.3927\n",
            "Epoch 33/100 - 0.03s - loss: 1.0824 - acc: 0.4073 - val_loss: 1.0869 - val_acc: 0.3947\n",
            "Epoch 34/100 - 0.03s - loss: 1.0821 - acc: 0.4098 - val_loss: 1.0866 - val_acc: 0.4049\n",
            "Epoch 35/100 - 0.03s - loss: 1.0818 - acc: 0.4116 - val_loss: 1.0863 - val_acc: 0.4069\n",
            "Epoch 36/100 - 0.03s - loss: 1.0815 - acc: 0.4134 - val_loss: 1.0860 - val_acc: 0.4028\n",
            "Epoch 37/100 - 0.03s - loss: 1.0812 - acc: 0.4159 - val_loss: 1.0858 - val_acc: 0.4028\n",
            "Epoch 38/100 - 0.03s - loss: 1.0809 - acc: 0.4170 - val_loss: 1.0855 - val_acc: 0.4069\n",
            "Epoch 39/100 - 0.03s - loss: 1.0805 - acc: 0.4175 - val_loss: 1.0853 - val_acc: 0.4069\n",
            "Epoch 40/100 - 0.03s - loss: 1.0802 - acc: 0.4170 - val_loss: 1.0850 - val_acc: 0.4049\n",
            "Epoch 41/100 - 0.03s - loss: 1.0799 - acc: 0.4177 - val_loss: 1.0848 - val_acc: 0.4028\n",
            "Epoch 42/100 - 0.03s - loss: 1.0796 - acc: 0.4202 - val_loss: 1.0845 - val_acc: 0.4049\n",
            "Epoch 43/100 - 0.03s - loss: 1.0793 - acc: 0.4211 - val_loss: 1.0843 - val_acc: 0.4049\n",
            "Epoch 44/100 - 0.03s - loss: 1.0790 - acc: 0.4220 - val_loss: 1.0840 - val_acc: 0.4049\n",
            "Epoch 45/100 - 0.03s - loss: 1.0787 - acc: 0.4235 - val_loss: 1.0838 - val_acc: 0.4089\n",
            "Epoch 46/100 - 0.03s - loss: 1.0784 - acc: 0.4229 - val_loss: 1.0836 - val_acc: 0.4130\n",
            "Epoch 47/100 - 0.03s - loss: 1.0781 - acc: 0.4235 - val_loss: 1.0833 - val_acc: 0.4150\n",
            "Epoch 48/100 - 0.03s - loss: 1.0778 - acc: 0.4247 - val_loss: 1.0831 - val_acc: 0.4211\n",
            "Epoch 49/100 - 0.03s - loss: 1.0775 - acc: 0.4233 - val_loss: 1.0829 - val_acc: 0.4231\n",
            "Epoch 50/100 - 0.03s - loss: 1.0772 - acc: 0.4231 - val_loss: 1.0827 - val_acc: 0.4211\n",
            "Epoch 51/100 - 0.03s - loss: 1.0769 - acc: 0.4229 - val_loss: 1.0824 - val_acc: 0.4190\n",
            "Epoch 52/100 - 0.03s - loss: 1.0766 - acc: 0.4249 - val_loss: 1.0822 - val_acc: 0.4170\n",
            "Epoch 53/100 - 0.03s - loss: 1.0762 - acc: 0.4260 - val_loss: 1.0820 - val_acc: 0.4150\n",
            "Epoch 54/100 - 0.03s - loss: 1.0759 - acc: 0.4298 - val_loss: 1.0818 - val_acc: 0.4109\n",
            "Epoch 55/100 - 0.03s - loss: 1.0756 - acc: 0.4309 - val_loss: 1.0816 - val_acc: 0.4150\n",
            "Epoch 56/100 - 0.03s - loss: 1.0753 - acc: 0.4309 - val_loss: 1.0814 - val_acc: 0.4231\n",
            "Epoch 57/100 - 0.03s - loss: 1.0750 - acc: 0.4323 - val_loss: 1.0812 - val_acc: 0.4251\n",
            "Epoch 58/100 - 0.03s - loss: 1.0747 - acc: 0.4318 - val_loss: 1.0810 - val_acc: 0.4251\n",
            "Epoch 59/100 - 0.03s - loss: 1.0744 - acc: 0.4332 - val_loss: 1.0808 - val_acc: 0.4251\n",
            "Epoch 60/100 - 0.03s - loss: 1.0741 - acc: 0.4325 - val_loss: 1.0806 - val_acc: 0.4251\n",
            "Epoch 61/100 - 0.03s - loss: 1.0738 - acc: 0.4321 - val_loss: 1.0804 - val_acc: 0.4231\n",
            "Epoch 62/100 - 0.03s - loss: 1.0734 - acc: 0.4309 - val_loss: 1.0802 - val_acc: 0.4211\n",
            "Epoch 63/100 - 0.03s - loss: 1.0731 - acc: 0.4323 - val_loss: 1.0800 - val_acc: 0.4231\n",
            "Epoch 64/100 - 0.03s - loss: 1.0728 - acc: 0.4334 - val_loss: 1.0798 - val_acc: 0.4211\n",
            "Epoch 65/100 - 0.03s - loss: 1.0725 - acc: 0.4339 - val_loss: 1.0796 - val_acc: 0.4211\n",
            "Epoch 66/100 - 0.03s - loss: 1.0722 - acc: 0.4330 - val_loss: 1.0794 - val_acc: 0.4190\n",
            "Epoch 67/100 - 0.03s - loss: 1.0719 - acc: 0.4321 - val_loss: 1.0792 - val_acc: 0.4190\n",
            "Epoch 68/100 - 0.03s - loss: 1.0716 - acc: 0.4336 - val_loss: 1.0790 - val_acc: 0.4211\n",
            "Epoch 69/100 - 0.03s - loss: 1.0712 - acc: 0.4334 - val_loss: 1.0787 - val_acc: 0.4271\n",
            "Epoch 70/100 - 0.03s - loss: 1.0709 - acc: 0.4348 - val_loss: 1.0785 - val_acc: 0.4271\n",
            "Epoch 71/100 - 0.03s - loss: 1.0706 - acc: 0.4354 - val_loss: 1.0783 - val_acc: 0.4291\n",
            "Epoch 72/100 - 0.03s - loss: 1.0703 - acc: 0.4354 - val_loss: 1.0780 - val_acc: 0.4312\n",
            "Epoch 73/100 - 0.03s - loss: 1.0700 - acc: 0.4366 - val_loss: 1.0778 - val_acc: 0.4352\n",
            "Epoch 74/100 - 0.03s - loss: 1.0696 - acc: 0.4390 - val_loss: 1.0776 - val_acc: 0.4352\n",
            "Epoch 75/100 - 0.03s - loss: 1.0693 - acc: 0.4393 - val_loss: 1.0773 - val_acc: 0.4352\n",
            "Epoch 76/100 - 0.03s - loss: 1.0690 - acc: 0.4404 - val_loss: 1.0771 - val_acc: 0.4332\n",
            "Epoch 77/100 - 0.03s - loss: 1.0686 - acc: 0.4399 - val_loss: 1.0769 - val_acc: 0.4332\n",
            "Epoch 78/100 - 0.03s - loss: 1.0683 - acc: 0.4399 - val_loss: 1.0766 - val_acc: 0.4393\n",
            "Epoch 79/100 - 0.03s - loss: 1.0680 - acc: 0.4393 - val_loss: 1.0764 - val_acc: 0.4393\n",
            "Epoch 80/100 - 0.03s - loss: 1.0676 - acc: 0.4406 - val_loss: 1.0762 - val_acc: 0.4312\n",
            "Epoch 81/100 - 0.03s - loss: 1.0673 - acc: 0.4415 - val_loss: 1.0759 - val_acc: 0.4312\n",
            "Epoch 82/100 - 0.03s - loss: 1.0670 - acc: 0.4442 - val_loss: 1.0757 - val_acc: 0.4312\n",
            "Epoch 83/100 - 0.03s - loss: 1.0666 - acc: 0.4453 - val_loss: 1.0755 - val_acc: 0.4332\n",
            "Epoch 84/100 - 0.03s - loss: 1.0663 - acc: 0.4471 - val_loss: 1.0752 - val_acc: 0.4372\n",
            "Epoch 85/100 - 0.03s - loss: 1.0660 - acc: 0.4483 - val_loss: 1.0750 - val_acc: 0.4352\n",
            "Epoch 86/100 - 0.03s - loss: 1.0656 - acc: 0.4485 - val_loss: 1.0747 - val_acc: 0.4352\n",
            "Epoch 87/100 - 0.03s - loss: 1.0653 - acc: 0.4480 - val_loss: 1.0745 - val_acc: 0.4352\n",
            "Epoch 88/100 - 0.03s - loss: 1.0649 - acc: 0.4485 - val_loss: 1.0742 - val_acc: 0.4372\n",
            "Epoch 89/100 - 0.03s - loss: 1.0646 - acc: 0.4496 - val_loss: 1.0740 - val_acc: 0.4372\n",
            "Epoch 90/100 - 0.03s - loss: 1.0643 - acc: 0.4503 - val_loss: 1.0737 - val_acc: 0.4372\n",
            "Epoch 91/100 - 0.03s - loss: 1.0639 - acc: 0.4501 - val_loss: 1.0735 - val_acc: 0.4372\n",
            "Epoch 92/100 - 0.03s - loss: 1.0636 - acc: 0.4505 - val_loss: 1.0732 - val_acc: 0.4372\n",
            "Epoch 93/100 - 0.03s - loss: 1.0633 - acc: 0.4532 - val_loss: 1.0730 - val_acc: 0.4372\n",
            "Epoch 94/100 - 0.03s - loss: 1.0629 - acc: 0.4537 - val_loss: 1.0727 - val_acc: 0.4332\n",
            "Epoch 95/100 - 0.03s - loss: 1.0626 - acc: 0.4534 - val_loss: 1.0725 - val_acc: 0.4332\n",
            "Epoch 96/100 - 0.03s - loss: 1.0622 - acc: 0.4530 - val_loss: 1.0722 - val_acc: 0.4332\n",
            "Epoch 97/100 - 0.03s - loss: 1.0619 - acc: 0.4546 - val_loss: 1.0720 - val_acc: 0.4352\n",
            "Epoch 98/100 - 0.03s - loss: 1.0615 - acc: 0.4550 - val_loss: 1.0717 - val_acc: 0.4352\n",
            "Epoch 99/100 - 0.03s - loss: 1.0612 - acc: 0.4552 - val_loss: 1.0715 - val_acc: 0.4393\n",
            "Epoch 100/100 - 0.03s - loss: 1.0608 - acc: 0.4564 - val_loss: 1.0713 - val_acc: 0.4393\n",
            "\n",
            "Combination 12/252:\n",
            "Hidden Layers: [64, 32], Activation: relu, Learning Rate: 0.001, Batch Size: 64, Epochs: 150\n",
            "Epoch 1/150 - 0.03s - loss: 1.1244 - acc: 0.3277 - val_loss: 1.1268 - val_acc: 0.3138\n",
            "Epoch 2/150 - 0.03s - loss: 1.1176 - acc: 0.3275 - val_loss: 1.1196 - val_acc: 0.3138\n",
            "Epoch 3/150 - 0.03s - loss: 1.1128 - acc: 0.3268 - val_loss: 1.1145 - val_acc: 0.3138\n",
            "Epoch 4/150 - 0.03s - loss: 1.1091 - acc: 0.3277 - val_loss: 1.1107 - val_acc: 0.3138\n",
            "Epoch 5/150 - 0.03s - loss: 1.1063 - acc: 0.3268 - val_loss: 1.1079 - val_acc: 0.3138\n",
            "Epoch 6/150 - 0.03s - loss: 1.1041 - acc: 0.3266 - val_loss: 1.1057 - val_acc: 0.3178\n",
            "Epoch 7/150 - 0.03s - loss: 1.1023 - acc: 0.3306 - val_loss: 1.1038 - val_acc: 0.3259\n",
            "Epoch 8/150 - 0.03s - loss: 1.1009 - acc: 0.3336 - val_loss: 1.1024 - val_acc: 0.3239\n",
            "Epoch 9/150 - 0.03s - loss: 1.0996 - acc: 0.3399 - val_loss: 1.1012 - val_acc: 0.3178\n",
            "Epoch 10/150 - 0.03s - loss: 1.0986 - acc: 0.3457 - val_loss: 1.1001 - val_acc: 0.3219\n",
            "Epoch 11/150 - 0.03s - loss: 1.0976 - acc: 0.3525 - val_loss: 1.0991 - val_acc: 0.3016\n",
            "Epoch 12/150 - 0.03s - loss: 1.0968 - acc: 0.3549 - val_loss: 1.0983 - val_acc: 0.3057\n",
            "Epoch 13/150 - 0.03s - loss: 1.0961 - acc: 0.3594 - val_loss: 1.0976 - val_acc: 0.3198\n",
            "Epoch 14/150 - 0.03s - loss: 1.0954 - acc: 0.3617 - val_loss: 1.0969 - val_acc: 0.3219\n",
            "Epoch 15/150 - 0.03s - loss: 1.0947 - acc: 0.3657 - val_loss: 1.0963 - val_acc: 0.3198\n",
            "Epoch 16/150 - 0.03s - loss: 1.0941 - acc: 0.3630 - val_loss: 1.0957 - val_acc: 0.3381\n",
            "Epoch 17/150 - 0.03s - loss: 1.0936 - acc: 0.3695 - val_loss: 1.0952 - val_acc: 0.3543\n",
            "Epoch 18/150 - 0.03s - loss: 1.0931 - acc: 0.3729 - val_loss: 1.0947 - val_acc: 0.3623\n",
            "Epoch 19/150 - 0.03s - loss: 1.0926 - acc: 0.3788 - val_loss: 1.0942 - val_acc: 0.3644\n",
            "Epoch 20/150 - 0.03s - loss: 1.0921 - acc: 0.3810 - val_loss: 1.0938 - val_acc: 0.3644\n",
            "Epoch 21/150 - 0.03s - loss: 1.0916 - acc: 0.3824 - val_loss: 1.0934 - val_acc: 0.3765\n",
            "Epoch 22/150 - 0.03s - loss: 1.0912 - acc: 0.3824 - val_loss: 1.0929 - val_acc: 0.3684\n",
            "Epoch 23/150 - 0.03s - loss: 1.0907 - acc: 0.3830 - val_loss: 1.0925 - val_acc: 0.3785\n",
            "Epoch 24/150 - 0.03s - loss: 1.0902 - acc: 0.3846 - val_loss: 1.0921 - val_acc: 0.3826\n",
            "Epoch 25/150 - 0.03s - loss: 1.0898 - acc: 0.3898 - val_loss: 1.0918 - val_acc: 0.3785\n",
            "Epoch 26/150 - 0.03s - loss: 1.0894 - acc: 0.3934 - val_loss: 1.0914 - val_acc: 0.3785\n",
            "Epoch 27/150 - 0.03s - loss: 1.0889 - acc: 0.3952 - val_loss: 1.0910 - val_acc: 0.3765\n",
            "Epoch 28/150 - 0.03s - loss: 1.0885 - acc: 0.3974 - val_loss: 1.0907 - val_acc: 0.3866\n",
            "Epoch 29/150 - 0.03s - loss: 1.0881 - acc: 0.3986 - val_loss: 1.0903 - val_acc: 0.3927\n",
            "Epoch 30/150 - 0.03s - loss: 1.0877 - acc: 0.4019 - val_loss: 1.0900 - val_acc: 0.4008\n",
            "Epoch 31/150 - 0.03s - loss: 1.0873 - acc: 0.4037 - val_loss: 1.0897 - val_acc: 0.4028\n",
            "Epoch 32/150 - 0.03s - loss: 1.0869 - acc: 0.4055 - val_loss: 1.0893 - val_acc: 0.4069\n",
            "Epoch 33/150 - 0.03s - loss: 1.0866 - acc: 0.4055 - val_loss: 1.0890 - val_acc: 0.4028\n",
            "Epoch 34/150 - 0.03s - loss: 1.0862 - acc: 0.4071 - val_loss: 1.0887 - val_acc: 0.4028\n",
            "Epoch 35/150 - 0.03s - loss: 1.0858 - acc: 0.4094 - val_loss: 1.0884 - val_acc: 0.4089\n",
            "Epoch 36/150 - 0.03s - loss: 1.0855 - acc: 0.4114 - val_loss: 1.0881 - val_acc: 0.4069\n",
            "Epoch 37/150 - 0.03s - loss: 1.0851 - acc: 0.4143 - val_loss: 1.0879 - val_acc: 0.4089\n",
            "Epoch 38/150 - 0.03s - loss: 1.0848 - acc: 0.4170 - val_loss: 1.0876 - val_acc: 0.4130\n",
            "Epoch 39/150 - 0.03s - loss: 1.0844 - acc: 0.4184 - val_loss: 1.0873 - val_acc: 0.4130\n",
            "Epoch 40/150 - 0.03s - loss: 1.0841 - acc: 0.4197 - val_loss: 1.0870 - val_acc: 0.4170\n",
            "Epoch 41/150 - 0.03s - loss: 1.0837 - acc: 0.4220 - val_loss: 1.0868 - val_acc: 0.4170\n",
            "Epoch 42/150 - 0.03s - loss: 1.0834 - acc: 0.4244 - val_loss: 1.0865 - val_acc: 0.4170\n",
            "Epoch 43/150 - 0.03s - loss: 1.0831 - acc: 0.4247 - val_loss: 1.0863 - val_acc: 0.4170\n",
            "Epoch 44/150 - 0.03s - loss: 1.0827 - acc: 0.4274 - val_loss: 1.0861 - val_acc: 0.4190\n",
            "Epoch 45/150 - 0.03s - loss: 1.0824 - acc: 0.4280 - val_loss: 1.0858 - val_acc: 0.4170\n",
            "Epoch 46/150 - 0.03s - loss: 1.0821 - acc: 0.4289 - val_loss: 1.0856 - val_acc: 0.4170\n",
            "Epoch 47/150 - 0.03s - loss: 1.0817 - acc: 0.4298 - val_loss: 1.0854 - val_acc: 0.4211\n",
            "Epoch 48/150 - 0.03s - loss: 1.0814 - acc: 0.4303 - val_loss: 1.0852 - val_acc: 0.4211\n",
            "Epoch 49/150 - 0.03s - loss: 1.0811 - acc: 0.4291 - val_loss: 1.0850 - val_acc: 0.4231\n",
            "Epoch 50/150 - 0.03s - loss: 1.0808 - acc: 0.4289 - val_loss: 1.0848 - val_acc: 0.4211\n",
            "Epoch 51/150 - 0.03s - loss: 1.0805 - acc: 0.4309 - val_loss: 1.0846 - val_acc: 0.4211\n",
            "Epoch 52/150 - 0.03s - loss: 1.0802 - acc: 0.4307 - val_loss: 1.0844 - val_acc: 0.4211\n",
            "Epoch 53/150 - 0.03s - loss: 1.0799 - acc: 0.4323 - val_loss: 1.0842 - val_acc: 0.4251\n",
            "Epoch 54/150 - 0.03s - loss: 1.0796 - acc: 0.4325 - val_loss: 1.0840 - val_acc: 0.4231\n",
            "Epoch 55/150 - 0.03s - loss: 1.0793 - acc: 0.4325 - val_loss: 1.0838 - val_acc: 0.4231\n",
            "Epoch 56/150 - 0.03s - loss: 1.0790 - acc: 0.4316 - val_loss: 1.0836 - val_acc: 0.4251\n",
            "Epoch 57/150 - 0.03s - loss: 1.0786 - acc: 0.4323 - val_loss: 1.0834 - val_acc: 0.4291\n",
            "Epoch 58/150 - 0.03s - loss: 1.0783 - acc: 0.4321 - val_loss: 1.0832 - val_acc: 0.4291\n",
            "Epoch 59/150 - 0.03s - loss: 1.0780 - acc: 0.4323 - val_loss: 1.0830 - val_acc: 0.4291\n",
            "Epoch 60/150 - 0.03s - loss: 1.0777 - acc: 0.4339 - val_loss: 1.0828 - val_acc: 0.4291\n",
            "Epoch 61/150 - 0.03s - loss: 1.0774 - acc: 0.4354 - val_loss: 1.0826 - val_acc: 0.4291\n",
            "Epoch 62/150 - 0.03s - loss: 1.0771 - acc: 0.4348 - val_loss: 1.0824 - val_acc: 0.4231\n",
            "Epoch 63/150 - 0.03s - loss: 1.0768 - acc: 0.4368 - val_loss: 1.0821 - val_acc: 0.4231\n",
            "Epoch 64/150 - 0.03s - loss: 1.0765 - acc: 0.4372 - val_loss: 1.0819 - val_acc: 0.4211\n",
            "Epoch 65/150 - 0.04s - loss: 1.0762 - acc: 0.4384 - val_loss: 1.0817 - val_acc: 0.4211\n",
            "Epoch 66/150 - 0.04s - loss: 1.0759 - acc: 0.4408 - val_loss: 1.0815 - val_acc: 0.4150\n",
            "Epoch 67/150 - 0.03s - loss: 1.0756 - acc: 0.4411 - val_loss: 1.0813 - val_acc: 0.4211\n",
            "Epoch 68/150 - 0.03s - loss: 1.0752 - acc: 0.4402 - val_loss: 1.0810 - val_acc: 0.4190\n",
            "Epoch 69/150 - 0.03s - loss: 1.0749 - acc: 0.4413 - val_loss: 1.0808 - val_acc: 0.4211\n",
            "Epoch 70/150 - 0.04s - loss: 1.0746 - acc: 0.4433 - val_loss: 1.0806 - val_acc: 0.4231\n",
            "Epoch 71/150 - 0.03s - loss: 1.0743 - acc: 0.4435 - val_loss: 1.0803 - val_acc: 0.4251\n",
            "Epoch 72/150 - 0.03s - loss: 1.0740 - acc: 0.4442 - val_loss: 1.0801 - val_acc: 0.4271\n",
            "Epoch 73/150 - 0.03s - loss: 1.0737 - acc: 0.4442 - val_loss: 1.0799 - val_acc: 0.4291\n",
            "Epoch 74/150 - 0.03s - loss: 1.0734 - acc: 0.4431 - val_loss: 1.0796 - val_acc: 0.4271\n",
            "Epoch 75/150 - 0.03s - loss: 1.0731 - acc: 0.4429 - val_loss: 1.0794 - val_acc: 0.4332\n",
            "Epoch 76/150 - 0.03s - loss: 1.0728 - acc: 0.4447 - val_loss: 1.0791 - val_acc: 0.4332\n",
            "Epoch 77/150 - 0.03s - loss: 1.0725 - acc: 0.4442 - val_loss: 1.0789 - val_acc: 0.4291\n",
            "Epoch 78/150 - 0.03s - loss: 1.0722 - acc: 0.4442 - val_loss: 1.0786 - val_acc: 0.4291\n",
            "Epoch 79/150 - 0.03s - loss: 1.0719 - acc: 0.4449 - val_loss: 1.0784 - val_acc: 0.4271\n",
            "Epoch 80/150 - 0.03s - loss: 1.0716 - acc: 0.4438 - val_loss: 1.0781 - val_acc: 0.4271\n",
            "Epoch 81/150 - 0.03s - loss: 1.0713 - acc: 0.4451 - val_loss: 1.0779 - val_acc: 0.4291\n",
            "Epoch 82/150 - 0.03s - loss: 1.0710 - acc: 0.4460 - val_loss: 1.0777 - val_acc: 0.4332\n",
            "Epoch 83/150 - 0.03s - loss: 1.0707 - acc: 0.4474 - val_loss: 1.0774 - val_acc: 0.4352\n",
            "Epoch 84/150 - 0.03s - loss: 1.0704 - acc: 0.4478 - val_loss: 1.0772 - val_acc: 0.4332\n",
            "Epoch 85/150 - 0.03s - loss: 1.0701 - acc: 0.4487 - val_loss: 1.0770 - val_acc: 0.4393\n",
            "Epoch 86/150 - 0.03s - loss: 1.0698 - acc: 0.4492 - val_loss: 1.0767 - val_acc: 0.4352\n",
            "Epoch 87/150 - 0.03s - loss: 1.0695 - acc: 0.4496 - val_loss: 1.0765 - val_acc: 0.4413\n",
            "Epoch 88/150 - 0.03s - loss: 1.0692 - acc: 0.4501 - val_loss: 1.0763 - val_acc: 0.4433\n",
            "Epoch 89/150 - 0.03s - loss: 1.0689 - acc: 0.4510 - val_loss: 1.0760 - val_acc: 0.4393\n",
            "Epoch 90/150 - 0.03s - loss: 1.0687 - acc: 0.4496 - val_loss: 1.0758 - val_acc: 0.4453\n",
            "Epoch 91/150 - 0.03s - loss: 1.0684 - acc: 0.4510 - val_loss: 1.0756 - val_acc: 0.4372\n",
            "Epoch 92/150 - 0.04s - loss: 1.0681 - acc: 0.4510 - val_loss: 1.0754 - val_acc: 0.4352\n",
            "Epoch 93/150 - 0.03s - loss: 1.0678 - acc: 0.4519 - val_loss: 1.0751 - val_acc: 0.4352\n",
            "Epoch 94/150 - 0.03s - loss: 1.0675 - acc: 0.4525 - val_loss: 1.0749 - val_acc: 0.4372\n",
            "Epoch 95/150 - 0.03s - loss: 1.0672 - acc: 0.4530 - val_loss: 1.0747 - val_acc: 0.4372\n",
            "Epoch 96/150 - 0.04s - loss: 1.0669 - acc: 0.4537 - val_loss: 1.0745 - val_acc: 0.4372\n",
            "Epoch 97/150 - 0.03s - loss: 1.0667 - acc: 0.4548 - val_loss: 1.0742 - val_acc: 0.4372\n",
            "Epoch 98/150 - 0.03s - loss: 1.0664 - acc: 0.4557 - val_loss: 1.0740 - val_acc: 0.4393\n",
            "Epoch 99/150 - 0.03s - loss: 1.0661 - acc: 0.4564 - val_loss: 1.0738 - val_acc: 0.4393\n",
            "Epoch 100/150 - 0.03s - loss: 1.0658 - acc: 0.4559 - val_loss: 1.0736 - val_acc: 0.4413\n",
            "Epoch 101/150 - 0.03s - loss: 1.0656 - acc: 0.4573 - val_loss: 1.0734 - val_acc: 0.4372\n",
            "Epoch 102/150 - 0.03s - loss: 1.0653 - acc: 0.4570 - val_loss: 1.0732 - val_acc: 0.4393\n",
            "Epoch 103/150 - 0.03s - loss: 1.0650 - acc: 0.4588 - val_loss: 1.0730 - val_acc: 0.4413\n",
            "Epoch 104/150 - 0.03s - loss: 1.0647 - acc: 0.4600 - val_loss: 1.0727 - val_acc: 0.4393\n",
            "Epoch 105/150 - 0.03s - loss: 1.0645 - acc: 0.4611 - val_loss: 1.0725 - val_acc: 0.4413\n",
            "Epoch 106/150 - 0.04s - loss: 1.0642 - acc: 0.4618 - val_loss: 1.0723 - val_acc: 0.4413\n",
            "Epoch 107/150 - 0.03s - loss: 1.0639 - acc: 0.4631 - val_loss: 1.0721 - val_acc: 0.4413\n",
            "Epoch 108/150 - 0.03s - loss: 1.0636 - acc: 0.4631 - val_loss: 1.0719 - val_acc: 0.4413\n",
            "Epoch 109/150 - 0.03s - loss: 1.0633 - acc: 0.4636 - val_loss: 1.0717 - val_acc: 0.4433\n",
            "Epoch 110/150 - 0.03s - loss: 1.0631 - acc: 0.4629 - val_loss: 1.0715 - val_acc: 0.4413\n",
            "Epoch 111/150 - 0.03s - loss: 1.0628 - acc: 0.4640 - val_loss: 1.0713 - val_acc: 0.4413\n",
            "Epoch 112/150 - 0.03s - loss: 1.0625 - acc: 0.4638 - val_loss: 1.0711 - val_acc: 0.4433\n",
            "Epoch 113/150 - 0.03s - loss: 1.0622 - acc: 0.4645 - val_loss: 1.0708 - val_acc: 0.4433\n",
            "Epoch 114/150 - 0.03s - loss: 1.0620 - acc: 0.4649 - val_loss: 1.0706 - val_acc: 0.4433\n",
            "Epoch 115/150 - 0.03s - loss: 1.0617 - acc: 0.4654 - val_loss: 1.0704 - val_acc: 0.4433\n",
            "Epoch 116/150 - 0.03s - loss: 1.0614 - acc: 0.4660 - val_loss: 1.0702 - val_acc: 0.4413\n",
            "Epoch 117/150 - 0.03s - loss: 1.0612 - acc: 0.4651 - val_loss: 1.0700 - val_acc: 0.4453\n",
            "Epoch 118/150 - 0.03s - loss: 1.0609 - acc: 0.4645 - val_loss: 1.0698 - val_acc: 0.4453\n",
            "Epoch 119/150 - 0.03s - loss: 1.0606 - acc: 0.4640 - val_loss: 1.0695 - val_acc: 0.4413\n",
            "Epoch 120/150 - 0.03s - loss: 1.0604 - acc: 0.4633 - val_loss: 1.0693 - val_acc: 0.4453\n",
            "Epoch 121/150 - 0.03s - loss: 1.0601 - acc: 0.4627 - val_loss: 1.0691 - val_acc: 0.4433\n",
            "Epoch 122/150 - 0.03s - loss: 1.0598 - acc: 0.4642 - val_loss: 1.0689 - val_acc: 0.4453\n",
            "Epoch 123/150 - 0.03s - loss: 1.0595 - acc: 0.4651 - val_loss: 1.0687 - val_acc: 0.4474\n",
            "Epoch 124/150 - 0.03s - loss: 1.0593 - acc: 0.4654 - val_loss: 1.0685 - val_acc: 0.4453\n",
            "Epoch 125/150 - 0.03s - loss: 1.0590 - acc: 0.4658 - val_loss: 1.0683 - val_acc: 0.4433\n",
            "Epoch 126/150 - 0.03s - loss: 1.0587 - acc: 0.4656 - val_loss: 1.0680 - val_acc: 0.4393\n",
            "Epoch 127/150 - 0.03s - loss: 1.0584 - acc: 0.4654 - val_loss: 1.0678 - val_acc: 0.4413\n",
            "Epoch 128/150 - 0.03s - loss: 1.0582 - acc: 0.4660 - val_loss: 1.0676 - val_acc: 0.4433\n",
            "Epoch 129/150 - 0.04s - loss: 1.0579 - acc: 0.4669 - val_loss: 1.0674 - val_acc: 0.4453\n",
            "Epoch 130/150 - 0.03s - loss: 1.0576 - acc: 0.4676 - val_loss: 1.0672 - val_acc: 0.4514\n",
            "Epoch 131/150 - 0.03s - loss: 1.0573 - acc: 0.4681 - val_loss: 1.0670 - val_acc: 0.4474\n",
            "Epoch 132/150 - 0.04s - loss: 1.0571 - acc: 0.4681 - val_loss: 1.0668 - val_acc: 0.4494\n",
            "Epoch 133/150 - 0.03s - loss: 1.0568 - acc: 0.4681 - val_loss: 1.0665 - val_acc: 0.4534\n",
            "Epoch 134/150 - 0.03s - loss: 1.0565 - acc: 0.4681 - val_loss: 1.0663 - val_acc: 0.4514\n",
            "Epoch 135/150 - 0.03s - loss: 1.0562 - acc: 0.4687 - val_loss: 1.0661 - val_acc: 0.4514\n",
            "Epoch 136/150 - 0.03s - loss: 1.0559 - acc: 0.4683 - val_loss: 1.0659 - val_acc: 0.4514\n",
            "Epoch 137/150 - 0.03s - loss: 1.0557 - acc: 0.4690 - val_loss: 1.0657 - val_acc: 0.4534\n",
            "Epoch 138/150 - 0.03s - loss: 1.0554 - acc: 0.4687 - val_loss: 1.0655 - val_acc: 0.4555\n",
            "Epoch 139/150 - 0.03s - loss: 1.0551 - acc: 0.4703 - val_loss: 1.0652 - val_acc: 0.4555\n",
            "Epoch 140/150 - 0.03s - loss: 1.0548 - acc: 0.4710 - val_loss: 1.0650 - val_acc: 0.4555\n",
            "Epoch 141/150 - 0.03s - loss: 1.0546 - acc: 0.4710 - val_loss: 1.0648 - val_acc: 0.4575\n",
            "Epoch 142/150 - 0.03s - loss: 1.0543 - acc: 0.4714 - val_loss: 1.0645 - val_acc: 0.4534\n",
            "Epoch 143/150 - 0.03s - loss: 1.0540 - acc: 0.4714 - val_loss: 1.0643 - val_acc: 0.4555\n",
            "Epoch 144/150 - 0.03s - loss: 1.0537 - acc: 0.4712 - val_loss: 1.0641 - val_acc: 0.4534\n",
            "Epoch 145/150 - 0.03s - loss: 1.0534 - acc: 0.4703 - val_loss: 1.0639 - val_acc: 0.4555\n",
            "Epoch 146/150 - 0.03s - loss: 1.0532 - acc: 0.4719 - val_loss: 1.0637 - val_acc: 0.4575\n",
            "Epoch 147/150 - 0.03s - loss: 1.0529 - acc: 0.4712 - val_loss: 1.0635 - val_acc: 0.4575\n",
            "Epoch 148/150 - 0.03s - loss: 1.0526 - acc: 0.4719 - val_loss: 1.0632 - val_acc: 0.4555\n",
            "Epoch 149/150 - 0.03s - loss: 1.0523 - acc: 0.4730 - val_loss: 1.0630 - val_acc: 0.4555\n",
            "Epoch 150/150 - 0.03s - loss: 1.0520 - acc: 0.4730 - val_loss: 1.0628 - val_acc: 0.4555\n",
            "\n",
            "Combination 13/252:\n",
            "Hidden Layers: [64, 32], Activation: relu, Learning Rate: 0.0001, Batch Size: 32, Epochs: 50\n",
            "Epoch 1/50 - 0.04s - loss: 1.1107 - acc: 0.3486 - val_loss: 1.1097 - val_acc: 0.3522\n",
            "Epoch 2/50 - 0.04s - loss: 1.1095 - acc: 0.3489 - val_loss: 1.1085 - val_acc: 0.3522\n",
            "Epoch 3/50 - 0.04s - loss: 1.1084 - acc: 0.3489 - val_loss: 1.1075 - val_acc: 0.3522\n",
            "Epoch 4/50 - 0.05s - loss: 1.1075 - acc: 0.3480 - val_loss: 1.1065 - val_acc: 0.3522\n",
            "Epoch 5/50 - 0.05s - loss: 1.1066 - acc: 0.3484 - val_loss: 1.1056 - val_acc: 0.3522\n",
            "Epoch 6/50 - 0.04s - loss: 1.1058 - acc: 0.3493 - val_loss: 1.1049 - val_acc: 0.3522\n",
            "Epoch 7/50 - 0.04s - loss: 1.1051 - acc: 0.3493 - val_loss: 1.1042 - val_acc: 0.3543\n",
            "Epoch 8/50 - 0.04s - loss: 1.1044 - acc: 0.3495 - val_loss: 1.1035 - val_acc: 0.3522\n",
            "Epoch 9/50 - 0.04s - loss: 1.1039 - acc: 0.3502 - val_loss: 1.1029 - val_acc: 0.3522\n",
            "Epoch 10/50 - 0.05s - loss: 1.1033 - acc: 0.3518 - val_loss: 1.1024 - val_acc: 0.3522\n",
            "Epoch 11/50 - 0.04s - loss: 1.1028 - acc: 0.3516 - val_loss: 1.1019 - val_acc: 0.3563\n",
            "Epoch 12/50 - 0.04s - loss: 1.1024 - acc: 0.3513 - val_loss: 1.1014 - val_acc: 0.3603\n",
            "Epoch 13/50 - 0.04s - loss: 1.1019 - acc: 0.3498 - val_loss: 1.1010 - val_acc: 0.3583\n",
            "Epoch 14/50 - 0.05s - loss: 1.1015 - acc: 0.3500 - val_loss: 1.1007 - val_acc: 0.3603\n",
            "Epoch 15/50 - 0.05s - loss: 1.1012 - acc: 0.3511 - val_loss: 1.1003 - val_acc: 0.3623\n",
            "Epoch 16/50 - 0.05s - loss: 1.1008 - acc: 0.3509 - val_loss: 1.1000 - val_acc: 0.3623\n",
            "Epoch 17/50 - 0.05s - loss: 1.1005 - acc: 0.3507 - val_loss: 1.0997 - val_acc: 0.3664\n",
            "Epoch 18/50 - 0.04s - loss: 1.1002 - acc: 0.3520 - val_loss: 1.0994 - val_acc: 0.3684\n",
            "Epoch 19/50 - 0.04s - loss: 1.0999 - acc: 0.3516 - val_loss: 1.0992 - val_acc: 0.3664\n",
            "Epoch 20/50 - 0.04s - loss: 1.0997 - acc: 0.3540 - val_loss: 1.0989 - val_acc: 0.3644\n",
            "Epoch 21/50 - 0.04s - loss: 1.0994 - acc: 0.3565 - val_loss: 1.0987 - val_acc: 0.3603\n",
            "Epoch 22/50 - 0.04s - loss: 1.0992 - acc: 0.3576 - val_loss: 1.0985 - val_acc: 0.3603\n",
            "Epoch 23/50 - 0.05s - loss: 1.0990 - acc: 0.3567 - val_loss: 1.0983 - val_acc: 0.3623\n",
            "Epoch 24/50 - 0.04s - loss: 1.0988 - acc: 0.3561 - val_loss: 1.0981 - val_acc: 0.3543\n",
            "Epoch 25/50 - 0.04s - loss: 1.0986 - acc: 0.3570 - val_loss: 1.0980 - val_acc: 0.3522\n",
            "Epoch 26/50 - 0.04s - loss: 1.0984 - acc: 0.3561 - val_loss: 1.0978 - val_acc: 0.3563\n",
            "Epoch 27/50 - 0.04s - loss: 1.0982 - acc: 0.3561 - val_loss: 1.0976 - val_acc: 0.3603\n",
            "Epoch 28/50 - 0.04s - loss: 1.0980 - acc: 0.3581 - val_loss: 1.0975 - val_acc: 0.3623\n",
            "Epoch 29/50 - 0.05s - loss: 1.0979 - acc: 0.3578 - val_loss: 1.0974 - val_acc: 0.3664\n",
            "Epoch 30/50 - 0.05s - loss: 1.0977 - acc: 0.3574 - val_loss: 1.0972 - val_acc: 0.3704\n",
            "Epoch 31/50 - 0.05s - loss: 1.0976 - acc: 0.3561 - val_loss: 1.0971 - val_acc: 0.3725\n",
            "Epoch 32/50 - 0.05s - loss: 1.0974 - acc: 0.3543 - val_loss: 1.0970 - val_acc: 0.3704\n",
            "Epoch 33/50 - 0.05s - loss: 1.0972 - acc: 0.3554 - val_loss: 1.0969 - val_acc: 0.3704\n",
            "Epoch 34/50 - 0.05s - loss: 1.0971 - acc: 0.3549 - val_loss: 1.0967 - val_acc: 0.3664\n",
            "Epoch 35/50 - 0.05s - loss: 1.0970 - acc: 0.3556 - val_loss: 1.0966 - val_acc: 0.3664\n",
            "Epoch 36/50 - 0.04s - loss: 1.0968 - acc: 0.3563 - val_loss: 1.0965 - val_acc: 0.3704\n",
            "Epoch 37/50 - 0.05s - loss: 1.0967 - acc: 0.3561 - val_loss: 1.0964 - val_acc: 0.3684\n",
            "Epoch 38/50 - 0.05s - loss: 1.0966 - acc: 0.3570 - val_loss: 1.0963 - val_acc: 0.3684\n",
            "Epoch 39/50 - 0.05s - loss: 1.0964 - acc: 0.3549 - val_loss: 1.0962 - val_acc: 0.3704\n",
            "Epoch 40/50 - 0.05s - loss: 1.0963 - acc: 0.3536 - val_loss: 1.0961 - val_acc: 0.3704\n",
            "Epoch 41/50 - 0.05s - loss: 1.0962 - acc: 0.3538 - val_loss: 1.0960 - val_acc: 0.3664\n",
            "Epoch 42/50 - 0.05s - loss: 1.0961 - acc: 0.3538 - val_loss: 1.0959 - val_acc: 0.3664\n",
            "Epoch 43/50 - 0.04s - loss: 1.0959 - acc: 0.3545 - val_loss: 1.0958 - val_acc: 0.3644\n",
            "Epoch 44/50 - 0.04s - loss: 1.0958 - acc: 0.3558 - val_loss: 1.0958 - val_acc: 0.3644\n",
            "Epoch 45/50 - 0.05s - loss: 1.0957 - acc: 0.3565 - val_loss: 1.0957 - val_acc: 0.3644\n",
            "Epoch 46/50 - 0.04s - loss: 1.0956 - acc: 0.3578 - val_loss: 1.0956 - val_acc: 0.3623\n",
            "Epoch 47/50 - 0.04s - loss: 1.0955 - acc: 0.3570 - val_loss: 1.0955 - val_acc: 0.3623\n",
            "Epoch 48/50 - 0.04s - loss: 1.0954 - acc: 0.3563 - val_loss: 1.0954 - val_acc: 0.3664\n",
            "Epoch 49/50 - 0.05s - loss: 1.0952 - acc: 0.3570 - val_loss: 1.0953 - val_acc: 0.3704\n",
            "Epoch 50/50 - 0.04s - loss: 1.0951 - acc: 0.3567 - val_loss: 1.0953 - val_acc: 0.3704\n",
            "\n",
            "Combination 14/252:\n",
            "Hidden Layers: [64, 32], Activation: relu, Learning Rate: 0.0001, Batch Size: 32, Epochs: 100\n",
            "Epoch 1/100 - 0.04s - loss: 1.0948 - acc: 0.3509 - val_loss: 1.0982 - val_acc: 0.3664\n",
            "Epoch 2/100 - 0.05s - loss: 1.0946 - acc: 0.3511 - val_loss: 1.0980 - val_acc: 0.3623\n",
            "Epoch 3/100 - 0.05s - loss: 1.0944 - acc: 0.3529 - val_loss: 1.0978 - val_acc: 0.3644\n",
            "Epoch 4/100 - 0.05s - loss: 1.0941 - acc: 0.3536 - val_loss: 1.0976 - val_acc: 0.3623\n",
            "Epoch 5/100 - 0.05s - loss: 1.0939 - acc: 0.3540 - val_loss: 1.0974 - val_acc: 0.3603\n",
            "Epoch 6/100 - 0.05s - loss: 1.0937 - acc: 0.3543 - val_loss: 1.0972 - val_acc: 0.3644\n",
            "Epoch 7/100 - 0.04s - loss: 1.0935 - acc: 0.3545 - val_loss: 1.0970 - val_acc: 0.3623\n",
            "Epoch 8/100 - 0.04s - loss: 1.0933 - acc: 0.3563 - val_loss: 1.0968 - val_acc: 0.3644\n",
            "Epoch 9/100 - 0.05s - loss: 1.0932 - acc: 0.3581 - val_loss: 1.0966 - val_acc: 0.3664\n",
            "Epoch 10/100 - 0.05s - loss: 1.0930 - acc: 0.3594 - val_loss: 1.0965 - val_acc: 0.3704\n",
            "Epoch 11/100 - 0.04s - loss: 1.0928 - acc: 0.3603 - val_loss: 1.0963 - val_acc: 0.3725\n",
            "Epoch 12/100 - 0.05s - loss: 1.0926 - acc: 0.3619 - val_loss: 1.0961 - val_acc: 0.3765\n",
            "Epoch 13/100 - 0.05s - loss: 1.0924 - acc: 0.3619 - val_loss: 1.0960 - val_acc: 0.3826\n",
            "Epoch 14/100 - 0.04s - loss: 1.0923 - acc: 0.3644 - val_loss: 1.0958 - val_acc: 0.3826\n",
            "Epoch 15/100 - 0.06s - loss: 1.0921 - acc: 0.3637 - val_loss: 1.0957 - val_acc: 0.3826\n",
            "Epoch 16/100 - 0.05s - loss: 1.0920 - acc: 0.3641 - val_loss: 1.0955 - val_acc: 0.3866\n",
            "Epoch 17/100 - 0.04s - loss: 1.0918 - acc: 0.3635 - val_loss: 1.0954 - val_acc: 0.3826\n",
            "Epoch 18/100 - 0.04s - loss: 1.0917 - acc: 0.3657 - val_loss: 1.0953 - val_acc: 0.3846\n",
            "Epoch 19/100 - 0.05s - loss: 1.0915 - acc: 0.3664 - val_loss: 1.0951 - val_acc: 0.3846\n",
            "Epoch 20/100 - 0.04s - loss: 1.0914 - acc: 0.3682 - val_loss: 1.0950 - val_acc: 0.3846\n",
            "Epoch 21/100 - 0.04s - loss: 1.0912 - acc: 0.3686 - val_loss: 1.0948 - val_acc: 0.3826\n",
            "Epoch 22/100 - 0.05s - loss: 1.0911 - acc: 0.3691 - val_loss: 1.0947 - val_acc: 0.3806\n",
            "Epoch 23/100 - 0.04s - loss: 1.0909 - acc: 0.3698 - val_loss: 1.0946 - val_acc: 0.3765\n",
            "Epoch 24/100 - 0.05s - loss: 1.0908 - acc: 0.3704 - val_loss: 1.0945 - val_acc: 0.3806\n",
            "Epoch 25/100 - 0.05s - loss: 1.0907 - acc: 0.3704 - val_loss: 1.0943 - val_acc: 0.3806\n",
            "Epoch 26/100 - 0.04s - loss: 1.0905 - acc: 0.3695 - val_loss: 1.0942 - val_acc: 0.3806\n",
            "Epoch 27/100 - 0.04s - loss: 1.0904 - acc: 0.3718 - val_loss: 1.0941 - val_acc: 0.3785\n",
            "Epoch 28/100 - 0.04s - loss: 1.0902 - acc: 0.3736 - val_loss: 1.0940 - val_acc: 0.3765\n",
            "Epoch 29/100 - 0.04s - loss: 1.0901 - acc: 0.3752 - val_loss: 1.0939 - val_acc: 0.3806\n",
            "Epoch 30/100 - 0.05s - loss: 1.0900 - acc: 0.3756 - val_loss: 1.0938 - val_acc: 0.3826\n",
            "Epoch 31/100 - 0.04s - loss: 1.0899 - acc: 0.3761 - val_loss: 1.0936 - val_acc: 0.3826\n",
            "Epoch 32/100 - 0.04s - loss: 1.0897 - acc: 0.3752 - val_loss: 1.0935 - val_acc: 0.3826\n",
            "Epoch 33/100 - 0.04s - loss: 1.0896 - acc: 0.3758 - val_loss: 1.0934 - val_acc: 0.3826\n",
            "Epoch 34/100 - 0.04s - loss: 1.0895 - acc: 0.3763 - val_loss: 1.0933 - val_acc: 0.3846\n",
            "Epoch 35/100 - 0.05s - loss: 1.0893 - acc: 0.3758 - val_loss: 1.0932 - val_acc: 0.3846\n",
            "Epoch 36/100 - 0.05s - loss: 1.0892 - acc: 0.3763 - val_loss: 1.0931 - val_acc: 0.3806\n",
            "Epoch 37/100 - 0.05s - loss: 1.0891 - acc: 0.3774 - val_loss: 1.0930 - val_acc: 0.3785\n",
            "Epoch 38/100 - 0.04s - loss: 1.0890 - acc: 0.3783 - val_loss: 1.0929 - val_acc: 0.3826\n",
            "Epoch 39/100 - 0.05s - loss: 1.0889 - acc: 0.3792 - val_loss: 1.0928 - val_acc: 0.3826\n",
            "Epoch 40/100 - 0.04s - loss: 1.0887 - acc: 0.3799 - val_loss: 1.0927 - val_acc: 0.3846\n",
            "Epoch 41/100 - 0.04s - loss: 1.0886 - acc: 0.3810 - val_loss: 1.0926 - val_acc: 0.3846\n",
            "Epoch 42/100 - 0.04s - loss: 1.0885 - acc: 0.3819 - val_loss: 1.0925 - val_acc: 0.3846\n",
            "Epoch 43/100 - 0.04s - loss: 1.0884 - acc: 0.3824 - val_loss: 1.0923 - val_acc: 0.3846\n",
            "Epoch 44/100 - 0.04s - loss: 1.0882 - acc: 0.3837 - val_loss: 1.0922 - val_acc: 0.3846\n",
            "Epoch 45/100 - 0.05s - loss: 1.0881 - acc: 0.3833 - val_loss: 1.0921 - val_acc: 0.3826\n",
            "Epoch 46/100 - 0.05s - loss: 1.0880 - acc: 0.3826 - val_loss: 1.0920 - val_acc: 0.3826\n",
            "Epoch 47/100 - 0.04s - loss: 1.0879 - acc: 0.3830 - val_loss: 1.0919 - val_acc: 0.3846\n",
            "Epoch 48/100 - 0.04s - loss: 1.0878 - acc: 0.3835 - val_loss: 1.0918 - val_acc: 0.3846\n",
            "Epoch 49/100 - 0.04s - loss: 1.0876 - acc: 0.3839 - val_loss: 1.0917 - val_acc: 0.3846\n",
            "Epoch 50/100 - 0.05s - loss: 1.0875 - acc: 0.3846 - val_loss: 1.0916 - val_acc: 0.3846\n",
            "Epoch 51/100 - 0.04s - loss: 1.0874 - acc: 0.3855 - val_loss: 1.0915 - val_acc: 0.3846\n",
            "Epoch 52/100 - 0.05s - loss: 1.0873 - acc: 0.3871 - val_loss: 1.0914 - val_acc: 0.3846\n",
            "Epoch 53/100 - 0.04s - loss: 1.0872 - acc: 0.3878 - val_loss: 1.0913 - val_acc: 0.3887\n",
            "Epoch 54/100 - 0.04s - loss: 1.0871 - acc: 0.3884 - val_loss: 1.0912 - val_acc: 0.3907\n",
            "Epoch 55/100 - 0.05s - loss: 1.0870 - acc: 0.3889 - val_loss: 1.0911 - val_acc: 0.3907\n",
            "Epoch 56/100 - 0.05s - loss: 1.0868 - acc: 0.3880 - val_loss: 1.0910 - val_acc: 0.3907\n",
            "Epoch 57/100 - 0.04s - loss: 1.0867 - acc: 0.3891 - val_loss: 1.0909 - val_acc: 0.3907\n",
            "Epoch 58/100 - 0.04s - loss: 1.0866 - acc: 0.3896 - val_loss: 1.0908 - val_acc: 0.3927\n",
            "Epoch 59/100 - 0.05s - loss: 1.0865 - acc: 0.3898 - val_loss: 1.0907 - val_acc: 0.3907\n",
            "Epoch 60/100 - 0.04s - loss: 1.0864 - acc: 0.3889 - val_loss: 1.0906 - val_acc: 0.3866\n",
            "Epoch 61/100 - 0.04s - loss: 1.0863 - acc: 0.3889 - val_loss: 1.0905 - val_acc: 0.3846\n",
            "Epoch 62/100 - 0.04s - loss: 1.0861 - acc: 0.3900 - val_loss: 1.0904 - val_acc: 0.3846\n",
            "Epoch 63/100 - 0.04s - loss: 1.0860 - acc: 0.3911 - val_loss: 1.0903 - val_acc: 0.3826\n",
            "Epoch 64/100 - 0.04s - loss: 1.0859 - acc: 0.3920 - val_loss: 1.0902 - val_acc: 0.3846\n",
            "Epoch 65/100 - 0.04s - loss: 1.0858 - acc: 0.3920 - val_loss: 1.0902 - val_acc: 0.3826\n",
            "Epoch 66/100 - 0.04s - loss: 1.0857 - acc: 0.3936 - val_loss: 1.0901 - val_acc: 0.3785\n",
            "Epoch 67/100 - 0.05s - loss: 1.0856 - acc: 0.3936 - val_loss: 1.0900 - val_acc: 0.3806\n",
            "Epoch 68/100 - 0.04s - loss: 1.0855 - acc: 0.3938 - val_loss: 1.0899 - val_acc: 0.3826\n",
            "Epoch 69/100 - 0.04s - loss: 1.0853 - acc: 0.3938 - val_loss: 1.0898 - val_acc: 0.3826\n",
            "Epoch 70/100 - 0.05s - loss: 1.0852 - acc: 0.3945 - val_loss: 1.0897 - val_acc: 0.3826\n",
            "Epoch 71/100 - 0.05s - loss: 1.0851 - acc: 0.3936 - val_loss: 1.0896 - val_acc: 0.3806\n",
            "Epoch 72/100 - 0.04s - loss: 1.0850 - acc: 0.3936 - val_loss: 1.0895 - val_acc: 0.3846\n",
            "Epoch 73/100 - 0.04s - loss: 1.0849 - acc: 0.3947 - val_loss: 1.0894 - val_acc: 0.3846\n",
            "Epoch 74/100 - 0.05s - loss: 1.0848 - acc: 0.3943 - val_loss: 1.0894 - val_acc: 0.3826\n",
            "Epoch 75/100 - 0.05s - loss: 1.0847 - acc: 0.3941 - val_loss: 1.0893 - val_acc: 0.3826\n",
            "Epoch 76/100 - 0.04s - loss: 1.0846 - acc: 0.3945 - val_loss: 1.0892 - val_acc: 0.3826\n",
            "Epoch 77/100 - 0.04s - loss: 1.0845 - acc: 0.3956 - val_loss: 1.0891 - val_acc: 0.3846\n",
            "Epoch 78/100 - 0.05s - loss: 1.0843 - acc: 0.3959 - val_loss: 1.0890 - val_acc: 0.3866\n",
            "Epoch 79/100 - 0.05s - loss: 1.0842 - acc: 0.3970 - val_loss: 1.0889 - val_acc: 0.3866\n",
            "Epoch 80/100 - 0.05s - loss: 1.0841 - acc: 0.3974 - val_loss: 1.0888 - val_acc: 0.3846\n",
            "Epoch 81/100 - 0.04s - loss: 1.0840 - acc: 0.3979 - val_loss: 1.0887 - val_acc: 0.3846\n",
            "Epoch 82/100 - 0.05s - loss: 1.0839 - acc: 0.3977 - val_loss: 1.0887 - val_acc: 0.3846\n",
            "Epoch 83/100 - 0.04s - loss: 1.0838 - acc: 0.3988 - val_loss: 1.0886 - val_acc: 0.3866\n",
            "Epoch 84/100 - 0.05s - loss: 1.0837 - acc: 0.3988 - val_loss: 1.0885 - val_acc: 0.3866\n",
            "Epoch 85/100 - 0.05s - loss: 1.0836 - acc: 0.3995 - val_loss: 1.0884 - val_acc: 0.3866\n",
            "Epoch 86/100 - 0.05s - loss: 1.0835 - acc: 0.3999 - val_loss: 1.0883 - val_acc: 0.3866\n",
            "Epoch 87/100 - 0.04s - loss: 1.0834 - acc: 0.3997 - val_loss: 1.0882 - val_acc: 0.3866\n",
            "Epoch 88/100 - 0.05s - loss: 1.0833 - acc: 0.4010 - val_loss: 1.0882 - val_acc: 0.3866\n",
            "Epoch 89/100 - 0.05s - loss: 1.0832 - acc: 0.4010 - val_loss: 1.0881 - val_acc: 0.3866\n",
            "Epoch 90/100 - 0.05s - loss: 1.0831 - acc: 0.4033 - val_loss: 1.0880 - val_acc: 0.3866\n",
            "Epoch 91/100 - 0.04s - loss: 1.0830 - acc: 0.4040 - val_loss: 1.0879 - val_acc: 0.3866\n",
            "Epoch 92/100 - 0.04s - loss: 1.0829 - acc: 0.4040 - val_loss: 1.0878 - val_acc: 0.3866\n",
            "Epoch 93/100 - 0.05s - loss: 1.0828 - acc: 0.4033 - val_loss: 1.0878 - val_acc: 0.3846\n",
            "Epoch 94/100 - 0.04s - loss: 1.0827 - acc: 0.4033 - val_loss: 1.0877 - val_acc: 0.3846\n",
            "Epoch 95/100 - 0.05s - loss: 1.0826 - acc: 0.4035 - val_loss: 1.0876 - val_acc: 0.3866\n",
            "Epoch 96/100 - 0.04s - loss: 1.0824 - acc: 0.4040 - val_loss: 1.0875 - val_acc: 0.3866\n",
            "Epoch 97/100 - 0.04s - loss: 1.0823 - acc: 0.4037 - val_loss: 1.0874 - val_acc: 0.3846\n",
            "Epoch 98/100 - 0.04s - loss: 1.0822 - acc: 0.4035 - val_loss: 1.0873 - val_acc: 0.3846\n",
            "Epoch 99/100 - 0.04s - loss: 1.0821 - acc: 0.4044 - val_loss: 1.0873 - val_acc: 0.3846\n",
            "Epoch 100/100 - 0.04s - loss: 1.0820 - acc: 0.4062 - val_loss: 1.0872 - val_acc: 0.3846\n",
            "\n",
            "Combination 15/252:\n",
            "Hidden Layers: [64, 32], Activation: relu, Learning Rate: 0.0001, Batch Size: 32, Epochs: 150\n",
            "Epoch 1/150 - 0.04s - loss: 1.1432 - acc: 0.3273 - val_loss: 1.1497 - val_acc: 0.3138\n",
            "Epoch 2/150 - 0.04s - loss: 1.1381 - acc: 0.3264 - val_loss: 1.1444 - val_acc: 0.3117\n",
            "Epoch 3/150 - 0.04s - loss: 1.1337 - acc: 0.3261 - val_loss: 1.1398 - val_acc: 0.3117\n",
            "Epoch 4/150 - 0.04s - loss: 1.1299 - acc: 0.3255 - val_loss: 1.1357 - val_acc: 0.3097\n",
            "Epoch 5/150 - 0.05s - loss: 1.1266 - acc: 0.3255 - val_loss: 1.1321 - val_acc: 0.3077\n",
            "Epoch 6/150 - 0.04s - loss: 1.1236 - acc: 0.3246 - val_loss: 1.1289 - val_acc: 0.3077\n",
            "Epoch 7/150 - 0.04s - loss: 1.1210 - acc: 0.3237 - val_loss: 1.1261 - val_acc: 0.3057\n",
            "Epoch 8/150 - 0.04s - loss: 1.1187 - acc: 0.3228 - val_loss: 1.1236 - val_acc: 0.3036\n",
            "Epoch 9/150 - 0.05s - loss: 1.1166 - acc: 0.3225 - val_loss: 1.1214 - val_acc: 0.3036\n",
            "Epoch 10/150 - 0.05s - loss: 1.1147 - acc: 0.3210 - val_loss: 1.1194 - val_acc: 0.3036\n",
            "Epoch 11/150 - 0.04s - loss: 1.1131 - acc: 0.3214 - val_loss: 1.1176 - val_acc: 0.2996\n",
            "Epoch 12/150 - 0.04s - loss: 1.1116 - acc: 0.3203 - val_loss: 1.1160 - val_acc: 0.2955\n",
            "Epoch 13/150 - 0.04s - loss: 1.1102 - acc: 0.3171 - val_loss: 1.1145 - val_acc: 0.2915\n",
            "Epoch 14/150 - 0.04s - loss: 1.1090 - acc: 0.3156 - val_loss: 1.1132 - val_acc: 0.2895\n",
            "Epoch 15/150 - 0.05s - loss: 1.1079 - acc: 0.3158 - val_loss: 1.1120 - val_acc: 0.2874\n",
            "Epoch 16/150 - 0.04s - loss: 1.1069 - acc: 0.3147 - val_loss: 1.1109 - val_acc: 0.2814\n",
            "Epoch 17/150 - 0.05s - loss: 1.1060 - acc: 0.3156 - val_loss: 1.1100 - val_acc: 0.2854\n",
            "Epoch 18/150 - 0.04s - loss: 1.1052 - acc: 0.3158 - val_loss: 1.1091 - val_acc: 0.2794\n",
            "Epoch 19/150 - 0.04s - loss: 1.1045 - acc: 0.3176 - val_loss: 1.1083 - val_acc: 0.2672\n",
            "Epoch 20/150 - 0.05s - loss: 1.1038 - acc: 0.3167 - val_loss: 1.1075 - val_acc: 0.2733\n",
            "Epoch 21/150 - 0.04s - loss: 1.1032 - acc: 0.3160 - val_loss: 1.1068 - val_acc: 0.2773\n",
            "Epoch 22/150 - 0.04s - loss: 1.1027 - acc: 0.3174 - val_loss: 1.1062 - val_acc: 0.2794\n",
            "Epoch 23/150 - 0.04s - loss: 1.1021 - acc: 0.3187 - val_loss: 1.1056 - val_acc: 0.2874\n",
            "Epoch 24/150 - 0.04s - loss: 1.1017 - acc: 0.3207 - val_loss: 1.1051 - val_acc: 0.2874\n",
            "Epoch 25/150 - 0.05s - loss: 1.1012 - acc: 0.3201 - val_loss: 1.1046 - val_acc: 0.2915\n",
            "Epoch 26/150 - 0.04s - loss: 1.1008 - acc: 0.3216 - val_loss: 1.1041 - val_acc: 0.2976\n",
            "Epoch 27/150 - 0.04s - loss: 1.1005 - acc: 0.3237 - val_loss: 1.1037 - val_acc: 0.3016\n",
            "Epoch 28/150 - 0.04s - loss: 1.1001 - acc: 0.3261 - val_loss: 1.1033 - val_acc: 0.3016\n",
            "Epoch 29/150 - 0.05s - loss: 1.0998 - acc: 0.3279 - val_loss: 1.1030 - val_acc: 0.2996\n",
            "Epoch 30/150 - 0.05s - loss: 1.0995 - acc: 0.3291 - val_loss: 1.1027 - val_acc: 0.3077\n",
            "Epoch 31/150 - 0.04s - loss: 1.0992 - acc: 0.3311 - val_loss: 1.1023 - val_acc: 0.3097\n",
            "Epoch 32/150 - 0.04s - loss: 1.0990 - acc: 0.3313 - val_loss: 1.1020 - val_acc: 0.3158\n",
            "Epoch 33/150 - 0.04s - loss: 1.0987 - acc: 0.3320 - val_loss: 1.1018 - val_acc: 0.3219\n",
            "Epoch 34/150 - 0.04s - loss: 1.0985 - acc: 0.3331 - val_loss: 1.1015 - val_acc: 0.3219\n",
            "Epoch 35/150 - 0.05s - loss: 1.0983 - acc: 0.3340 - val_loss: 1.1012 - val_acc: 0.3300\n",
            "Epoch 36/150 - 0.05s - loss: 1.0981 - acc: 0.3351 - val_loss: 1.1010 - val_acc: 0.3401\n",
            "Epoch 37/150 - 0.04s - loss: 1.0979 - acc: 0.3360 - val_loss: 1.1008 - val_acc: 0.3340\n",
            "Epoch 38/150 - 0.05s - loss: 1.0977 - acc: 0.3374 - val_loss: 1.1006 - val_acc: 0.3340\n",
            "Epoch 39/150 - 0.04s - loss: 1.0975 - acc: 0.3394 - val_loss: 1.1004 - val_acc: 0.3360\n",
            "Epoch 40/150 - 0.05s - loss: 1.0973 - acc: 0.3403 - val_loss: 1.1002 - val_acc: 0.3421\n",
            "Epoch 41/150 - 0.04s - loss: 1.0972 - acc: 0.3410 - val_loss: 1.1000 - val_acc: 0.3441\n",
            "Epoch 42/150 - 0.05s - loss: 1.0970 - acc: 0.3392 - val_loss: 1.0998 - val_acc: 0.3441\n",
            "Epoch 43/150 - 0.04s - loss: 1.0968 - acc: 0.3412 - val_loss: 1.0996 - val_acc: 0.3482\n",
            "Epoch 44/150 - 0.05s - loss: 1.0967 - acc: 0.3430 - val_loss: 1.0995 - val_acc: 0.3563\n",
            "Epoch 45/150 - 0.05s - loss: 1.0965 - acc: 0.3444 - val_loss: 1.0993 - val_acc: 0.3623\n",
            "Epoch 46/150 - 0.04s - loss: 1.0964 - acc: 0.3466 - val_loss: 1.0992 - val_acc: 0.3644\n",
            "Epoch 47/150 - 0.04s - loss: 1.0962 - acc: 0.3475 - val_loss: 1.0990 - val_acc: 0.3644\n",
            "Epoch 48/150 - 0.04s - loss: 1.0961 - acc: 0.3475 - val_loss: 1.0989 - val_acc: 0.3664\n",
            "Epoch 49/150 - 0.04s - loss: 1.0960 - acc: 0.3486 - val_loss: 1.0988 - val_acc: 0.3644\n",
            "Epoch 50/150 - 0.04s - loss: 1.0958 - acc: 0.3507 - val_loss: 1.0986 - val_acc: 0.3644\n",
            "Epoch 51/150 - 0.05s - loss: 1.0957 - acc: 0.3502 - val_loss: 1.0985 - val_acc: 0.3603\n",
            "Epoch 52/150 - 0.05s - loss: 1.0956 - acc: 0.3511 - val_loss: 1.0984 - val_acc: 0.3623\n",
            "Epoch 53/150 - 0.05s - loss: 1.0954 - acc: 0.3518 - val_loss: 1.0982 - val_acc: 0.3583\n",
            "Epoch 54/150 - 0.04s - loss: 1.0953 - acc: 0.3520 - val_loss: 1.0981 - val_acc: 0.3543\n",
            "Epoch 55/150 - 0.05s - loss: 1.0952 - acc: 0.3527 - val_loss: 1.0980 - val_acc: 0.3522\n",
            "Epoch 56/150 - 0.04s - loss: 1.0951 - acc: 0.3538 - val_loss: 1.0979 - val_acc: 0.3543\n",
            "Epoch 57/150 - 0.04s - loss: 1.0950 - acc: 0.3534 - val_loss: 1.0978 - val_acc: 0.3543\n",
            "Epoch 58/150 - 0.04s - loss: 1.0948 - acc: 0.3549 - val_loss: 1.0977 - val_acc: 0.3603\n",
            "Epoch 59/150 - 0.05s - loss: 1.0947 - acc: 0.3556 - val_loss: 1.0975 - val_acc: 0.3583\n",
            "Epoch 60/150 - 0.05s - loss: 1.0946 - acc: 0.3585 - val_loss: 1.0974 - val_acc: 0.3583\n",
            "Epoch 61/150 - 0.04s - loss: 1.0945 - acc: 0.3603 - val_loss: 1.0973 - val_acc: 0.3644\n",
            "Epoch 62/150 - 0.05s - loss: 1.0944 - acc: 0.3594 - val_loss: 1.0972 - val_acc: 0.3623\n",
            "Epoch 63/150 - 0.04s - loss: 1.0943 - acc: 0.3605 - val_loss: 1.0971 - val_acc: 0.3684\n",
            "Epoch 64/150 - 0.05s - loss: 1.0942 - acc: 0.3610 - val_loss: 1.0970 - val_acc: 0.3644\n",
            "Epoch 65/150 - 0.05s - loss: 1.0940 - acc: 0.3619 - val_loss: 1.0969 - val_acc: 0.3623\n",
            "Epoch 66/150 - 0.04s - loss: 1.0939 - acc: 0.3635 - val_loss: 1.0968 - val_acc: 0.3623\n",
            "Epoch 67/150 - 0.05s - loss: 1.0938 - acc: 0.3648 - val_loss: 1.0967 - val_acc: 0.3603\n",
            "Epoch 68/150 - 0.04s - loss: 1.0937 - acc: 0.3646 - val_loss: 1.0966 - val_acc: 0.3623\n",
            "Epoch 69/150 - 0.04s - loss: 1.0936 - acc: 0.3653 - val_loss: 1.0965 - val_acc: 0.3684\n",
            "Epoch 70/150 - 0.05s - loss: 1.0935 - acc: 0.3653 - val_loss: 1.0964 - val_acc: 0.3684\n",
            "Epoch 71/150 - 0.04s - loss: 1.0934 - acc: 0.3653 - val_loss: 1.0963 - val_acc: 0.3704\n",
            "Epoch 72/150 - 0.04s - loss: 1.0933 - acc: 0.3671 - val_loss: 1.0962 - val_acc: 0.3684\n",
            "Epoch 73/150 - 0.05s - loss: 1.0932 - acc: 0.3677 - val_loss: 1.0961 - val_acc: 0.3664\n",
            "Epoch 74/150 - 0.05s - loss: 1.0931 - acc: 0.3677 - val_loss: 1.0960 - val_acc: 0.3664\n",
            "Epoch 75/150 - 0.05s - loss: 1.0929 - acc: 0.3686 - val_loss: 1.0959 - val_acc: 0.3664\n",
            "Epoch 76/150 - 0.04s - loss: 1.0928 - acc: 0.3693 - val_loss: 1.0958 - val_acc: 0.3664\n",
            "Epoch 77/150 - 0.04s - loss: 1.0927 - acc: 0.3711 - val_loss: 1.0957 - val_acc: 0.3644\n",
            "Epoch 78/150 - 0.05s - loss: 1.0926 - acc: 0.3722 - val_loss: 1.0956 - val_acc: 0.3644\n",
            "Epoch 79/150 - 0.05s - loss: 1.0925 - acc: 0.3729 - val_loss: 1.0956 - val_acc: 0.3644\n",
            "Epoch 80/150 - 0.05s - loss: 1.0924 - acc: 0.3738 - val_loss: 1.0955 - val_acc: 0.3664\n",
            "Epoch 81/150 - 0.04s - loss: 1.0923 - acc: 0.3749 - val_loss: 1.0954 - val_acc: 0.3725\n",
            "Epoch 82/150 - 0.04s - loss: 1.0922 - acc: 0.3758 - val_loss: 1.0953 - val_acc: 0.3725\n",
            "Epoch 83/150 - 0.04s - loss: 1.0921 - acc: 0.3758 - val_loss: 1.0952 - val_acc: 0.3704\n",
            "Epoch 84/150 - 0.05s - loss: 1.0920 - acc: 0.3765 - val_loss: 1.0951 - val_acc: 0.3745\n",
            "Epoch 85/150 - 0.05s - loss: 1.0919 - acc: 0.3758 - val_loss: 1.0950 - val_acc: 0.3745\n",
            "Epoch 86/150 - 0.04s - loss: 1.0918 - acc: 0.3763 - val_loss: 1.0949 - val_acc: 0.3765\n",
            "Epoch 87/150 - 0.05s - loss: 1.0917 - acc: 0.3790 - val_loss: 1.0948 - val_acc: 0.3765\n",
            "Epoch 88/150 - 0.04s - loss: 1.0916 - acc: 0.3799 - val_loss: 1.0948 - val_acc: 0.3765\n",
            "Epoch 89/150 - 0.05s - loss: 1.0915 - acc: 0.3806 - val_loss: 1.0947 - val_acc: 0.3765\n",
            "Epoch 90/150 - 0.05s - loss: 1.0914 - acc: 0.3803 - val_loss: 1.0946 - val_acc: 0.3725\n",
            "Epoch 91/150 - 0.05s - loss: 1.0913 - acc: 0.3803 - val_loss: 1.0945 - val_acc: 0.3725\n",
            "Epoch 92/150 - 0.04s - loss: 1.0912 - acc: 0.3803 - val_loss: 1.0944 - val_acc: 0.3745\n",
            "Epoch 93/150 - 0.04s - loss: 1.0911 - acc: 0.3806 - val_loss: 1.0943 - val_acc: 0.3725\n",
            "Epoch 94/150 - 0.04s - loss: 1.0910 - acc: 0.3799 - val_loss: 1.0942 - val_acc: 0.3684\n",
            "Epoch 95/150 - 0.05s - loss: 1.0909 - acc: 0.3801 - val_loss: 1.0941 - val_acc: 0.3684\n",
            "Epoch 96/150 - 0.04s - loss: 1.0908 - acc: 0.3808 - val_loss: 1.0941 - val_acc: 0.3725\n",
            "Epoch 97/150 - 0.04s - loss: 1.0907 - acc: 0.3810 - val_loss: 1.0940 - val_acc: 0.3704\n",
            "Epoch 98/150 - 0.04s - loss: 1.0906 - acc: 0.3810 - val_loss: 1.0939 - val_acc: 0.3704\n",
            "Epoch 99/150 - 0.04s - loss: 1.0905 - acc: 0.3806 - val_loss: 1.0938 - val_acc: 0.3704\n",
            "Epoch 100/150 - 0.05s - loss: 1.0904 - acc: 0.3799 - val_loss: 1.0937 - val_acc: 0.3704\n",
            "Epoch 101/150 - 0.04s - loss: 1.0903 - acc: 0.3810 - val_loss: 1.0936 - val_acc: 0.3704\n",
            "Epoch 102/150 - 0.05s - loss: 1.0902 - acc: 0.3819 - val_loss: 1.0936 - val_acc: 0.3684\n",
            "Epoch 103/150 - 0.04s - loss: 1.0901 - acc: 0.3821 - val_loss: 1.0935 - val_acc: 0.3725\n",
            "Epoch 104/150 - 0.05s - loss: 1.0900 - acc: 0.3819 - val_loss: 1.0934 - val_acc: 0.3745\n",
            "Epoch 105/150 - 0.05s - loss: 1.0899 - acc: 0.3815 - val_loss: 1.0933 - val_acc: 0.3725\n",
            "Epoch 106/150 - 0.05s - loss: 1.0898 - acc: 0.3819 - val_loss: 1.0932 - val_acc: 0.3725\n",
            "Epoch 107/150 - 0.04s - loss: 1.0897 - acc: 0.3821 - val_loss: 1.0931 - val_acc: 0.3725\n",
            "Epoch 108/150 - 0.05s - loss: 1.0896 - acc: 0.3824 - val_loss: 1.0930 - val_acc: 0.3745\n",
            "Epoch 109/150 - 0.05s - loss: 1.0895 - acc: 0.3821 - val_loss: 1.0930 - val_acc: 0.3745\n",
            "Epoch 110/150 - 0.05s - loss: 1.0895 - acc: 0.3837 - val_loss: 1.0929 - val_acc: 0.3745\n",
            "Epoch 111/150 - 0.05s - loss: 1.0894 - acc: 0.3839 - val_loss: 1.0928 - val_acc: 0.3765\n",
            "Epoch 112/150 - 0.05s - loss: 1.0893 - acc: 0.3846 - val_loss: 1.0927 - val_acc: 0.3765\n",
            "Epoch 113/150 - 0.04s - loss: 1.0892 - acc: 0.3855 - val_loss: 1.0926 - val_acc: 0.3765\n",
            "Epoch 114/150 - 0.05s - loss: 1.0891 - acc: 0.3860 - val_loss: 1.0925 - val_acc: 0.3765\n",
            "Epoch 115/150 - 0.04s - loss: 1.0890 - acc: 0.3866 - val_loss: 1.0925 - val_acc: 0.3765\n",
            "Epoch 116/150 - 0.05s - loss: 1.0889 - acc: 0.3862 - val_loss: 1.0924 - val_acc: 0.3765\n",
            "Epoch 117/150 - 0.05s - loss: 1.0888 - acc: 0.3875 - val_loss: 1.0923 - val_acc: 0.3765\n",
            "Epoch 118/150 - 0.04s - loss: 1.0887 - acc: 0.3884 - val_loss: 1.0922 - val_acc: 0.3745\n",
            "Epoch 119/150 - 0.04s - loss: 1.0886 - acc: 0.3891 - val_loss: 1.0921 - val_acc: 0.3765\n",
            "Epoch 120/150 - 0.05s - loss: 1.0885 - acc: 0.3887 - val_loss: 1.0921 - val_acc: 0.3765\n",
            "Epoch 121/150 - 0.04s - loss: 1.0885 - acc: 0.3889 - val_loss: 1.0920 - val_acc: 0.3745\n",
            "Epoch 122/150 - 0.05s - loss: 1.0884 - acc: 0.3902 - val_loss: 1.0919 - val_acc: 0.3745\n",
            "Epoch 123/150 - 0.04s - loss: 1.0883 - acc: 0.3905 - val_loss: 1.0918 - val_acc: 0.3765\n",
            "Epoch 124/150 - 0.05s - loss: 1.0882 - acc: 0.3905 - val_loss: 1.0917 - val_acc: 0.3765\n",
            "Epoch 125/150 - 0.05s - loss: 1.0881 - acc: 0.3909 - val_loss: 1.0917 - val_acc: 0.3765\n",
            "Epoch 126/150 - 0.05s - loss: 1.0880 - acc: 0.3911 - val_loss: 1.0916 - val_acc: 0.3745\n",
            "Epoch 127/150 - 0.05s - loss: 1.0879 - acc: 0.3902 - val_loss: 1.0915 - val_acc: 0.3745\n",
            "Epoch 128/150 - 0.04s - loss: 1.0878 - acc: 0.3905 - val_loss: 1.0914 - val_acc: 0.3765\n",
            "Epoch 129/150 - 0.04s - loss: 1.0878 - acc: 0.3909 - val_loss: 1.0913 - val_acc: 0.3765\n",
            "Epoch 130/150 - 0.05s - loss: 1.0877 - acc: 0.3905 - val_loss: 1.0913 - val_acc: 0.3765\n",
            "Epoch 131/150 - 0.05s - loss: 1.0876 - acc: 0.3902 - val_loss: 1.0912 - val_acc: 0.3765\n",
            "Epoch 132/150 - 0.05s - loss: 1.0875 - acc: 0.3914 - val_loss: 1.0911 - val_acc: 0.3765\n",
            "Epoch 133/150 - 0.04s - loss: 1.0874 - acc: 0.3916 - val_loss: 1.0910 - val_acc: 0.3806\n",
            "Epoch 134/150 - 0.05s - loss: 1.0873 - acc: 0.3918 - val_loss: 1.0910 - val_acc: 0.3806\n",
            "Epoch 135/150 - 0.04s - loss: 1.0872 - acc: 0.3918 - val_loss: 1.0909 - val_acc: 0.3806\n",
            "Epoch 136/150 - 0.04s - loss: 1.0871 - acc: 0.3925 - val_loss: 1.0908 - val_acc: 0.3826\n",
            "Epoch 137/150 - 0.04s - loss: 1.0871 - acc: 0.3945 - val_loss: 1.0907 - val_acc: 0.3806\n",
            "Epoch 138/150 - 0.04s - loss: 1.0870 - acc: 0.3954 - val_loss: 1.0906 - val_acc: 0.3806\n",
            "Epoch 139/150 - 0.04s - loss: 1.0869 - acc: 0.3959 - val_loss: 1.0906 - val_acc: 0.3806\n",
            "Epoch 140/150 - 0.05s - loss: 1.0868 - acc: 0.3950 - val_loss: 1.0905 - val_acc: 0.3785\n",
            "Epoch 141/150 - 0.05s - loss: 1.0867 - acc: 0.3956 - val_loss: 1.0904 - val_acc: 0.3785\n",
            "Epoch 142/150 - 0.04s - loss: 1.0866 - acc: 0.3963 - val_loss: 1.0903 - val_acc: 0.3785\n",
            "Epoch 143/150 - 0.04s - loss: 1.0865 - acc: 0.3965 - val_loss: 1.0903 - val_acc: 0.3826\n",
            "Epoch 144/150 - 0.04s - loss: 1.0865 - acc: 0.3968 - val_loss: 1.0902 - val_acc: 0.3826\n",
            "Epoch 145/150 - 0.04s - loss: 1.0864 - acc: 0.3979 - val_loss: 1.0901 - val_acc: 0.3846\n",
            "Epoch 146/150 - 0.04s - loss: 1.0863 - acc: 0.3979 - val_loss: 1.0900 - val_acc: 0.3866\n",
            "Epoch 147/150 - 0.05s - loss: 1.0862 - acc: 0.3979 - val_loss: 1.0900 - val_acc: 0.3907\n",
            "Epoch 148/150 - 0.05s - loss: 1.0861 - acc: 0.3992 - val_loss: 1.0899 - val_acc: 0.3907\n",
            "Epoch 149/150 - 0.05s - loss: 1.0860 - acc: 0.3997 - val_loss: 1.0898 - val_acc: 0.3887\n",
            "Epoch 150/150 - 0.05s - loss: 1.0860 - acc: 0.4001 - val_loss: 1.0898 - val_acc: 0.3866\n",
            "\n",
            "Combination 16/252:\n",
            "Hidden Layers: [64, 32], Activation: relu, Learning Rate: 0.0001, Batch Size: 64, Epochs: 50\n",
            "Epoch 1/50 - 0.03s - loss: 1.1123 - acc: 0.3513 - val_loss: 1.1244 - val_acc: 0.3441\n",
            "Epoch 2/50 - 0.03s - loss: 1.1114 - acc: 0.3516 - val_loss: 1.1234 - val_acc: 0.3421\n",
            "Epoch 3/50 - 0.03s - loss: 1.1106 - acc: 0.3520 - val_loss: 1.1225 - val_acc: 0.3421\n",
            "Epoch 4/50 - 0.03s - loss: 1.1098 - acc: 0.3516 - val_loss: 1.1217 - val_acc: 0.3421\n",
            "Epoch 5/50 - 0.03s - loss: 1.1090 - acc: 0.3504 - val_loss: 1.1209 - val_acc: 0.3421\n",
            "Epoch 6/50 - 0.03s - loss: 1.1083 - acc: 0.3500 - val_loss: 1.1201 - val_acc: 0.3421\n",
            "Epoch 7/50 - 0.03s - loss: 1.1076 - acc: 0.3500 - val_loss: 1.1194 - val_acc: 0.3421\n",
            "Epoch 8/50 - 0.03s - loss: 1.1069 - acc: 0.3491 - val_loss: 1.1187 - val_acc: 0.3401\n",
            "Epoch 9/50 - 0.03s - loss: 1.1063 - acc: 0.3484 - val_loss: 1.1181 - val_acc: 0.3401\n",
            "Epoch 10/50 - 0.03s - loss: 1.1057 - acc: 0.3484 - val_loss: 1.1174 - val_acc: 0.3401\n",
            "Epoch 11/50 - 0.03s - loss: 1.1052 - acc: 0.3486 - val_loss: 1.1168 - val_acc: 0.3401\n",
            "Epoch 12/50 - 0.03s - loss: 1.1046 - acc: 0.3489 - val_loss: 1.1163 - val_acc: 0.3381\n",
            "Epoch 13/50 - 0.03s - loss: 1.1041 - acc: 0.3489 - val_loss: 1.1157 - val_acc: 0.3381\n",
            "Epoch 14/50 - 0.03s - loss: 1.1037 - acc: 0.3482 - val_loss: 1.1152 - val_acc: 0.3381\n",
            "Epoch 15/50 - 0.03s - loss: 1.1032 - acc: 0.3489 - val_loss: 1.1147 - val_acc: 0.3401\n",
            "Epoch 16/50 - 0.03s - loss: 1.1028 - acc: 0.3491 - val_loss: 1.1143 - val_acc: 0.3401\n",
            "Epoch 17/50 - 0.03s - loss: 1.1024 - acc: 0.3489 - val_loss: 1.1138 - val_acc: 0.3381\n",
            "Epoch 18/50 - 0.03s - loss: 1.1020 - acc: 0.3484 - val_loss: 1.1134 - val_acc: 0.3401\n",
            "Epoch 19/50 - 0.03s - loss: 1.1016 - acc: 0.3477 - val_loss: 1.1130 - val_acc: 0.3401\n",
            "Epoch 20/50 - 0.03s - loss: 1.1012 - acc: 0.3473 - val_loss: 1.1126 - val_acc: 0.3401\n",
            "Epoch 21/50 - 0.03s - loss: 1.1009 - acc: 0.3464 - val_loss: 1.1122 - val_acc: 0.3401\n",
            "Epoch 22/50 - 0.03s - loss: 1.1005 - acc: 0.3457 - val_loss: 1.1119 - val_acc: 0.3421\n",
            "Epoch 23/50 - 0.03s - loss: 1.1002 - acc: 0.3446 - val_loss: 1.1115 - val_acc: 0.3421\n",
            "Epoch 24/50 - 0.03s - loss: 1.0999 - acc: 0.3448 - val_loss: 1.1112 - val_acc: 0.3441\n",
            "Epoch 25/50 - 0.03s - loss: 1.0996 - acc: 0.3450 - val_loss: 1.1109 - val_acc: 0.3441\n",
            "Epoch 26/50 - 0.03s - loss: 1.0994 - acc: 0.3448 - val_loss: 1.1106 - val_acc: 0.3401\n",
            "Epoch 27/50 - 0.03s - loss: 1.0991 - acc: 0.3453 - val_loss: 1.1103 - val_acc: 0.3381\n",
            "Epoch 28/50 - 0.03s - loss: 1.0988 - acc: 0.3450 - val_loss: 1.1100 - val_acc: 0.3401\n",
            "Epoch 29/50 - 0.03s - loss: 1.0986 - acc: 0.3457 - val_loss: 1.1098 - val_acc: 0.3381\n",
            "Epoch 30/50 - 0.03s - loss: 1.0983 - acc: 0.3466 - val_loss: 1.1095 - val_acc: 0.3381\n",
            "Epoch 31/50 - 0.03s - loss: 1.0981 - acc: 0.3466 - val_loss: 1.1093 - val_acc: 0.3401\n",
            "Epoch 32/50 - 0.03s - loss: 1.0979 - acc: 0.3459 - val_loss: 1.1091 - val_acc: 0.3401\n",
            "Epoch 33/50 - 0.03s - loss: 1.0977 - acc: 0.3464 - val_loss: 1.1088 - val_acc: 0.3381\n",
            "Epoch 34/50 - 0.03s - loss: 1.0975 - acc: 0.3459 - val_loss: 1.1086 - val_acc: 0.3360\n",
            "Epoch 35/50 - 0.03s - loss: 1.0973 - acc: 0.3471 - val_loss: 1.1084 - val_acc: 0.3360\n",
            "Epoch 36/50 - 0.03s - loss: 1.0971 - acc: 0.3486 - val_loss: 1.1082 - val_acc: 0.3381\n",
            "Epoch 37/50 - 0.03s - loss: 1.0969 - acc: 0.3502 - val_loss: 1.1080 - val_acc: 0.3360\n",
            "Epoch 38/50 - 0.03s - loss: 1.0967 - acc: 0.3509 - val_loss: 1.1078 - val_acc: 0.3340\n",
            "Epoch 39/50 - 0.03s - loss: 1.0965 - acc: 0.3518 - val_loss: 1.1076 - val_acc: 0.3340\n",
            "Epoch 40/50 - 0.03s - loss: 1.0964 - acc: 0.3522 - val_loss: 1.1075 - val_acc: 0.3360\n",
            "Epoch 41/50 - 0.03s - loss: 1.0962 - acc: 0.3520 - val_loss: 1.1073 - val_acc: 0.3360\n",
            "Epoch 42/50 - 0.03s - loss: 1.0960 - acc: 0.3520 - val_loss: 1.1071 - val_acc: 0.3381\n",
            "Epoch 43/50 - 0.03s - loss: 1.0959 - acc: 0.3529 - val_loss: 1.1070 - val_acc: 0.3381\n",
            "Epoch 44/50 - 0.03s - loss: 1.0957 - acc: 0.3543 - val_loss: 1.1068 - val_acc: 0.3381\n",
            "Epoch 45/50 - 0.03s - loss: 1.0956 - acc: 0.3540 - val_loss: 1.1067 - val_acc: 0.3340\n",
            "Epoch 46/50 - 0.03s - loss: 1.0955 - acc: 0.3529 - val_loss: 1.1065 - val_acc: 0.3320\n",
            "Epoch 47/50 - 0.03s - loss: 1.0953 - acc: 0.3534 - val_loss: 1.1064 - val_acc: 0.3340\n",
            "Epoch 48/50 - 0.03s - loss: 1.0952 - acc: 0.3534 - val_loss: 1.1063 - val_acc: 0.3340\n",
            "Epoch 49/50 - 0.03s - loss: 1.0951 - acc: 0.3547 - val_loss: 1.1061 - val_acc: 0.3360\n",
            "Epoch 50/50 - 0.03s - loss: 1.0949 - acc: 0.3554 - val_loss: 1.1060 - val_acc: 0.3360\n",
            "\n",
            "Combination 17/252:\n",
            "Hidden Layers: [64, 32], Activation: relu, Learning Rate: 0.0001, Batch Size: 64, Epochs: 100\n",
            "Epoch 1/100 - 0.03s - loss: 1.1281 - acc: 0.3225 - val_loss: 1.1216 - val_acc: 0.3360\n",
            "Epoch 2/100 - 0.03s - loss: 1.1270 - acc: 0.3225 - val_loss: 1.1207 - val_acc: 0.3360\n",
            "Epoch 3/100 - 0.03s - loss: 1.1259 - acc: 0.3225 - val_loss: 1.1197 - val_acc: 0.3360\n",
            "Epoch 4/100 - 0.04s - loss: 1.1248 - acc: 0.3228 - val_loss: 1.1189 - val_acc: 0.3360\n",
            "Epoch 5/100 - 0.03s - loss: 1.1239 - acc: 0.3228 - val_loss: 1.1180 - val_acc: 0.3360\n",
            "Epoch 6/100 - 0.03s - loss: 1.1229 - acc: 0.3228 - val_loss: 1.1172 - val_acc: 0.3360\n",
            "Epoch 7/100 - 0.03s - loss: 1.1220 - acc: 0.3225 - val_loss: 1.1165 - val_acc: 0.3340\n",
            "Epoch 8/100 - 0.03s - loss: 1.1211 - acc: 0.3225 - val_loss: 1.1157 - val_acc: 0.3340\n",
            "Epoch 9/100 - 0.03s - loss: 1.1203 - acc: 0.3230 - val_loss: 1.1150 - val_acc: 0.3340\n",
            "Epoch 10/100 - 0.03s - loss: 1.1195 - acc: 0.3230 - val_loss: 1.1143 - val_acc: 0.3340\n",
            "Epoch 11/100 - 0.03s - loss: 1.1187 - acc: 0.3230 - val_loss: 1.1137 - val_acc: 0.3340\n",
            "Epoch 12/100 - 0.03s - loss: 1.1180 - acc: 0.3234 - val_loss: 1.1131 - val_acc: 0.3340\n",
            "Epoch 13/100 - 0.03s - loss: 1.1173 - acc: 0.3237 - val_loss: 1.1125 - val_acc: 0.3340\n",
            "Epoch 14/100 - 0.03s - loss: 1.1166 - acc: 0.3239 - val_loss: 1.1119 - val_acc: 0.3340\n",
            "Epoch 15/100 - 0.03s - loss: 1.1159 - acc: 0.3237 - val_loss: 1.1113 - val_acc: 0.3340\n",
            "Epoch 16/100 - 0.03s - loss: 1.1153 - acc: 0.3239 - val_loss: 1.1108 - val_acc: 0.3340\n",
            "Epoch 17/100 - 0.03s - loss: 1.1147 - acc: 0.3241 - val_loss: 1.1103 - val_acc: 0.3340\n",
            "Epoch 18/100 - 0.03s - loss: 1.1141 - acc: 0.3243 - val_loss: 1.1098 - val_acc: 0.3340\n",
            "Epoch 19/100 - 0.04s - loss: 1.1135 - acc: 0.3243 - val_loss: 1.1093 - val_acc: 0.3340\n",
            "Epoch 20/100 - 0.03s - loss: 1.1130 - acc: 0.3246 - val_loss: 1.1089 - val_acc: 0.3340\n",
            "Epoch 21/100 - 0.03s - loss: 1.1125 - acc: 0.3246 - val_loss: 1.1084 - val_acc: 0.3340\n",
            "Epoch 22/100 - 0.03s - loss: 1.1120 - acc: 0.3248 - val_loss: 1.1080 - val_acc: 0.3340\n",
            "Epoch 23/100 - 0.03s - loss: 1.1115 - acc: 0.3250 - val_loss: 1.1076 - val_acc: 0.3340\n",
            "Epoch 24/100 - 0.03s - loss: 1.1110 - acc: 0.3257 - val_loss: 1.1072 - val_acc: 0.3320\n",
            "Epoch 25/100 - 0.03s - loss: 1.1105 - acc: 0.3255 - val_loss: 1.1068 - val_acc: 0.3320\n",
            "Epoch 26/100 - 0.03s - loss: 1.1101 - acc: 0.3259 - val_loss: 1.1064 - val_acc: 0.3340\n",
            "Epoch 27/100 - 0.03s - loss: 1.1097 - acc: 0.3257 - val_loss: 1.1061 - val_acc: 0.3340\n",
            "Epoch 28/100 - 0.03s - loss: 1.1093 - acc: 0.3266 - val_loss: 1.1057 - val_acc: 0.3340\n",
            "Epoch 29/100 - 0.03s - loss: 1.1089 - acc: 0.3257 - val_loss: 1.1054 - val_acc: 0.3340\n",
            "Epoch 30/100 - 0.03s - loss: 1.1085 - acc: 0.3252 - val_loss: 1.1051 - val_acc: 0.3340\n",
            "Epoch 31/100 - 0.03s - loss: 1.1081 - acc: 0.3261 - val_loss: 1.1047 - val_acc: 0.3340\n",
            "Epoch 32/100 - 0.03s - loss: 1.1077 - acc: 0.3255 - val_loss: 1.1044 - val_acc: 0.3360\n",
            "Epoch 33/100 - 0.03s - loss: 1.1074 - acc: 0.3255 - val_loss: 1.1042 - val_acc: 0.3320\n",
            "Epoch 34/100 - 0.03s - loss: 1.1070 - acc: 0.3257 - val_loss: 1.1039 - val_acc: 0.3320\n",
            "Epoch 35/100 - 0.03s - loss: 1.1067 - acc: 0.3261 - val_loss: 1.1036 - val_acc: 0.3300\n",
            "Epoch 36/100 - 0.03s - loss: 1.1064 - acc: 0.3264 - val_loss: 1.1033 - val_acc: 0.3320\n",
            "Epoch 37/100 - 0.03s - loss: 1.1061 - acc: 0.3252 - val_loss: 1.1031 - val_acc: 0.3320\n",
            "Epoch 38/100 - 0.03s - loss: 1.1058 - acc: 0.3266 - val_loss: 1.1028 - val_acc: 0.3320\n",
            "Epoch 39/100 - 0.03s - loss: 1.1055 - acc: 0.3273 - val_loss: 1.1026 - val_acc: 0.3320\n",
            "Epoch 40/100 - 0.03s - loss: 1.1052 - acc: 0.3273 - val_loss: 1.1023 - val_acc: 0.3320\n",
            "Epoch 41/100 - 0.04s - loss: 1.1049 - acc: 0.3279 - val_loss: 1.1021 - val_acc: 0.3320\n",
            "Epoch 42/100 - 0.03s - loss: 1.1047 - acc: 0.3275 - val_loss: 1.1019 - val_acc: 0.3340\n",
            "Epoch 43/100 - 0.03s - loss: 1.1044 - acc: 0.3270 - val_loss: 1.1017 - val_acc: 0.3340\n",
            "Epoch 44/100 - 0.03s - loss: 1.1041 - acc: 0.3282 - val_loss: 1.1014 - val_acc: 0.3360\n",
            "Epoch 45/100 - 0.03s - loss: 1.1039 - acc: 0.3279 - val_loss: 1.1012 - val_acc: 0.3381\n",
            "Epoch 46/100 - 0.03s - loss: 1.1036 - acc: 0.3293 - val_loss: 1.1010 - val_acc: 0.3381\n",
            "Epoch 47/100 - 0.03s - loss: 1.1034 - acc: 0.3304 - val_loss: 1.1008 - val_acc: 0.3401\n",
            "Epoch 48/100 - 0.03s - loss: 1.1032 - acc: 0.3306 - val_loss: 1.1006 - val_acc: 0.3421\n",
            "Epoch 49/100 - 0.03s - loss: 1.1029 - acc: 0.3284 - val_loss: 1.1004 - val_acc: 0.3502\n",
            "Epoch 50/100 - 0.03s - loss: 1.1027 - acc: 0.3300 - val_loss: 1.1002 - val_acc: 0.3462\n",
            "Epoch 51/100 - 0.03s - loss: 1.1025 - acc: 0.3302 - val_loss: 1.1001 - val_acc: 0.3462\n",
            "Epoch 52/100 - 0.03s - loss: 1.1023 - acc: 0.3304 - val_loss: 1.0999 - val_acc: 0.3462\n",
            "Epoch 53/100 - 0.03s - loss: 1.1021 - acc: 0.3309 - val_loss: 1.0997 - val_acc: 0.3441\n",
            "Epoch 54/100 - 0.03s - loss: 1.1018 - acc: 0.3313 - val_loss: 1.0995 - val_acc: 0.3421\n",
            "Epoch 55/100 - 0.03s - loss: 1.1016 - acc: 0.3309 - val_loss: 1.0994 - val_acc: 0.3441\n",
            "Epoch 56/100 - 0.03s - loss: 1.1014 - acc: 0.3318 - val_loss: 1.0992 - val_acc: 0.3502\n",
            "Epoch 57/100 - 0.03s - loss: 1.1012 - acc: 0.3315 - val_loss: 1.0991 - val_acc: 0.3522\n",
            "Epoch 58/100 - 0.03s - loss: 1.1011 - acc: 0.3327 - val_loss: 1.0989 - val_acc: 0.3522\n",
            "Epoch 59/100 - 0.03s - loss: 1.1009 - acc: 0.3324 - val_loss: 1.0987 - val_acc: 0.3522\n",
            "Epoch 60/100 - 0.03s - loss: 1.1007 - acc: 0.3324 - val_loss: 1.0986 - val_acc: 0.3502\n",
            "Epoch 61/100 - 0.03s - loss: 1.1005 - acc: 0.3333 - val_loss: 1.0984 - val_acc: 0.3522\n",
            "Epoch 62/100 - 0.03s - loss: 1.1003 - acc: 0.3367 - val_loss: 1.0983 - val_acc: 0.3563\n",
            "Epoch 63/100 - 0.03s - loss: 1.1001 - acc: 0.3365 - val_loss: 1.0982 - val_acc: 0.3543\n",
            "Epoch 64/100 - 0.03s - loss: 1.1000 - acc: 0.3378 - val_loss: 1.0980 - val_acc: 0.3543\n",
            "Epoch 65/100 - 0.03s - loss: 1.0998 - acc: 0.3385 - val_loss: 1.0979 - val_acc: 0.3502\n",
            "Epoch 66/100 - 0.03s - loss: 1.0996 - acc: 0.3390 - val_loss: 1.0978 - val_acc: 0.3482\n",
            "Epoch 67/100 - 0.03s - loss: 1.0995 - acc: 0.3390 - val_loss: 1.0976 - val_acc: 0.3441\n",
            "Epoch 68/100 - 0.03s - loss: 1.0993 - acc: 0.3401 - val_loss: 1.0975 - val_acc: 0.3421\n",
            "Epoch 69/100 - 0.03s - loss: 1.0992 - acc: 0.3428 - val_loss: 1.0974 - val_acc: 0.3421\n",
            "Epoch 70/100 - 0.03s - loss: 1.0990 - acc: 0.3426 - val_loss: 1.0973 - val_acc: 0.3401\n",
            "Epoch 71/100 - 0.03s - loss: 1.0989 - acc: 0.3432 - val_loss: 1.0971 - val_acc: 0.3401\n",
            "Epoch 72/100 - 0.03s - loss: 1.0987 - acc: 0.3446 - val_loss: 1.0970 - val_acc: 0.3421\n",
            "Epoch 73/100 - 0.03s - loss: 1.0986 - acc: 0.3466 - val_loss: 1.0969 - val_acc: 0.3462\n",
            "Epoch 74/100 - 0.03s - loss: 1.0984 - acc: 0.3473 - val_loss: 1.0968 - val_acc: 0.3502\n",
            "Epoch 75/100 - 0.03s - loss: 1.0983 - acc: 0.3482 - val_loss: 1.0967 - val_acc: 0.3482\n",
            "Epoch 76/100 - 0.03s - loss: 1.0982 - acc: 0.3471 - val_loss: 1.0966 - val_acc: 0.3522\n",
            "Epoch 77/100 - 0.03s - loss: 1.0980 - acc: 0.3493 - val_loss: 1.0965 - val_acc: 0.3502\n",
            "Epoch 78/100 - 0.03s - loss: 1.0979 - acc: 0.3509 - val_loss: 1.0964 - val_acc: 0.3522\n",
            "Epoch 79/100 - 0.03s - loss: 1.0978 - acc: 0.3527 - val_loss: 1.0963 - val_acc: 0.3543\n",
            "Epoch 80/100 - 0.03s - loss: 1.0977 - acc: 0.3525 - val_loss: 1.0962 - val_acc: 0.3563\n",
            "Epoch 81/100 - 0.03s - loss: 1.0975 - acc: 0.3531 - val_loss: 1.0961 - val_acc: 0.3603\n",
            "Epoch 82/100 - 0.03s - loss: 1.0974 - acc: 0.3549 - val_loss: 1.0960 - val_acc: 0.3644\n",
            "Epoch 83/100 - 0.03s - loss: 1.0973 - acc: 0.3561 - val_loss: 1.0959 - val_acc: 0.3725\n",
            "Epoch 84/100 - 0.03s - loss: 1.0972 - acc: 0.3574 - val_loss: 1.0958 - val_acc: 0.3725\n",
            "Epoch 85/100 - 0.03s - loss: 1.0971 - acc: 0.3576 - val_loss: 1.0957 - val_acc: 0.3725\n",
            "Epoch 86/100 - 0.03s - loss: 1.0969 - acc: 0.3594 - val_loss: 1.0956 - val_acc: 0.3745\n",
            "Epoch 87/100 - 0.04s - loss: 1.0968 - acc: 0.3619 - val_loss: 1.0955 - val_acc: 0.3704\n",
            "Epoch 88/100 - 0.04s - loss: 1.0967 - acc: 0.3628 - val_loss: 1.0954 - val_acc: 0.3704\n",
            "Epoch 89/100 - 0.03s - loss: 1.0966 - acc: 0.3648 - val_loss: 1.0953 - val_acc: 0.3644\n",
            "Epoch 90/100 - 0.03s - loss: 1.0965 - acc: 0.3650 - val_loss: 1.0953 - val_acc: 0.3664\n",
            "Epoch 91/100 - 0.03s - loss: 1.0964 - acc: 0.3655 - val_loss: 1.0952 - val_acc: 0.3644\n",
            "Epoch 92/100 - 0.03s - loss: 1.0963 - acc: 0.3664 - val_loss: 1.0951 - val_acc: 0.3644\n",
            "Epoch 93/100 - 0.03s - loss: 1.0961 - acc: 0.3689 - val_loss: 1.0950 - val_acc: 0.3603\n",
            "Epoch 94/100 - 0.03s - loss: 1.0960 - acc: 0.3695 - val_loss: 1.0949 - val_acc: 0.3623\n",
            "Epoch 95/100 - 0.03s - loss: 1.0959 - acc: 0.3700 - val_loss: 1.0949 - val_acc: 0.3623\n",
            "Epoch 96/100 - 0.03s - loss: 1.0958 - acc: 0.3716 - val_loss: 1.0948 - val_acc: 0.3623\n",
            "Epoch 97/100 - 0.04s - loss: 1.0957 - acc: 0.3734 - val_loss: 1.0947 - val_acc: 0.3583\n",
            "Epoch 98/100 - 0.04s - loss: 1.0956 - acc: 0.3745 - val_loss: 1.0946 - val_acc: 0.3583\n",
            "Epoch 99/100 - 0.03s - loss: 1.0955 - acc: 0.3747 - val_loss: 1.0945 - val_acc: 0.3603\n",
            "Epoch 100/100 - 0.03s - loss: 1.0954 - acc: 0.3749 - val_loss: 1.0944 - val_acc: 0.3603\n",
            "\n",
            "Combination 18/252:\n",
            "Hidden Layers: [64, 32], Activation: relu, Learning Rate: 0.0001, Batch Size: 64, Epochs: 150\n",
            "Epoch 1/150 - 0.03s - loss: 1.0990 - acc: 0.3507 - val_loss: 1.1031 - val_acc: 0.3279\n",
            "Epoch 2/150 - 0.04s - loss: 1.0988 - acc: 0.3531 - val_loss: 1.1029 - val_acc: 0.3300\n",
            "Epoch 3/150 - 0.03s - loss: 1.0986 - acc: 0.3527 - val_loss: 1.1027 - val_acc: 0.3320\n",
            "Epoch 4/150 - 0.03s - loss: 1.0985 - acc: 0.3536 - val_loss: 1.1025 - val_acc: 0.3320\n",
            "Epoch 5/150 - 0.03s - loss: 1.0983 - acc: 0.3561 - val_loss: 1.1023 - val_acc: 0.3340\n",
            "Epoch 6/150 - 0.03s - loss: 1.0982 - acc: 0.3556 - val_loss: 1.1021 - val_acc: 0.3360\n",
            "Epoch 7/150 - 0.03s - loss: 1.0981 - acc: 0.3570 - val_loss: 1.1020 - val_acc: 0.3381\n",
            "Epoch 8/150 - 0.03s - loss: 1.0979 - acc: 0.3599 - val_loss: 1.1018 - val_acc: 0.3381\n",
            "Epoch 9/150 - 0.03s - loss: 1.0978 - acc: 0.3592 - val_loss: 1.1017 - val_acc: 0.3401\n",
            "Epoch 10/150 - 0.04s - loss: 1.0977 - acc: 0.3599 - val_loss: 1.1016 - val_acc: 0.3381\n",
            "Epoch 11/150 - 0.03s - loss: 1.0975 - acc: 0.3596 - val_loss: 1.1014 - val_acc: 0.3381\n",
            "Epoch 12/150 - 0.03s - loss: 1.0974 - acc: 0.3596 - val_loss: 1.1013 - val_acc: 0.3381\n",
            "Epoch 13/150 - 0.03s - loss: 1.0973 - acc: 0.3596 - val_loss: 1.1011 - val_acc: 0.3401\n",
            "Epoch 14/150 - 0.03s - loss: 1.0972 - acc: 0.3610 - val_loss: 1.1010 - val_acc: 0.3441\n",
            "Epoch 15/150 - 0.04s - loss: 1.0971 - acc: 0.3637 - val_loss: 1.1009 - val_acc: 0.3462\n",
            "Epoch 16/150 - 0.04s - loss: 1.0970 - acc: 0.3637 - val_loss: 1.1008 - val_acc: 0.3482\n",
            "Epoch 17/150 - 0.03s - loss: 1.0969 - acc: 0.3646 - val_loss: 1.1007 - val_acc: 0.3482\n",
            "Epoch 18/150 - 0.03s - loss: 1.0968 - acc: 0.3655 - val_loss: 1.1006 - val_acc: 0.3522\n",
            "Epoch 19/150 - 0.04s - loss: 1.0966 - acc: 0.3646 - val_loss: 1.1005 - val_acc: 0.3522\n",
            "Epoch 20/150 - 0.04s - loss: 1.0965 - acc: 0.3655 - val_loss: 1.1004 - val_acc: 0.3563\n",
            "Epoch 21/150 - 0.04s - loss: 1.0964 - acc: 0.3655 - val_loss: 1.1003 - val_acc: 0.3583\n",
            "Epoch 22/150 - 0.04s - loss: 1.0963 - acc: 0.3657 - val_loss: 1.1002 - val_acc: 0.3583\n",
            "Epoch 23/150 - 0.04s - loss: 1.0962 - acc: 0.3664 - val_loss: 1.1001 - val_acc: 0.3603\n",
            "Epoch 24/150 - 0.03s - loss: 1.0961 - acc: 0.3668 - val_loss: 1.1000 - val_acc: 0.3583\n",
            "Epoch 25/150 - 0.03s - loss: 1.0960 - acc: 0.3677 - val_loss: 1.0999 - val_acc: 0.3603\n",
            "Epoch 26/150 - 0.03s - loss: 1.0960 - acc: 0.3684 - val_loss: 1.0998 - val_acc: 0.3583\n",
            "Epoch 27/150 - 0.03s - loss: 1.0959 - acc: 0.3675 - val_loss: 1.0997 - val_acc: 0.3603\n",
            "Epoch 28/150 - 0.03s - loss: 1.0958 - acc: 0.3673 - val_loss: 1.0996 - val_acc: 0.3583\n",
            "Epoch 29/150 - 0.03s - loss: 1.0957 - acc: 0.3664 - val_loss: 1.0995 - val_acc: 0.3583\n",
            "Epoch 30/150 - 0.03s - loss: 1.0956 - acc: 0.3657 - val_loss: 1.0995 - val_acc: 0.3603\n",
            "Epoch 31/150 - 0.03s - loss: 1.0955 - acc: 0.3659 - val_loss: 1.0994 - val_acc: 0.3583\n",
            "Epoch 32/150 - 0.03s - loss: 1.0954 - acc: 0.3666 - val_loss: 1.0993 - val_acc: 0.3563\n",
            "Epoch 33/150 - 0.03s - loss: 1.0953 - acc: 0.3662 - val_loss: 1.0992 - val_acc: 0.3583\n",
            "Epoch 34/150 - 0.03s - loss: 1.0952 - acc: 0.3662 - val_loss: 1.0991 - val_acc: 0.3583\n",
            "Epoch 35/150 - 0.03s - loss: 1.0951 - acc: 0.3659 - val_loss: 1.0991 - val_acc: 0.3623\n",
            "Epoch 36/150 - 0.03s - loss: 1.0950 - acc: 0.3671 - val_loss: 1.0990 - val_acc: 0.3644\n",
            "Epoch 37/150 - 0.03s - loss: 1.0949 - acc: 0.3666 - val_loss: 1.0989 - val_acc: 0.3563\n",
            "Epoch 38/150 - 0.03s - loss: 1.0948 - acc: 0.3677 - val_loss: 1.0988 - val_acc: 0.3563\n",
            "Epoch 39/150 - 0.03s - loss: 1.0948 - acc: 0.3680 - val_loss: 1.0987 - val_acc: 0.3563\n",
            "Epoch 40/150 - 0.03s - loss: 1.0947 - acc: 0.3689 - val_loss: 1.0987 - val_acc: 0.3563\n",
            "Epoch 41/150 - 0.03s - loss: 1.0946 - acc: 0.3686 - val_loss: 1.0986 - val_acc: 0.3563\n",
            "Epoch 42/150 - 0.03s - loss: 1.0945 - acc: 0.3695 - val_loss: 1.0985 - val_acc: 0.3563\n",
            "Epoch 43/150 - 0.03s - loss: 1.0944 - acc: 0.3698 - val_loss: 1.0985 - val_acc: 0.3563\n",
            "Epoch 44/150 - 0.03s - loss: 1.0943 - acc: 0.3704 - val_loss: 1.0984 - val_acc: 0.3522\n",
            "Epoch 45/150 - 0.03s - loss: 1.0942 - acc: 0.3711 - val_loss: 1.0983 - val_acc: 0.3543\n",
            "Epoch 46/150 - 0.03s - loss: 1.0941 - acc: 0.3709 - val_loss: 1.0982 - val_acc: 0.3543\n",
            "Epoch 47/150 - 0.03s - loss: 1.0940 - acc: 0.3711 - val_loss: 1.0982 - val_acc: 0.3543\n",
            "Epoch 48/150 - 0.03s - loss: 1.0940 - acc: 0.3713 - val_loss: 1.0981 - val_acc: 0.3563\n",
            "Epoch 49/150 - 0.03s - loss: 1.0939 - acc: 0.3711 - val_loss: 1.0980 - val_acc: 0.3522\n",
            "Epoch 50/150 - 0.03s - loss: 1.0938 - acc: 0.3709 - val_loss: 1.0980 - val_acc: 0.3543\n",
            "Epoch 51/150 - 0.03s - loss: 1.0937 - acc: 0.3716 - val_loss: 1.0979 - val_acc: 0.3543\n",
            "Epoch 52/150 - 0.03s - loss: 1.0936 - acc: 0.3718 - val_loss: 1.0978 - val_acc: 0.3543\n",
            "Epoch 53/150 - 0.03s - loss: 1.0935 - acc: 0.3725 - val_loss: 1.0978 - val_acc: 0.3522\n",
            "Epoch 54/150 - 0.03s - loss: 1.0934 - acc: 0.3731 - val_loss: 1.0977 - val_acc: 0.3522\n",
            "Epoch 55/150 - 0.03s - loss: 1.0934 - acc: 0.3727 - val_loss: 1.0976 - val_acc: 0.3502\n",
            "Epoch 56/150 - 0.03s - loss: 1.0933 - acc: 0.3727 - val_loss: 1.0976 - val_acc: 0.3502\n",
            "Epoch 57/150 - 0.03s - loss: 1.0932 - acc: 0.3734 - val_loss: 1.0975 - val_acc: 0.3502\n",
            "Epoch 58/150 - 0.03s - loss: 1.0931 - acc: 0.3736 - val_loss: 1.0974 - val_acc: 0.3502\n",
            "Epoch 59/150 - 0.03s - loss: 1.0930 - acc: 0.3736 - val_loss: 1.0974 - val_acc: 0.3502\n",
            "Epoch 60/150 - 0.03s - loss: 1.0929 - acc: 0.3740 - val_loss: 1.0973 - val_acc: 0.3482\n",
            "Epoch 61/150 - 0.03s - loss: 1.0929 - acc: 0.3747 - val_loss: 1.0972 - val_acc: 0.3502\n",
            "Epoch 62/150 - 0.03s - loss: 1.0928 - acc: 0.3752 - val_loss: 1.0972 - val_acc: 0.3502\n",
            "Epoch 63/150 - 0.03s - loss: 1.0927 - acc: 0.3754 - val_loss: 1.0971 - val_acc: 0.3502\n",
            "Epoch 64/150 - 0.03s - loss: 1.0926 - acc: 0.3756 - val_loss: 1.0971 - val_acc: 0.3502\n",
            "Epoch 65/150 - 0.03s - loss: 1.0925 - acc: 0.3761 - val_loss: 1.0970 - val_acc: 0.3522\n",
            "Epoch 66/150 - 0.03s - loss: 1.0924 - acc: 0.3763 - val_loss: 1.0969 - val_acc: 0.3543\n",
            "Epoch 67/150 - 0.03s - loss: 1.0924 - acc: 0.3770 - val_loss: 1.0969 - val_acc: 0.3543\n",
            "Epoch 68/150 - 0.03s - loss: 1.0923 - acc: 0.3765 - val_loss: 1.0968 - val_acc: 0.3563\n",
            "Epoch 69/150 - 0.03s - loss: 1.0922 - acc: 0.3770 - val_loss: 1.0967 - val_acc: 0.3563\n",
            "Epoch 70/150 - 0.03s - loss: 1.0921 - acc: 0.3776 - val_loss: 1.0967 - val_acc: 0.3603\n",
            "Epoch 71/150 - 0.03s - loss: 1.0920 - acc: 0.3774 - val_loss: 1.0966 - val_acc: 0.3623\n",
            "Epoch 72/150 - 0.03s - loss: 1.0920 - acc: 0.3792 - val_loss: 1.0966 - val_acc: 0.3623\n",
            "Epoch 73/150 - 0.03s - loss: 1.0919 - acc: 0.3790 - val_loss: 1.0965 - val_acc: 0.3623\n",
            "Epoch 74/150 - 0.03s - loss: 1.0918 - acc: 0.3794 - val_loss: 1.0964 - val_acc: 0.3623\n",
            "Epoch 75/150 - 0.03s - loss: 1.0917 - acc: 0.3801 - val_loss: 1.0964 - val_acc: 0.3623\n",
            "Epoch 76/150 - 0.03s - loss: 1.0916 - acc: 0.3810 - val_loss: 1.0963 - val_acc: 0.3644\n",
            "Epoch 77/150 - 0.03s - loss: 1.0916 - acc: 0.3815 - val_loss: 1.0962 - val_acc: 0.3644\n",
            "Epoch 78/150 - 0.03s - loss: 1.0915 - acc: 0.3815 - val_loss: 1.0962 - val_acc: 0.3664\n",
            "Epoch 79/150 - 0.03s - loss: 1.0914 - acc: 0.3815 - val_loss: 1.0961 - val_acc: 0.3664\n",
            "Epoch 80/150 - 0.03s - loss: 1.0913 - acc: 0.3817 - val_loss: 1.0960 - val_acc: 0.3664\n",
            "Epoch 81/150 - 0.03s - loss: 1.0912 - acc: 0.3815 - val_loss: 1.0960 - val_acc: 0.3664\n",
            "Epoch 82/150 - 0.03s - loss: 1.0912 - acc: 0.3817 - val_loss: 1.0959 - val_acc: 0.3644\n",
            "Epoch 83/150 - 0.03s - loss: 1.0911 - acc: 0.3815 - val_loss: 1.0958 - val_acc: 0.3644\n",
            "Epoch 84/150 - 0.03s - loss: 1.0910 - acc: 0.3819 - val_loss: 1.0958 - val_acc: 0.3644\n",
            "Epoch 85/150 - 0.03s - loss: 1.0909 - acc: 0.3819 - val_loss: 1.0957 - val_acc: 0.3644\n",
            "Epoch 86/150 - 0.03s - loss: 1.0908 - acc: 0.3824 - val_loss: 1.0956 - val_acc: 0.3644\n",
            "Epoch 87/150 - 0.03s - loss: 1.0908 - acc: 0.3830 - val_loss: 1.0956 - val_acc: 0.3644\n",
            "Epoch 88/150 - 0.03s - loss: 1.0907 - acc: 0.3835 - val_loss: 1.0955 - val_acc: 0.3644\n",
            "Epoch 89/150 - 0.03s - loss: 1.0906 - acc: 0.3837 - val_loss: 1.0955 - val_acc: 0.3664\n",
            "Epoch 90/150 - 0.03s - loss: 1.0905 - acc: 0.3837 - val_loss: 1.0954 - val_acc: 0.3664\n",
            "Epoch 91/150 - 0.03s - loss: 1.0905 - acc: 0.3833 - val_loss: 1.0953 - val_acc: 0.3644\n",
            "Epoch 92/150 - 0.03s - loss: 1.0904 - acc: 0.3833 - val_loss: 1.0953 - val_acc: 0.3644\n",
            "Epoch 93/150 - 0.03s - loss: 1.0903 - acc: 0.3833 - val_loss: 1.0952 - val_acc: 0.3644\n",
            "Epoch 94/150 - 0.03s - loss: 1.0902 - acc: 0.3826 - val_loss: 1.0952 - val_acc: 0.3644\n",
            "Epoch 95/150 - 0.03s - loss: 1.0901 - acc: 0.3828 - val_loss: 1.0951 - val_acc: 0.3644\n",
            "Epoch 96/150 - 0.03s - loss: 1.0901 - acc: 0.3830 - val_loss: 1.0950 - val_acc: 0.3684\n",
            "Epoch 97/150 - 0.03s - loss: 1.0900 - acc: 0.3826 - val_loss: 1.0950 - val_acc: 0.3684\n",
            "Epoch 98/150 - 0.03s - loss: 1.0899 - acc: 0.3824 - val_loss: 1.0949 - val_acc: 0.3704\n",
            "Epoch 99/150 - 0.03s - loss: 1.0898 - acc: 0.3826 - val_loss: 1.0948 - val_acc: 0.3704\n",
            "Epoch 100/150 - 0.03s - loss: 1.0898 - acc: 0.3828 - val_loss: 1.0948 - val_acc: 0.3704\n",
            "Epoch 101/150 - 0.03s - loss: 1.0897 - acc: 0.3839 - val_loss: 1.0947 - val_acc: 0.3704\n",
            "Epoch 102/150 - 0.03s - loss: 1.0896 - acc: 0.3842 - val_loss: 1.0947 - val_acc: 0.3704\n",
            "Epoch 103/150 - 0.03s - loss: 1.0895 - acc: 0.3842 - val_loss: 1.0946 - val_acc: 0.3704\n",
            "Epoch 104/150 - 0.03s - loss: 1.0895 - acc: 0.3839 - val_loss: 1.0946 - val_acc: 0.3704\n",
            "Epoch 105/150 - 0.03s - loss: 1.0894 - acc: 0.3844 - val_loss: 1.0945 - val_acc: 0.3704\n",
            "Epoch 106/150 - 0.03s - loss: 1.0893 - acc: 0.3844 - val_loss: 1.0944 - val_acc: 0.3704\n",
            "Epoch 107/150 - 0.04s - loss: 1.0892 - acc: 0.3848 - val_loss: 1.0944 - val_acc: 0.3704\n",
            "Epoch 108/150 - 0.04s - loss: 1.0892 - acc: 0.3855 - val_loss: 1.0943 - val_acc: 0.3704\n",
            "Epoch 109/150 - 0.03s - loss: 1.0891 - acc: 0.3857 - val_loss: 1.0943 - val_acc: 0.3704\n",
            "Epoch 110/150 - 0.04s - loss: 1.0890 - acc: 0.3857 - val_loss: 1.0942 - val_acc: 0.3704\n",
            "Epoch 111/150 - 0.04s - loss: 1.0889 - acc: 0.3862 - val_loss: 1.0942 - val_acc: 0.3704\n",
            "Epoch 112/150 - 0.04s - loss: 1.0889 - acc: 0.3862 - val_loss: 1.0941 - val_acc: 0.3704\n",
            "Epoch 113/150 - 0.03s - loss: 1.0888 - acc: 0.3862 - val_loss: 1.0940 - val_acc: 0.3725\n",
            "Epoch 114/150 - 0.03s - loss: 1.0887 - acc: 0.3864 - val_loss: 1.0940 - val_acc: 0.3745\n",
            "Epoch 115/150 - 0.04s - loss: 1.0886 - acc: 0.3864 - val_loss: 1.0939 - val_acc: 0.3745\n",
            "Epoch 116/150 - 0.03s - loss: 1.0886 - acc: 0.3873 - val_loss: 1.0939 - val_acc: 0.3745\n",
            "Epoch 117/150 - 0.03s - loss: 1.0885 - acc: 0.3875 - val_loss: 1.0938 - val_acc: 0.3745\n",
            "Epoch 118/150 - 0.04s - loss: 1.0884 - acc: 0.3875 - val_loss: 1.0938 - val_acc: 0.3745\n",
            "Epoch 119/150 - 0.03s - loss: 1.0883 - acc: 0.3880 - val_loss: 1.0937 - val_acc: 0.3745\n",
            "Epoch 120/150 - 0.04s - loss: 1.0883 - acc: 0.3884 - val_loss: 1.0937 - val_acc: 0.3745\n",
            "Epoch 121/150 - 0.03s - loss: 1.0882 - acc: 0.3898 - val_loss: 1.0936 - val_acc: 0.3745\n",
            "Epoch 122/150 - 0.04s - loss: 1.0881 - acc: 0.3900 - val_loss: 1.0936 - val_acc: 0.3745\n",
            "Epoch 123/150 - 0.04s - loss: 1.0881 - acc: 0.3887 - val_loss: 1.0935 - val_acc: 0.3745\n",
            "Epoch 124/150 - 0.04s - loss: 1.0880 - acc: 0.3898 - val_loss: 1.0934 - val_acc: 0.3765\n",
            "Epoch 125/150 - 0.03s - loss: 1.0879 - acc: 0.3905 - val_loss: 1.0934 - val_acc: 0.3765\n",
            "Epoch 126/150 - 0.04s - loss: 1.0878 - acc: 0.3911 - val_loss: 1.0933 - val_acc: 0.3785\n",
            "Epoch 127/150 - 0.04s - loss: 1.0878 - acc: 0.3911 - val_loss: 1.0933 - val_acc: 0.3806\n",
            "Epoch 128/150 - 0.03s - loss: 1.0877 - acc: 0.3907 - val_loss: 1.0932 - val_acc: 0.3826\n",
            "Epoch 129/150 - 0.03s - loss: 1.0876 - acc: 0.3909 - val_loss: 1.0932 - val_acc: 0.3826\n",
            "Epoch 130/150 - 0.03s - loss: 1.0875 - acc: 0.3911 - val_loss: 1.0931 - val_acc: 0.3826\n",
            "Epoch 131/150 - 0.03s - loss: 1.0875 - acc: 0.3916 - val_loss: 1.0931 - val_acc: 0.3826\n",
            "Epoch 132/150 - 0.03s - loss: 1.0874 - acc: 0.3914 - val_loss: 1.0930 - val_acc: 0.3846\n",
            "Epoch 133/150 - 0.03s - loss: 1.0873 - acc: 0.3914 - val_loss: 1.0930 - val_acc: 0.3846\n",
            "Epoch 134/150 - 0.03s - loss: 1.0873 - acc: 0.3916 - val_loss: 1.0929 - val_acc: 0.3846\n",
            "Epoch 135/150 - 0.03s - loss: 1.0872 - acc: 0.3916 - val_loss: 1.0928 - val_acc: 0.3846\n",
            "Epoch 136/150 - 0.03s - loss: 1.0871 - acc: 0.3916 - val_loss: 1.0928 - val_acc: 0.3846\n",
            "Epoch 137/150 - 0.03s - loss: 1.0870 - acc: 0.3923 - val_loss: 1.0927 - val_acc: 0.3846\n",
            "Epoch 138/150 - 0.03s - loss: 1.0870 - acc: 0.3920 - val_loss: 1.0927 - val_acc: 0.3846\n",
            "Epoch 139/150 - 0.03s - loss: 1.0869 - acc: 0.3929 - val_loss: 1.0926 - val_acc: 0.3846\n",
            "Epoch 140/150 - 0.03s - loss: 1.0868 - acc: 0.3932 - val_loss: 1.0926 - val_acc: 0.3846\n",
            "Epoch 141/150 - 0.03s - loss: 1.0868 - acc: 0.3934 - val_loss: 1.0925 - val_acc: 0.3887\n",
            "Epoch 142/150 - 0.04s - loss: 1.0867 - acc: 0.3934 - val_loss: 1.0925 - val_acc: 0.3907\n",
            "Epoch 143/150 - 0.04s - loss: 1.0866 - acc: 0.3934 - val_loss: 1.0924 - val_acc: 0.3887\n",
            "Epoch 144/150 - 0.04s - loss: 1.0865 - acc: 0.3938 - val_loss: 1.0924 - val_acc: 0.3887\n",
            "Epoch 145/150 - 0.03s - loss: 1.0865 - acc: 0.3934 - val_loss: 1.0923 - val_acc: 0.3887\n",
            "Epoch 146/150 - 0.04s - loss: 1.0864 - acc: 0.3936 - val_loss: 1.0922 - val_acc: 0.3887\n",
            "Epoch 147/150 - 0.03s - loss: 1.0863 - acc: 0.3934 - val_loss: 1.0922 - val_acc: 0.3907\n",
            "Epoch 148/150 - 0.03s - loss: 1.0863 - acc: 0.3932 - val_loss: 1.0921 - val_acc: 0.3927\n",
            "Epoch 149/150 - 0.03s - loss: 1.0862 - acc: 0.3941 - val_loss: 1.0921 - val_acc: 0.3927\n",
            "Epoch 150/150 - 0.03s - loss: 1.0861 - acc: 0.3941 - val_loss: 1.0920 - val_acc: 0.3927\n",
            "\n",
            "Combination 19/252:\n",
            "Hidden Layers: [64, 32], Activation: tanh, Learning Rate: 0.01, Batch Size: 32, Epochs: 50\n",
            "Epoch 1/50 - 0.06s - loss: 1.0883 - acc: 0.3801 - val_loss: 1.0960 - val_acc: 0.3866\n",
            "Epoch 2/50 - 0.06s - loss: 1.0756 - acc: 0.4325 - val_loss: 1.0850 - val_acc: 0.4049\n",
            "Epoch 3/50 - 0.06s - loss: 1.0657 - acc: 0.4525 - val_loss: 1.0778 - val_acc: 0.4190\n",
            "Epoch 4/50 - 0.06s - loss: 1.0574 - acc: 0.4640 - val_loss: 1.0716 - val_acc: 0.4332\n",
            "Epoch 5/50 - 0.06s - loss: 1.0536 - acc: 0.4485 - val_loss: 1.0683 - val_acc: 0.4291\n",
            "Epoch 6/50 - 0.06s - loss: 1.0423 - acc: 0.4831 - val_loss: 1.0598 - val_acc: 0.4534\n",
            "Epoch 7/50 - 0.06s - loss: 1.0363 - acc: 0.4811 - val_loss: 1.0568 - val_acc: 0.4798\n",
            "Epoch 8/50 - 0.06s - loss: 1.0301 - acc: 0.4910 - val_loss: 1.0518 - val_acc: 0.4777\n",
            "Epoch 9/50 - 0.06s - loss: 1.0229 - acc: 0.4973 - val_loss: 1.0458 - val_acc: 0.5000\n",
            "Epoch 10/50 - 0.06s - loss: 1.0180 - acc: 0.5027 - val_loss: 1.0427 - val_acc: 0.4818\n",
            "Epoch 11/50 - 0.06s - loss: 1.0121 - acc: 0.5027 - val_loss: 1.0388 - val_acc: 0.4858\n",
            "Epoch 12/50 - 0.06s - loss: 1.0069 - acc: 0.5079 - val_loss: 1.0331 - val_acc: 0.4899\n",
            "Epoch 13/50 - 0.06s - loss: 1.0043 - acc: 0.4991 - val_loss: 1.0321 - val_acc: 0.5182\n",
            "Epoch 14/50 - 0.06s - loss: 0.9978 - acc: 0.5117 - val_loss: 1.0266 - val_acc: 0.4960\n",
            "Epoch 15/50 - 0.06s - loss: 0.9911 - acc: 0.5164 - val_loss: 1.0196 - val_acc: 0.5101\n",
            "Epoch 16/50 - 0.06s - loss: 0.9851 - acc: 0.5241 - val_loss: 1.0155 - val_acc: 0.5162\n",
            "Epoch 17/50 - 0.06s - loss: 0.9809 - acc: 0.5297 - val_loss: 1.0109 - val_acc: 0.5283\n",
            "Epoch 18/50 - 0.06s - loss: 0.9776 - acc: 0.5295 - val_loss: 1.0083 - val_acc: 0.5304\n",
            "Epoch 19/50 - 0.06s - loss: 0.9723 - acc: 0.5344 - val_loss: 1.0046 - val_acc: 0.5385\n",
            "Epoch 20/50 - 0.06s - loss: 0.9679 - acc: 0.5396 - val_loss: 0.9994 - val_acc: 0.5324\n",
            "Epoch 21/50 - 0.06s - loss: 0.9661 - acc: 0.5362 - val_loss: 1.0006 - val_acc: 0.5364\n",
            "Epoch 22/50 - 0.06s - loss: 0.9656 - acc: 0.5331 - val_loss: 0.9966 - val_acc: 0.5182\n",
            "Epoch 23/50 - 0.06s - loss: 0.9615 - acc: 0.5403 - val_loss: 0.9945 - val_acc: 0.5466\n",
            "Epoch 24/50 - 0.06s - loss: 0.9598 - acc: 0.5351 - val_loss: 0.9921 - val_acc: 0.5324\n",
            "Epoch 25/50 - 0.06s - loss: 0.9499 - acc: 0.5486 - val_loss: 0.9841 - val_acc: 0.5425\n",
            "Epoch 26/50 - 0.06s - loss: 0.9577 - acc: 0.5340 - val_loss: 0.9950 - val_acc: 0.5182\n",
            "Epoch 27/50 - 0.06s - loss: 0.9446 - acc: 0.5506 - val_loss: 0.9796 - val_acc: 0.5445\n",
            "Epoch 28/50 - 0.06s - loss: 0.9432 - acc: 0.5522 - val_loss: 0.9815 - val_acc: 0.5405\n",
            "Epoch 29/50 - 0.06s - loss: 0.9378 - acc: 0.5569 - val_loss: 0.9750 - val_acc: 0.5486\n",
            "Epoch 30/50 - 0.06s - loss: 0.9351 - acc: 0.5605 - val_loss: 0.9746 - val_acc: 0.5445\n",
            "Epoch 31/50 - 0.06s - loss: 0.9318 - acc: 0.5625 - val_loss: 0.9714 - val_acc: 0.5506\n",
            "Epoch 32/50 - 0.06s - loss: 0.9399 - acc: 0.5535 - val_loss: 0.9815 - val_acc: 0.5466\n",
            "Epoch 33/50 - 0.06s - loss: 0.9278 - acc: 0.5650 - val_loss: 0.9687 - val_acc: 0.5567\n",
            "Epoch 34/50 - 0.06s - loss: 0.9311 - acc: 0.5628 - val_loss: 0.9709 - val_acc: 0.5547\n",
            "Epoch 35/50 - 0.06s - loss: 0.9213 - acc: 0.5686 - val_loss: 0.9651 - val_acc: 0.5526\n",
            "Epoch 36/50 - 0.06s - loss: 0.9222 - acc: 0.5643 - val_loss: 0.9660 - val_acc: 0.5526\n",
            "Epoch 37/50 - 0.06s - loss: 0.9199 - acc: 0.5682 - val_loss: 0.9614 - val_acc: 0.5567\n",
            "Epoch 38/50 - 0.06s - loss: 0.9169 - acc: 0.5722 - val_loss: 0.9636 - val_acc: 0.5466\n",
            "Epoch 39/50 - 0.06s - loss: 0.9167 - acc: 0.5670 - val_loss: 0.9608 - val_acc: 0.5486\n",
            "Epoch 40/50 - 0.06s - loss: 0.9126 - acc: 0.5742 - val_loss: 0.9623 - val_acc: 0.5385\n",
            "Epoch 41/50 - 0.06s - loss: 0.9104 - acc: 0.5767 - val_loss: 0.9599 - val_acc: 0.5506\n",
            "Epoch 42/50 - 0.06s - loss: 0.9092 - acc: 0.5744 - val_loss: 0.9599 - val_acc: 0.5364\n",
            "Epoch 43/50 - 0.06s - loss: 0.9124 - acc: 0.5670 - val_loss: 0.9600 - val_acc: 0.5445\n",
            "Epoch 44/50 - 0.05s - loss: 0.9061 - acc: 0.5787 - val_loss: 0.9545 - val_acc: 0.5567\n",
            "Epoch 45/50 - 0.06s - loss: 0.9012 - acc: 0.5841 - val_loss: 0.9527 - val_acc: 0.5486\n",
            "Epoch 46/50 - 0.06s - loss: 0.9063 - acc: 0.5828 - val_loss: 0.9582 - val_acc: 0.5709\n",
            "Epoch 47/50 - 0.06s - loss: 0.9022 - acc: 0.5769 - val_loss: 0.9538 - val_acc: 0.5547\n",
            "Epoch 48/50 - 0.06s - loss: 0.8964 - acc: 0.5877 - val_loss: 0.9487 - val_acc: 0.5688\n",
            "Epoch 49/50 - 0.06s - loss: 0.8961 - acc: 0.5846 - val_loss: 0.9495 - val_acc: 0.5648\n",
            "Epoch 50/50 - 0.06s - loss: 0.9042 - acc: 0.5733 - val_loss: 0.9635 - val_acc: 0.5364\n",
            "\n",
            "Combination 20/252:\n",
            "Hidden Layers: [64, 32], Activation: tanh, Learning Rate: 0.01, Batch Size: 32, Epochs: 100\n",
            "Epoch 1/100 - 0.05s - loss: 1.0921 - acc: 0.3713 - val_loss: 1.0965 - val_acc: 0.3664\n",
            "Epoch 2/100 - 0.06s - loss: 1.0768 - acc: 0.4010 - val_loss: 1.0850 - val_acc: 0.3947\n",
            "Epoch 3/100 - 0.06s - loss: 1.0680 - acc: 0.4498 - val_loss: 1.0757 - val_acc: 0.4251\n",
            "Epoch 4/100 - 0.06s - loss: 1.0564 - acc: 0.4593 - val_loss: 1.0678 - val_acc: 0.4494\n",
            "Epoch 5/100 - 0.06s - loss: 1.0483 - acc: 0.4642 - val_loss: 1.0623 - val_acc: 0.4413\n",
            "Epoch 6/100 - 0.06s - loss: 1.0402 - acc: 0.4753 - val_loss: 1.0575 - val_acc: 0.4656\n",
            "Epoch 7/100 - 0.06s - loss: 1.0329 - acc: 0.4840 - val_loss: 1.0511 - val_acc: 0.4636\n",
            "Epoch 8/100 - 0.05s - loss: 1.0282 - acc: 0.4798 - val_loss: 1.0492 - val_acc: 0.4696\n",
            "Epoch 9/100 - 0.06s - loss: 1.0166 - acc: 0.5022 - val_loss: 1.0379 - val_acc: 0.5020\n",
            "Epoch 10/100 - 0.06s - loss: 1.0094 - acc: 0.5038 - val_loss: 1.0327 - val_acc: 0.5020\n",
            "Epoch 11/100 - 0.06s - loss: 1.0060 - acc: 0.5058 - val_loss: 1.0305 - val_acc: 0.5040\n",
            "Epoch 12/100 - 0.06s - loss: 1.0066 - acc: 0.4933 - val_loss: 1.0323 - val_acc: 0.4737\n",
            "Epoch 13/100 - 0.06s - loss: 0.9901 - acc: 0.5227 - val_loss: 1.0160 - val_acc: 0.5121\n",
            "Epoch 14/100 - 0.06s - loss: 0.9914 - acc: 0.5144 - val_loss: 1.0179 - val_acc: 0.4858\n",
            "Epoch 15/100 - 0.06s - loss: 0.9802 - acc: 0.5319 - val_loss: 1.0070 - val_acc: 0.5101\n",
            "Epoch 16/100 - 0.06s - loss: 0.9740 - acc: 0.5367 - val_loss: 1.0016 - val_acc: 0.5243\n",
            "Epoch 17/100 - 0.06s - loss: 0.9705 - acc: 0.5394 - val_loss: 0.9985 - val_acc: 0.5385\n",
            "Epoch 18/100 - 0.06s - loss: 0.9667 - acc: 0.5380 - val_loss: 0.9963 - val_acc: 0.5162\n",
            "Epoch 19/100 - 0.06s - loss: 0.9610 - acc: 0.5430 - val_loss: 0.9901 - val_acc: 0.5405\n",
            "Epoch 20/100 - 0.06s - loss: 0.9600 - acc: 0.5405 - val_loss: 0.9883 - val_acc: 0.5243\n",
            "Epoch 21/100 - 0.06s - loss: 0.9582 - acc: 0.5436 - val_loss: 0.9895 - val_acc: 0.5466\n",
            "Epoch 22/100 - 0.06s - loss: 0.9543 - acc: 0.5434 - val_loss: 0.9878 - val_acc: 0.5162\n",
            "Epoch 23/100 - 0.06s - loss: 0.9508 - acc: 0.5486 - val_loss: 0.9846 - val_acc: 0.5101\n",
            "Epoch 24/100 - 0.06s - loss: 0.9442 - acc: 0.5567 - val_loss: 0.9778 - val_acc: 0.5243\n",
            "Epoch 25/100 - 0.06s - loss: 0.9418 - acc: 0.5504 - val_loss: 0.9775 - val_acc: 0.5162\n",
            "Epoch 26/100 - 0.06s - loss: 0.9387 - acc: 0.5547 - val_loss: 0.9736 - val_acc: 0.5263\n",
            "Epoch 27/100 - 0.06s - loss: 0.9398 - acc: 0.5549 - val_loss: 0.9773 - val_acc: 0.5202\n",
            "Epoch 28/100 - 0.06s - loss: 0.9313 - acc: 0.5612 - val_loss: 0.9685 - val_acc: 0.5486\n",
            "Epoch 29/100 - 0.06s - loss: 0.9286 - acc: 0.5589 - val_loss: 0.9674 - val_acc: 0.5304\n",
            "Epoch 30/100 - 0.06s - loss: 0.9330 - acc: 0.5580 - val_loss: 0.9749 - val_acc: 0.5121\n",
            "Epoch 31/100 - 0.06s - loss: 0.9348 - acc: 0.5630 - val_loss: 0.9735 - val_acc: 0.5607\n",
            "Epoch 32/100 - 0.05s - loss: 0.9236 - acc: 0.5639 - val_loss: 0.9657 - val_acc: 0.5385\n",
            "Epoch 33/100 - 0.06s - loss: 0.9188 - acc: 0.5661 - val_loss: 0.9611 - val_acc: 0.5344\n",
            "Epoch 34/100 - 0.06s - loss: 0.9176 - acc: 0.5659 - val_loss: 0.9615 - val_acc: 0.5425\n",
            "Epoch 35/100 - 0.06s - loss: 0.9154 - acc: 0.5704 - val_loss: 0.9600 - val_acc: 0.5324\n",
            "Epoch 36/100 - 0.06s - loss: 0.9157 - acc: 0.5686 - val_loss: 0.9613 - val_acc: 0.5567\n",
            "Epoch 37/100 - 0.06s - loss: 0.9235 - acc: 0.5578 - val_loss: 0.9733 - val_acc: 0.5061\n",
            "Epoch 38/100 - 0.06s - loss: 0.9151 - acc: 0.5771 - val_loss: 0.9641 - val_acc: 0.5486\n",
            "Epoch 39/100 - 0.06s - loss: 0.9069 - acc: 0.5749 - val_loss: 0.9548 - val_acc: 0.5405\n",
            "Epoch 40/100 - 0.06s - loss: 0.9076 - acc: 0.5778 - val_loss: 0.9559 - val_acc: 0.5587\n",
            "Epoch 41/100 - 0.06s - loss: 0.9110 - acc: 0.5704 - val_loss: 0.9638 - val_acc: 0.5263\n",
            "Epoch 42/100 - 0.06s - loss: 0.9100 - acc: 0.5693 - val_loss: 0.9662 - val_acc: 0.5223\n",
            "Epoch 43/100 - 0.06s - loss: 0.9000 - acc: 0.5769 - val_loss: 0.9565 - val_acc: 0.5283\n",
            "Epoch 44/100 - 0.06s - loss: 0.9017 - acc: 0.5805 - val_loss: 0.9592 - val_acc: 0.5506\n",
            "Epoch 45/100 - 0.06s - loss: 0.8959 - acc: 0.5868 - val_loss: 0.9516 - val_acc: 0.5526\n",
            "Epoch 46/100 - 0.06s - loss: 0.8990 - acc: 0.5812 - val_loss: 0.9540 - val_acc: 0.5526\n",
            "Epoch 47/100 - 0.06s - loss: 0.8924 - acc: 0.5855 - val_loss: 0.9517 - val_acc: 0.5425\n",
            "Epoch 48/100 - 0.06s - loss: 0.8916 - acc: 0.5882 - val_loss: 0.9514 - val_acc: 0.5648\n",
            "Epoch 49/100 - 0.06s - loss: 0.9377 - acc: 0.5448 - val_loss: 1.0021 - val_acc: 0.4939\n",
            "Epoch 50/100 - 0.06s - loss: 0.8918 - acc: 0.5837 - val_loss: 0.9575 - val_acc: 0.5304\n",
            "Epoch 51/100 - 0.06s - loss: 0.9032 - acc: 0.5717 - val_loss: 0.9731 - val_acc: 0.5000\n",
            "Epoch 52/100 - 0.06s - loss: 0.8901 - acc: 0.5834 - val_loss: 0.9618 - val_acc: 0.5142\n",
            "Epoch 53/100 - 0.06s - loss: 0.8919 - acc: 0.5816 - val_loss: 0.9596 - val_acc: 0.5445\n",
            "Epoch 54/100 - 0.06s - loss: 0.9224 - acc: 0.5551 - val_loss: 0.9981 - val_acc: 0.4960\n",
            "Epoch 55/100 - 0.06s - loss: 0.9073 - acc: 0.5753 - val_loss: 0.9710 - val_acc: 0.5587\n",
            "Epoch 56/100 - 0.06s - loss: 0.8832 - acc: 0.5875 - val_loss: 0.9542 - val_acc: 0.5486\n",
            "Epoch 57/100 - 0.06s - loss: 0.8821 - acc: 0.5886 - val_loss: 0.9594 - val_acc: 0.5223\n",
            "Epoch 58/100 - 0.06s - loss: 0.8906 - acc: 0.5879 - val_loss: 0.9627 - val_acc: 0.5607\n",
            "Epoch 59/100 - 0.06s - loss: 0.8773 - acc: 0.5985 - val_loss: 0.9536 - val_acc: 0.5648\n",
            "Epoch 60/100 - 0.06s - loss: 0.8917 - acc: 0.5798 - val_loss: 0.9751 - val_acc: 0.4838\n",
            "Epoch 61/100 - 0.06s - loss: 0.8976 - acc: 0.5726 - val_loss: 0.9706 - val_acc: 0.5486\n",
            "Epoch 62/100 - 0.06s - loss: 0.8742 - acc: 0.5940 - val_loss: 0.9585 - val_acc: 0.5385\n",
            "Epoch 63/100 - 0.06s - loss: 0.8936 - acc: 0.5756 - val_loss: 0.9784 - val_acc: 0.5081\n",
            "Epoch 64/100 - 0.06s - loss: 0.8692 - acc: 0.5965 - val_loss: 0.9524 - val_acc: 0.5506\n",
            "Epoch 65/100 - 0.06s - loss: 0.8697 - acc: 0.5990 - val_loss: 0.9551 - val_acc: 0.5385\n",
            "Epoch 66/100 - 0.06s - loss: 0.8663 - acc: 0.6008 - val_loss: 0.9529 - val_acc: 0.5587\n",
            "Epoch 67/100 - 0.06s - loss: 0.8718 - acc: 0.5990 - val_loss: 0.9588 - val_acc: 0.5466\n",
            "Epoch 68/100 - 0.06s - loss: 0.8694 - acc: 0.5965 - val_loss: 0.9595 - val_acc: 0.5385\n",
            "Epoch 69/100 - 0.06s - loss: 0.8640 - acc: 0.6057 - val_loss: 0.9554 - val_acc: 0.5466\n",
            "Epoch 70/100 - 0.06s - loss: 0.8873 - acc: 0.5812 - val_loss: 0.9802 - val_acc: 0.5162\n",
            "Epoch 71/100 - 0.06s - loss: 0.8648 - acc: 0.6023 - val_loss: 0.9613 - val_acc: 0.5385\n",
            "Epoch 72/100 - 0.06s - loss: 0.8604 - acc: 0.6071 - val_loss: 0.9561 - val_acc: 0.5445\n",
            "Epoch 73/100 - 0.06s - loss: 0.8663 - acc: 0.6113 - val_loss: 0.9597 - val_acc: 0.5587\n",
            "Epoch 74/100 - 0.06s - loss: 0.8618 - acc: 0.6039 - val_loss: 0.9558 - val_acc: 0.5567\n",
            "Epoch 75/100 - 0.06s - loss: 0.8629 - acc: 0.6075 - val_loss: 0.9614 - val_acc: 0.5364\n",
            "Epoch 76/100 - 0.06s - loss: 0.8610 - acc: 0.6014 - val_loss: 0.9658 - val_acc: 0.5223\n",
            "Epoch 77/100 - 0.06s - loss: 0.8792 - acc: 0.5965 - val_loss: 0.9734 - val_acc: 0.5607\n",
            "Epoch 78/100 - 0.06s - loss: 0.8789 - acc: 0.5848 - val_loss: 0.9759 - val_acc: 0.5202\n",
            "Epoch 79/100 - 0.06s - loss: 0.8615 - acc: 0.6102 - val_loss: 0.9626 - val_acc: 0.5526\n",
            "Epoch 80/100 - 0.06s - loss: 0.8792 - acc: 0.5830 - val_loss: 0.9785 - val_acc: 0.5243\n",
            "Epoch 81/100 - 0.05s - loss: 0.8745 - acc: 0.5938 - val_loss: 0.9856 - val_acc: 0.5324\n",
            "Epoch 82/100 - 0.06s - loss: 0.8563 - acc: 0.6064 - val_loss: 0.9599 - val_acc: 0.5547\n",
            "Epoch 83/100 - 0.06s - loss: 0.8533 - acc: 0.6109 - val_loss: 0.9592 - val_acc: 0.5607\n",
            "Epoch 84/100 - 0.05s - loss: 0.8521 - acc: 0.6068 - val_loss: 0.9627 - val_acc: 0.5425\n",
            "Epoch 85/100 - 0.06s - loss: 0.8521 - acc: 0.6109 - val_loss: 0.9614 - val_acc: 0.5526\n",
            "Epoch 86/100 - 0.06s - loss: 0.8621 - acc: 0.5958 - val_loss: 0.9670 - val_acc: 0.5344\n",
            "Epoch 87/100 - 0.06s - loss: 0.8623 - acc: 0.6089 - val_loss: 0.9698 - val_acc: 0.5486\n",
            "Epoch 88/100 - 0.06s - loss: 0.8489 - acc: 0.6095 - val_loss: 0.9620 - val_acc: 0.5607\n",
            "Epoch 89/100 - 0.06s - loss: 0.8481 - acc: 0.6147 - val_loss: 0.9598 - val_acc: 0.5466\n",
            "Epoch 90/100 - 0.06s - loss: 0.8711 - acc: 0.6080 - val_loss: 0.9831 - val_acc: 0.5466\n",
            "Epoch 91/100 - 0.06s - loss: 0.8515 - acc: 0.6073 - val_loss: 0.9643 - val_acc: 0.5506\n",
            "Epoch 92/100 - 0.06s - loss: 0.8539 - acc: 0.6071 - val_loss: 0.9628 - val_acc: 0.5567\n",
            "Epoch 93/100 - 0.06s - loss: 0.8462 - acc: 0.6149 - val_loss: 0.9591 - val_acc: 0.5526\n",
            "Epoch 94/100 - 0.06s - loss: 0.8466 - acc: 0.6102 - val_loss: 0.9662 - val_acc: 0.5587\n",
            "Epoch 95/100 - 0.06s - loss: 0.8453 - acc: 0.6143 - val_loss: 0.9661 - val_acc: 0.5405\n",
            "Epoch 96/100 - 0.06s - loss: 0.8987 - acc: 0.5922 - val_loss: 1.0068 - val_acc: 0.5445\n",
            "Epoch 97/100 - 0.06s - loss: 0.8433 - acc: 0.6122 - val_loss: 0.9620 - val_acc: 0.5486\n",
            "Epoch 98/100 - 0.06s - loss: 0.9602 - acc: 0.5376 - val_loss: 1.0586 - val_acc: 0.5101\n",
            "Epoch 99/100 - 0.06s - loss: 0.8624 - acc: 0.6073 - val_loss: 0.9741 - val_acc: 0.5607\n",
            "Epoch 100/100 - 0.06s - loss: 0.8410 - acc: 0.6181 - val_loss: 0.9637 - val_acc: 0.5567\n",
            "\n",
            "Combination 21/252:\n",
            "Hidden Layers: [64, 32], Activation: tanh, Learning Rate: 0.01, Batch Size: 32, Epochs: 150\n",
            "Epoch 1/150 - 0.06s - loss: 1.0883 - acc: 0.3855 - val_loss: 1.0930 - val_acc: 0.3644\n",
            "Epoch 2/150 - 0.06s - loss: 1.0766 - acc: 0.4283 - val_loss: 1.0833 - val_acc: 0.4130\n",
            "Epoch 3/150 - 0.06s - loss: 1.0669 - acc: 0.4442 - val_loss: 1.0763 - val_acc: 0.4474\n",
            "Epoch 4/150 - 0.05s - loss: 1.0595 - acc: 0.4483 - val_loss: 1.0708 - val_acc: 0.4595\n",
            "Epoch 5/150 - 0.06s - loss: 1.0528 - acc: 0.4663 - val_loss: 1.0677 - val_acc: 0.4555\n",
            "Epoch 6/150 - 0.06s - loss: 1.0464 - acc: 0.4685 - val_loss: 1.0629 - val_acc: 0.4696\n",
            "Epoch 7/150 - 0.06s - loss: 1.0411 - acc: 0.4694 - val_loss: 1.0596 - val_acc: 0.4696\n",
            "Epoch 8/150 - 0.06s - loss: 1.0356 - acc: 0.4843 - val_loss: 1.0551 - val_acc: 0.4818\n",
            "Epoch 9/150 - 0.06s - loss: 1.0300 - acc: 0.4872 - val_loss: 1.0527 - val_acc: 0.4818\n",
            "Epoch 10/150 - 0.06s - loss: 1.0250 - acc: 0.4984 - val_loss: 1.0496 - val_acc: 0.5000\n",
            "Epoch 11/150 - 0.06s - loss: 1.0198 - acc: 0.5007 - val_loss: 1.0458 - val_acc: 0.4980\n",
            "Epoch 12/150 - 0.06s - loss: 1.0145 - acc: 0.5004 - val_loss: 1.0427 - val_acc: 0.5000\n",
            "Epoch 13/150 - 0.05s - loss: 1.0103 - acc: 0.5025 - val_loss: 1.0398 - val_acc: 0.5000\n",
            "Epoch 14/150 - 0.06s - loss: 1.0062 - acc: 0.5063 - val_loss: 1.0350 - val_acc: 0.5061\n",
            "Epoch 15/150 - 0.06s - loss: 1.0038 - acc: 0.5079 - val_loss: 1.0336 - val_acc: 0.5081\n",
            "Epoch 16/150 - 0.05s - loss: 0.9953 - acc: 0.5209 - val_loss: 1.0288 - val_acc: 0.5121\n",
            "Epoch 17/150 - 0.06s - loss: 0.9894 - acc: 0.5241 - val_loss: 1.0243 - val_acc: 0.5263\n",
            "Epoch 18/150 - 0.05s - loss: 0.9851 - acc: 0.5270 - val_loss: 1.0193 - val_acc: 0.5202\n",
            "Epoch 19/150 - 0.06s - loss: 0.9801 - acc: 0.5286 - val_loss: 1.0158 - val_acc: 0.5162\n",
            "Epoch 20/150 - 0.06s - loss: 0.9779 - acc: 0.5256 - val_loss: 1.0146 - val_acc: 0.5040\n",
            "Epoch 21/150 - 0.06s - loss: 0.9750 - acc: 0.5319 - val_loss: 1.0112 - val_acc: 0.5405\n",
            "Epoch 22/150 - 0.06s - loss: 0.9675 - acc: 0.5421 - val_loss: 1.0053 - val_acc: 0.5506\n",
            "Epoch 23/150 - 0.06s - loss: 0.9644 - acc: 0.5394 - val_loss: 1.0016 - val_acc: 0.5263\n",
            "Epoch 24/150 - 0.06s - loss: 0.9622 - acc: 0.5427 - val_loss: 1.0010 - val_acc: 0.5567\n",
            "Epoch 25/150 - 0.05s - loss: 0.9577 - acc: 0.5475 - val_loss: 0.9972 - val_acc: 0.5628\n",
            "Epoch 26/150 - 0.06s - loss: 0.9511 - acc: 0.5515 - val_loss: 0.9925 - val_acc: 0.5547\n",
            "Epoch 27/150 - 0.06s - loss: 0.9542 - acc: 0.5452 - val_loss: 0.9987 - val_acc: 0.5223\n",
            "Epoch 28/150 - 0.05s - loss: 0.9470 - acc: 0.5544 - val_loss: 0.9897 - val_acc: 0.5567\n",
            "Epoch 29/150 - 0.05s - loss: 0.9408 - acc: 0.5553 - val_loss: 0.9849 - val_acc: 0.5445\n",
            "Epoch 30/150 - 0.06s - loss: 0.9402 - acc: 0.5522 - val_loss: 0.9863 - val_acc: 0.5364\n",
            "Epoch 31/150 - 0.06s - loss: 0.9429 - acc: 0.5583 - val_loss: 0.9924 - val_acc: 0.5020\n",
            "Epoch 32/150 - 0.06s - loss: 0.9318 - acc: 0.5585 - val_loss: 0.9812 - val_acc: 0.5405\n",
            "Epoch 33/150 - 0.06s - loss: 0.9288 - acc: 0.5650 - val_loss: 0.9769 - val_acc: 0.5587\n",
            "Epoch 34/150 - 0.06s - loss: 0.9254 - acc: 0.5659 - val_loss: 0.9747 - val_acc: 0.5526\n",
            "Epoch 35/150 - 0.06s - loss: 0.9343 - acc: 0.5682 - val_loss: 0.9827 - val_acc: 0.5587\n",
            "Epoch 36/150 - 0.06s - loss: 0.9255 - acc: 0.5738 - val_loss: 0.9768 - val_acc: 0.5567\n",
            "Epoch 37/150 - 0.05s - loss: 0.9266 - acc: 0.5693 - val_loss: 0.9763 - val_acc: 0.5506\n",
            "Epoch 38/150 - 0.06s - loss: 0.9206 - acc: 0.5700 - val_loss: 0.9783 - val_acc: 0.5283\n",
            "Epoch 39/150 - 0.06s - loss: 0.9146 - acc: 0.5704 - val_loss: 0.9699 - val_acc: 0.5466\n",
            "Epoch 40/150 - 0.06s - loss: 0.9146 - acc: 0.5711 - val_loss: 0.9685 - val_acc: 0.5445\n",
            "Epoch 41/150 - 0.06s - loss: 0.9137 - acc: 0.5735 - val_loss: 0.9738 - val_acc: 0.5283\n",
            "Epoch 42/150 - 0.06s - loss: 0.9098 - acc: 0.5749 - val_loss: 0.9649 - val_acc: 0.5425\n",
            "Epoch 43/150 - 0.06s - loss: 0.9058 - acc: 0.5740 - val_loss: 0.9642 - val_acc: 0.5445\n",
            "Epoch 44/150 - 0.05s - loss: 0.9014 - acc: 0.5801 - val_loss: 0.9611 - val_acc: 0.5506\n",
            "Epoch 45/150 - 0.06s - loss: 0.8993 - acc: 0.5837 - val_loss: 0.9619 - val_acc: 0.5445\n",
            "Epoch 46/150 - 0.06s - loss: 0.9028 - acc: 0.5726 - val_loss: 0.9673 - val_acc: 0.5324\n",
            "Epoch 47/150 - 0.06s - loss: 0.8984 - acc: 0.5913 - val_loss: 0.9652 - val_acc: 0.5567\n",
            "Epoch 48/150 - 0.06s - loss: 0.9052 - acc: 0.5823 - val_loss: 0.9743 - val_acc: 0.5344\n",
            "Epoch 49/150 - 0.06s - loss: 0.8916 - acc: 0.5852 - val_loss: 0.9594 - val_acc: 0.5364\n",
            "Epoch 50/150 - 0.06s - loss: 0.8968 - acc: 0.5738 - val_loss: 0.9625 - val_acc: 0.5385\n",
            "Epoch 51/150 - 0.07s - loss: 0.8908 - acc: 0.5906 - val_loss: 0.9642 - val_acc: 0.5344\n",
            "Epoch 52/150 - 0.06s - loss: 0.8905 - acc: 0.5805 - val_loss: 0.9617 - val_acc: 0.5425\n",
            "Epoch 53/150 - 0.06s - loss: 0.9036 - acc: 0.5765 - val_loss: 0.9826 - val_acc: 0.5061\n",
            "Epoch 54/150 - 0.06s - loss: 0.8849 - acc: 0.5873 - val_loss: 0.9574 - val_acc: 0.5445\n",
            "Epoch 55/150 - 0.06s - loss: 0.8836 - acc: 0.5915 - val_loss: 0.9610 - val_acc: 0.5283\n",
            "Epoch 56/150 - 0.06s - loss: 0.8815 - acc: 0.5882 - val_loss: 0.9567 - val_acc: 0.5425\n",
            "Epoch 57/150 - 0.05s - loss: 0.8820 - acc: 0.5992 - val_loss: 0.9614 - val_acc: 0.5445\n",
            "Epoch 58/150 - 0.06s - loss: 0.8847 - acc: 0.5828 - val_loss: 0.9606 - val_acc: 0.5445\n",
            "Epoch 59/150 - 0.06s - loss: 0.8849 - acc: 0.5830 - val_loss: 0.9690 - val_acc: 0.5243\n",
            "Epoch 60/150 - 0.06s - loss: 0.8749 - acc: 0.5954 - val_loss: 0.9590 - val_acc: 0.5466\n",
            "Epoch 61/150 - 0.06s - loss: 0.8787 - acc: 0.5985 - val_loss: 0.9599 - val_acc: 0.5445\n",
            "Epoch 62/150 - 0.06s - loss: 0.8780 - acc: 0.5983 - val_loss: 0.9685 - val_acc: 0.5202\n",
            "Epoch 63/150 - 0.06s - loss: 0.8874 - acc: 0.5978 - val_loss: 0.9731 - val_acc: 0.5506\n",
            "Epoch 64/150 - 0.06s - loss: 0.9075 - acc: 0.5695 - val_loss: 0.9846 - val_acc: 0.5445\n",
            "Epoch 65/150 - 0.06s - loss: 0.8689 - acc: 0.5983 - val_loss: 0.9572 - val_acc: 0.5526\n",
            "Epoch 66/150 - 0.06s - loss: 0.8783 - acc: 0.5870 - val_loss: 0.9612 - val_acc: 0.5466\n",
            "Epoch 67/150 - 0.06s - loss: 0.8732 - acc: 0.6014 - val_loss: 0.9608 - val_acc: 0.5466\n",
            "Epoch 68/150 - 0.06s - loss: 0.8669 - acc: 0.6012 - val_loss: 0.9578 - val_acc: 0.5445\n",
            "Epoch 69/150 - 0.06s - loss: 0.8664 - acc: 0.6023 - val_loss: 0.9636 - val_acc: 0.5182\n",
            "Epoch 70/150 - 0.06s - loss: 0.8773 - acc: 0.5969 - val_loss: 0.9794 - val_acc: 0.5182\n",
            "Epoch 71/150 - 0.06s - loss: 0.8660 - acc: 0.6035 - val_loss: 0.9617 - val_acc: 0.5567\n",
            "Epoch 72/150 - 0.06s - loss: 0.8880 - acc: 0.5976 - val_loss: 0.9836 - val_acc: 0.5445\n",
            "Epoch 73/150 - 0.06s - loss: 0.8667 - acc: 0.5956 - val_loss: 0.9697 - val_acc: 0.5162\n",
            "Epoch 74/150 - 0.06s - loss: 0.8942 - acc: 0.5801 - val_loss: 1.0051 - val_acc: 0.5081\n",
            "Epoch 75/150 - 0.06s - loss: 0.8585 - acc: 0.6035 - val_loss: 0.9623 - val_acc: 0.5304\n",
            "Epoch 76/150 - 0.06s - loss: 0.8692 - acc: 0.6030 - val_loss: 0.9791 - val_acc: 0.5182\n",
            "Epoch 77/150 - 0.06s - loss: 0.8592 - acc: 0.6012 - val_loss: 0.9633 - val_acc: 0.5263\n",
            "Epoch 78/150 - 0.06s - loss: 0.8695 - acc: 0.6019 - val_loss: 0.9671 - val_acc: 0.5526\n",
            "Epoch 79/150 - 0.06s - loss: 0.8752 - acc: 0.5846 - val_loss: 0.9750 - val_acc: 0.5425\n",
            "Epoch 80/150 - 0.06s - loss: 0.9176 - acc: 0.5612 - val_loss: 1.0350 - val_acc: 0.4777\n",
            "Epoch 81/150 - 0.06s - loss: 0.8559 - acc: 0.6102 - val_loss: 0.9606 - val_acc: 0.5385\n",
            "Epoch 82/150 - 0.06s - loss: 0.8684 - acc: 0.6062 - val_loss: 0.9771 - val_acc: 0.5466\n",
            "Epoch 83/150 - 0.06s - loss: 0.8546 - acc: 0.6055 - val_loss: 0.9594 - val_acc: 0.5547\n",
            "Epoch 84/150 - 0.06s - loss: 0.8970 - acc: 0.5789 - val_loss: 1.0177 - val_acc: 0.4899\n",
            "Epoch 85/150 - 0.06s - loss: 0.8629 - acc: 0.5967 - val_loss: 0.9751 - val_acc: 0.5223\n",
            "Epoch 86/150 - 0.06s - loss: 0.8774 - acc: 0.5938 - val_loss: 0.9907 - val_acc: 0.5324\n",
            "Epoch 87/150 - 0.06s - loss: 0.8630 - acc: 0.5965 - val_loss: 0.9772 - val_acc: 0.5202\n",
            "Epoch 88/150 - 0.06s - loss: 0.8740 - acc: 0.5945 - val_loss: 0.9914 - val_acc: 0.5223\n",
            "Epoch 89/150 - 0.06s - loss: 0.8564 - acc: 0.6131 - val_loss: 0.9712 - val_acc: 0.5466\n",
            "Epoch 90/150 - 0.06s - loss: 0.8618 - acc: 0.6068 - val_loss: 0.9837 - val_acc: 0.5162\n",
            "Epoch 91/150 - 0.06s - loss: 0.8635 - acc: 0.6023 - val_loss: 0.9853 - val_acc: 0.5162\n",
            "Epoch 92/150 - 0.06s - loss: 0.8768 - acc: 0.5875 - val_loss: 0.9842 - val_acc: 0.5466\n",
            "Epoch 93/150 - 0.06s - loss: 0.8610 - acc: 0.6003 - val_loss: 0.9723 - val_acc: 0.5405\n",
            "Epoch 94/150 - 0.06s - loss: 0.8735 - acc: 0.6044 - val_loss: 0.9826 - val_acc: 0.5648\n",
            "Epoch 95/150 - 0.06s - loss: 0.8567 - acc: 0.6066 - val_loss: 0.9695 - val_acc: 0.5486\n",
            "Epoch 96/150 - 0.06s - loss: 0.8754 - acc: 0.6030 - val_loss: 0.9880 - val_acc: 0.5526\n",
            "Epoch 97/150 - 0.06s - loss: 0.8599 - acc: 0.5954 - val_loss: 0.9733 - val_acc: 0.5466\n",
            "Epoch 98/150 - 0.06s - loss: 0.8451 - acc: 0.6140 - val_loss: 0.9621 - val_acc: 0.5587\n",
            "Epoch 99/150 - 0.06s - loss: 0.8519 - acc: 0.6046 - val_loss: 0.9657 - val_acc: 0.5486\n",
            "Epoch 100/150 - 0.06s - loss: 0.8533 - acc: 0.6062 - val_loss: 0.9780 - val_acc: 0.5324\n",
            "Epoch 101/150 - 0.06s - loss: 0.8987 - acc: 0.5765 - val_loss: 1.0216 - val_acc: 0.5142\n",
            "Epoch 102/150 - 0.05s - loss: 0.8459 - acc: 0.6111 - val_loss: 0.9707 - val_acc: 0.5304\n",
            "Epoch 103/150 - 0.06s - loss: 0.8444 - acc: 0.6219 - val_loss: 0.9659 - val_acc: 0.5567\n",
            "Epoch 104/150 - 0.06s - loss: 0.8516 - acc: 0.6140 - val_loss: 0.9772 - val_acc: 0.5405\n",
            "Epoch 105/150 - 0.06s - loss: 0.8424 - acc: 0.6143 - val_loss: 0.9647 - val_acc: 0.5425\n",
            "Epoch 106/150 - 0.06s - loss: 0.8434 - acc: 0.6176 - val_loss: 0.9642 - val_acc: 0.5425\n",
            "Epoch 107/150 - 0.06s - loss: 0.8684 - acc: 0.6093 - val_loss: 0.9884 - val_acc: 0.5628\n",
            "Epoch 108/150 - 0.06s - loss: 0.8721 - acc: 0.5886 - val_loss: 0.9850 - val_acc: 0.5526\n",
            "Epoch 109/150 - 0.06s - loss: 0.8405 - acc: 0.6176 - val_loss: 0.9654 - val_acc: 0.5405\n",
            "Epoch 110/150 - 0.06s - loss: 0.8540 - acc: 0.6098 - val_loss: 0.9892 - val_acc: 0.5243\n",
            "Epoch 111/150 - 0.06s - loss: 0.8426 - acc: 0.6174 - val_loss: 0.9729 - val_acc: 0.5506\n",
            "Epoch 112/150 - 0.06s - loss: 0.8371 - acc: 0.6226 - val_loss: 0.9652 - val_acc: 0.5668\n",
            "Epoch 113/150 - 0.06s - loss: 0.8441 - acc: 0.6122 - val_loss: 0.9653 - val_acc: 0.5364\n",
            "Epoch 114/150 - 0.06s - loss: 0.8418 - acc: 0.6143 - val_loss: 0.9692 - val_acc: 0.5486\n",
            "Epoch 115/150 - 0.06s - loss: 0.8500 - acc: 0.6073 - val_loss: 0.9718 - val_acc: 0.5567\n",
            "Epoch 116/150 - 0.06s - loss: 0.8470 - acc: 0.6104 - val_loss: 0.9691 - val_acc: 0.5405\n",
            "Epoch 117/150 - 0.06s - loss: 0.8446 - acc: 0.6246 - val_loss: 0.9719 - val_acc: 0.5526\n",
            "Epoch 118/150 - 0.06s - loss: 0.8495 - acc: 0.6129 - val_loss: 0.9730 - val_acc: 0.5486\n",
            "Epoch 119/150 - 0.06s - loss: 0.8579 - acc: 0.5951 - val_loss: 0.9767 - val_acc: 0.5607\n",
            "Epoch 120/150 - 0.05s - loss: 0.8348 - acc: 0.6262 - val_loss: 0.9672 - val_acc: 0.5567\n",
            "Epoch 121/150 - 0.06s - loss: 0.8374 - acc: 0.6244 - val_loss: 0.9661 - val_acc: 0.5709\n",
            "Epoch 122/150 - 0.06s - loss: 0.9074 - acc: 0.5720 - val_loss: 1.0400 - val_acc: 0.5182\n",
            "Epoch 123/150 - 0.06s - loss: 0.8349 - acc: 0.6246 - val_loss: 0.9640 - val_acc: 0.5709\n",
            "Epoch 124/150 - 0.06s - loss: 0.8382 - acc: 0.6174 - val_loss: 0.9775 - val_acc: 0.5344\n",
            "Epoch 125/150 - 0.06s - loss: 0.8343 - acc: 0.6260 - val_loss: 0.9653 - val_acc: 0.5688\n",
            "Epoch 126/150 - 0.06s - loss: 0.8482 - acc: 0.6179 - val_loss: 0.9788 - val_acc: 0.5506\n",
            "Epoch 127/150 - 0.06s - loss: 0.8364 - acc: 0.6192 - val_loss: 0.9760 - val_acc: 0.5425\n",
            "Epoch 128/150 - 0.06s - loss: 0.8494 - acc: 0.6174 - val_loss: 0.9782 - val_acc: 0.5648\n",
            "Epoch 129/150 - 0.06s - loss: 0.8451 - acc: 0.6129 - val_loss: 0.9831 - val_acc: 0.5324\n",
            "Epoch 130/150 - 0.06s - loss: 0.8308 - acc: 0.6210 - val_loss: 0.9661 - val_acc: 0.5607\n",
            "Epoch 131/150 - 0.06s - loss: 0.8355 - acc: 0.6161 - val_loss: 0.9744 - val_acc: 0.5445\n",
            "Epoch 132/150 - 0.06s - loss: 0.8652 - acc: 0.5911 - val_loss: 1.0028 - val_acc: 0.5121\n",
            "Epoch 133/150 - 0.06s - loss: 0.8540 - acc: 0.5999 - val_loss: 0.9793 - val_acc: 0.5466\n",
            "Epoch 134/150 - 0.06s - loss: 0.8288 - acc: 0.6260 - val_loss: 0.9649 - val_acc: 0.5648\n",
            "Epoch 135/150 - 0.06s - loss: 0.8286 - acc: 0.6239 - val_loss: 0.9690 - val_acc: 0.5526\n",
            "Epoch 136/150 - 0.06s - loss: 0.8385 - acc: 0.6230 - val_loss: 0.9699 - val_acc: 0.5607\n",
            "Epoch 137/150 - 0.06s - loss: 0.8454 - acc: 0.6149 - val_loss: 0.9922 - val_acc: 0.5243\n",
            "Epoch 138/150 - 0.06s - loss: 0.8317 - acc: 0.6226 - val_loss: 0.9635 - val_acc: 0.5567\n",
            "Epoch 139/150 - 0.06s - loss: 0.8679 - acc: 0.6091 - val_loss: 0.9945 - val_acc: 0.5466\n",
            "Epoch 140/150 - 0.07s - loss: 0.8277 - acc: 0.6242 - val_loss: 0.9675 - val_acc: 0.5567\n",
            "Epoch 141/150 - 0.06s - loss: 0.8344 - acc: 0.6170 - val_loss: 0.9790 - val_acc: 0.5425\n",
            "Epoch 142/150 - 0.06s - loss: 0.8541 - acc: 0.6050 - val_loss: 1.0011 - val_acc: 0.5142\n",
            "Epoch 143/150 - 0.06s - loss: 0.8568 - acc: 0.6093 - val_loss: 0.9975 - val_acc: 0.5344\n",
            "Epoch 144/150 - 0.06s - loss: 0.8438 - acc: 0.6062 - val_loss: 0.9751 - val_acc: 0.5567\n",
            "Epoch 145/150 - 0.06s - loss: 0.8274 - acc: 0.6244 - val_loss: 0.9690 - val_acc: 0.5526\n",
            "Epoch 146/150 - 0.06s - loss: 0.8290 - acc: 0.6300 - val_loss: 0.9727 - val_acc: 0.5648\n",
            "Epoch 147/150 - 0.06s - loss: 0.8262 - acc: 0.6269 - val_loss: 0.9669 - val_acc: 0.5648\n",
            "Epoch 148/150 - 0.06s - loss: 0.8661 - acc: 0.5967 - val_loss: 1.0201 - val_acc: 0.5162\n",
            "Epoch 149/150 - 0.06s - loss: 0.8461 - acc: 0.6143 - val_loss: 0.9978 - val_acc: 0.5283\n",
            "Epoch 150/150 - 0.06s - loss: 0.8246 - acc: 0.6287 - val_loss: 0.9667 - val_acc: 0.5587\n",
            "\n",
            "Combination 22/252:\n",
            "Hidden Layers: [64, 32], Activation: tanh, Learning Rate: 0.01, Batch Size: 64, Epochs: 50\n",
            "Epoch 1/50 - 0.05s - loss: 1.0959 - acc: 0.3529 - val_loss: 1.0943 - val_acc: 0.3947\n",
            "Epoch 2/50 - 0.04s - loss: 1.0892 - acc: 0.3662 - val_loss: 1.0891 - val_acc: 0.3704\n",
            "Epoch 3/50 - 0.04s - loss: 1.0829 - acc: 0.4188 - val_loss: 1.0837 - val_acc: 0.4190\n",
            "Epoch 4/50 - 0.04s - loss: 1.0787 - acc: 0.4327 - val_loss: 1.0798 - val_acc: 0.4291\n",
            "Epoch 5/50 - 0.04s - loss: 1.0734 - acc: 0.4397 - val_loss: 1.0770 - val_acc: 0.4332\n",
            "Epoch 6/50 - 0.05s - loss: 1.0698 - acc: 0.4503 - val_loss: 1.0736 - val_acc: 0.4352\n",
            "Epoch 7/50 - 0.04s - loss: 1.0666 - acc: 0.4519 - val_loss: 1.0726 - val_acc: 0.4514\n",
            "Epoch 8/50 - 0.04s - loss: 1.0616 - acc: 0.4521 - val_loss: 1.0691 - val_acc: 0.4534\n",
            "Epoch 9/50 - 0.04s - loss: 1.0575 - acc: 0.4762 - val_loss: 1.0649 - val_acc: 0.4656\n",
            "Epoch 10/50 - 0.04s - loss: 1.0542 - acc: 0.4606 - val_loss: 1.0637 - val_acc: 0.4413\n",
            "Epoch 11/50 - 0.04s - loss: 1.0499 - acc: 0.4798 - val_loss: 1.0594 - val_acc: 0.4757\n",
            "Epoch 12/50 - 0.04s - loss: 1.0458 - acc: 0.4867 - val_loss: 1.0569 - val_acc: 0.4818\n",
            "Epoch 13/50 - 0.04s - loss: 1.0422 - acc: 0.4881 - val_loss: 1.0545 - val_acc: 0.4879\n",
            "Epoch 14/50 - 0.05s - loss: 1.0383 - acc: 0.4883 - val_loss: 1.0518 - val_acc: 0.4939\n",
            "Epoch 15/50 - 0.05s - loss: 1.0359 - acc: 0.4883 - val_loss: 1.0510 - val_acc: 0.5000\n",
            "Epoch 16/50 - 0.04s - loss: 1.0315 - acc: 0.4928 - val_loss: 1.0469 - val_acc: 0.4757\n",
            "Epoch 17/50 - 0.05s - loss: 1.0277 - acc: 0.4984 - val_loss: 1.0445 - val_acc: 0.4879\n",
            "Epoch 18/50 - 0.05s - loss: 1.0252 - acc: 0.4946 - val_loss: 1.0430 - val_acc: 0.4777\n",
            "Epoch 19/50 - 0.04s - loss: 1.0209 - acc: 0.4998 - val_loss: 1.0396 - val_acc: 0.4899\n",
            "Epoch 20/50 - 0.05s - loss: 1.0188 - acc: 0.5002 - val_loss: 1.0393 - val_acc: 0.4899\n",
            "Epoch 21/50 - 0.05s - loss: 1.0141 - acc: 0.5058 - val_loss: 1.0347 - val_acc: 0.5081\n",
            "Epoch 22/50 - 0.04s - loss: 1.0121 - acc: 0.5045 - val_loss: 1.0338 - val_acc: 0.4858\n",
            "Epoch 23/50 - 0.04s - loss: 1.0080 - acc: 0.5088 - val_loss: 1.0294 - val_acc: 0.5040\n",
            "Epoch 24/50 - 0.04s - loss: 1.0082 - acc: 0.5081 - val_loss: 1.0304 - val_acc: 0.5202\n",
            "Epoch 25/50 - 0.04s - loss: 1.0018 - acc: 0.5164 - val_loss: 1.0247 - val_acc: 0.5263\n",
            "Epoch 26/50 - 0.05s - loss: 1.0002 - acc: 0.5142 - val_loss: 1.0246 - val_acc: 0.4939\n",
            "Epoch 27/50 - 0.04s - loss: 0.9957 - acc: 0.5182 - val_loss: 1.0205 - val_acc: 0.5223\n",
            "Epoch 28/50 - 0.04s - loss: 0.9925 - acc: 0.5218 - val_loss: 1.0174 - val_acc: 0.5263\n",
            "Epoch 29/50 - 0.04s - loss: 0.9900 - acc: 0.5259 - val_loss: 1.0159 - val_acc: 0.5385\n",
            "Epoch 30/50 - 0.04s - loss: 0.9874 - acc: 0.5205 - val_loss: 1.0131 - val_acc: 0.5081\n",
            "Epoch 31/50 - 0.04s - loss: 0.9843 - acc: 0.5277 - val_loss: 1.0109 - val_acc: 0.5385\n",
            "Epoch 32/50 - 0.04s - loss: 0.9819 - acc: 0.5225 - val_loss: 1.0085 - val_acc: 0.5121\n",
            "Epoch 33/50 - 0.04s - loss: 0.9805 - acc: 0.5265 - val_loss: 1.0065 - val_acc: 0.5061\n",
            "Epoch 34/50 - 0.04s - loss: 0.9772 - acc: 0.5261 - val_loss: 1.0051 - val_acc: 0.5162\n",
            "Epoch 35/50 - 0.04s - loss: 0.9774 - acc: 0.5245 - val_loss: 1.0054 - val_acc: 0.5081\n",
            "Epoch 36/50 - 0.04s - loss: 0.9752 - acc: 0.5344 - val_loss: 1.0036 - val_acc: 0.5466\n",
            "Epoch 37/50 - 0.04s - loss: 0.9712 - acc: 0.5382 - val_loss: 0.9995 - val_acc: 0.5405\n",
            "Epoch 38/50 - 0.04s - loss: 0.9761 - acc: 0.5227 - val_loss: 1.0056 - val_acc: 0.5061\n",
            "Epoch 39/50 - 0.04s - loss: 0.9677 - acc: 0.5326 - val_loss: 0.9978 - val_acc: 0.5182\n",
            "Epoch 40/50 - 0.04s - loss: 0.9632 - acc: 0.5380 - val_loss: 0.9935 - val_acc: 0.5486\n",
            "Epoch 41/50 - 0.05s - loss: 0.9635 - acc: 0.5322 - val_loss: 0.9934 - val_acc: 0.5202\n",
            "Epoch 42/50 - 0.04s - loss: 0.9612 - acc: 0.5364 - val_loss: 0.9922 - val_acc: 0.5304\n",
            "Epoch 43/50 - 0.04s - loss: 0.9567 - acc: 0.5382 - val_loss: 0.9874 - val_acc: 0.5425\n",
            "Epoch 44/50 - 0.04s - loss: 0.9586 - acc: 0.5405 - val_loss: 0.9903 - val_acc: 0.5385\n",
            "Epoch 45/50 - 0.05s - loss: 0.9573 - acc: 0.5488 - val_loss: 0.9889 - val_acc: 0.5607\n",
            "Epoch 46/50 - 0.04s - loss: 0.9517 - acc: 0.5394 - val_loss: 0.9840 - val_acc: 0.5344\n",
            "Epoch 47/50 - 0.04s - loss: 0.9494 - acc: 0.5472 - val_loss: 0.9814 - val_acc: 0.5445\n",
            "Epoch 48/50 - 0.04s - loss: 0.9477 - acc: 0.5468 - val_loss: 0.9805 - val_acc: 0.5466\n",
            "Epoch 49/50 - 0.04s - loss: 0.9457 - acc: 0.5477 - val_loss: 0.9791 - val_acc: 0.5425\n",
            "Epoch 50/50 - 0.04s - loss: 0.9450 - acc: 0.5508 - val_loss: 0.9785 - val_acc: 0.5628\n",
            "\n",
            "Combination 23/252:\n",
            "Hidden Layers: [64, 32], Activation: tanh, Learning Rate: 0.01, Batch Size: 64, Epochs: 100\n",
            "Epoch 1/100 - 0.04s - loss: 1.1024 - acc: 0.3396 - val_loss: 1.1030 - val_acc: 0.3421\n",
            "Epoch 2/100 - 0.04s - loss: 1.0931 - acc: 0.3772 - val_loss: 1.0950 - val_acc: 0.3725\n",
            "Epoch 3/100 - 0.04s - loss: 1.0860 - acc: 0.3875 - val_loss: 1.0898 - val_acc: 0.3623\n",
            "Epoch 4/100 - 0.04s - loss: 1.0804 - acc: 0.4125 - val_loss: 1.0843 - val_acc: 0.3947\n",
            "Epoch 5/100 - 0.04s - loss: 1.0749 - acc: 0.4305 - val_loss: 1.0796 - val_acc: 0.4008\n",
            "Epoch 6/100 - 0.04s - loss: 1.0708 - acc: 0.4278 - val_loss: 1.0766 - val_acc: 0.3968\n",
            "Epoch 7/100 - 0.04s - loss: 1.0670 - acc: 0.4411 - val_loss: 1.0740 - val_acc: 0.4069\n",
            "Epoch 8/100 - 0.04s - loss: 1.0631 - acc: 0.4485 - val_loss: 1.0698 - val_acc: 0.4332\n",
            "Epoch 9/100 - 0.04s - loss: 1.0593 - acc: 0.4514 - val_loss: 1.0673 - val_acc: 0.4393\n",
            "Epoch 10/100 - 0.04s - loss: 1.0558 - acc: 0.4577 - val_loss: 1.0641 - val_acc: 0.4433\n",
            "Epoch 11/100 - 0.05s - loss: 1.0524 - acc: 0.4609 - val_loss: 1.0618 - val_acc: 0.4494\n",
            "Epoch 12/100 - 0.04s - loss: 1.0497 - acc: 0.4669 - val_loss: 1.0597 - val_acc: 0.4514\n",
            "Epoch 13/100 - 0.04s - loss: 1.0462 - acc: 0.4658 - val_loss: 1.0573 - val_acc: 0.4595\n",
            "Epoch 14/100 - 0.04s - loss: 1.0432 - acc: 0.4771 - val_loss: 1.0556 - val_acc: 0.4676\n",
            "Epoch 15/100 - 0.04s - loss: 1.0404 - acc: 0.4793 - val_loss: 1.0538 - val_acc: 0.4696\n",
            "Epoch 16/100 - 0.04s - loss: 1.0372 - acc: 0.4789 - val_loss: 1.0509 - val_acc: 0.4818\n",
            "Epoch 17/100 - 0.04s - loss: 1.0358 - acc: 0.4723 - val_loss: 1.0501 - val_acc: 0.4676\n",
            "Epoch 18/100 - 0.04s - loss: 1.0313 - acc: 0.4890 - val_loss: 1.0467 - val_acc: 0.4818\n",
            "Epoch 19/100 - 0.04s - loss: 1.0313 - acc: 0.4843 - val_loss: 1.0485 - val_acc: 0.4433\n",
            "Epoch 20/100 - 0.04s - loss: 1.0256 - acc: 0.4908 - val_loss: 1.0419 - val_acc: 0.4980\n",
            "Epoch 21/100 - 0.04s - loss: 1.0231 - acc: 0.4960 - val_loss: 1.0399 - val_acc: 0.4838\n",
            "Epoch 22/100 - 0.04s - loss: 1.0218 - acc: 0.4863 - val_loss: 1.0399 - val_acc: 0.5000\n",
            "Epoch 23/100 - 0.04s - loss: 1.0176 - acc: 0.5047 - val_loss: 1.0369 - val_acc: 0.4858\n",
            "Epoch 24/100 - 0.04s - loss: 1.0148 - acc: 0.5076 - val_loss: 1.0347 - val_acc: 0.4879\n",
            "Epoch 25/100 - 0.04s - loss: 1.0114 - acc: 0.5047 - val_loss: 1.0310 - val_acc: 0.5000\n",
            "Epoch 26/100 - 0.04s - loss: 1.0088 - acc: 0.5076 - val_loss: 1.0288 - val_acc: 0.5061\n",
            "Epoch 27/100 - 0.04s - loss: 1.0068 - acc: 0.5065 - val_loss: 1.0278 - val_acc: 0.5263\n",
            "Epoch 28/100 - 0.04s - loss: 1.0034 - acc: 0.5135 - val_loss: 1.0252 - val_acc: 0.4980\n",
            "Epoch 29/100 - 0.04s - loss: 1.0006 - acc: 0.5146 - val_loss: 1.0225 - val_acc: 0.5304\n",
            "Epoch 30/100 - 0.04s - loss: 0.9985 - acc: 0.5164 - val_loss: 1.0212 - val_acc: 0.5324\n",
            "Epoch 31/100 - 0.04s - loss: 0.9948 - acc: 0.5211 - val_loss: 1.0176 - val_acc: 0.5223\n",
            "Epoch 32/100 - 0.04s - loss: 0.9924 - acc: 0.5220 - val_loss: 1.0151 - val_acc: 0.5405\n",
            "Epoch 33/100 - 0.04s - loss: 0.9897 - acc: 0.5265 - val_loss: 1.0134 - val_acc: 0.5385\n",
            "Epoch 34/100 - 0.04s - loss: 0.9875 - acc: 0.5279 - val_loss: 1.0119 - val_acc: 0.5304\n",
            "Epoch 35/100 - 0.04s - loss: 0.9856 - acc: 0.5358 - val_loss: 1.0108 - val_acc: 0.5364\n",
            "Epoch 36/100 - 0.04s - loss: 0.9826 - acc: 0.5295 - val_loss: 1.0070 - val_acc: 0.5506\n",
            "Epoch 37/100 - 0.04s - loss: 0.9832 - acc: 0.5265 - val_loss: 1.0068 - val_acc: 0.5506\n",
            "Epoch 38/100 - 0.04s - loss: 0.9772 - acc: 0.5340 - val_loss: 1.0026 - val_acc: 0.5324\n",
            "Epoch 39/100 - 0.04s - loss: 0.9746 - acc: 0.5409 - val_loss: 1.0010 - val_acc: 0.5405\n",
            "Epoch 40/100 - 0.04s - loss: 0.9727 - acc: 0.5358 - val_loss: 0.9993 - val_acc: 0.5344\n",
            "Epoch 41/100 - 0.04s - loss: 0.9727 - acc: 0.5353 - val_loss: 1.0004 - val_acc: 0.5283\n",
            "Epoch 42/100 - 0.04s - loss: 0.9696 - acc: 0.5416 - val_loss: 0.9977 - val_acc: 0.5304\n",
            "Epoch 43/100 - 0.04s - loss: 0.9674 - acc: 0.5403 - val_loss: 0.9935 - val_acc: 0.5526\n",
            "Epoch 44/100 - 0.04s - loss: 0.9644 - acc: 0.5430 - val_loss: 0.9908 - val_acc: 0.5486\n",
            "Epoch 45/100 - 0.04s - loss: 0.9623 - acc: 0.5432 - val_loss: 0.9904 - val_acc: 0.5405\n",
            "Epoch 46/100 - 0.05s - loss: 0.9633 - acc: 0.5405 - val_loss: 0.9894 - val_acc: 0.5547\n",
            "Epoch 47/100 - 0.04s - loss: 0.9631 - acc: 0.5427 - val_loss: 0.9900 - val_acc: 0.5607\n",
            "Epoch 48/100 - 0.04s - loss: 0.9605 - acc: 0.5499 - val_loss: 0.9890 - val_acc: 0.5688\n",
            "Epoch 49/100 - 0.04s - loss: 0.9547 - acc: 0.5493 - val_loss: 0.9856 - val_acc: 0.5263\n",
            "Epoch 50/100 - 0.04s - loss: 0.9692 - acc: 0.5211 - val_loss: 1.0007 - val_acc: 0.5000\n",
            "Epoch 51/100 - 0.04s - loss: 0.9513 - acc: 0.5533 - val_loss: 0.9805 - val_acc: 0.5729\n",
            "Epoch 52/100 - 0.04s - loss: 0.9482 - acc: 0.5466 - val_loss: 0.9780 - val_acc: 0.5445\n",
            "Epoch 53/100 - 0.04s - loss: 0.9466 - acc: 0.5506 - val_loss: 0.9775 - val_acc: 0.5385\n",
            "Epoch 54/100 - 0.05s - loss: 0.9440 - acc: 0.5520 - val_loss: 0.9750 - val_acc: 0.5445\n",
            "Epoch 55/100 - 0.05s - loss: 0.9427 - acc: 0.5504 - val_loss: 0.9745 - val_acc: 0.5385\n",
            "Epoch 56/100 - 0.05s - loss: 0.9405 - acc: 0.5533 - val_loss: 0.9724 - val_acc: 0.5486\n",
            "Epoch 57/100 - 0.05s - loss: 0.9389 - acc: 0.5583 - val_loss: 0.9711 - val_acc: 0.5547\n",
            "Epoch 58/100 - 0.05s - loss: 0.9424 - acc: 0.5450 - val_loss: 0.9721 - val_acc: 0.5385\n",
            "Epoch 59/100 - 0.05s - loss: 0.9441 - acc: 0.5553 - val_loss: 0.9755 - val_acc: 0.5628\n",
            "Epoch 60/100 - 0.05s - loss: 0.9381 - acc: 0.5601 - val_loss: 0.9739 - val_acc: 0.5283\n",
            "Epoch 61/100 - 0.04s - loss: 0.9369 - acc: 0.5517 - val_loss: 0.9709 - val_acc: 0.5385\n",
            "Epoch 62/100 - 0.04s - loss: 0.9314 - acc: 0.5641 - val_loss: 0.9669 - val_acc: 0.5567\n",
            "Epoch 63/100 - 0.04s - loss: 0.9312 - acc: 0.5569 - val_loss: 0.9664 - val_acc: 0.5466\n",
            "Epoch 64/100 - 0.04s - loss: 0.9280 - acc: 0.5630 - val_loss: 0.9631 - val_acc: 0.5648\n",
            "Epoch 65/100 - 0.04s - loss: 0.9274 - acc: 0.5711 - val_loss: 0.9633 - val_acc: 0.5749\n",
            "Epoch 66/100 - 0.05s - loss: 0.9402 - acc: 0.5542 - val_loss: 0.9723 - val_acc: 0.5607\n",
            "Epoch 67/100 - 0.04s - loss: 0.9241 - acc: 0.5648 - val_loss: 0.9614 - val_acc: 0.5607\n",
            "Epoch 68/100 - 0.04s - loss: 0.9254 - acc: 0.5632 - val_loss: 0.9640 - val_acc: 0.5445\n",
            "Epoch 69/100 - 0.04s - loss: 0.9231 - acc: 0.5686 - val_loss: 0.9624 - val_acc: 0.5607\n",
            "Epoch 70/100 - 0.04s - loss: 0.9388 - acc: 0.5574 - val_loss: 0.9728 - val_acc: 0.5729\n",
            "Epoch 71/100 - 0.04s - loss: 0.9219 - acc: 0.5726 - val_loss: 0.9622 - val_acc: 0.5486\n",
            "Epoch 72/100 - 0.04s - loss: 0.9189 - acc: 0.5659 - val_loss: 0.9581 - val_acc: 0.5607\n",
            "Epoch 73/100 - 0.04s - loss: 0.9269 - acc: 0.5614 - val_loss: 0.9705 - val_acc: 0.5324\n",
            "Epoch 74/100 - 0.04s - loss: 0.9160 - acc: 0.5724 - val_loss: 0.9555 - val_acc: 0.5729\n",
            "Epoch 75/100 - 0.04s - loss: 0.9152 - acc: 0.5742 - val_loss: 0.9577 - val_acc: 0.5607\n",
            "Epoch 76/100 - 0.05s - loss: 0.9167 - acc: 0.5771 - val_loss: 0.9563 - val_acc: 0.5749\n",
            "Epoch 77/100 - 0.04s - loss: 0.9151 - acc: 0.5726 - val_loss: 0.9597 - val_acc: 0.5486\n",
            "Epoch 78/100 - 0.04s - loss: 0.9264 - acc: 0.5697 - val_loss: 0.9650 - val_acc: 0.5769\n",
            "Epoch 79/100 - 0.04s - loss: 0.9146 - acc: 0.5798 - val_loss: 0.9561 - val_acc: 0.5769\n",
            "Epoch 80/100 - 0.04s - loss: 0.9312 - acc: 0.5558 - val_loss: 0.9793 - val_acc: 0.5243\n",
            "Epoch 81/100 - 0.04s - loss: 0.9126 - acc: 0.5657 - val_loss: 0.9570 - val_acc: 0.5344\n",
            "Epoch 82/100 - 0.04s - loss: 0.9083 - acc: 0.5816 - val_loss: 0.9551 - val_acc: 0.5486\n",
            "Epoch 83/100 - 0.04s - loss: 0.9278 - acc: 0.5607 - val_loss: 0.9801 - val_acc: 0.4919\n",
            "Epoch 84/100 - 0.04s - loss: 0.9138 - acc: 0.5700 - val_loss: 0.9642 - val_acc: 0.5385\n",
            "Epoch 85/100 - 0.04s - loss: 0.9040 - acc: 0.5819 - val_loss: 0.9536 - val_acc: 0.5526\n",
            "Epoch 86/100 - 0.05s - loss: 0.9073 - acc: 0.5664 - val_loss: 0.9554 - val_acc: 0.5304\n",
            "Epoch 87/100 - 0.04s - loss: 0.9054 - acc: 0.5821 - val_loss: 0.9523 - val_acc: 0.5789\n",
            "Epoch 88/100 - 0.04s - loss: 0.9009 - acc: 0.5812 - val_loss: 0.9527 - val_acc: 0.5587\n",
            "Epoch 89/100 - 0.04s - loss: 0.8984 - acc: 0.5812 - val_loss: 0.9483 - val_acc: 0.5567\n",
            "Epoch 90/100 - 0.04s - loss: 0.9036 - acc: 0.5758 - val_loss: 0.9559 - val_acc: 0.5364\n",
            "Epoch 91/100 - 0.04s - loss: 0.9030 - acc: 0.5837 - val_loss: 0.9521 - val_acc: 0.5688\n",
            "Epoch 92/100 - 0.04s - loss: 0.9038 - acc: 0.5749 - val_loss: 0.9592 - val_acc: 0.5324\n",
            "Epoch 93/100 - 0.04s - loss: 0.9023 - acc: 0.5722 - val_loss: 0.9543 - val_acc: 0.5506\n",
            "Epoch 94/100 - 0.04s - loss: 0.9039 - acc: 0.5769 - val_loss: 0.9534 - val_acc: 0.5648\n",
            "Epoch 95/100 - 0.04s - loss: 0.8927 - acc: 0.5888 - val_loss: 0.9487 - val_acc: 0.5567\n",
            "Epoch 96/100 - 0.05s - loss: 0.9057 - acc: 0.5704 - val_loss: 0.9642 - val_acc: 0.5324\n",
            "Epoch 97/100 - 0.04s - loss: 0.8983 - acc: 0.5760 - val_loss: 0.9539 - val_acc: 0.5344\n",
            "Epoch 98/100 - 0.05s - loss: 0.8900 - acc: 0.5902 - val_loss: 0.9462 - val_acc: 0.5709\n",
            "Epoch 99/100 - 0.04s - loss: 0.8893 - acc: 0.5906 - val_loss: 0.9464 - val_acc: 0.5628\n",
            "Epoch 100/100 - 0.05s - loss: 0.8917 - acc: 0.5846 - val_loss: 0.9532 - val_acc: 0.5405\n",
            "\n",
            "Combination 24/252:\n",
            "Hidden Layers: [64, 32], Activation: tanh, Learning Rate: 0.01, Batch Size: 64, Epochs: 150\n",
            "Epoch 1/150 - 0.05s - loss: 1.0902 - acc: 0.3691 - val_loss: 1.0951 - val_acc: 0.3482\n",
            "Epoch 2/150 - 0.04s - loss: 1.0825 - acc: 0.4085 - val_loss: 1.0883 - val_acc: 0.3887\n",
            "Epoch 3/150 - 0.04s - loss: 1.0764 - acc: 0.4168 - val_loss: 1.0838 - val_acc: 0.3947\n",
            "Epoch 4/150 - 0.04s - loss: 1.0710 - acc: 0.4316 - val_loss: 1.0793 - val_acc: 0.4130\n",
            "Epoch 5/150 - 0.05s - loss: 1.0661 - acc: 0.4397 - val_loss: 1.0749 - val_acc: 0.4231\n",
            "Epoch 6/150 - 0.04s - loss: 1.0618 - acc: 0.4467 - val_loss: 1.0722 - val_acc: 0.4271\n",
            "Epoch 7/150 - 0.04s - loss: 1.0581 - acc: 0.4586 - val_loss: 1.0680 - val_acc: 0.4393\n",
            "Epoch 8/150 - 0.04s - loss: 1.0535 - acc: 0.4613 - val_loss: 1.0652 - val_acc: 0.4453\n",
            "Epoch 9/150 - 0.04s - loss: 1.0500 - acc: 0.4717 - val_loss: 1.0627 - val_acc: 0.4595\n",
            "Epoch 10/150 - 0.04s - loss: 1.0458 - acc: 0.4746 - val_loss: 1.0581 - val_acc: 0.4656\n",
            "Epoch 11/150 - 0.05s - loss: 1.0424 - acc: 0.4719 - val_loss: 1.0560 - val_acc: 0.4595\n",
            "Epoch 12/150 - 0.04s - loss: 1.0397 - acc: 0.4773 - val_loss: 1.0531 - val_acc: 0.4575\n",
            "Epoch 13/150 - 0.04s - loss: 1.0354 - acc: 0.4809 - val_loss: 1.0500 - val_acc: 0.4818\n",
            "Epoch 14/150 - 0.04s - loss: 1.0324 - acc: 0.4867 - val_loss: 1.0465 - val_acc: 0.4777\n",
            "Epoch 15/150 - 0.04s - loss: 1.0311 - acc: 0.4836 - val_loss: 1.0448 - val_acc: 0.4575\n",
            "Epoch 16/150 - 0.05s - loss: 1.0259 - acc: 0.4926 - val_loss: 1.0417 - val_acc: 0.4980\n",
            "Epoch 17/150 - 0.04s - loss: 1.0226 - acc: 0.4924 - val_loss: 1.0393 - val_acc: 0.4838\n",
            "Epoch 18/150 - 0.04s - loss: 1.0218 - acc: 0.4937 - val_loss: 1.0367 - val_acc: 0.4838\n",
            "Epoch 19/150 - 0.04s - loss: 1.0175 - acc: 0.5034 - val_loss: 1.0333 - val_acc: 0.4879\n",
            "Epoch 20/150 - 0.05s - loss: 1.0150 - acc: 0.5031 - val_loss: 1.0310 - val_acc: 0.4919\n",
            "Epoch 21/150 - 0.04s - loss: 1.0104 - acc: 0.5092 - val_loss: 1.0277 - val_acc: 0.4899\n",
            "Epoch 22/150 - 0.04s - loss: 1.0076 - acc: 0.5142 - val_loss: 1.0259 - val_acc: 0.4919\n",
            "Epoch 23/150 - 0.04s - loss: 1.0048 - acc: 0.5135 - val_loss: 1.0237 - val_acc: 0.5101\n",
            "Epoch 24/150 - 0.04s - loss: 1.0026 - acc: 0.5128 - val_loss: 1.0201 - val_acc: 0.4919\n",
            "Epoch 25/150 - 0.05s - loss: 0.9989 - acc: 0.5202 - val_loss: 1.0176 - val_acc: 0.5081\n",
            "Epoch 26/150 - 0.04s - loss: 0.9965 - acc: 0.5214 - val_loss: 1.0151 - val_acc: 0.4899\n",
            "Epoch 27/150 - 0.04s - loss: 0.9964 - acc: 0.5121 - val_loss: 1.0143 - val_acc: 0.5101\n",
            "Epoch 28/150 - 0.04s - loss: 0.9915 - acc: 0.5241 - val_loss: 1.0108 - val_acc: 0.4919\n",
            "Epoch 29/150 - 0.04s - loss: 0.9919 - acc: 0.5130 - val_loss: 1.0094 - val_acc: 0.5223\n",
            "Epoch 30/150 - 0.05s - loss: 0.9850 - acc: 0.5310 - val_loss: 1.0055 - val_acc: 0.5304\n",
            "Epoch 31/150 - 0.05s - loss: 0.9852 - acc: 0.5252 - val_loss: 1.0070 - val_acc: 0.5081\n",
            "Epoch 32/150 - 0.04s - loss: 0.9798 - acc: 0.5346 - val_loss: 1.0009 - val_acc: 0.5304\n",
            "Epoch 33/150 - 0.04s - loss: 0.9785 - acc: 0.5328 - val_loss: 0.9994 - val_acc: 0.5040\n",
            "Epoch 34/150 - 0.04s - loss: 0.9821 - acc: 0.5238 - val_loss: 1.0056 - val_acc: 0.4980\n",
            "Epoch 35/150 - 0.05s - loss: 0.9818 - acc: 0.5202 - val_loss: 1.0057 - val_acc: 0.5000\n",
            "Epoch 36/150 - 0.04s - loss: 0.9710 - acc: 0.5358 - val_loss: 0.9936 - val_acc: 0.5344\n",
            "Epoch 37/150 - 0.04s - loss: 0.9676 - acc: 0.5403 - val_loss: 0.9892 - val_acc: 0.5304\n",
            "Epoch 38/150 - 0.04s - loss: 0.9714 - acc: 0.5288 - val_loss: 0.9905 - val_acc: 0.5324\n",
            "Epoch 39/150 - 0.04s - loss: 0.9634 - acc: 0.5423 - val_loss: 0.9848 - val_acc: 0.5344\n",
            "Epoch 40/150 - 0.04s - loss: 0.9628 - acc: 0.5439 - val_loss: 0.9862 - val_acc: 0.5202\n",
            "Epoch 41/150 - 0.04s - loss: 0.9701 - acc: 0.5376 - val_loss: 0.9909 - val_acc: 0.5466\n",
            "Epoch 42/150 - 0.04s - loss: 0.9598 - acc: 0.5412 - val_loss: 0.9851 - val_acc: 0.5243\n",
            "Epoch 43/150 - 0.04s - loss: 0.9603 - acc: 0.5423 - val_loss: 0.9819 - val_acc: 0.5466\n",
            "Epoch 44/150 - 0.04s - loss: 0.9532 - acc: 0.5490 - val_loss: 0.9764 - val_acc: 0.5486\n",
            "Epoch 45/150 - 0.05s - loss: 0.9512 - acc: 0.5517 - val_loss: 0.9760 - val_acc: 0.5547\n",
            "Epoch 46/150 - 0.05s - loss: 0.9499 - acc: 0.5466 - val_loss: 0.9738 - val_acc: 0.5466\n",
            "Epoch 47/150 - 0.04s - loss: 0.9476 - acc: 0.5549 - val_loss: 0.9723 - val_acc: 0.5587\n",
            "Epoch 48/150 - 0.04s - loss: 0.9491 - acc: 0.5508 - val_loss: 0.9745 - val_acc: 0.5567\n",
            "Epoch 49/150 - 0.04s - loss: 0.9469 - acc: 0.5513 - val_loss: 0.9715 - val_acc: 0.5648\n",
            "Epoch 50/150 - 0.04s - loss: 0.9476 - acc: 0.5517 - val_loss: 0.9718 - val_acc: 0.5547\n",
            "Epoch 51/150 - 0.04s - loss: 0.9407 - acc: 0.5540 - val_loss: 0.9669 - val_acc: 0.5587\n",
            "Epoch 52/150 - 0.04s - loss: 0.9410 - acc: 0.5531 - val_loss: 0.9671 - val_acc: 0.5628\n",
            "Epoch 53/150 - 0.04s - loss: 0.9379 - acc: 0.5569 - val_loss: 0.9648 - val_acc: 0.5526\n",
            "Epoch 54/150 - 0.04s - loss: 0.9447 - acc: 0.5495 - val_loss: 0.9699 - val_acc: 0.5526\n",
            "Epoch 55/150 - 0.04s - loss: 0.9347 - acc: 0.5576 - val_loss: 0.9647 - val_acc: 0.5547\n",
            "Epoch 56/150 - 0.05s - loss: 0.9330 - acc: 0.5612 - val_loss: 0.9623 - val_acc: 0.5668\n",
            "Epoch 57/150 - 0.04s - loss: 0.9320 - acc: 0.5560 - val_loss: 0.9610 - val_acc: 0.5607\n",
            "Epoch 58/150 - 0.04s - loss: 0.9309 - acc: 0.5592 - val_loss: 0.9606 - val_acc: 0.5628\n",
            "Epoch 59/150 - 0.04s - loss: 0.9451 - acc: 0.5508 - val_loss: 0.9714 - val_acc: 0.5547\n",
            "Epoch 60/150 - 0.04s - loss: 0.9275 - acc: 0.5632 - val_loss: 0.9589 - val_acc: 0.5709\n",
            "Epoch 61/150 - 0.04s - loss: 0.9257 - acc: 0.5605 - val_loss: 0.9574 - val_acc: 0.5587\n",
            "Epoch 62/150 - 0.04s - loss: 0.9291 - acc: 0.5493 - val_loss: 0.9588 - val_acc: 0.5567\n",
            "Epoch 63/150 - 0.04s - loss: 0.9300 - acc: 0.5596 - val_loss: 0.9661 - val_acc: 0.5445\n",
            "Epoch 64/150 - 0.04s - loss: 0.9227 - acc: 0.5621 - val_loss: 0.9572 - val_acc: 0.5547\n",
            "Epoch 65/150 - 0.05s - loss: 0.9241 - acc: 0.5605 - val_loss: 0.9613 - val_acc: 0.5587\n",
            "Epoch 66/150 - 0.05s - loss: 0.9247 - acc: 0.5587 - val_loss: 0.9627 - val_acc: 0.5506\n",
            "Epoch 67/150 - 0.05s - loss: 0.9240 - acc: 0.5585 - val_loss: 0.9625 - val_acc: 0.5405\n",
            "Epoch 68/150 - 0.04s - loss: 0.9167 - acc: 0.5675 - val_loss: 0.9533 - val_acc: 0.5587\n",
            "Epoch 69/150 - 0.04s - loss: 0.9264 - acc: 0.5585 - val_loss: 0.9664 - val_acc: 0.5445\n",
            "Epoch 70/150 - 0.04s - loss: 0.9186 - acc: 0.5648 - val_loss: 0.9586 - val_acc: 0.5547\n",
            "Epoch 71/150 - 0.04s - loss: 0.9182 - acc: 0.5641 - val_loss: 0.9566 - val_acc: 0.5466\n",
            "Epoch 72/150 - 0.04s - loss: 0.9278 - acc: 0.5587 - val_loss: 0.9685 - val_acc: 0.5223\n",
            "Epoch 73/150 - 0.04s - loss: 0.9113 - acc: 0.5688 - val_loss: 0.9495 - val_acc: 0.5547\n",
            "Epoch 74/150 - 0.04s - loss: 0.9104 - acc: 0.5738 - val_loss: 0.9507 - val_acc: 0.5648\n",
            "Epoch 75/150 - 0.04s - loss: 0.9195 - acc: 0.5700 - val_loss: 0.9565 - val_acc: 0.5729\n",
            "Epoch 76/150 - 0.05s - loss: 0.9081 - acc: 0.5740 - val_loss: 0.9478 - val_acc: 0.5769\n",
            "Epoch 77/150 - 0.04s - loss: 0.9098 - acc: 0.5695 - val_loss: 0.9541 - val_acc: 0.5466\n",
            "Epoch 78/150 - 0.04s - loss: 0.9057 - acc: 0.5749 - val_loss: 0.9468 - val_acc: 0.5668\n",
            "Epoch 79/150 - 0.04s - loss: 0.9234 - acc: 0.5621 - val_loss: 0.9602 - val_acc: 0.5567\n",
            "Epoch 80/150 - 0.04s - loss: 0.9044 - acc: 0.5760 - val_loss: 0.9486 - val_acc: 0.5486\n",
            "Epoch 81/150 - 0.04s - loss: 0.9035 - acc: 0.5798 - val_loss: 0.9488 - val_acc: 0.5607\n",
            "Epoch 82/150 - 0.04s - loss: 0.9205 - acc: 0.5628 - val_loss: 0.9731 - val_acc: 0.5202\n",
            "Epoch 83/150 - 0.04s - loss: 0.9085 - acc: 0.5675 - val_loss: 0.9578 - val_acc: 0.5445\n",
            "Epoch 84/150 - 0.04s - loss: 0.9137 - acc: 0.5666 - val_loss: 0.9661 - val_acc: 0.5243\n",
            "Epoch 85/150 - 0.04s - loss: 0.8982 - acc: 0.5805 - val_loss: 0.9460 - val_acc: 0.5668\n",
            "Epoch 86/150 - 0.04s - loss: 0.8979 - acc: 0.5814 - val_loss: 0.9468 - val_acc: 0.5486\n",
            "Epoch 87/150 - 0.04s - loss: 0.9014 - acc: 0.5792 - val_loss: 0.9541 - val_acc: 0.5385\n",
            "Epoch 88/150 - 0.04s - loss: 0.9058 - acc: 0.5783 - val_loss: 0.9532 - val_acc: 0.5830\n",
            "Epoch 89/150 - 0.04s - loss: 0.9118 - acc: 0.5740 - val_loss: 0.9568 - val_acc: 0.5749\n",
            "Epoch 90/150 - 0.05s - loss: 0.9229 - acc: 0.5587 - val_loss: 0.9783 - val_acc: 0.5182\n",
            "Epoch 91/150 - 0.05s - loss: 0.8941 - acc: 0.5830 - val_loss: 0.9448 - val_acc: 0.5668\n",
            "Epoch 92/150 - 0.04s - loss: 0.8932 - acc: 0.5850 - val_loss: 0.9454 - val_acc: 0.5729\n",
            "Epoch 93/150 - 0.04s - loss: 0.8912 - acc: 0.5843 - val_loss: 0.9426 - val_acc: 0.5607\n",
            "Epoch 94/150 - 0.04s - loss: 0.8916 - acc: 0.5846 - val_loss: 0.9438 - val_acc: 0.5709\n",
            "Epoch 95/150 - 0.04s - loss: 0.8986 - acc: 0.5825 - val_loss: 0.9507 - val_acc: 0.5830\n",
            "Epoch 96/150 - 0.04s - loss: 0.8921 - acc: 0.5884 - val_loss: 0.9470 - val_acc: 0.5688\n",
            "Epoch 97/150 - 0.04s - loss: 0.8909 - acc: 0.5879 - val_loss: 0.9470 - val_acc: 0.5648\n",
            "Epoch 98/150 - 0.04s - loss: 0.8916 - acc: 0.5810 - val_loss: 0.9445 - val_acc: 0.5628\n",
            "Epoch 99/150 - 0.04s - loss: 0.8872 - acc: 0.5877 - val_loss: 0.9476 - val_acc: 0.5466\n",
            "Epoch 100/150 - 0.05s - loss: 0.9064 - acc: 0.5789 - val_loss: 0.9585 - val_acc: 0.5648\n",
            "Epoch 101/150 - 0.04s - loss: 0.9364 - acc: 0.5679 - val_loss: 0.9874 - val_acc: 0.5526\n",
            "Epoch 102/150 - 0.04s - loss: 0.8936 - acc: 0.5776 - val_loss: 0.9562 - val_acc: 0.5405\n",
            "Epoch 103/150 - 0.04s - loss: 0.9012 - acc: 0.5843 - val_loss: 0.9576 - val_acc: 0.5668\n",
            "Epoch 104/150 - 0.04s - loss: 0.8983 - acc: 0.5803 - val_loss: 0.9535 - val_acc: 0.5587\n",
            "Epoch 105/150 - 0.04s - loss: 0.8806 - acc: 0.5897 - val_loss: 0.9439 - val_acc: 0.5486\n",
            "Epoch 106/150 - 0.04s - loss: 0.8841 - acc: 0.5895 - val_loss: 0.9446 - val_acc: 0.5709\n",
            "Epoch 107/150 - 0.04s - loss: 0.8848 - acc: 0.5846 - val_loss: 0.9450 - val_acc: 0.5587\n",
            "Epoch 108/150 - 0.04s - loss: 0.9019 - acc: 0.5778 - val_loss: 0.9740 - val_acc: 0.5385\n",
            "Epoch 109/150 - 0.04s - loss: 0.8815 - acc: 0.5924 - val_loss: 0.9437 - val_acc: 0.5709\n",
            "Epoch 110/150 - 0.04s - loss: 0.9155 - acc: 0.5668 - val_loss: 0.9924 - val_acc: 0.5101\n",
            "Epoch 111/150 - 0.05s - loss: 0.8768 - acc: 0.5963 - val_loss: 0.9448 - val_acc: 0.5648\n",
            "Epoch 112/150 - 0.04s - loss: 0.8756 - acc: 0.5942 - val_loss: 0.9423 - val_acc: 0.5628\n",
            "Epoch 113/150 - 0.04s - loss: 0.8772 - acc: 0.5942 - val_loss: 0.9430 - val_acc: 0.5769\n",
            "Epoch 114/150 - 0.05s - loss: 0.8787 - acc: 0.5886 - val_loss: 0.9508 - val_acc: 0.5486\n",
            "Epoch 115/150 - 0.04s - loss: 0.8827 - acc: 0.5870 - val_loss: 0.9470 - val_acc: 0.5506\n",
            "Epoch 116/150 - 0.04s - loss: 0.8731 - acc: 0.5974 - val_loss: 0.9454 - val_acc: 0.5587\n",
            "Epoch 117/150 - 0.04s - loss: 0.8868 - acc: 0.5906 - val_loss: 0.9525 - val_acc: 0.5688\n",
            "Epoch 118/150 - 0.04s - loss: 0.8791 - acc: 0.5884 - val_loss: 0.9470 - val_acc: 0.5567\n",
            "Epoch 119/150 - 0.04s - loss: 0.8949 - acc: 0.5726 - val_loss: 0.9741 - val_acc: 0.5263\n",
            "Epoch 120/150 - 0.04s - loss: 0.8803 - acc: 0.5938 - val_loss: 0.9564 - val_acc: 0.5486\n",
            "Epoch 121/150 - 0.05s - loss: 0.8722 - acc: 0.5942 - val_loss: 0.9487 - val_acc: 0.5526\n",
            "Epoch 122/150 - 0.04s - loss: 0.8858 - acc: 0.5924 - val_loss: 0.9551 - val_acc: 0.5547\n",
            "Epoch 123/150 - 0.04s - loss: 0.8781 - acc: 0.5967 - val_loss: 0.9508 - val_acc: 0.5688\n",
            "Epoch 124/150 - 0.04s - loss: 0.8758 - acc: 0.5857 - val_loss: 0.9497 - val_acc: 0.5486\n",
            "Epoch 125/150 - 0.04s - loss: 0.8746 - acc: 0.6023 - val_loss: 0.9506 - val_acc: 0.5850\n",
            "Epoch 126/150 - 0.04s - loss: 0.8662 - acc: 0.5981 - val_loss: 0.9434 - val_acc: 0.5587\n",
            "Epoch 127/150 - 0.04s - loss: 0.8677 - acc: 0.6028 - val_loss: 0.9494 - val_acc: 0.5567\n",
            "Epoch 128/150 - 0.04s - loss: 0.8663 - acc: 0.6035 - val_loss: 0.9450 - val_acc: 0.5688\n",
            "Epoch 129/150 - 0.04s - loss: 0.8920 - acc: 0.5814 - val_loss: 0.9798 - val_acc: 0.5243\n",
            "Epoch 130/150 - 0.04s - loss: 0.8638 - acc: 0.6080 - val_loss: 0.9455 - val_acc: 0.5607\n",
            "Epoch 131/150 - 0.04s - loss: 0.8766 - acc: 0.5960 - val_loss: 0.9549 - val_acc: 0.5749\n",
            "Epoch 132/150 - 0.04s - loss: 0.8773 - acc: 0.5839 - val_loss: 0.9544 - val_acc: 0.5547\n",
            "Epoch 133/150 - 0.04s - loss: 0.8956 - acc: 0.5740 - val_loss: 0.9897 - val_acc: 0.5020\n",
            "Epoch 134/150 - 0.04s - loss: 0.8714 - acc: 0.5951 - val_loss: 0.9508 - val_acc: 0.5526\n",
            "Epoch 135/150 - 0.05s - loss: 0.9155 - acc: 0.5637 - val_loss: 1.0108 - val_acc: 0.5101\n",
            "Epoch 136/150 - 0.05s - loss: 0.8629 - acc: 0.6028 - val_loss: 0.9531 - val_acc: 0.5486\n",
            "Epoch 137/150 - 0.05s - loss: 0.8639 - acc: 0.6041 - val_loss: 0.9485 - val_acc: 0.5850\n",
            "Epoch 138/150 - 0.04s - loss: 0.9367 - acc: 0.5497 - val_loss: 1.0366 - val_acc: 0.4939\n",
            "Epoch 139/150 - 0.04s - loss: 0.8626 - acc: 0.5974 - val_loss: 0.9484 - val_acc: 0.5749\n",
            "Epoch 140/150 - 0.05s - loss: 0.8790 - acc: 0.5965 - val_loss: 0.9621 - val_acc: 0.5688\n",
            "Epoch 141/150 - 0.04s - loss: 0.8727 - acc: 0.5963 - val_loss: 0.9565 - val_acc: 0.5567\n",
            "Epoch 142/150 - 0.04s - loss: 0.8624 - acc: 0.6008 - val_loss: 0.9581 - val_acc: 0.5425\n",
            "Epoch 143/150 - 0.04s - loss: 0.9182 - acc: 0.5630 - val_loss: 1.0259 - val_acc: 0.4879\n",
            "Epoch 144/150 - 0.04s - loss: 0.8614 - acc: 0.6089 - val_loss: 0.9543 - val_acc: 0.5709\n",
            "Epoch 145/150 - 0.04s - loss: 0.8591 - acc: 0.6005 - val_loss: 0.9564 - val_acc: 0.5567\n",
            "Epoch 146/150 - 0.04s - loss: 0.8562 - acc: 0.6089 - val_loss: 0.9526 - val_acc: 0.5547\n",
            "Epoch 147/150 - 0.04s - loss: 0.8656 - acc: 0.5985 - val_loss: 0.9556 - val_acc: 0.5587\n",
            "Epoch 148/150 - 0.04s - loss: 0.8579 - acc: 0.6113 - val_loss: 0.9562 - val_acc: 0.5567\n",
            "Epoch 149/150 - 0.04s - loss: 0.8567 - acc: 0.6109 - val_loss: 0.9566 - val_acc: 0.5466\n",
            "Epoch 150/150 - 0.04s - loss: 0.8628 - acc: 0.5999 - val_loss: 0.9555 - val_acc: 0.5567\n",
            "\n",
            "Combination 25/252:\n",
            "Hidden Layers: [64, 32], Activation: tanh, Learning Rate: 0.001, Batch Size: 32, Epochs: 50\n",
            "Epoch 1/50 - 0.06s - loss: 1.1219 - acc: 0.3237 - val_loss: 1.1307 - val_acc: 0.2834\n",
            "Epoch 2/50 - 0.06s - loss: 1.1056 - acc: 0.3302 - val_loss: 1.1126 - val_acc: 0.2794\n",
            "Epoch 3/50 - 0.06s - loss: 1.0985 - acc: 0.3412 - val_loss: 1.1043 - val_acc: 0.3036\n",
            "Epoch 4/50 - 0.06s - loss: 1.0942 - acc: 0.3549 - val_loss: 1.0998 - val_acc: 0.3340\n",
            "Epoch 5/50 - 0.06s - loss: 1.0910 - acc: 0.3709 - val_loss: 1.0967 - val_acc: 0.3421\n",
            "Epoch 6/50 - 0.06s - loss: 1.0883 - acc: 0.3803 - val_loss: 1.0940 - val_acc: 0.3522\n",
            "Epoch 7/50 - 0.06s - loss: 1.0859 - acc: 0.3889 - val_loss: 1.0919 - val_acc: 0.3482\n",
            "Epoch 8/50 - 0.06s - loss: 1.0837 - acc: 0.3950 - val_loss: 1.0901 - val_acc: 0.3502\n",
            "Epoch 9/50 - 0.06s - loss: 1.0817 - acc: 0.3981 - val_loss: 1.0885 - val_acc: 0.3623\n",
            "Epoch 10/50 - 0.06s - loss: 1.0798 - acc: 0.4046 - val_loss: 1.0870 - val_acc: 0.3664\n",
            "Epoch 11/50 - 0.06s - loss: 1.0780 - acc: 0.4073 - val_loss: 1.0855 - val_acc: 0.3583\n",
            "Epoch 12/50 - 0.06s - loss: 1.0763 - acc: 0.4143 - val_loss: 1.0841 - val_acc: 0.3623\n",
            "Epoch 13/50 - 0.07s - loss: 1.0748 - acc: 0.4154 - val_loss: 1.0830 - val_acc: 0.3623\n",
            "Epoch 14/50 - 0.06s - loss: 1.0732 - acc: 0.4229 - val_loss: 1.0817 - val_acc: 0.3704\n",
            "Epoch 15/50 - 0.06s - loss: 1.0718 - acc: 0.4251 - val_loss: 1.0804 - val_acc: 0.3704\n",
            "Epoch 16/50 - 0.06s - loss: 1.0704 - acc: 0.4269 - val_loss: 1.0794 - val_acc: 0.3765\n",
            "Epoch 17/50 - 0.06s - loss: 1.0690 - acc: 0.4325 - val_loss: 1.0783 - val_acc: 0.3785\n",
            "Epoch 18/50 - 0.06s - loss: 1.0677 - acc: 0.4348 - val_loss: 1.0773 - val_acc: 0.3765\n",
            "Epoch 19/50 - 0.06s - loss: 1.0664 - acc: 0.4415 - val_loss: 1.0763 - val_acc: 0.3907\n",
            "Epoch 20/50 - 0.06s - loss: 1.0651 - acc: 0.4440 - val_loss: 1.0754 - val_acc: 0.3947\n",
            "Epoch 21/50 - 0.06s - loss: 1.0639 - acc: 0.4483 - val_loss: 1.0744 - val_acc: 0.4049\n",
            "Epoch 22/50 - 0.06s - loss: 1.0627 - acc: 0.4494 - val_loss: 1.0734 - val_acc: 0.4231\n",
            "Epoch 23/50 - 0.06s - loss: 1.0615 - acc: 0.4541 - val_loss: 1.0725 - val_acc: 0.4251\n",
            "Epoch 24/50 - 0.06s - loss: 1.0604 - acc: 0.4575 - val_loss: 1.0717 - val_acc: 0.4251\n",
            "Epoch 25/50 - 0.06s - loss: 1.0593 - acc: 0.4591 - val_loss: 1.0708 - val_acc: 0.4251\n",
            "Epoch 26/50 - 0.06s - loss: 1.0581 - acc: 0.4651 - val_loss: 1.0699 - val_acc: 0.4372\n",
            "Epoch 27/50 - 0.06s - loss: 1.0570 - acc: 0.4633 - val_loss: 1.0689 - val_acc: 0.4372\n",
            "Epoch 28/50 - 0.06s - loss: 1.0559 - acc: 0.4633 - val_loss: 1.0681 - val_acc: 0.4352\n",
            "Epoch 29/50 - 0.06s - loss: 1.0548 - acc: 0.4687 - val_loss: 1.0673 - val_acc: 0.4453\n",
            "Epoch 30/50 - 0.06s - loss: 1.0537 - acc: 0.4717 - val_loss: 1.0664 - val_acc: 0.4453\n",
            "Epoch 31/50 - 0.06s - loss: 1.0526 - acc: 0.4721 - val_loss: 1.0656 - val_acc: 0.4453\n",
            "Epoch 32/50 - 0.06s - loss: 1.0516 - acc: 0.4730 - val_loss: 1.0648 - val_acc: 0.4433\n",
            "Epoch 33/50 - 0.06s - loss: 1.0506 - acc: 0.4735 - val_loss: 1.0639 - val_acc: 0.4474\n",
            "Epoch 34/50 - 0.06s - loss: 1.0495 - acc: 0.4755 - val_loss: 1.0632 - val_acc: 0.4453\n",
            "Epoch 35/50 - 0.06s - loss: 1.0486 - acc: 0.4748 - val_loss: 1.0626 - val_acc: 0.4453\n",
            "Epoch 36/50 - 0.06s - loss: 1.0475 - acc: 0.4789 - val_loss: 1.0617 - val_acc: 0.4413\n",
            "Epoch 37/50 - 0.06s - loss: 1.0465 - acc: 0.4804 - val_loss: 1.0608 - val_acc: 0.4555\n",
            "Epoch 38/50 - 0.06s - loss: 1.0455 - acc: 0.4831 - val_loss: 1.0600 - val_acc: 0.4555\n",
            "Epoch 39/50 - 0.06s - loss: 1.0445 - acc: 0.4829 - val_loss: 1.0593 - val_acc: 0.4555\n",
            "Epoch 40/50 - 0.06s - loss: 1.0435 - acc: 0.4820 - val_loss: 1.0585 - val_acc: 0.4676\n",
            "Epoch 41/50 - 0.06s - loss: 1.0426 - acc: 0.4831 - val_loss: 1.0578 - val_acc: 0.4636\n",
            "Epoch 42/50 - 0.06s - loss: 1.0416 - acc: 0.4838 - val_loss: 1.0569 - val_acc: 0.4636\n",
            "Epoch 43/50 - 0.06s - loss: 1.0406 - acc: 0.4885 - val_loss: 1.0561 - val_acc: 0.4656\n",
            "Epoch 44/50 - 0.06s - loss: 1.0396 - acc: 0.4885 - val_loss: 1.0553 - val_acc: 0.4615\n",
            "Epoch 45/50 - 0.06s - loss: 1.0387 - acc: 0.4912 - val_loss: 1.0545 - val_acc: 0.4676\n",
            "Epoch 46/50 - 0.06s - loss: 1.0377 - acc: 0.4885 - val_loss: 1.0538 - val_acc: 0.4696\n",
            "Epoch 47/50 - 0.06s - loss: 1.0368 - acc: 0.4921 - val_loss: 1.0530 - val_acc: 0.4676\n",
            "Epoch 48/50 - 0.06s - loss: 1.0359 - acc: 0.4935 - val_loss: 1.0522 - val_acc: 0.4676\n",
            "Epoch 49/50 - 0.06s - loss: 1.0350 - acc: 0.4912 - val_loss: 1.0517 - val_acc: 0.4696\n",
            "Epoch 50/50 - 0.06s - loss: 1.0340 - acc: 0.4933 - val_loss: 1.0508 - val_acc: 0.4696\n",
            "\n",
            "Combination 26/252:\n",
            "Hidden Layers: [64, 32], Activation: tanh, Learning Rate: 0.001, Batch Size: 32, Epochs: 100\n",
            "Epoch 1/100 - 0.06s - loss: 1.1156 - acc: 0.2967 - val_loss: 1.1174 - val_acc: 0.3259\n",
            "Epoch 2/100 - 0.06s - loss: 1.1097 - acc: 0.3093 - val_loss: 1.1112 - val_acc: 0.3279\n",
            "Epoch 3/100 - 0.06s - loss: 1.1064 - acc: 0.3201 - val_loss: 1.1080 - val_acc: 0.3219\n",
            "Epoch 4/100 - 0.06s - loss: 1.1035 - acc: 0.3277 - val_loss: 1.1055 - val_acc: 0.3219\n",
            "Epoch 5/100 - 0.06s - loss: 1.1009 - acc: 0.3394 - val_loss: 1.1032 - val_acc: 0.3279\n",
            "Epoch 6/100 - 0.06s - loss: 1.0984 - acc: 0.3493 - val_loss: 1.1011 - val_acc: 0.3300\n",
            "Epoch 7/100 - 0.06s - loss: 1.0961 - acc: 0.3608 - val_loss: 1.0990 - val_acc: 0.3381\n",
            "Epoch 8/100 - 0.06s - loss: 1.0940 - acc: 0.3709 - val_loss: 1.0971 - val_acc: 0.3563\n",
            "Epoch 9/100 - 0.06s - loss: 1.0919 - acc: 0.3819 - val_loss: 1.0953 - val_acc: 0.3684\n",
            "Epoch 10/100 - 0.06s - loss: 1.0900 - acc: 0.3932 - val_loss: 1.0939 - val_acc: 0.3664\n",
            "Epoch 11/100 - 0.06s - loss: 1.0882 - acc: 0.3999 - val_loss: 1.0923 - val_acc: 0.3725\n",
            "Epoch 12/100 - 0.06s - loss: 1.0865 - acc: 0.4071 - val_loss: 1.0907 - val_acc: 0.3866\n",
            "Epoch 13/100 - 0.06s - loss: 1.0849 - acc: 0.4112 - val_loss: 1.0894 - val_acc: 0.3927\n",
            "Epoch 14/100 - 0.06s - loss: 1.0833 - acc: 0.4172 - val_loss: 1.0880 - val_acc: 0.3988\n",
            "Epoch 15/100 - 0.06s - loss: 1.0818 - acc: 0.4168 - val_loss: 1.0870 - val_acc: 0.3988\n",
            "Epoch 16/100 - 0.06s - loss: 1.0804 - acc: 0.4217 - val_loss: 1.0858 - val_acc: 0.4028\n",
            "Epoch 17/100 - 0.06s - loss: 1.0791 - acc: 0.4229 - val_loss: 1.0849 - val_acc: 0.4028\n",
            "Epoch 18/100 - 0.06s - loss: 1.0778 - acc: 0.4267 - val_loss: 1.0837 - val_acc: 0.4049\n",
            "Epoch 19/100 - 0.06s - loss: 1.0765 - acc: 0.4262 - val_loss: 1.0825 - val_acc: 0.4028\n",
            "Epoch 20/100 - 0.06s - loss: 1.0753 - acc: 0.4287 - val_loss: 1.0816 - val_acc: 0.4049\n",
            "Epoch 21/100 - 0.06s - loss: 1.0741 - acc: 0.4316 - val_loss: 1.0807 - val_acc: 0.4089\n",
            "Epoch 22/100 - 0.06s - loss: 1.0730 - acc: 0.4298 - val_loss: 1.0800 - val_acc: 0.4049\n",
            "Epoch 23/100 - 0.06s - loss: 1.0719 - acc: 0.4381 - val_loss: 1.0789 - val_acc: 0.4231\n",
            "Epoch 24/100 - 0.06s - loss: 1.0708 - acc: 0.4384 - val_loss: 1.0782 - val_acc: 0.4291\n",
            "Epoch 25/100 - 0.06s - loss: 1.0698 - acc: 0.4406 - val_loss: 1.0774 - val_acc: 0.4291\n",
            "Epoch 26/100 - 0.06s - loss: 1.0688 - acc: 0.4397 - val_loss: 1.0765 - val_acc: 0.4291\n",
            "Epoch 27/100 - 0.06s - loss: 1.0678 - acc: 0.4415 - val_loss: 1.0758 - val_acc: 0.4332\n",
            "Epoch 28/100 - 0.06s - loss: 1.0668 - acc: 0.4411 - val_loss: 1.0751 - val_acc: 0.4291\n",
            "Epoch 29/100 - 0.06s - loss: 1.0659 - acc: 0.4431 - val_loss: 1.0745 - val_acc: 0.4332\n",
            "Epoch 30/100 - 0.06s - loss: 1.0650 - acc: 0.4417 - val_loss: 1.0738 - val_acc: 0.4312\n",
            "Epoch 31/100 - 0.06s - loss: 1.0641 - acc: 0.4444 - val_loss: 1.0731 - val_acc: 0.4352\n",
            "Epoch 32/100 - 0.06s - loss: 1.0632 - acc: 0.4453 - val_loss: 1.0723 - val_acc: 0.4352\n",
            "Epoch 33/100 - 0.06s - loss: 1.0623 - acc: 0.4449 - val_loss: 1.0718 - val_acc: 0.4372\n",
            "Epoch 34/100 - 0.06s - loss: 1.0615 - acc: 0.4458 - val_loss: 1.0712 - val_acc: 0.4372\n",
            "Epoch 35/100 - 0.06s - loss: 1.0607 - acc: 0.4460 - val_loss: 1.0707 - val_acc: 0.4413\n",
            "Epoch 36/100 - 0.06s - loss: 1.0598 - acc: 0.4471 - val_loss: 1.0700 - val_acc: 0.4393\n",
            "Epoch 37/100 - 0.06s - loss: 1.0590 - acc: 0.4494 - val_loss: 1.0694 - val_acc: 0.4393\n",
            "Epoch 38/100 - 0.06s - loss: 1.0582 - acc: 0.4519 - val_loss: 1.0688 - val_acc: 0.4393\n",
            "Epoch 39/100 - 0.06s - loss: 1.0574 - acc: 0.4505 - val_loss: 1.0683 - val_acc: 0.4453\n",
            "Epoch 40/100 - 0.06s - loss: 1.0566 - acc: 0.4507 - val_loss: 1.0678 - val_acc: 0.4474\n",
            "Epoch 41/100 - 0.06s - loss: 1.0559 - acc: 0.4528 - val_loss: 1.0673 - val_acc: 0.4433\n",
            "Epoch 42/100 - 0.06s - loss: 1.0551 - acc: 0.4541 - val_loss: 1.0667 - val_acc: 0.4393\n",
            "Epoch 43/100 - 0.06s - loss: 1.0543 - acc: 0.4543 - val_loss: 1.0662 - val_acc: 0.4413\n",
            "Epoch 44/100 - 0.06s - loss: 1.0536 - acc: 0.4575 - val_loss: 1.0656 - val_acc: 0.4474\n",
            "Epoch 45/100 - 0.06s - loss: 1.0529 - acc: 0.4550 - val_loss: 1.0654 - val_acc: 0.4474\n",
            "Epoch 46/100 - 0.06s - loss: 1.0522 - acc: 0.4568 - val_loss: 1.0647 - val_acc: 0.4494\n",
            "Epoch 47/100 - 0.06s - loss: 1.0514 - acc: 0.4582 - val_loss: 1.0641 - val_acc: 0.4474\n",
            "Epoch 48/100 - 0.06s - loss: 1.0507 - acc: 0.4591 - val_loss: 1.0637 - val_acc: 0.4453\n",
            "Epoch 49/100 - 0.06s - loss: 1.0500 - acc: 0.4602 - val_loss: 1.0633 - val_acc: 0.4453\n",
            "Epoch 50/100 - 0.06s - loss: 1.0493 - acc: 0.4609 - val_loss: 1.0628 - val_acc: 0.4514\n",
            "Epoch 51/100 - 0.06s - loss: 1.0486 - acc: 0.4611 - val_loss: 1.0623 - val_acc: 0.4453\n",
            "Epoch 52/100 - 0.06s - loss: 1.0479 - acc: 0.4627 - val_loss: 1.0620 - val_acc: 0.4474\n",
            "Epoch 53/100 - 0.06s - loss: 1.0472 - acc: 0.4622 - val_loss: 1.0615 - val_acc: 0.4474\n",
            "Epoch 54/100 - 0.06s - loss: 1.0465 - acc: 0.4638 - val_loss: 1.0609 - val_acc: 0.4474\n",
            "Epoch 55/100 - 0.06s - loss: 1.0459 - acc: 0.4647 - val_loss: 1.0604 - val_acc: 0.4453\n",
            "Epoch 56/100 - 0.06s - loss: 1.0452 - acc: 0.4651 - val_loss: 1.0601 - val_acc: 0.4474\n",
            "Epoch 57/100 - 0.06s - loss: 1.0446 - acc: 0.4658 - val_loss: 1.0594 - val_acc: 0.4453\n",
            "Epoch 58/100 - 0.06s - loss: 1.0439 - acc: 0.4674 - val_loss: 1.0591 - val_acc: 0.4514\n",
            "Epoch 59/100 - 0.06s - loss: 1.0432 - acc: 0.4683 - val_loss: 1.0588 - val_acc: 0.4474\n",
            "Epoch 60/100 - 0.06s - loss: 1.0426 - acc: 0.4672 - val_loss: 1.0583 - val_acc: 0.4514\n",
            "Epoch 61/100 - 0.06s - loss: 1.0419 - acc: 0.4694 - val_loss: 1.0578 - val_acc: 0.4534\n",
            "Epoch 62/100 - 0.06s - loss: 1.0412 - acc: 0.4703 - val_loss: 1.0574 - val_acc: 0.4575\n",
            "Epoch 63/100 - 0.06s - loss: 1.0407 - acc: 0.4714 - val_loss: 1.0569 - val_acc: 0.4595\n",
            "Epoch 64/100 - 0.06s - loss: 1.0400 - acc: 0.4717 - val_loss: 1.0566 - val_acc: 0.4595\n",
            "Epoch 65/100 - 0.06s - loss: 1.0393 - acc: 0.4741 - val_loss: 1.0561 - val_acc: 0.4555\n",
            "Epoch 66/100 - 0.06s - loss: 1.0387 - acc: 0.4753 - val_loss: 1.0556 - val_acc: 0.4575\n",
            "Epoch 67/100 - 0.06s - loss: 1.0381 - acc: 0.4786 - val_loss: 1.0553 - val_acc: 0.4534\n",
            "Epoch 68/100 - 0.06s - loss: 1.0375 - acc: 0.4753 - val_loss: 1.0547 - val_acc: 0.4595\n",
            "Epoch 69/100 - 0.06s - loss: 1.0368 - acc: 0.4773 - val_loss: 1.0546 - val_acc: 0.4615\n",
            "Epoch 70/100 - 0.06s - loss: 1.0362 - acc: 0.4777 - val_loss: 1.0540 - val_acc: 0.4595\n",
            "Epoch 71/100 - 0.06s - loss: 1.0355 - acc: 0.4780 - val_loss: 1.0537 - val_acc: 0.4615\n",
            "Epoch 72/100 - 0.06s - loss: 1.0350 - acc: 0.4782 - val_loss: 1.0531 - val_acc: 0.4575\n",
            "Epoch 73/100 - 0.06s - loss: 1.0343 - acc: 0.4789 - val_loss: 1.0527 - val_acc: 0.4555\n",
            "Epoch 74/100 - 0.06s - loss: 1.0337 - acc: 0.4802 - val_loss: 1.0524 - val_acc: 0.4595\n",
            "Epoch 75/100 - 0.06s - loss: 1.0331 - acc: 0.4802 - val_loss: 1.0521 - val_acc: 0.4575\n",
            "Epoch 76/100 - 0.06s - loss: 1.0325 - acc: 0.4798 - val_loss: 1.0517 - val_acc: 0.4595\n",
            "Epoch 77/100 - 0.06s - loss: 1.0319 - acc: 0.4827 - val_loss: 1.0512 - val_acc: 0.4615\n",
            "Epoch 78/100 - 0.06s - loss: 1.0313 - acc: 0.4816 - val_loss: 1.0509 - val_acc: 0.4615\n",
            "Epoch 79/100 - 0.06s - loss: 1.0307 - acc: 0.4816 - val_loss: 1.0507 - val_acc: 0.4636\n",
            "Epoch 80/100 - 0.06s - loss: 1.0301 - acc: 0.4829 - val_loss: 1.0503 - val_acc: 0.4696\n",
            "Epoch 81/100 - 0.06s - loss: 1.0295 - acc: 0.4818 - val_loss: 1.0495 - val_acc: 0.4615\n",
            "Epoch 82/100 - 0.06s - loss: 1.0289 - acc: 0.4847 - val_loss: 1.0495 - val_acc: 0.4656\n",
            "Epoch 83/100 - 0.06s - loss: 1.0282 - acc: 0.4831 - val_loss: 1.0488 - val_acc: 0.4615\n",
            "Epoch 84/100 - 0.06s - loss: 1.0277 - acc: 0.4858 - val_loss: 1.0486 - val_acc: 0.4636\n",
            "Epoch 85/100 - 0.06s - loss: 1.0270 - acc: 0.4849 - val_loss: 1.0479 - val_acc: 0.4696\n",
            "Epoch 86/100 - 0.06s - loss: 1.0264 - acc: 0.4843 - val_loss: 1.0475 - val_acc: 0.4717\n",
            "Epoch 87/100 - 0.06s - loss: 1.0258 - acc: 0.4870 - val_loss: 1.0472 - val_acc: 0.4676\n",
            "Epoch 88/100 - 0.06s - loss: 1.0252 - acc: 0.4854 - val_loss: 1.0468 - val_acc: 0.4717\n",
            "Epoch 89/100 - 0.06s - loss: 1.0247 - acc: 0.4908 - val_loss: 1.0468 - val_acc: 0.4696\n",
            "Epoch 90/100 - 0.06s - loss: 1.0241 - acc: 0.4917 - val_loss: 1.0462 - val_acc: 0.4676\n",
            "Epoch 91/100 - 0.06s - loss: 1.0235 - acc: 0.4910 - val_loss: 1.0458 - val_acc: 0.4696\n",
            "Epoch 92/100 - 0.06s - loss: 1.0229 - acc: 0.4888 - val_loss: 1.0453 - val_acc: 0.4777\n",
            "Epoch 93/100 - 0.06s - loss: 1.0223 - acc: 0.4894 - val_loss: 1.0447 - val_acc: 0.4798\n",
            "Epoch 94/100 - 0.06s - loss: 1.0217 - acc: 0.4897 - val_loss: 1.0442 - val_acc: 0.4798\n",
            "Epoch 95/100 - 0.06s - loss: 1.0211 - acc: 0.4908 - val_loss: 1.0439 - val_acc: 0.4858\n",
            "Epoch 96/100 - 0.06s - loss: 1.0205 - acc: 0.4919 - val_loss: 1.0435 - val_acc: 0.4818\n",
            "Epoch 97/100 - 0.06s - loss: 1.0199 - acc: 0.4910 - val_loss: 1.0433 - val_acc: 0.4777\n",
            "Epoch 98/100 - 0.06s - loss: 1.0193 - acc: 0.4921 - val_loss: 1.0429 - val_acc: 0.4818\n",
            "Epoch 99/100 - 0.06s - loss: 1.0188 - acc: 0.4930 - val_loss: 1.0423 - val_acc: 0.4879\n",
            "Epoch 100/100 - 0.06s - loss: 1.0182 - acc: 0.4935 - val_loss: 1.0418 - val_acc: 0.4879\n",
            "\n",
            "Combination 27/252:\n",
            "Hidden Layers: [64, 32], Activation: tanh, Learning Rate: 0.001, Batch Size: 32, Epochs: 150\n",
            "Epoch 1/150 - 0.06s - loss: 1.0930 - acc: 0.3833 - val_loss: 1.1005 - val_acc: 0.3603\n",
            "Epoch 2/150 - 0.06s - loss: 1.0893 - acc: 0.4022 - val_loss: 1.0982 - val_acc: 0.3543\n",
            "Epoch 3/150 - 0.06s - loss: 1.0868 - acc: 0.4121 - val_loss: 1.0965 - val_acc: 0.3644\n",
            "Epoch 4/150 - 0.06s - loss: 1.0846 - acc: 0.4215 - val_loss: 1.0949 - val_acc: 0.3684\n",
            "Epoch 5/150 - 0.06s - loss: 1.0826 - acc: 0.4229 - val_loss: 1.0935 - val_acc: 0.3806\n",
            "Epoch 6/150 - 0.06s - loss: 1.0808 - acc: 0.4300 - val_loss: 1.0920 - val_acc: 0.3745\n",
            "Epoch 7/150 - 0.06s - loss: 1.0790 - acc: 0.4327 - val_loss: 1.0906 - val_acc: 0.3907\n",
            "Epoch 8/150 - 0.06s - loss: 1.0773 - acc: 0.4345 - val_loss: 1.0892 - val_acc: 0.3968\n",
            "Epoch 9/150 - 0.06s - loss: 1.0757 - acc: 0.4361 - val_loss: 1.0880 - val_acc: 0.4069\n",
            "Epoch 10/150 - 0.06s - loss: 1.0741 - acc: 0.4404 - val_loss: 1.0869 - val_acc: 0.4028\n",
            "Epoch 11/150 - 0.06s - loss: 1.0726 - acc: 0.4417 - val_loss: 1.0855 - val_acc: 0.4150\n",
            "Epoch 12/150 - 0.06s - loss: 1.0712 - acc: 0.4453 - val_loss: 1.0845 - val_acc: 0.4170\n",
            "Epoch 13/150 - 0.06s - loss: 1.0698 - acc: 0.4469 - val_loss: 1.0833 - val_acc: 0.4190\n",
            "Epoch 14/150 - 0.06s - loss: 1.0685 - acc: 0.4496 - val_loss: 1.0822 - val_acc: 0.4251\n",
            "Epoch 15/150 - 0.06s - loss: 1.0673 - acc: 0.4523 - val_loss: 1.0812 - val_acc: 0.4271\n",
            "Epoch 16/150 - 0.06s - loss: 1.0660 - acc: 0.4530 - val_loss: 1.0803 - val_acc: 0.4251\n",
            "Epoch 17/150 - 0.06s - loss: 1.0648 - acc: 0.4539 - val_loss: 1.0794 - val_acc: 0.4231\n",
            "Epoch 18/150 - 0.06s - loss: 1.0636 - acc: 0.4559 - val_loss: 1.0786 - val_acc: 0.4231\n",
            "Epoch 19/150 - 0.06s - loss: 1.0625 - acc: 0.4586 - val_loss: 1.0777 - val_acc: 0.4211\n",
            "Epoch 20/150 - 0.06s - loss: 1.0614 - acc: 0.4595 - val_loss: 1.0771 - val_acc: 0.4271\n",
            "Epoch 21/150 - 0.06s - loss: 1.0603 - acc: 0.4600 - val_loss: 1.0762 - val_acc: 0.4271\n",
            "Epoch 22/150 - 0.06s - loss: 1.0592 - acc: 0.4613 - val_loss: 1.0752 - val_acc: 0.4312\n",
            "Epoch 23/150 - 0.06s - loss: 1.0582 - acc: 0.4622 - val_loss: 1.0743 - val_acc: 0.4393\n",
            "Epoch 24/150 - 0.05s - loss: 1.0572 - acc: 0.4642 - val_loss: 1.0736 - val_acc: 0.4433\n",
            "Epoch 25/150 - 0.06s - loss: 1.0562 - acc: 0.4640 - val_loss: 1.0729 - val_acc: 0.4433\n",
            "Epoch 26/150 - 0.06s - loss: 1.0553 - acc: 0.4692 - val_loss: 1.0724 - val_acc: 0.4372\n",
            "Epoch 27/150 - 0.06s - loss: 1.0543 - acc: 0.4683 - val_loss: 1.0715 - val_acc: 0.4474\n",
            "Epoch 28/150 - 0.06s - loss: 1.0533 - acc: 0.4699 - val_loss: 1.0707 - val_acc: 0.4494\n",
            "Epoch 29/150 - 0.06s - loss: 1.0524 - acc: 0.4694 - val_loss: 1.0700 - val_acc: 0.4534\n",
            "Epoch 30/150 - 0.06s - loss: 1.0515 - acc: 0.4672 - val_loss: 1.0692 - val_acc: 0.4575\n",
            "Epoch 31/150 - 0.06s - loss: 1.0506 - acc: 0.4712 - val_loss: 1.0687 - val_acc: 0.4534\n",
            "Epoch 32/150 - 0.06s - loss: 1.0497 - acc: 0.4726 - val_loss: 1.0680 - val_acc: 0.4534\n",
            "Epoch 33/150 - 0.06s - loss: 1.0488 - acc: 0.4735 - val_loss: 1.0672 - val_acc: 0.4636\n",
            "Epoch 34/150 - 0.06s - loss: 1.0480 - acc: 0.4757 - val_loss: 1.0666 - val_acc: 0.4595\n",
            "Epoch 35/150 - 0.06s - loss: 1.0471 - acc: 0.4701 - val_loss: 1.0659 - val_acc: 0.4717\n",
            "Epoch 36/150 - 0.06s - loss: 1.0463 - acc: 0.4762 - val_loss: 1.0653 - val_acc: 0.4676\n",
            "Epoch 37/150 - 0.06s - loss: 1.0454 - acc: 0.4753 - val_loss: 1.0647 - val_acc: 0.4676\n",
            "Epoch 38/150 - 0.07s - loss: 1.0446 - acc: 0.4791 - val_loss: 1.0640 - val_acc: 0.4696\n",
            "Epoch 39/150 - 0.06s - loss: 1.0438 - acc: 0.4800 - val_loss: 1.0633 - val_acc: 0.4717\n",
            "Epoch 40/150 - 0.06s - loss: 1.0430 - acc: 0.4809 - val_loss: 1.0627 - val_acc: 0.4696\n",
            "Epoch 41/150 - 0.06s - loss: 1.0422 - acc: 0.4798 - val_loss: 1.0622 - val_acc: 0.4737\n",
            "Epoch 42/150 - 0.07s - loss: 1.0414 - acc: 0.4798 - val_loss: 1.0615 - val_acc: 0.4615\n",
            "Epoch 43/150 - 0.07s - loss: 1.0406 - acc: 0.4802 - val_loss: 1.0610 - val_acc: 0.4656\n",
            "Epoch 44/150 - 0.06s - loss: 1.0399 - acc: 0.4807 - val_loss: 1.0605 - val_acc: 0.4696\n",
            "Epoch 45/150 - 0.06s - loss: 1.0391 - acc: 0.4818 - val_loss: 1.0597 - val_acc: 0.4656\n",
            "Epoch 46/150 - 0.06s - loss: 1.0383 - acc: 0.4818 - val_loss: 1.0591 - val_acc: 0.4676\n",
            "Epoch 47/150 - 0.06s - loss: 1.0376 - acc: 0.4795 - val_loss: 1.0585 - val_acc: 0.4717\n",
            "Epoch 48/150 - 0.06s - loss: 1.0369 - acc: 0.4854 - val_loss: 1.0580 - val_acc: 0.4696\n",
            "Epoch 49/150 - 0.06s - loss: 1.0361 - acc: 0.4852 - val_loss: 1.0574 - val_acc: 0.4757\n",
            "Epoch 50/150 - 0.06s - loss: 1.0354 - acc: 0.4798 - val_loss: 1.0567 - val_acc: 0.4737\n",
            "Epoch 51/150 - 0.06s - loss: 1.0347 - acc: 0.4849 - val_loss: 1.0563 - val_acc: 0.4798\n",
            "Epoch 52/150 - 0.06s - loss: 1.0339 - acc: 0.4861 - val_loss: 1.0557 - val_acc: 0.4818\n",
            "Epoch 53/150 - 0.06s - loss: 1.0332 - acc: 0.4867 - val_loss: 1.0551 - val_acc: 0.4838\n",
            "Epoch 54/150 - 0.06s - loss: 1.0326 - acc: 0.4867 - val_loss: 1.0548 - val_acc: 0.4777\n",
            "Epoch 55/150 - 0.06s - loss: 1.0318 - acc: 0.4874 - val_loss: 1.0539 - val_acc: 0.4798\n",
            "Epoch 56/150 - 0.06s - loss: 1.0311 - acc: 0.4872 - val_loss: 1.0533 - val_acc: 0.4798\n",
            "Epoch 57/150 - 0.06s - loss: 1.0304 - acc: 0.4890 - val_loss: 1.0529 - val_acc: 0.4838\n",
            "Epoch 58/150 - 0.06s - loss: 1.0298 - acc: 0.4876 - val_loss: 1.0523 - val_acc: 0.4777\n",
            "Epoch 59/150 - 0.06s - loss: 1.0291 - acc: 0.4906 - val_loss: 1.0517 - val_acc: 0.4838\n",
            "Epoch 60/150 - 0.06s - loss: 1.0284 - acc: 0.4910 - val_loss: 1.0510 - val_acc: 0.4858\n",
            "Epoch 61/150 - 0.06s - loss: 1.0277 - acc: 0.4906 - val_loss: 1.0505 - val_acc: 0.4818\n",
            "Epoch 62/150 - 0.06s - loss: 1.0270 - acc: 0.4921 - val_loss: 1.0501 - val_acc: 0.4919\n",
            "Epoch 63/150 - 0.06s - loss: 1.0264 - acc: 0.4912 - val_loss: 1.0497 - val_acc: 0.4858\n",
            "Epoch 64/150 - 0.06s - loss: 1.0257 - acc: 0.4935 - val_loss: 1.0492 - val_acc: 0.4858\n",
            "Epoch 65/150 - 0.06s - loss: 1.0251 - acc: 0.4946 - val_loss: 1.0483 - val_acc: 0.4879\n",
            "Epoch 66/150 - 0.06s - loss: 1.0244 - acc: 0.4930 - val_loss: 1.0479 - val_acc: 0.4899\n",
            "Epoch 67/150 - 0.06s - loss: 1.0237 - acc: 0.4933 - val_loss: 1.0475 - val_acc: 0.4858\n",
            "Epoch 68/150 - 0.06s - loss: 1.0231 - acc: 0.4933 - val_loss: 1.0469 - val_acc: 0.4858\n",
            "Epoch 69/150 - 0.06s - loss: 1.0224 - acc: 0.4957 - val_loss: 1.0463 - val_acc: 0.4879\n",
            "Epoch 70/150 - 0.06s - loss: 1.0218 - acc: 0.4969 - val_loss: 1.0458 - val_acc: 0.4899\n",
            "Epoch 71/150 - 0.06s - loss: 1.0212 - acc: 0.4975 - val_loss: 1.0454 - val_acc: 0.4919\n",
            "Epoch 72/150 - 0.06s - loss: 1.0205 - acc: 0.4996 - val_loss: 1.0448 - val_acc: 0.4939\n",
            "Epoch 73/150 - 0.05s - loss: 1.0199 - acc: 0.5016 - val_loss: 1.0444 - val_acc: 0.4899\n",
            "Epoch 74/150 - 0.06s - loss: 1.0192 - acc: 0.5011 - val_loss: 1.0436 - val_acc: 0.4919\n",
            "Epoch 75/150 - 0.06s - loss: 1.0186 - acc: 0.5020 - val_loss: 1.0431 - val_acc: 0.4899\n",
            "Epoch 76/150 - 0.06s - loss: 1.0180 - acc: 0.5020 - val_loss: 1.0430 - val_acc: 0.4919\n",
            "Epoch 77/150 - 0.06s - loss: 1.0174 - acc: 0.5036 - val_loss: 1.0421 - val_acc: 0.4939\n",
            "Epoch 78/150 - 0.06s - loss: 1.0168 - acc: 0.5036 - val_loss: 1.0418 - val_acc: 0.4980\n",
            "Epoch 79/150 - 0.06s - loss: 1.0161 - acc: 0.5040 - val_loss: 1.0413 - val_acc: 0.4858\n",
            "Epoch 80/150 - 0.06s - loss: 1.0155 - acc: 0.5049 - val_loss: 1.0406 - val_acc: 0.4919\n",
            "Epoch 81/150 - 0.06s - loss: 1.0149 - acc: 0.5058 - val_loss: 1.0399 - val_acc: 0.4960\n",
            "Epoch 82/150 - 0.06s - loss: 1.0143 - acc: 0.5047 - val_loss: 1.0394 - val_acc: 0.4899\n",
            "Epoch 83/150 - 0.06s - loss: 1.0137 - acc: 0.5056 - val_loss: 1.0388 - val_acc: 0.4919\n",
            "Epoch 84/150 - 0.06s - loss: 1.0131 - acc: 0.5052 - val_loss: 1.0387 - val_acc: 0.4960\n",
            "Epoch 85/150 - 0.06s - loss: 1.0125 - acc: 0.5040 - val_loss: 1.0381 - val_acc: 0.4939\n",
            "Epoch 86/150 - 0.06s - loss: 1.0119 - acc: 0.5058 - val_loss: 1.0375 - val_acc: 0.4960\n",
            "Epoch 87/150 - 0.06s - loss: 1.0112 - acc: 0.5056 - val_loss: 1.0369 - val_acc: 0.4980\n",
            "Epoch 88/150 - 0.06s - loss: 1.0106 - acc: 0.5061 - val_loss: 1.0361 - val_acc: 0.5061\n",
            "Epoch 89/150 - 0.06s - loss: 1.0100 - acc: 0.5067 - val_loss: 1.0358 - val_acc: 0.4980\n",
            "Epoch 90/150 - 0.06s - loss: 1.0095 - acc: 0.5092 - val_loss: 1.0352 - val_acc: 0.4980\n",
            "Epoch 91/150 - 0.06s - loss: 1.0089 - acc: 0.5067 - val_loss: 1.0346 - val_acc: 0.5000\n",
            "Epoch 92/150 - 0.06s - loss: 1.0085 - acc: 0.5067 - val_loss: 1.0339 - val_acc: 0.4939\n",
            "Epoch 93/150 - 0.06s - loss: 1.0076 - acc: 0.5079 - val_loss: 1.0337 - val_acc: 0.5081\n",
            "Epoch 94/150 - 0.06s - loss: 1.0071 - acc: 0.5097 - val_loss: 1.0336 - val_acc: 0.5040\n",
            "Epoch 95/150 - 0.06s - loss: 1.0065 - acc: 0.5090 - val_loss: 1.0328 - val_acc: 0.5101\n",
            "Epoch 96/150 - 0.06s - loss: 1.0059 - acc: 0.5094 - val_loss: 1.0325 - val_acc: 0.5020\n",
            "Epoch 97/150 - 0.06s - loss: 1.0054 - acc: 0.5112 - val_loss: 1.0315 - val_acc: 0.5000\n",
            "Epoch 98/150 - 0.06s - loss: 1.0048 - acc: 0.5099 - val_loss: 1.0309 - val_acc: 0.5020\n",
            "Epoch 99/150 - 0.06s - loss: 1.0042 - acc: 0.5106 - val_loss: 1.0305 - val_acc: 0.5081\n",
            "Epoch 100/150 - 0.06s - loss: 1.0036 - acc: 0.5110 - val_loss: 1.0299 - val_acc: 0.5081\n",
            "Epoch 101/150 - 0.06s - loss: 1.0030 - acc: 0.5110 - val_loss: 1.0298 - val_acc: 0.5121\n",
            "Epoch 102/150 - 0.06s - loss: 1.0024 - acc: 0.5124 - val_loss: 1.0290 - val_acc: 0.5121\n",
            "Epoch 103/150 - 0.06s - loss: 1.0018 - acc: 0.5124 - val_loss: 1.0287 - val_acc: 0.5142\n",
            "Epoch 104/150 - 0.06s - loss: 1.0012 - acc: 0.5148 - val_loss: 1.0280 - val_acc: 0.5121\n",
            "Epoch 105/150 - 0.06s - loss: 1.0007 - acc: 0.5139 - val_loss: 1.0276 - val_acc: 0.5121\n",
            "Epoch 106/150 - 0.06s - loss: 1.0001 - acc: 0.5157 - val_loss: 1.0270 - val_acc: 0.5121\n",
            "Epoch 107/150 - 0.06s - loss: 0.9997 - acc: 0.5142 - val_loss: 1.0264 - val_acc: 0.5121\n",
            "Epoch 108/150 - 0.06s - loss: 0.9991 - acc: 0.5119 - val_loss: 1.0266 - val_acc: 0.5101\n",
            "Epoch 109/150 - 0.06s - loss: 0.9985 - acc: 0.5119 - val_loss: 1.0259 - val_acc: 0.5182\n",
            "Epoch 110/150 - 0.06s - loss: 0.9979 - acc: 0.5155 - val_loss: 1.0251 - val_acc: 0.5162\n",
            "Epoch 111/150 - 0.06s - loss: 0.9973 - acc: 0.5166 - val_loss: 1.0243 - val_acc: 0.5202\n",
            "Epoch 112/150 - 0.06s - loss: 0.9967 - acc: 0.5160 - val_loss: 1.0239 - val_acc: 0.5182\n",
            "Epoch 113/150 - 0.06s - loss: 0.9963 - acc: 0.5146 - val_loss: 1.0238 - val_acc: 0.5223\n",
            "Epoch 114/150 - 0.06s - loss: 0.9956 - acc: 0.5162 - val_loss: 1.0229 - val_acc: 0.5202\n",
            "Epoch 115/150 - 0.06s - loss: 0.9952 - acc: 0.5180 - val_loss: 1.0222 - val_acc: 0.5202\n",
            "Epoch 116/150 - 0.06s - loss: 0.9945 - acc: 0.5173 - val_loss: 1.0219 - val_acc: 0.5223\n",
            "Epoch 117/150 - 0.06s - loss: 0.9940 - acc: 0.5178 - val_loss: 1.0218 - val_acc: 0.5223\n",
            "Epoch 118/150 - 0.06s - loss: 0.9936 - acc: 0.5184 - val_loss: 1.0215 - val_acc: 0.5243\n",
            "Epoch 119/150 - 0.06s - loss: 0.9929 - acc: 0.5173 - val_loss: 1.0205 - val_acc: 0.5243\n",
            "Epoch 120/150 - 0.06s - loss: 0.9925 - acc: 0.5193 - val_loss: 1.0204 - val_acc: 0.5263\n",
            "Epoch 121/150 - 0.06s - loss: 0.9918 - acc: 0.5173 - val_loss: 1.0196 - val_acc: 0.5263\n",
            "Epoch 122/150 - 0.06s - loss: 0.9914 - acc: 0.5198 - val_loss: 1.0196 - val_acc: 0.5263\n",
            "Epoch 123/150 - 0.06s - loss: 0.9907 - acc: 0.5196 - val_loss: 1.0187 - val_acc: 0.5283\n",
            "Epoch 124/150 - 0.06s - loss: 0.9904 - acc: 0.5211 - val_loss: 1.0180 - val_acc: 0.5283\n",
            "Epoch 125/150 - 0.06s - loss: 0.9896 - acc: 0.5200 - val_loss: 1.0175 - val_acc: 0.5243\n",
            "Epoch 126/150 - 0.06s - loss: 0.9892 - acc: 0.5223 - val_loss: 1.0169 - val_acc: 0.5263\n",
            "Epoch 127/150 - 0.06s - loss: 0.9887 - acc: 0.5225 - val_loss: 1.0163 - val_acc: 0.5263\n",
            "Epoch 128/150 - 0.06s - loss: 0.9881 - acc: 0.5238 - val_loss: 1.0160 - val_acc: 0.5283\n",
            "Epoch 129/150 - 0.06s - loss: 0.9875 - acc: 0.5241 - val_loss: 1.0156 - val_acc: 0.5324\n",
            "Epoch 130/150 - 0.06s - loss: 0.9872 - acc: 0.5225 - val_loss: 1.0149 - val_acc: 0.5304\n",
            "Epoch 131/150 - 0.06s - loss: 0.9866 - acc: 0.5232 - val_loss: 1.0144 - val_acc: 0.5324\n",
            "Epoch 132/150 - 0.06s - loss: 0.9863 - acc: 0.5241 - val_loss: 1.0141 - val_acc: 0.5344\n",
            "Epoch 133/150 - 0.06s - loss: 0.9857 - acc: 0.5241 - val_loss: 1.0134 - val_acc: 0.5304\n",
            "Epoch 134/150 - 0.06s - loss: 0.9849 - acc: 0.5236 - val_loss: 1.0134 - val_acc: 0.5344\n",
            "Epoch 135/150 - 0.06s - loss: 0.9844 - acc: 0.5256 - val_loss: 1.0129 - val_acc: 0.5364\n",
            "Epoch 136/150 - 0.06s - loss: 0.9839 - acc: 0.5250 - val_loss: 1.0126 - val_acc: 0.5344\n",
            "Epoch 137/150 - 0.06s - loss: 0.9835 - acc: 0.5272 - val_loss: 1.0124 - val_acc: 0.5324\n",
            "Epoch 138/150 - 0.07s - loss: 0.9829 - acc: 0.5261 - val_loss: 1.0115 - val_acc: 0.5385\n",
            "Epoch 139/150 - 0.06s - loss: 0.9824 - acc: 0.5256 - val_loss: 1.0110 - val_acc: 0.5385\n",
            "Epoch 140/150 - 0.06s - loss: 0.9821 - acc: 0.5290 - val_loss: 1.0102 - val_acc: 0.5364\n",
            "Epoch 141/150 - 0.06s - loss: 0.9814 - acc: 0.5283 - val_loss: 1.0099 - val_acc: 0.5364\n",
            "Epoch 142/150 - 0.06s - loss: 0.9810 - acc: 0.5277 - val_loss: 1.0101 - val_acc: 0.5344\n",
            "Epoch 143/150 - 0.06s - loss: 0.9805 - acc: 0.5286 - val_loss: 1.0089 - val_acc: 0.5364\n",
            "Epoch 144/150 - 0.06s - loss: 0.9800 - acc: 0.5290 - val_loss: 1.0085 - val_acc: 0.5364\n",
            "Epoch 145/150 - 0.06s - loss: 0.9796 - acc: 0.5297 - val_loss: 1.0089 - val_acc: 0.5324\n",
            "Epoch 146/150 - 0.06s - loss: 0.9794 - acc: 0.5306 - val_loss: 1.0090 - val_acc: 0.5223\n",
            "Epoch 147/150 - 0.06s - loss: 0.9787 - acc: 0.5304 - val_loss: 1.0080 - val_acc: 0.5324\n",
            "Epoch 148/150 - 0.06s - loss: 0.9779 - acc: 0.5304 - val_loss: 1.0069 - val_acc: 0.5344\n",
            "Epoch 149/150 - 0.06s - loss: 0.9775 - acc: 0.5304 - val_loss: 1.0064 - val_acc: 0.5344\n",
            "Epoch 150/150 - 0.06s - loss: 0.9770 - acc: 0.5288 - val_loss: 1.0062 - val_acc: 0.5405\n",
            "\n",
            "Combination 28/252:\n",
            "Hidden Layers: [64, 32], Activation: tanh, Learning Rate: 0.001, Batch Size: 64, Epochs: 50\n",
            "Epoch 1/50 - 0.05s - loss: 1.1024 - acc: 0.3475 - val_loss: 1.0983 - val_acc: 0.3664\n",
            "Epoch 2/50 - 0.04s - loss: 1.1002 - acc: 0.3466 - val_loss: 1.0954 - val_acc: 0.3846\n",
            "Epoch 3/50 - 0.04s - loss: 1.0990 - acc: 0.3486 - val_loss: 1.0939 - val_acc: 0.3745\n",
            "Epoch 4/50 - 0.04s - loss: 1.0981 - acc: 0.3500 - val_loss: 1.0929 - val_acc: 0.3603\n",
            "Epoch 5/50 - 0.04s - loss: 1.0973 - acc: 0.3516 - val_loss: 1.0920 - val_acc: 0.3704\n",
            "Epoch 6/50 - 0.04s - loss: 1.0966 - acc: 0.3549 - val_loss: 1.0912 - val_acc: 0.3765\n",
            "Epoch 7/50 - 0.04s - loss: 1.0959 - acc: 0.3567 - val_loss: 1.0905 - val_acc: 0.3704\n",
            "Epoch 8/50 - 0.05s - loss: 1.0953 - acc: 0.3605 - val_loss: 1.0898 - val_acc: 0.3725\n",
            "Epoch 9/50 - 0.04s - loss: 1.0946 - acc: 0.3646 - val_loss: 1.0892 - val_acc: 0.3765\n",
            "Epoch 10/50 - 0.05s - loss: 1.0940 - acc: 0.3664 - val_loss: 1.0886 - val_acc: 0.3785\n",
            "Epoch 11/50 - 0.05s - loss: 1.0934 - acc: 0.3686 - val_loss: 1.0880 - val_acc: 0.3725\n",
            "Epoch 12/50 - 0.05s - loss: 1.0928 - acc: 0.3738 - val_loss: 1.0875 - val_acc: 0.3785\n",
            "Epoch 13/50 - 0.04s - loss: 1.0922 - acc: 0.3754 - val_loss: 1.0870 - val_acc: 0.3745\n",
            "Epoch 14/50 - 0.05s - loss: 1.0916 - acc: 0.3767 - val_loss: 1.0865 - val_acc: 0.3725\n",
            "Epoch 15/50 - 0.05s - loss: 1.0910 - acc: 0.3790 - val_loss: 1.0860 - val_acc: 0.3765\n",
            "Epoch 16/50 - 0.05s - loss: 1.0905 - acc: 0.3806 - val_loss: 1.0855 - val_acc: 0.3826\n",
            "Epoch 17/50 - 0.05s - loss: 1.0900 - acc: 0.3830 - val_loss: 1.0851 - val_acc: 0.3887\n",
            "Epoch 18/50 - 0.05s - loss: 1.0894 - acc: 0.3869 - val_loss: 1.0846 - val_acc: 0.3968\n",
            "Epoch 19/50 - 0.04s - loss: 1.0889 - acc: 0.3866 - val_loss: 1.0841 - val_acc: 0.3927\n",
            "Epoch 20/50 - 0.05s - loss: 1.0884 - acc: 0.3902 - val_loss: 1.0837 - val_acc: 0.4049\n",
            "Epoch 21/50 - 0.05s - loss: 1.0879 - acc: 0.3936 - val_loss: 1.0832 - val_acc: 0.4069\n",
            "Epoch 22/50 - 0.05s - loss: 1.0873 - acc: 0.3941 - val_loss: 1.0828 - val_acc: 0.4109\n",
            "Epoch 23/50 - 0.05s - loss: 1.0869 - acc: 0.3932 - val_loss: 1.0823 - val_acc: 0.4130\n",
            "Epoch 24/50 - 0.04s - loss: 1.0864 - acc: 0.3938 - val_loss: 1.0819 - val_acc: 0.4150\n",
            "Epoch 25/50 - 0.05s - loss: 1.0859 - acc: 0.3952 - val_loss: 1.0815 - val_acc: 0.4170\n",
            "Epoch 26/50 - 0.05s - loss: 1.0854 - acc: 0.3999 - val_loss: 1.0811 - val_acc: 0.4150\n",
            "Epoch 27/50 - 0.05s - loss: 1.0849 - acc: 0.4046 - val_loss: 1.0807 - val_acc: 0.4211\n",
            "Epoch 28/50 - 0.05s - loss: 1.0845 - acc: 0.4053 - val_loss: 1.0803 - val_acc: 0.4231\n",
            "Epoch 29/50 - 0.04s - loss: 1.0840 - acc: 0.4053 - val_loss: 1.0799 - val_acc: 0.4231\n",
            "Epoch 30/50 - 0.05s - loss: 1.0836 - acc: 0.4064 - val_loss: 1.0796 - val_acc: 0.4251\n",
            "Epoch 31/50 - 0.05s - loss: 1.0832 - acc: 0.4060 - val_loss: 1.0792 - val_acc: 0.4271\n",
            "Epoch 32/50 - 0.04s - loss: 1.0827 - acc: 0.4082 - val_loss: 1.0788 - val_acc: 0.4271\n",
            "Epoch 33/50 - 0.04s - loss: 1.0823 - acc: 0.4096 - val_loss: 1.0784 - val_acc: 0.4271\n",
            "Epoch 34/50 - 0.05s - loss: 1.0819 - acc: 0.4103 - val_loss: 1.0781 - val_acc: 0.4332\n",
            "Epoch 35/50 - 0.04s - loss: 1.0814 - acc: 0.4116 - val_loss: 1.0777 - val_acc: 0.4372\n",
            "Epoch 36/50 - 0.04s - loss: 1.0810 - acc: 0.4157 - val_loss: 1.0774 - val_acc: 0.4393\n",
            "Epoch 37/50 - 0.04s - loss: 1.0806 - acc: 0.4186 - val_loss: 1.0770 - val_acc: 0.4433\n",
            "Epoch 38/50 - 0.04s - loss: 1.0802 - acc: 0.4186 - val_loss: 1.0767 - val_acc: 0.4413\n",
            "Epoch 39/50 - 0.04s - loss: 1.0798 - acc: 0.4220 - val_loss: 1.0764 - val_acc: 0.4453\n",
            "Epoch 40/50 - 0.04s - loss: 1.0794 - acc: 0.4220 - val_loss: 1.0761 - val_acc: 0.4433\n",
            "Epoch 41/50 - 0.05s - loss: 1.0790 - acc: 0.4222 - val_loss: 1.0757 - val_acc: 0.4453\n",
            "Epoch 42/50 - 0.04s - loss: 1.0786 - acc: 0.4220 - val_loss: 1.0754 - val_acc: 0.4393\n",
            "Epoch 43/50 - 0.04s - loss: 1.0782 - acc: 0.4213 - val_loss: 1.0751 - val_acc: 0.4393\n",
            "Epoch 44/50 - 0.04s - loss: 1.0778 - acc: 0.4222 - val_loss: 1.0748 - val_acc: 0.4372\n",
            "Epoch 45/50 - 0.04s - loss: 1.0774 - acc: 0.4249 - val_loss: 1.0745 - val_acc: 0.4433\n",
            "Epoch 46/50 - 0.05s - loss: 1.0771 - acc: 0.4271 - val_loss: 1.0742 - val_acc: 0.4433\n",
            "Epoch 47/50 - 0.05s - loss: 1.0767 - acc: 0.4285 - val_loss: 1.0738 - val_acc: 0.4453\n",
            "Epoch 48/50 - 0.04s - loss: 1.0763 - acc: 0.4307 - val_loss: 1.0735 - val_acc: 0.4413\n",
            "Epoch 49/50 - 0.04s - loss: 1.0760 - acc: 0.4341 - val_loss: 1.0732 - val_acc: 0.4393\n",
            "Epoch 50/50 - 0.04s - loss: 1.0756 - acc: 0.4339 - val_loss: 1.0729 - val_acc: 0.4393\n",
            "\n",
            "Combination 29/252:\n",
            "Hidden Layers: [64, 32], Activation: tanh, Learning Rate: 0.001, Batch Size: 64, Epochs: 100\n",
            "Epoch 1/100 - 0.04s - loss: 1.1014 - acc: 0.3052 - val_loss: 1.1029 - val_acc: 0.3138\n",
            "Epoch 2/100 - 0.04s - loss: 1.1000 - acc: 0.3219 - val_loss: 1.1011 - val_acc: 0.3462\n",
            "Epoch 3/100 - 0.04s - loss: 1.0988 - acc: 0.3286 - val_loss: 1.0997 - val_acc: 0.3522\n",
            "Epoch 4/100 - 0.04s - loss: 1.0977 - acc: 0.3363 - val_loss: 1.0986 - val_acc: 0.3543\n",
            "Epoch 5/100 - 0.04s - loss: 1.0967 - acc: 0.3459 - val_loss: 1.0975 - val_acc: 0.3583\n",
            "Epoch 6/100 - 0.05s - loss: 1.0958 - acc: 0.3563 - val_loss: 1.0966 - val_acc: 0.3745\n",
            "Epoch 7/100 - 0.04s - loss: 1.0948 - acc: 0.3599 - val_loss: 1.0957 - val_acc: 0.3785\n",
            "Epoch 8/100 - 0.04s - loss: 1.0939 - acc: 0.3707 - val_loss: 1.0948 - val_acc: 0.3745\n",
            "Epoch 9/100 - 0.05s - loss: 1.0930 - acc: 0.3774 - val_loss: 1.0940 - val_acc: 0.3846\n",
            "Epoch 10/100 - 0.04s - loss: 1.0921 - acc: 0.3860 - val_loss: 1.0931 - val_acc: 0.3866\n",
            "Epoch 11/100 - 0.04s - loss: 1.0913 - acc: 0.3945 - val_loss: 1.0924 - val_acc: 0.3826\n",
            "Epoch 12/100 - 0.04s - loss: 1.0905 - acc: 0.3936 - val_loss: 1.0917 - val_acc: 0.3846\n",
            "Epoch 13/100 - 0.04s - loss: 1.0896 - acc: 0.3979 - val_loss: 1.0909 - val_acc: 0.3826\n",
            "Epoch 14/100 - 0.05s - loss: 1.0888 - acc: 0.3997 - val_loss: 1.0901 - val_acc: 0.3806\n",
            "Epoch 15/100 - 0.04s - loss: 1.0880 - acc: 0.4017 - val_loss: 1.0894 - val_acc: 0.3826\n",
            "Epoch 16/100 - 0.05s - loss: 1.0873 - acc: 0.4044 - val_loss: 1.0888 - val_acc: 0.3826\n",
            "Epoch 17/100 - 0.04s - loss: 1.0866 - acc: 0.4071 - val_loss: 1.0880 - val_acc: 0.3927\n",
            "Epoch 18/100 - 0.04s - loss: 1.0858 - acc: 0.4107 - val_loss: 1.0874 - val_acc: 0.3947\n",
            "Epoch 19/100 - 0.04s - loss: 1.0851 - acc: 0.4132 - val_loss: 1.0867 - val_acc: 0.4008\n",
            "Epoch 20/100 - 0.04s - loss: 1.0844 - acc: 0.4141 - val_loss: 1.0860 - val_acc: 0.4028\n",
            "Epoch 21/100 - 0.04s - loss: 1.0837 - acc: 0.4163 - val_loss: 1.0854 - val_acc: 0.4028\n",
            "Epoch 22/100 - 0.04s - loss: 1.0830 - acc: 0.4166 - val_loss: 1.0848 - val_acc: 0.4069\n",
            "Epoch 23/100 - 0.04s - loss: 1.0823 - acc: 0.4181 - val_loss: 1.0843 - val_acc: 0.4109\n",
            "Epoch 24/100 - 0.04s - loss: 1.0817 - acc: 0.4188 - val_loss: 1.0837 - val_acc: 0.4150\n",
            "Epoch 25/100 - 0.04s - loss: 1.0811 - acc: 0.4186 - val_loss: 1.0832 - val_acc: 0.4190\n",
            "Epoch 26/100 - 0.05s - loss: 1.0804 - acc: 0.4204 - val_loss: 1.0825 - val_acc: 0.4190\n",
            "Epoch 27/100 - 0.04s - loss: 1.0798 - acc: 0.4217 - val_loss: 1.0819 - val_acc: 0.4211\n",
            "Epoch 28/100 - 0.04s - loss: 1.0792 - acc: 0.4220 - val_loss: 1.0814 - val_acc: 0.4170\n",
            "Epoch 29/100 - 0.04s - loss: 1.0786 - acc: 0.4240 - val_loss: 1.0808 - val_acc: 0.4109\n",
            "Epoch 30/100 - 0.04s - loss: 1.0781 - acc: 0.4247 - val_loss: 1.0804 - val_acc: 0.4150\n",
            "Epoch 31/100 - 0.05s - loss: 1.0775 - acc: 0.4258 - val_loss: 1.0799 - val_acc: 0.4150\n",
            "Epoch 32/100 - 0.04s - loss: 1.0769 - acc: 0.4260 - val_loss: 1.0793 - val_acc: 0.4170\n",
            "Epoch 33/100 - 0.04s - loss: 1.0764 - acc: 0.4251 - val_loss: 1.0789 - val_acc: 0.4251\n",
            "Epoch 34/100 - 0.04s - loss: 1.0758 - acc: 0.4247 - val_loss: 1.0784 - val_acc: 0.4251\n",
            "Epoch 35/100 - 0.04s - loss: 1.0753 - acc: 0.4265 - val_loss: 1.0780 - val_acc: 0.4251\n",
            "Epoch 36/100 - 0.04s - loss: 1.0747 - acc: 0.4278 - val_loss: 1.0775 - val_acc: 0.4170\n",
            "Epoch 37/100 - 0.04s - loss: 1.0742 - acc: 0.4305 - val_loss: 1.0770 - val_acc: 0.4211\n",
            "Epoch 38/100 - 0.04s - loss: 1.0737 - acc: 0.4314 - val_loss: 1.0765 - val_acc: 0.4211\n",
            "Epoch 39/100 - 0.04s - loss: 1.0732 - acc: 0.4350 - val_loss: 1.0760 - val_acc: 0.4251\n",
            "Epoch 40/100 - 0.04s - loss: 1.0727 - acc: 0.4341 - val_loss: 1.0757 - val_acc: 0.4231\n",
            "Epoch 41/100 - 0.04s - loss: 1.0722 - acc: 0.4352 - val_loss: 1.0752 - val_acc: 0.4251\n",
            "Epoch 42/100 - 0.04s - loss: 1.0717 - acc: 0.4357 - val_loss: 1.0748 - val_acc: 0.4312\n",
            "Epoch 43/100 - 0.04s - loss: 1.0712 - acc: 0.4379 - val_loss: 1.0745 - val_acc: 0.4271\n",
            "Epoch 44/100 - 0.04s - loss: 1.0707 - acc: 0.4379 - val_loss: 1.0740 - val_acc: 0.4291\n",
            "Epoch 45/100 - 0.04s - loss: 1.0703 - acc: 0.4395 - val_loss: 1.0737 - val_acc: 0.4291\n",
            "Epoch 46/100 - 0.05s - loss: 1.0698 - acc: 0.4397 - val_loss: 1.0732 - val_acc: 0.4312\n",
            "Epoch 47/100 - 0.04s - loss: 1.0694 - acc: 0.4422 - val_loss: 1.0728 - val_acc: 0.4352\n",
            "Epoch 48/100 - 0.04s - loss: 1.0689 - acc: 0.4406 - val_loss: 1.0725 - val_acc: 0.4332\n",
            "Epoch 49/100 - 0.05s - loss: 1.0685 - acc: 0.4440 - val_loss: 1.0721 - val_acc: 0.4393\n",
            "Epoch 50/100 - 0.04s - loss: 1.0680 - acc: 0.4453 - val_loss: 1.0717 - val_acc: 0.4433\n",
            "Epoch 51/100 - 0.04s - loss: 1.0676 - acc: 0.4462 - val_loss: 1.0713 - val_acc: 0.4413\n",
            "Epoch 52/100 - 0.04s - loss: 1.0672 - acc: 0.4458 - val_loss: 1.0710 - val_acc: 0.4413\n",
            "Epoch 53/100 - 0.04s - loss: 1.0667 - acc: 0.4467 - val_loss: 1.0706 - val_acc: 0.4413\n",
            "Epoch 54/100 - 0.05s - loss: 1.0663 - acc: 0.4480 - val_loss: 1.0703 - val_acc: 0.4453\n",
            "Epoch 55/100 - 0.04s - loss: 1.0659 - acc: 0.4501 - val_loss: 1.0699 - val_acc: 0.4453\n",
            "Epoch 56/100 - 0.05s - loss: 1.0655 - acc: 0.4507 - val_loss: 1.0695 - val_acc: 0.4474\n",
            "Epoch 57/100 - 0.04s - loss: 1.0651 - acc: 0.4503 - val_loss: 1.0693 - val_acc: 0.4453\n",
            "Epoch 58/100 - 0.04s - loss: 1.0647 - acc: 0.4505 - val_loss: 1.0690 - val_acc: 0.4474\n",
            "Epoch 59/100 - 0.04s - loss: 1.0643 - acc: 0.4519 - val_loss: 1.0686 - val_acc: 0.4514\n",
            "Epoch 60/100 - 0.04s - loss: 1.0639 - acc: 0.4516 - val_loss: 1.0682 - val_acc: 0.4494\n",
            "Epoch 61/100 - 0.04s - loss: 1.0635 - acc: 0.4516 - val_loss: 1.0679 - val_acc: 0.4514\n",
            "Epoch 62/100 - 0.04s - loss: 1.0631 - acc: 0.4528 - val_loss: 1.0677 - val_acc: 0.4534\n",
            "Epoch 63/100 - 0.04s - loss: 1.0627 - acc: 0.4521 - val_loss: 1.0673 - val_acc: 0.4555\n",
            "Epoch 64/100 - 0.04s - loss: 1.0623 - acc: 0.4528 - val_loss: 1.0670 - val_acc: 0.4555\n",
            "Epoch 65/100 - 0.04s - loss: 1.0619 - acc: 0.4525 - val_loss: 1.0666 - val_acc: 0.4555\n",
            "Epoch 66/100 - 0.05s - loss: 1.0616 - acc: 0.4519 - val_loss: 1.0664 - val_acc: 0.4575\n",
            "Epoch 67/100 - 0.04s - loss: 1.0612 - acc: 0.4523 - val_loss: 1.0661 - val_acc: 0.4555\n",
            "Epoch 68/100 - 0.04s - loss: 1.0608 - acc: 0.4532 - val_loss: 1.0658 - val_acc: 0.4534\n",
            "Epoch 69/100 - 0.04s - loss: 1.0604 - acc: 0.4528 - val_loss: 1.0655 - val_acc: 0.4555\n",
            "Epoch 70/100 - 0.05s - loss: 1.0601 - acc: 0.4539 - val_loss: 1.0652 - val_acc: 0.4555\n",
            "Epoch 71/100 - 0.05s - loss: 1.0597 - acc: 0.4546 - val_loss: 1.0649 - val_acc: 0.4555\n",
            "Epoch 72/100 - 0.04s - loss: 1.0593 - acc: 0.4546 - val_loss: 1.0646 - val_acc: 0.4575\n",
            "Epoch 73/100 - 0.04s - loss: 1.0590 - acc: 0.4555 - val_loss: 1.0643 - val_acc: 0.4595\n",
            "Epoch 74/100 - 0.04s - loss: 1.0586 - acc: 0.4550 - val_loss: 1.0640 - val_acc: 0.4656\n",
            "Epoch 75/100 - 0.04s - loss: 1.0583 - acc: 0.4552 - val_loss: 1.0637 - val_acc: 0.4636\n",
            "Epoch 76/100 - 0.05s - loss: 1.0579 - acc: 0.4552 - val_loss: 1.0634 - val_acc: 0.4656\n",
            "Epoch 77/100 - 0.04s - loss: 1.0576 - acc: 0.4561 - val_loss: 1.0631 - val_acc: 0.4676\n",
            "Epoch 78/100 - 0.04s - loss: 1.0572 - acc: 0.4566 - val_loss: 1.0629 - val_acc: 0.4676\n",
            "Epoch 79/100 - 0.04s - loss: 1.0569 - acc: 0.4566 - val_loss: 1.0627 - val_acc: 0.4676\n",
            "Epoch 80/100 - 0.04s - loss: 1.0565 - acc: 0.4570 - val_loss: 1.0624 - val_acc: 0.4676\n",
            "Epoch 81/100 - 0.05s - loss: 1.0562 - acc: 0.4584 - val_loss: 1.0622 - val_acc: 0.4656\n",
            "Epoch 82/100 - 0.04s - loss: 1.0559 - acc: 0.4584 - val_loss: 1.0619 - val_acc: 0.4656\n",
            "Epoch 83/100 - 0.04s - loss: 1.0555 - acc: 0.4575 - val_loss: 1.0616 - val_acc: 0.4656\n",
            "Epoch 84/100 - 0.04s - loss: 1.0552 - acc: 0.4573 - val_loss: 1.0613 - val_acc: 0.4676\n",
            "Epoch 85/100 - 0.04s - loss: 1.0549 - acc: 0.4600 - val_loss: 1.0611 - val_acc: 0.4676\n",
            "Epoch 86/100 - 0.05s - loss: 1.0545 - acc: 0.4586 - val_loss: 1.0609 - val_acc: 0.4636\n",
            "Epoch 87/100 - 0.04s - loss: 1.0542 - acc: 0.4613 - val_loss: 1.0605 - val_acc: 0.4676\n",
            "Epoch 88/100 - 0.04s - loss: 1.0539 - acc: 0.4613 - val_loss: 1.0603 - val_acc: 0.4676\n",
            "Epoch 89/100 - 0.04s - loss: 1.0536 - acc: 0.4622 - val_loss: 1.0599 - val_acc: 0.4595\n",
            "Epoch 90/100 - 0.04s - loss: 1.0532 - acc: 0.4622 - val_loss: 1.0598 - val_acc: 0.4636\n",
            "Epoch 91/100 - 0.04s - loss: 1.0529 - acc: 0.4620 - val_loss: 1.0596 - val_acc: 0.4656\n",
            "Epoch 92/100 - 0.04s - loss: 1.0526 - acc: 0.4636 - val_loss: 1.0593 - val_acc: 0.4615\n",
            "Epoch 93/100 - 0.04s - loss: 1.0523 - acc: 0.4636 - val_loss: 1.0590 - val_acc: 0.4636\n",
            "Epoch 94/100 - 0.04s - loss: 1.0519 - acc: 0.4636 - val_loss: 1.0588 - val_acc: 0.4636\n",
            "Epoch 95/100 - 0.04s - loss: 1.0516 - acc: 0.4640 - val_loss: 1.0586 - val_acc: 0.4615\n",
            "Epoch 96/100 - 0.04s - loss: 1.0513 - acc: 0.4640 - val_loss: 1.0584 - val_acc: 0.4656\n",
            "Epoch 97/100 - 0.04s - loss: 1.0510 - acc: 0.4647 - val_loss: 1.0581 - val_acc: 0.4615\n",
            "Epoch 98/100 - 0.04s - loss: 1.0507 - acc: 0.4640 - val_loss: 1.0579 - val_acc: 0.4615\n",
            "Epoch 99/100 - 0.04s - loss: 1.0504 - acc: 0.4649 - val_loss: 1.0576 - val_acc: 0.4636\n",
            "Epoch 100/100 - 0.04s - loss: 1.0501 - acc: 0.4665 - val_loss: 1.0574 - val_acc: 0.4696\n",
            "\n",
            "Combination 30/252:\n",
            "Hidden Layers: [64, 32], Activation: tanh, Learning Rate: 0.001, Batch Size: 64, Epochs: 150\n",
            "Epoch 1/150 - 0.04s - loss: 1.1041 - acc: 0.3183 - val_loss: 1.1053 - val_acc: 0.3239\n",
            "Epoch 2/150 - 0.04s - loss: 1.1017 - acc: 0.3270 - val_loss: 1.1037 - val_acc: 0.3421\n",
            "Epoch 3/150 - 0.05s - loss: 1.1003 - acc: 0.3291 - val_loss: 1.1027 - val_acc: 0.3462\n",
            "Epoch 4/150 - 0.04s - loss: 1.0992 - acc: 0.3363 - val_loss: 1.1020 - val_acc: 0.3623\n",
            "Epoch 5/150 - 0.04s - loss: 1.0983 - acc: 0.3455 - val_loss: 1.1013 - val_acc: 0.3563\n",
            "Epoch 6/150 - 0.04s - loss: 1.0974 - acc: 0.3511 - val_loss: 1.1007 - val_acc: 0.3583\n",
            "Epoch 7/150 - 0.04s - loss: 1.0966 - acc: 0.3547 - val_loss: 1.1000 - val_acc: 0.3603\n",
            "Epoch 8/150 - 0.04s - loss: 1.0958 - acc: 0.3590 - val_loss: 1.0994 - val_acc: 0.3583\n",
            "Epoch 9/150 - 0.04s - loss: 1.0950 - acc: 0.3621 - val_loss: 1.0988 - val_acc: 0.3623\n",
            "Epoch 10/150 - 0.04s - loss: 1.0943 - acc: 0.3646 - val_loss: 1.0981 - val_acc: 0.3644\n",
            "Epoch 11/150 - 0.04s - loss: 1.0936 - acc: 0.3698 - val_loss: 1.0976 - val_acc: 0.3704\n",
            "Epoch 12/150 - 0.04s - loss: 1.0929 - acc: 0.3718 - val_loss: 1.0969 - val_acc: 0.3725\n",
            "Epoch 13/150 - 0.05s - loss: 1.0922 - acc: 0.3761 - val_loss: 1.0964 - val_acc: 0.3725\n",
            "Epoch 14/150 - 0.04s - loss: 1.0915 - acc: 0.3783 - val_loss: 1.0958 - val_acc: 0.3785\n",
            "Epoch 15/150 - 0.04s - loss: 1.0908 - acc: 0.3799 - val_loss: 1.0952 - val_acc: 0.3806\n",
            "Epoch 16/150 - 0.05s - loss: 1.0902 - acc: 0.3810 - val_loss: 1.0947 - val_acc: 0.3826\n",
            "Epoch 17/150 - 0.04s - loss: 1.0896 - acc: 0.3819 - val_loss: 1.0941 - val_acc: 0.3826\n",
            "Epoch 18/150 - 0.04s - loss: 1.0890 - acc: 0.3819 - val_loss: 1.0936 - val_acc: 0.3846\n",
            "Epoch 19/150 - 0.04s - loss: 1.0883 - acc: 0.3833 - val_loss: 1.0931 - val_acc: 0.3866\n",
            "Epoch 20/150 - 0.04s - loss: 1.0878 - acc: 0.3821 - val_loss: 1.0926 - val_acc: 0.3866\n",
            "Epoch 21/150 - 0.05s - loss: 1.0872 - acc: 0.3844 - val_loss: 1.0921 - val_acc: 0.3866\n",
            "Epoch 22/150 - 0.04s - loss: 1.0866 - acc: 0.3857 - val_loss: 1.0916 - val_acc: 0.3887\n",
            "Epoch 23/150 - 0.04s - loss: 1.0860 - acc: 0.3878 - val_loss: 1.0911 - val_acc: 0.3846\n",
            "Epoch 24/150 - 0.04s - loss: 1.0855 - acc: 0.3898 - val_loss: 1.0906 - val_acc: 0.3826\n",
            "Epoch 25/150 - 0.05s - loss: 1.0849 - acc: 0.3929 - val_loss: 1.0902 - val_acc: 0.3765\n",
            "Epoch 26/150 - 0.05s - loss: 1.0844 - acc: 0.3936 - val_loss: 1.0898 - val_acc: 0.3785\n",
            "Epoch 27/150 - 0.05s - loss: 1.0839 - acc: 0.3947 - val_loss: 1.0893 - val_acc: 0.3826\n",
            "Epoch 28/150 - 0.04s - loss: 1.0834 - acc: 0.3968 - val_loss: 1.0889 - val_acc: 0.3927\n",
            "Epoch 29/150 - 0.04s - loss: 1.0828 - acc: 0.4033 - val_loss: 1.0885 - val_acc: 0.3968\n",
            "Epoch 30/150 - 0.04s - loss: 1.0823 - acc: 0.4040 - val_loss: 1.0881 - val_acc: 0.3968\n",
            "Epoch 31/150 - 0.05s - loss: 1.0818 - acc: 0.4073 - val_loss: 1.0876 - val_acc: 0.3968\n",
            "Epoch 32/150 - 0.04s - loss: 1.0813 - acc: 0.4087 - val_loss: 1.0872 - val_acc: 0.3968\n",
            "Epoch 33/150 - 0.04s - loss: 1.0808 - acc: 0.4123 - val_loss: 1.0868 - val_acc: 0.3947\n",
            "Epoch 34/150 - 0.04s - loss: 1.0804 - acc: 0.4127 - val_loss: 1.0865 - val_acc: 0.3988\n",
            "Epoch 35/150 - 0.04s - loss: 1.0799 - acc: 0.4163 - val_loss: 1.0861 - val_acc: 0.3988\n",
            "Epoch 36/150 - 0.05s - loss: 1.0794 - acc: 0.4179 - val_loss: 1.0856 - val_acc: 0.4008\n",
            "Epoch 37/150 - 0.04s - loss: 1.0789 - acc: 0.4217 - val_loss: 1.0853 - val_acc: 0.4049\n",
            "Epoch 38/150 - 0.04s - loss: 1.0785 - acc: 0.4229 - val_loss: 1.0848 - val_acc: 0.4109\n",
            "Epoch 39/150 - 0.04s - loss: 1.0780 - acc: 0.4235 - val_loss: 1.0845 - val_acc: 0.4130\n",
            "Epoch 40/150 - 0.04s - loss: 1.0776 - acc: 0.4251 - val_loss: 1.0841 - val_acc: 0.4089\n",
            "Epoch 41/150 - 0.05s - loss: 1.0771 - acc: 0.4260 - val_loss: 1.0838 - val_acc: 0.4089\n",
            "Epoch 42/150 - 0.04s - loss: 1.0767 - acc: 0.4265 - val_loss: 1.0834 - val_acc: 0.4089\n",
            "Epoch 43/150 - 0.04s - loss: 1.0762 - acc: 0.4271 - val_loss: 1.0831 - val_acc: 0.4109\n",
            "Epoch 44/150 - 0.04s - loss: 1.0758 - acc: 0.4283 - val_loss: 1.0827 - val_acc: 0.4170\n",
            "Epoch 45/150 - 0.04s - loss: 1.0754 - acc: 0.4323 - val_loss: 1.0824 - val_acc: 0.4150\n",
            "Epoch 46/150 - 0.05s - loss: 1.0749 - acc: 0.4318 - val_loss: 1.0820 - val_acc: 0.4150\n",
            "Epoch 47/150 - 0.04s - loss: 1.0745 - acc: 0.4334 - val_loss: 1.0817 - val_acc: 0.4231\n",
            "Epoch 48/150 - 0.05s - loss: 1.0741 - acc: 0.4336 - val_loss: 1.0814 - val_acc: 0.4231\n",
            "Epoch 49/150 - 0.04s - loss: 1.0737 - acc: 0.4327 - val_loss: 1.0810 - val_acc: 0.4271\n",
            "Epoch 50/150 - 0.04s - loss: 1.0733 - acc: 0.4341 - val_loss: 1.0807 - val_acc: 0.4211\n",
            "Epoch 51/150 - 0.05s - loss: 1.0728 - acc: 0.4370 - val_loss: 1.0803 - val_acc: 0.4231\n",
            "Epoch 52/150 - 0.05s - loss: 1.0724 - acc: 0.4375 - val_loss: 1.0800 - val_acc: 0.4211\n",
            "Epoch 53/150 - 0.05s - loss: 1.0720 - acc: 0.4386 - val_loss: 1.0797 - val_acc: 0.4150\n",
            "Epoch 54/150 - 0.05s - loss: 1.0716 - acc: 0.4408 - val_loss: 1.0794 - val_acc: 0.4150\n",
            "Epoch 55/150 - 0.05s - loss: 1.0712 - acc: 0.4408 - val_loss: 1.0791 - val_acc: 0.4170\n",
            "Epoch 56/150 - 0.05s - loss: 1.0708 - acc: 0.4435 - val_loss: 1.0788 - val_acc: 0.4211\n",
            "Epoch 57/150 - 0.05s - loss: 1.0704 - acc: 0.4442 - val_loss: 1.0785 - val_acc: 0.4211\n",
            "Epoch 58/150 - 0.04s - loss: 1.0700 - acc: 0.4447 - val_loss: 1.0782 - val_acc: 0.4190\n",
            "Epoch 59/150 - 0.04s - loss: 1.0696 - acc: 0.4456 - val_loss: 1.0779 - val_acc: 0.4190\n",
            "Epoch 60/150 - 0.05s - loss: 1.0692 - acc: 0.4444 - val_loss: 1.0776 - val_acc: 0.4211\n",
            "Epoch 61/150 - 0.05s - loss: 1.0688 - acc: 0.4435 - val_loss: 1.0773 - val_acc: 0.4291\n",
            "Epoch 62/150 - 0.04s - loss: 1.0684 - acc: 0.4442 - val_loss: 1.0770 - val_acc: 0.4291\n",
            "Epoch 63/150 - 0.04s - loss: 1.0680 - acc: 0.4460 - val_loss: 1.0767 - val_acc: 0.4291\n",
            "Epoch 64/150 - 0.04s - loss: 1.0676 - acc: 0.4467 - val_loss: 1.0764 - val_acc: 0.4332\n",
            "Epoch 65/150 - 0.04s - loss: 1.0672 - acc: 0.4476 - val_loss: 1.0761 - val_acc: 0.4352\n",
            "Epoch 66/150 - 0.04s - loss: 1.0669 - acc: 0.4485 - val_loss: 1.0758 - val_acc: 0.4332\n",
            "Epoch 67/150 - 0.04s - loss: 1.0665 - acc: 0.4498 - val_loss: 1.0755 - val_acc: 0.4352\n",
            "Epoch 68/150 - 0.05s - loss: 1.0661 - acc: 0.4521 - val_loss: 1.0753 - val_acc: 0.4352\n",
            "Epoch 69/150 - 0.04s - loss: 1.0657 - acc: 0.4516 - val_loss: 1.0750 - val_acc: 0.4352\n",
            "Epoch 70/150 - 0.04s - loss: 1.0653 - acc: 0.4514 - val_loss: 1.0747 - val_acc: 0.4372\n",
            "Epoch 71/150 - 0.04s - loss: 1.0649 - acc: 0.4516 - val_loss: 1.0744 - val_acc: 0.4332\n",
            "Epoch 72/150 - 0.04s - loss: 1.0646 - acc: 0.4532 - val_loss: 1.0741 - val_acc: 0.4332\n",
            "Epoch 73/150 - 0.04s - loss: 1.0642 - acc: 0.4516 - val_loss: 1.0739 - val_acc: 0.4332\n",
            "Epoch 74/150 - 0.04s - loss: 1.0638 - acc: 0.4516 - val_loss: 1.0736 - val_acc: 0.4332\n",
            "Epoch 75/150 - 0.04s - loss: 1.0634 - acc: 0.4516 - val_loss: 1.0733 - val_acc: 0.4332\n",
            "Epoch 76/150 - 0.05s - loss: 1.0631 - acc: 0.4498 - val_loss: 1.0730 - val_acc: 0.4312\n",
            "Epoch 77/150 - 0.04s - loss: 1.0627 - acc: 0.4507 - val_loss: 1.0728 - val_acc: 0.4291\n",
            "Epoch 78/150 - 0.04s - loss: 1.0623 - acc: 0.4512 - val_loss: 1.0725 - val_acc: 0.4291\n",
            "Epoch 79/150 - 0.04s - loss: 1.0620 - acc: 0.4516 - val_loss: 1.0723 - val_acc: 0.4332\n",
            "Epoch 80/150 - 0.04s - loss: 1.0616 - acc: 0.4543 - val_loss: 1.0720 - val_acc: 0.4291\n",
            "Epoch 81/150 - 0.05s - loss: 1.0612 - acc: 0.4530 - val_loss: 1.0718 - val_acc: 0.4312\n",
            "Epoch 82/150 - 0.04s - loss: 1.0608 - acc: 0.4541 - val_loss: 1.0715 - val_acc: 0.4291\n",
            "Epoch 83/150 - 0.04s - loss: 1.0605 - acc: 0.4548 - val_loss: 1.0712 - val_acc: 0.4231\n",
            "Epoch 84/150 - 0.04s - loss: 1.0601 - acc: 0.4582 - val_loss: 1.0709 - val_acc: 0.4271\n",
            "Epoch 85/150 - 0.04s - loss: 1.0597 - acc: 0.4597 - val_loss: 1.0707 - val_acc: 0.4251\n",
            "Epoch 86/150 - 0.04s - loss: 1.0594 - acc: 0.4604 - val_loss: 1.0704 - val_acc: 0.4231\n",
            "Epoch 87/150 - 0.04s - loss: 1.0590 - acc: 0.4602 - val_loss: 1.0701 - val_acc: 0.4251\n",
            "Epoch 88/150 - 0.04s - loss: 1.0586 - acc: 0.4606 - val_loss: 1.0699 - val_acc: 0.4251\n",
            "Epoch 89/150 - 0.04s - loss: 1.0583 - acc: 0.4611 - val_loss: 1.0696 - val_acc: 0.4271\n",
            "Epoch 90/150 - 0.04s - loss: 1.0579 - acc: 0.4611 - val_loss: 1.0694 - val_acc: 0.4312\n",
            "Epoch 91/150 - 0.05s - loss: 1.0576 - acc: 0.4609 - val_loss: 1.0692 - val_acc: 0.4312\n",
            "Epoch 92/150 - 0.05s - loss: 1.0572 - acc: 0.4624 - val_loss: 1.0689 - val_acc: 0.4291\n",
            "Epoch 93/150 - 0.04s - loss: 1.0568 - acc: 0.4636 - val_loss: 1.0686 - val_acc: 0.4312\n",
            "Epoch 94/150 - 0.04s - loss: 1.0565 - acc: 0.4620 - val_loss: 1.0684 - val_acc: 0.4291\n",
            "Epoch 95/150 - 0.05s - loss: 1.0561 - acc: 0.4645 - val_loss: 1.0681 - val_acc: 0.4271\n",
            "Epoch 96/150 - 0.05s - loss: 1.0558 - acc: 0.4663 - val_loss: 1.0679 - val_acc: 0.4271\n",
            "Epoch 97/150 - 0.04s - loss: 1.0554 - acc: 0.4651 - val_loss: 1.0676 - val_acc: 0.4271\n",
            "Epoch 98/150 - 0.05s - loss: 1.0550 - acc: 0.4658 - val_loss: 1.0674 - val_acc: 0.4271\n",
            "Epoch 99/150 - 0.05s - loss: 1.0547 - acc: 0.4654 - val_loss: 1.0671 - val_acc: 0.4271\n",
            "Epoch 100/150 - 0.05s - loss: 1.0543 - acc: 0.4681 - val_loss: 1.0669 - val_acc: 0.4332\n",
            "Epoch 101/150 - 0.05s - loss: 1.0540 - acc: 0.4690 - val_loss: 1.0667 - val_acc: 0.4372\n",
            "Epoch 102/150 - 0.05s - loss: 1.0536 - acc: 0.4694 - val_loss: 1.0664 - val_acc: 0.4352\n",
            "Epoch 103/150 - 0.04s - loss: 1.0532 - acc: 0.4696 - val_loss: 1.0662 - val_acc: 0.4372\n",
            "Epoch 104/150 - 0.04s - loss: 1.0529 - acc: 0.4685 - val_loss: 1.0660 - val_acc: 0.4393\n",
            "Epoch 105/150 - 0.05s - loss: 1.0525 - acc: 0.4699 - val_loss: 1.0657 - val_acc: 0.4372\n",
            "Epoch 106/150 - 0.05s - loss: 1.0522 - acc: 0.4708 - val_loss: 1.0655 - val_acc: 0.4393\n",
            "Epoch 107/150 - 0.05s - loss: 1.0518 - acc: 0.4714 - val_loss: 1.0652 - val_acc: 0.4393\n",
            "Epoch 108/150 - 0.04s - loss: 1.0515 - acc: 0.4712 - val_loss: 1.0650 - val_acc: 0.4372\n",
            "Epoch 109/150 - 0.04s - loss: 1.0511 - acc: 0.4719 - val_loss: 1.0648 - val_acc: 0.4372\n",
            "Epoch 110/150 - 0.05s - loss: 1.0508 - acc: 0.4728 - val_loss: 1.0645 - val_acc: 0.4393\n",
            "Epoch 111/150 - 0.05s - loss: 1.0504 - acc: 0.4721 - val_loss: 1.0642 - val_acc: 0.4393\n",
            "Epoch 112/150 - 0.04s - loss: 1.0501 - acc: 0.4737 - val_loss: 1.0640 - val_acc: 0.4393\n",
            "Epoch 113/150 - 0.05s - loss: 1.0497 - acc: 0.4737 - val_loss: 1.0638 - val_acc: 0.4413\n",
            "Epoch 114/150 - 0.04s - loss: 1.0494 - acc: 0.4735 - val_loss: 1.0636 - val_acc: 0.4413\n",
            "Epoch 115/150 - 0.05s - loss: 1.0490 - acc: 0.4737 - val_loss: 1.0633 - val_acc: 0.4393\n",
            "Epoch 116/150 - 0.05s - loss: 1.0486 - acc: 0.4737 - val_loss: 1.0631 - val_acc: 0.4393\n",
            "Epoch 117/150 - 0.05s - loss: 1.0483 - acc: 0.4744 - val_loss: 1.0628 - val_acc: 0.4433\n",
            "Epoch 118/150 - 0.04s - loss: 1.0479 - acc: 0.4741 - val_loss: 1.0626 - val_acc: 0.4433\n",
            "Epoch 119/150 - 0.04s - loss: 1.0476 - acc: 0.4746 - val_loss: 1.0624 - val_acc: 0.4413\n",
            "Epoch 120/150 - 0.05s - loss: 1.0472 - acc: 0.4748 - val_loss: 1.0622 - val_acc: 0.4413\n",
            "Epoch 121/150 - 0.05s - loss: 1.0469 - acc: 0.4755 - val_loss: 1.0620 - val_acc: 0.4413\n",
            "Epoch 122/150 - 0.04s - loss: 1.0465 - acc: 0.4757 - val_loss: 1.0617 - val_acc: 0.4413\n",
            "Epoch 123/150 - 0.04s - loss: 1.0462 - acc: 0.4755 - val_loss: 1.0614 - val_acc: 0.4393\n",
            "Epoch 124/150 - 0.04s - loss: 1.0458 - acc: 0.4764 - val_loss: 1.0612 - val_acc: 0.4393\n",
            "Epoch 125/150 - 0.04s - loss: 1.0455 - acc: 0.4755 - val_loss: 1.0610 - val_acc: 0.4413\n",
            "Epoch 126/150 - 0.05s - loss: 1.0451 - acc: 0.4757 - val_loss: 1.0608 - val_acc: 0.4413\n",
            "Epoch 127/150 - 0.04s - loss: 1.0448 - acc: 0.4766 - val_loss: 1.0606 - val_acc: 0.4433\n",
            "Epoch 128/150 - 0.04s - loss: 1.0445 - acc: 0.4768 - val_loss: 1.0604 - val_acc: 0.4433\n",
            "Epoch 129/150 - 0.04s - loss: 1.0441 - acc: 0.4766 - val_loss: 1.0601 - val_acc: 0.4453\n",
            "Epoch 130/150 - 0.04s - loss: 1.0438 - acc: 0.4777 - val_loss: 1.0599 - val_acc: 0.4453\n",
            "Epoch 131/150 - 0.04s - loss: 1.0434 - acc: 0.4773 - val_loss: 1.0597 - val_acc: 0.4453\n",
            "Epoch 132/150 - 0.04s - loss: 1.0431 - acc: 0.4780 - val_loss: 1.0594 - val_acc: 0.4413\n",
            "Epoch 133/150 - 0.05s - loss: 1.0427 - acc: 0.4791 - val_loss: 1.0592 - val_acc: 0.4433\n",
            "Epoch 134/150 - 0.05s - loss: 1.0424 - acc: 0.4786 - val_loss: 1.0590 - val_acc: 0.4433\n",
            "Epoch 135/150 - 0.04s - loss: 1.0420 - acc: 0.4780 - val_loss: 1.0588 - val_acc: 0.4453\n",
            "Epoch 136/150 - 0.05s - loss: 1.0417 - acc: 0.4789 - val_loss: 1.0586 - val_acc: 0.4453\n",
            "Epoch 137/150 - 0.05s - loss: 1.0413 - acc: 0.4784 - val_loss: 1.0584 - val_acc: 0.4474\n",
            "Epoch 138/150 - 0.04s - loss: 1.0410 - acc: 0.4798 - val_loss: 1.0581 - val_acc: 0.4474\n",
            "Epoch 139/150 - 0.05s - loss: 1.0406 - acc: 0.4784 - val_loss: 1.0579 - val_acc: 0.4433\n",
            "Epoch 140/150 - 0.05s - loss: 1.0403 - acc: 0.4795 - val_loss: 1.0577 - val_acc: 0.4494\n",
            "Epoch 141/150 - 0.04s - loss: 1.0399 - acc: 0.4798 - val_loss: 1.0574 - val_acc: 0.4474\n",
            "Epoch 142/150 - 0.04s - loss: 1.0396 - acc: 0.4793 - val_loss: 1.0572 - val_acc: 0.4494\n",
            "Epoch 143/150 - 0.04s - loss: 1.0393 - acc: 0.4809 - val_loss: 1.0570 - val_acc: 0.4514\n",
            "Epoch 144/150 - 0.04s - loss: 1.0389 - acc: 0.4813 - val_loss: 1.0568 - val_acc: 0.4474\n",
            "Epoch 145/150 - 0.04s - loss: 1.0386 - acc: 0.4807 - val_loss: 1.0566 - val_acc: 0.4514\n",
            "Epoch 146/150 - 0.05s - loss: 1.0382 - acc: 0.4809 - val_loss: 1.0564 - val_acc: 0.4494\n",
            "Epoch 147/150 - 0.04s - loss: 1.0379 - acc: 0.4811 - val_loss: 1.0561 - val_acc: 0.4514\n",
            "Epoch 148/150 - 0.04s - loss: 1.0375 - acc: 0.4807 - val_loss: 1.0559 - val_acc: 0.4534\n",
            "Epoch 149/150 - 0.04s - loss: 1.0372 - acc: 0.4809 - val_loss: 1.0557 - val_acc: 0.4575\n",
            "Epoch 150/150 - 0.04s - loss: 1.0369 - acc: 0.4818 - val_loss: 1.0555 - val_acc: 0.4555\n",
            "\n",
            "Combination 31/252:\n",
            "Hidden Layers: [64, 32], Activation: tanh, Learning Rate: 0.0001, Batch Size: 32, Epochs: 50\n",
            "Epoch 1/50 - 0.06s - loss: 1.0976 - acc: 0.3601 - val_loss: 1.0999 - val_acc: 0.3725\n",
            "Epoch 2/50 - 0.06s - loss: 1.0972 - acc: 0.3628 - val_loss: 1.0996 - val_acc: 0.3745\n",
            "Epoch 3/50 - 0.06s - loss: 1.0968 - acc: 0.3626 - val_loss: 1.0993 - val_acc: 0.3765\n",
            "Epoch 4/50 - 0.06s - loss: 1.0964 - acc: 0.3671 - val_loss: 1.0990 - val_acc: 0.3725\n",
            "Epoch 5/50 - 0.06s - loss: 1.0961 - acc: 0.3646 - val_loss: 1.0988 - val_acc: 0.3704\n",
            "Epoch 6/50 - 0.06s - loss: 1.0958 - acc: 0.3668 - val_loss: 1.0985 - val_acc: 0.3684\n",
            "Epoch 7/50 - 0.06s - loss: 1.0955 - acc: 0.3655 - val_loss: 1.0983 - val_acc: 0.3684\n",
            "Epoch 8/50 - 0.06s - loss: 1.0952 - acc: 0.3675 - val_loss: 1.0980 - val_acc: 0.3765\n",
            "Epoch 9/50 - 0.06s - loss: 1.0949 - acc: 0.3704 - val_loss: 1.0978 - val_acc: 0.3684\n",
            "Epoch 10/50 - 0.06s - loss: 1.0947 - acc: 0.3727 - val_loss: 1.0976 - val_acc: 0.3603\n",
            "Epoch 11/50 - 0.06s - loss: 1.0944 - acc: 0.3731 - val_loss: 1.0974 - val_acc: 0.3543\n",
            "Epoch 12/50 - 0.06s - loss: 1.0942 - acc: 0.3752 - val_loss: 1.0972 - val_acc: 0.3563\n",
            "Epoch 13/50 - 0.06s - loss: 1.0939 - acc: 0.3758 - val_loss: 1.0970 - val_acc: 0.3583\n",
            "Epoch 14/50 - 0.06s - loss: 1.0937 - acc: 0.3772 - val_loss: 1.0968 - val_acc: 0.3583\n",
            "Epoch 15/50 - 0.06s - loss: 1.0934 - acc: 0.3765 - val_loss: 1.0966 - val_acc: 0.3563\n",
            "Epoch 16/50 - 0.06s - loss: 1.0932 - acc: 0.3761 - val_loss: 1.0964 - val_acc: 0.3543\n",
            "Epoch 17/50 - 0.06s - loss: 1.0930 - acc: 0.3770 - val_loss: 1.0962 - val_acc: 0.3583\n",
            "Epoch 18/50 - 0.06s - loss: 1.0928 - acc: 0.3767 - val_loss: 1.0960 - val_acc: 0.3623\n",
            "Epoch 19/50 - 0.06s - loss: 1.0926 - acc: 0.3767 - val_loss: 1.0958 - val_acc: 0.3623\n",
            "Epoch 20/50 - 0.06s - loss: 1.0923 - acc: 0.3774 - val_loss: 1.0956 - val_acc: 0.3664\n",
            "Epoch 21/50 - 0.06s - loss: 1.0921 - acc: 0.3774 - val_loss: 1.0954 - val_acc: 0.3664\n",
            "Epoch 22/50 - 0.06s - loss: 1.0919 - acc: 0.3792 - val_loss: 1.0952 - val_acc: 0.3704\n",
            "Epoch 23/50 - 0.06s - loss: 1.0917 - acc: 0.3792 - val_loss: 1.0950 - val_acc: 0.3704\n",
            "Epoch 24/50 - 0.06s - loss: 1.0915 - acc: 0.3801 - val_loss: 1.0948 - val_acc: 0.3704\n",
            "Epoch 25/50 - 0.06s - loss: 1.0913 - acc: 0.3806 - val_loss: 1.0947 - val_acc: 0.3745\n",
            "Epoch 26/50 - 0.06s - loss: 1.0911 - acc: 0.3821 - val_loss: 1.0945 - val_acc: 0.3725\n",
            "Epoch 27/50 - 0.05s - loss: 1.0909 - acc: 0.3819 - val_loss: 1.0943 - val_acc: 0.3725\n",
            "Epoch 28/50 - 0.06s - loss: 1.0907 - acc: 0.3830 - val_loss: 1.0941 - val_acc: 0.3725\n",
            "Epoch 29/50 - 0.06s - loss: 1.0905 - acc: 0.3837 - val_loss: 1.0939 - val_acc: 0.3765\n",
            "Epoch 30/50 - 0.06s - loss: 1.0903 - acc: 0.3846 - val_loss: 1.0937 - val_acc: 0.3806\n",
            "Epoch 31/50 - 0.06s - loss: 1.0901 - acc: 0.3857 - val_loss: 1.0936 - val_acc: 0.3806\n",
            "Epoch 32/50 - 0.06s - loss: 1.0899 - acc: 0.3873 - val_loss: 1.0934 - val_acc: 0.3785\n",
            "Epoch 33/50 - 0.06s - loss: 1.0897 - acc: 0.3896 - val_loss: 1.0932 - val_acc: 0.3806\n",
            "Epoch 34/50 - 0.06s - loss: 1.0895 - acc: 0.3907 - val_loss: 1.0930 - val_acc: 0.3806\n",
            "Epoch 35/50 - 0.06s - loss: 1.0893 - acc: 0.3920 - val_loss: 1.0929 - val_acc: 0.3785\n",
            "Epoch 36/50 - 0.06s - loss: 1.0891 - acc: 0.3934 - val_loss: 1.0927 - val_acc: 0.3745\n",
            "Epoch 37/50 - 0.06s - loss: 1.0889 - acc: 0.3938 - val_loss: 1.0925 - val_acc: 0.3765\n",
            "Epoch 38/50 - 0.06s - loss: 1.0887 - acc: 0.3938 - val_loss: 1.0923 - val_acc: 0.3745\n",
            "Epoch 39/50 - 0.06s - loss: 1.0886 - acc: 0.3938 - val_loss: 1.0922 - val_acc: 0.3745\n",
            "Epoch 40/50 - 0.06s - loss: 1.0884 - acc: 0.3945 - val_loss: 1.0920 - val_acc: 0.3765\n",
            "Epoch 41/50 - 0.06s - loss: 1.0882 - acc: 0.3954 - val_loss: 1.0918 - val_acc: 0.3765\n",
            "Epoch 42/50 - 0.06s - loss: 1.0880 - acc: 0.3956 - val_loss: 1.0917 - val_acc: 0.3765\n",
            "Epoch 43/50 - 0.06s - loss: 1.0878 - acc: 0.3970 - val_loss: 1.0915 - val_acc: 0.3745\n",
            "Epoch 44/50 - 0.06s - loss: 1.0876 - acc: 0.3968 - val_loss: 1.0913 - val_acc: 0.3765\n",
            "Epoch 45/50 - 0.06s - loss: 1.0875 - acc: 0.3972 - val_loss: 1.0912 - val_acc: 0.3765\n",
            "Epoch 46/50 - 0.06s - loss: 1.0873 - acc: 0.3990 - val_loss: 1.0910 - val_acc: 0.3785\n",
            "Epoch 47/50 - 0.06s - loss: 1.0871 - acc: 0.3997 - val_loss: 1.0909 - val_acc: 0.3785\n",
            "Epoch 48/50 - 0.06s - loss: 1.0869 - acc: 0.3999 - val_loss: 1.0907 - val_acc: 0.3826\n",
            "Epoch 49/50 - 0.06s - loss: 1.0868 - acc: 0.4006 - val_loss: 1.0906 - val_acc: 0.3826\n",
            "Epoch 50/50 - 0.06s - loss: 1.0866 - acc: 0.4008 - val_loss: 1.0904 - val_acc: 0.3826\n",
            "\n",
            "Combination 32/252:\n",
            "Hidden Layers: [64, 32], Activation: tanh, Learning Rate: 0.0001, Batch Size: 32, Epochs: 100\n",
            "Epoch 1/100 - 0.06s - loss: 1.1317 - acc: 0.3401 - val_loss: 1.1343 - val_acc: 0.3583\n",
            "Epoch 2/100 - 0.06s - loss: 1.1284 - acc: 0.3390 - val_loss: 1.1306 - val_acc: 0.3603\n",
            "Epoch 3/100 - 0.06s - loss: 1.1254 - acc: 0.3396 - val_loss: 1.1274 - val_acc: 0.3644\n",
            "Epoch 4/100 - 0.06s - loss: 1.1227 - acc: 0.3394 - val_loss: 1.1245 - val_acc: 0.3623\n",
            "Epoch 5/100 - 0.06s - loss: 1.1204 - acc: 0.3360 - val_loss: 1.1219 - val_acc: 0.3603\n",
            "Epoch 6/100 - 0.05s - loss: 1.1183 - acc: 0.3349 - val_loss: 1.1197 - val_acc: 0.3623\n",
            "Epoch 7/100 - 0.06s - loss: 1.1164 - acc: 0.3345 - val_loss: 1.1176 - val_acc: 0.3603\n",
            "Epoch 8/100 - 0.06s - loss: 1.1148 - acc: 0.3345 - val_loss: 1.1158 - val_acc: 0.3623\n",
            "Epoch 9/100 - 0.06s - loss: 1.1134 - acc: 0.3349 - val_loss: 1.1142 - val_acc: 0.3644\n",
            "Epoch 10/100 - 0.06s - loss: 1.1121 - acc: 0.3338 - val_loss: 1.1127 - val_acc: 0.3644\n",
            "Epoch 11/100 - 0.06s - loss: 1.1109 - acc: 0.3342 - val_loss: 1.1114 - val_acc: 0.3644\n",
            "Epoch 12/100 - 0.06s - loss: 1.1099 - acc: 0.3331 - val_loss: 1.1103 - val_acc: 0.3623\n",
            "Epoch 13/100 - 0.06s - loss: 1.1090 - acc: 0.3309 - val_loss: 1.1092 - val_acc: 0.3623\n",
            "Epoch 14/100 - 0.06s - loss: 1.1082 - acc: 0.3315 - val_loss: 1.1083 - val_acc: 0.3543\n",
            "Epoch 15/100 - 0.06s - loss: 1.1074 - acc: 0.3311 - val_loss: 1.1074 - val_acc: 0.3543\n",
            "Epoch 16/100 - 0.06s - loss: 1.1068 - acc: 0.3273 - val_loss: 1.1067 - val_acc: 0.3522\n",
            "Epoch 17/100 - 0.06s - loss: 1.1062 - acc: 0.3255 - val_loss: 1.1060 - val_acc: 0.3543\n",
            "Epoch 18/100 - 0.06s - loss: 1.1056 - acc: 0.3252 - val_loss: 1.1054 - val_acc: 0.3522\n",
            "Epoch 19/100 - 0.06s - loss: 1.1051 - acc: 0.3241 - val_loss: 1.1048 - val_acc: 0.3543\n",
            "Epoch 20/100 - 0.05s - loss: 1.1047 - acc: 0.3230 - val_loss: 1.1043 - val_acc: 0.3543\n",
            "Epoch 21/100 - 0.06s - loss: 1.1043 - acc: 0.3230 - val_loss: 1.1038 - val_acc: 0.3502\n",
            "Epoch 22/100 - 0.06s - loss: 1.1039 - acc: 0.3232 - val_loss: 1.1033 - val_acc: 0.3482\n",
            "Epoch 23/100 - 0.06s - loss: 1.1035 - acc: 0.3232 - val_loss: 1.1029 - val_acc: 0.3482\n",
            "Epoch 24/100 - 0.06s - loss: 1.1032 - acc: 0.3252 - val_loss: 1.1025 - val_acc: 0.3462\n",
            "Epoch 25/100 - 0.06s - loss: 1.1029 - acc: 0.3255 - val_loss: 1.1022 - val_acc: 0.3462\n",
            "Epoch 26/100 - 0.06s - loss: 1.1026 - acc: 0.3252 - val_loss: 1.1019 - val_acc: 0.3543\n",
            "Epoch 27/100 - 0.06s - loss: 1.1024 - acc: 0.3246 - val_loss: 1.1015 - val_acc: 0.3563\n",
            "Epoch 28/100 - 0.06s - loss: 1.1021 - acc: 0.3234 - val_loss: 1.1013 - val_acc: 0.3543\n",
            "Epoch 29/100 - 0.06s - loss: 1.1019 - acc: 0.3228 - val_loss: 1.1010 - val_acc: 0.3563\n",
            "Epoch 30/100 - 0.06s - loss: 1.1016 - acc: 0.3230 - val_loss: 1.1007 - val_acc: 0.3502\n",
            "Epoch 31/100 - 0.06s - loss: 1.1014 - acc: 0.3225 - val_loss: 1.1005 - val_acc: 0.3522\n",
            "Epoch 32/100 - 0.06s - loss: 1.1012 - acc: 0.3237 - val_loss: 1.1002 - val_acc: 0.3623\n",
            "Epoch 33/100 - 0.06s - loss: 1.1010 - acc: 0.3252 - val_loss: 1.1000 - val_acc: 0.3644\n",
            "Epoch 34/100 - 0.06s - loss: 1.1008 - acc: 0.3261 - val_loss: 1.0998 - val_acc: 0.3664\n",
            "Epoch 35/100 - 0.06s - loss: 1.1006 - acc: 0.3291 - val_loss: 1.0996 - val_acc: 0.3644\n",
            "Epoch 36/100 - 0.06s - loss: 1.1004 - acc: 0.3297 - val_loss: 1.0994 - val_acc: 0.3644\n",
            "Epoch 37/100 - 0.06s - loss: 1.1002 - acc: 0.3297 - val_loss: 1.0992 - val_acc: 0.3623\n",
            "Epoch 38/100 - 0.06s - loss: 1.1000 - acc: 0.3302 - val_loss: 1.0990 - val_acc: 0.3583\n",
            "Epoch 39/100 - 0.06s - loss: 1.0999 - acc: 0.3295 - val_loss: 1.0988 - val_acc: 0.3543\n",
            "Epoch 40/100 - 0.06s - loss: 1.0997 - acc: 0.3286 - val_loss: 1.0987 - val_acc: 0.3502\n",
            "Epoch 41/100 - 0.06s - loss: 1.0995 - acc: 0.3300 - val_loss: 1.0985 - val_acc: 0.3522\n",
            "Epoch 42/100 - 0.06s - loss: 1.0994 - acc: 0.3306 - val_loss: 1.0983 - val_acc: 0.3543\n",
            "Epoch 43/100 - 0.06s - loss: 1.0992 - acc: 0.3309 - val_loss: 1.0982 - val_acc: 0.3563\n",
            "Epoch 44/100 - 0.06s - loss: 1.0990 - acc: 0.3331 - val_loss: 1.0980 - val_acc: 0.3522\n",
            "Epoch 45/100 - 0.06s - loss: 1.0989 - acc: 0.3351 - val_loss: 1.0979 - val_acc: 0.3543\n",
            "Epoch 46/100 - 0.06s - loss: 1.0987 - acc: 0.3372 - val_loss: 1.0977 - val_acc: 0.3583\n",
            "Epoch 47/100 - 0.06s - loss: 1.0986 - acc: 0.3369 - val_loss: 1.0976 - val_acc: 0.3603\n",
            "Epoch 48/100 - 0.06s - loss: 1.0984 - acc: 0.3390 - val_loss: 1.0974 - val_acc: 0.3623\n",
            "Epoch 49/100 - 0.07s - loss: 1.0983 - acc: 0.3385 - val_loss: 1.0973 - val_acc: 0.3704\n",
            "Epoch 50/100 - 0.06s - loss: 1.0981 - acc: 0.3381 - val_loss: 1.0971 - val_acc: 0.3745\n",
            "Epoch 51/100 - 0.06s - loss: 1.0980 - acc: 0.3381 - val_loss: 1.0970 - val_acc: 0.3745\n",
            "Epoch 52/100 - 0.06s - loss: 1.0978 - acc: 0.3394 - val_loss: 1.0969 - val_acc: 0.3725\n",
            "Epoch 53/100 - 0.05s - loss: 1.0977 - acc: 0.3396 - val_loss: 1.0967 - val_acc: 0.3745\n",
            "Epoch 54/100 - 0.06s - loss: 1.0975 - acc: 0.3403 - val_loss: 1.0966 - val_acc: 0.3704\n",
            "Epoch 55/100 - 0.06s - loss: 1.0974 - acc: 0.3412 - val_loss: 1.0965 - val_acc: 0.3684\n",
            "Epoch 56/100 - 0.06s - loss: 1.0972 - acc: 0.3423 - val_loss: 1.0963 - val_acc: 0.3684\n",
            "Epoch 57/100 - 0.06s - loss: 1.0971 - acc: 0.3441 - val_loss: 1.0962 - val_acc: 0.3704\n",
            "Epoch 58/100 - 0.06s - loss: 1.0969 - acc: 0.3446 - val_loss: 1.0961 - val_acc: 0.3684\n",
            "Epoch 59/100 - 0.06s - loss: 1.0968 - acc: 0.3446 - val_loss: 1.0960 - val_acc: 0.3664\n",
            "Epoch 60/100 - 0.06s - loss: 1.0966 - acc: 0.3464 - val_loss: 1.0958 - val_acc: 0.3664\n",
            "Epoch 61/100 - 0.06s - loss: 1.0965 - acc: 0.3489 - val_loss: 1.0957 - val_acc: 0.3644\n",
            "Epoch 62/100 - 0.06s - loss: 1.0963 - acc: 0.3493 - val_loss: 1.0956 - val_acc: 0.3623\n",
            "Epoch 63/100 - 0.06s - loss: 1.0962 - acc: 0.3493 - val_loss: 1.0955 - val_acc: 0.3644\n",
            "Epoch 64/100 - 0.06s - loss: 1.0961 - acc: 0.3493 - val_loss: 1.0953 - val_acc: 0.3623\n",
            "Epoch 65/100 - 0.06s - loss: 1.0959 - acc: 0.3498 - val_loss: 1.0952 - val_acc: 0.3603\n",
            "Epoch 66/100 - 0.06s - loss: 1.0958 - acc: 0.3504 - val_loss: 1.0951 - val_acc: 0.3644\n",
            "Epoch 67/100 - 0.06s - loss: 1.0956 - acc: 0.3504 - val_loss: 1.0950 - val_acc: 0.3644\n",
            "Epoch 68/100 - 0.06s - loss: 1.0955 - acc: 0.3518 - val_loss: 1.0949 - val_acc: 0.3644\n",
            "Epoch 69/100 - 0.06s - loss: 1.0954 - acc: 0.3513 - val_loss: 1.0947 - val_acc: 0.3684\n",
            "Epoch 70/100 - 0.06s - loss: 1.0952 - acc: 0.3536 - val_loss: 1.0946 - val_acc: 0.3644\n",
            "Epoch 71/100 - 0.06s - loss: 1.0951 - acc: 0.3547 - val_loss: 1.0945 - val_acc: 0.3644\n",
            "Epoch 72/100 - 0.06s - loss: 1.0949 - acc: 0.3556 - val_loss: 1.0944 - val_acc: 0.3644\n",
            "Epoch 73/100 - 0.06s - loss: 1.0948 - acc: 0.3565 - val_loss: 1.0943 - val_acc: 0.3644\n",
            "Epoch 74/100 - 0.06s - loss: 1.0947 - acc: 0.3587 - val_loss: 1.0942 - val_acc: 0.3644\n",
            "Epoch 75/100 - 0.06s - loss: 1.0945 - acc: 0.3592 - val_loss: 1.0941 - val_acc: 0.3644\n",
            "Epoch 76/100 - 0.06s - loss: 1.0944 - acc: 0.3590 - val_loss: 1.0939 - val_acc: 0.3704\n",
            "Epoch 77/100 - 0.06s - loss: 1.0943 - acc: 0.3596 - val_loss: 1.0938 - val_acc: 0.3704\n",
            "Epoch 78/100 - 0.06s - loss: 1.0941 - acc: 0.3601 - val_loss: 1.0937 - val_acc: 0.3745\n",
            "Epoch 79/100 - 0.06s - loss: 1.0940 - acc: 0.3610 - val_loss: 1.0936 - val_acc: 0.3745\n",
            "Epoch 80/100 - 0.06s - loss: 1.0939 - acc: 0.3619 - val_loss: 1.0935 - val_acc: 0.3765\n",
            "Epoch 81/100 - 0.06s - loss: 1.0937 - acc: 0.3623 - val_loss: 1.0934 - val_acc: 0.3725\n",
            "Epoch 82/100 - 0.06s - loss: 1.0936 - acc: 0.3628 - val_loss: 1.0933 - val_acc: 0.3725\n",
            "Epoch 83/100 - 0.06s - loss: 1.0935 - acc: 0.3646 - val_loss: 1.0932 - val_acc: 0.3725\n",
            "Epoch 84/100 - 0.06s - loss: 1.0933 - acc: 0.3653 - val_loss: 1.0931 - val_acc: 0.3725\n",
            "Epoch 85/100 - 0.05s - loss: 1.0932 - acc: 0.3655 - val_loss: 1.0930 - val_acc: 0.3745\n",
            "Epoch 86/100 - 0.06s - loss: 1.0931 - acc: 0.3662 - val_loss: 1.0928 - val_acc: 0.3725\n",
            "Epoch 87/100 - 0.06s - loss: 1.0929 - acc: 0.3668 - val_loss: 1.0927 - val_acc: 0.3725\n",
            "Epoch 88/100 - 0.06s - loss: 1.0928 - acc: 0.3666 - val_loss: 1.0926 - val_acc: 0.3725\n",
            "Epoch 89/100 - 0.06s - loss: 1.0927 - acc: 0.3673 - val_loss: 1.0925 - val_acc: 0.3704\n",
            "Epoch 90/100 - 0.06s - loss: 1.0926 - acc: 0.3673 - val_loss: 1.0924 - val_acc: 0.3725\n",
            "Epoch 91/100 - 0.06s - loss: 1.0924 - acc: 0.3693 - val_loss: 1.0923 - val_acc: 0.3745\n",
            "Epoch 92/100 - 0.06s - loss: 1.0923 - acc: 0.3700 - val_loss: 1.0922 - val_acc: 0.3765\n",
            "Epoch 93/100 - 0.06s - loss: 1.0922 - acc: 0.3707 - val_loss: 1.0921 - val_acc: 0.3745\n",
            "Epoch 94/100 - 0.06s - loss: 1.0920 - acc: 0.3713 - val_loss: 1.0920 - val_acc: 0.3745\n",
            "Epoch 95/100 - 0.06s - loss: 1.0919 - acc: 0.3716 - val_loss: 1.0919 - val_acc: 0.3806\n",
            "Epoch 96/100 - 0.06s - loss: 1.0918 - acc: 0.3731 - val_loss: 1.0918 - val_acc: 0.3806\n",
            "Epoch 97/100 - 0.06s - loss: 1.0917 - acc: 0.3745 - val_loss: 1.0917 - val_acc: 0.3826\n",
            "Epoch 98/100 - 0.06s - loss: 1.0915 - acc: 0.3743 - val_loss: 1.0916 - val_acc: 0.3887\n",
            "Epoch 99/100 - 0.06s - loss: 1.0914 - acc: 0.3734 - val_loss: 1.0915 - val_acc: 0.3846\n",
            "Epoch 100/100 - 0.05s - loss: 1.0913 - acc: 0.3740 - val_loss: 1.0914 - val_acc: 0.3826\n",
            "\n",
            "Combination 33/252:\n",
            "Hidden Layers: [64, 32], Activation: tanh, Learning Rate: 0.0001, Batch Size: 32, Epochs: 150\n",
            "Epoch 1/150 - 0.05s - loss: 1.1276 - acc: 0.3237 - val_loss: 1.1228 - val_acc: 0.3340\n",
            "Epoch 2/150 - 0.06s - loss: 1.1251 - acc: 0.3241 - val_loss: 1.1208 - val_acc: 0.3300\n",
            "Epoch 3/150 - 0.06s - loss: 1.1230 - acc: 0.3250 - val_loss: 1.1190 - val_acc: 0.3239\n",
            "Epoch 4/150 - 0.06s - loss: 1.1210 - acc: 0.3237 - val_loss: 1.1175 - val_acc: 0.3259\n",
            "Epoch 5/150 - 0.06s - loss: 1.1193 - acc: 0.3214 - val_loss: 1.1161 - val_acc: 0.3340\n",
            "Epoch 6/150 - 0.06s - loss: 1.1178 - acc: 0.3239 - val_loss: 1.1150 - val_acc: 0.3381\n",
            "Epoch 7/150 - 0.06s - loss: 1.1165 - acc: 0.3257 - val_loss: 1.1140 - val_acc: 0.3320\n",
            "Epoch 8/150 - 0.06s - loss: 1.1153 - acc: 0.3270 - val_loss: 1.1131 - val_acc: 0.3219\n",
            "Epoch 9/150 - 0.05s - loss: 1.1142 - acc: 0.3275 - val_loss: 1.1123 - val_acc: 0.3239\n",
            "Epoch 10/150 - 0.06s - loss: 1.1132 - acc: 0.3304 - val_loss: 1.1115 - val_acc: 0.3138\n",
            "Epoch 11/150 - 0.06s - loss: 1.1123 - acc: 0.3286 - val_loss: 1.1109 - val_acc: 0.3117\n",
            "Epoch 12/150 - 0.06s - loss: 1.1115 - acc: 0.3239 - val_loss: 1.1103 - val_acc: 0.3158\n",
            "Epoch 13/150 - 0.06s - loss: 1.1108 - acc: 0.3203 - val_loss: 1.1098 - val_acc: 0.3219\n",
            "Epoch 14/150 - 0.06s - loss: 1.1101 - acc: 0.3203 - val_loss: 1.1093 - val_acc: 0.3219\n",
            "Epoch 15/150 - 0.06s - loss: 1.1095 - acc: 0.3198 - val_loss: 1.1089 - val_acc: 0.3259\n",
            "Epoch 16/150 - 0.06s - loss: 1.1089 - acc: 0.3196 - val_loss: 1.1085 - val_acc: 0.3219\n",
            "Epoch 17/150 - 0.06s - loss: 1.1083 - acc: 0.3223 - val_loss: 1.1081 - val_acc: 0.3259\n",
            "Epoch 18/150 - 0.06s - loss: 1.1078 - acc: 0.3192 - val_loss: 1.1078 - val_acc: 0.3360\n",
            "Epoch 19/150 - 0.06s - loss: 1.1073 - acc: 0.3194 - val_loss: 1.1074 - val_acc: 0.3259\n",
            "Epoch 20/150 - 0.06s - loss: 1.1069 - acc: 0.3189 - val_loss: 1.1071 - val_acc: 0.3320\n",
            "Epoch 21/150 - 0.06s - loss: 1.1064 - acc: 0.3192 - val_loss: 1.1068 - val_acc: 0.3320\n",
            "Epoch 22/150 - 0.06s - loss: 1.1060 - acc: 0.3162 - val_loss: 1.1066 - val_acc: 0.3198\n",
            "Epoch 23/150 - 0.06s - loss: 1.1056 - acc: 0.3142 - val_loss: 1.1063 - val_acc: 0.3158\n",
            "Epoch 24/150 - 0.06s - loss: 1.1053 - acc: 0.3153 - val_loss: 1.1060 - val_acc: 0.3178\n",
            "Epoch 25/150 - 0.06s - loss: 1.1049 - acc: 0.3185 - val_loss: 1.1058 - val_acc: 0.3077\n",
            "Epoch 26/150 - 0.06s - loss: 1.1045 - acc: 0.3189 - val_loss: 1.1056 - val_acc: 0.3097\n",
            "Epoch 27/150 - 0.06s - loss: 1.1042 - acc: 0.3180 - val_loss: 1.1053 - val_acc: 0.3036\n",
            "Epoch 28/150 - 0.06s - loss: 1.1039 - acc: 0.3201 - val_loss: 1.1051 - val_acc: 0.3016\n",
            "Epoch 29/150 - 0.06s - loss: 1.1036 - acc: 0.3201 - val_loss: 1.1049 - val_acc: 0.2996\n",
            "Epoch 30/150 - 0.06s - loss: 1.1033 - acc: 0.3176 - val_loss: 1.1047 - val_acc: 0.2955\n",
            "Epoch 31/150 - 0.06s - loss: 1.1030 - acc: 0.3162 - val_loss: 1.1044 - val_acc: 0.2915\n",
            "Epoch 32/150 - 0.06s - loss: 1.1027 - acc: 0.3158 - val_loss: 1.1042 - val_acc: 0.2874\n",
            "Epoch 33/150 - 0.06s - loss: 1.1024 - acc: 0.3169 - val_loss: 1.1040 - val_acc: 0.2895\n",
            "Epoch 34/150 - 0.06s - loss: 1.1021 - acc: 0.3180 - val_loss: 1.1038 - val_acc: 0.2895\n",
            "Epoch 35/150 - 0.06s - loss: 1.1018 - acc: 0.3198 - val_loss: 1.1036 - val_acc: 0.2915\n",
            "Epoch 36/150 - 0.06s - loss: 1.1015 - acc: 0.3183 - val_loss: 1.1034 - val_acc: 0.2976\n",
            "Epoch 37/150 - 0.06s - loss: 1.1013 - acc: 0.3185 - val_loss: 1.1032 - val_acc: 0.2996\n",
            "Epoch 38/150 - 0.06s - loss: 1.1010 - acc: 0.3174 - val_loss: 1.1030 - val_acc: 0.2976\n",
            "Epoch 39/150 - 0.06s - loss: 1.1008 - acc: 0.3178 - val_loss: 1.1028 - val_acc: 0.2955\n",
            "Epoch 40/150 - 0.06s - loss: 1.1005 - acc: 0.3189 - val_loss: 1.1026 - val_acc: 0.2915\n",
            "Epoch 41/150 - 0.06s - loss: 1.1003 - acc: 0.3205 - val_loss: 1.1025 - val_acc: 0.2915\n",
            "Epoch 42/150 - 0.06s - loss: 1.1000 - acc: 0.3225 - val_loss: 1.1023 - val_acc: 0.2955\n",
            "Epoch 43/150 - 0.06s - loss: 1.0998 - acc: 0.3210 - val_loss: 1.1021 - val_acc: 0.2955\n",
            "Epoch 44/150 - 0.06s - loss: 1.0995 - acc: 0.3205 - val_loss: 1.1019 - val_acc: 0.2976\n",
            "Epoch 45/150 - 0.06s - loss: 1.0993 - acc: 0.3212 - val_loss: 1.1017 - val_acc: 0.2976\n",
            "Epoch 46/150 - 0.06s - loss: 1.0990 - acc: 0.3234 - val_loss: 1.1015 - val_acc: 0.2955\n",
            "Epoch 47/150 - 0.06s - loss: 1.0988 - acc: 0.3237 - val_loss: 1.1013 - val_acc: 0.2935\n",
            "Epoch 48/150 - 0.06s - loss: 1.0986 - acc: 0.3252 - val_loss: 1.1012 - val_acc: 0.2976\n",
            "Epoch 49/150 - 0.06s - loss: 1.0983 - acc: 0.3261 - val_loss: 1.1010 - val_acc: 0.2976\n",
            "Epoch 50/150 - 0.06s - loss: 1.0981 - acc: 0.3286 - val_loss: 1.1008 - val_acc: 0.2976\n",
            "Epoch 51/150 - 0.06s - loss: 1.0979 - acc: 0.3306 - val_loss: 1.1006 - val_acc: 0.2996\n",
            "Epoch 52/150 - 0.06s - loss: 1.0977 - acc: 0.3315 - val_loss: 1.1004 - val_acc: 0.3036\n",
            "Epoch 53/150 - 0.06s - loss: 1.0974 - acc: 0.3327 - val_loss: 1.1003 - val_acc: 0.3036\n",
            "Epoch 54/150 - 0.06s - loss: 1.0972 - acc: 0.3367 - val_loss: 1.1001 - val_acc: 0.3057\n",
            "Epoch 55/150 - 0.06s - loss: 1.0970 - acc: 0.3385 - val_loss: 1.0999 - val_acc: 0.3077\n",
            "Epoch 56/150 - 0.06s - loss: 1.0968 - acc: 0.3385 - val_loss: 1.0997 - val_acc: 0.3117\n",
            "Epoch 57/150 - 0.06s - loss: 1.0966 - acc: 0.3405 - val_loss: 1.0995 - val_acc: 0.3117\n",
            "Epoch 58/150 - 0.06s - loss: 1.0964 - acc: 0.3414 - val_loss: 1.0994 - val_acc: 0.3117\n",
            "Epoch 59/150 - 0.06s - loss: 1.0962 - acc: 0.3428 - val_loss: 1.0992 - val_acc: 0.3138\n",
            "Epoch 60/150 - 0.06s - loss: 1.0960 - acc: 0.3428 - val_loss: 1.0990 - val_acc: 0.3117\n",
            "Epoch 61/150 - 0.06s - loss: 1.0957 - acc: 0.3439 - val_loss: 1.0989 - val_acc: 0.3117\n",
            "Epoch 62/150 - 0.06s - loss: 1.0955 - acc: 0.3473 - val_loss: 1.0987 - val_acc: 0.3138\n",
            "Epoch 63/150 - 0.06s - loss: 1.0953 - acc: 0.3486 - val_loss: 1.0985 - val_acc: 0.3198\n",
            "Epoch 64/150 - 0.05s - loss: 1.0951 - acc: 0.3495 - val_loss: 1.0984 - val_acc: 0.3239\n",
            "Epoch 65/150 - 0.06s - loss: 1.0949 - acc: 0.3509 - val_loss: 1.0982 - val_acc: 0.3279\n",
            "Epoch 66/150 - 0.06s - loss: 1.0947 - acc: 0.3513 - val_loss: 1.0980 - val_acc: 0.3259\n",
            "Epoch 67/150 - 0.06s - loss: 1.0945 - acc: 0.3520 - val_loss: 1.0979 - val_acc: 0.3279\n",
            "Epoch 68/150 - 0.06s - loss: 1.0943 - acc: 0.3527 - val_loss: 1.0977 - val_acc: 0.3300\n",
            "Epoch 69/150 - 0.06s - loss: 1.0941 - acc: 0.3554 - val_loss: 1.0975 - val_acc: 0.3279\n",
            "Epoch 70/150 - 0.06s - loss: 1.0939 - acc: 0.3549 - val_loss: 1.0974 - val_acc: 0.3320\n",
            "Epoch 71/150 - 0.06s - loss: 1.0938 - acc: 0.3552 - val_loss: 1.0972 - val_acc: 0.3320\n",
            "Epoch 72/150 - 0.06s - loss: 1.0936 - acc: 0.3558 - val_loss: 1.0971 - val_acc: 0.3340\n",
            "Epoch 73/150 - 0.06s - loss: 1.0934 - acc: 0.3574 - val_loss: 1.0969 - val_acc: 0.3340\n",
            "Epoch 74/150 - 0.06s - loss: 1.0932 - acc: 0.3585 - val_loss: 1.0968 - val_acc: 0.3340\n",
            "Epoch 75/150 - 0.06s - loss: 1.0930 - acc: 0.3585 - val_loss: 1.0966 - val_acc: 0.3320\n",
            "Epoch 76/150 - 0.06s - loss: 1.0928 - acc: 0.3587 - val_loss: 1.0964 - val_acc: 0.3320\n",
            "Epoch 77/150 - 0.06s - loss: 1.0926 - acc: 0.3590 - val_loss: 1.0963 - val_acc: 0.3320\n",
            "Epoch 78/150 - 0.06s - loss: 1.0924 - acc: 0.3621 - val_loss: 1.0961 - val_acc: 0.3320\n",
            "Epoch 79/150 - 0.06s - loss: 1.0923 - acc: 0.3617 - val_loss: 1.0960 - val_acc: 0.3320\n",
            "Epoch 80/150 - 0.06s - loss: 1.0921 - acc: 0.3628 - val_loss: 1.0958 - val_acc: 0.3340\n",
            "Epoch 81/150 - 0.06s - loss: 1.0919 - acc: 0.3630 - val_loss: 1.0957 - val_acc: 0.3360\n",
            "Epoch 82/150 - 0.06s - loss: 1.0917 - acc: 0.3644 - val_loss: 1.0955 - val_acc: 0.3401\n",
            "Epoch 83/150 - 0.06s - loss: 1.0915 - acc: 0.3653 - val_loss: 1.0954 - val_acc: 0.3482\n",
            "Epoch 84/150 - 0.06s - loss: 1.0914 - acc: 0.3671 - val_loss: 1.0952 - val_acc: 0.3502\n",
            "Epoch 85/150 - 0.06s - loss: 1.0912 - acc: 0.3677 - val_loss: 1.0951 - val_acc: 0.3502\n",
            "Epoch 86/150 - 0.06s - loss: 1.0910 - acc: 0.3677 - val_loss: 1.0949 - val_acc: 0.3522\n",
            "Epoch 87/150 - 0.06s - loss: 1.0908 - acc: 0.3675 - val_loss: 1.0948 - val_acc: 0.3522\n",
            "Epoch 88/150 - 0.06s - loss: 1.0907 - acc: 0.3673 - val_loss: 1.0947 - val_acc: 0.3563\n",
            "Epoch 89/150 - 0.06s - loss: 1.0905 - acc: 0.3675 - val_loss: 1.0945 - val_acc: 0.3563\n",
            "Epoch 90/150 - 0.06s - loss: 1.0903 - acc: 0.3675 - val_loss: 1.0944 - val_acc: 0.3563\n",
            "Epoch 91/150 - 0.06s - loss: 1.0901 - acc: 0.3680 - val_loss: 1.0942 - val_acc: 0.3563\n",
            "Epoch 92/150 - 0.06s - loss: 1.0900 - acc: 0.3691 - val_loss: 1.0941 - val_acc: 0.3563\n",
            "Epoch 93/150 - 0.06s - loss: 1.0898 - acc: 0.3693 - val_loss: 1.0939 - val_acc: 0.3543\n",
            "Epoch 94/150 - 0.06s - loss: 1.0896 - acc: 0.3695 - val_loss: 1.0938 - val_acc: 0.3522\n",
            "Epoch 95/150 - 0.06s - loss: 1.0895 - acc: 0.3707 - val_loss: 1.0937 - val_acc: 0.3502\n",
            "Epoch 96/150 - 0.06s - loss: 1.0893 - acc: 0.3707 - val_loss: 1.0935 - val_acc: 0.3502\n",
            "Epoch 97/150 - 0.06s - loss: 1.0891 - acc: 0.3716 - val_loss: 1.0934 - val_acc: 0.3502\n",
            "Epoch 98/150 - 0.06s - loss: 1.0890 - acc: 0.3722 - val_loss: 1.0933 - val_acc: 0.3502\n",
            "Epoch 99/150 - 0.06s - loss: 1.0888 - acc: 0.3722 - val_loss: 1.0931 - val_acc: 0.3502\n",
            "Epoch 100/150 - 0.06s - loss: 1.0887 - acc: 0.3725 - val_loss: 1.0930 - val_acc: 0.3462\n",
            "Epoch 101/150 - 0.06s - loss: 1.0885 - acc: 0.3734 - val_loss: 1.0929 - val_acc: 0.3441\n",
            "Epoch 102/150 - 0.06s - loss: 1.0883 - acc: 0.3734 - val_loss: 1.0927 - val_acc: 0.3462\n",
            "Epoch 103/150 - 0.06s - loss: 1.0882 - acc: 0.3743 - val_loss: 1.0926 - val_acc: 0.3482\n",
            "Epoch 104/150 - 0.06s - loss: 1.0880 - acc: 0.3747 - val_loss: 1.0925 - val_acc: 0.3502\n",
            "Epoch 105/150 - 0.06s - loss: 1.0879 - acc: 0.3756 - val_loss: 1.0923 - val_acc: 0.3482\n",
            "Epoch 106/150 - 0.06s - loss: 1.0877 - acc: 0.3770 - val_loss: 1.0922 - val_acc: 0.3482\n",
            "Epoch 107/150 - 0.06s - loss: 1.0876 - acc: 0.3776 - val_loss: 1.0921 - val_acc: 0.3462\n",
            "Epoch 108/150 - 0.06s - loss: 1.0874 - acc: 0.3794 - val_loss: 1.0920 - val_acc: 0.3482\n",
            "Epoch 109/150 - 0.06s - loss: 1.0872 - acc: 0.3801 - val_loss: 1.0918 - val_acc: 0.3543\n",
            "Epoch 110/150 - 0.06s - loss: 1.0871 - acc: 0.3803 - val_loss: 1.0917 - val_acc: 0.3563\n",
            "Epoch 111/150 - 0.06s - loss: 1.0869 - acc: 0.3821 - val_loss: 1.0916 - val_acc: 0.3563\n",
            "Epoch 112/150 - 0.05s - loss: 1.0868 - acc: 0.3817 - val_loss: 1.0915 - val_acc: 0.3563\n",
            "Epoch 113/150 - 0.06s - loss: 1.0866 - acc: 0.3810 - val_loss: 1.0913 - val_acc: 0.3583\n",
            "Epoch 114/150 - 0.06s - loss: 1.0865 - acc: 0.3826 - val_loss: 1.0912 - val_acc: 0.3583\n",
            "Epoch 115/150 - 0.06s - loss: 1.0863 - acc: 0.3842 - val_loss: 1.0911 - val_acc: 0.3603\n",
            "Epoch 116/150 - 0.06s - loss: 1.0862 - acc: 0.3844 - val_loss: 1.0910 - val_acc: 0.3603\n",
            "Epoch 117/150 - 0.06s - loss: 1.0860 - acc: 0.3851 - val_loss: 1.0909 - val_acc: 0.3603\n",
            "Epoch 118/150 - 0.06s - loss: 1.0859 - acc: 0.3862 - val_loss: 1.0907 - val_acc: 0.3603\n",
            "Epoch 119/150 - 0.06s - loss: 1.0858 - acc: 0.3873 - val_loss: 1.0906 - val_acc: 0.3644\n",
            "Epoch 120/150 - 0.06s - loss: 1.0856 - acc: 0.3880 - val_loss: 1.0905 - val_acc: 0.3623\n",
            "Epoch 121/150 - 0.06s - loss: 1.0855 - acc: 0.3878 - val_loss: 1.0904 - val_acc: 0.3623\n",
            "Epoch 122/150 - 0.06s - loss: 1.0853 - acc: 0.3889 - val_loss: 1.0903 - val_acc: 0.3603\n",
            "Epoch 123/150 - 0.06s - loss: 1.0852 - acc: 0.3887 - val_loss: 1.0901 - val_acc: 0.3644\n",
            "Epoch 124/150 - 0.06s - loss: 1.0850 - acc: 0.3887 - val_loss: 1.0900 - val_acc: 0.3664\n",
            "Epoch 125/150 - 0.06s - loss: 1.0849 - acc: 0.3900 - val_loss: 1.0899 - val_acc: 0.3664\n",
            "Epoch 126/150 - 0.06s - loss: 1.0848 - acc: 0.3918 - val_loss: 1.0898 - val_acc: 0.3664\n",
            "Epoch 127/150 - 0.06s - loss: 1.0846 - acc: 0.3925 - val_loss: 1.0897 - val_acc: 0.3684\n",
            "Epoch 128/150 - 0.06s - loss: 1.0845 - acc: 0.3925 - val_loss: 1.0896 - val_acc: 0.3704\n",
            "Epoch 129/150 - 0.06s - loss: 1.0843 - acc: 0.3925 - val_loss: 1.0895 - val_acc: 0.3704\n",
            "Epoch 130/150 - 0.06s - loss: 1.0842 - acc: 0.3923 - val_loss: 1.0893 - val_acc: 0.3704\n",
            "Epoch 131/150 - 0.06s - loss: 1.0841 - acc: 0.3927 - val_loss: 1.0892 - val_acc: 0.3704\n",
            "Epoch 132/150 - 0.06s - loss: 1.0839 - acc: 0.3927 - val_loss: 1.0891 - val_acc: 0.3704\n",
            "Epoch 133/150 - 0.06s - loss: 1.0838 - acc: 0.3932 - val_loss: 1.0890 - val_acc: 0.3704\n",
            "Epoch 134/150 - 0.06s - loss: 1.0837 - acc: 0.3936 - val_loss: 1.0889 - val_acc: 0.3704\n",
            "Epoch 135/150 - 0.07s - loss: 1.0835 - acc: 0.3934 - val_loss: 1.0888 - val_acc: 0.3704\n",
            "Epoch 136/150 - 0.06s - loss: 1.0834 - acc: 0.3943 - val_loss: 1.0887 - val_acc: 0.3725\n",
            "Epoch 137/150 - 0.06s - loss: 1.0832 - acc: 0.3943 - val_loss: 1.0886 - val_acc: 0.3725\n",
            "Epoch 138/150 - 0.07s - loss: 1.0831 - acc: 0.3950 - val_loss: 1.0885 - val_acc: 0.3725\n",
            "Epoch 139/150 - 0.06s - loss: 1.0830 - acc: 0.3956 - val_loss: 1.0884 - val_acc: 0.3785\n",
            "Epoch 140/150 - 0.06s - loss: 1.0828 - acc: 0.3956 - val_loss: 1.0882 - val_acc: 0.3785\n",
            "Epoch 141/150 - 0.06s - loss: 1.0827 - acc: 0.3968 - val_loss: 1.0881 - val_acc: 0.3765\n",
            "Epoch 142/150 - 0.06s - loss: 1.0826 - acc: 0.3977 - val_loss: 1.0880 - val_acc: 0.3765\n",
            "Epoch 143/150 - 0.06s - loss: 1.0825 - acc: 0.3988 - val_loss: 1.0879 - val_acc: 0.3785\n",
            "Epoch 144/150 - 0.06s - loss: 1.0823 - acc: 0.3992 - val_loss: 1.0878 - val_acc: 0.3785\n",
            "Epoch 145/150 - 0.06s - loss: 1.0822 - acc: 0.3992 - val_loss: 1.0877 - val_acc: 0.3785\n",
            "Epoch 146/150 - 0.06s - loss: 1.0821 - acc: 0.4006 - val_loss: 1.0876 - val_acc: 0.3806\n",
            "Epoch 147/150 - 0.06s - loss: 1.0819 - acc: 0.4006 - val_loss: 1.0875 - val_acc: 0.3806\n",
            "Epoch 148/150 - 0.06s - loss: 1.0818 - acc: 0.4013 - val_loss: 1.0874 - val_acc: 0.3826\n",
            "Epoch 149/150 - 0.05s - loss: 1.0817 - acc: 0.4013 - val_loss: 1.0873 - val_acc: 0.3826\n",
            "Epoch 150/150 - 0.06s - loss: 1.0816 - acc: 0.4028 - val_loss: 1.0872 - val_acc: 0.3826\n",
            "\n",
            "Combination 34/252:\n",
            "Hidden Layers: [64, 32], Activation: tanh, Learning Rate: 0.0001, Batch Size: 64, Epochs: 50\n",
            "Epoch 1/50 - 0.05s - loss: 1.1235 - acc: 0.3153 - val_loss: 1.1237 - val_acc: 0.3300\n",
            "Epoch 2/50 - 0.05s - loss: 1.1228 - acc: 0.3162 - val_loss: 1.1232 - val_acc: 0.3300\n",
            "Epoch 3/50 - 0.04s - loss: 1.1222 - acc: 0.3160 - val_loss: 1.1228 - val_acc: 0.3320\n",
            "Epoch 4/50 - 0.04s - loss: 1.1217 - acc: 0.3149 - val_loss: 1.1224 - val_acc: 0.3279\n",
            "Epoch 5/50 - 0.05s - loss: 1.1211 - acc: 0.3153 - val_loss: 1.1220 - val_acc: 0.3279\n",
            "Epoch 6/50 - 0.04s - loss: 1.1206 - acc: 0.3160 - val_loss: 1.1216 - val_acc: 0.3259\n",
            "Epoch 7/50 - 0.04s - loss: 1.1201 - acc: 0.3147 - val_loss: 1.1213 - val_acc: 0.3279\n",
            "Epoch 8/50 - 0.04s - loss: 1.1197 - acc: 0.3147 - val_loss: 1.1210 - val_acc: 0.3279\n",
            "Epoch 9/50 - 0.04s - loss: 1.1192 - acc: 0.3147 - val_loss: 1.1207 - val_acc: 0.3279\n",
            "Epoch 10/50 - 0.05s - loss: 1.1188 - acc: 0.3135 - val_loss: 1.1204 - val_acc: 0.3360\n",
            "Epoch 11/50 - 0.05s - loss: 1.1184 - acc: 0.3131 - val_loss: 1.1201 - val_acc: 0.3360\n",
            "Epoch 12/50 - 0.04s - loss: 1.1180 - acc: 0.3122 - val_loss: 1.1198 - val_acc: 0.3381\n",
            "Epoch 13/50 - 0.04s - loss: 1.1177 - acc: 0.3124 - val_loss: 1.1196 - val_acc: 0.3340\n",
            "Epoch 14/50 - 0.04s - loss: 1.1173 - acc: 0.3129 - val_loss: 1.1193 - val_acc: 0.3340\n",
            "Epoch 15/50 - 0.05s - loss: 1.1170 - acc: 0.3131 - val_loss: 1.1191 - val_acc: 0.3340\n",
            "Epoch 16/50 - 0.05s - loss: 1.1167 - acc: 0.3133 - val_loss: 1.1189 - val_acc: 0.3360\n",
            "Epoch 17/50 - 0.04s - loss: 1.1163 - acc: 0.3138 - val_loss: 1.1187 - val_acc: 0.3320\n",
            "Epoch 18/50 - 0.05s - loss: 1.1160 - acc: 0.3115 - val_loss: 1.1184 - val_acc: 0.3279\n",
            "Epoch 19/50 - 0.04s - loss: 1.1157 - acc: 0.3124 - val_loss: 1.1182 - val_acc: 0.3279\n",
            "Epoch 20/50 - 0.04s - loss: 1.1154 - acc: 0.3135 - val_loss: 1.1180 - val_acc: 0.3320\n",
            "Epoch 21/50 - 0.05s - loss: 1.1151 - acc: 0.3142 - val_loss: 1.1178 - val_acc: 0.3320\n",
            "Epoch 22/50 - 0.05s - loss: 1.1149 - acc: 0.3153 - val_loss: 1.1176 - val_acc: 0.3300\n",
            "Epoch 23/50 - 0.04s - loss: 1.1146 - acc: 0.3151 - val_loss: 1.1174 - val_acc: 0.3300\n",
            "Epoch 24/50 - 0.05s - loss: 1.1143 - acc: 0.3144 - val_loss: 1.1172 - val_acc: 0.3259\n",
            "Epoch 25/50 - 0.05s - loss: 1.1141 - acc: 0.3142 - val_loss: 1.1170 - val_acc: 0.3239\n",
            "Epoch 26/50 - 0.05s - loss: 1.1138 - acc: 0.3142 - val_loss: 1.1169 - val_acc: 0.3219\n",
            "Epoch 27/50 - 0.05s - loss: 1.1135 - acc: 0.3158 - val_loss: 1.1167 - val_acc: 0.3198\n",
            "Epoch 28/50 - 0.04s - loss: 1.1133 - acc: 0.3135 - val_loss: 1.1165 - val_acc: 0.3178\n",
            "Epoch 29/50 - 0.04s - loss: 1.1131 - acc: 0.3129 - val_loss: 1.1163 - val_acc: 0.3138\n",
            "Epoch 30/50 - 0.05s - loss: 1.1128 - acc: 0.3126 - val_loss: 1.1161 - val_acc: 0.3117\n",
            "Epoch 31/50 - 0.05s - loss: 1.1126 - acc: 0.3126 - val_loss: 1.1159 - val_acc: 0.3097\n",
            "Epoch 32/50 - 0.05s - loss: 1.1124 - acc: 0.3135 - val_loss: 1.1158 - val_acc: 0.3138\n",
            "Epoch 33/50 - 0.05s - loss: 1.1121 - acc: 0.3131 - val_loss: 1.1156 - val_acc: 0.3097\n",
            "Epoch 34/50 - 0.04s - loss: 1.1119 - acc: 0.3138 - val_loss: 1.1154 - val_acc: 0.3117\n",
            "Epoch 35/50 - 0.05s - loss: 1.1117 - acc: 0.3144 - val_loss: 1.1152 - val_acc: 0.3117\n",
            "Epoch 36/50 - 0.04s - loss: 1.1114 - acc: 0.3144 - val_loss: 1.1151 - val_acc: 0.3077\n",
            "Epoch 37/50 - 0.04s - loss: 1.1112 - acc: 0.3144 - val_loss: 1.1149 - val_acc: 0.3036\n",
            "Epoch 38/50 - 0.04s - loss: 1.1110 - acc: 0.3165 - val_loss: 1.1147 - val_acc: 0.3057\n",
            "Epoch 39/50 - 0.04s - loss: 1.1108 - acc: 0.3169 - val_loss: 1.1145 - val_acc: 0.3057\n",
            "Epoch 40/50 - 0.04s - loss: 1.1106 - acc: 0.3171 - val_loss: 1.1144 - val_acc: 0.3097\n",
            "Epoch 41/50 - 0.04s - loss: 1.1104 - acc: 0.3171 - val_loss: 1.1142 - val_acc: 0.3117\n",
            "Epoch 42/50 - 0.04s - loss: 1.1101 - acc: 0.3169 - val_loss: 1.1140 - val_acc: 0.3117\n",
            "Epoch 43/50 - 0.04s - loss: 1.1099 - acc: 0.3165 - val_loss: 1.1139 - val_acc: 0.3097\n",
            "Epoch 44/50 - 0.04s - loss: 1.1097 - acc: 0.3167 - val_loss: 1.1137 - val_acc: 0.3097\n",
            "Epoch 45/50 - 0.04s - loss: 1.1095 - acc: 0.3174 - val_loss: 1.1135 - val_acc: 0.3097\n",
            "Epoch 46/50 - 0.04s - loss: 1.1093 - acc: 0.3171 - val_loss: 1.1134 - val_acc: 0.3077\n",
            "Epoch 47/50 - 0.04s - loss: 1.1091 - acc: 0.3178 - val_loss: 1.1132 - val_acc: 0.3057\n",
            "Epoch 48/50 - 0.04s - loss: 1.1089 - acc: 0.3167 - val_loss: 1.1130 - val_acc: 0.3036\n",
            "Epoch 49/50 - 0.04s - loss: 1.1087 - acc: 0.3169 - val_loss: 1.1129 - val_acc: 0.3036\n",
            "Epoch 50/50 - 0.04s - loss: 1.1085 - acc: 0.3167 - val_loss: 1.1127 - val_acc: 0.3036\n",
            "\n",
            "Combination 35/252:\n",
            "Hidden Layers: [64, 32], Activation: tanh, Learning Rate: 0.0001, Batch Size: 64, Epochs: 100\n",
            "Epoch 1/100 - 0.05s - loss: 1.1199 - acc: 0.3133 - val_loss: 1.1167 - val_acc: 0.3178\n",
            "Epoch 2/100 - 0.05s - loss: 1.1188 - acc: 0.3144 - val_loss: 1.1156 - val_acc: 0.3158\n",
            "Epoch 3/100 - 0.04s - loss: 1.1177 - acc: 0.3158 - val_loss: 1.1146 - val_acc: 0.3138\n",
            "Epoch 4/100 - 0.04s - loss: 1.1167 - acc: 0.3176 - val_loss: 1.1136 - val_acc: 0.3097\n",
            "Epoch 5/100 - 0.05s - loss: 1.1157 - acc: 0.3176 - val_loss: 1.1127 - val_acc: 0.3097\n",
            "Epoch 6/100 - 0.05s - loss: 1.1148 - acc: 0.3176 - val_loss: 1.1118 - val_acc: 0.3117\n",
            "Epoch 7/100 - 0.04s - loss: 1.1140 - acc: 0.3178 - val_loss: 1.1110 - val_acc: 0.3117\n",
            "Epoch 8/100 - 0.04s - loss: 1.1132 - acc: 0.3178 - val_loss: 1.1103 - val_acc: 0.3138\n",
            "Epoch 9/100 - 0.04s - loss: 1.1124 - acc: 0.3183 - val_loss: 1.1095 - val_acc: 0.3158\n",
            "Epoch 10/100 - 0.05s - loss: 1.1117 - acc: 0.3180 - val_loss: 1.1089 - val_acc: 0.3117\n",
            "Epoch 11/100 - 0.05s - loss: 1.1110 - acc: 0.3189 - val_loss: 1.1082 - val_acc: 0.3138\n",
            "Epoch 12/100 - 0.05s - loss: 1.1104 - acc: 0.3196 - val_loss: 1.1076 - val_acc: 0.3198\n",
            "Epoch 13/100 - 0.05s - loss: 1.1098 - acc: 0.3194 - val_loss: 1.1070 - val_acc: 0.3219\n",
            "Epoch 14/100 - 0.05s - loss: 1.1092 - acc: 0.3210 - val_loss: 1.1064 - val_acc: 0.3239\n",
            "Epoch 15/100 - 0.05s - loss: 1.1086 - acc: 0.3207 - val_loss: 1.1059 - val_acc: 0.3259\n",
            "Epoch 16/100 - 0.05s - loss: 1.1081 - acc: 0.3230 - val_loss: 1.1054 - val_acc: 0.3239\n",
            "Epoch 17/100 - 0.04s - loss: 1.1076 - acc: 0.3250 - val_loss: 1.1050 - val_acc: 0.3259\n",
            "Epoch 18/100 - 0.04s - loss: 1.1071 - acc: 0.3261 - val_loss: 1.1045 - val_acc: 0.3300\n",
            "Epoch 19/100 - 0.04s - loss: 1.1067 - acc: 0.3261 - val_loss: 1.1041 - val_acc: 0.3320\n",
            "Epoch 20/100 - 0.04s - loss: 1.1063 - acc: 0.3255 - val_loss: 1.1037 - val_acc: 0.3300\n",
            "Epoch 21/100 - 0.04s - loss: 1.1059 - acc: 0.3275 - val_loss: 1.1033 - val_acc: 0.3320\n",
            "Epoch 22/100 - 0.05s - loss: 1.1055 - acc: 0.3277 - val_loss: 1.1029 - val_acc: 0.3300\n",
            "Epoch 23/100 - 0.05s - loss: 1.1051 - acc: 0.3284 - val_loss: 1.1026 - val_acc: 0.3300\n",
            "Epoch 24/100 - 0.05s - loss: 1.1048 - acc: 0.3295 - val_loss: 1.1023 - val_acc: 0.3300\n",
            "Epoch 25/100 - 0.05s - loss: 1.1044 - acc: 0.3304 - val_loss: 1.1019 - val_acc: 0.3300\n",
            "Epoch 26/100 - 0.05s - loss: 1.1041 - acc: 0.3311 - val_loss: 1.1016 - val_acc: 0.3300\n",
            "Epoch 27/100 - 0.04s - loss: 1.1038 - acc: 0.3313 - val_loss: 1.1014 - val_acc: 0.3279\n",
            "Epoch 28/100 - 0.04s - loss: 1.1035 - acc: 0.3309 - val_loss: 1.1011 - val_acc: 0.3259\n",
            "Epoch 29/100 - 0.04s - loss: 1.1032 - acc: 0.3327 - val_loss: 1.1008 - val_acc: 0.3300\n",
            "Epoch 30/100 - 0.04s - loss: 1.1030 - acc: 0.3336 - val_loss: 1.1006 - val_acc: 0.3381\n",
            "Epoch 31/100 - 0.05s - loss: 1.1027 - acc: 0.3342 - val_loss: 1.1004 - val_acc: 0.3401\n",
            "Epoch 32/100 - 0.04s - loss: 1.1025 - acc: 0.3354 - val_loss: 1.1001 - val_acc: 0.3462\n",
            "Epoch 33/100 - 0.04s - loss: 1.1022 - acc: 0.3360 - val_loss: 1.0999 - val_acc: 0.3482\n",
            "Epoch 34/100 - 0.04s - loss: 1.1020 - acc: 0.3360 - val_loss: 1.0997 - val_acc: 0.3502\n",
            "Epoch 35/100 - 0.04s - loss: 1.1018 - acc: 0.3374 - val_loss: 1.0995 - val_acc: 0.3502\n",
            "Epoch 36/100 - 0.05s - loss: 1.1016 - acc: 0.3385 - val_loss: 1.0993 - val_acc: 0.3543\n",
            "Epoch 37/100 - 0.04s - loss: 1.1014 - acc: 0.3417 - val_loss: 1.0991 - val_acc: 0.3522\n",
            "Epoch 38/100 - 0.04s - loss: 1.1012 - acc: 0.3408 - val_loss: 1.0990 - val_acc: 0.3502\n",
            "Epoch 39/100 - 0.05s - loss: 1.1010 - acc: 0.3426 - val_loss: 1.0988 - val_acc: 0.3441\n",
            "Epoch 40/100 - 0.05s - loss: 1.1009 - acc: 0.3441 - val_loss: 1.0986 - val_acc: 0.3462\n",
            "Epoch 41/100 - 0.05s - loss: 1.1007 - acc: 0.3462 - val_loss: 1.0985 - val_acc: 0.3441\n",
            "Epoch 42/100 - 0.04s - loss: 1.1005 - acc: 0.3468 - val_loss: 1.0983 - val_acc: 0.3462\n",
            "Epoch 43/100 - 0.05s - loss: 1.1004 - acc: 0.3475 - val_loss: 1.0982 - val_acc: 0.3482\n",
            "Epoch 44/100 - 0.04s - loss: 1.1002 - acc: 0.3486 - val_loss: 1.0980 - val_acc: 0.3482\n",
            "Epoch 45/100 - 0.04s - loss: 1.1001 - acc: 0.3509 - val_loss: 1.0979 - val_acc: 0.3482\n",
            "Epoch 46/100 - 0.05s - loss: 1.0999 - acc: 0.3531 - val_loss: 1.0978 - val_acc: 0.3482\n",
            "Epoch 47/100 - 0.05s - loss: 1.0998 - acc: 0.3529 - val_loss: 1.0977 - val_acc: 0.3522\n",
            "Epoch 48/100 - 0.04s - loss: 1.0997 - acc: 0.3522 - val_loss: 1.0975 - val_acc: 0.3502\n",
            "Epoch 49/100 - 0.04s - loss: 1.0995 - acc: 0.3522 - val_loss: 1.0974 - val_acc: 0.3543\n",
            "Epoch 50/100 - 0.05s - loss: 1.0994 - acc: 0.3525 - val_loss: 1.0973 - val_acc: 0.3563\n",
            "Epoch 51/100 - 0.05s - loss: 1.0993 - acc: 0.3520 - val_loss: 1.0972 - val_acc: 0.3522\n",
            "Epoch 52/100 - 0.04s - loss: 1.0991 - acc: 0.3538 - val_loss: 1.0971 - val_acc: 0.3522\n",
            "Epoch 53/100 - 0.05s - loss: 1.0990 - acc: 0.3525 - val_loss: 1.0970 - val_acc: 0.3502\n",
            "Epoch 54/100 - 0.04s - loss: 1.0989 - acc: 0.3538 - val_loss: 1.0969 - val_acc: 0.3462\n",
            "Epoch 55/100 - 0.05s - loss: 1.0988 - acc: 0.3556 - val_loss: 1.0968 - val_acc: 0.3502\n",
            "Epoch 56/100 - 0.05s - loss: 1.0987 - acc: 0.3570 - val_loss: 1.0967 - val_acc: 0.3482\n",
            "Epoch 57/100 - 0.04s - loss: 1.0986 - acc: 0.3590 - val_loss: 1.0966 - val_acc: 0.3462\n",
            "Epoch 58/100 - 0.04s - loss: 1.0985 - acc: 0.3585 - val_loss: 1.0965 - val_acc: 0.3381\n",
            "Epoch 59/100 - 0.04s - loss: 1.0984 - acc: 0.3583 - val_loss: 1.0964 - val_acc: 0.3360\n",
            "Epoch 60/100 - 0.05s - loss: 1.0983 - acc: 0.3578 - val_loss: 1.0963 - val_acc: 0.3421\n",
            "Epoch 61/100 - 0.05s - loss: 1.0982 - acc: 0.3590 - val_loss: 1.0962 - val_acc: 0.3441\n",
            "Epoch 62/100 - 0.05s - loss: 1.0981 - acc: 0.3592 - val_loss: 1.0961 - val_acc: 0.3462\n",
            "Epoch 63/100 - 0.04s - loss: 1.0980 - acc: 0.3583 - val_loss: 1.0960 - val_acc: 0.3421\n",
            "Epoch 64/100 - 0.04s - loss: 1.0979 - acc: 0.3576 - val_loss: 1.0959 - val_acc: 0.3441\n",
            "Epoch 65/100 - 0.05s - loss: 1.0978 - acc: 0.3610 - val_loss: 1.0958 - val_acc: 0.3502\n",
            "Epoch 66/100 - 0.05s - loss: 1.0977 - acc: 0.3596 - val_loss: 1.0958 - val_acc: 0.3462\n",
            "Epoch 67/100 - 0.05s - loss: 1.0976 - acc: 0.3599 - val_loss: 1.0957 - val_acc: 0.3401\n",
            "Epoch 68/100 - 0.04s - loss: 1.0975 - acc: 0.3610 - val_loss: 1.0956 - val_acc: 0.3401\n",
            "Epoch 69/100 - 0.04s - loss: 1.0974 - acc: 0.3605 - val_loss: 1.0955 - val_acc: 0.3381\n",
            "Epoch 70/100 - 0.05s - loss: 1.0973 - acc: 0.3619 - val_loss: 1.0954 - val_acc: 0.3381\n",
            "Epoch 71/100 - 0.05s - loss: 1.0972 - acc: 0.3614 - val_loss: 1.0953 - val_acc: 0.3441\n",
            "Epoch 72/100 - 0.05s - loss: 1.0971 - acc: 0.3599 - val_loss: 1.0953 - val_acc: 0.3462\n",
            "Epoch 73/100 - 0.05s - loss: 1.0971 - acc: 0.3596 - val_loss: 1.0952 - val_acc: 0.3502\n",
            "Epoch 74/100 - 0.04s - loss: 1.0970 - acc: 0.3592 - val_loss: 1.0951 - val_acc: 0.3522\n",
            "Epoch 75/100 - 0.05s - loss: 1.0969 - acc: 0.3590 - val_loss: 1.0950 - val_acc: 0.3522\n",
            "Epoch 76/100 - 0.04s - loss: 1.0968 - acc: 0.3581 - val_loss: 1.0950 - val_acc: 0.3543\n",
            "Epoch 77/100 - 0.05s - loss: 1.0967 - acc: 0.3578 - val_loss: 1.0949 - val_acc: 0.3563\n",
            "Epoch 78/100 - 0.05s - loss: 1.0966 - acc: 0.3585 - val_loss: 1.0948 - val_acc: 0.3603\n",
            "Epoch 79/100 - 0.05s - loss: 1.0966 - acc: 0.3576 - val_loss: 1.0948 - val_acc: 0.3603\n",
            "Epoch 80/100 - 0.05s - loss: 1.0965 - acc: 0.3590 - val_loss: 1.0947 - val_acc: 0.3623\n",
            "Epoch 81/100 - 0.05s - loss: 1.0964 - acc: 0.3583 - val_loss: 1.0946 - val_acc: 0.3623\n",
            "Epoch 82/100 - 0.05s - loss: 1.0963 - acc: 0.3574 - val_loss: 1.0945 - val_acc: 0.3623\n",
            "Epoch 83/100 - 0.05s - loss: 1.0962 - acc: 0.3587 - val_loss: 1.0945 - val_acc: 0.3644\n",
            "Epoch 84/100 - 0.05s - loss: 1.0962 - acc: 0.3576 - val_loss: 1.0944 - val_acc: 0.3644\n",
            "Epoch 85/100 - 0.05s - loss: 1.0961 - acc: 0.3587 - val_loss: 1.0943 - val_acc: 0.3644\n",
            "Epoch 86/100 - 0.06s - loss: 1.0960 - acc: 0.3587 - val_loss: 1.0943 - val_acc: 0.3644\n",
            "Epoch 87/100 - 0.05s - loss: 1.0959 - acc: 0.3596 - val_loss: 1.0942 - val_acc: 0.3644\n",
            "Epoch 88/100 - 0.05s - loss: 1.0958 - acc: 0.3596 - val_loss: 1.0941 - val_acc: 0.3644\n",
            "Epoch 89/100 - 0.05s - loss: 1.0958 - acc: 0.3599 - val_loss: 1.0941 - val_acc: 0.3664\n",
            "Epoch 90/100 - 0.05s - loss: 1.0957 - acc: 0.3605 - val_loss: 1.0940 - val_acc: 0.3664\n",
            "Epoch 91/100 - 0.05s - loss: 1.0956 - acc: 0.3601 - val_loss: 1.0939 - val_acc: 0.3684\n",
            "Epoch 92/100 - 0.05s - loss: 1.0955 - acc: 0.3612 - val_loss: 1.0939 - val_acc: 0.3664\n",
            "Epoch 93/100 - 0.05s - loss: 1.0955 - acc: 0.3605 - val_loss: 1.0938 - val_acc: 0.3664\n",
            "Epoch 94/100 - 0.05s - loss: 1.0954 - acc: 0.3610 - val_loss: 1.0937 - val_acc: 0.3684\n",
            "Epoch 95/100 - 0.05s - loss: 1.0953 - acc: 0.3617 - val_loss: 1.0937 - val_acc: 0.3725\n",
            "Epoch 96/100 - 0.05s - loss: 1.0952 - acc: 0.3614 - val_loss: 1.0936 - val_acc: 0.3745\n",
            "Epoch 97/100 - 0.04s - loss: 1.0952 - acc: 0.3610 - val_loss: 1.0936 - val_acc: 0.3725\n",
            "Epoch 98/100 - 0.05s - loss: 1.0951 - acc: 0.3608 - val_loss: 1.0935 - val_acc: 0.3745\n",
            "Epoch 99/100 - 0.05s - loss: 1.0950 - acc: 0.3610 - val_loss: 1.0934 - val_acc: 0.3765\n",
            "Epoch 100/100 - 0.05s - loss: 1.0949 - acc: 0.3612 - val_loss: 1.0934 - val_acc: 0.3765\n",
            "\n",
            "Combination 36/252:\n",
            "Hidden Layers: [64, 32], Activation: tanh, Learning Rate: 0.0001, Batch Size: 64, Epochs: 150\n",
            "Epoch 1/150 - 0.04s - loss: 1.1015 - acc: 0.3408 - val_loss: 1.1045 - val_acc: 0.3563\n",
            "Epoch 2/150 - 0.05s - loss: 1.1013 - acc: 0.3426 - val_loss: 1.1044 - val_acc: 0.3563\n",
            "Epoch 3/150 - 0.05s - loss: 1.1011 - acc: 0.3437 - val_loss: 1.1043 - val_acc: 0.3543\n",
            "Epoch 4/150 - 0.05s - loss: 1.1009 - acc: 0.3450 - val_loss: 1.1041 - val_acc: 0.3563\n",
            "Epoch 5/150 - 0.05s - loss: 1.1008 - acc: 0.3444 - val_loss: 1.1040 - val_acc: 0.3583\n",
            "Epoch 6/150 - 0.05s - loss: 1.1006 - acc: 0.3428 - val_loss: 1.1039 - val_acc: 0.3583\n",
            "Epoch 7/150 - 0.05s - loss: 1.1004 - acc: 0.3435 - val_loss: 1.1038 - val_acc: 0.3522\n",
            "Epoch 8/150 - 0.04s - loss: 1.1003 - acc: 0.3439 - val_loss: 1.1037 - val_acc: 0.3502\n",
            "Epoch 9/150 - 0.05s - loss: 1.1001 - acc: 0.3446 - val_loss: 1.1036 - val_acc: 0.3502\n",
            "Epoch 10/150 - 0.05s - loss: 1.1000 - acc: 0.3441 - val_loss: 1.1035 - val_acc: 0.3522\n",
            "Epoch 11/150 - 0.04s - loss: 1.0998 - acc: 0.3444 - val_loss: 1.1034 - val_acc: 0.3502\n",
            "Epoch 12/150 - 0.04s - loss: 1.0997 - acc: 0.3441 - val_loss: 1.1033 - val_acc: 0.3502\n",
            "Epoch 13/150 - 0.04s - loss: 1.0995 - acc: 0.3441 - val_loss: 1.1032 - val_acc: 0.3502\n",
            "Epoch 14/150 - 0.05s - loss: 1.0994 - acc: 0.3437 - val_loss: 1.1031 - val_acc: 0.3441\n",
            "Epoch 15/150 - 0.04s - loss: 1.0993 - acc: 0.3435 - val_loss: 1.1031 - val_acc: 0.3421\n",
            "Epoch 16/150 - 0.04s - loss: 1.0991 - acc: 0.3430 - val_loss: 1.1030 - val_acc: 0.3421\n",
            "Epoch 17/150 - 0.04s - loss: 1.0990 - acc: 0.3441 - val_loss: 1.1029 - val_acc: 0.3441\n",
            "Epoch 18/150 - 0.04s - loss: 1.0989 - acc: 0.3468 - val_loss: 1.1028 - val_acc: 0.3421\n",
            "Epoch 19/150 - 0.04s - loss: 1.0987 - acc: 0.3462 - val_loss: 1.1027 - val_acc: 0.3381\n",
            "Epoch 20/150 - 0.05s - loss: 1.0986 - acc: 0.3464 - val_loss: 1.1026 - val_acc: 0.3401\n",
            "Epoch 21/150 - 0.04s - loss: 1.0985 - acc: 0.3471 - val_loss: 1.1026 - val_acc: 0.3401\n",
            "Epoch 22/150 - 0.04s - loss: 1.0984 - acc: 0.3473 - val_loss: 1.1025 - val_acc: 0.3401\n",
            "Epoch 23/150 - 0.05s - loss: 1.0983 - acc: 0.3484 - val_loss: 1.1024 - val_acc: 0.3381\n",
            "Epoch 24/150 - 0.04s - loss: 1.0982 - acc: 0.3473 - val_loss: 1.1024 - val_acc: 0.3381\n",
            "Epoch 25/150 - 0.04s - loss: 1.0981 - acc: 0.3475 - val_loss: 1.1023 - val_acc: 0.3381\n",
            "Epoch 26/150 - 0.04s - loss: 1.0980 - acc: 0.3477 - val_loss: 1.1022 - val_acc: 0.3401\n",
            "Epoch 27/150 - 0.04s - loss: 1.0979 - acc: 0.3477 - val_loss: 1.1021 - val_acc: 0.3401\n",
            "Epoch 28/150 - 0.04s - loss: 1.0978 - acc: 0.3480 - val_loss: 1.1021 - val_acc: 0.3360\n",
            "Epoch 29/150 - 0.04s - loss: 1.0976 - acc: 0.3484 - val_loss: 1.1020 - val_acc: 0.3340\n",
            "Epoch 30/150 - 0.05s - loss: 1.0975 - acc: 0.3468 - val_loss: 1.1019 - val_acc: 0.3340\n",
            "Epoch 31/150 - 0.04s - loss: 1.0974 - acc: 0.3475 - val_loss: 1.1019 - val_acc: 0.3300\n",
            "Epoch 32/150 - 0.04s - loss: 1.0973 - acc: 0.3466 - val_loss: 1.1018 - val_acc: 0.3300\n",
            "Epoch 33/150 - 0.05s - loss: 1.0972 - acc: 0.3473 - val_loss: 1.1017 - val_acc: 0.3279\n",
            "Epoch 34/150 - 0.05s - loss: 1.0972 - acc: 0.3473 - val_loss: 1.1017 - val_acc: 0.3279\n",
            "Epoch 35/150 - 0.05s - loss: 1.0971 - acc: 0.3484 - val_loss: 1.1016 - val_acc: 0.3259\n",
            "Epoch 36/150 - 0.04s - loss: 1.0970 - acc: 0.3482 - val_loss: 1.1015 - val_acc: 0.3300\n",
            "Epoch 37/150 - 0.04s - loss: 1.0969 - acc: 0.3473 - val_loss: 1.1015 - val_acc: 0.3320\n",
            "Epoch 38/150 - 0.04s - loss: 1.0968 - acc: 0.3471 - val_loss: 1.1014 - val_acc: 0.3340\n",
            "Epoch 39/150 - 0.05s - loss: 1.0967 - acc: 0.3477 - val_loss: 1.1014 - val_acc: 0.3360\n",
            "Epoch 40/150 - 0.04s - loss: 1.0966 - acc: 0.3471 - val_loss: 1.1013 - val_acc: 0.3340\n",
            "Epoch 41/150 - 0.04s - loss: 1.0965 - acc: 0.3473 - val_loss: 1.1012 - val_acc: 0.3279\n",
            "Epoch 42/150 - 0.05s - loss: 1.0964 - acc: 0.3466 - val_loss: 1.1012 - val_acc: 0.3279\n",
            "Epoch 43/150 - 0.04s - loss: 1.0963 - acc: 0.3482 - val_loss: 1.1011 - val_acc: 0.3279\n",
            "Epoch 44/150 - 0.04s - loss: 1.0962 - acc: 0.3477 - val_loss: 1.1011 - val_acc: 0.3279\n",
            "Epoch 45/150 - 0.04s - loss: 1.0962 - acc: 0.3480 - val_loss: 1.1010 - val_acc: 0.3300\n",
            "Epoch 46/150 - 0.04s - loss: 1.0961 - acc: 0.3482 - val_loss: 1.1009 - val_acc: 0.3300\n",
            "Epoch 47/150 - 0.04s - loss: 1.0960 - acc: 0.3495 - val_loss: 1.1009 - val_acc: 0.3259\n",
            "Epoch 48/150 - 0.04s - loss: 1.0959 - acc: 0.3500 - val_loss: 1.1008 - val_acc: 0.3259\n",
            "Epoch 49/150 - 0.04s - loss: 1.0958 - acc: 0.3504 - val_loss: 1.1007 - val_acc: 0.3279\n",
            "Epoch 50/150 - 0.05s - loss: 1.0957 - acc: 0.3516 - val_loss: 1.1007 - val_acc: 0.3259\n",
            "Epoch 51/150 - 0.04s - loss: 1.0956 - acc: 0.3520 - val_loss: 1.1006 - val_acc: 0.3219\n",
            "Epoch 52/150 - 0.04s - loss: 1.0956 - acc: 0.3522 - val_loss: 1.1006 - val_acc: 0.3219\n",
            "Epoch 53/150 - 0.05s - loss: 1.0955 - acc: 0.3529 - val_loss: 1.1005 - val_acc: 0.3239\n",
            "Epoch 54/150 - 0.04s - loss: 1.0954 - acc: 0.3543 - val_loss: 1.1005 - val_acc: 0.3259\n",
            "Epoch 55/150 - 0.05s - loss: 1.0953 - acc: 0.3543 - val_loss: 1.1004 - val_acc: 0.3279\n",
            "Epoch 56/150 - 0.04s - loss: 1.0952 - acc: 0.3540 - val_loss: 1.1003 - val_acc: 0.3300\n",
            "Epoch 57/150 - 0.04s - loss: 1.0951 - acc: 0.3549 - val_loss: 1.1003 - val_acc: 0.3300\n",
            "Epoch 58/150 - 0.04s - loss: 1.0951 - acc: 0.3540 - val_loss: 1.1002 - val_acc: 0.3300\n",
            "Epoch 59/150 - 0.05s - loss: 1.0950 - acc: 0.3547 - val_loss: 1.1002 - val_acc: 0.3320\n",
            "Epoch 60/150 - 0.04s - loss: 1.0949 - acc: 0.3549 - val_loss: 1.1001 - val_acc: 0.3320\n",
            "Epoch 61/150 - 0.04s - loss: 1.0948 - acc: 0.3561 - val_loss: 1.1000 - val_acc: 0.3320\n",
            "Epoch 62/150 - 0.04s - loss: 1.0947 - acc: 0.3556 - val_loss: 1.1000 - val_acc: 0.3360\n",
            "Epoch 63/150 - 0.04s - loss: 1.0947 - acc: 0.3547 - val_loss: 1.0999 - val_acc: 0.3381\n",
            "Epoch 64/150 - 0.04s - loss: 1.0946 - acc: 0.3563 - val_loss: 1.0999 - val_acc: 0.3381\n",
            "Epoch 65/150 - 0.05s - loss: 1.0945 - acc: 0.3570 - val_loss: 1.0998 - val_acc: 0.3381\n",
            "Epoch 66/150 - 0.05s - loss: 1.0944 - acc: 0.3565 - val_loss: 1.0998 - val_acc: 0.3381\n",
            "Epoch 67/150 - 0.04s - loss: 1.0944 - acc: 0.3578 - val_loss: 1.0997 - val_acc: 0.3381\n",
            "Epoch 68/150 - 0.05s - loss: 1.0943 - acc: 0.3585 - val_loss: 1.0996 - val_acc: 0.3381\n",
            "Epoch 69/150 - 0.04s - loss: 1.0942 - acc: 0.3590 - val_loss: 1.0996 - val_acc: 0.3381\n",
            "Epoch 70/150 - 0.05s - loss: 1.0941 - acc: 0.3590 - val_loss: 1.0995 - val_acc: 0.3401\n",
            "Epoch 71/150 - 0.04s - loss: 1.0940 - acc: 0.3594 - val_loss: 1.0995 - val_acc: 0.3381\n",
            "Epoch 72/150 - 0.04s - loss: 1.0940 - acc: 0.3599 - val_loss: 1.0994 - val_acc: 0.3360\n",
            "Epoch 73/150 - 0.04s - loss: 1.0939 - acc: 0.3601 - val_loss: 1.0993 - val_acc: 0.3381\n",
            "Epoch 74/150 - 0.05s - loss: 1.0938 - acc: 0.3614 - val_loss: 1.0993 - val_acc: 0.3381\n",
            "Epoch 75/150 - 0.05s - loss: 1.0937 - acc: 0.3623 - val_loss: 1.0992 - val_acc: 0.3381\n",
            "Epoch 76/150 - 0.04s - loss: 1.0937 - acc: 0.3619 - val_loss: 1.0992 - val_acc: 0.3381\n",
            "Epoch 77/150 - 0.04s - loss: 1.0936 - acc: 0.3630 - val_loss: 1.0991 - val_acc: 0.3381\n",
            "Epoch 78/150 - 0.04s - loss: 1.0935 - acc: 0.3630 - val_loss: 1.0991 - val_acc: 0.3381\n",
            "Epoch 79/150 - 0.04s - loss: 1.0934 - acc: 0.3630 - val_loss: 1.0990 - val_acc: 0.3401\n",
            "Epoch 80/150 - 0.05s - loss: 1.0934 - acc: 0.3637 - val_loss: 1.0990 - val_acc: 0.3421\n",
            "Epoch 81/150 - 0.04s - loss: 1.0933 - acc: 0.3641 - val_loss: 1.0989 - val_acc: 0.3441\n",
            "Epoch 82/150 - 0.04s - loss: 1.0932 - acc: 0.3644 - val_loss: 1.0988 - val_acc: 0.3441\n",
            "Epoch 83/150 - 0.04s - loss: 1.0931 - acc: 0.3641 - val_loss: 1.0988 - val_acc: 0.3441\n",
            "Epoch 84/150 - 0.05s - loss: 1.0931 - acc: 0.3648 - val_loss: 1.0987 - val_acc: 0.3441\n",
            "Epoch 85/150 - 0.05s - loss: 1.0930 - acc: 0.3650 - val_loss: 1.0987 - val_acc: 0.3462\n",
            "Epoch 86/150 - 0.04s - loss: 1.0929 - acc: 0.3648 - val_loss: 1.0986 - val_acc: 0.3482\n",
            "Epoch 87/150 - 0.04s - loss: 1.0928 - acc: 0.3657 - val_loss: 1.0986 - val_acc: 0.3502\n",
            "Epoch 88/150 - 0.04s - loss: 1.0928 - acc: 0.3657 - val_loss: 1.0985 - val_acc: 0.3502\n",
            "Epoch 89/150 - 0.05s - loss: 1.0927 - acc: 0.3657 - val_loss: 1.0984 - val_acc: 0.3502\n",
            "Epoch 90/150 - 0.04s - loss: 1.0926 - acc: 0.3659 - val_loss: 1.0984 - val_acc: 0.3482\n",
            "Epoch 91/150 - 0.04s - loss: 1.0926 - acc: 0.3666 - val_loss: 1.0983 - val_acc: 0.3482\n",
            "Epoch 92/150 - 0.04s - loss: 1.0925 - acc: 0.3668 - val_loss: 1.0983 - val_acc: 0.3482\n",
            "Epoch 93/150 - 0.04s - loss: 1.0924 - acc: 0.3673 - val_loss: 1.0982 - val_acc: 0.3482\n",
            "Epoch 94/150 - 0.04s - loss: 1.0923 - acc: 0.3671 - val_loss: 1.0982 - val_acc: 0.3502\n",
            "Epoch 95/150 - 0.05s - loss: 1.0923 - acc: 0.3673 - val_loss: 1.0981 - val_acc: 0.3502\n",
            "Epoch 96/150 - 0.04s - loss: 1.0922 - acc: 0.3682 - val_loss: 1.0981 - val_acc: 0.3502\n",
            "Epoch 97/150 - 0.04s - loss: 1.0921 - acc: 0.3684 - val_loss: 1.0980 - val_acc: 0.3482\n",
            "Epoch 98/150 - 0.04s - loss: 1.0921 - acc: 0.3695 - val_loss: 1.0979 - val_acc: 0.3482\n",
            "Epoch 99/150 - 0.04s - loss: 1.0920 - acc: 0.3689 - val_loss: 1.0979 - val_acc: 0.3482\n",
            "Epoch 100/150 - 0.05s - loss: 1.0919 - acc: 0.3689 - val_loss: 1.0978 - val_acc: 0.3482\n",
            "Epoch 101/150 - 0.04s - loss: 1.0918 - acc: 0.3689 - val_loss: 1.0978 - val_acc: 0.3482\n",
            "Epoch 102/150 - 0.04s - loss: 1.0918 - acc: 0.3689 - val_loss: 1.0977 - val_acc: 0.3502\n",
            "Epoch 103/150 - 0.04s - loss: 1.0917 - acc: 0.3684 - val_loss: 1.0977 - val_acc: 0.3502\n",
            "Epoch 104/150 - 0.04s - loss: 1.0916 - acc: 0.3684 - val_loss: 1.0976 - val_acc: 0.3522\n",
            "Epoch 105/150 - 0.05s - loss: 1.0916 - acc: 0.3686 - val_loss: 1.0976 - val_acc: 0.3522\n",
            "Epoch 106/150 - 0.04s - loss: 1.0915 - acc: 0.3691 - val_loss: 1.0975 - val_acc: 0.3522\n",
            "Epoch 107/150 - 0.04s - loss: 1.0914 - acc: 0.3698 - val_loss: 1.0975 - val_acc: 0.3522\n",
            "Epoch 108/150 - 0.04s - loss: 1.0914 - acc: 0.3711 - val_loss: 1.0974 - val_acc: 0.3522\n",
            "Epoch 109/150 - 0.04s - loss: 1.0913 - acc: 0.3718 - val_loss: 1.0973 - val_acc: 0.3522\n",
            "Epoch 110/150 - 0.04s - loss: 1.0912 - acc: 0.3716 - val_loss: 1.0973 - val_acc: 0.3522\n",
            "Epoch 111/150 - 0.04s - loss: 1.0912 - acc: 0.3716 - val_loss: 1.0972 - val_acc: 0.3522\n",
            "Epoch 112/150 - 0.04s - loss: 1.0911 - acc: 0.3722 - val_loss: 1.0972 - val_acc: 0.3522\n",
            "Epoch 113/150 - 0.04s - loss: 1.0910 - acc: 0.3727 - val_loss: 1.0971 - val_acc: 0.3543\n",
            "Epoch 114/150 - 0.04s - loss: 1.0909 - acc: 0.3729 - val_loss: 1.0971 - val_acc: 0.3543\n",
            "Epoch 115/150 - 0.04s - loss: 1.0909 - acc: 0.3734 - val_loss: 1.0970 - val_acc: 0.3543\n",
            "Epoch 116/150 - 0.04s - loss: 1.0908 - acc: 0.3727 - val_loss: 1.0970 - val_acc: 0.3522\n",
            "Epoch 117/150 - 0.04s - loss: 1.0907 - acc: 0.3725 - val_loss: 1.0969 - val_acc: 0.3563\n",
            "Epoch 118/150 - 0.04s - loss: 1.0907 - acc: 0.3725 - val_loss: 1.0969 - val_acc: 0.3543\n",
            "Epoch 119/150 - 0.04s - loss: 1.0906 - acc: 0.3729 - val_loss: 1.0968 - val_acc: 0.3543\n",
            "Epoch 120/150 - 0.04s - loss: 1.0905 - acc: 0.3727 - val_loss: 1.0968 - val_acc: 0.3543\n",
            "Epoch 121/150 - 0.04s - loss: 1.0905 - acc: 0.3734 - val_loss: 1.0967 - val_acc: 0.3522\n",
            "Epoch 122/150 - 0.04s - loss: 1.0904 - acc: 0.3731 - val_loss: 1.0967 - val_acc: 0.3522\n",
            "Epoch 123/150 - 0.04s - loss: 1.0903 - acc: 0.3738 - val_loss: 1.0966 - val_acc: 0.3522\n",
            "Epoch 124/150 - 0.04s - loss: 1.0903 - acc: 0.3747 - val_loss: 1.0966 - val_acc: 0.3543\n",
            "Epoch 125/150 - 0.04s - loss: 1.0902 - acc: 0.3752 - val_loss: 1.0965 - val_acc: 0.3543\n",
            "Epoch 126/150 - 0.04s - loss: 1.0901 - acc: 0.3765 - val_loss: 1.0964 - val_acc: 0.3543\n",
            "Epoch 127/150 - 0.04s - loss: 1.0901 - acc: 0.3770 - val_loss: 1.0964 - val_acc: 0.3543\n",
            "Epoch 128/150 - 0.04s - loss: 1.0900 - acc: 0.3770 - val_loss: 1.0963 - val_acc: 0.3563\n",
            "Epoch 129/150 - 0.05s - loss: 1.0899 - acc: 0.3772 - val_loss: 1.0963 - val_acc: 0.3563\n",
            "Epoch 130/150 - 0.04s - loss: 1.0899 - acc: 0.3763 - val_loss: 1.0962 - val_acc: 0.3563\n",
            "Epoch 131/150 - 0.04s - loss: 1.0898 - acc: 0.3767 - val_loss: 1.0962 - val_acc: 0.3563\n",
            "Epoch 132/150 - 0.04s - loss: 1.0897 - acc: 0.3770 - val_loss: 1.0961 - val_acc: 0.3563\n",
            "Epoch 133/150 - 0.05s - loss: 1.0897 - acc: 0.3774 - val_loss: 1.0961 - val_acc: 0.3583\n",
            "Epoch 134/150 - 0.05s - loss: 1.0896 - acc: 0.3779 - val_loss: 1.0960 - val_acc: 0.3583\n",
            "Epoch 135/150 - 0.05s - loss: 1.0896 - acc: 0.3779 - val_loss: 1.0960 - val_acc: 0.3563\n",
            "Epoch 136/150 - 0.05s - loss: 1.0895 - acc: 0.3774 - val_loss: 1.0959 - val_acc: 0.3563\n",
            "Epoch 137/150 - 0.05s - loss: 1.0894 - acc: 0.3783 - val_loss: 1.0959 - val_acc: 0.3563\n",
            "Epoch 138/150 - 0.04s - loss: 1.0894 - acc: 0.3781 - val_loss: 1.0958 - val_acc: 0.3563\n",
            "Epoch 139/150 - 0.05s - loss: 1.0893 - acc: 0.3783 - val_loss: 1.0958 - val_acc: 0.3563\n",
            "Epoch 140/150 - 0.05s - loss: 1.0892 - acc: 0.3794 - val_loss: 1.0957 - val_acc: 0.3563\n",
            "Epoch 141/150 - 0.04s - loss: 1.0892 - acc: 0.3794 - val_loss: 1.0957 - val_acc: 0.3583\n",
            "Epoch 142/150 - 0.04s - loss: 1.0891 - acc: 0.3801 - val_loss: 1.0956 - val_acc: 0.3583\n",
            "Epoch 143/150 - 0.04s - loss: 1.0890 - acc: 0.3801 - val_loss: 1.0956 - val_acc: 0.3583\n",
            "Epoch 144/150 - 0.04s - loss: 1.0890 - acc: 0.3806 - val_loss: 1.0955 - val_acc: 0.3583\n",
            "Epoch 145/150 - 0.04s - loss: 1.0889 - acc: 0.3817 - val_loss: 1.0955 - val_acc: 0.3583\n",
            "Epoch 146/150 - 0.04s - loss: 1.0888 - acc: 0.3821 - val_loss: 1.0954 - val_acc: 0.3603\n",
            "Epoch 147/150 - 0.04s - loss: 1.0888 - acc: 0.3830 - val_loss: 1.0954 - val_acc: 0.3603\n",
            "Epoch 148/150 - 0.04s - loss: 1.0887 - acc: 0.3830 - val_loss: 1.0953 - val_acc: 0.3603\n",
            "Epoch 149/150 - 0.04s - loss: 1.0887 - acc: 0.3833 - val_loss: 1.0953 - val_acc: 0.3603\n",
            "Epoch 150/150 - 0.04s - loss: 1.0886 - acc: 0.3833 - val_loss: 1.0952 - val_acc: 0.3563\n",
            "\n",
            "Combination 37/252:\n",
            "Hidden Layers: [128, 64], Activation: relu, Learning Rate: 0.01, Batch Size: 32, Epochs: 50\n",
            "Epoch 1/50 - 0.06s - loss: 1.0840 - acc: 0.4285 - val_loss: 1.0879 - val_acc: 0.3806\n",
            "Epoch 2/50 - 0.06s - loss: 1.0744 - acc: 0.4444 - val_loss: 1.0803 - val_acc: 0.4028\n",
            "Epoch 3/50 - 0.06s - loss: 1.0673 - acc: 0.4528 - val_loss: 1.0737 - val_acc: 0.4049\n",
            "Epoch 4/50 - 0.06s - loss: 1.0600 - acc: 0.4665 - val_loss: 1.0682 - val_acc: 0.4231\n",
            "Epoch 5/50 - 0.07s - loss: 1.0540 - acc: 0.4726 - val_loss: 1.0640 - val_acc: 0.4453\n",
            "Epoch 6/50 - 0.07s - loss: 1.0480 - acc: 0.4777 - val_loss: 1.0596 - val_acc: 0.4312\n",
            "Epoch 7/50 - 0.07s - loss: 1.0431 - acc: 0.4696 - val_loss: 1.0571 - val_acc: 0.4615\n",
            "Epoch 8/50 - 0.07s - loss: 1.0353 - acc: 0.4867 - val_loss: 1.0508 - val_acc: 0.4575\n",
            "Epoch 9/50 - 0.07s - loss: 1.0288 - acc: 0.4975 - val_loss: 1.0465 - val_acc: 0.4656\n",
            "Epoch 10/50 - 0.07s - loss: 1.0242 - acc: 0.4996 - val_loss: 1.0448 - val_acc: 0.4676\n",
            "Epoch 11/50 - 0.07s - loss: 1.0186 - acc: 0.5002 - val_loss: 1.0396 - val_acc: 0.4696\n",
            "Epoch 12/50 - 0.06s - loss: 1.0109 - acc: 0.5142 - val_loss: 1.0361 - val_acc: 0.4798\n",
            "Epoch 13/50 - 0.06s - loss: 1.0047 - acc: 0.5128 - val_loss: 1.0315 - val_acc: 0.4777\n",
            "Epoch 14/50 - 0.06s - loss: 1.0041 - acc: 0.5088 - val_loss: 1.0356 - val_acc: 0.4960\n",
            "Epoch 15/50 - 0.07s - loss: 0.9932 - acc: 0.5259 - val_loss: 1.0247 - val_acc: 0.5040\n",
            "Epoch 16/50 - 0.07s - loss: 0.9875 - acc: 0.5259 - val_loss: 1.0206 - val_acc: 0.5040\n",
            "Epoch 17/50 - 0.07s - loss: 0.9821 - acc: 0.5301 - val_loss: 1.0174 - val_acc: 0.4960\n",
            "Epoch 18/50 - 0.07s - loss: 0.9776 - acc: 0.5322 - val_loss: 1.0137 - val_acc: 0.5081\n",
            "Epoch 19/50 - 0.07s - loss: 0.9759 - acc: 0.5295 - val_loss: 1.0109 - val_acc: 0.5040\n",
            "Epoch 20/50 - 0.07s - loss: 0.9764 - acc: 0.5340 - val_loss: 1.0149 - val_acc: 0.5061\n",
            "Epoch 21/50 - 0.06s - loss: 0.9642 - acc: 0.5421 - val_loss: 1.0033 - val_acc: 0.5202\n",
            "Epoch 22/50 - 0.07s - loss: 0.9606 - acc: 0.5461 - val_loss: 1.0032 - val_acc: 0.5223\n",
            "Epoch 23/50 - 0.07s - loss: 0.9528 - acc: 0.5488 - val_loss: 0.9968 - val_acc: 0.5202\n",
            "Epoch 24/50 - 0.07s - loss: 0.9575 - acc: 0.5398 - val_loss: 1.0055 - val_acc: 0.4899\n",
            "Epoch 25/50 - 0.07s - loss: 0.9455 - acc: 0.5535 - val_loss: 0.9932 - val_acc: 0.5364\n",
            "Epoch 26/50 - 0.07s - loss: 0.9538 - acc: 0.5423 - val_loss: 1.0059 - val_acc: 0.4899\n",
            "Epoch 27/50 - 0.07s - loss: 0.9517 - acc: 0.5418 - val_loss: 1.0062 - val_acc: 0.4777\n",
            "Epoch 28/50 - 0.06s - loss: 0.9346 - acc: 0.5585 - val_loss: 0.9864 - val_acc: 0.5364\n",
            "Epoch 29/50 - 0.06s - loss: 0.9290 - acc: 0.5641 - val_loss: 0.9834 - val_acc: 0.5364\n",
            "Epoch 30/50 - 0.06s - loss: 0.9295 - acc: 0.5587 - val_loss: 0.9842 - val_acc: 0.5283\n",
            "Epoch 31/50 - 0.07s - loss: 0.9225 - acc: 0.5740 - val_loss: 0.9796 - val_acc: 0.5445\n",
            "Epoch 32/50 - 0.06s - loss: 0.9203 - acc: 0.5643 - val_loss: 0.9813 - val_acc: 0.5162\n",
            "Epoch 33/50 - 0.06s - loss: 0.9153 - acc: 0.5711 - val_loss: 0.9769 - val_acc: 0.5283\n",
            "Epoch 34/50 - 0.06s - loss: 0.9178 - acc: 0.5652 - val_loss: 0.9839 - val_acc: 0.5121\n",
            "Epoch 35/50 - 0.07s - loss: 0.9086 - acc: 0.5771 - val_loss: 0.9732 - val_acc: 0.5324\n",
            "Epoch 36/50 - 0.07s - loss: 0.9260 - acc: 0.5679 - val_loss: 0.9870 - val_acc: 0.5668\n",
            "Epoch 37/50 - 0.07s - loss: 0.9056 - acc: 0.5713 - val_loss: 0.9772 - val_acc: 0.5182\n",
            "Epoch 38/50 - 0.07s - loss: 0.9003 - acc: 0.5794 - val_loss: 0.9681 - val_acc: 0.5648\n",
            "Epoch 39/50 - 0.07s - loss: 0.8955 - acc: 0.5859 - val_loss: 0.9670 - val_acc: 0.5405\n",
            "Epoch 40/50 - 0.07s - loss: 0.8931 - acc: 0.5843 - val_loss: 0.9664 - val_acc: 0.5405\n",
            "Epoch 41/50 - 0.06s - loss: 0.8931 - acc: 0.5861 - val_loss: 0.9688 - val_acc: 0.5466\n",
            "Epoch 42/50 - 0.07s - loss: 0.8965 - acc: 0.5783 - val_loss: 0.9794 - val_acc: 0.5121\n",
            "Epoch 43/50 - 0.07s - loss: 0.8874 - acc: 0.5834 - val_loss: 0.9628 - val_acc: 0.5385\n",
            "Epoch 44/50 - 0.06s - loss: 0.8795 - acc: 0.5945 - val_loss: 0.9595 - val_acc: 0.5466\n",
            "Epoch 45/50 - 0.07s - loss: 0.8818 - acc: 0.5911 - val_loss: 0.9678 - val_acc: 0.5425\n",
            "Epoch 46/50 - 0.06s - loss: 0.8759 - acc: 0.5940 - val_loss: 0.9575 - val_acc: 0.5628\n",
            "Epoch 47/50 - 0.07s - loss: 0.9000 - acc: 0.5657 - val_loss: 0.9886 - val_acc: 0.5121\n",
            "Epoch 48/50 - 0.06s - loss: 0.8834 - acc: 0.5886 - val_loss: 0.9667 - val_acc: 0.5688\n",
            "Epoch 49/50 - 0.06s - loss: 0.8644 - acc: 0.6082 - val_loss: 0.9551 - val_acc: 0.5567\n",
            "Epoch 50/50 - 0.06s - loss: 0.8646 - acc: 0.6066 - val_loss: 0.9574 - val_acc: 0.5668\n",
            "\n",
            "Combination 38/252:\n",
            "Hidden Layers: [128, 64], Activation: relu, Learning Rate: 0.01, Batch Size: 32, Epochs: 100\n",
            "Epoch 1/100 - 0.07s - loss: 1.0837 - acc: 0.3963 - val_loss: 1.0853 - val_acc: 0.3927\n",
            "Epoch 2/100 - 0.07s - loss: 1.0722 - acc: 0.4238 - val_loss: 1.0725 - val_acc: 0.4453\n",
            "Epoch 3/100 - 0.06s - loss: 1.0659 - acc: 0.4413 - val_loss: 1.0685 - val_acc: 0.4211\n",
            "Epoch 4/100 - 0.06s - loss: 1.0585 - acc: 0.4577 - val_loss: 1.0617 - val_acc: 0.4312\n",
            "Epoch 5/100 - 0.07s - loss: 1.0525 - acc: 0.4624 - val_loss: 1.0564 - val_acc: 0.4393\n",
            "Epoch 6/100 - 0.06s - loss: 1.0471 - acc: 0.4696 - val_loss: 1.0531 - val_acc: 0.4474\n",
            "Epoch 7/100 - 0.06s - loss: 1.0408 - acc: 0.4768 - val_loss: 1.0497 - val_acc: 0.4433\n",
            "Epoch 8/100 - 0.06s - loss: 1.0352 - acc: 0.4825 - val_loss: 1.0458 - val_acc: 0.4615\n",
            "Epoch 9/100 - 0.06s - loss: 1.0323 - acc: 0.4723 - val_loss: 1.0435 - val_acc: 0.4656\n",
            "Epoch 10/100 - 0.06s - loss: 1.0241 - acc: 0.4897 - val_loss: 1.0384 - val_acc: 0.4818\n",
            "Epoch 11/100 - 0.06s - loss: 1.0187 - acc: 0.4951 - val_loss: 1.0365 - val_acc: 0.4838\n",
            "Epoch 12/100 - 0.06s - loss: 1.0128 - acc: 0.5056 - val_loss: 1.0306 - val_acc: 0.4899\n",
            "Epoch 13/100 - 0.07s - loss: 1.0084 - acc: 0.5022 - val_loss: 1.0288 - val_acc: 0.5121\n",
            "Epoch 14/100 - 0.06s - loss: 1.0004 - acc: 0.5099 - val_loss: 1.0220 - val_acc: 0.5223\n",
            "Epoch 15/100 - 0.06s - loss: 0.9946 - acc: 0.5238 - val_loss: 1.0182 - val_acc: 0.5081\n",
            "Epoch 16/100 - 0.06s - loss: 0.9892 - acc: 0.5252 - val_loss: 1.0132 - val_acc: 0.5040\n",
            "Epoch 17/100 - 0.07s - loss: 0.9828 - acc: 0.5288 - val_loss: 1.0088 - val_acc: 0.5101\n",
            "Epoch 18/100 - 0.06s - loss: 0.9784 - acc: 0.5292 - val_loss: 1.0068 - val_acc: 0.5101\n",
            "Epoch 19/100 - 0.06s - loss: 0.9717 - acc: 0.5333 - val_loss: 1.0018 - val_acc: 0.5344\n",
            "Epoch 20/100 - 0.06s - loss: 0.9660 - acc: 0.5389 - val_loss: 0.9972 - val_acc: 0.5364\n",
            "Epoch 21/100 - 0.07s - loss: 0.9636 - acc: 0.5382 - val_loss: 0.9936 - val_acc: 0.5385\n",
            "Epoch 22/100 - 0.07s - loss: 0.9621 - acc: 0.5360 - val_loss: 0.9921 - val_acc: 0.5162\n",
            "Epoch 23/100 - 0.06s - loss: 0.9532 - acc: 0.5423 - val_loss: 0.9863 - val_acc: 0.5364\n",
            "Epoch 24/100 - 0.06s - loss: 0.9487 - acc: 0.5495 - val_loss: 0.9863 - val_acc: 0.5466\n",
            "Epoch 25/100 - 0.07s - loss: 0.9444 - acc: 0.5553 - val_loss: 0.9811 - val_acc: 0.5648\n",
            "Epoch 26/100 - 0.07s - loss: 0.9376 - acc: 0.5547 - val_loss: 0.9752 - val_acc: 0.5445\n",
            "Epoch 27/100 - 0.06s - loss: 0.9339 - acc: 0.5576 - val_loss: 0.9743 - val_acc: 0.5506\n",
            "Epoch 28/100 - 0.06s - loss: 0.9317 - acc: 0.5646 - val_loss: 0.9730 - val_acc: 0.5587\n",
            "Epoch 29/100 - 0.07s - loss: 0.9303 - acc: 0.5603 - val_loss: 0.9755 - val_acc: 0.5324\n",
            "Epoch 30/100 - 0.06s - loss: 0.9250 - acc: 0.5700 - val_loss: 0.9685 - val_acc: 0.5729\n",
            "Epoch 31/100 - 0.06s - loss: 0.9317 - acc: 0.5652 - val_loss: 0.9770 - val_acc: 0.5405\n",
            "Epoch 32/100 - 0.06s - loss: 0.9181 - acc: 0.5686 - val_loss: 0.9643 - val_acc: 0.5688\n",
            "Epoch 33/100 - 0.07s - loss: 0.9144 - acc: 0.5783 - val_loss: 0.9631 - val_acc: 0.5729\n",
            "Epoch 34/100 - 0.07s - loss: 0.9093 - acc: 0.5717 - val_loss: 0.9607 - val_acc: 0.5628\n",
            "Epoch 35/100 - 0.06s - loss: 0.9036 - acc: 0.5753 - val_loss: 0.9556 - val_acc: 0.5709\n",
            "Epoch 36/100 - 0.07s - loss: 0.9082 - acc: 0.5632 - val_loss: 0.9601 - val_acc: 0.5526\n",
            "Epoch 37/100 - 0.07s - loss: 0.8984 - acc: 0.5846 - val_loss: 0.9535 - val_acc: 0.5769\n",
            "Epoch 38/100 - 0.07s - loss: 0.8968 - acc: 0.5859 - val_loss: 0.9585 - val_acc: 0.5425\n",
            "Epoch 39/100 - 0.07s - loss: 0.8905 - acc: 0.5868 - val_loss: 0.9532 - val_acc: 0.5587\n",
            "Epoch 40/100 - 0.06s - loss: 0.8902 - acc: 0.5924 - val_loss: 0.9528 - val_acc: 0.5709\n",
            "Epoch 41/100 - 0.07s - loss: 0.8945 - acc: 0.5801 - val_loss: 0.9617 - val_acc: 0.5425\n",
            "Epoch 42/100 - 0.06s - loss: 0.9061 - acc: 0.5821 - val_loss: 0.9697 - val_acc: 0.5364\n",
            "Epoch 43/100 - 0.06s - loss: 0.8795 - acc: 0.6010 - val_loss: 0.9489 - val_acc: 0.5628\n",
            "Epoch 44/100 - 0.06s - loss: 0.8911 - acc: 0.5679 - val_loss: 0.9555 - val_acc: 0.5283\n",
            "Epoch 45/100 - 0.07s - loss: 0.8727 - acc: 0.5994 - val_loss: 0.9447 - val_acc: 0.5769\n",
            "Epoch 46/100 - 0.06s - loss: 0.8700 - acc: 0.6059 - val_loss: 0.9475 - val_acc: 0.5668\n",
            "Epoch 47/100 - 0.06s - loss: 0.8674 - acc: 0.6053 - val_loss: 0.9460 - val_acc: 0.5486\n",
            "Epoch 48/100 - 0.06s - loss: 0.8668 - acc: 0.6066 - val_loss: 0.9494 - val_acc: 0.5688\n",
            "Epoch 49/100 - 0.07s - loss: 0.8621 - acc: 0.6100 - val_loss: 0.9485 - val_acc: 0.5709\n",
            "Epoch 50/100 - 0.06s - loss: 0.8573 - acc: 0.6093 - val_loss: 0.9445 - val_acc: 0.5628\n",
            "Epoch 51/100 - 0.07s - loss: 0.8541 - acc: 0.6138 - val_loss: 0.9443 - val_acc: 0.5648\n",
            "Epoch 52/100 - 0.07s - loss: 0.8549 - acc: 0.6062 - val_loss: 0.9428 - val_acc: 0.5749\n",
            "Epoch 53/100 - 0.07s - loss: 0.8734 - acc: 0.5830 - val_loss: 0.9708 - val_acc: 0.5466\n",
            "Epoch 54/100 - 0.07s - loss: 0.8601 - acc: 0.5972 - val_loss: 0.9608 - val_acc: 0.5425\n",
            "Epoch 55/100 - 0.06s - loss: 0.8429 - acc: 0.6165 - val_loss: 0.9446 - val_acc: 0.5587\n",
            "Epoch 56/100 - 0.07s - loss: 0.8401 - acc: 0.6210 - val_loss: 0.9414 - val_acc: 0.5648\n",
            "Epoch 57/100 - 0.07s - loss: 0.8446 - acc: 0.6228 - val_loss: 0.9438 - val_acc: 0.5709\n",
            "Epoch 58/100 - 0.06s - loss: 0.8340 - acc: 0.6244 - val_loss: 0.9407 - val_acc: 0.5688\n",
            "Epoch 59/100 - 0.06s - loss: 0.8506 - acc: 0.5974 - val_loss: 0.9586 - val_acc: 0.5364\n",
            "Epoch 60/100 - 0.07s - loss: 0.8295 - acc: 0.6221 - val_loss: 0.9443 - val_acc: 0.5526\n",
            "Epoch 61/100 - 0.07s - loss: 0.8283 - acc: 0.6275 - val_loss: 0.9390 - val_acc: 0.5749\n",
            "Epoch 62/100 - 0.07s - loss: 0.8266 - acc: 0.6282 - val_loss: 0.9470 - val_acc: 0.5506\n",
            "Epoch 63/100 - 0.07s - loss: 0.8353 - acc: 0.6244 - val_loss: 0.9555 - val_acc: 0.5445\n",
            "Epoch 64/100 - 0.07s - loss: 0.8302 - acc: 0.6336 - val_loss: 0.9489 - val_acc: 0.5729\n",
            "Epoch 65/100 - 0.07s - loss: 0.8156 - acc: 0.6386 - val_loss: 0.9435 - val_acc: 0.5486\n",
            "Epoch 66/100 - 0.06s - loss: 0.8793 - acc: 0.5976 - val_loss: 0.9870 - val_acc: 0.5526\n",
            "Epoch 67/100 - 0.07s - loss: 0.8331 - acc: 0.6179 - val_loss: 0.9726 - val_acc: 0.5364\n",
            "Epoch 68/100 - 0.07s - loss: 0.8251 - acc: 0.6228 - val_loss: 0.9683 - val_acc: 0.5385\n",
            "Epoch 69/100 - 0.07s - loss: 0.8332 - acc: 0.6138 - val_loss: 0.9792 - val_acc: 0.5364\n",
            "Epoch 70/100 - 0.06s - loss: 0.8104 - acc: 0.6336 - val_loss: 0.9433 - val_acc: 0.5769\n",
            "Epoch 71/100 - 0.06s - loss: 0.8033 - acc: 0.6390 - val_loss: 0.9432 - val_acc: 0.5506\n",
            "Epoch 72/100 - 0.06s - loss: 0.7972 - acc: 0.6442 - val_loss: 0.9438 - val_acc: 0.5688\n",
            "Epoch 73/100 - 0.07s - loss: 0.8040 - acc: 0.6435 - val_loss: 0.9513 - val_acc: 0.5506\n",
            "Epoch 74/100 - 0.06s - loss: 0.7911 - acc: 0.6487 - val_loss: 0.9419 - val_acc: 0.5486\n",
            "Epoch 75/100 - 0.06s - loss: 0.7880 - acc: 0.6502 - val_loss: 0.9443 - val_acc: 0.5668\n",
            "Epoch 76/100 - 0.06s - loss: 0.7922 - acc: 0.6462 - val_loss: 0.9507 - val_acc: 0.5567\n",
            "Epoch 77/100 - 0.07s - loss: 0.8599 - acc: 0.5904 - val_loss: 1.0258 - val_acc: 0.5263\n",
            "Epoch 78/100 - 0.07s - loss: 0.7998 - acc: 0.6413 - val_loss: 0.9706 - val_acc: 0.5526\n",
            "Epoch 79/100 - 0.07s - loss: 0.8064 - acc: 0.6336 - val_loss: 0.9584 - val_acc: 0.5628\n",
            "Epoch 80/100 - 0.07s - loss: 0.7865 - acc: 0.6480 - val_loss: 0.9616 - val_acc: 0.5486\n",
            "Epoch 81/100 - 0.07s - loss: 0.7742 - acc: 0.6570 - val_loss: 0.9456 - val_acc: 0.5688\n",
            "Epoch 82/100 - 0.07s - loss: 0.7834 - acc: 0.6529 - val_loss: 0.9729 - val_acc: 0.5344\n",
            "Epoch 83/100 - 0.06s - loss: 0.8919 - acc: 0.5792 - val_loss: 1.0923 - val_acc: 0.4879\n",
            "Epoch 84/100 - 0.07s - loss: 0.7701 - acc: 0.6586 - val_loss: 0.9537 - val_acc: 0.5526\n",
            "Epoch 85/100 - 0.07s - loss: 0.7785 - acc: 0.6568 - val_loss: 0.9536 - val_acc: 0.5729\n",
            "Epoch 86/100 - 0.07s - loss: 0.7635 - acc: 0.6617 - val_loss: 0.9548 - val_acc: 0.5547\n",
            "Epoch 87/100 - 0.06s - loss: 0.7564 - acc: 0.6712 - val_loss: 0.9533 - val_acc: 0.5526\n",
            "Epoch 88/100 - 0.07s - loss: 0.7705 - acc: 0.6590 - val_loss: 0.9578 - val_acc: 0.5587\n",
            "Epoch 89/100 - 0.06s - loss: 0.7520 - acc: 0.6752 - val_loss: 0.9425 - val_acc: 0.5709\n",
            "Epoch 90/100 - 0.06s - loss: 0.7567 - acc: 0.6754 - val_loss: 0.9541 - val_acc: 0.5648\n",
            "Epoch 91/100 - 0.07s - loss: 0.7487 - acc: 0.6723 - val_loss: 0.9488 - val_acc: 0.5526\n",
            "Epoch 92/100 - 0.07s - loss: 0.7715 - acc: 0.6568 - val_loss: 0.9848 - val_acc: 0.5445\n",
            "Epoch 93/100 - 0.07s - loss: 0.7489 - acc: 0.6732 - val_loss: 0.9657 - val_acc: 0.5526\n",
            "Epoch 94/100 - 0.08s - loss: 0.7596 - acc: 0.6626 - val_loss: 0.9630 - val_acc: 0.5547\n",
            "Epoch 95/100 - 0.07s - loss: 0.7476 - acc: 0.6757 - val_loss: 0.9630 - val_acc: 0.5526\n",
            "Epoch 96/100 - 0.07s - loss: 0.7328 - acc: 0.6885 - val_loss: 0.9561 - val_acc: 0.5547\n",
            "Epoch 97/100 - 0.07s - loss: 0.7377 - acc: 0.6842 - val_loss: 0.9507 - val_acc: 0.5668\n",
            "Epoch 98/100 - 0.06s - loss: 0.7660 - acc: 0.6626 - val_loss: 1.0033 - val_acc: 0.5304\n",
            "Epoch 99/100 - 0.07s - loss: 0.7296 - acc: 0.6883 - val_loss: 0.9445 - val_acc: 0.5709\n",
            "Epoch 100/100 - 0.06s - loss: 0.7484 - acc: 0.6678 - val_loss: 0.9766 - val_acc: 0.5607\n",
            "\n",
            "Combination 39/252:\n",
            "Hidden Layers: [128, 64], Activation: relu, Learning Rate: 0.01, Batch Size: 32, Epochs: 150\n",
            "Epoch 1/150 - 0.06s - loss: 1.0860 - acc: 0.4031 - val_loss: 1.0870 - val_acc: 0.3907\n",
            "Epoch 2/150 - 0.07s - loss: 1.0747 - acc: 0.4397 - val_loss: 1.0771 - val_acc: 0.4089\n",
            "Epoch 3/150 - 0.07s - loss: 1.0680 - acc: 0.4442 - val_loss: 1.0739 - val_acc: 0.4069\n",
            "Epoch 4/150 - 0.06s - loss: 1.0589 - acc: 0.4622 - val_loss: 1.0665 - val_acc: 0.4514\n",
            "Epoch 5/150 - 0.07s - loss: 1.0536 - acc: 0.4627 - val_loss: 1.0641 - val_acc: 0.4332\n",
            "Epoch 6/150 - 0.07s - loss: 1.0461 - acc: 0.4777 - val_loss: 1.0584 - val_acc: 0.4656\n",
            "Epoch 7/150 - 0.07s - loss: 1.0467 - acc: 0.4582 - val_loss: 1.0604 - val_acc: 0.4413\n",
            "Epoch 8/150 - 0.07s - loss: 1.0381 - acc: 0.4717 - val_loss: 1.0546 - val_acc: 0.4352\n",
            "Epoch 9/150 - 0.06s - loss: 1.0294 - acc: 0.4901 - val_loss: 1.0480 - val_acc: 0.4838\n",
            "Epoch 10/150 - 0.06s - loss: 1.0233 - acc: 0.4962 - val_loss: 1.0437 - val_acc: 0.4858\n",
            "Epoch 11/150 - 0.06s - loss: 1.0178 - acc: 0.5029 - val_loss: 1.0405 - val_acc: 0.4879\n",
            "Epoch 12/150 - 0.07s - loss: 1.0129 - acc: 0.5072 - val_loss: 1.0381 - val_acc: 0.4858\n",
            "Epoch 13/150 - 0.07s - loss: 1.0076 - acc: 0.5133 - val_loss: 1.0323 - val_acc: 0.5101\n",
            "Epoch 14/150 - 0.07s - loss: 1.0008 - acc: 0.5146 - val_loss: 1.0275 - val_acc: 0.5223\n",
            "Epoch 15/150 - 0.08s - loss: 0.9946 - acc: 0.5202 - val_loss: 1.0229 - val_acc: 0.5263\n",
            "Epoch 16/150 - 0.07s - loss: 0.9916 - acc: 0.5263 - val_loss: 1.0231 - val_acc: 0.4939\n",
            "Epoch 17/150 - 0.06s - loss: 0.9834 - acc: 0.5277 - val_loss: 1.0137 - val_acc: 0.5223\n",
            "Epoch 18/150 - 0.07s - loss: 0.9823 - acc: 0.5265 - val_loss: 1.0150 - val_acc: 0.4919\n",
            "Epoch 19/150 - 0.07s - loss: 0.9737 - acc: 0.5362 - val_loss: 1.0044 - val_acc: 0.5344\n",
            "Epoch 20/150 - 0.07s - loss: 0.9673 - acc: 0.5396 - val_loss: 1.0014 - val_acc: 0.5162\n",
            "Epoch 21/150 - 0.06s - loss: 0.9631 - acc: 0.5412 - val_loss: 0.9958 - val_acc: 0.5202\n",
            "Epoch 22/150 - 0.06s - loss: 0.9641 - acc: 0.5396 - val_loss: 0.9982 - val_acc: 0.5486\n",
            "Epoch 23/150 - 0.07s - loss: 0.9543 - acc: 0.5418 - val_loss: 0.9911 - val_acc: 0.5142\n",
            "Epoch 24/150 - 0.07s - loss: 0.9611 - acc: 0.5432 - val_loss: 0.9970 - val_acc: 0.5385\n",
            "Epoch 25/150 - 0.07s - loss: 0.9452 - acc: 0.5553 - val_loss: 0.9839 - val_acc: 0.5304\n",
            "Epoch 26/150 - 0.08s - loss: 0.9429 - acc: 0.5547 - val_loss: 0.9807 - val_acc: 0.5547\n",
            "Epoch 27/150 - 0.07s - loss: 0.9389 - acc: 0.5574 - val_loss: 0.9764 - val_acc: 0.5547\n",
            "Epoch 28/150 - 0.07s - loss: 0.9345 - acc: 0.5585 - val_loss: 0.9750 - val_acc: 0.5547\n",
            "Epoch 29/150 - 0.07s - loss: 0.9302 - acc: 0.5585 - val_loss: 0.9720 - val_acc: 0.5425\n",
            "Epoch 30/150 - 0.07s - loss: 0.9270 - acc: 0.5652 - val_loss: 0.9689 - val_acc: 0.5587\n",
            "Epoch 31/150 - 0.07s - loss: 0.9407 - acc: 0.5540 - val_loss: 0.9833 - val_acc: 0.5445\n",
            "Epoch 32/150 - 0.07s - loss: 0.9198 - acc: 0.5686 - val_loss: 0.9665 - val_acc: 0.5466\n",
            "Epoch 33/150 - 0.07s - loss: 0.9161 - acc: 0.5713 - val_loss: 0.9634 - val_acc: 0.5466\n",
            "Epoch 34/150 - 0.08s - loss: 0.9136 - acc: 0.5691 - val_loss: 0.9613 - val_acc: 0.5526\n",
            "Epoch 35/150 - 0.07s - loss: 0.9096 - acc: 0.5774 - val_loss: 0.9607 - val_acc: 0.5486\n",
            "Epoch 36/150 - 0.07s - loss: 0.9075 - acc: 0.5767 - val_loss: 0.9596 - val_acc: 0.5587\n",
            "Epoch 37/150 - 0.07s - loss: 0.9110 - acc: 0.5717 - val_loss: 0.9672 - val_acc: 0.5223\n",
            "Epoch 38/150 - 0.06s - loss: 0.9073 - acc: 0.5762 - val_loss: 0.9671 - val_acc: 0.5243\n",
            "Epoch 39/150 - 0.06s - loss: 0.8981 - acc: 0.5855 - val_loss: 0.9564 - val_acc: 0.5547\n",
            "Epoch 40/150 - 0.06s - loss: 0.9004 - acc: 0.5834 - val_loss: 0.9552 - val_acc: 0.5547\n",
            "Epoch 41/150 - 0.07s - loss: 0.8985 - acc: 0.5774 - val_loss: 0.9577 - val_acc: 0.5405\n",
            "Epoch 42/150 - 0.08s - loss: 0.8946 - acc: 0.5870 - val_loss: 0.9562 - val_acc: 0.5385\n",
            "Epoch 43/150 - 0.07s - loss: 0.9058 - acc: 0.5648 - val_loss: 0.9684 - val_acc: 0.5182\n",
            "Epoch 44/150 - 0.07s - loss: 0.8838 - acc: 0.5972 - val_loss: 0.9488 - val_acc: 0.5526\n",
            "Epoch 45/150 - 0.07s - loss: 0.8805 - acc: 0.5996 - val_loss: 0.9475 - val_acc: 0.5506\n",
            "Epoch 46/150 - 0.06s - loss: 0.8940 - acc: 0.5841 - val_loss: 0.9560 - val_acc: 0.5466\n",
            "Epoch 47/150 - 0.06s - loss: 0.8762 - acc: 0.6003 - val_loss: 0.9485 - val_acc: 0.5385\n",
            "Epoch 48/150 - 0.06s - loss: 0.8815 - acc: 0.5949 - val_loss: 0.9528 - val_acc: 0.5567\n",
            "Epoch 49/150 - 0.06s - loss: 0.8729 - acc: 0.6039 - val_loss: 0.9452 - val_acc: 0.5769\n",
            "Epoch 50/150 - 0.07s - loss: 0.8771 - acc: 0.5870 - val_loss: 0.9574 - val_acc: 0.5364\n",
            "Epoch 51/150 - 0.07s - loss: 0.8675 - acc: 0.6026 - val_loss: 0.9466 - val_acc: 0.5547\n",
            "Epoch 52/150 - 0.07s - loss: 0.8689 - acc: 0.5906 - val_loss: 0.9442 - val_acc: 0.5587\n",
            "Epoch 53/150 - 0.06s - loss: 0.8620 - acc: 0.6064 - val_loss: 0.9463 - val_acc: 0.5405\n",
            "Epoch 54/150 - 0.06s - loss: 0.8564 - acc: 0.6149 - val_loss: 0.9415 - val_acc: 0.5587\n",
            "Epoch 55/150 - 0.06s - loss: 0.8575 - acc: 0.6093 - val_loss: 0.9454 - val_acc: 0.5587\n",
            "Epoch 56/150 - 0.07s - loss: 0.8752 - acc: 0.5958 - val_loss: 0.9615 - val_acc: 0.5405\n",
            "Epoch 57/150 - 0.07s - loss: 0.8486 - acc: 0.6143 - val_loss: 0.9406 - val_acc: 0.5405\n",
            "Epoch 58/150 - 0.07s - loss: 0.9013 - acc: 0.5652 - val_loss: 0.9959 - val_acc: 0.5142\n",
            "Epoch 59/150 - 0.07s - loss: 0.8443 - acc: 0.6172 - val_loss: 0.9360 - val_acc: 0.5648\n",
            "Epoch 60/150 - 0.07s - loss: 0.8568 - acc: 0.6005 - val_loss: 0.9509 - val_acc: 0.5547\n",
            "Epoch 61/150 - 0.07s - loss: 0.8716 - acc: 0.5843 - val_loss: 0.9688 - val_acc: 0.5466\n",
            "Epoch 62/150 - 0.07s - loss: 0.8442 - acc: 0.6161 - val_loss: 0.9422 - val_acc: 0.5344\n",
            "Epoch 63/150 - 0.07s - loss: 0.8339 - acc: 0.6215 - val_loss: 0.9391 - val_acc: 0.5466\n",
            "Epoch 64/150 - 0.06s - loss: 0.8321 - acc: 0.6242 - val_loss: 0.9351 - val_acc: 0.5648\n",
            "Epoch 65/150 - 0.06s - loss: 0.8296 - acc: 0.6224 - val_loss: 0.9341 - val_acc: 0.5486\n",
            "Epoch 66/150 - 0.07s - loss: 0.8515 - acc: 0.6059 - val_loss: 0.9673 - val_acc: 0.5223\n",
            "Epoch 67/150 - 0.07s - loss: 0.8625 - acc: 0.6012 - val_loss: 0.9830 - val_acc: 0.5202\n",
            "Epoch 68/150 - 0.07s - loss: 0.8360 - acc: 0.6127 - val_loss: 0.9517 - val_acc: 0.5385\n",
            "Epoch 69/150 - 0.06s - loss: 0.8179 - acc: 0.6307 - val_loss: 0.9382 - val_acc: 0.5506\n",
            "Epoch 70/150 - 0.07s - loss: 0.8273 - acc: 0.6255 - val_loss: 0.9393 - val_acc: 0.5567\n",
            "Epoch 71/150 - 0.06s - loss: 0.8156 - acc: 0.6302 - val_loss: 0.9422 - val_acc: 0.5466\n",
            "Epoch 72/150 - 0.06s - loss: 0.8138 - acc: 0.6284 - val_loss: 0.9432 - val_acc: 0.5547\n",
            "Epoch 73/150 - 0.07s - loss: 0.8061 - acc: 0.6359 - val_loss: 0.9333 - val_acc: 0.5587\n",
            "Epoch 74/150 - 0.07s - loss: 0.8059 - acc: 0.6329 - val_loss: 0.9357 - val_acc: 0.5506\n",
            "Epoch 75/150 - 0.07s - loss: 0.8472 - acc: 0.6021 - val_loss: 0.9783 - val_acc: 0.5526\n",
            "Epoch 76/150 - 0.06s - loss: 0.8025 - acc: 0.6352 - val_loss: 0.9419 - val_acc: 0.5324\n",
            "Epoch 77/150 - 0.07s - loss: 0.8152 - acc: 0.6248 - val_loss: 0.9422 - val_acc: 0.5567\n",
            "Epoch 78/150 - 0.06s - loss: 0.7943 - acc: 0.6487 - val_loss: 0.9329 - val_acc: 0.5486\n",
            "Epoch 79/150 - 0.06s - loss: 0.8002 - acc: 0.6401 - val_loss: 0.9430 - val_acc: 0.5506\n",
            "Epoch 80/150 - 0.06s - loss: 0.8119 - acc: 0.6264 - val_loss: 0.9599 - val_acc: 0.5364\n",
            "Epoch 81/150 - 0.07s - loss: 0.8060 - acc: 0.6347 - val_loss: 0.9559 - val_acc: 0.5506\n",
            "Epoch 82/150 - 0.06s - loss: 0.7847 - acc: 0.6520 - val_loss: 0.9335 - val_acc: 0.5567\n",
            "Epoch 83/150 - 0.06s - loss: 0.7994 - acc: 0.6347 - val_loss: 0.9551 - val_acc: 0.5304\n",
            "Epoch 84/150 - 0.06s - loss: 0.7822 - acc: 0.6496 - val_loss: 0.9356 - val_acc: 0.5648\n",
            "Epoch 85/150 - 0.07s - loss: 0.7788 - acc: 0.6561 - val_loss: 0.9335 - val_acc: 0.5526\n",
            "Epoch 86/150 - 0.06s - loss: 0.7842 - acc: 0.6471 - val_loss: 0.9333 - val_acc: 0.5668\n",
            "Epoch 87/150 - 0.06s - loss: 0.7838 - acc: 0.6547 - val_loss: 0.9442 - val_acc: 0.5445\n",
            "Epoch 88/150 - 0.06s - loss: 0.8035 - acc: 0.6397 - val_loss: 0.9566 - val_acc: 0.5587\n",
            "Epoch 89/150 - 0.06s - loss: 0.7681 - acc: 0.6581 - val_loss: 0.9353 - val_acc: 0.5526\n",
            "Epoch 90/150 - 0.07s - loss: 0.7882 - acc: 0.6478 - val_loss: 0.9466 - val_acc: 0.5364\n",
            "Epoch 91/150 - 0.06s - loss: 0.7634 - acc: 0.6617 - val_loss: 0.9320 - val_acc: 0.5587\n",
            "Epoch 92/150 - 0.06s - loss: 0.7798 - acc: 0.6475 - val_loss: 0.9576 - val_acc: 0.5385\n",
            "Epoch 93/150 - 0.07s - loss: 0.7953 - acc: 0.6379 - val_loss: 0.9806 - val_acc: 0.5385\n",
            "Epoch 94/150 - 0.06s - loss: 0.7858 - acc: 0.6482 - val_loss: 0.9563 - val_acc: 0.5466\n",
            "Epoch 95/150 - 0.06s - loss: 0.8211 - acc: 0.6174 - val_loss: 0.9980 - val_acc: 0.5587\n",
            "Epoch 96/150 - 0.06s - loss: 0.7659 - acc: 0.6667 - val_loss: 0.9376 - val_acc: 0.5587\n",
            "Epoch 97/150 - 0.07s - loss: 0.7555 - acc: 0.6705 - val_loss: 0.9410 - val_acc: 0.5567\n",
            "Epoch 98/150 - 0.06s - loss: 0.7841 - acc: 0.6478 - val_loss: 0.9626 - val_acc: 0.5445\n",
            "Epoch 99/150 - 0.06s - loss: 0.7434 - acc: 0.6777 - val_loss: 0.9350 - val_acc: 0.5385\n",
            "Epoch 100/150 - 0.06s - loss: 0.7469 - acc: 0.6759 - val_loss: 0.9419 - val_acc: 0.5364\n",
            "Epoch 101/150 - 0.07s - loss: 0.7577 - acc: 0.6579 - val_loss: 0.9478 - val_acc: 0.5749\n",
            "Epoch 102/150 - 0.06s - loss: 0.7409 - acc: 0.6815 - val_loss: 0.9346 - val_acc: 0.5668\n",
            "Epoch 103/150 - 0.06s - loss: 0.7414 - acc: 0.6761 - val_loss: 0.9351 - val_acc: 0.5587\n",
            "Epoch 104/150 - 0.06s - loss: 0.7484 - acc: 0.6653 - val_loss: 0.9404 - val_acc: 0.5709\n",
            "Epoch 105/150 - 0.07s - loss: 0.7427 - acc: 0.6727 - val_loss: 0.9396 - val_acc: 0.5688\n",
            "Epoch 106/150 - 0.06s - loss: 0.7616 - acc: 0.6635 - val_loss: 0.9693 - val_acc: 0.5506\n",
            "Epoch 107/150 - 0.06s - loss: 0.7243 - acc: 0.6892 - val_loss: 0.9387 - val_acc: 0.5587\n",
            "Epoch 108/150 - 0.06s - loss: 0.7449 - acc: 0.6714 - val_loss: 0.9650 - val_acc: 0.5506\n",
            "Epoch 109/150 - 0.07s - loss: 0.7611 - acc: 0.6604 - val_loss: 0.9771 - val_acc: 0.5709\n",
            "Epoch 110/150 - 0.06s - loss: 0.7438 - acc: 0.6622 - val_loss: 0.9738 - val_acc: 0.5506\n",
            "Epoch 111/150 - 0.06s - loss: 0.7389 - acc: 0.6750 - val_loss: 0.9473 - val_acc: 0.5506\n",
            "Epoch 112/150 - 0.06s - loss: 0.7354 - acc: 0.6745 - val_loss: 0.9501 - val_acc: 0.5526\n",
            "Epoch 113/150 - 0.07s - loss: 0.7088 - acc: 0.7004 - val_loss: 0.9361 - val_acc: 0.5607\n",
            "Epoch 114/150 - 0.06s - loss: 0.8293 - acc: 0.6095 - val_loss: 1.0740 - val_acc: 0.4960\n",
            "Epoch 115/150 - 0.07s - loss: 0.7050 - acc: 0.7004 - val_loss: 0.9397 - val_acc: 0.5729\n",
            "Epoch 116/150 - 0.07s - loss: 0.7028 - acc: 0.7076 - val_loss: 0.9370 - val_acc: 0.5688\n",
            "Epoch 117/150 - 0.07s - loss: 0.7136 - acc: 0.7009 - val_loss: 0.9492 - val_acc: 0.5668\n",
            "Epoch 118/150 - 0.07s - loss: 0.7735 - acc: 0.6365 - val_loss: 0.9937 - val_acc: 0.5445\n",
            "Epoch 119/150 - 0.07s - loss: 0.7046 - acc: 0.6928 - val_loss: 0.9458 - val_acc: 0.5547\n",
            "Epoch 120/150 - 0.06s - loss: 0.7214 - acc: 0.6896 - val_loss: 0.9787 - val_acc: 0.5425\n",
            "Epoch 121/150 - 0.07s - loss: 0.6962 - acc: 0.7078 - val_loss: 0.9499 - val_acc: 0.5810\n",
            "Epoch 122/150 - 0.06s - loss: 0.6957 - acc: 0.7067 - val_loss: 0.9351 - val_acc: 0.5729\n",
            "Epoch 123/150 - 0.07s - loss: 0.7178 - acc: 0.6844 - val_loss: 0.9799 - val_acc: 0.5405\n",
            "Epoch 124/150 - 0.07s - loss: 0.6892 - acc: 0.7103 - val_loss: 0.9520 - val_acc: 0.5648\n",
            "Epoch 125/150 - 0.07s - loss: 0.7044 - acc: 0.6912 - val_loss: 0.9538 - val_acc: 0.5607\n",
            "Epoch 126/150 - 0.07s - loss: 0.7142 - acc: 0.6905 - val_loss: 0.9797 - val_acc: 0.5668\n",
            "Epoch 127/150 - 0.07s - loss: 0.6926 - acc: 0.6979 - val_loss: 0.9566 - val_acc: 0.5668\n",
            "Epoch 128/150 - 0.07s - loss: 0.6677 - acc: 0.7236 - val_loss: 0.9424 - val_acc: 0.5749\n",
            "Epoch 129/150 - 0.07s - loss: 0.7084 - acc: 0.6788 - val_loss: 0.9759 - val_acc: 0.5789\n",
            "Epoch 130/150 - 0.07s - loss: 0.7468 - acc: 0.6655 - val_loss: 1.0117 - val_acc: 0.5526\n",
            "Epoch 131/150 - 0.06s - loss: 0.6890 - acc: 0.7015 - val_loss: 0.9853 - val_acc: 0.5466\n",
            "Epoch 132/150 - 0.07s - loss: 0.6685 - acc: 0.7168 - val_loss: 0.9550 - val_acc: 0.5668\n",
            "Epoch 133/150 - 0.06s - loss: 0.6684 - acc: 0.7159 - val_loss: 0.9421 - val_acc: 0.5648\n",
            "Epoch 134/150 - 0.06s - loss: 0.6917 - acc: 0.6939 - val_loss: 0.9727 - val_acc: 0.5607\n",
            "Epoch 135/150 - 0.07s - loss: 0.7670 - acc: 0.6493 - val_loss: 1.0824 - val_acc: 0.5162\n",
            "Epoch 136/150 - 0.07s - loss: 0.7608 - acc: 0.6383 - val_loss: 1.0512 - val_acc: 0.5263\n",
            "Epoch 137/150 - 0.07s - loss: 0.6814 - acc: 0.7087 - val_loss: 0.9836 - val_acc: 0.5729\n",
            "Epoch 138/150 - 0.06s - loss: 0.6394 - acc: 0.7371 - val_loss: 0.9464 - val_acc: 0.5769\n",
            "Epoch 139/150 - 0.06s - loss: 0.6385 - acc: 0.7364 - val_loss: 0.9399 - val_acc: 0.5789\n",
            "Epoch 140/150 - 0.07s - loss: 0.6380 - acc: 0.7368 - val_loss: 0.9551 - val_acc: 0.5789\n",
            "Epoch 141/150 - 0.07s - loss: 0.6639 - acc: 0.7148 - val_loss: 0.9876 - val_acc: 0.5385\n",
            "Epoch 142/150 - 0.06s - loss: 0.6889 - acc: 0.6867 - val_loss: 1.0111 - val_acc: 0.5445\n",
            "Epoch 143/150 - 0.06s - loss: 0.6465 - acc: 0.7326 - val_loss: 0.9663 - val_acc: 0.5709\n",
            "Epoch 144/150 - 0.07s - loss: 0.6970 - acc: 0.7045 - val_loss: 1.0054 - val_acc: 0.5830\n",
            "Epoch 145/150 - 0.07s - loss: 0.7143 - acc: 0.6824 - val_loss: 1.0632 - val_acc: 0.5324\n",
            "Epoch 146/150 - 0.07s - loss: 0.6238 - acc: 0.7429 - val_loss: 0.9472 - val_acc: 0.5830\n",
            "Epoch 147/150 - 0.07s - loss: 0.6295 - acc: 0.7398 - val_loss: 0.9601 - val_acc: 0.5688\n",
            "Epoch 148/150 - 0.07s - loss: 0.6673 - acc: 0.7130 - val_loss: 0.9951 - val_acc: 0.5668\n",
            "Epoch 149/150 - 0.07s - loss: 0.6033 - acc: 0.7591 - val_loss: 0.9506 - val_acc: 0.5911\n",
            "Epoch 150/150 - 0.07s - loss: 0.6632 - acc: 0.7094 - val_loss: 1.0091 - val_acc: 0.5425\n",
            "\n",
            "Combination 40/252:\n",
            "Hidden Layers: [128, 64], Activation: relu, Learning Rate: 0.01, Batch Size: 64, Epochs: 50\n",
            "Epoch 1/50 - 0.06s - loss: 1.1031 - acc: 0.3257 - val_loss: 1.1038 - val_acc: 0.3482\n",
            "Epoch 2/50 - 0.05s - loss: 1.0970 - acc: 0.3626 - val_loss: 1.0987 - val_acc: 0.3563\n",
            "Epoch 3/50 - 0.05s - loss: 1.0924 - acc: 0.3884 - val_loss: 1.0951 - val_acc: 0.3765\n",
            "Epoch 4/50 - 0.06s - loss: 1.0885 - acc: 0.4060 - val_loss: 1.0921 - val_acc: 0.3988\n",
            "Epoch 5/50 - 0.08s - loss: 1.0853 - acc: 0.4121 - val_loss: 1.0901 - val_acc: 0.4008\n",
            "Epoch 6/50 - 0.06s - loss: 1.0820 - acc: 0.4298 - val_loss: 1.0875 - val_acc: 0.4049\n",
            "Epoch 7/50 - 0.06s - loss: 1.0789 - acc: 0.4404 - val_loss: 1.0857 - val_acc: 0.4231\n",
            "Epoch 8/50 - 0.06s - loss: 1.0758 - acc: 0.4523 - val_loss: 1.0834 - val_acc: 0.4372\n",
            "Epoch 9/50 - 0.05s - loss: 1.0727 - acc: 0.4582 - val_loss: 1.0814 - val_acc: 0.4231\n",
            "Epoch 10/50 - 0.05s - loss: 1.0697 - acc: 0.4615 - val_loss: 1.0793 - val_acc: 0.4312\n",
            "Epoch 11/50 - 0.05s - loss: 1.0665 - acc: 0.4660 - val_loss: 1.0773 - val_acc: 0.4352\n",
            "Epoch 12/50 - 0.05s - loss: 1.0632 - acc: 0.4708 - val_loss: 1.0751 - val_acc: 0.4352\n",
            "Epoch 13/50 - 0.06s - loss: 1.0601 - acc: 0.4669 - val_loss: 1.0726 - val_acc: 0.4534\n",
            "Epoch 14/50 - 0.06s - loss: 1.0564 - acc: 0.4789 - val_loss: 1.0708 - val_acc: 0.4372\n",
            "Epoch 15/50 - 0.05s - loss: 1.0528 - acc: 0.4816 - val_loss: 1.0688 - val_acc: 0.4514\n",
            "Epoch 16/50 - 0.07s - loss: 1.0492 - acc: 0.4838 - val_loss: 1.0664 - val_acc: 0.4534\n",
            "Epoch 17/50 - 0.06s - loss: 1.0460 - acc: 0.4888 - val_loss: 1.0649 - val_acc: 0.4534\n",
            "Epoch 18/50 - 0.06s - loss: 1.0426 - acc: 0.4858 - val_loss: 1.0632 - val_acc: 0.4575\n",
            "Epoch 19/50 - 0.06s - loss: 1.0391 - acc: 0.4917 - val_loss: 1.0605 - val_acc: 0.4534\n",
            "Epoch 20/50 - 0.05s - loss: 1.0356 - acc: 0.4831 - val_loss: 1.0582 - val_acc: 0.4757\n",
            "Epoch 21/50 - 0.06s - loss: 1.0324 - acc: 0.4894 - val_loss: 1.0564 - val_acc: 0.4656\n",
            "Epoch 22/50 - 0.05s - loss: 1.0286 - acc: 0.4969 - val_loss: 1.0553 - val_acc: 0.4555\n",
            "Epoch 23/50 - 0.05s - loss: 1.0252 - acc: 0.4987 - val_loss: 1.0529 - val_acc: 0.4737\n",
            "Epoch 24/50 - 0.05s - loss: 1.0225 - acc: 0.4946 - val_loss: 1.0508 - val_acc: 0.4717\n",
            "Epoch 25/50 - 0.05s - loss: 1.0193 - acc: 0.5027 - val_loss: 1.0505 - val_acc: 0.4656\n",
            "Epoch 26/50 - 0.05s - loss: 1.0162 - acc: 0.4957 - val_loss: 1.0476 - val_acc: 0.4696\n",
            "Epoch 27/50 - 0.05s - loss: 1.0122 - acc: 0.5065 - val_loss: 1.0452 - val_acc: 0.4777\n",
            "Epoch 28/50 - 0.05s - loss: 1.0093 - acc: 0.5153 - val_loss: 1.0433 - val_acc: 0.4818\n",
            "Epoch 29/50 - 0.06s - loss: 1.0060 - acc: 0.5173 - val_loss: 1.0409 - val_acc: 0.4919\n",
            "Epoch 30/50 - 0.05s - loss: 1.0030 - acc: 0.5160 - val_loss: 1.0384 - val_acc: 0.4899\n",
            "Epoch 31/50 - 0.05s - loss: 1.0002 - acc: 0.5175 - val_loss: 1.0363 - val_acc: 0.4939\n",
            "Epoch 32/50 - 0.06s - loss: 0.9968 - acc: 0.5247 - val_loss: 1.0345 - val_acc: 0.4879\n",
            "Epoch 33/50 - 0.06s - loss: 0.9945 - acc: 0.5189 - val_loss: 1.0341 - val_acc: 0.4757\n",
            "Epoch 34/50 - 0.05s - loss: 0.9912 - acc: 0.5198 - val_loss: 1.0306 - val_acc: 0.4960\n",
            "Epoch 35/50 - 0.05s - loss: 0.9878 - acc: 0.5245 - val_loss: 1.0286 - val_acc: 0.4838\n",
            "Epoch 36/50 - 0.05s - loss: 0.9866 - acc: 0.5198 - val_loss: 1.0290 - val_acc: 0.4798\n",
            "Epoch 37/50 - 0.06s - loss: 0.9823 - acc: 0.5304 - val_loss: 1.0233 - val_acc: 0.4798\n",
            "Epoch 38/50 - 0.05s - loss: 0.9810 - acc: 0.5229 - val_loss: 1.0243 - val_acc: 0.4757\n",
            "Epoch 39/50 - 0.05s - loss: 0.9770 - acc: 0.5288 - val_loss: 1.0185 - val_acc: 0.4919\n",
            "Epoch 40/50 - 0.05s - loss: 0.9751 - acc: 0.5268 - val_loss: 1.0181 - val_acc: 0.4980\n",
            "Epoch 41/50 - 0.05s - loss: 0.9710 - acc: 0.5364 - val_loss: 1.0136 - val_acc: 0.4960\n",
            "Epoch 42/50 - 0.05s - loss: 0.9674 - acc: 0.5385 - val_loss: 1.0109 - val_acc: 0.5142\n",
            "Epoch 43/50 - 0.05s - loss: 0.9655 - acc: 0.5385 - val_loss: 1.0110 - val_acc: 0.5040\n",
            "Epoch 44/50 - 0.05s - loss: 0.9624 - acc: 0.5403 - val_loss: 1.0074 - val_acc: 0.5121\n",
            "Epoch 45/50 - 0.05s - loss: 0.9600 - acc: 0.5432 - val_loss: 1.0062 - val_acc: 0.5101\n",
            "Epoch 46/50 - 0.06s - loss: 0.9580 - acc: 0.5432 - val_loss: 1.0037 - val_acc: 0.5121\n",
            "Epoch 47/50 - 0.06s - loss: 0.9594 - acc: 0.5439 - val_loss: 1.0038 - val_acc: 0.5142\n",
            "Epoch 48/50 - 0.06s - loss: 0.9521 - acc: 0.5468 - val_loss: 0.9991 - val_acc: 0.5182\n",
            "Epoch 49/50 - 0.06s - loss: 0.9517 - acc: 0.5481 - val_loss: 0.9988 - val_acc: 0.5202\n",
            "Epoch 50/50 - 0.05s - loss: 0.9495 - acc: 0.5502 - val_loss: 0.9981 - val_acc: 0.5162\n",
            "\n",
            "Combination 41/252:\n",
            "Hidden Layers: [128, 64], Activation: relu, Learning Rate: 0.01, Batch Size: 64, Epochs: 100\n",
            "Epoch 1/100 - 0.05s - loss: 1.0861 - acc: 0.4107 - val_loss: 1.0871 - val_acc: 0.3887\n",
            "Epoch 2/100 - 0.05s - loss: 1.0809 - acc: 0.4435 - val_loss: 1.0824 - val_acc: 0.4190\n",
            "Epoch 3/100 - 0.05s - loss: 1.0758 - acc: 0.4478 - val_loss: 1.0789 - val_acc: 0.4231\n",
            "Epoch 4/100 - 0.05s - loss: 1.0719 - acc: 0.4420 - val_loss: 1.0765 - val_acc: 0.4190\n",
            "Epoch 5/100 - 0.05s - loss: 1.0675 - acc: 0.4539 - val_loss: 1.0728 - val_acc: 0.4393\n",
            "Epoch 6/100 - 0.06s - loss: 1.0641 - acc: 0.4570 - val_loss: 1.0712 - val_acc: 0.4494\n",
            "Epoch 7/100 - 0.06s - loss: 1.0602 - acc: 0.4631 - val_loss: 1.0669 - val_acc: 0.4636\n",
            "Epoch 8/100 - 0.06s - loss: 1.0568 - acc: 0.4658 - val_loss: 1.0651 - val_acc: 0.4555\n",
            "Epoch 9/100 - 0.05s - loss: 1.0535 - acc: 0.4681 - val_loss: 1.0630 - val_acc: 0.4656\n",
            "Epoch 10/100 - 0.05s - loss: 1.0507 - acc: 0.4732 - val_loss: 1.0613 - val_acc: 0.4818\n",
            "Epoch 11/100 - 0.05s - loss: 1.0477 - acc: 0.4723 - val_loss: 1.0596 - val_acc: 0.4717\n",
            "Epoch 12/100 - 0.06s - loss: 1.0451 - acc: 0.4714 - val_loss: 1.0565 - val_acc: 0.4615\n",
            "Epoch 13/100 - 0.06s - loss: 1.0418 - acc: 0.4741 - val_loss: 1.0545 - val_acc: 0.4696\n",
            "Epoch 14/100 - 0.05s - loss: 1.0388 - acc: 0.4780 - val_loss: 1.0527 - val_acc: 0.4737\n",
            "Epoch 15/100 - 0.06s - loss: 1.0361 - acc: 0.4825 - val_loss: 1.0519 - val_acc: 0.4939\n",
            "Epoch 16/100 - 0.06s - loss: 1.0334 - acc: 0.4807 - val_loss: 1.0495 - val_acc: 0.4838\n",
            "Epoch 17/100 - 0.05s - loss: 1.0310 - acc: 0.4894 - val_loss: 1.0477 - val_acc: 0.4939\n",
            "Epoch 18/100 - 0.06s - loss: 1.0276 - acc: 0.4872 - val_loss: 1.0448 - val_acc: 0.4960\n",
            "Epoch 19/100 - 0.06s - loss: 1.0245 - acc: 0.4915 - val_loss: 1.0429 - val_acc: 0.4980\n",
            "Epoch 20/100 - 0.06s - loss: 1.0216 - acc: 0.4957 - val_loss: 1.0402 - val_acc: 0.5000\n",
            "Epoch 21/100 - 0.05s - loss: 1.0193 - acc: 0.4903 - val_loss: 1.0396 - val_acc: 0.5040\n",
            "Epoch 22/100 - 0.06s - loss: 1.0159 - acc: 0.4996 - val_loss: 1.0353 - val_acc: 0.5000\n",
            "Epoch 23/100 - 0.06s - loss: 1.0139 - acc: 0.5025 - val_loss: 1.0339 - val_acc: 0.4919\n",
            "Epoch 24/100 - 0.06s - loss: 1.0097 - acc: 0.5009 - val_loss: 1.0316 - val_acc: 0.5162\n",
            "Epoch 25/100 - 0.06s - loss: 1.0075 - acc: 0.4996 - val_loss: 1.0303 - val_acc: 0.5121\n",
            "Epoch 26/100 - 0.06s - loss: 1.0042 - acc: 0.5047 - val_loss: 1.0278 - val_acc: 0.5182\n",
            "Epoch 27/100 - 0.06s - loss: 1.0008 - acc: 0.5081 - val_loss: 1.0234 - val_acc: 0.5061\n",
            "Epoch 28/100 - 0.05s - loss: 0.9989 - acc: 0.5070 - val_loss: 1.0223 - val_acc: 0.5223\n",
            "Epoch 29/100 - 0.06s - loss: 0.9958 - acc: 0.5175 - val_loss: 1.0211 - val_acc: 0.4980\n",
            "Epoch 30/100 - 0.06s - loss: 0.9941 - acc: 0.5187 - val_loss: 1.0205 - val_acc: 0.4899\n",
            "Epoch 31/100 - 0.06s - loss: 0.9897 - acc: 0.5236 - val_loss: 1.0156 - val_acc: 0.4960\n",
            "Epoch 32/100 - 0.06s - loss: 0.9877 - acc: 0.5252 - val_loss: 1.0145 - val_acc: 0.4939\n",
            "Epoch 33/100 - 0.06s - loss: 0.9829 - acc: 0.5227 - val_loss: 1.0090 - val_acc: 0.5101\n",
            "Epoch 34/100 - 0.05s - loss: 0.9838 - acc: 0.5209 - val_loss: 1.0127 - val_acc: 0.5020\n",
            "Epoch 35/100 - 0.05s - loss: 0.9809 - acc: 0.5191 - val_loss: 1.0069 - val_acc: 0.5243\n",
            "Epoch 36/100 - 0.05s - loss: 0.9754 - acc: 0.5317 - val_loss: 1.0044 - val_acc: 0.5081\n",
            "Epoch 37/100 - 0.05s - loss: 0.9738 - acc: 0.5265 - val_loss: 1.0006 - val_acc: 0.5162\n",
            "Epoch 38/100 - 0.05s - loss: 0.9698 - acc: 0.5322 - val_loss: 0.9984 - val_acc: 0.5142\n",
            "Epoch 39/100 - 0.05s - loss: 0.9664 - acc: 0.5362 - val_loss: 0.9959 - val_acc: 0.5081\n",
            "Epoch 40/100 - 0.06s - loss: 0.9639 - acc: 0.5358 - val_loss: 0.9945 - val_acc: 0.5081\n",
            "Epoch 41/100 - 0.05s - loss: 0.9642 - acc: 0.5319 - val_loss: 0.9928 - val_acc: 0.5162\n",
            "Epoch 42/100 - 0.05s - loss: 0.9594 - acc: 0.5376 - val_loss: 0.9899 - val_acc: 0.5121\n",
            "Epoch 43/100 - 0.05s - loss: 0.9586 - acc: 0.5423 - val_loss: 0.9917 - val_acc: 0.5061\n",
            "Epoch 44/100 - 0.06s - loss: 0.9542 - acc: 0.5432 - val_loss: 0.9862 - val_acc: 0.5182\n",
            "Epoch 45/100 - 0.06s - loss: 0.9523 - acc: 0.5445 - val_loss: 0.9845 - val_acc: 0.5182\n",
            "Epoch 46/100 - 0.06s - loss: 0.9512 - acc: 0.5454 - val_loss: 0.9839 - val_acc: 0.5142\n",
            "Epoch 47/100 - 0.06s - loss: 0.9489 - acc: 0.5502 - val_loss: 0.9828 - val_acc: 0.5243\n",
            "Epoch 48/100 - 0.06s - loss: 0.9457 - acc: 0.5499 - val_loss: 0.9808 - val_acc: 0.5263\n",
            "Epoch 49/100 - 0.06s - loss: 0.9506 - acc: 0.5443 - val_loss: 0.9891 - val_acc: 0.5263\n",
            "Epoch 50/100 - 0.05s - loss: 0.9412 - acc: 0.5576 - val_loss: 0.9779 - val_acc: 0.5385\n",
            "Epoch 51/100 - 0.05s - loss: 0.9404 - acc: 0.5551 - val_loss: 0.9785 - val_acc: 0.5486\n",
            "Epoch 52/100 - 0.05s - loss: 0.9393 - acc: 0.5515 - val_loss: 0.9787 - val_acc: 0.5405\n",
            "Epoch 53/100 - 0.06s - loss: 0.9457 - acc: 0.5452 - val_loss: 0.9866 - val_acc: 0.5243\n",
            "Epoch 54/100 - 0.05s - loss: 0.9363 - acc: 0.5542 - val_loss: 0.9734 - val_acc: 0.5324\n",
            "Epoch 55/100 - 0.05s - loss: 0.9331 - acc: 0.5605 - val_loss: 0.9727 - val_acc: 0.5324\n",
            "Epoch 56/100 - 0.05s - loss: 0.9312 - acc: 0.5601 - val_loss: 0.9713 - val_acc: 0.5445\n",
            "Epoch 57/100 - 0.05s - loss: 0.9446 - acc: 0.5481 - val_loss: 0.9810 - val_acc: 0.5466\n",
            "Epoch 58/100 - 0.05s - loss: 0.9300 - acc: 0.5585 - val_loss: 0.9702 - val_acc: 0.5263\n",
            "Epoch 59/100 - 0.05s - loss: 0.9249 - acc: 0.5679 - val_loss: 0.9669 - val_acc: 0.5405\n",
            "Epoch 60/100 - 0.05s - loss: 0.9228 - acc: 0.5652 - val_loss: 0.9650 - val_acc: 0.5405\n",
            "Epoch 61/100 - 0.05s - loss: 0.9252 - acc: 0.5637 - val_loss: 0.9669 - val_acc: 0.5405\n",
            "Epoch 62/100 - 0.05s - loss: 0.9221 - acc: 0.5643 - val_loss: 0.9648 - val_acc: 0.5344\n",
            "Epoch 63/100 - 0.05s - loss: 0.9189 - acc: 0.5711 - val_loss: 0.9668 - val_acc: 0.5364\n",
            "Epoch 64/100 - 0.05s - loss: 0.9150 - acc: 0.5684 - val_loss: 0.9621 - val_acc: 0.5547\n",
            "Epoch 65/100 - 0.06s - loss: 0.9142 - acc: 0.5691 - val_loss: 0.9640 - val_acc: 0.5506\n",
            "Epoch 66/100 - 0.05s - loss: 0.9133 - acc: 0.5704 - val_loss: 0.9633 - val_acc: 0.5567\n",
            "Epoch 67/100 - 0.06s - loss: 0.9100 - acc: 0.5700 - val_loss: 0.9585 - val_acc: 0.5506\n",
            "Epoch 68/100 - 0.05s - loss: 0.9275 - acc: 0.5517 - val_loss: 0.9828 - val_acc: 0.5364\n",
            "Epoch 69/100 - 0.05s - loss: 0.9082 - acc: 0.5751 - val_loss: 0.9595 - val_acc: 0.5364\n",
            "Epoch 70/100 - 0.06s - loss: 0.9084 - acc: 0.5713 - val_loss: 0.9579 - val_acc: 0.5425\n",
            "Epoch 71/100 - 0.05s - loss: 0.9038 - acc: 0.5765 - val_loss: 0.9577 - val_acc: 0.5486\n",
            "Epoch 72/100 - 0.05s - loss: 0.9023 - acc: 0.5749 - val_loss: 0.9565 - val_acc: 0.5506\n",
            "Epoch 73/100 - 0.05s - loss: 0.9027 - acc: 0.5787 - val_loss: 0.9597 - val_acc: 0.5547\n",
            "Epoch 74/100 - 0.05s - loss: 0.9039 - acc: 0.5760 - val_loss: 0.9577 - val_acc: 0.5466\n",
            "Epoch 75/100 - 0.05s - loss: 0.8981 - acc: 0.5774 - val_loss: 0.9548 - val_acc: 0.5526\n",
            "Epoch 76/100 - 0.05s - loss: 0.9042 - acc: 0.5733 - val_loss: 0.9563 - val_acc: 0.5425\n",
            "Epoch 77/100 - 0.06s - loss: 0.8995 - acc: 0.5803 - val_loss: 0.9614 - val_acc: 0.5385\n",
            "Epoch 78/100 - 0.06s - loss: 0.9081 - acc: 0.5735 - val_loss: 0.9613 - val_acc: 0.5607\n",
            "Epoch 79/100 - 0.06s - loss: 0.8948 - acc: 0.5821 - val_loss: 0.9517 - val_acc: 0.5445\n",
            "Epoch 80/100 - 0.06s - loss: 0.8939 - acc: 0.5796 - val_loss: 0.9505 - val_acc: 0.5405\n",
            "Epoch 81/100 - 0.06s - loss: 0.8906 - acc: 0.5866 - val_loss: 0.9548 - val_acc: 0.5304\n",
            "Epoch 82/100 - 0.06s - loss: 0.8990 - acc: 0.5774 - val_loss: 0.9546 - val_acc: 0.5486\n",
            "Epoch 83/100 - 0.05s - loss: 0.8929 - acc: 0.5812 - val_loss: 0.9522 - val_acc: 0.5607\n",
            "Epoch 84/100 - 0.05s - loss: 0.8912 - acc: 0.5816 - val_loss: 0.9614 - val_acc: 0.5506\n",
            "Epoch 85/100 - 0.06s - loss: 0.8826 - acc: 0.5879 - val_loss: 0.9476 - val_acc: 0.5547\n",
            "Epoch 86/100 - 0.07s - loss: 0.8991 - acc: 0.5796 - val_loss: 0.9578 - val_acc: 0.5405\n",
            "Epoch 87/100 - 0.05s - loss: 0.8833 - acc: 0.5852 - val_loss: 0.9474 - val_acc: 0.5567\n",
            "Epoch 88/100 - 0.05s - loss: 0.8779 - acc: 0.5915 - val_loss: 0.9479 - val_acc: 0.5506\n",
            "Epoch 89/100 - 0.06s - loss: 0.8889 - acc: 0.5864 - val_loss: 0.9532 - val_acc: 0.5648\n",
            "Epoch 90/100 - 0.06s - loss: 0.8807 - acc: 0.5870 - val_loss: 0.9484 - val_acc: 0.5506\n",
            "Epoch 91/100 - 0.06s - loss: 0.8980 - acc: 0.5821 - val_loss: 0.9601 - val_acc: 0.5567\n",
            "Epoch 92/100 - 0.06s - loss: 0.8743 - acc: 0.5931 - val_loss: 0.9476 - val_acc: 0.5466\n",
            "Epoch 93/100 - 0.06s - loss: 0.8823 - acc: 0.5846 - val_loss: 0.9618 - val_acc: 0.5385\n",
            "Epoch 94/100 - 0.06s - loss: 0.8744 - acc: 0.5922 - val_loss: 0.9436 - val_acc: 0.5486\n",
            "Epoch 95/100 - 0.06s - loss: 0.8692 - acc: 0.5960 - val_loss: 0.9441 - val_acc: 0.5587\n",
            "Epoch 96/100 - 0.06s - loss: 0.8680 - acc: 0.5960 - val_loss: 0.9468 - val_acc: 0.5466\n",
            "Epoch 97/100 - 0.06s - loss: 0.8709 - acc: 0.5963 - val_loss: 0.9524 - val_acc: 0.5466\n",
            "Epoch 98/100 - 0.05s - loss: 0.8645 - acc: 0.5996 - val_loss: 0.9440 - val_acc: 0.5405\n",
            "Epoch 99/100 - 0.05s - loss: 0.8760 - acc: 0.5927 - val_loss: 0.9518 - val_acc: 0.5567\n",
            "Epoch 100/100 - 0.05s - loss: 0.8652 - acc: 0.5956 - val_loss: 0.9513 - val_acc: 0.5324\n",
            "\n",
            "Combination 42/252:\n",
            "Hidden Layers: [128, 64], Activation: relu, Learning Rate: 0.01, Batch Size: 64, Epochs: 150\n",
            "Epoch 1/150 - 0.06s - loss: 1.0920 - acc: 0.3878 - val_loss: 1.0952 - val_acc: 0.3785\n",
            "Epoch 2/150 - 0.06s - loss: 1.0865 - acc: 0.4096 - val_loss: 1.0913 - val_acc: 0.3988\n",
            "Epoch 3/150 - 0.05s - loss: 1.0817 - acc: 0.4206 - val_loss: 1.0881 - val_acc: 0.3887\n",
            "Epoch 4/150 - 0.06s - loss: 1.0773 - acc: 0.4318 - val_loss: 1.0850 - val_acc: 0.3927\n",
            "Epoch 5/150 - 0.06s - loss: 1.0732 - acc: 0.4379 - val_loss: 1.0821 - val_acc: 0.4130\n",
            "Epoch 6/150 - 0.05s - loss: 1.0691 - acc: 0.4449 - val_loss: 1.0790 - val_acc: 0.4231\n",
            "Epoch 7/150 - 0.05s - loss: 1.0652 - acc: 0.4519 - val_loss: 1.0765 - val_acc: 0.4312\n",
            "Epoch 8/150 - 0.05s - loss: 1.0616 - acc: 0.4521 - val_loss: 1.0737 - val_acc: 0.4271\n",
            "Epoch 9/150 - 0.05s - loss: 1.0579 - acc: 0.4559 - val_loss: 1.0712 - val_acc: 0.4231\n",
            "Epoch 10/150 - 0.06s - loss: 1.0542 - acc: 0.4620 - val_loss: 1.0691 - val_acc: 0.4312\n",
            "Epoch 11/150 - 0.06s - loss: 1.0511 - acc: 0.4618 - val_loss: 1.0680 - val_acc: 0.4170\n",
            "Epoch 12/150 - 0.05s - loss: 1.0473 - acc: 0.4719 - val_loss: 1.0647 - val_acc: 0.4474\n",
            "Epoch 13/150 - 0.05s - loss: 1.0440 - acc: 0.4759 - val_loss: 1.0629 - val_acc: 0.4636\n",
            "Epoch 14/150 - 0.05s - loss: 1.0413 - acc: 0.4741 - val_loss: 1.0613 - val_acc: 0.4656\n",
            "Epoch 15/150 - 0.05s - loss: 1.0380 - acc: 0.4807 - val_loss: 1.0591 - val_acc: 0.4656\n",
            "Epoch 16/150 - 0.05s - loss: 1.0353 - acc: 0.4836 - val_loss: 1.0566 - val_acc: 0.4737\n",
            "Epoch 17/150 - 0.06s - loss: 1.0321 - acc: 0.4892 - val_loss: 1.0548 - val_acc: 0.4879\n",
            "Epoch 18/150 - 0.05s - loss: 1.0300 - acc: 0.4861 - val_loss: 1.0545 - val_acc: 0.4717\n",
            "Epoch 19/150 - 0.05s - loss: 1.0268 - acc: 0.4915 - val_loss: 1.0514 - val_acc: 0.5040\n",
            "Epoch 20/150 - 0.05s - loss: 1.0237 - acc: 0.4942 - val_loss: 1.0483 - val_acc: 0.4858\n",
            "Epoch 21/150 - 0.06s - loss: 1.0214 - acc: 0.5034 - val_loss: 1.0472 - val_acc: 0.5101\n",
            "Epoch 22/150 - 0.06s - loss: 1.0186 - acc: 0.5025 - val_loss: 1.0452 - val_acc: 0.5081\n",
            "Epoch 23/150 - 0.06s - loss: 1.0160 - acc: 0.5036 - val_loss: 1.0433 - val_acc: 0.5101\n",
            "Epoch 24/150 - 0.06s - loss: 1.0123 - acc: 0.5045 - val_loss: 1.0394 - val_acc: 0.5040\n",
            "Epoch 25/150 - 0.06s - loss: 1.0099 - acc: 0.5070 - val_loss: 1.0370 - val_acc: 0.4879\n",
            "Epoch 26/150 - 0.05s - loss: 1.0082 - acc: 0.5092 - val_loss: 1.0374 - val_acc: 0.5081\n",
            "Epoch 27/150 - 0.05s - loss: 1.0045 - acc: 0.5180 - val_loss: 1.0345 - val_acc: 0.5142\n",
            "Epoch 28/150 - 0.05s - loss: 1.0017 - acc: 0.5207 - val_loss: 1.0318 - val_acc: 0.5121\n",
            "Epoch 29/150 - 0.06s - loss: 0.9993 - acc: 0.5180 - val_loss: 1.0300 - val_acc: 0.5182\n",
            "Epoch 30/150 - 0.05s - loss: 0.9963 - acc: 0.5202 - val_loss: 1.0265 - val_acc: 0.5162\n",
            "Epoch 31/150 - 0.05s - loss: 0.9930 - acc: 0.5227 - val_loss: 1.0242 - val_acc: 0.5304\n",
            "Epoch 32/150 - 0.05s - loss: 0.9910 - acc: 0.5272 - val_loss: 1.0225 - val_acc: 0.5202\n",
            "Epoch 33/150 - 0.06s - loss: 0.9885 - acc: 0.5261 - val_loss: 1.0193 - val_acc: 0.5182\n",
            "Epoch 34/150 - 0.06s - loss: 0.9864 - acc: 0.5306 - val_loss: 1.0199 - val_acc: 0.5202\n",
            "Epoch 35/150 - 0.05s - loss: 0.9833 - acc: 0.5322 - val_loss: 1.0174 - val_acc: 0.5162\n",
            "Epoch 36/150 - 0.05s - loss: 0.9817 - acc: 0.5299 - val_loss: 1.0168 - val_acc: 0.5182\n",
            "Epoch 37/150 - 0.06s - loss: 0.9785 - acc: 0.5315 - val_loss: 1.0105 - val_acc: 0.5283\n",
            "Epoch 38/150 - 0.05s - loss: 0.9762 - acc: 0.5362 - val_loss: 1.0110 - val_acc: 0.5283\n",
            "Epoch 39/150 - 0.06s - loss: 0.9765 - acc: 0.5313 - val_loss: 1.0133 - val_acc: 0.5101\n",
            "Epoch 40/150 - 0.06s - loss: 0.9694 - acc: 0.5405 - val_loss: 1.0049 - val_acc: 0.5324\n",
            "Epoch 41/150 - 0.06s - loss: 0.9669 - acc: 0.5423 - val_loss: 1.0024 - val_acc: 0.5385\n",
            "Epoch 42/150 - 0.05s - loss: 0.9651 - acc: 0.5405 - val_loss: 1.0000 - val_acc: 0.5526\n",
            "Epoch 43/150 - 0.05s - loss: 0.9639 - acc: 0.5439 - val_loss: 0.9995 - val_acc: 0.5526\n",
            "Epoch 44/150 - 0.05s - loss: 0.9590 - acc: 0.5452 - val_loss: 0.9953 - val_acc: 0.5486\n",
            "Epoch 45/150 - 0.05s - loss: 0.9574 - acc: 0.5495 - val_loss: 0.9956 - val_acc: 0.5526\n",
            "Epoch 46/150 - 0.05s - loss: 0.9678 - acc: 0.5389 - val_loss: 1.0022 - val_acc: 0.5263\n",
            "Epoch 47/150 - 0.05s - loss: 0.9517 - acc: 0.5549 - val_loss: 0.9918 - val_acc: 0.5385\n",
            "Epoch 48/150 - 0.06s - loss: 0.9497 - acc: 0.5488 - val_loss: 0.9885 - val_acc: 0.5547\n",
            "Epoch 49/150 - 0.06s - loss: 0.9515 - acc: 0.5529 - val_loss: 0.9931 - val_acc: 0.5486\n",
            "Epoch 50/150 - 0.06s - loss: 0.9450 - acc: 0.5569 - val_loss: 0.9854 - val_acc: 0.5607\n",
            "Epoch 51/150 - 0.05s - loss: 0.9419 - acc: 0.5569 - val_loss: 0.9827 - val_acc: 0.5567\n",
            "Epoch 52/150 - 0.05s - loss: 0.9400 - acc: 0.5612 - val_loss: 0.9829 - val_acc: 0.5486\n",
            "Epoch 53/150 - 0.06s - loss: 0.9374 - acc: 0.5634 - val_loss: 0.9799 - val_acc: 0.5506\n",
            "Epoch 54/150 - 0.06s - loss: 0.9379 - acc: 0.5569 - val_loss: 0.9812 - val_acc: 0.5567\n",
            "Epoch 55/150 - 0.05s - loss: 0.9335 - acc: 0.5673 - val_loss: 0.9767 - val_acc: 0.5506\n",
            "Epoch 56/150 - 0.05s - loss: 0.9347 - acc: 0.5596 - val_loss: 0.9759 - val_acc: 0.5445\n",
            "Epoch 57/150 - 0.05s - loss: 0.9427 - acc: 0.5427 - val_loss: 0.9888 - val_acc: 0.5304\n",
            "Epoch 58/150 - 0.06s - loss: 0.9293 - acc: 0.5621 - val_loss: 0.9733 - val_acc: 0.5425\n",
            "Epoch 59/150 - 0.05s - loss: 0.9344 - acc: 0.5601 - val_loss: 0.9778 - val_acc: 0.5567\n",
            "Epoch 60/150 - 0.05s - loss: 0.9264 - acc: 0.5610 - val_loss: 0.9737 - val_acc: 0.5526\n",
            "Epoch 61/150 - 0.05s - loss: 0.9277 - acc: 0.5612 - val_loss: 0.9726 - val_acc: 0.5526\n",
            "Epoch 62/150 - 0.05s - loss: 0.9292 - acc: 0.5621 - val_loss: 0.9743 - val_acc: 0.5587\n",
            "Epoch 63/150 - 0.05s - loss: 0.9255 - acc: 0.5670 - val_loss: 0.9774 - val_acc: 0.5466\n",
            "Epoch 64/150 - 0.05s - loss: 0.9182 - acc: 0.5688 - val_loss: 0.9694 - val_acc: 0.5587\n",
            "Epoch 65/150 - 0.05s - loss: 0.9212 - acc: 0.5724 - val_loss: 0.9755 - val_acc: 0.5547\n",
            "Epoch 66/150 - 0.05s - loss: 0.9160 - acc: 0.5661 - val_loss: 0.9646 - val_acc: 0.5445\n",
            "Epoch 67/150 - 0.05s - loss: 0.9131 - acc: 0.5720 - val_loss: 0.9625 - val_acc: 0.5486\n",
            "Epoch 68/150 - 0.05s - loss: 0.9132 - acc: 0.5688 - val_loss: 0.9631 - val_acc: 0.5486\n",
            "Epoch 69/150 - 0.05s - loss: 0.9091 - acc: 0.5744 - val_loss: 0.9606 - val_acc: 0.5405\n",
            "Epoch 70/150 - 0.06s - loss: 0.9070 - acc: 0.5852 - val_loss: 0.9633 - val_acc: 0.5628\n",
            "Epoch 71/150 - 0.06s - loss: 0.9090 - acc: 0.5796 - val_loss: 0.9618 - val_acc: 0.5648\n",
            "Epoch 72/150 - 0.06s - loss: 0.9211 - acc: 0.5630 - val_loss: 0.9798 - val_acc: 0.5283\n",
            "Epoch 73/150 - 0.06s - loss: 0.9018 - acc: 0.5830 - val_loss: 0.9562 - val_acc: 0.5547\n",
            "Epoch 74/150 - 0.06s - loss: 0.9016 - acc: 0.5855 - val_loss: 0.9571 - val_acc: 0.5567\n",
            "Epoch 75/150 - 0.06s - loss: 0.8981 - acc: 0.5821 - val_loss: 0.9553 - val_acc: 0.5567\n",
            "Epoch 76/150 - 0.06s - loss: 0.8969 - acc: 0.5780 - val_loss: 0.9542 - val_acc: 0.5526\n",
            "Epoch 77/150 - 0.06s - loss: 0.8959 - acc: 0.5794 - val_loss: 0.9531 - val_acc: 0.5506\n",
            "Epoch 78/150 - 0.06s - loss: 0.9085 - acc: 0.5762 - val_loss: 0.9760 - val_acc: 0.5304\n",
            "Epoch 79/150 - 0.06s - loss: 0.8940 - acc: 0.5875 - val_loss: 0.9584 - val_acc: 0.5628\n",
            "Epoch 80/150 - 0.06s - loss: 0.9047 - acc: 0.5769 - val_loss: 0.9621 - val_acc: 0.5648\n",
            "Epoch 81/150 - 0.06s - loss: 0.8916 - acc: 0.5897 - val_loss: 0.9565 - val_acc: 0.5587\n",
            "Epoch 82/150 - 0.06s - loss: 0.9176 - acc: 0.5652 - val_loss: 0.9699 - val_acc: 0.5709\n",
            "Epoch 83/150 - 0.07s - loss: 0.8902 - acc: 0.5837 - val_loss: 0.9562 - val_acc: 0.5567\n",
            "Epoch 84/150 - 0.06s - loss: 0.8844 - acc: 0.5974 - val_loss: 0.9512 - val_acc: 0.5648\n",
            "Epoch 85/150 - 0.06s - loss: 0.8881 - acc: 0.5922 - val_loss: 0.9512 - val_acc: 0.5607\n",
            "Epoch 86/150 - 0.06s - loss: 0.8981 - acc: 0.5852 - val_loss: 0.9596 - val_acc: 0.5567\n",
            "Epoch 87/150 - 0.06s - loss: 0.8921 - acc: 0.5848 - val_loss: 0.9543 - val_acc: 0.5688\n",
            "Epoch 88/150 - 0.06s - loss: 0.8871 - acc: 0.5864 - val_loss: 0.9598 - val_acc: 0.5547\n",
            "Epoch 89/150 - 0.06s - loss: 0.8856 - acc: 0.5882 - val_loss: 0.9482 - val_acc: 0.5688\n",
            "Epoch 90/150 - 0.06s - loss: 0.9021 - acc: 0.5839 - val_loss: 0.9678 - val_acc: 0.5506\n",
            "Epoch 91/150 - 0.06s - loss: 0.8810 - acc: 0.5861 - val_loss: 0.9541 - val_acc: 0.5587\n",
            "Epoch 92/150 - 0.06s - loss: 0.8843 - acc: 0.5913 - val_loss: 0.9504 - val_acc: 0.5729\n",
            "Epoch 93/150 - 0.07s - loss: 0.8741 - acc: 0.6030 - val_loss: 0.9452 - val_acc: 0.5688\n",
            "Epoch 94/150 - 0.06s - loss: 0.8724 - acc: 0.5960 - val_loss: 0.9443 - val_acc: 0.5587\n",
            "Epoch 95/150 - 0.06s - loss: 0.8753 - acc: 0.5994 - val_loss: 0.9452 - val_acc: 0.5749\n",
            "Epoch 96/150 - 0.06s - loss: 0.8676 - acc: 0.6044 - val_loss: 0.9433 - val_acc: 0.5466\n",
            "Epoch 97/150 - 0.05s - loss: 0.8654 - acc: 0.6055 - val_loss: 0.9432 - val_acc: 0.5587\n",
            "Epoch 98/150 - 0.05s - loss: 0.8669 - acc: 0.6030 - val_loss: 0.9414 - val_acc: 0.5688\n",
            "Epoch 99/150 - 0.06s - loss: 0.8641 - acc: 0.6082 - val_loss: 0.9431 - val_acc: 0.5628\n",
            "Epoch 100/150 - 0.06s - loss: 0.8803 - acc: 0.5974 - val_loss: 0.9540 - val_acc: 0.5648\n",
            "Epoch 101/150 - 0.06s - loss: 0.8596 - acc: 0.6084 - val_loss: 0.9402 - val_acc: 0.5567\n",
            "Epoch 102/150 - 0.06s - loss: 0.8711 - acc: 0.5945 - val_loss: 0.9567 - val_acc: 0.5385\n",
            "Epoch 103/150 - 0.06s - loss: 0.8773 - acc: 0.5974 - val_loss: 0.9525 - val_acc: 0.5789\n",
            "Epoch 104/150 - 0.06s - loss: 0.8610 - acc: 0.6017 - val_loss: 0.9411 - val_acc: 0.5769\n",
            "Epoch 105/150 - 0.06s - loss: 0.8589 - acc: 0.6093 - val_loss: 0.9483 - val_acc: 0.5729\n",
            "Epoch 106/150 - 0.05s - loss: 0.8538 - acc: 0.6093 - val_loss: 0.9396 - val_acc: 0.5587\n",
            "Epoch 107/150 - 0.06s - loss: 0.8533 - acc: 0.6116 - val_loss: 0.9385 - val_acc: 0.5789\n",
            "Epoch 108/150 - 0.05s - loss: 0.8518 - acc: 0.6181 - val_loss: 0.9429 - val_acc: 0.5587\n",
            "Epoch 109/150 - 0.05s - loss: 0.8626 - acc: 0.5963 - val_loss: 0.9483 - val_acc: 0.5587\n",
            "Epoch 110/150 - 0.06s - loss: 0.8500 - acc: 0.6190 - val_loss: 0.9431 - val_acc: 0.5587\n",
            "Epoch 111/150 - 0.06s - loss: 0.8486 - acc: 0.6183 - val_loss: 0.9438 - val_acc: 0.5526\n",
            "Epoch 112/150 - 0.05s - loss: 0.8459 - acc: 0.6197 - val_loss: 0.9404 - val_acc: 0.5628\n",
            "Epoch 113/150 - 0.05s - loss: 0.8469 - acc: 0.6174 - val_loss: 0.9430 - val_acc: 0.5587\n",
            "Epoch 114/150 - 0.05s - loss: 0.8504 - acc: 0.6134 - val_loss: 0.9467 - val_acc: 0.5466\n",
            "Epoch 115/150 - 0.06s - loss: 0.8438 - acc: 0.6221 - val_loss: 0.9437 - val_acc: 0.5526\n",
            "Epoch 116/150 - 0.05s - loss: 0.8619 - acc: 0.6062 - val_loss: 0.9548 - val_acc: 0.5486\n",
            "Epoch 117/150 - 0.05s - loss: 0.8383 - acc: 0.6206 - val_loss: 0.9387 - val_acc: 0.5628\n",
            "Epoch 118/150 - 0.05s - loss: 0.8374 - acc: 0.6224 - val_loss: 0.9373 - val_acc: 0.5607\n",
            "Epoch 119/150 - 0.05s - loss: 0.8473 - acc: 0.6165 - val_loss: 0.9423 - val_acc: 0.5648\n",
            "Epoch 120/150 - 0.05s - loss: 0.8375 - acc: 0.6248 - val_loss: 0.9418 - val_acc: 0.5425\n",
            "Epoch 121/150 - 0.05s - loss: 0.8405 - acc: 0.6235 - val_loss: 0.9460 - val_acc: 0.5587\n",
            "Epoch 122/150 - 0.06s - loss: 0.8481 - acc: 0.6057 - val_loss: 0.9438 - val_acc: 0.5648\n",
            "Epoch 123/150 - 0.05s - loss: 0.8358 - acc: 0.6282 - val_loss: 0.9399 - val_acc: 0.5709\n",
            "Epoch 124/150 - 0.05s - loss: 0.8422 - acc: 0.6100 - val_loss: 0.9478 - val_acc: 0.5668\n",
            "Epoch 125/150 - 0.06s - loss: 0.8269 - acc: 0.6280 - val_loss: 0.9341 - val_acc: 0.5749\n",
            "Epoch 126/150 - 0.06s - loss: 0.8317 - acc: 0.6228 - val_loss: 0.9327 - val_acc: 0.5769\n",
            "Epoch 127/150 - 0.05s - loss: 0.8419 - acc: 0.6167 - val_loss: 0.9581 - val_acc: 0.5344\n",
            "Epoch 128/150 - 0.05s - loss: 0.8395 - acc: 0.6228 - val_loss: 0.9393 - val_acc: 0.5810\n",
            "Epoch 129/150 - 0.06s - loss: 0.8226 - acc: 0.6325 - val_loss: 0.9364 - val_acc: 0.5668\n",
            "Epoch 130/150 - 0.06s - loss: 0.8280 - acc: 0.6320 - val_loss: 0.9421 - val_acc: 0.5506\n",
            "Epoch 131/150 - 0.06s - loss: 0.8261 - acc: 0.6287 - val_loss: 0.9503 - val_acc: 0.5506\n",
            "Epoch 132/150 - 0.06s - loss: 0.8197 - acc: 0.6334 - val_loss: 0.9346 - val_acc: 0.5587\n",
            "Epoch 133/150 - 0.06s - loss: 0.8163 - acc: 0.6368 - val_loss: 0.9306 - val_acc: 0.5749\n",
            "Epoch 134/150 - 0.05s - loss: 0.8439 - acc: 0.6134 - val_loss: 0.9721 - val_acc: 0.5223\n",
            "Epoch 135/150 - 0.05s - loss: 0.8197 - acc: 0.6359 - val_loss: 0.9346 - val_acc: 0.5648\n",
            "Epoch 136/150 - 0.06s - loss: 0.8142 - acc: 0.6347 - val_loss: 0.9369 - val_acc: 0.5688\n",
            "Epoch 137/150 - 0.06s - loss: 0.8106 - acc: 0.6399 - val_loss: 0.9326 - val_acc: 0.5688\n",
            "Epoch 138/150 - 0.06s - loss: 0.8183 - acc: 0.6318 - val_loss: 0.9420 - val_acc: 0.5709\n",
            "Epoch 139/150 - 0.05s - loss: 0.8150 - acc: 0.6368 - val_loss: 0.9335 - val_acc: 0.5830\n",
            "Epoch 140/150 - 0.06s - loss: 0.8175 - acc: 0.6334 - val_loss: 0.9361 - val_acc: 0.5810\n",
            "Epoch 141/150 - 0.06s - loss: 0.8058 - acc: 0.6395 - val_loss: 0.9303 - val_acc: 0.5810\n",
            "Epoch 142/150 - 0.06s - loss: 0.8472 - acc: 0.6174 - val_loss: 0.9601 - val_acc: 0.5709\n",
            "Epoch 143/150 - 0.06s - loss: 0.8859 - acc: 0.5758 - val_loss: 1.0368 - val_acc: 0.4899\n",
            "Epoch 144/150 - 0.05s - loss: 0.8143 - acc: 0.6392 - val_loss: 0.9455 - val_acc: 0.5526\n",
            "Epoch 145/150 - 0.06s - loss: 0.8240 - acc: 0.6253 - val_loss: 0.9538 - val_acc: 0.5607\n",
            "Epoch 146/150 - 0.05s - loss: 0.8045 - acc: 0.6426 - val_loss: 0.9349 - val_acc: 0.5749\n",
            "Epoch 147/150 - 0.05s - loss: 0.8010 - acc: 0.6413 - val_loss: 0.9350 - val_acc: 0.5709\n",
            "Epoch 148/150 - 0.06s - loss: 0.8134 - acc: 0.6377 - val_loss: 0.9397 - val_acc: 0.5911\n",
            "Epoch 149/150 - 0.06s - loss: 0.7945 - acc: 0.6500 - val_loss: 0.9293 - val_acc: 0.5729\n",
            "Epoch 150/150 - 0.05s - loss: 0.7982 - acc: 0.6478 - val_loss: 0.9306 - val_acc: 0.5850\n",
            "Model saved to models/best_model.npy\n",
            "New best model found! Validation accuracy: 0.5850\n",
            "\n",
            "Combination 43/252:\n",
            "Hidden Layers: [128, 64], Activation: relu, Learning Rate: 0.001, Batch Size: 32, Epochs: 50\n",
            "Epoch 1/50 - 0.07s - loss: 1.1077 - acc: 0.3275 - val_loss: 1.0941 - val_acc: 0.3907\n",
            "Epoch 2/50 - 0.07s - loss: 1.1006 - acc: 0.3401 - val_loss: 1.0892 - val_acc: 0.3846\n",
            "Epoch 3/50 - 0.07s - loss: 1.0974 - acc: 0.3423 - val_loss: 1.0872 - val_acc: 0.4008\n",
            "Epoch 4/50 - 0.07s - loss: 1.0951 - acc: 0.3585 - val_loss: 1.0856 - val_acc: 0.4069\n",
            "Epoch 5/50 - 0.07s - loss: 1.0931 - acc: 0.3684 - val_loss: 1.0841 - val_acc: 0.4312\n",
            "Epoch 6/50 - 0.08s - loss: 1.0912 - acc: 0.3779 - val_loss: 1.0827 - val_acc: 0.4251\n",
            "Epoch 7/50 - 0.07s - loss: 1.0895 - acc: 0.3828 - val_loss: 1.0812 - val_acc: 0.4312\n",
            "Epoch 8/50 - 0.07s - loss: 1.0878 - acc: 0.3884 - val_loss: 1.0799 - val_acc: 0.4271\n",
            "Epoch 9/50 - 0.07s - loss: 1.0862 - acc: 0.3963 - val_loss: 1.0785 - val_acc: 0.4393\n",
            "Epoch 10/50 - 0.06s - loss: 1.0847 - acc: 0.4044 - val_loss: 1.0772 - val_acc: 0.4474\n",
            "Epoch 11/50 - 0.07s - loss: 1.0833 - acc: 0.4087 - val_loss: 1.0760 - val_acc: 0.4534\n",
            "Epoch 12/50 - 0.06s - loss: 1.0819 - acc: 0.4080 - val_loss: 1.0750 - val_acc: 0.4453\n",
            "Epoch 13/50 - 0.07s - loss: 1.0806 - acc: 0.4154 - val_loss: 1.0740 - val_acc: 0.4494\n",
            "Epoch 14/50 - 0.06s - loss: 1.0794 - acc: 0.4186 - val_loss: 1.0730 - val_acc: 0.4575\n",
            "Epoch 15/50 - 0.07s - loss: 1.0782 - acc: 0.4215 - val_loss: 1.0721 - val_acc: 0.4575\n",
            "Epoch 16/50 - 0.06s - loss: 1.0770 - acc: 0.4238 - val_loss: 1.0711 - val_acc: 0.4595\n",
            "Epoch 17/50 - 0.07s - loss: 1.0759 - acc: 0.4271 - val_loss: 1.0703 - val_acc: 0.4595\n",
            "Epoch 18/50 - 0.06s - loss: 1.0748 - acc: 0.4294 - val_loss: 1.0694 - val_acc: 0.4555\n",
            "Epoch 19/50 - 0.06s - loss: 1.0737 - acc: 0.4291 - val_loss: 1.0687 - val_acc: 0.4555\n",
            "Epoch 20/50 - 0.07s - loss: 1.0726 - acc: 0.4307 - val_loss: 1.0678 - val_acc: 0.4555\n",
            "Epoch 21/50 - 0.07s - loss: 1.0715 - acc: 0.4316 - val_loss: 1.0670 - val_acc: 0.4514\n",
            "Epoch 22/50 - 0.07s - loss: 1.0705 - acc: 0.4341 - val_loss: 1.0662 - val_acc: 0.4575\n",
            "Epoch 23/50 - 0.07s - loss: 1.0695 - acc: 0.4361 - val_loss: 1.0655 - val_acc: 0.4575\n",
            "Epoch 24/50 - 0.07s - loss: 1.0684 - acc: 0.4372 - val_loss: 1.0648 - val_acc: 0.4534\n",
            "Epoch 25/50 - 0.07s - loss: 1.0674 - acc: 0.4386 - val_loss: 1.0640 - val_acc: 0.4575\n",
            "Epoch 26/50 - 0.07s - loss: 1.0665 - acc: 0.4406 - val_loss: 1.0632 - val_acc: 0.4595\n",
            "Epoch 27/50 - 0.06s - loss: 1.0655 - acc: 0.4444 - val_loss: 1.0625 - val_acc: 0.4555\n",
            "Epoch 28/50 - 0.07s - loss: 1.0646 - acc: 0.4404 - val_loss: 1.0618 - val_acc: 0.4575\n",
            "Epoch 29/50 - 0.07s - loss: 1.0636 - acc: 0.4449 - val_loss: 1.0612 - val_acc: 0.4575\n",
            "Epoch 30/50 - 0.07s - loss: 1.0627 - acc: 0.4489 - val_loss: 1.0606 - val_acc: 0.4615\n",
            "Epoch 31/50 - 0.06s - loss: 1.0618 - acc: 0.4489 - val_loss: 1.0599 - val_acc: 0.4636\n",
            "Epoch 32/50 - 0.07s - loss: 1.0609 - acc: 0.4532 - val_loss: 1.0594 - val_acc: 0.4615\n",
            "Epoch 33/50 - 0.07s - loss: 1.0600 - acc: 0.4546 - val_loss: 1.0589 - val_acc: 0.4555\n",
            "Epoch 34/50 - 0.06s - loss: 1.0591 - acc: 0.4514 - val_loss: 1.0580 - val_acc: 0.4595\n",
            "Epoch 35/50 - 0.06s - loss: 1.0583 - acc: 0.4521 - val_loss: 1.0574 - val_acc: 0.4534\n",
            "Epoch 36/50 - 0.07s - loss: 1.0574 - acc: 0.4523 - val_loss: 1.0568 - val_acc: 0.4615\n",
            "Epoch 37/50 - 0.06s - loss: 1.0566 - acc: 0.4557 - val_loss: 1.0563 - val_acc: 0.4595\n",
            "Epoch 38/50 - 0.06s - loss: 1.0558 - acc: 0.4557 - val_loss: 1.0559 - val_acc: 0.4595\n",
            "Epoch 39/50 - 0.06s - loss: 1.0549 - acc: 0.4530 - val_loss: 1.0552 - val_acc: 0.4555\n",
            "Epoch 40/50 - 0.07s - loss: 1.0541 - acc: 0.4566 - val_loss: 1.0547 - val_acc: 0.4534\n",
            "Epoch 41/50 - 0.06s - loss: 1.0533 - acc: 0.4579 - val_loss: 1.0542 - val_acc: 0.4514\n",
            "Epoch 42/50 - 0.07s - loss: 1.0525 - acc: 0.4593 - val_loss: 1.0537 - val_acc: 0.4514\n",
            "Epoch 43/50 - 0.07s - loss: 1.0517 - acc: 0.4593 - val_loss: 1.0532 - val_acc: 0.4494\n",
            "Epoch 44/50 - 0.07s - loss: 1.0509 - acc: 0.4593 - val_loss: 1.0528 - val_acc: 0.4534\n",
            "Epoch 45/50 - 0.07s - loss: 1.0501 - acc: 0.4615 - val_loss: 1.0524 - val_acc: 0.4595\n",
            "Epoch 46/50 - 0.07s - loss: 1.0494 - acc: 0.4624 - val_loss: 1.0518 - val_acc: 0.4534\n",
            "Epoch 47/50 - 0.07s - loss: 1.0486 - acc: 0.4606 - val_loss: 1.0512 - val_acc: 0.4453\n",
            "Epoch 48/50 - 0.07s - loss: 1.0478 - acc: 0.4606 - val_loss: 1.0506 - val_acc: 0.4453\n",
            "Epoch 49/50 - 0.07s - loss: 1.0471 - acc: 0.4618 - val_loss: 1.0503 - val_acc: 0.4453\n",
            "Epoch 50/50 - 0.07s - loss: 1.0463 - acc: 0.4624 - val_loss: 1.0497 - val_acc: 0.4494\n",
            "\n",
            "Combination 44/252:\n",
            "Hidden Layers: [128, 64], Activation: relu, Learning Rate: 0.001, Batch Size: 32, Epochs: 100\n",
            "Epoch 1/100 - 0.07s - loss: 1.0955 - acc: 0.3819 - val_loss: 1.0970 - val_acc: 0.3806\n",
            "Epoch 2/100 - 0.07s - loss: 1.0929 - acc: 0.3819 - val_loss: 1.0949 - val_acc: 0.3765\n",
            "Epoch 3/100 - 0.06s - loss: 1.0907 - acc: 0.3869 - val_loss: 1.0932 - val_acc: 0.3745\n",
            "Epoch 4/100 - 0.06s - loss: 1.0889 - acc: 0.3932 - val_loss: 1.0919 - val_acc: 0.3684\n",
            "Epoch 5/100 - 0.07s - loss: 1.0873 - acc: 0.3986 - val_loss: 1.0909 - val_acc: 0.3704\n",
            "Epoch 6/100 - 0.08s - loss: 1.0858 - acc: 0.4046 - val_loss: 1.0900 - val_acc: 0.3765\n",
            "Epoch 7/100 - 0.07s - loss: 1.0845 - acc: 0.4060 - val_loss: 1.0891 - val_acc: 0.3826\n",
            "Epoch 8/100 - 0.07s - loss: 1.0832 - acc: 0.4121 - val_loss: 1.0883 - val_acc: 0.3806\n",
            "Epoch 9/100 - 0.07s - loss: 1.0819 - acc: 0.4125 - val_loss: 1.0875 - val_acc: 0.3826\n",
            "Epoch 10/100 - 0.06s - loss: 1.0807 - acc: 0.4148 - val_loss: 1.0867 - val_acc: 0.3826\n",
            "Epoch 11/100 - 0.06s - loss: 1.0795 - acc: 0.4172 - val_loss: 1.0860 - val_acc: 0.3866\n",
            "Epoch 12/100 - 0.07s - loss: 1.0784 - acc: 0.4175 - val_loss: 1.0853 - val_acc: 0.3887\n",
            "Epoch 13/100 - 0.07s - loss: 1.0774 - acc: 0.4240 - val_loss: 1.0847 - val_acc: 0.3988\n",
            "Epoch 14/100 - 0.06s - loss: 1.0764 - acc: 0.4278 - val_loss: 1.0841 - val_acc: 0.4049\n",
            "Epoch 15/100 - 0.06s - loss: 1.0754 - acc: 0.4305 - val_loss: 1.0835 - val_acc: 0.4049\n",
            "Epoch 16/100 - 0.06s - loss: 1.0745 - acc: 0.4323 - val_loss: 1.0828 - val_acc: 0.4150\n",
            "Epoch 17/100 - 0.06s - loss: 1.0737 - acc: 0.4352 - val_loss: 1.0823 - val_acc: 0.4190\n",
            "Epoch 18/100 - 0.07s - loss: 1.0728 - acc: 0.4370 - val_loss: 1.0817 - val_acc: 0.4271\n",
            "Epoch 19/100 - 0.06s - loss: 1.0720 - acc: 0.4388 - val_loss: 1.0812 - val_acc: 0.4312\n",
            "Epoch 20/100 - 0.07s - loss: 1.0711 - acc: 0.4415 - val_loss: 1.0807 - val_acc: 0.4352\n",
            "Epoch 21/100 - 0.08s - loss: 1.0704 - acc: 0.4402 - val_loss: 1.0801 - val_acc: 0.4372\n",
            "Epoch 22/100 - 0.09s - loss: 1.0696 - acc: 0.4431 - val_loss: 1.0797 - val_acc: 0.4312\n",
            "Epoch 23/100 - 0.11s - loss: 1.0689 - acc: 0.4444 - val_loss: 1.0791 - val_acc: 0.4352\n",
            "Epoch 24/100 - 0.08s - loss: 1.0681 - acc: 0.4492 - val_loss: 1.0786 - val_acc: 0.4413\n",
            "Epoch 25/100 - 0.08s - loss: 1.0674 - acc: 0.4503 - val_loss: 1.0780 - val_acc: 0.4291\n",
            "Epoch 26/100 - 0.07s - loss: 1.0667 - acc: 0.4525 - val_loss: 1.0776 - val_acc: 0.4312\n",
            "Epoch 27/100 - 0.08s - loss: 1.0660 - acc: 0.4552 - val_loss: 1.0771 - val_acc: 0.4271\n",
            "Epoch 28/100 - 0.07s - loss: 1.0653 - acc: 0.4579 - val_loss: 1.0766 - val_acc: 0.4312\n",
            "Epoch 29/100 - 0.07s - loss: 1.0646 - acc: 0.4579 - val_loss: 1.0762 - val_acc: 0.4231\n",
            "Epoch 30/100 - 0.07s - loss: 1.0639 - acc: 0.4584 - val_loss: 1.0758 - val_acc: 0.4271\n",
            "Epoch 31/100 - 0.11s - loss: 1.0632 - acc: 0.4600 - val_loss: 1.0753 - val_acc: 0.4251\n",
            "Epoch 32/100 - 0.11s - loss: 1.0625 - acc: 0.4629 - val_loss: 1.0748 - val_acc: 0.4251\n",
            "Epoch 33/100 - 0.10s - loss: 1.0618 - acc: 0.4645 - val_loss: 1.0744 - val_acc: 0.4271\n",
            "Epoch 34/100 - 0.11s - loss: 1.0611 - acc: 0.4656 - val_loss: 1.0739 - val_acc: 0.4291\n",
            "Epoch 35/100 - 0.11s - loss: 1.0605 - acc: 0.4685 - val_loss: 1.0734 - val_acc: 0.4291\n",
            "Epoch 36/100 - 0.10s - loss: 1.0598 - acc: 0.4687 - val_loss: 1.0730 - val_acc: 0.4312\n",
            "Epoch 37/100 - 0.10s - loss: 1.0592 - acc: 0.4699 - val_loss: 1.0726 - val_acc: 0.4352\n",
            "Epoch 38/100 - 0.09s - loss: 1.0586 - acc: 0.4710 - val_loss: 1.0720 - val_acc: 0.4332\n",
            "Epoch 39/100 - 0.11s - loss: 1.0579 - acc: 0.4712 - val_loss: 1.0716 - val_acc: 0.4352\n",
            "Epoch 40/100 - 0.10s - loss: 1.0573 - acc: 0.4717 - val_loss: 1.0712 - val_acc: 0.4312\n",
            "Epoch 41/100 - 0.11s - loss: 1.0566 - acc: 0.4712 - val_loss: 1.0708 - val_acc: 0.4352\n",
            "Epoch 42/100 - 0.12s - loss: 1.0560 - acc: 0.4726 - val_loss: 1.0704 - val_acc: 0.4352\n",
            "Epoch 43/100 - 0.12s - loss: 1.0553 - acc: 0.4732 - val_loss: 1.0699 - val_acc: 0.4332\n",
            "Epoch 44/100 - 0.11s - loss: 1.0547 - acc: 0.4748 - val_loss: 1.0695 - val_acc: 0.4393\n",
            "Epoch 45/100 - 0.11s - loss: 1.0541 - acc: 0.4739 - val_loss: 1.0689 - val_acc: 0.4372\n",
            "Epoch 46/100 - 0.11s - loss: 1.0534 - acc: 0.4730 - val_loss: 1.0685 - val_acc: 0.4271\n",
            "Epoch 47/100 - 0.10s - loss: 1.0528 - acc: 0.4744 - val_loss: 1.0681 - val_acc: 0.4312\n",
            "Epoch 48/100 - 0.10s - loss: 1.0522 - acc: 0.4750 - val_loss: 1.0676 - val_acc: 0.4372\n",
            "Epoch 49/100 - 0.09s - loss: 1.0516 - acc: 0.4748 - val_loss: 1.0671 - val_acc: 0.4352\n",
            "Epoch 50/100 - 0.10s - loss: 1.0509 - acc: 0.4748 - val_loss: 1.0666 - val_acc: 0.4372\n",
            "Epoch 51/100 - 0.11s - loss: 1.0503 - acc: 0.4753 - val_loss: 1.0664 - val_acc: 0.4312\n",
            "Epoch 52/100 - 0.12s - loss: 1.0497 - acc: 0.4773 - val_loss: 1.0659 - val_acc: 0.4352\n",
            "Epoch 53/100 - 0.14s - loss: 1.0490 - acc: 0.4771 - val_loss: 1.0655 - val_acc: 0.4352\n",
            "Epoch 54/100 - 0.17s - loss: 1.0484 - acc: 0.4764 - val_loss: 1.0650 - val_acc: 0.4352\n",
            "Epoch 55/100 - 0.22s - loss: 1.0477 - acc: 0.4750 - val_loss: 1.0647 - val_acc: 0.4352\n",
            "Epoch 56/100 - 0.13s - loss: 1.0471 - acc: 0.4775 - val_loss: 1.0641 - val_acc: 0.4372\n",
            "Epoch 57/100 - 0.10s - loss: 1.0465 - acc: 0.4773 - val_loss: 1.0636 - val_acc: 0.4413\n",
            "Epoch 58/100 - 0.12s - loss: 1.0458 - acc: 0.4780 - val_loss: 1.0632 - val_acc: 0.4433\n",
            "Epoch 59/100 - 0.11s - loss: 1.0452 - acc: 0.4795 - val_loss: 1.0627 - val_acc: 0.4453\n",
            "Epoch 60/100 - 0.08s - loss: 1.0445 - acc: 0.4802 - val_loss: 1.0623 - val_acc: 0.4555\n",
            "Epoch 61/100 - 0.07s - loss: 1.0439 - acc: 0.4809 - val_loss: 1.0617 - val_acc: 0.4595\n",
            "Epoch 62/100 - 0.06s - loss: 1.0432 - acc: 0.4807 - val_loss: 1.0614 - val_acc: 0.4575\n",
            "Epoch 63/100 - 0.06s - loss: 1.0426 - acc: 0.4816 - val_loss: 1.0609 - val_acc: 0.4595\n",
            "Epoch 64/100 - 0.06s - loss: 1.0419 - acc: 0.4804 - val_loss: 1.0604 - val_acc: 0.4615\n",
            "Epoch 65/100 - 0.06s - loss: 1.0413 - acc: 0.4795 - val_loss: 1.0599 - val_acc: 0.4636\n",
            "Epoch 66/100 - 0.06s - loss: 1.0406 - acc: 0.4825 - val_loss: 1.0596 - val_acc: 0.4575\n",
            "Epoch 67/100 - 0.06s - loss: 1.0400 - acc: 0.4825 - val_loss: 1.0593 - val_acc: 0.4555\n",
            "Epoch 68/100 - 0.06s - loss: 1.0393 - acc: 0.4822 - val_loss: 1.0586 - val_acc: 0.4595\n",
            "Epoch 69/100 - 0.06s - loss: 1.0386 - acc: 0.4836 - val_loss: 1.0582 - val_acc: 0.4575\n",
            "Epoch 70/100 - 0.06s - loss: 1.0380 - acc: 0.4834 - val_loss: 1.0573 - val_acc: 0.4615\n",
            "Epoch 71/100 - 0.07s - loss: 1.0373 - acc: 0.4849 - val_loss: 1.0570 - val_acc: 0.4656\n",
            "Epoch 72/100 - 0.06s - loss: 1.0366 - acc: 0.4843 - val_loss: 1.0566 - val_acc: 0.4676\n",
            "Epoch 73/100 - 0.06s - loss: 1.0359 - acc: 0.4863 - val_loss: 1.0561 - val_acc: 0.4696\n",
            "Epoch 74/100 - 0.06s - loss: 1.0353 - acc: 0.4861 - val_loss: 1.0556 - val_acc: 0.4717\n",
            "Epoch 75/100 - 0.07s - loss: 1.0346 - acc: 0.4854 - val_loss: 1.0548 - val_acc: 0.4636\n",
            "Epoch 76/100 - 0.06s - loss: 1.0339 - acc: 0.4863 - val_loss: 1.0544 - val_acc: 0.4615\n",
            "Epoch 77/100 - 0.06s - loss: 1.0332 - acc: 0.4867 - val_loss: 1.0539 - val_acc: 0.4676\n",
            "Epoch 78/100 - 0.06s - loss: 1.0325 - acc: 0.4874 - val_loss: 1.0533 - val_acc: 0.4615\n",
            "Epoch 79/100 - 0.06s - loss: 1.0318 - acc: 0.4879 - val_loss: 1.0528 - val_acc: 0.4636\n",
            "Epoch 80/100 - 0.06s - loss: 1.0311 - acc: 0.4890 - val_loss: 1.0523 - val_acc: 0.4615\n",
            "Epoch 81/100 - 0.06s - loss: 1.0304 - acc: 0.4917 - val_loss: 1.0521 - val_acc: 0.4636\n",
            "Epoch 82/100 - 0.06s - loss: 1.0297 - acc: 0.4888 - val_loss: 1.0512 - val_acc: 0.4595\n",
            "Epoch 83/100 - 0.07s - loss: 1.0290 - acc: 0.4930 - val_loss: 1.0509 - val_acc: 0.4636\n",
            "Epoch 84/100 - 0.06s - loss: 1.0283 - acc: 0.4930 - val_loss: 1.0503 - val_acc: 0.4636\n",
            "Epoch 85/100 - 0.06s - loss: 1.0276 - acc: 0.4935 - val_loss: 1.0499 - val_acc: 0.4636\n",
            "Epoch 86/100 - 0.06s - loss: 1.0269 - acc: 0.4946 - val_loss: 1.0495 - val_acc: 0.4636\n",
            "Epoch 87/100 - 0.06s - loss: 1.0261 - acc: 0.4960 - val_loss: 1.0488 - val_acc: 0.4656\n",
            "Epoch 88/100 - 0.06s - loss: 1.0254 - acc: 0.4962 - val_loss: 1.0483 - val_acc: 0.4676\n",
            "Epoch 89/100 - 0.06s - loss: 1.0247 - acc: 0.4964 - val_loss: 1.0480 - val_acc: 0.4656\n",
            "Epoch 90/100 - 0.06s - loss: 1.0240 - acc: 0.4980 - val_loss: 1.0472 - val_acc: 0.4696\n",
            "Epoch 91/100 - 0.07s - loss: 1.0233 - acc: 0.4993 - val_loss: 1.0469 - val_acc: 0.4696\n",
            "Epoch 92/100 - 0.06s - loss: 1.0226 - acc: 0.4975 - val_loss: 1.0460 - val_acc: 0.4757\n",
            "Epoch 93/100 - 0.06s - loss: 1.0218 - acc: 0.5007 - val_loss: 1.0459 - val_acc: 0.4696\n",
            "Epoch 94/100 - 0.06s - loss: 1.0211 - acc: 0.4991 - val_loss: 1.0453 - val_acc: 0.4737\n",
            "Epoch 95/100 - 0.07s - loss: 1.0204 - acc: 0.5011 - val_loss: 1.0448 - val_acc: 0.4717\n",
            "Epoch 96/100 - 0.07s - loss: 1.0197 - acc: 0.5016 - val_loss: 1.0444 - val_acc: 0.4757\n",
            "Epoch 97/100 - 0.06s - loss: 1.0190 - acc: 0.5018 - val_loss: 1.0439 - val_acc: 0.4818\n",
            "Epoch 98/100 - 0.06s - loss: 1.0184 - acc: 0.5013 - val_loss: 1.0429 - val_acc: 0.4757\n",
            "Epoch 99/100 - 0.06s - loss: 1.0176 - acc: 0.5045 - val_loss: 1.0427 - val_acc: 0.4798\n",
            "Epoch 100/100 - 0.06s - loss: 1.0169 - acc: 0.5036 - val_loss: 1.0422 - val_acc: 0.4818\n",
            "\n",
            "Combination 45/252:\n",
            "Hidden Layers: [128, 64], Activation: relu, Learning Rate: 0.001, Batch Size: 32, Epochs: 150\n",
            "Epoch 1/150 - 0.07s - loss: 1.0993 - acc: 0.3511 - val_loss: 1.1010 - val_acc: 0.3421\n",
            "Epoch 2/150 - 0.07s - loss: 1.0969 - acc: 0.3561 - val_loss: 1.0983 - val_acc: 0.3462\n",
            "Epoch 3/150 - 0.07s - loss: 1.0952 - acc: 0.3572 - val_loss: 1.0965 - val_acc: 0.3543\n",
            "Epoch 4/150 - 0.06s - loss: 1.0938 - acc: 0.3702 - val_loss: 1.0952 - val_acc: 0.3563\n",
            "Epoch 5/150 - 0.06s - loss: 1.0925 - acc: 0.3747 - val_loss: 1.0940 - val_acc: 0.3704\n",
            "Epoch 6/150 - 0.06s - loss: 1.0913 - acc: 0.3776 - val_loss: 1.0930 - val_acc: 0.3684\n",
            "Epoch 7/150 - 0.06s - loss: 1.0903 - acc: 0.3882 - val_loss: 1.0921 - val_acc: 0.3745\n",
            "Epoch 8/150 - 0.06s - loss: 1.0892 - acc: 0.3936 - val_loss: 1.0912 - val_acc: 0.3806\n",
            "Epoch 9/150 - 0.06s - loss: 1.0882 - acc: 0.3986 - val_loss: 1.0903 - val_acc: 0.3826\n",
            "Epoch 10/150 - 0.06s - loss: 1.0872 - acc: 0.4019 - val_loss: 1.0894 - val_acc: 0.3826\n",
            "Epoch 11/150 - 0.07s - loss: 1.0862 - acc: 0.4071 - val_loss: 1.0885 - val_acc: 0.3947\n",
            "Epoch 12/150 - 0.06s - loss: 1.0853 - acc: 0.4103 - val_loss: 1.0878 - val_acc: 0.4008\n",
            "Epoch 13/150 - 0.06s - loss: 1.0843 - acc: 0.4132 - val_loss: 1.0869 - val_acc: 0.4069\n",
            "Epoch 14/150 - 0.06s - loss: 1.0834 - acc: 0.4139 - val_loss: 1.0861 - val_acc: 0.4069\n",
            "Epoch 15/150 - 0.06s - loss: 1.0825 - acc: 0.4152 - val_loss: 1.0853 - val_acc: 0.4008\n",
            "Epoch 16/150 - 0.07s - loss: 1.0815 - acc: 0.4215 - val_loss: 1.0846 - val_acc: 0.4008\n",
            "Epoch 17/150 - 0.07s - loss: 1.0807 - acc: 0.4244 - val_loss: 1.0838 - val_acc: 0.3968\n",
            "Epoch 18/150 - 0.07s - loss: 1.0798 - acc: 0.4265 - val_loss: 1.0831 - val_acc: 0.3988\n",
            "Epoch 19/150 - 0.07s - loss: 1.0789 - acc: 0.4296 - val_loss: 1.0824 - val_acc: 0.4008\n",
            "Epoch 20/150 - 0.06s - loss: 1.0781 - acc: 0.4289 - val_loss: 1.0818 - val_acc: 0.4008\n",
            "Epoch 21/150 - 0.06s - loss: 1.0773 - acc: 0.4336 - val_loss: 1.0812 - val_acc: 0.4069\n",
            "Epoch 22/150 - 0.06s - loss: 1.0764 - acc: 0.4350 - val_loss: 1.0805 - val_acc: 0.4008\n",
            "Epoch 23/150 - 0.06s - loss: 1.0756 - acc: 0.4350 - val_loss: 1.0798 - val_acc: 0.4069\n",
            "Epoch 24/150 - 0.06s - loss: 1.0748 - acc: 0.4384 - val_loss: 1.0792 - val_acc: 0.4150\n",
            "Epoch 25/150 - 0.06s - loss: 1.0740 - acc: 0.4402 - val_loss: 1.0786 - val_acc: 0.4170\n",
            "Epoch 26/150 - 0.06s - loss: 1.0732 - acc: 0.4397 - val_loss: 1.0780 - val_acc: 0.4231\n",
            "Epoch 27/150 - 0.07s - loss: 1.0724 - acc: 0.4390 - val_loss: 1.0773 - val_acc: 0.4211\n",
            "Epoch 28/150 - 0.06s - loss: 1.0716 - acc: 0.4397 - val_loss: 1.0767 - val_acc: 0.4251\n",
            "Epoch 29/150 - 0.06s - loss: 1.0709 - acc: 0.4402 - val_loss: 1.0760 - val_acc: 0.4231\n",
            "Epoch 30/150 - 0.06s - loss: 1.0701 - acc: 0.4393 - val_loss: 1.0754 - val_acc: 0.4211\n",
            "Epoch 31/150 - 0.06s - loss: 1.0694 - acc: 0.4384 - val_loss: 1.0748 - val_acc: 0.4211\n",
            "Epoch 32/150 - 0.06s - loss: 1.0686 - acc: 0.4399 - val_loss: 1.0742 - val_acc: 0.4190\n",
            "Epoch 33/150 - 0.06s - loss: 1.0679 - acc: 0.4399 - val_loss: 1.0735 - val_acc: 0.4170\n",
            "Epoch 34/150 - 0.06s - loss: 1.0671 - acc: 0.4411 - val_loss: 1.0729 - val_acc: 0.4190\n",
            "Epoch 35/150 - 0.07s - loss: 1.0664 - acc: 0.4408 - val_loss: 1.0723 - val_acc: 0.4231\n",
            "Epoch 36/150 - 0.06s - loss: 1.0656 - acc: 0.4411 - val_loss: 1.0717 - val_acc: 0.4231\n",
            "Epoch 37/150 - 0.06s - loss: 1.0649 - acc: 0.4447 - val_loss: 1.0711 - val_acc: 0.4251\n",
            "Epoch 38/150 - 0.06s - loss: 1.0641 - acc: 0.4453 - val_loss: 1.0705 - val_acc: 0.4271\n",
            "Epoch 39/150 - 0.06s - loss: 1.0634 - acc: 0.4467 - val_loss: 1.0699 - val_acc: 0.4291\n",
            "Epoch 40/150 - 0.07s - loss: 1.0627 - acc: 0.4453 - val_loss: 1.0695 - val_acc: 0.4251\n",
            "Epoch 41/150 - 0.06s - loss: 1.0620 - acc: 0.4496 - val_loss: 1.0688 - val_acc: 0.4271\n",
            "Epoch 42/150 - 0.06s - loss: 1.0612 - acc: 0.4498 - val_loss: 1.0683 - val_acc: 0.4271\n",
            "Epoch 43/150 - 0.07s - loss: 1.0605 - acc: 0.4528 - val_loss: 1.0677 - val_acc: 0.4271\n",
            "Epoch 44/150 - 0.06s - loss: 1.0598 - acc: 0.4534 - val_loss: 1.0671 - val_acc: 0.4271\n",
            "Epoch 45/150 - 0.06s - loss: 1.0591 - acc: 0.4548 - val_loss: 1.0666 - val_acc: 0.4271\n",
            "Epoch 46/150 - 0.06s - loss: 1.0584 - acc: 0.4570 - val_loss: 1.0662 - val_acc: 0.4271\n",
            "Epoch 47/150 - 0.06s - loss: 1.0577 - acc: 0.4579 - val_loss: 1.0656 - val_acc: 0.4291\n",
            "Epoch 48/150 - 0.06s - loss: 1.0570 - acc: 0.4586 - val_loss: 1.0653 - val_acc: 0.4291\n",
            "Epoch 49/150 - 0.06s - loss: 1.0562 - acc: 0.4595 - val_loss: 1.0646 - val_acc: 0.4332\n",
            "Epoch 50/150 - 0.06s - loss: 1.0555 - acc: 0.4613 - val_loss: 1.0642 - val_acc: 0.4271\n",
            "Epoch 51/150 - 0.06s - loss: 1.0548 - acc: 0.4615 - val_loss: 1.0637 - val_acc: 0.4352\n",
            "Epoch 52/150 - 0.06s - loss: 1.0542 - acc: 0.4613 - val_loss: 1.0631 - val_acc: 0.4332\n",
            "Epoch 53/150 - 0.06s - loss: 1.0535 - acc: 0.4620 - val_loss: 1.0626 - val_acc: 0.4332\n",
            "Epoch 54/150 - 0.06s - loss: 1.0528 - acc: 0.4638 - val_loss: 1.0623 - val_acc: 0.4352\n",
            "Epoch 55/150 - 0.06s - loss: 1.0522 - acc: 0.4649 - val_loss: 1.0618 - val_acc: 0.4312\n",
            "Epoch 56/150 - 0.06s - loss: 1.0515 - acc: 0.4660 - val_loss: 1.0613 - val_acc: 0.4332\n",
            "Epoch 57/150 - 0.06s - loss: 1.0509 - acc: 0.4647 - val_loss: 1.0609 - val_acc: 0.4271\n",
            "Epoch 58/150 - 0.06s - loss: 1.0502 - acc: 0.4647 - val_loss: 1.0604 - val_acc: 0.4372\n",
            "Epoch 59/150 - 0.06s - loss: 1.0496 - acc: 0.4651 - val_loss: 1.0600 - val_acc: 0.4312\n",
            "Epoch 60/150 - 0.06s - loss: 1.0490 - acc: 0.4669 - val_loss: 1.0595 - val_acc: 0.4413\n",
            "Epoch 61/150 - 0.06s - loss: 1.0484 - acc: 0.4676 - val_loss: 1.0591 - val_acc: 0.4332\n",
            "Epoch 62/150 - 0.06s - loss: 1.0478 - acc: 0.4678 - val_loss: 1.0587 - val_acc: 0.4372\n",
            "Epoch 63/150 - 0.07s - loss: 1.0471 - acc: 0.4690 - val_loss: 1.0583 - val_acc: 0.4372\n",
            "Epoch 64/150 - 0.06s - loss: 1.0466 - acc: 0.4705 - val_loss: 1.0580 - val_acc: 0.4352\n",
            "Epoch 65/150 - 0.06s - loss: 1.0460 - acc: 0.4712 - val_loss: 1.0576 - val_acc: 0.4352\n",
            "Epoch 66/150 - 0.06s - loss: 1.0454 - acc: 0.4710 - val_loss: 1.0572 - val_acc: 0.4372\n",
            "Epoch 67/150 - 0.07s - loss: 1.0448 - acc: 0.4708 - val_loss: 1.0568 - val_acc: 0.4372\n",
            "Epoch 68/150 - 0.06s - loss: 1.0442 - acc: 0.4723 - val_loss: 1.0564 - val_acc: 0.4372\n",
            "Epoch 69/150 - 0.06s - loss: 1.0436 - acc: 0.4726 - val_loss: 1.0561 - val_acc: 0.4413\n",
            "Epoch 70/150 - 0.06s - loss: 1.0431 - acc: 0.4739 - val_loss: 1.0558 - val_acc: 0.4453\n",
            "Epoch 71/150 - 0.07s - loss: 1.0425 - acc: 0.4753 - val_loss: 1.0554 - val_acc: 0.4474\n",
            "Epoch 72/150 - 0.06s - loss: 1.0419 - acc: 0.4757 - val_loss: 1.0550 - val_acc: 0.4494\n",
            "Epoch 73/150 - 0.06s - loss: 1.0414 - acc: 0.4732 - val_loss: 1.0545 - val_acc: 0.4453\n",
            "Epoch 74/150 - 0.06s - loss: 1.0408 - acc: 0.4762 - val_loss: 1.0544 - val_acc: 0.4494\n",
            "Epoch 75/150 - 0.07s - loss: 1.0403 - acc: 0.4755 - val_loss: 1.0540 - val_acc: 0.4514\n",
            "Epoch 76/150 - 0.06s - loss: 1.0397 - acc: 0.4771 - val_loss: 1.0536 - val_acc: 0.4514\n",
            "Epoch 77/150 - 0.06s - loss: 1.0391 - acc: 0.4755 - val_loss: 1.0531 - val_acc: 0.4514\n",
            "Epoch 78/150 - 0.06s - loss: 1.0386 - acc: 0.4768 - val_loss: 1.0530 - val_acc: 0.4534\n",
            "Epoch 79/150 - 0.06s - loss: 1.0380 - acc: 0.4786 - val_loss: 1.0526 - val_acc: 0.4514\n",
            "Epoch 80/150 - 0.06s - loss: 1.0375 - acc: 0.4791 - val_loss: 1.0522 - val_acc: 0.4514\n",
            "Epoch 81/150 - 0.07s - loss: 1.0369 - acc: 0.4764 - val_loss: 1.0517 - val_acc: 0.4555\n",
            "Epoch 82/150 - 0.08s - loss: 1.0364 - acc: 0.4804 - val_loss: 1.0515 - val_acc: 0.4555\n",
            "Epoch 83/150 - 0.07s - loss: 1.0358 - acc: 0.4782 - val_loss: 1.0509 - val_acc: 0.4555\n",
            "Epoch 84/150 - 0.06s - loss: 1.0353 - acc: 0.4807 - val_loss: 1.0506 - val_acc: 0.4575\n",
            "Epoch 85/150 - 0.06s - loss: 1.0347 - acc: 0.4822 - val_loss: 1.0504 - val_acc: 0.4555\n",
            "Epoch 86/150 - 0.06s - loss: 1.0342 - acc: 0.4827 - val_loss: 1.0501 - val_acc: 0.4555\n",
            "Epoch 87/150 - 0.07s - loss: 1.0336 - acc: 0.4845 - val_loss: 1.0496 - val_acc: 0.4555\n",
            "Epoch 88/150 - 0.06s - loss: 1.0331 - acc: 0.4831 - val_loss: 1.0495 - val_acc: 0.4575\n",
            "Epoch 89/150 - 0.06s - loss: 1.0325 - acc: 0.4831 - val_loss: 1.0490 - val_acc: 0.4555\n",
            "Epoch 90/150 - 0.06s - loss: 1.0320 - acc: 0.4849 - val_loss: 1.0487 - val_acc: 0.4555\n",
            "Epoch 91/150 - 0.07s - loss: 1.0315 - acc: 0.4854 - val_loss: 1.0481 - val_acc: 0.4494\n",
            "Epoch 92/150 - 0.06s - loss: 1.0309 - acc: 0.4849 - val_loss: 1.0479 - val_acc: 0.4514\n",
            "Epoch 93/150 - 0.06s - loss: 1.0304 - acc: 0.4885 - val_loss: 1.0476 - val_acc: 0.4555\n",
            "Epoch 94/150 - 0.06s - loss: 1.0300 - acc: 0.4881 - val_loss: 1.0479 - val_acc: 0.4676\n",
            "Epoch 95/150 - 0.06s - loss: 1.0294 - acc: 0.4876 - val_loss: 1.0474 - val_acc: 0.4656\n",
            "Epoch 96/150 - 0.06s - loss: 1.0288 - acc: 0.4890 - val_loss: 1.0467 - val_acc: 0.4615\n",
            "Epoch 97/150 - 0.06s - loss: 1.0282 - acc: 0.4874 - val_loss: 1.0463 - val_acc: 0.4534\n",
            "Epoch 98/150 - 0.06s - loss: 1.0277 - acc: 0.4890 - val_loss: 1.0458 - val_acc: 0.4534\n",
            "Epoch 99/150 - 0.06s - loss: 1.0271 - acc: 0.4901 - val_loss: 1.0457 - val_acc: 0.4575\n",
            "Epoch 100/150 - 0.06s - loss: 1.0266 - acc: 0.4892 - val_loss: 1.0454 - val_acc: 0.4595\n",
            "Epoch 101/150 - 0.06s - loss: 1.0260 - acc: 0.4919 - val_loss: 1.0450 - val_acc: 0.4595\n",
            "Epoch 102/150 - 0.06s - loss: 1.0255 - acc: 0.4876 - val_loss: 1.0448 - val_acc: 0.4534\n",
            "Epoch 103/150 - 0.07s - loss: 1.0250 - acc: 0.4924 - val_loss: 1.0444 - val_acc: 0.4575\n",
            "Epoch 104/150 - 0.06s - loss: 1.0245 - acc: 0.4888 - val_loss: 1.0439 - val_acc: 0.4595\n",
            "Epoch 105/150 - 0.06s - loss: 1.0239 - acc: 0.4937 - val_loss: 1.0437 - val_acc: 0.4595\n",
            "Epoch 106/150 - 0.06s - loss: 1.0234 - acc: 0.4915 - val_loss: 1.0433 - val_acc: 0.4595\n",
            "Epoch 107/150 - 0.06s - loss: 1.0228 - acc: 0.4953 - val_loss: 1.0431 - val_acc: 0.4656\n",
            "Epoch 108/150 - 0.06s - loss: 1.0223 - acc: 0.4942 - val_loss: 1.0426 - val_acc: 0.4636\n",
            "Epoch 109/150 - 0.06s - loss: 1.0217 - acc: 0.4944 - val_loss: 1.0423 - val_acc: 0.4656\n",
            "Epoch 110/150 - 0.07s - loss: 1.0212 - acc: 0.4948 - val_loss: 1.0421 - val_acc: 0.4676\n",
            "Epoch 111/150 - 0.07s - loss: 1.0206 - acc: 0.4942 - val_loss: 1.0416 - val_acc: 0.4696\n",
            "Epoch 112/150 - 0.07s - loss: 1.0201 - acc: 0.4975 - val_loss: 1.0417 - val_acc: 0.4656\n",
            "Epoch 113/150 - 0.07s - loss: 1.0195 - acc: 0.4957 - val_loss: 1.0410 - val_acc: 0.4737\n",
            "Epoch 114/150 - 0.07s - loss: 1.0190 - acc: 0.4969 - val_loss: 1.0407 - val_acc: 0.4737\n",
            "Epoch 115/150 - 0.07s - loss: 1.0184 - acc: 0.4964 - val_loss: 1.0403 - val_acc: 0.4737\n",
            "Epoch 116/150 - 0.07s - loss: 1.0179 - acc: 0.4964 - val_loss: 1.0399 - val_acc: 0.4737\n",
            "Epoch 117/150 - 0.07s - loss: 1.0174 - acc: 0.4996 - val_loss: 1.0399 - val_acc: 0.4676\n",
            "Epoch 118/150 - 0.07s - loss: 1.0168 - acc: 0.4973 - val_loss: 1.0393 - val_acc: 0.4737\n",
            "Epoch 119/150 - 0.06s - loss: 1.0162 - acc: 0.4987 - val_loss: 1.0389 - val_acc: 0.4737\n",
            "Epoch 120/150 - 0.06s - loss: 1.0157 - acc: 0.5000 - val_loss: 1.0387 - val_acc: 0.4757\n",
            "Epoch 121/150 - 0.07s - loss: 1.0151 - acc: 0.4998 - val_loss: 1.0382 - val_acc: 0.4737\n",
            "Epoch 122/150 - 0.07s - loss: 1.0146 - acc: 0.4971 - val_loss: 1.0376 - val_acc: 0.4818\n",
            "Epoch 123/150 - 0.06s - loss: 1.0141 - acc: 0.4980 - val_loss: 1.0373 - val_acc: 0.4757\n",
            "Epoch 124/150 - 0.06s - loss: 1.0135 - acc: 0.4993 - val_loss: 1.0370 - val_acc: 0.4858\n",
            "Epoch 125/150 - 0.06s - loss: 1.0129 - acc: 0.5020 - val_loss: 1.0368 - val_acc: 0.4899\n",
            "Epoch 126/150 - 0.07s - loss: 1.0124 - acc: 0.5011 - val_loss: 1.0363 - val_acc: 0.4818\n",
            "Epoch 127/150 - 0.06s - loss: 1.0118 - acc: 0.5013 - val_loss: 1.0358 - val_acc: 0.4818\n",
            "Epoch 128/150 - 0.06s - loss: 1.0113 - acc: 0.5025 - val_loss: 1.0355 - val_acc: 0.4960\n",
            "Epoch 129/150 - 0.06s - loss: 1.0107 - acc: 0.5043 - val_loss: 1.0353 - val_acc: 0.4919\n",
            "Epoch 130/150 - 0.07s - loss: 1.0101 - acc: 0.5016 - val_loss: 1.0348 - val_acc: 0.4838\n",
            "Epoch 131/150 - 0.06s - loss: 1.0096 - acc: 0.5031 - val_loss: 1.0346 - val_acc: 0.5000\n",
            "Epoch 132/150 - 0.06s - loss: 1.0091 - acc: 0.5025 - val_loss: 1.0344 - val_acc: 0.4960\n",
            "Epoch 133/150 - 0.06s - loss: 1.0084 - acc: 0.5047 - val_loss: 1.0338 - val_acc: 0.4980\n",
            "Epoch 134/150 - 0.06s - loss: 1.0079 - acc: 0.5036 - val_loss: 1.0334 - val_acc: 0.4919\n",
            "Epoch 135/150 - 0.06s - loss: 1.0073 - acc: 0.5045 - val_loss: 1.0330 - val_acc: 0.5020\n",
            "Epoch 136/150 - 0.06s - loss: 1.0067 - acc: 0.5038 - val_loss: 1.0327 - val_acc: 0.5020\n",
            "Epoch 137/150 - 0.06s - loss: 1.0062 - acc: 0.5034 - val_loss: 1.0323 - val_acc: 0.5020\n",
            "Epoch 138/150 - 0.06s - loss: 1.0056 - acc: 0.5049 - val_loss: 1.0319 - val_acc: 0.5000\n",
            "Epoch 139/150 - 0.07s - loss: 1.0051 - acc: 0.5036 - val_loss: 1.0316 - val_acc: 0.5020\n",
            "Epoch 140/150 - 0.06s - loss: 1.0045 - acc: 0.5061 - val_loss: 1.0311 - val_acc: 0.4980\n",
            "Epoch 141/150 - 0.06s - loss: 1.0039 - acc: 0.5063 - val_loss: 1.0306 - val_acc: 0.5020\n",
            "Epoch 142/150 - 0.07s - loss: 1.0034 - acc: 0.5054 - val_loss: 1.0303 - val_acc: 0.5020\n",
            "Epoch 143/150 - 0.06s - loss: 1.0028 - acc: 0.5070 - val_loss: 1.0301 - val_acc: 0.5020\n",
            "Epoch 144/150 - 0.06s - loss: 1.0023 - acc: 0.5067 - val_loss: 1.0295 - val_acc: 0.5040\n",
            "Epoch 145/150 - 0.06s - loss: 1.0017 - acc: 0.5079 - val_loss: 1.0292 - val_acc: 0.5081\n",
            "Epoch 146/150 - 0.07s - loss: 1.0011 - acc: 0.5088 - val_loss: 1.0290 - val_acc: 0.5040\n",
            "Epoch 147/150 - 0.06s - loss: 1.0005 - acc: 0.5083 - val_loss: 1.0285 - val_acc: 0.5020\n",
            "Epoch 148/150 - 0.06s - loss: 1.0000 - acc: 0.5081 - val_loss: 1.0277 - val_acc: 0.5020\n",
            "Epoch 149/150 - 0.07s - loss: 0.9994 - acc: 0.5094 - val_loss: 1.0274 - val_acc: 0.5040\n",
            "Epoch 150/150 - 0.06s - loss: 0.9989 - acc: 0.5106 - val_loss: 1.0270 - val_acc: 0.5000\n",
            "\n",
            "Combination 46/252:\n",
            "Hidden Layers: [128, 64], Activation: relu, Learning Rate: 0.001, Batch Size: 64, Epochs: 50\n",
            "Epoch 1/50 - 0.05s - loss: 1.1015 - acc: 0.3446 - val_loss: 1.1020 - val_acc: 0.3279\n",
            "Epoch 2/50 - 0.05s - loss: 1.0988 - acc: 0.3466 - val_loss: 1.0993 - val_acc: 0.3320\n",
            "Epoch 3/50 - 0.05s - loss: 1.0968 - acc: 0.3441 - val_loss: 1.0974 - val_acc: 0.3502\n",
            "Epoch 4/50 - 0.05s - loss: 1.0955 - acc: 0.3441 - val_loss: 1.0962 - val_acc: 0.3765\n",
            "Epoch 5/50 - 0.05s - loss: 1.0944 - acc: 0.3578 - val_loss: 1.0952 - val_acc: 0.3725\n",
            "Epoch 6/50 - 0.05s - loss: 1.0934 - acc: 0.3635 - val_loss: 1.0944 - val_acc: 0.3623\n",
            "Epoch 7/50 - 0.05s - loss: 1.0926 - acc: 0.3673 - val_loss: 1.0937 - val_acc: 0.3644\n",
            "Epoch 8/50 - 0.05s - loss: 1.0918 - acc: 0.3725 - val_loss: 1.0931 - val_acc: 0.3745\n",
            "Epoch 9/50 - 0.05s - loss: 1.0911 - acc: 0.3767 - val_loss: 1.0925 - val_acc: 0.3765\n",
            "Epoch 10/50 - 0.05s - loss: 1.0903 - acc: 0.3783 - val_loss: 1.0920 - val_acc: 0.3745\n",
            "Epoch 11/50 - 0.05s - loss: 1.0896 - acc: 0.3819 - val_loss: 1.0915 - val_acc: 0.3704\n",
            "Epoch 12/50 - 0.05s - loss: 1.0889 - acc: 0.3830 - val_loss: 1.0909 - val_acc: 0.3765\n",
            "Epoch 13/50 - 0.05s - loss: 1.0882 - acc: 0.3855 - val_loss: 1.0904 - val_acc: 0.3826\n",
            "Epoch 14/50 - 0.05s - loss: 1.0875 - acc: 0.3862 - val_loss: 1.0899 - val_acc: 0.3826\n",
            "Epoch 15/50 - 0.05s - loss: 1.0869 - acc: 0.3889 - val_loss: 1.0895 - val_acc: 0.3866\n",
            "Epoch 16/50 - 0.06s - loss: 1.0862 - acc: 0.3898 - val_loss: 1.0891 - val_acc: 0.3927\n",
            "Epoch 17/50 - 0.05s - loss: 1.0856 - acc: 0.3918 - val_loss: 1.0887 - val_acc: 0.4028\n",
            "Epoch 18/50 - 0.05s - loss: 1.0850 - acc: 0.3950 - val_loss: 1.0883 - val_acc: 0.4008\n",
            "Epoch 19/50 - 0.05s - loss: 1.0843 - acc: 0.3972 - val_loss: 1.0879 - val_acc: 0.4049\n",
            "Epoch 20/50 - 0.05s - loss: 1.0837 - acc: 0.4013 - val_loss: 1.0875 - val_acc: 0.4049\n",
            "Epoch 21/50 - 0.05s - loss: 1.0831 - acc: 0.4053 - val_loss: 1.0872 - val_acc: 0.4089\n",
            "Epoch 22/50 - 0.05s - loss: 1.0825 - acc: 0.4067 - val_loss: 1.0868 - val_acc: 0.4150\n",
            "Epoch 23/50 - 0.05s - loss: 1.0819 - acc: 0.4073 - val_loss: 1.0865 - val_acc: 0.4109\n",
            "Epoch 24/50 - 0.05s - loss: 1.0813 - acc: 0.4098 - val_loss: 1.0862 - val_acc: 0.4130\n",
            "Epoch 25/50 - 0.05s - loss: 1.0808 - acc: 0.4123 - val_loss: 1.0859 - val_acc: 0.4069\n",
            "Epoch 26/50 - 0.05s - loss: 1.0802 - acc: 0.4136 - val_loss: 1.0857 - val_acc: 0.4089\n",
            "Epoch 27/50 - 0.05s - loss: 1.0796 - acc: 0.4139 - val_loss: 1.0854 - val_acc: 0.4069\n",
            "Epoch 28/50 - 0.05s - loss: 1.0791 - acc: 0.4163 - val_loss: 1.0851 - val_acc: 0.4109\n",
            "Epoch 29/50 - 0.05s - loss: 1.0785 - acc: 0.4190 - val_loss: 1.0848 - val_acc: 0.4089\n",
            "Epoch 30/50 - 0.05s - loss: 1.0779 - acc: 0.4184 - val_loss: 1.0845 - val_acc: 0.4109\n",
            "Epoch 31/50 - 0.05s - loss: 1.0774 - acc: 0.4188 - val_loss: 1.0842 - val_acc: 0.4130\n",
            "Epoch 32/50 - 0.05s - loss: 1.0768 - acc: 0.4231 - val_loss: 1.0839 - val_acc: 0.4170\n",
            "Epoch 33/50 - 0.05s - loss: 1.0763 - acc: 0.4226 - val_loss: 1.0837 - val_acc: 0.4231\n",
            "Epoch 34/50 - 0.05s - loss: 1.0757 - acc: 0.4238 - val_loss: 1.0834 - val_acc: 0.4271\n",
            "Epoch 35/50 - 0.05s - loss: 1.0751 - acc: 0.4224 - val_loss: 1.0831 - val_acc: 0.4251\n",
            "Epoch 36/50 - 0.05s - loss: 1.0746 - acc: 0.4231 - val_loss: 1.0828 - val_acc: 0.4231\n",
            "Epoch 37/50 - 0.05s - loss: 1.0740 - acc: 0.4269 - val_loss: 1.0825 - val_acc: 0.4231\n",
            "Epoch 38/50 - 0.05s - loss: 1.0734 - acc: 0.4289 - val_loss: 1.0823 - val_acc: 0.4190\n",
            "Epoch 39/50 - 0.05s - loss: 1.0728 - acc: 0.4312 - val_loss: 1.0820 - val_acc: 0.4190\n",
            "Epoch 40/50 - 0.05s - loss: 1.0723 - acc: 0.4325 - val_loss: 1.0817 - val_acc: 0.4190\n",
            "Epoch 41/50 - 0.05s - loss: 1.0717 - acc: 0.4316 - val_loss: 1.0814 - val_acc: 0.4190\n",
            "Epoch 42/50 - 0.05s - loss: 1.0711 - acc: 0.4325 - val_loss: 1.0811 - val_acc: 0.4251\n",
            "Epoch 43/50 - 0.05s - loss: 1.0706 - acc: 0.4334 - val_loss: 1.0809 - val_acc: 0.4251\n",
            "Epoch 44/50 - 0.05s - loss: 1.0700 - acc: 0.4334 - val_loss: 1.0806 - val_acc: 0.4251\n",
            "Epoch 45/50 - 0.06s - loss: 1.0695 - acc: 0.4348 - val_loss: 1.0803 - val_acc: 0.4251\n",
            "Epoch 46/50 - 0.06s - loss: 1.0689 - acc: 0.4375 - val_loss: 1.0800 - val_acc: 0.4211\n",
            "Epoch 47/50 - 0.06s - loss: 1.0683 - acc: 0.4381 - val_loss: 1.0797 - val_acc: 0.4251\n",
            "Epoch 48/50 - 0.07s - loss: 1.0677 - acc: 0.4379 - val_loss: 1.0794 - val_acc: 0.4251\n",
            "Epoch 49/50 - 0.07s - loss: 1.0672 - acc: 0.4393 - val_loss: 1.0791 - val_acc: 0.4291\n",
            "Epoch 50/50 - 0.06s - loss: 1.0666 - acc: 0.4399 - val_loss: 1.0789 - val_acc: 0.4312\n",
            "\n",
            "Combination 47/252:\n",
            "Hidden Layers: [128, 64], Activation: relu, Learning Rate: 0.001, Batch Size: 64, Epochs: 100\n",
            "Epoch 1/100 - 0.05s - loss: 1.0890 - acc: 0.3815 - val_loss: 1.0904 - val_acc: 0.4008\n",
            "Epoch 2/100 - 0.06s - loss: 1.0865 - acc: 0.3878 - val_loss: 1.0877 - val_acc: 0.4008\n",
            "Epoch 3/100 - 0.05s - loss: 1.0848 - acc: 0.3916 - val_loss: 1.0859 - val_acc: 0.4109\n",
            "Epoch 4/100 - 0.05s - loss: 1.0836 - acc: 0.3970 - val_loss: 1.0846 - val_acc: 0.4089\n",
            "Epoch 5/100 - 0.05s - loss: 1.0826 - acc: 0.4006 - val_loss: 1.0836 - val_acc: 0.4109\n",
            "Epoch 6/100 - 0.05s - loss: 1.0817 - acc: 0.4006 - val_loss: 1.0829 - val_acc: 0.4211\n",
            "Epoch 7/100 - 0.05s - loss: 1.0810 - acc: 0.4015 - val_loss: 1.0822 - val_acc: 0.4130\n",
            "Epoch 8/100 - 0.05s - loss: 1.0803 - acc: 0.4064 - val_loss: 1.0817 - val_acc: 0.4150\n",
            "Epoch 9/100 - 0.05s - loss: 1.0796 - acc: 0.4103 - val_loss: 1.0811 - val_acc: 0.4170\n",
            "Epoch 10/100 - 0.05s - loss: 1.0789 - acc: 0.4121 - val_loss: 1.0806 - val_acc: 0.4190\n",
            "Epoch 11/100 - 0.05s - loss: 1.0783 - acc: 0.4130 - val_loss: 1.0802 - val_acc: 0.4231\n",
            "Epoch 12/100 - 0.05s - loss: 1.0777 - acc: 0.4159 - val_loss: 1.0797 - val_acc: 0.4211\n",
            "Epoch 13/100 - 0.05s - loss: 1.0771 - acc: 0.4179 - val_loss: 1.0793 - val_acc: 0.4251\n",
            "Epoch 14/100 - 0.05s - loss: 1.0764 - acc: 0.4193 - val_loss: 1.0789 - val_acc: 0.4150\n",
            "Epoch 15/100 - 0.05s - loss: 1.0758 - acc: 0.4215 - val_loss: 1.0785 - val_acc: 0.4150\n",
            "Epoch 16/100 - 0.05s - loss: 1.0752 - acc: 0.4240 - val_loss: 1.0781 - val_acc: 0.4130\n",
            "Epoch 17/100 - 0.05s - loss: 1.0746 - acc: 0.4251 - val_loss: 1.0777 - val_acc: 0.4150\n",
            "Epoch 18/100 - 0.05s - loss: 1.0740 - acc: 0.4271 - val_loss: 1.0773 - val_acc: 0.4150\n",
            "Epoch 19/100 - 0.05s - loss: 1.0734 - acc: 0.4283 - val_loss: 1.0769 - val_acc: 0.4089\n",
            "Epoch 20/100 - 0.05s - loss: 1.0728 - acc: 0.4305 - val_loss: 1.0766 - val_acc: 0.4069\n",
            "Epoch 21/100 - 0.05s - loss: 1.0722 - acc: 0.4316 - val_loss: 1.0762 - val_acc: 0.4170\n",
            "Epoch 22/100 - 0.05s - loss: 1.0717 - acc: 0.4332 - val_loss: 1.0759 - val_acc: 0.4130\n",
            "Epoch 23/100 - 0.06s - loss: 1.0711 - acc: 0.4357 - val_loss: 1.0755 - val_acc: 0.4251\n",
            "Epoch 24/100 - 0.05s - loss: 1.0705 - acc: 0.4381 - val_loss: 1.0752 - val_acc: 0.4211\n",
            "Epoch 25/100 - 0.05s - loss: 1.0700 - acc: 0.4388 - val_loss: 1.0748 - val_acc: 0.4251\n",
            "Epoch 26/100 - 0.05s - loss: 1.0694 - acc: 0.4388 - val_loss: 1.0744 - val_acc: 0.4312\n",
            "Epoch 27/100 - 0.05s - loss: 1.0689 - acc: 0.4415 - val_loss: 1.0741 - val_acc: 0.4332\n",
            "Epoch 28/100 - 0.05s - loss: 1.0683 - acc: 0.4440 - val_loss: 1.0737 - val_acc: 0.4291\n",
            "Epoch 29/100 - 0.05s - loss: 1.0678 - acc: 0.4431 - val_loss: 1.0733 - val_acc: 0.4312\n",
            "Epoch 30/100 - 0.05s - loss: 1.0673 - acc: 0.4449 - val_loss: 1.0730 - val_acc: 0.4312\n",
            "Epoch 31/100 - 0.05s - loss: 1.0668 - acc: 0.4458 - val_loss: 1.0726 - val_acc: 0.4291\n",
            "Epoch 32/100 - 0.05s - loss: 1.0662 - acc: 0.4494 - val_loss: 1.0722 - val_acc: 0.4251\n",
            "Epoch 33/100 - 0.05s - loss: 1.0657 - acc: 0.4510 - val_loss: 1.0719 - val_acc: 0.4332\n",
            "Epoch 34/100 - 0.05s - loss: 1.0652 - acc: 0.4512 - val_loss: 1.0715 - val_acc: 0.4352\n",
            "Epoch 35/100 - 0.05s - loss: 1.0647 - acc: 0.4510 - val_loss: 1.0712 - val_acc: 0.4352\n",
            "Epoch 36/100 - 0.05s - loss: 1.0642 - acc: 0.4521 - val_loss: 1.0709 - val_acc: 0.4352\n",
            "Epoch 37/100 - 0.05s - loss: 1.0637 - acc: 0.4512 - val_loss: 1.0705 - val_acc: 0.4332\n",
            "Epoch 38/100 - 0.05s - loss: 1.0632 - acc: 0.4514 - val_loss: 1.0701 - val_acc: 0.4352\n",
            "Epoch 39/100 - 0.05s - loss: 1.0627 - acc: 0.4534 - val_loss: 1.0698 - val_acc: 0.4372\n",
            "Epoch 40/100 - 0.05s - loss: 1.0622 - acc: 0.4532 - val_loss: 1.0694 - val_acc: 0.4413\n",
            "Epoch 41/100 - 0.05s - loss: 1.0617 - acc: 0.4559 - val_loss: 1.0691 - val_acc: 0.4413\n",
            "Epoch 42/100 - 0.05s - loss: 1.0612 - acc: 0.4557 - val_loss: 1.0687 - val_acc: 0.4372\n",
            "Epoch 43/100 - 0.05s - loss: 1.0607 - acc: 0.4552 - val_loss: 1.0683 - val_acc: 0.4372\n",
            "Epoch 44/100 - 0.05s - loss: 1.0602 - acc: 0.4577 - val_loss: 1.0679 - val_acc: 0.4352\n",
            "Epoch 45/100 - 0.05s - loss: 1.0597 - acc: 0.4597 - val_loss: 1.0676 - val_acc: 0.4312\n",
            "Epoch 46/100 - 0.05s - loss: 1.0592 - acc: 0.4593 - val_loss: 1.0672 - val_acc: 0.4312\n",
            "Epoch 47/100 - 0.05s - loss: 1.0587 - acc: 0.4606 - val_loss: 1.0668 - val_acc: 0.4312\n",
            "Epoch 48/100 - 0.05s - loss: 1.0582 - acc: 0.4615 - val_loss: 1.0664 - val_acc: 0.4332\n",
            "Epoch 49/100 - 0.05s - loss: 1.0577 - acc: 0.4624 - val_loss: 1.0660 - val_acc: 0.4372\n",
            "Epoch 50/100 - 0.05s - loss: 1.0572 - acc: 0.4604 - val_loss: 1.0657 - val_acc: 0.4332\n",
            "Epoch 51/100 - 0.06s - loss: 1.0567 - acc: 0.4618 - val_loss: 1.0653 - val_acc: 0.4332\n",
            "Epoch 52/100 - 0.05s - loss: 1.0563 - acc: 0.4624 - val_loss: 1.0649 - val_acc: 0.4332\n",
            "Epoch 53/100 - 0.05s - loss: 1.0557 - acc: 0.4631 - val_loss: 1.0645 - val_acc: 0.4312\n",
            "Epoch 54/100 - 0.05s - loss: 1.0553 - acc: 0.4642 - val_loss: 1.0642 - val_acc: 0.4291\n",
            "Epoch 55/100 - 0.05s - loss: 1.0548 - acc: 0.4645 - val_loss: 1.0638 - val_acc: 0.4271\n",
            "Epoch 56/100 - 0.06s - loss: 1.0543 - acc: 0.4645 - val_loss: 1.0635 - val_acc: 0.4271\n",
            "Epoch 57/100 - 0.05s - loss: 1.0538 - acc: 0.4642 - val_loss: 1.0631 - val_acc: 0.4312\n",
            "Epoch 58/100 - 0.05s - loss: 1.0533 - acc: 0.4649 - val_loss: 1.0627 - val_acc: 0.4291\n",
            "Epoch 59/100 - 0.05s - loss: 1.0528 - acc: 0.4663 - val_loss: 1.0624 - val_acc: 0.4332\n",
            "Epoch 60/100 - 0.05s - loss: 1.0523 - acc: 0.4660 - val_loss: 1.0621 - val_acc: 0.4291\n",
            "Epoch 61/100 - 0.05s - loss: 1.0518 - acc: 0.4658 - val_loss: 1.0617 - val_acc: 0.4312\n",
            "Epoch 62/100 - 0.05s - loss: 1.0513 - acc: 0.4665 - val_loss: 1.0614 - val_acc: 0.4312\n",
            "Epoch 63/100 - 0.05s - loss: 1.0508 - acc: 0.4683 - val_loss: 1.0611 - val_acc: 0.4231\n",
            "Epoch 64/100 - 0.05s - loss: 1.0503 - acc: 0.4687 - val_loss: 1.0608 - val_acc: 0.4251\n",
            "Epoch 65/100 - 0.05s - loss: 1.0499 - acc: 0.4687 - val_loss: 1.0605 - val_acc: 0.4251\n",
            "Epoch 66/100 - 0.05s - loss: 1.0494 - acc: 0.4708 - val_loss: 1.0601 - val_acc: 0.4271\n",
            "Epoch 67/100 - 0.06s - loss: 1.0489 - acc: 0.4714 - val_loss: 1.0598 - val_acc: 0.4271\n",
            "Epoch 68/100 - 0.05s - loss: 1.0484 - acc: 0.4710 - val_loss: 1.0595 - val_acc: 0.4291\n",
            "Epoch 69/100 - 0.05s - loss: 1.0480 - acc: 0.4719 - val_loss: 1.0592 - val_acc: 0.4271\n",
            "Epoch 70/100 - 0.05s - loss: 1.0475 - acc: 0.4723 - val_loss: 1.0588 - val_acc: 0.4251\n",
            "Epoch 71/100 - 0.05s - loss: 1.0470 - acc: 0.4741 - val_loss: 1.0586 - val_acc: 0.4251\n",
            "Epoch 72/100 - 0.05s - loss: 1.0466 - acc: 0.4744 - val_loss: 1.0583 - val_acc: 0.4231\n",
            "Epoch 73/100 - 0.05s - loss: 1.0461 - acc: 0.4748 - val_loss: 1.0580 - val_acc: 0.4251\n",
            "Epoch 74/100 - 0.05s - loss: 1.0456 - acc: 0.4753 - val_loss: 1.0577 - val_acc: 0.4271\n",
            "Epoch 75/100 - 0.05s - loss: 1.0452 - acc: 0.4753 - val_loss: 1.0574 - val_acc: 0.4271\n",
            "Epoch 76/100 - 0.05s - loss: 1.0447 - acc: 0.4759 - val_loss: 1.0571 - val_acc: 0.4271\n",
            "Epoch 77/100 - 0.05s - loss: 1.0443 - acc: 0.4759 - val_loss: 1.0568 - val_acc: 0.4312\n",
            "Epoch 78/100 - 0.05s - loss: 1.0438 - acc: 0.4784 - val_loss: 1.0565 - val_acc: 0.4332\n",
            "Epoch 79/100 - 0.05s - loss: 1.0434 - acc: 0.4768 - val_loss: 1.0562 - val_acc: 0.4352\n",
            "Epoch 80/100 - 0.06s - loss: 1.0429 - acc: 0.4800 - val_loss: 1.0560 - val_acc: 0.4332\n",
            "Epoch 81/100 - 0.05s - loss: 1.0425 - acc: 0.4786 - val_loss: 1.0557 - val_acc: 0.4372\n",
            "Epoch 82/100 - 0.05s - loss: 1.0421 - acc: 0.4791 - val_loss: 1.0554 - val_acc: 0.4372\n",
            "Epoch 83/100 - 0.05s - loss: 1.0416 - acc: 0.4782 - val_loss: 1.0551 - val_acc: 0.4393\n",
            "Epoch 84/100 - 0.05s - loss: 1.0412 - acc: 0.4804 - val_loss: 1.0548 - val_acc: 0.4413\n",
            "Epoch 85/100 - 0.06s - loss: 1.0407 - acc: 0.4804 - val_loss: 1.0545 - val_acc: 0.4372\n",
            "Epoch 86/100 - 0.05s - loss: 1.0403 - acc: 0.4804 - val_loss: 1.0542 - val_acc: 0.4433\n",
            "Epoch 87/100 - 0.05s - loss: 1.0398 - acc: 0.4811 - val_loss: 1.0539 - val_acc: 0.4393\n",
            "Epoch 88/100 - 0.05s - loss: 1.0394 - acc: 0.4825 - val_loss: 1.0536 - val_acc: 0.4433\n",
            "Epoch 89/100 - 0.05s - loss: 1.0389 - acc: 0.4811 - val_loss: 1.0533 - val_acc: 0.4393\n",
            "Epoch 90/100 - 0.05s - loss: 1.0385 - acc: 0.4818 - val_loss: 1.0530 - val_acc: 0.4413\n",
            "Epoch 91/100 - 0.05s - loss: 1.0381 - acc: 0.4816 - val_loss: 1.0528 - val_acc: 0.4352\n",
            "Epoch 92/100 - 0.05s - loss: 1.0376 - acc: 0.4813 - val_loss: 1.0525 - val_acc: 0.4393\n",
            "Epoch 93/100 - 0.05s - loss: 1.0372 - acc: 0.4822 - val_loss: 1.0522 - val_acc: 0.4393\n",
            "Epoch 94/100 - 0.05s - loss: 1.0368 - acc: 0.4822 - val_loss: 1.0519 - val_acc: 0.4413\n",
            "Epoch 95/100 - 0.06s - loss: 1.0364 - acc: 0.4836 - val_loss: 1.0517 - val_acc: 0.4372\n",
            "Epoch 96/100 - 0.06s - loss: 1.0359 - acc: 0.4827 - val_loss: 1.0514 - val_acc: 0.4413\n",
            "Epoch 97/100 - 0.06s - loss: 1.0355 - acc: 0.4838 - val_loss: 1.0511 - val_acc: 0.4393\n",
            "Epoch 98/100 - 0.06s - loss: 1.0351 - acc: 0.4836 - val_loss: 1.0509 - val_acc: 0.4413\n",
            "Epoch 99/100 - 0.06s - loss: 1.0347 - acc: 0.4831 - val_loss: 1.0505 - val_acc: 0.4413\n",
            "Epoch 100/100 - 0.06s - loss: 1.0342 - acc: 0.4836 - val_loss: 1.0502 - val_acc: 0.4413\n",
            "\n",
            "Combination 48/252:\n",
            "Hidden Layers: [128, 64], Activation: relu, Learning Rate: 0.001, Batch Size: 64, Epochs: 150\n",
            "Epoch 1/150 - 0.06s - loss: 1.1019 - acc: 0.3257 - val_loss: 1.1010 - val_acc: 0.3421\n",
            "Epoch 2/150 - 0.06s - loss: 1.0994 - acc: 0.3356 - val_loss: 1.0990 - val_acc: 0.3522\n",
            "Epoch 3/150 - 0.06s - loss: 1.0974 - acc: 0.3495 - val_loss: 1.0975 - val_acc: 0.3563\n",
            "Epoch 4/150 - 0.06s - loss: 1.0958 - acc: 0.3653 - val_loss: 1.0963 - val_acc: 0.3502\n",
            "Epoch 5/150 - 0.06s - loss: 1.0944 - acc: 0.3763 - val_loss: 1.0954 - val_acc: 0.3421\n",
            "Epoch 6/150 - 0.06s - loss: 1.0932 - acc: 0.3758 - val_loss: 1.0946 - val_acc: 0.3623\n",
            "Epoch 7/150 - 0.06s - loss: 1.0922 - acc: 0.3801 - val_loss: 1.0940 - val_acc: 0.3522\n",
            "Epoch 8/150 - 0.06s - loss: 1.0913 - acc: 0.3851 - val_loss: 1.0934 - val_acc: 0.3563\n",
            "Epoch 9/150 - 0.06s - loss: 1.0904 - acc: 0.3848 - val_loss: 1.0929 - val_acc: 0.3462\n",
            "Epoch 10/150 - 0.06s - loss: 1.0897 - acc: 0.3844 - val_loss: 1.0925 - val_acc: 0.3543\n",
            "Epoch 11/150 - 0.06s - loss: 1.0890 - acc: 0.3842 - val_loss: 1.0920 - val_acc: 0.3502\n",
            "Epoch 12/150 - 0.06s - loss: 1.0883 - acc: 0.3857 - val_loss: 1.0917 - val_acc: 0.3502\n",
            "Epoch 13/150 - 0.06s - loss: 1.0877 - acc: 0.3893 - val_loss: 1.0913 - val_acc: 0.3522\n",
            "Epoch 14/150 - 0.06s - loss: 1.0870 - acc: 0.3902 - val_loss: 1.0909 - val_acc: 0.3502\n",
            "Epoch 15/150 - 0.06s - loss: 1.0864 - acc: 0.3929 - val_loss: 1.0904 - val_acc: 0.3563\n",
            "Epoch 16/150 - 0.06s - loss: 1.0859 - acc: 0.3938 - val_loss: 1.0901 - val_acc: 0.3623\n",
            "Epoch 17/150 - 0.06s - loss: 1.0853 - acc: 0.3956 - val_loss: 1.0897 - val_acc: 0.3644\n",
            "Epoch 18/150 - 0.06s - loss: 1.0847 - acc: 0.3963 - val_loss: 1.0893 - val_acc: 0.3644\n",
            "Epoch 19/150 - 0.06s - loss: 1.0842 - acc: 0.3970 - val_loss: 1.0890 - val_acc: 0.3664\n",
            "Epoch 20/150 - 0.06s - loss: 1.0836 - acc: 0.3988 - val_loss: 1.0886 - val_acc: 0.3704\n",
            "Epoch 21/150 - 0.06s - loss: 1.0831 - acc: 0.4001 - val_loss: 1.0882 - val_acc: 0.3765\n",
            "Epoch 22/150 - 0.06s - loss: 1.0825 - acc: 0.4028 - val_loss: 1.0878 - val_acc: 0.3846\n",
            "Epoch 23/150 - 0.06s - loss: 1.0820 - acc: 0.4053 - val_loss: 1.0874 - val_acc: 0.3826\n",
            "Epoch 24/150 - 0.06s - loss: 1.0815 - acc: 0.4078 - val_loss: 1.0870 - val_acc: 0.3927\n",
            "Epoch 25/150 - 0.06s - loss: 1.0810 - acc: 0.4116 - val_loss: 1.0866 - val_acc: 0.3907\n",
            "Epoch 26/150 - 0.06s - loss: 1.0805 - acc: 0.4105 - val_loss: 1.0862 - val_acc: 0.3927\n",
            "Epoch 27/150 - 0.06s - loss: 1.0800 - acc: 0.4152 - val_loss: 1.0858 - val_acc: 0.3968\n",
            "Epoch 28/150 - 0.06s - loss: 1.0795 - acc: 0.4166 - val_loss: 1.0854 - val_acc: 0.4008\n",
            "Epoch 29/150 - 0.06s - loss: 1.0790 - acc: 0.4184 - val_loss: 1.0850 - val_acc: 0.4008\n",
            "Epoch 30/150 - 0.07s - loss: 1.0785 - acc: 0.4211 - val_loss: 1.0846 - val_acc: 0.4028\n",
            "Epoch 31/150 - 0.06s - loss: 1.0780 - acc: 0.4238 - val_loss: 1.0842 - val_acc: 0.4069\n",
            "Epoch 32/150 - 0.06s - loss: 1.0775 - acc: 0.4251 - val_loss: 1.0838 - val_acc: 0.4109\n",
            "Epoch 33/150 - 0.06s - loss: 1.0770 - acc: 0.4274 - val_loss: 1.0834 - val_acc: 0.4190\n",
            "Epoch 34/150 - 0.06s - loss: 1.0765 - acc: 0.4303 - val_loss: 1.0831 - val_acc: 0.4231\n",
            "Epoch 35/150 - 0.06s - loss: 1.0761 - acc: 0.4312 - val_loss: 1.0827 - val_acc: 0.4211\n",
            "Epoch 36/150 - 0.06s - loss: 1.0756 - acc: 0.4323 - val_loss: 1.0823 - val_acc: 0.4190\n",
            "Epoch 37/150 - 0.06s - loss: 1.0751 - acc: 0.4334 - val_loss: 1.0820 - val_acc: 0.4130\n",
            "Epoch 38/150 - 0.06s - loss: 1.0747 - acc: 0.4352 - val_loss: 1.0816 - val_acc: 0.4190\n",
            "Epoch 39/150 - 0.06s - loss: 1.0742 - acc: 0.4372 - val_loss: 1.0813 - val_acc: 0.4190\n",
            "Epoch 40/150 - 0.06s - loss: 1.0737 - acc: 0.4384 - val_loss: 1.0809 - val_acc: 0.4291\n",
            "Epoch 41/150 - 0.06s - loss: 1.0733 - acc: 0.4399 - val_loss: 1.0806 - val_acc: 0.4251\n",
            "Epoch 42/150 - 0.06s - loss: 1.0728 - acc: 0.4417 - val_loss: 1.0802 - val_acc: 0.4271\n",
            "Epoch 43/150 - 0.05s - loss: 1.0724 - acc: 0.4420 - val_loss: 1.0799 - val_acc: 0.4251\n",
            "Epoch 44/150 - 0.06s - loss: 1.0719 - acc: 0.4431 - val_loss: 1.0795 - val_acc: 0.4231\n",
            "Epoch 45/150 - 0.06s - loss: 1.0715 - acc: 0.4431 - val_loss: 1.0791 - val_acc: 0.4251\n",
            "Epoch 46/150 - 0.06s - loss: 1.0710 - acc: 0.4460 - val_loss: 1.0788 - val_acc: 0.4291\n",
            "Epoch 47/150 - 0.07s - loss: 1.0706 - acc: 0.4480 - val_loss: 1.0784 - val_acc: 0.4251\n",
            "Epoch 48/150 - 0.09s - loss: 1.0702 - acc: 0.4494 - val_loss: 1.0781 - val_acc: 0.4251\n",
            "Epoch 49/150 - 0.07s - loss: 1.0697 - acc: 0.4519 - val_loss: 1.0777 - val_acc: 0.4251\n",
            "Epoch 50/150 - 0.06s - loss: 1.0693 - acc: 0.4516 - val_loss: 1.0773 - val_acc: 0.4211\n",
            "Epoch 51/150 - 0.07s - loss: 1.0688 - acc: 0.4514 - val_loss: 1.0770 - val_acc: 0.4231\n",
            "Epoch 52/150 - 0.08s - loss: 1.0684 - acc: 0.4534 - val_loss: 1.0766 - val_acc: 0.4271\n",
            "Epoch 53/150 - 0.08s - loss: 1.0680 - acc: 0.4541 - val_loss: 1.0763 - val_acc: 0.4291\n",
            "Epoch 54/150 - 0.07s - loss: 1.0676 - acc: 0.4552 - val_loss: 1.0760 - val_acc: 0.4271\n",
            "Epoch 55/150 - 0.07s - loss: 1.0671 - acc: 0.4564 - val_loss: 1.0756 - val_acc: 0.4291\n",
            "Epoch 56/150 - 0.06s - loss: 1.0667 - acc: 0.4566 - val_loss: 1.0752 - val_acc: 0.4271\n",
            "Epoch 57/150 - 0.06s - loss: 1.0663 - acc: 0.4595 - val_loss: 1.0749 - val_acc: 0.4291\n",
            "Epoch 58/150 - 0.06s - loss: 1.0659 - acc: 0.4604 - val_loss: 1.0746 - val_acc: 0.4352\n",
            "Epoch 59/150 - 0.06s - loss: 1.0655 - acc: 0.4602 - val_loss: 1.0742 - val_acc: 0.4372\n",
            "Epoch 60/150 - 0.06s - loss: 1.0651 - acc: 0.4609 - val_loss: 1.0739 - val_acc: 0.4433\n",
            "Epoch 61/150 - 0.06s - loss: 1.0647 - acc: 0.4600 - val_loss: 1.0735 - val_acc: 0.4413\n",
            "Epoch 62/150 - 0.06s - loss: 1.0643 - acc: 0.4606 - val_loss: 1.0732 - val_acc: 0.4413\n",
            "Epoch 63/150 - 0.06s - loss: 1.0639 - acc: 0.4613 - val_loss: 1.0729 - val_acc: 0.4413\n",
            "Epoch 64/150 - 0.06s - loss: 1.0635 - acc: 0.4624 - val_loss: 1.0726 - val_acc: 0.4413\n",
            "Epoch 65/150 - 0.06s - loss: 1.0631 - acc: 0.4591 - val_loss: 1.0722 - val_acc: 0.4372\n",
            "Epoch 66/150 - 0.06s - loss: 1.0627 - acc: 0.4582 - val_loss: 1.0719 - val_acc: 0.4372\n",
            "Epoch 67/150 - 0.06s - loss: 1.0623 - acc: 0.4593 - val_loss: 1.0716 - val_acc: 0.4372\n",
            "Epoch 68/150 - 0.06s - loss: 1.0619 - acc: 0.4595 - val_loss: 1.0713 - val_acc: 0.4332\n",
            "Epoch 69/150 - 0.07s - loss: 1.0615 - acc: 0.4597 - val_loss: 1.0710 - val_acc: 0.4352\n",
            "Epoch 70/150 - 0.09s - loss: 1.0611 - acc: 0.4604 - val_loss: 1.0706 - val_acc: 0.4332\n",
            "Epoch 71/150 - 0.09s - loss: 1.0607 - acc: 0.4627 - val_loss: 1.0703 - val_acc: 0.4312\n",
            "Epoch 72/150 - 0.07s - loss: 1.0603 - acc: 0.4629 - val_loss: 1.0700 - val_acc: 0.4332\n",
            "Epoch 73/150 - 0.07s - loss: 1.0599 - acc: 0.4624 - val_loss: 1.0697 - val_acc: 0.4372\n",
            "Epoch 74/150 - 0.07s - loss: 1.0596 - acc: 0.4624 - val_loss: 1.0694 - val_acc: 0.4332\n",
            "Epoch 75/150 - 0.06s - loss: 1.0592 - acc: 0.4651 - val_loss: 1.0691 - val_acc: 0.4372\n",
            "Epoch 76/150 - 0.06s - loss: 1.0588 - acc: 0.4656 - val_loss: 1.0688 - val_acc: 0.4393\n",
            "Epoch 77/150 - 0.06s - loss: 1.0584 - acc: 0.4658 - val_loss: 1.0685 - val_acc: 0.4413\n",
            "Epoch 78/150 - 0.06s - loss: 1.0580 - acc: 0.4656 - val_loss: 1.0683 - val_acc: 0.4332\n",
            "Epoch 79/150 - 0.06s - loss: 1.0576 - acc: 0.4660 - val_loss: 1.0680 - val_acc: 0.4393\n",
            "Epoch 80/150 - 0.06s - loss: 1.0573 - acc: 0.4656 - val_loss: 1.0676 - val_acc: 0.4372\n",
            "Epoch 81/150 - 0.06s - loss: 1.0569 - acc: 0.4651 - val_loss: 1.0674 - val_acc: 0.4332\n",
            "Epoch 82/150 - 0.06s - loss: 1.0565 - acc: 0.4654 - val_loss: 1.0671 - val_acc: 0.4291\n",
            "Epoch 83/150 - 0.06s - loss: 1.0561 - acc: 0.4649 - val_loss: 1.0668 - val_acc: 0.4332\n",
            "Epoch 84/150 - 0.06s - loss: 1.0558 - acc: 0.4656 - val_loss: 1.0665 - val_acc: 0.4352\n",
            "Epoch 85/150 - 0.06s - loss: 1.0554 - acc: 0.4665 - val_loss: 1.0662 - val_acc: 0.4332\n",
            "Epoch 86/150 - 0.06s - loss: 1.0550 - acc: 0.4665 - val_loss: 1.0660 - val_acc: 0.4352\n",
            "Epoch 87/150 - 0.06s - loss: 1.0547 - acc: 0.4667 - val_loss: 1.0657 - val_acc: 0.4332\n",
            "Epoch 88/150 - 0.06s - loss: 1.0543 - acc: 0.4660 - val_loss: 1.0654 - val_acc: 0.4251\n",
            "Epoch 89/150 - 0.06s - loss: 1.0539 - acc: 0.4674 - val_loss: 1.0651 - val_acc: 0.4291\n",
            "Epoch 90/150 - 0.06s - loss: 1.0536 - acc: 0.4656 - val_loss: 1.0648 - val_acc: 0.4271\n",
            "Epoch 91/150 - 0.06s - loss: 1.0532 - acc: 0.4651 - val_loss: 1.0645 - val_acc: 0.4312\n",
            "Epoch 92/150 - 0.06s - loss: 1.0528 - acc: 0.4651 - val_loss: 1.0642 - val_acc: 0.4312\n",
            "Epoch 93/150 - 0.06s - loss: 1.0525 - acc: 0.4665 - val_loss: 1.0640 - val_acc: 0.4291\n",
            "Epoch 94/150 - 0.06s - loss: 1.0521 - acc: 0.4672 - val_loss: 1.0637 - val_acc: 0.4291\n",
            "Epoch 95/150 - 0.06s - loss: 1.0518 - acc: 0.4672 - val_loss: 1.0634 - val_acc: 0.4291\n",
            "Epoch 96/150 - 0.06s - loss: 1.0514 - acc: 0.4678 - val_loss: 1.0631 - val_acc: 0.4312\n",
            "Epoch 97/150 - 0.07s - loss: 1.0510 - acc: 0.4690 - val_loss: 1.0628 - val_acc: 0.4372\n",
            "Epoch 98/150 - 0.06s - loss: 1.0507 - acc: 0.4690 - val_loss: 1.0625 - val_acc: 0.4352\n",
            "Epoch 99/150 - 0.06s - loss: 1.0503 - acc: 0.4674 - val_loss: 1.0622 - val_acc: 0.4372\n",
            "Epoch 100/150 - 0.06s - loss: 1.0500 - acc: 0.4685 - val_loss: 1.0619 - val_acc: 0.4393\n",
            "Epoch 101/150 - 0.06s - loss: 1.0496 - acc: 0.4674 - val_loss: 1.0617 - val_acc: 0.4433\n",
            "Epoch 102/150 - 0.07s - loss: 1.0493 - acc: 0.4683 - val_loss: 1.0614 - val_acc: 0.4413\n",
            "Epoch 103/150 - 0.06s - loss: 1.0489 - acc: 0.4683 - val_loss: 1.0612 - val_acc: 0.4433\n",
            "Epoch 104/150 - 0.06s - loss: 1.0486 - acc: 0.4672 - val_loss: 1.0609 - val_acc: 0.4433\n",
            "Epoch 105/150 - 0.06s - loss: 1.0482 - acc: 0.4685 - val_loss: 1.0606 - val_acc: 0.4413\n",
            "Epoch 106/150 - 0.06s - loss: 1.0479 - acc: 0.4687 - val_loss: 1.0604 - val_acc: 0.4393\n",
            "Epoch 107/150 - 0.06s - loss: 1.0475 - acc: 0.4683 - val_loss: 1.0601 - val_acc: 0.4433\n",
            "Epoch 108/150 - 0.06s - loss: 1.0472 - acc: 0.4687 - val_loss: 1.0599 - val_acc: 0.4433\n",
            "Epoch 109/150 - 0.06s - loss: 1.0468 - acc: 0.4690 - val_loss: 1.0596 - val_acc: 0.4413\n",
            "Epoch 110/150 - 0.06s - loss: 1.0465 - acc: 0.4685 - val_loss: 1.0593 - val_acc: 0.4433\n",
            "Epoch 111/150 - 0.06s - loss: 1.0461 - acc: 0.4692 - val_loss: 1.0591 - val_acc: 0.4433\n",
            "Epoch 112/150 - 0.05s - loss: 1.0458 - acc: 0.4703 - val_loss: 1.0588 - val_acc: 0.4433\n",
            "Epoch 113/150 - 0.06s - loss: 1.0454 - acc: 0.4703 - val_loss: 1.0585 - val_acc: 0.4453\n",
            "Epoch 114/150 - 0.06s - loss: 1.0451 - acc: 0.4701 - val_loss: 1.0583 - val_acc: 0.4413\n",
            "Epoch 115/150 - 0.07s - loss: 1.0448 - acc: 0.4710 - val_loss: 1.0580 - val_acc: 0.4433\n",
            "Epoch 116/150 - 0.06s - loss: 1.0444 - acc: 0.4708 - val_loss: 1.0577 - val_acc: 0.4433\n",
            "Epoch 117/150 - 0.06s - loss: 1.0441 - acc: 0.4732 - val_loss: 1.0575 - val_acc: 0.4433\n",
            "Epoch 118/150 - 0.06s - loss: 1.0437 - acc: 0.4726 - val_loss: 1.0572 - val_acc: 0.4433\n",
            "Epoch 119/150 - 0.06s - loss: 1.0434 - acc: 0.4714 - val_loss: 1.0569 - val_acc: 0.4474\n",
            "Epoch 120/150 - 0.05s - loss: 1.0430 - acc: 0.4732 - val_loss: 1.0567 - val_acc: 0.4494\n",
            "Epoch 121/150 - 0.06s - loss: 1.0427 - acc: 0.4728 - val_loss: 1.0564 - val_acc: 0.4534\n",
            "Epoch 122/150 - 0.06s - loss: 1.0423 - acc: 0.4730 - val_loss: 1.0561 - val_acc: 0.4534\n",
            "Epoch 123/150 - 0.06s - loss: 1.0420 - acc: 0.4721 - val_loss: 1.0558 - val_acc: 0.4494\n",
            "Epoch 124/150 - 0.06s - loss: 1.0416 - acc: 0.4728 - val_loss: 1.0556 - val_acc: 0.4494\n",
            "Epoch 125/150 - 0.06s - loss: 1.0413 - acc: 0.4730 - val_loss: 1.0553 - val_acc: 0.4494\n",
            "Epoch 126/150 - 0.06s - loss: 1.0409 - acc: 0.4732 - val_loss: 1.0550 - val_acc: 0.4494\n",
            "Epoch 127/150 - 0.06s - loss: 1.0406 - acc: 0.4732 - val_loss: 1.0547 - val_acc: 0.4514\n",
            "Epoch 128/150 - 0.06s - loss: 1.0402 - acc: 0.4744 - val_loss: 1.0545 - val_acc: 0.4514\n",
            "Epoch 129/150 - 0.06s - loss: 1.0399 - acc: 0.4744 - val_loss: 1.0543 - val_acc: 0.4514\n",
            "Epoch 130/150 - 0.05s - loss: 1.0395 - acc: 0.4748 - val_loss: 1.0540 - val_acc: 0.4575\n",
            "Epoch 131/150 - 0.05s - loss: 1.0392 - acc: 0.4755 - val_loss: 1.0537 - val_acc: 0.4595\n",
            "Epoch 132/150 - 0.05s - loss: 1.0388 - acc: 0.4744 - val_loss: 1.0534 - val_acc: 0.4555\n",
            "Epoch 133/150 - 0.05s - loss: 1.0384 - acc: 0.4759 - val_loss: 1.0530 - val_acc: 0.4595\n",
            "Epoch 134/150 - 0.05s - loss: 1.0381 - acc: 0.4768 - val_loss: 1.0527 - val_acc: 0.4595\n",
            "Epoch 135/150 - 0.05s - loss: 1.0377 - acc: 0.4786 - val_loss: 1.0525 - val_acc: 0.4595\n",
            "Epoch 136/150 - 0.05s - loss: 1.0373 - acc: 0.4777 - val_loss: 1.0522 - val_acc: 0.4595\n",
            "Epoch 137/150 - 0.05s - loss: 1.0369 - acc: 0.4791 - val_loss: 1.0519 - val_acc: 0.4595\n",
            "Epoch 138/150 - 0.05s - loss: 1.0366 - acc: 0.4786 - val_loss: 1.0516 - val_acc: 0.4595\n",
            "Epoch 139/150 - 0.05s - loss: 1.0362 - acc: 0.4795 - val_loss: 1.0514 - val_acc: 0.4595\n",
            "Epoch 140/150 - 0.05s - loss: 1.0358 - acc: 0.4807 - val_loss: 1.0511 - val_acc: 0.4575\n",
            "Epoch 141/150 - 0.05s - loss: 1.0355 - acc: 0.4800 - val_loss: 1.0508 - val_acc: 0.4575\n",
            "Epoch 142/150 - 0.05s - loss: 1.0351 - acc: 0.4822 - val_loss: 1.0504 - val_acc: 0.4575\n",
            "Epoch 143/150 - 0.05s - loss: 1.0347 - acc: 0.4820 - val_loss: 1.0502 - val_acc: 0.4555\n",
            "Epoch 144/150 - 0.05s - loss: 1.0344 - acc: 0.4834 - val_loss: 1.0499 - val_acc: 0.4555\n",
            "Epoch 145/150 - 0.05s - loss: 1.0340 - acc: 0.4843 - val_loss: 1.0496 - val_acc: 0.4615\n",
            "Epoch 146/150 - 0.05s - loss: 1.0336 - acc: 0.4836 - val_loss: 1.0492 - val_acc: 0.4636\n",
            "Epoch 147/150 - 0.05s - loss: 1.0333 - acc: 0.4843 - val_loss: 1.0489 - val_acc: 0.4636\n",
            "Epoch 148/150 - 0.05s - loss: 1.0329 - acc: 0.4845 - val_loss: 1.0486 - val_acc: 0.4615\n",
            "Epoch 149/150 - 0.06s - loss: 1.0325 - acc: 0.4852 - val_loss: 1.0484 - val_acc: 0.4615\n",
            "Epoch 150/150 - 0.05s - loss: 1.0322 - acc: 0.4856 - val_loss: 1.0481 - val_acc: 0.4636\n",
            "\n",
            "Combination 49/252:\n",
            "Hidden Layers: [128, 64], Activation: relu, Learning Rate: 0.0001, Batch Size: 32, Epochs: 50\n",
            "Epoch 1/50 - 0.06s - loss: 1.1137 - acc: 0.3250 - val_loss: 1.1092 - val_acc: 0.3381\n",
            "Epoch 2/50 - 0.06s - loss: 1.1123 - acc: 0.3273 - val_loss: 1.1080 - val_acc: 0.3360\n",
            "Epoch 3/50 - 0.06s - loss: 1.1109 - acc: 0.3288 - val_loss: 1.1068 - val_acc: 0.3381\n",
            "Epoch 4/50 - 0.06s - loss: 1.1097 - acc: 0.3295 - val_loss: 1.1057 - val_acc: 0.3381\n",
            "Epoch 5/50 - 0.06s - loss: 1.1085 - acc: 0.3295 - val_loss: 1.1048 - val_acc: 0.3421\n",
            "Epoch 6/50 - 0.06s - loss: 1.1074 - acc: 0.3306 - val_loss: 1.1038 - val_acc: 0.3360\n",
            "Epoch 7/50 - 0.06s - loss: 1.1063 - acc: 0.3306 - val_loss: 1.1030 - val_acc: 0.3401\n",
            "Epoch 8/50 - 0.06s - loss: 1.1054 - acc: 0.3342 - val_loss: 1.1022 - val_acc: 0.3441\n",
            "Epoch 9/50 - 0.06s - loss: 1.1045 - acc: 0.3376 - val_loss: 1.1015 - val_acc: 0.3441\n",
            "Epoch 10/50 - 0.06s - loss: 1.1036 - acc: 0.3378 - val_loss: 1.1008 - val_acc: 0.3482\n",
            "Epoch 11/50 - 0.07s - loss: 1.1028 - acc: 0.3430 - val_loss: 1.1001 - val_acc: 0.3462\n",
            "Epoch 12/50 - 0.07s - loss: 1.1021 - acc: 0.3450 - val_loss: 1.0995 - val_acc: 0.3441\n",
            "Epoch 13/50 - 0.06s - loss: 1.1014 - acc: 0.3462 - val_loss: 1.0990 - val_acc: 0.3502\n",
            "Epoch 14/50 - 0.07s - loss: 1.1007 - acc: 0.3475 - val_loss: 1.0984 - val_acc: 0.3482\n",
            "Epoch 15/50 - 0.07s - loss: 1.1001 - acc: 0.3507 - val_loss: 1.0980 - val_acc: 0.3563\n",
            "Epoch 16/50 - 0.06s - loss: 1.0995 - acc: 0.3522 - val_loss: 1.0975 - val_acc: 0.3563\n",
            "Epoch 17/50 - 0.06s - loss: 1.0989 - acc: 0.3534 - val_loss: 1.0971 - val_acc: 0.3603\n",
            "Epoch 18/50 - 0.06s - loss: 1.0984 - acc: 0.3552 - val_loss: 1.0967 - val_acc: 0.3644\n",
            "Epoch 19/50 - 0.06s - loss: 1.0979 - acc: 0.3540 - val_loss: 1.0963 - val_acc: 0.3725\n",
            "Epoch 20/50 - 0.06s - loss: 1.0974 - acc: 0.3552 - val_loss: 1.0960 - val_acc: 0.3522\n",
            "Epoch 21/50 - 0.06s - loss: 1.0970 - acc: 0.3563 - val_loss: 1.0956 - val_acc: 0.3522\n",
            "Epoch 22/50 - 0.06s - loss: 1.0965 - acc: 0.3594 - val_loss: 1.0953 - val_acc: 0.3543\n",
            "Epoch 23/50 - 0.07s - loss: 1.0961 - acc: 0.3630 - val_loss: 1.0950 - val_acc: 0.3583\n",
            "Epoch 24/50 - 0.06s - loss: 1.0958 - acc: 0.3664 - val_loss: 1.0947 - val_acc: 0.3583\n",
            "Epoch 25/50 - 0.06s - loss: 1.0954 - acc: 0.3686 - val_loss: 1.0945 - val_acc: 0.3603\n",
            "Epoch 26/50 - 0.06s - loss: 1.0950 - acc: 0.3731 - val_loss: 1.0942 - val_acc: 0.3684\n",
            "Epoch 27/50 - 0.06s - loss: 1.0947 - acc: 0.3747 - val_loss: 1.0940 - val_acc: 0.3684\n",
            "Epoch 28/50 - 0.06s - loss: 1.0944 - acc: 0.3754 - val_loss: 1.0937 - val_acc: 0.3644\n",
            "Epoch 29/50 - 0.06s - loss: 1.0941 - acc: 0.3788 - val_loss: 1.0935 - val_acc: 0.3623\n",
            "Epoch 30/50 - 0.06s - loss: 1.0938 - acc: 0.3828 - val_loss: 1.0933 - val_acc: 0.3826\n",
            "Epoch 31/50 - 0.06s - loss: 1.0935 - acc: 0.3866 - val_loss: 1.0931 - val_acc: 0.3704\n",
            "Epoch 32/50 - 0.06s - loss: 1.0933 - acc: 0.3880 - val_loss: 1.0930 - val_acc: 0.3664\n",
            "Epoch 33/50 - 0.06s - loss: 1.0930 - acc: 0.3891 - val_loss: 1.0928 - val_acc: 0.3826\n",
            "Epoch 34/50 - 0.06s - loss: 1.0928 - acc: 0.3907 - val_loss: 1.0926 - val_acc: 0.3887\n",
            "Epoch 35/50 - 0.06s - loss: 1.0925 - acc: 0.3936 - val_loss: 1.0925 - val_acc: 0.3947\n",
            "Epoch 36/50 - 0.06s - loss: 1.0923 - acc: 0.3965 - val_loss: 1.0923 - val_acc: 0.3927\n",
            "Epoch 37/50 - 0.06s - loss: 1.0921 - acc: 0.3983 - val_loss: 1.0922 - val_acc: 0.3968\n",
            "Epoch 38/50 - 0.06s - loss: 1.0919 - acc: 0.3990 - val_loss: 1.0920 - val_acc: 0.3947\n",
            "Epoch 39/50 - 0.06s - loss: 1.0917 - acc: 0.3997 - val_loss: 1.0919 - val_acc: 0.3947\n",
            "Epoch 40/50 - 0.06s - loss: 1.0915 - acc: 0.4001 - val_loss: 1.0918 - val_acc: 0.3907\n",
            "Epoch 41/50 - 0.06s - loss: 1.0913 - acc: 0.4004 - val_loss: 1.0917 - val_acc: 0.3866\n",
            "Epoch 42/50 - 0.06s - loss: 1.0911 - acc: 0.4001 - val_loss: 1.0915 - val_acc: 0.3907\n",
            "Epoch 43/50 - 0.06s - loss: 1.0909 - acc: 0.4013 - val_loss: 1.0914 - val_acc: 0.3927\n",
            "Epoch 44/50 - 0.06s - loss: 1.0907 - acc: 0.4024 - val_loss: 1.0913 - val_acc: 0.3866\n",
            "Epoch 45/50 - 0.06s - loss: 1.0906 - acc: 0.4053 - val_loss: 1.0912 - val_acc: 0.3866\n",
            "Epoch 46/50 - 0.06s - loss: 1.0904 - acc: 0.4058 - val_loss: 1.0911 - val_acc: 0.3866\n",
            "Epoch 47/50 - 0.07s - loss: 1.0902 - acc: 0.4078 - val_loss: 1.0910 - val_acc: 0.3866\n",
            "Epoch 48/50 - 0.06s - loss: 1.0901 - acc: 0.4085 - val_loss: 1.0909 - val_acc: 0.3887\n",
            "Epoch 49/50 - 0.06s - loss: 1.0899 - acc: 0.4094 - val_loss: 1.0908 - val_acc: 0.3866\n",
            "Epoch 50/50 - 0.06s - loss: 1.0898 - acc: 0.4080 - val_loss: 1.0907 - val_acc: 0.3846\n",
            "\n",
            "Combination 50/252:\n",
            "Hidden Layers: [128, 64], Activation: relu, Learning Rate: 0.0001, Batch Size: 32, Epochs: 100\n",
            "Epoch 1/100 - 0.06s - loss: 1.1064 - acc: 0.3369 - val_loss: 1.1076 - val_acc: 0.3462\n",
            "Epoch 2/100 - 0.06s - loss: 1.1055 - acc: 0.3385 - val_loss: 1.1069 - val_acc: 0.3502\n",
            "Epoch 3/100 - 0.06s - loss: 1.1047 - acc: 0.3396 - val_loss: 1.1063 - val_acc: 0.3502\n",
            "Epoch 4/100 - 0.06s - loss: 1.1041 - acc: 0.3399 - val_loss: 1.1058 - val_acc: 0.3502\n",
            "Epoch 5/100 - 0.06s - loss: 1.1035 - acc: 0.3372 - val_loss: 1.1054 - val_acc: 0.3563\n",
            "Epoch 6/100 - 0.06s - loss: 1.1029 - acc: 0.3410 - val_loss: 1.1050 - val_acc: 0.3583\n",
            "Epoch 7/100 - 0.06s - loss: 1.1024 - acc: 0.3412 - val_loss: 1.1047 - val_acc: 0.3563\n",
            "Epoch 8/100 - 0.06s - loss: 1.1020 - acc: 0.3455 - val_loss: 1.1044 - val_acc: 0.3381\n",
            "Epoch 9/100 - 0.06s - loss: 1.1016 - acc: 0.3441 - val_loss: 1.1041 - val_acc: 0.3340\n",
            "Epoch 10/100 - 0.06s - loss: 1.1013 - acc: 0.3423 - val_loss: 1.1038 - val_acc: 0.3360\n",
            "Epoch 11/100 - 0.06s - loss: 1.1009 - acc: 0.3437 - val_loss: 1.1036 - val_acc: 0.3300\n",
            "Epoch 12/100 - 0.06s - loss: 1.1006 - acc: 0.3435 - val_loss: 1.1034 - val_acc: 0.3239\n",
            "Epoch 13/100 - 0.06s - loss: 1.1003 - acc: 0.3453 - val_loss: 1.1032 - val_acc: 0.3279\n",
            "Epoch 14/100 - 0.06s - loss: 1.1000 - acc: 0.3462 - val_loss: 1.1031 - val_acc: 0.3239\n",
            "Epoch 15/100 - 0.06s - loss: 1.0998 - acc: 0.3471 - val_loss: 1.1029 - val_acc: 0.3198\n",
            "Epoch 16/100 - 0.06s - loss: 1.0995 - acc: 0.3489 - val_loss: 1.1028 - val_acc: 0.3198\n",
            "Epoch 17/100 - 0.06s - loss: 1.0993 - acc: 0.3482 - val_loss: 1.1026 - val_acc: 0.3097\n",
            "Epoch 18/100 - 0.07s - loss: 1.0991 - acc: 0.3493 - val_loss: 1.1025 - val_acc: 0.3036\n",
            "Epoch 19/100 - 0.06s - loss: 1.0989 - acc: 0.3504 - val_loss: 1.1023 - val_acc: 0.3036\n",
            "Epoch 20/100 - 0.06s - loss: 1.0987 - acc: 0.3520 - val_loss: 1.1022 - val_acc: 0.3097\n",
            "Epoch 21/100 - 0.06s - loss: 1.0985 - acc: 0.3509 - val_loss: 1.1021 - val_acc: 0.3097\n",
            "Epoch 22/100 - 0.06s - loss: 1.0983 - acc: 0.3525 - val_loss: 1.1020 - val_acc: 0.3138\n",
            "Epoch 23/100 - 0.06s - loss: 1.0981 - acc: 0.3558 - val_loss: 1.1018 - val_acc: 0.3158\n",
            "Epoch 24/100 - 0.06s - loss: 1.0979 - acc: 0.3567 - val_loss: 1.1017 - val_acc: 0.3158\n",
            "Epoch 25/100 - 0.06s - loss: 1.0977 - acc: 0.3576 - val_loss: 1.1016 - val_acc: 0.3239\n",
            "Epoch 26/100 - 0.06s - loss: 1.0975 - acc: 0.3592 - val_loss: 1.1015 - val_acc: 0.3219\n",
            "Epoch 27/100 - 0.06s - loss: 1.0973 - acc: 0.3614 - val_loss: 1.1013 - val_acc: 0.3219\n",
            "Epoch 28/100 - 0.06s - loss: 1.0972 - acc: 0.3617 - val_loss: 1.1012 - val_acc: 0.3198\n",
            "Epoch 29/100 - 0.07s - loss: 1.0970 - acc: 0.3612 - val_loss: 1.1011 - val_acc: 0.3219\n",
            "Epoch 30/100 - 0.06s - loss: 1.0968 - acc: 0.3617 - val_loss: 1.1010 - val_acc: 0.3259\n",
            "Epoch 31/100 - 0.06s - loss: 1.0966 - acc: 0.3630 - val_loss: 1.1009 - val_acc: 0.3178\n",
            "Epoch 32/100 - 0.06s - loss: 1.0964 - acc: 0.3641 - val_loss: 1.1007 - val_acc: 0.3178\n",
            "Epoch 33/100 - 0.06s - loss: 1.0963 - acc: 0.3646 - val_loss: 1.1006 - val_acc: 0.3219\n",
            "Epoch 34/100 - 0.06s - loss: 1.0961 - acc: 0.3646 - val_loss: 1.1005 - val_acc: 0.3219\n",
            "Epoch 35/100 - 0.06s - loss: 1.0959 - acc: 0.3662 - val_loss: 1.1004 - val_acc: 0.3198\n",
            "Epoch 36/100 - 0.06s - loss: 1.0957 - acc: 0.3664 - val_loss: 1.1003 - val_acc: 0.3198\n",
            "Epoch 37/100 - 0.06s - loss: 1.0955 - acc: 0.3675 - val_loss: 1.1001 - val_acc: 0.3219\n",
            "Epoch 38/100 - 0.06s - loss: 1.0954 - acc: 0.3684 - val_loss: 1.1000 - val_acc: 0.3259\n",
            "Epoch 39/100 - 0.06s - loss: 1.0952 - acc: 0.3686 - val_loss: 1.0999 - val_acc: 0.3239\n",
            "Epoch 40/100 - 0.06s - loss: 1.0950 - acc: 0.3693 - val_loss: 1.0998 - val_acc: 0.3239\n",
            "Epoch 41/100 - 0.07s - loss: 1.0949 - acc: 0.3684 - val_loss: 1.0997 - val_acc: 0.3279\n",
            "Epoch 42/100 - 0.06s - loss: 1.0947 - acc: 0.3695 - val_loss: 1.0995 - val_acc: 0.3279\n",
            "Epoch 43/100 - 0.06s - loss: 1.0945 - acc: 0.3709 - val_loss: 1.0994 - val_acc: 0.3279\n",
            "Epoch 44/100 - 0.06s - loss: 1.0943 - acc: 0.3720 - val_loss: 1.0993 - val_acc: 0.3300\n",
            "Epoch 45/100 - 0.06s - loss: 1.0942 - acc: 0.3718 - val_loss: 1.0992 - val_acc: 0.3279\n",
            "Epoch 46/100 - 0.06s - loss: 1.0940 - acc: 0.3725 - val_loss: 1.0991 - val_acc: 0.3320\n",
            "Epoch 47/100 - 0.06s - loss: 1.0938 - acc: 0.3722 - val_loss: 1.0990 - val_acc: 0.3340\n",
            "Epoch 48/100 - 0.06s - loss: 1.0937 - acc: 0.3736 - val_loss: 1.0988 - val_acc: 0.3360\n",
            "Epoch 49/100 - 0.06s - loss: 1.0935 - acc: 0.3734 - val_loss: 1.0987 - val_acc: 0.3381\n",
            "Epoch 50/100 - 0.06s - loss: 1.0933 - acc: 0.3747 - val_loss: 1.0986 - val_acc: 0.3401\n",
            "Epoch 51/100 - 0.06s - loss: 1.0932 - acc: 0.3743 - val_loss: 1.0985 - val_acc: 0.3401\n",
            "Epoch 52/100 - 0.06s - loss: 1.0930 - acc: 0.3745 - val_loss: 1.0984 - val_acc: 0.3421\n",
            "Epoch 53/100 - 0.06s - loss: 1.0929 - acc: 0.3754 - val_loss: 1.0983 - val_acc: 0.3441\n",
            "Epoch 54/100 - 0.06s - loss: 1.0927 - acc: 0.3761 - val_loss: 1.0981 - val_acc: 0.3462\n",
            "Epoch 55/100 - 0.06s - loss: 1.0925 - acc: 0.3772 - val_loss: 1.0980 - val_acc: 0.3462\n",
            "Epoch 56/100 - 0.06s - loss: 1.0924 - acc: 0.3779 - val_loss: 1.0979 - val_acc: 0.3441\n",
            "Epoch 57/100 - 0.06s - loss: 1.0922 - acc: 0.3785 - val_loss: 1.0978 - val_acc: 0.3441\n",
            "Epoch 58/100 - 0.06s - loss: 1.0920 - acc: 0.3794 - val_loss: 1.0977 - val_acc: 0.3441\n",
            "Epoch 59/100 - 0.06s - loss: 1.0919 - acc: 0.3797 - val_loss: 1.0976 - val_acc: 0.3441\n",
            "Epoch 60/100 - 0.06s - loss: 1.0917 - acc: 0.3806 - val_loss: 1.0975 - val_acc: 0.3462\n",
            "Epoch 61/100 - 0.07s - loss: 1.0916 - acc: 0.3812 - val_loss: 1.0974 - val_acc: 0.3462\n",
            "Epoch 62/100 - 0.06s - loss: 1.0914 - acc: 0.3808 - val_loss: 1.0972 - val_acc: 0.3441\n",
            "Epoch 63/100 - 0.06s - loss: 1.0912 - acc: 0.3819 - val_loss: 1.0971 - val_acc: 0.3462\n",
            "Epoch 64/100 - 0.06s - loss: 1.0911 - acc: 0.3830 - val_loss: 1.0970 - val_acc: 0.3462\n",
            "Epoch 65/100 - 0.06s - loss: 1.0909 - acc: 0.3846 - val_loss: 1.0969 - val_acc: 0.3462\n",
            "Epoch 66/100 - 0.06s - loss: 1.0908 - acc: 0.3857 - val_loss: 1.0968 - val_acc: 0.3482\n",
            "Epoch 67/100 - 0.06s - loss: 1.0906 - acc: 0.3855 - val_loss: 1.0967 - val_acc: 0.3482\n",
            "Epoch 68/100 - 0.06s - loss: 1.0904 - acc: 0.3860 - val_loss: 1.0966 - val_acc: 0.3482\n",
            "Epoch 69/100 - 0.06s - loss: 1.0903 - acc: 0.3860 - val_loss: 1.0965 - val_acc: 0.3482\n",
            "Epoch 70/100 - 0.06s - loss: 1.0901 - acc: 0.3875 - val_loss: 1.0963 - val_acc: 0.3482\n",
            "Epoch 71/100 - 0.06s - loss: 1.0900 - acc: 0.3869 - val_loss: 1.0962 - val_acc: 0.3482\n",
            "Epoch 72/100 - 0.06s - loss: 1.0898 - acc: 0.3882 - val_loss: 1.0961 - val_acc: 0.3502\n",
            "Epoch 73/100 - 0.06s - loss: 1.0897 - acc: 0.3880 - val_loss: 1.0960 - val_acc: 0.3482\n",
            "Epoch 74/100 - 0.06s - loss: 1.0895 - acc: 0.3880 - val_loss: 1.0959 - val_acc: 0.3482\n",
            "Epoch 75/100 - 0.06s - loss: 1.0894 - acc: 0.3869 - val_loss: 1.0958 - val_acc: 0.3502\n",
            "Epoch 76/100 - 0.06s - loss: 1.0892 - acc: 0.3880 - val_loss: 1.0957 - val_acc: 0.3502\n",
            "Epoch 77/100 - 0.06s - loss: 1.0891 - acc: 0.3878 - val_loss: 1.0955 - val_acc: 0.3563\n",
            "Epoch 78/100 - 0.06s - loss: 1.0889 - acc: 0.3878 - val_loss: 1.0954 - val_acc: 0.3563\n",
            "Epoch 79/100 - 0.06s - loss: 1.0888 - acc: 0.3896 - val_loss: 1.0953 - val_acc: 0.3563\n",
            "Epoch 80/100 - 0.06s - loss: 1.0886 - acc: 0.3902 - val_loss: 1.0952 - val_acc: 0.3563\n",
            "Epoch 81/100 - 0.06s - loss: 1.0885 - acc: 0.3905 - val_loss: 1.0951 - val_acc: 0.3563\n",
            "Epoch 82/100 - 0.06s - loss: 1.0883 - acc: 0.3909 - val_loss: 1.0950 - val_acc: 0.3543\n",
            "Epoch 83/100 - 0.07s - loss: 1.0882 - acc: 0.3911 - val_loss: 1.0948 - val_acc: 0.3543\n",
            "Epoch 84/100 - 0.06s - loss: 1.0880 - acc: 0.3914 - val_loss: 1.0947 - val_acc: 0.3522\n",
            "Epoch 85/100 - 0.07s - loss: 1.0879 - acc: 0.3923 - val_loss: 1.0946 - val_acc: 0.3543\n",
            "Epoch 86/100 - 0.06s - loss: 1.0878 - acc: 0.3927 - val_loss: 1.0945 - val_acc: 0.3543\n",
            "Epoch 87/100 - 0.06s - loss: 1.0876 - acc: 0.3932 - val_loss: 1.0944 - val_acc: 0.3543\n",
            "Epoch 88/100 - 0.06s - loss: 1.0875 - acc: 0.3932 - val_loss: 1.0943 - val_acc: 0.3543\n",
            "Epoch 89/100 - 0.06s - loss: 1.0873 - acc: 0.3936 - val_loss: 1.0942 - val_acc: 0.3583\n",
            "Epoch 90/100 - 0.06s - loss: 1.0872 - acc: 0.3932 - val_loss: 1.0941 - val_acc: 0.3583\n",
            "Epoch 91/100 - 0.06s - loss: 1.0870 - acc: 0.3936 - val_loss: 1.0939 - val_acc: 0.3583\n",
            "Epoch 92/100 - 0.06s - loss: 1.0869 - acc: 0.3947 - val_loss: 1.0938 - val_acc: 0.3623\n",
            "Epoch 93/100 - 0.06s - loss: 1.0868 - acc: 0.3956 - val_loss: 1.0937 - val_acc: 0.3623\n",
            "Epoch 94/100 - 0.06s - loss: 1.0866 - acc: 0.3961 - val_loss: 1.0936 - val_acc: 0.3644\n",
            "Epoch 95/100 - 0.06s - loss: 1.0865 - acc: 0.3961 - val_loss: 1.0935 - val_acc: 0.3623\n",
            "Epoch 96/100 - 0.06s - loss: 1.0863 - acc: 0.3977 - val_loss: 1.0934 - val_acc: 0.3664\n",
            "Epoch 97/100 - 0.06s - loss: 1.0862 - acc: 0.3981 - val_loss: 1.0933 - val_acc: 0.3684\n",
            "Epoch 98/100 - 0.06s - loss: 1.0861 - acc: 0.3988 - val_loss: 1.0932 - val_acc: 0.3704\n",
            "Epoch 99/100 - 0.06s - loss: 1.0859 - acc: 0.3986 - val_loss: 1.0930 - val_acc: 0.3704\n",
            "Epoch 100/100 - 0.06s - loss: 1.0858 - acc: 0.3983 - val_loss: 1.0929 - val_acc: 0.3684\n",
            "\n",
            "Combination 51/252:\n",
            "Hidden Layers: [128, 64], Activation: relu, Learning Rate: 0.0001, Batch Size: 32, Epochs: 150\n",
            "Epoch 1/150 - 0.06s - loss: 1.1068 - acc: 0.3180 - val_loss: 1.1002 - val_acc: 0.3401\n",
            "Epoch 2/150 - 0.06s - loss: 1.1065 - acc: 0.3219 - val_loss: 1.1000 - val_acc: 0.3401\n",
            "Epoch 3/150 - 0.06s - loss: 1.1061 - acc: 0.3239 - val_loss: 1.0998 - val_acc: 0.3360\n",
            "Epoch 4/150 - 0.06s - loss: 1.1058 - acc: 0.3255 - val_loss: 1.0996 - val_acc: 0.3360\n",
            "Epoch 5/150 - 0.07s - loss: 1.1055 - acc: 0.3248 - val_loss: 1.0994 - val_acc: 0.3401\n",
            "Epoch 6/150 - 0.06s - loss: 1.1052 - acc: 0.3241 - val_loss: 1.0992 - val_acc: 0.3381\n",
            "Epoch 7/150 - 0.06s - loss: 1.1049 - acc: 0.3243 - val_loss: 1.0991 - val_acc: 0.3421\n",
            "Epoch 8/150 - 0.06s - loss: 1.1047 - acc: 0.3261 - val_loss: 1.0989 - val_acc: 0.3421\n",
            "Epoch 9/150 - 0.06s - loss: 1.1044 - acc: 0.3275 - val_loss: 1.0987 - val_acc: 0.3462\n",
            "Epoch 10/150 - 0.06s - loss: 1.1041 - acc: 0.3302 - val_loss: 1.0986 - val_acc: 0.3522\n",
            "Epoch 11/150 - 0.06s - loss: 1.1039 - acc: 0.3318 - val_loss: 1.0984 - val_acc: 0.3522\n",
            "Epoch 12/150 - 0.06s - loss: 1.1036 - acc: 0.3349 - val_loss: 1.0983 - val_acc: 0.3583\n",
            "Epoch 13/150 - 0.06s - loss: 1.1034 - acc: 0.3356 - val_loss: 1.0982 - val_acc: 0.3664\n",
            "Epoch 14/150 - 0.06s - loss: 1.1032 - acc: 0.3376 - val_loss: 1.0980 - val_acc: 0.3644\n",
            "Epoch 15/150 - 0.06s - loss: 1.1029 - acc: 0.3392 - val_loss: 1.0979 - val_acc: 0.3684\n",
            "Epoch 16/150 - 0.06s - loss: 1.1027 - acc: 0.3390 - val_loss: 1.0978 - val_acc: 0.3644\n",
            "Epoch 17/150 - 0.06s - loss: 1.1025 - acc: 0.3403 - val_loss: 1.0976 - val_acc: 0.3623\n",
            "Epoch 18/150 - 0.06s - loss: 1.1023 - acc: 0.3412 - val_loss: 1.0975 - val_acc: 0.3543\n",
            "Epoch 19/150 - 0.06s - loss: 1.1021 - acc: 0.3426 - val_loss: 1.0974 - val_acc: 0.3583\n",
            "Epoch 20/150 - 0.06s - loss: 1.1019 - acc: 0.3453 - val_loss: 1.0973 - val_acc: 0.3583\n",
            "Epoch 21/150 - 0.06s - loss: 1.1017 - acc: 0.3462 - val_loss: 1.0971 - val_acc: 0.3644\n",
            "Epoch 22/150 - 0.06s - loss: 1.1015 - acc: 0.3473 - val_loss: 1.0970 - val_acc: 0.3664\n",
            "Epoch 23/150 - 0.06s - loss: 1.1013 - acc: 0.3473 - val_loss: 1.0969 - val_acc: 0.3603\n",
            "Epoch 24/150 - 0.06s - loss: 1.1011 - acc: 0.3468 - val_loss: 1.0968 - val_acc: 0.3583\n",
            "Epoch 25/150 - 0.07s - loss: 1.1009 - acc: 0.3489 - val_loss: 1.0967 - val_acc: 0.3644\n",
            "Epoch 26/150 - 0.06s - loss: 1.1007 - acc: 0.3495 - val_loss: 1.0965 - val_acc: 0.3644\n",
            "Epoch 27/150 - 0.06s - loss: 1.1006 - acc: 0.3504 - val_loss: 1.0964 - val_acc: 0.3644\n",
            "Epoch 28/150 - 0.06s - loss: 1.1004 - acc: 0.3511 - val_loss: 1.0963 - val_acc: 0.3664\n",
            "Epoch 29/150 - 0.06s - loss: 1.1002 - acc: 0.3520 - val_loss: 1.0962 - val_acc: 0.3644\n",
            "Epoch 30/150 - 0.06s - loss: 1.1000 - acc: 0.3525 - val_loss: 1.0961 - val_acc: 0.3664\n",
            "Epoch 31/150 - 0.06s - loss: 1.0999 - acc: 0.3538 - val_loss: 1.0960 - val_acc: 0.3684\n",
            "Epoch 32/150 - 0.06s - loss: 1.0997 - acc: 0.3554 - val_loss: 1.0959 - val_acc: 0.3684\n",
            "Epoch 33/150 - 0.06s - loss: 1.0995 - acc: 0.3567 - val_loss: 1.0957 - val_acc: 0.3664\n",
            "Epoch 34/150 - 0.06s - loss: 1.0994 - acc: 0.3574 - val_loss: 1.0956 - val_acc: 0.3664\n",
            "Epoch 35/150 - 0.06s - loss: 1.0992 - acc: 0.3590 - val_loss: 1.0955 - val_acc: 0.3623\n",
            "Epoch 36/150 - 0.06s - loss: 1.0990 - acc: 0.3605 - val_loss: 1.0954 - val_acc: 0.3664\n",
            "Epoch 37/150 - 0.06s - loss: 1.0989 - acc: 0.3612 - val_loss: 1.0953 - val_acc: 0.3644\n",
            "Epoch 38/150 - 0.06s - loss: 1.0987 - acc: 0.3619 - val_loss: 1.0952 - val_acc: 0.3664\n",
            "Epoch 39/150 - 0.06s - loss: 1.0985 - acc: 0.3621 - val_loss: 1.0951 - val_acc: 0.3664\n",
            "Epoch 40/150 - 0.06s - loss: 1.0984 - acc: 0.3644 - val_loss: 1.0949 - val_acc: 0.3664\n",
            "Epoch 41/150 - 0.06s - loss: 1.0982 - acc: 0.3653 - val_loss: 1.0948 - val_acc: 0.3664\n",
            "Epoch 42/150 - 0.06s - loss: 1.0981 - acc: 0.3650 - val_loss: 1.0947 - val_acc: 0.3704\n",
            "Epoch 43/150 - 0.06s - loss: 1.0979 - acc: 0.3662 - val_loss: 1.0946 - val_acc: 0.3725\n",
            "Epoch 44/150 - 0.06s - loss: 1.0978 - acc: 0.3682 - val_loss: 1.0945 - val_acc: 0.3725\n",
            "Epoch 45/150 - 0.06s - loss: 1.0976 - acc: 0.3700 - val_loss: 1.0944 - val_acc: 0.3745\n",
            "Epoch 46/150 - 0.06s - loss: 1.0975 - acc: 0.3709 - val_loss: 1.0942 - val_acc: 0.3745\n",
            "Epoch 47/150 - 0.06s - loss: 1.0973 - acc: 0.3720 - val_loss: 1.0941 - val_acc: 0.3725\n",
            "Epoch 48/150 - 0.06s - loss: 1.0971 - acc: 0.3722 - val_loss: 1.0940 - val_acc: 0.3725\n",
            "Epoch 49/150 - 0.07s - loss: 1.0970 - acc: 0.3727 - val_loss: 1.0939 - val_acc: 0.3765\n",
            "Epoch 50/150 - 0.06s - loss: 1.0968 - acc: 0.3727 - val_loss: 1.0938 - val_acc: 0.3765\n",
            "Epoch 51/150 - 0.06s - loss: 1.0967 - acc: 0.3729 - val_loss: 1.0937 - val_acc: 0.3765\n",
            "Epoch 52/150 - 0.06s - loss: 1.0965 - acc: 0.3738 - val_loss: 1.0935 - val_acc: 0.3806\n",
            "Epoch 53/150 - 0.06s - loss: 1.0964 - acc: 0.3738 - val_loss: 1.0934 - val_acc: 0.3826\n",
            "Epoch 54/150 - 0.06s - loss: 1.0962 - acc: 0.3740 - val_loss: 1.0933 - val_acc: 0.3826\n",
            "Epoch 55/150 - 0.06s - loss: 1.0961 - acc: 0.3747 - val_loss: 1.0932 - val_acc: 0.3826\n",
            "Epoch 56/150 - 0.06s - loss: 1.0959 - acc: 0.3761 - val_loss: 1.0931 - val_acc: 0.3785\n",
            "Epoch 57/150 - 0.06s - loss: 1.0958 - acc: 0.3761 - val_loss: 1.0930 - val_acc: 0.3765\n",
            "Epoch 58/150 - 0.06s - loss: 1.0956 - acc: 0.3774 - val_loss: 1.0929 - val_acc: 0.3785\n",
            "Epoch 59/150 - 0.06s - loss: 1.0955 - acc: 0.3781 - val_loss: 1.0928 - val_acc: 0.3806\n",
            "Epoch 60/150 - 0.06s - loss: 1.0954 - acc: 0.3783 - val_loss: 1.0926 - val_acc: 0.3806\n",
            "Epoch 61/150 - 0.06s - loss: 1.0952 - acc: 0.3785 - val_loss: 1.0925 - val_acc: 0.3806\n",
            "Epoch 62/150 - 0.06s - loss: 1.0951 - acc: 0.3781 - val_loss: 1.0924 - val_acc: 0.3765\n",
            "Epoch 63/150 - 0.06s - loss: 1.0949 - acc: 0.3781 - val_loss: 1.0923 - val_acc: 0.3725\n",
            "Epoch 64/150 - 0.06s - loss: 1.0948 - acc: 0.3788 - val_loss: 1.0922 - val_acc: 0.3745\n",
            "Epoch 65/150 - 0.06s - loss: 1.0946 - acc: 0.3788 - val_loss: 1.0921 - val_acc: 0.3745\n",
            "Epoch 66/150 - 0.06s - loss: 1.0945 - acc: 0.3790 - val_loss: 1.0920 - val_acc: 0.3765\n",
            "Epoch 67/150 - 0.06s - loss: 1.0944 - acc: 0.3794 - val_loss: 1.0919 - val_acc: 0.3765\n",
            "Epoch 68/150 - 0.06s - loss: 1.0942 - acc: 0.3801 - val_loss: 1.0918 - val_acc: 0.3765\n",
            "Epoch 69/150 - 0.07s - loss: 1.0941 - acc: 0.3808 - val_loss: 1.0917 - val_acc: 0.3785\n",
            "Epoch 70/150 - 0.06s - loss: 1.0940 - acc: 0.3815 - val_loss: 1.0916 - val_acc: 0.3765\n",
            "Epoch 71/150 - 0.06s - loss: 1.0938 - acc: 0.3824 - val_loss: 1.0915 - val_acc: 0.3765\n",
            "Epoch 72/150 - 0.06s - loss: 1.0937 - acc: 0.3828 - val_loss: 1.0914 - val_acc: 0.3765\n",
            "Epoch 73/150 - 0.06s - loss: 1.0936 - acc: 0.3830 - val_loss: 1.0913 - val_acc: 0.3765\n",
            "Epoch 74/150 - 0.07s - loss: 1.0934 - acc: 0.3826 - val_loss: 1.0912 - val_acc: 0.3765\n",
            "Epoch 75/150 - 0.06s - loss: 1.0933 - acc: 0.3835 - val_loss: 1.0911 - val_acc: 0.3785\n",
            "Epoch 76/150 - 0.06s - loss: 1.0932 - acc: 0.3844 - val_loss: 1.0910 - val_acc: 0.3785\n",
            "Epoch 77/150 - 0.06s - loss: 1.0930 - acc: 0.3844 - val_loss: 1.0909 - val_acc: 0.3785\n",
            "Epoch 78/150 - 0.06s - loss: 1.0929 - acc: 0.3842 - val_loss: 1.0908 - val_acc: 0.3806\n",
            "Epoch 79/150 - 0.06s - loss: 1.0928 - acc: 0.3826 - val_loss: 1.0907 - val_acc: 0.3846\n",
            "Epoch 80/150 - 0.06s - loss: 1.0926 - acc: 0.3839 - val_loss: 1.0906 - val_acc: 0.3846\n",
            "Epoch 81/150 - 0.06s - loss: 1.0925 - acc: 0.3855 - val_loss: 1.0905 - val_acc: 0.3866\n",
            "Epoch 82/150 - 0.06s - loss: 1.0924 - acc: 0.3855 - val_loss: 1.0904 - val_acc: 0.3846\n",
            "Epoch 83/150 - 0.06s - loss: 1.0922 - acc: 0.3857 - val_loss: 1.0903 - val_acc: 0.3846\n",
            "Epoch 84/150 - 0.06s - loss: 1.0921 - acc: 0.3864 - val_loss: 1.0902 - val_acc: 0.3866\n",
            "Epoch 85/150 - 0.06s - loss: 1.0920 - acc: 0.3860 - val_loss: 1.0901 - val_acc: 0.3866\n",
            "Epoch 86/150 - 0.06s - loss: 1.0918 - acc: 0.3869 - val_loss: 1.0900 - val_acc: 0.3887\n",
            "Epoch 87/150 - 0.06s - loss: 1.0917 - acc: 0.3871 - val_loss: 1.0899 - val_acc: 0.3887\n",
            "Epoch 88/150 - 0.06s - loss: 1.0916 - acc: 0.3871 - val_loss: 1.0898 - val_acc: 0.3927\n",
            "Epoch 89/150 - 0.07s - loss: 1.0915 - acc: 0.3869 - val_loss: 1.0897 - val_acc: 0.3947\n",
            "Epoch 90/150 - 0.06s - loss: 1.0913 - acc: 0.3875 - val_loss: 1.0896 - val_acc: 0.3927\n",
            "Epoch 91/150 - 0.06s - loss: 1.0912 - acc: 0.3882 - val_loss: 1.0895 - val_acc: 0.3907\n",
            "Epoch 92/150 - 0.06s - loss: 1.0911 - acc: 0.3884 - val_loss: 1.0894 - val_acc: 0.3887\n",
            "Epoch 93/150 - 0.06s - loss: 1.0910 - acc: 0.3878 - val_loss: 1.0893 - val_acc: 0.3887\n",
            "Epoch 94/150 - 0.06s - loss: 1.0908 - acc: 0.3891 - val_loss: 1.0892 - val_acc: 0.3887\n",
            "Epoch 95/150 - 0.06s - loss: 1.0907 - acc: 0.3898 - val_loss: 1.0891 - val_acc: 0.3887\n",
            "Epoch 96/150 - 0.06s - loss: 1.0906 - acc: 0.3898 - val_loss: 1.0890 - val_acc: 0.3887\n",
            "Epoch 97/150 - 0.06s - loss: 1.0905 - acc: 0.3907 - val_loss: 1.0889 - val_acc: 0.3887\n",
            "Epoch 98/150 - 0.06s - loss: 1.0904 - acc: 0.3909 - val_loss: 1.0888 - val_acc: 0.3887\n",
            "Epoch 99/150 - 0.06s - loss: 1.0902 - acc: 0.3918 - val_loss: 1.0887 - val_acc: 0.3907\n",
            "Epoch 100/150 - 0.06s - loss: 1.0901 - acc: 0.3914 - val_loss: 1.0886 - val_acc: 0.3947\n",
            "Epoch 101/150 - 0.06s - loss: 1.0900 - acc: 0.3911 - val_loss: 1.0885 - val_acc: 0.3947\n",
            "Epoch 102/150 - 0.06s - loss: 1.0899 - acc: 0.3905 - val_loss: 1.0884 - val_acc: 0.3927\n",
            "Epoch 103/150 - 0.06s - loss: 1.0898 - acc: 0.3909 - val_loss: 1.0884 - val_acc: 0.3927\n",
            "Epoch 104/150 - 0.06s - loss: 1.0897 - acc: 0.3916 - val_loss: 1.0883 - val_acc: 0.3927\n",
            "Epoch 105/150 - 0.06s - loss: 1.0895 - acc: 0.3920 - val_loss: 1.0882 - val_acc: 0.3947\n",
            "Epoch 106/150 - 0.06s - loss: 1.0894 - acc: 0.3918 - val_loss: 1.0881 - val_acc: 0.3927\n",
            "Epoch 107/150 - 0.06s - loss: 1.0893 - acc: 0.3911 - val_loss: 1.0880 - val_acc: 0.3927\n",
            "Epoch 108/150 - 0.06s - loss: 1.0892 - acc: 0.3916 - val_loss: 1.0879 - val_acc: 0.3907\n",
            "Epoch 109/150 - 0.07s - loss: 1.0891 - acc: 0.3916 - val_loss: 1.0878 - val_acc: 0.3907\n",
            "Epoch 110/150 - 0.06s - loss: 1.0890 - acc: 0.3914 - val_loss: 1.0877 - val_acc: 0.3927\n",
            "Epoch 111/150 - 0.06s - loss: 1.0889 - acc: 0.3907 - val_loss: 1.0876 - val_acc: 0.3927\n",
            "Epoch 112/150 - 0.06s - loss: 1.0887 - acc: 0.3911 - val_loss: 1.0875 - val_acc: 0.3927\n",
            "Epoch 113/150 - 0.06s - loss: 1.0886 - acc: 0.3920 - val_loss: 1.0874 - val_acc: 0.3947\n",
            "Epoch 114/150 - 0.06s - loss: 1.0885 - acc: 0.3923 - val_loss: 1.0873 - val_acc: 0.3947\n",
            "Epoch 115/150 - 0.06s - loss: 1.0884 - acc: 0.3918 - val_loss: 1.0872 - val_acc: 0.3968\n",
            "Epoch 116/150 - 0.06s - loss: 1.0883 - acc: 0.3923 - val_loss: 1.0871 - val_acc: 0.3947\n",
            "Epoch 117/150 - 0.06s - loss: 1.0882 - acc: 0.3929 - val_loss: 1.0870 - val_acc: 0.3947\n",
            "Epoch 118/150 - 0.06s - loss: 1.0881 - acc: 0.3938 - val_loss: 1.0870 - val_acc: 0.3968\n",
            "Epoch 119/150 - 0.06s - loss: 1.0880 - acc: 0.3947 - val_loss: 1.0869 - val_acc: 0.3968\n",
            "Epoch 120/150 - 0.06s - loss: 1.0879 - acc: 0.3947 - val_loss: 1.0868 - val_acc: 0.3968\n",
            "Epoch 121/150 - 0.06s - loss: 1.0877 - acc: 0.3945 - val_loss: 1.0867 - val_acc: 0.3968\n",
            "Epoch 122/150 - 0.06s - loss: 1.0876 - acc: 0.3947 - val_loss: 1.0866 - val_acc: 0.3968\n",
            "Epoch 123/150 - 0.06s - loss: 1.0875 - acc: 0.3938 - val_loss: 1.0865 - val_acc: 0.3947\n",
            "Epoch 124/150 - 0.06s - loss: 1.0874 - acc: 0.3947 - val_loss: 1.0864 - val_acc: 0.3968\n",
            "Epoch 125/150 - 0.06s - loss: 1.0873 - acc: 0.3954 - val_loss: 1.0863 - val_acc: 0.3988\n",
            "Epoch 126/150 - 0.06s - loss: 1.0872 - acc: 0.3961 - val_loss: 1.0863 - val_acc: 0.3988\n",
            "Epoch 127/150 - 0.06s - loss: 1.0871 - acc: 0.3959 - val_loss: 1.0862 - val_acc: 0.3988\n",
            "Epoch 128/150 - 0.06s - loss: 1.0870 - acc: 0.3974 - val_loss: 1.0861 - val_acc: 0.3988\n",
            "Epoch 129/150 - 0.06s - loss: 1.0869 - acc: 0.3986 - val_loss: 1.0860 - val_acc: 0.3968\n",
            "Epoch 130/150 - 0.07s - loss: 1.0868 - acc: 0.3986 - val_loss: 1.0859 - val_acc: 0.3968\n",
            "Epoch 131/150 - 0.06s - loss: 1.0866 - acc: 0.3986 - val_loss: 1.0858 - val_acc: 0.3968\n",
            "Epoch 132/150 - 0.06s - loss: 1.0865 - acc: 0.3983 - val_loss: 1.0857 - val_acc: 0.3968\n",
            "Epoch 133/150 - 0.06s - loss: 1.0864 - acc: 0.3988 - val_loss: 1.0857 - val_acc: 0.3968\n",
            "Epoch 134/150 - 0.06s - loss: 1.0863 - acc: 0.3990 - val_loss: 1.0856 - val_acc: 0.3988\n",
            "Epoch 135/150 - 0.06s - loss: 1.0862 - acc: 0.3992 - val_loss: 1.0855 - val_acc: 0.3988\n",
            "Epoch 136/150 - 0.06s - loss: 1.0861 - acc: 0.3992 - val_loss: 1.0854 - val_acc: 0.3988\n",
            "Epoch 137/150 - 0.06s - loss: 1.0860 - acc: 0.3992 - val_loss: 1.0853 - val_acc: 0.3988\n",
            "Epoch 138/150 - 0.06s - loss: 1.0859 - acc: 0.3997 - val_loss: 1.0852 - val_acc: 0.4028\n",
            "Epoch 139/150 - 0.06s - loss: 1.0858 - acc: 0.4001 - val_loss: 1.0851 - val_acc: 0.4049\n",
            "Epoch 140/150 - 0.06s - loss: 1.0857 - acc: 0.4004 - val_loss: 1.0851 - val_acc: 0.4049\n",
            "Epoch 141/150 - 0.06s - loss: 1.0856 - acc: 0.4004 - val_loss: 1.0850 - val_acc: 0.4069\n",
            "Epoch 142/150 - 0.06s - loss: 1.0855 - acc: 0.3999 - val_loss: 1.0849 - val_acc: 0.4069\n",
            "Epoch 143/150 - 0.06s - loss: 1.0854 - acc: 0.3990 - val_loss: 1.0848 - val_acc: 0.4089\n",
            "Epoch 144/150 - 0.06s - loss: 1.0853 - acc: 0.4004 - val_loss: 1.0847 - val_acc: 0.4089\n",
            "Epoch 145/150 - 0.06s - loss: 1.0852 - acc: 0.4019 - val_loss: 1.0846 - val_acc: 0.4109\n",
            "Epoch 146/150 - 0.06s - loss: 1.0851 - acc: 0.4015 - val_loss: 1.0845 - val_acc: 0.4089\n",
            "Epoch 147/150 - 0.06s - loss: 1.0850 - acc: 0.4015 - val_loss: 1.0845 - val_acc: 0.4069\n",
            "Epoch 148/150 - 0.06s - loss: 1.0849 - acc: 0.4017 - val_loss: 1.0844 - val_acc: 0.4069\n",
            "Epoch 149/150 - 0.07s - loss: 1.0848 - acc: 0.4026 - val_loss: 1.0843 - val_acc: 0.4089\n",
            "Epoch 150/150 - 0.06s - loss: 1.0846 - acc: 0.4031 - val_loss: 1.0842 - val_acc: 0.4069\n",
            "\n",
            "Combination 52/252:\n",
            "Hidden Layers: [128, 64], Activation: relu, Learning Rate: 0.0001, Batch Size: 64, Epochs: 50\n",
            "Epoch 1/50 - 0.05s - loss: 1.1046 - acc: 0.3221 - val_loss: 1.1067 - val_acc: 0.3057\n",
            "Epoch 2/50 - 0.05s - loss: 1.1044 - acc: 0.3223 - val_loss: 1.1065 - val_acc: 0.3077\n",
            "Epoch 3/50 - 0.05s - loss: 1.1042 - acc: 0.3223 - val_loss: 1.1063 - val_acc: 0.3036\n",
            "Epoch 4/50 - 0.05s - loss: 1.1040 - acc: 0.3234 - val_loss: 1.1061 - val_acc: 0.3016\n",
            "Epoch 5/50 - 0.05s - loss: 1.1039 - acc: 0.3225 - val_loss: 1.1059 - val_acc: 0.2996\n",
            "Epoch 6/50 - 0.05s - loss: 1.1037 - acc: 0.3216 - val_loss: 1.1057 - val_acc: 0.3016\n",
            "Epoch 7/50 - 0.05s - loss: 1.1036 - acc: 0.3219 - val_loss: 1.1055 - val_acc: 0.3016\n",
            "Epoch 8/50 - 0.05s - loss: 1.1034 - acc: 0.3230 - val_loss: 1.1053 - val_acc: 0.3036\n",
            "Epoch 9/50 - 0.05s - loss: 1.1033 - acc: 0.3234 - val_loss: 1.1051 - val_acc: 0.3036\n",
            "Epoch 10/50 - 0.06s - loss: 1.1031 - acc: 0.3230 - val_loss: 1.1049 - val_acc: 0.3077\n",
            "Epoch 11/50 - 0.05s - loss: 1.1030 - acc: 0.3230 - val_loss: 1.1048 - val_acc: 0.3057\n",
            "Epoch 12/50 - 0.05s - loss: 1.1028 - acc: 0.3223 - val_loss: 1.1046 - val_acc: 0.3036\n",
            "Epoch 13/50 - 0.06s - loss: 1.1027 - acc: 0.3225 - val_loss: 1.1044 - val_acc: 0.3057\n",
            "Epoch 14/50 - 0.05s - loss: 1.1026 - acc: 0.3223 - val_loss: 1.1043 - val_acc: 0.3077\n",
            "Epoch 15/50 - 0.05s - loss: 1.1024 - acc: 0.3230 - val_loss: 1.1041 - val_acc: 0.3097\n",
            "Epoch 16/50 - 0.05s - loss: 1.1023 - acc: 0.3239 - val_loss: 1.1039 - val_acc: 0.3117\n",
            "Epoch 17/50 - 0.05s - loss: 1.1022 - acc: 0.3239 - val_loss: 1.1038 - val_acc: 0.3117\n",
            "Epoch 18/50 - 0.05s - loss: 1.1020 - acc: 0.3237 - val_loss: 1.1036 - val_acc: 0.3138\n",
            "Epoch 19/50 - 0.05s - loss: 1.1019 - acc: 0.3234 - val_loss: 1.1035 - val_acc: 0.3138\n",
            "Epoch 20/50 - 0.05s - loss: 1.1018 - acc: 0.3237 - val_loss: 1.1033 - val_acc: 0.3117\n",
            "Epoch 21/50 - 0.06s - loss: 1.1017 - acc: 0.3252 - val_loss: 1.1032 - val_acc: 0.3138\n",
            "Epoch 22/50 - 0.05s - loss: 1.1016 - acc: 0.3255 - val_loss: 1.1031 - val_acc: 0.3117\n",
            "Epoch 23/50 - 0.05s - loss: 1.1015 - acc: 0.3252 - val_loss: 1.1029 - val_acc: 0.3117\n",
            "Epoch 24/50 - 0.05s - loss: 1.1013 - acc: 0.3257 - val_loss: 1.1028 - val_acc: 0.3117\n",
            "Epoch 25/50 - 0.05s - loss: 1.1012 - acc: 0.3275 - val_loss: 1.1027 - val_acc: 0.3097\n",
            "Epoch 26/50 - 0.05s - loss: 1.1011 - acc: 0.3282 - val_loss: 1.1025 - val_acc: 0.3138\n",
            "Epoch 27/50 - 0.05s - loss: 1.1010 - acc: 0.3284 - val_loss: 1.1024 - val_acc: 0.3138\n",
            "Epoch 28/50 - 0.05s - loss: 1.1009 - acc: 0.3284 - val_loss: 1.1023 - val_acc: 0.3117\n",
            "Epoch 29/50 - 0.05s - loss: 1.1008 - acc: 0.3282 - val_loss: 1.1022 - val_acc: 0.3097\n",
            "Epoch 30/50 - 0.05s - loss: 1.1007 - acc: 0.3288 - val_loss: 1.1020 - val_acc: 0.3077\n",
            "Epoch 31/50 - 0.05s - loss: 1.1006 - acc: 0.3295 - val_loss: 1.1019 - val_acc: 0.3077\n",
            "Epoch 32/50 - 0.05s - loss: 1.1005 - acc: 0.3279 - val_loss: 1.1018 - val_acc: 0.3077\n",
            "Epoch 33/50 - 0.05s - loss: 1.1004 - acc: 0.3277 - val_loss: 1.1017 - val_acc: 0.3057\n",
            "Epoch 34/50 - 0.05s - loss: 1.1003 - acc: 0.3284 - val_loss: 1.1016 - val_acc: 0.3057\n",
            "Epoch 35/50 - 0.05s - loss: 1.1002 - acc: 0.3261 - val_loss: 1.1015 - val_acc: 0.3036\n",
            "Epoch 36/50 - 0.05s - loss: 1.1001 - acc: 0.3279 - val_loss: 1.1014 - val_acc: 0.3036\n",
            "Epoch 37/50 - 0.05s - loss: 1.1000 - acc: 0.3288 - val_loss: 1.1013 - val_acc: 0.3057\n",
            "Epoch 38/50 - 0.05s - loss: 1.1000 - acc: 0.3291 - val_loss: 1.1012 - val_acc: 0.3117\n",
            "Epoch 39/50 - 0.05s - loss: 1.0999 - acc: 0.3300 - val_loss: 1.1011 - val_acc: 0.3117\n",
            "Epoch 40/50 - 0.05s - loss: 1.0998 - acc: 0.3295 - val_loss: 1.1010 - val_acc: 0.3097\n",
            "Epoch 41/50 - 0.05s - loss: 1.0997 - acc: 0.3304 - val_loss: 1.1009 - val_acc: 0.3158\n",
            "Epoch 42/50 - 0.05s - loss: 1.0996 - acc: 0.3306 - val_loss: 1.1008 - val_acc: 0.3117\n",
            "Epoch 43/50 - 0.05s - loss: 1.0995 - acc: 0.3315 - val_loss: 1.1007 - val_acc: 0.3097\n",
            "Epoch 44/50 - 0.05s - loss: 1.0994 - acc: 0.3309 - val_loss: 1.1006 - val_acc: 0.3097\n",
            "Epoch 45/50 - 0.05s - loss: 1.0994 - acc: 0.3300 - val_loss: 1.1005 - val_acc: 0.3077\n",
            "Epoch 46/50 - 0.06s - loss: 1.0993 - acc: 0.3304 - val_loss: 1.1004 - val_acc: 0.3077\n",
            "Epoch 47/50 - 0.05s - loss: 1.0992 - acc: 0.3304 - val_loss: 1.1003 - val_acc: 0.3077\n",
            "Epoch 48/50 - 0.05s - loss: 1.0991 - acc: 0.3302 - val_loss: 1.1002 - val_acc: 0.3077\n",
            "Epoch 49/50 - 0.06s - loss: 1.0990 - acc: 0.3306 - val_loss: 1.1001 - val_acc: 0.3077\n",
            "Epoch 50/50 - 0.07s - loss: 1.0990 - acc: 0.3291 - val_loss: 1.1000 - val_acc: 0.3097\n",
            "\n",
            "Combination 53/252:\n",
            "Hidden Layers: [128, 64], Activation: relu, Learning Rate: 0.0001, Batch Size: 64, Epochs: 100\n",
            "Epoch 1/100 - 0.06s - loss: 1.1328 - acc: 0.3489 - val_loss: 1.1343 - val_acc: 0.3502\n",
            "Epoch 2/100 - 0.05s - loss: 1.1306 - acc: 0.3489 - val_loss: 1.1323 - val_acc: 0.3502\n",
            "Epoch 3/100 - 0.05s - loss: 1.1286 - acc: 0.3489 - val_loss: 1.1304 - val_acc: 0.3502\n",
            "Epoch 4/100 - 0.05s - loss: 1.1266 - acc: 0.3491 - val_loss: 1.1286 - val_acc: 0.3502\n",
            "Epoch 5/100 - 0.05s - loss: 1.1248 - acc: 0.3493 - val_loss: 1.1270 - val_acc: 0.3502\n",
            "Epoch 6/100 - 0.05s - loss: 1.1231 - acc: 0.3486 - val_loss: 1.1255 - val_acc: 0.3502\n",
            "Epoch 7/100 - 0.05s - loss: 1.1216 - acc: 0.3484 - val_loss: 1.1241 - val_acc: 0.3482\n",
            "Epoch 8/100 - 0.05s - loss: 1.1201 - acc: 0.3486 - val_loss: 1.1227 - val_acc: 0.3482\n",
            "Epoch 9/100 - 0.06s - loss: 1.1187 - acc: 0.3489 - val_loss: 1.1215 - val_acc: 0.3482\n",
            "Epoch 10/100 - 0.06s - loss: 1.1174 - acc: 0.3489 - val_loss: 1.1203 - val_acc: 0.3502\n",
            "Epoch 11/100 - 0.05s - loss: 1.1161 - acc: 0.3493 - val_loss: 1.1192 - val_acc: 0.3502\n",
            "Epoch 12/100 - 0.05s - loss: 1.1150 - acc: 0.3495 - val_loss: 1.1182 - val_acc: 0.3502\n",
            "Epoch 13/100 - 0.05s - loss: 1.1139 - acc: 0.3500 - val_loss: 1.1172 - val_acc: 0.3502\n",
            "Epoch 14/100 - 0.05s - loss: 1.1128 - acc: 0.3498 - val_loss: 1.1163 - val_acc: 0.3502\n",
            "Epoch 15/100 - 0.05s - loss: 1.1119 - acc: 0.3491 - val_loss: 1.1154 - val_acc: 0.3482\n",
            "Epoch 16/100 - 0.05s - loss: 1.1110 - acc: 0.3491 - val_loss: 1.1146 - val_acc: 0.3462\n",
            "Epoch 17/100 - 0.05s - loss: 1.1101 - acc: 0.3486 - val_loss: 1.1139 - val_acc: 0.3462\n",
            "Epoch 18/100 - 0.05s - loss: 1.1093 - acc: 0.3486 - val_loss: 1.1132 - val_acc: 0.3502\n",
            "Epoch 19/100 - 0.06s - loss: 1.1085 - acc: 0.3482 - val_loss: 1.1125 - val_acc: 0.3502\n",
            "Epoch 20/100 - 0.05s - loss: 1.1078 - acc: 0.3491 - val_loss: 1.1118 - val_acc: 0.3502\n",
            "Epoch 21/100 - 0.05s - loss: 1.1071 - acc: 0.3500 - val_loss: 1.1112 - val_acc: 0.3482\n",
            "Epoch 22/100 - 0.05s - loss: 1.1064 - acc: 0.3511 - val_loss: 1.1107 - val_acc: 0.3482\n",
            "Epoch 23/100 - 0.05s - loss: 1.1058 - acc: 0.3500 - val_loss: 1.1101 - val_acc: 0.3502\n",
            "Epoch 24/100 - 0.05s - loss: 1.1052 - acc: 0.3498 - val_loss: 1.1096 - val_acc: 0.3502\n",
            "Epoch 25/100 - 0.05s - loss: 1.1047 - acc: 0.3502 - val_loss: 1.1091 - val_acc: 0.3502\n",
            "Epoch 26/100 - 0.05s - loss: 1.1041 - acc: 0.3493 - val_loss: 1.1086 - val_acc: 0.3502\n",
            "Epoch 27/100 - 0.05s - loss: 1.1036 - acc: 0.3498 - val_loss: 1.1082 - val_acc: 0.3522\n",
            "Epoch 28/100 - 0.05s - loss: 1.1031 - acc: 0.3493 - val_loss: 1.1078 - val_acc: 0.3502\n",
            "Epoch 29/100 - 0.05s - loss: 1.1027 - acc: 0.3484 - val_loss: 1.1074 - val_acc: 0.3502\n",
            "Epoch 30/100 - 0.05s - loss: 1.1022 - acc: 0.3500 - val_loss: 1.1070 - val_acc: 0.3502\n",
            "Epoch 31/100 - 0.05s - loss: 1.1018 - acc: 0.3486 - val_loss: 1.1067 - val_acc: 0.3502\n",
            "Epoch 32/100 - 0.05s - loss: 1.1014 - acc: 0.3493 - val_loss: 1.1063 - val_acc: 0.3482\n",
            "Epoch 33/100 - 0.05s - loss: 1.1011 - acc: 0.3493 - val_loss: 1.1060 - val_acc: 0.3482\n",
            "Epoch 34/100 - 0.05s - loss: 1.1007 - acc: 0.3473 - val_loss: 1.1057 - val_acc: 0.3482\n",
            "Epoch 35/100 - 0.05s - loss: 1.1003 - acc: 0.3462 - val_loss: 1.1054 - val_acc: 0.3543\n",
            "Epoch 36/100 - 0.05s - loss: 1.1000 - acc: 0.3482 - val_loss: 1.1052 - val_acc: 0.3563\n",
            "Epoch 37/100 - 0.05s - loss: 1.0997 - acc: 0.3500 - val_loss: 1.1049 - val_acc: 0.3543\n",
            "Epoch 38/100 - 0.05s - loss: 1.0994 - acc: 0.3513 - val_loss: 1.1047 - val_acc: 0.3543\n",
            "Epoch 39/100 - 0.05s - loss: 1.0991 - acc: 0.3507 - val_loss: 1.1044 - val_acc: 0.3543\n",
            "Epoch 40/100 - 0.05s - loss: 1.0988 - acc: 0.3511 - val_loss: 1.1042 - val_acc: 0.3563\n",
            "Epoch 41/100 - 0.05s - loss: 1.0985 - acc: 0.3509 - val_loss: 1.1040 - val_acc: 0.3583\n",
            "Epoch 42/100 - 0.05s - loss: 1.0983 - acc: 0.3504 - val_loss: 1.1038 - val_acc: 0.3603\n",
            "Epoch 43/100 - 0.05s - loss: 1.0980 - acc: 0.3495 - val_loss: 1.1036 - val_acc: 0.3603\n",
            "Epoch 44/100 - 0.06s - loss: 1.0978 - acc: 0.3498 - val_loss: 1.1034 - val_acc: 0.3603\n",
            "Epoch 45/100 - 0.05s - loss: 1.0976 - acc: 0.3480 - val_loss: 1.1032 - val_acc: 0.3583\n",
            "Epoch 46/100 - 0.05s - loss: 1.0974 - acc: 0.3477 - val_loss: 1.1030 - val_acc: 0.3522\n",
            "Epoch 47/100 - 0.05s - loss: 1.0972 - acc: 0.3484 - val_loss: 1.1029 - val_acc: 0.3543\n",
            "Epoch 48/100 - 0.05s - loss: 1.0970 - acc: 0.3482 - val_loss: 1.1027 - val_acc: 0.3543\n",
            "Epoch 49/100 - 0.05s - loss: 1.0968 - acc: 0.3495 - val_loss: 1.1025 - val_acc: 0.3543\n",
            "Epoch 50/100 - 0.05s - loss: 1.0966 - acc: 0.3511 - val_loss: 1.1024 - val_acc: 0.3543\n",
            "Epoch 51/100 - 0.05s - loss: 1.0964 - acc: 0.3520 - val_loss: 1.1022 - val_acc: 0.3522\n",
            "Epoch 52/100 - 0.05s - loss: 1.0962 - acc: 0.3525 - val_loss: 1.1021 - val_acc: 0.3522\n",
            "Epoch 53/100 - 0.05s - loss: 1.0960 - acc: 0.3547 - val_loss: 1.1020 - val_acc: 0.3583\n",
            "Epoch 54/100 - 0.05s - loss: 1.0958 - acc: 0.3554 - val_loss: 1.1018 - val_acc: 0.3583\n",
            "Epoch 55/100 - 0.05s - loss: 1.0957 - acc: 0.3561 - val_loss: 1.1017 - val_acc: 0.3603\n",
            "Epoch 56/100 - 0.05s - loss: 1.0955 - acc: 0.3565 - val_loss: 1.1016 - val_acc: 0.3704\n",
            "Epoch 57/100 - 0.05s - loss: 1.0954 - acc: 0.3590 - val_loss: 1.1015 - val_acc: 0.3644\n",
            "Epoch 58/100 - 0.05s - loss: 1.0952 - acc: 0.3599 - val_loss: 1.1013 - val_acc: 0.3684\n",
            "Epoch 59/100 - 0.05s - loss: 1.0950 - acc: 0.3605 - val_loss: 1.1012 - val_acc: 0.3644\n",
            "Epoch 60/100 - 0.05s - loss: 1.0949 - acc: 0.3621 - val_loss: 1.1011 - val_acc: 0.3644\n",
            "Epoch 61/100 - 0.05s - loss: 1.0948 - acc: 0.3641 - val_loss: 1.1010 - val_acc: 0.3623\n",
            "Epoch 62/100 - 0.06s - loss: 1.0946 - acc: 0.3641 - val_loss: 1.1009 - val_acc: 0.3543\n",
            "Epoch 63/100 - 0.06s - loss: 1.0945 - acc: 0.3632 - val_loss: 1.1008 - val_acc: 0.3583\n",
            "Epoch 64/100 - 0.05s - loss: 1.0943 - acc: 0.3653 - val_loss: 1.1007 - val_acc: 0.3623\n",
            "Epoch 65/100 - 0.05s - loss: 1.0942 - acc: 0.3657 - val_loss: 1.1006 - val_acc: 0.3623\n",
            "Epoch 66/100 - 0.05s - loss: 1.0941 - acc: 0.3680 - val_loss: 1.1005 - val_acc: 0.3664\n",
            "Epoch 67/100 - 0.06s - loss: 1.0940 - acc: 0.3700 - val_loss: 1.1004 - val_acc: 0.3644\n",
            "Epoch 68/100 - 0.05s - loss: 1.0938 - acc: 0.3700 - val_loss: 1.1003 - val_acc: 0.3664\n",
            "Epoch 69/100 - 0.05s - loss: 1.0937 - acc: 0.3698 - val_loss: 1.1002 - val_acc: 0.3603\n",
            "Epoch 70/100 - 0.05s - loss: 1.0936 - acc: 0.3682 - val_loss: 1.1001 - val_acc: 0.3563\n",
            "Epoch 71/100 - 0.05s - loss: 1.0935 - acc: 0.3689 - val_loss: 1.1000 - val_acc: 0.3563\n",
            "Epoch 72/100 - 0.05s - loss: 1.0934 - acc: 0.3698 - val_loss: 1.1000 - val_acc: 0.3563\n",
            "Epoch 73/100 - 0.05s - loss: 1.0933 - acc: 0.3707 - val_loss: 1.0999 - val_acc: 0.3563\n",
            "Epoch 74/100 - 0.05s - loss: 1.0932 - acc: 0.3704 - val_loss: 1.0998 - val_acc: 0.3543\n",
            "Epoch 75/100 - 0.05s - loss: 1.0931 - acc: 0.3707 - val_loss: 1.0997 - val_acc: 0.3482\n",
            "Epoch 76/100 - 0.05s - loss: 1.0930 - acc: 0.3713 - val_loss: 1.0996 - val_acc: 0.3482\n",
            "Epoch 77/100 - 0.05s - loss: 1.0929 - acc: 0.3711 - val_loss: 1.0995 - val_acc: 0.3482\n",
            "Epoch 78/100 - 0.05s - loss: 1.0928 - acc: 0.3740 - val_loss: 1.0995 - val_acc: 0.3441\n",
            "Epoch 79/100 - 0.05s - loss: 1.0927 - acc: 0.3731 - val_loss: 1.0994 - val_acc: 0.3421\n",
            "Epoch 80/100 - 0.05s - loss: 1.0926 - acc: 0.3738 - val_loss: 1.0993 - val_acc: 0.3441\n",
            "Epoch 81/100 - 0.05s - loss: 1.0925 - acc: 0.3752 - val_loss: 1.0992 - val_acc: 0.3462\n",
            "Epoch 82/100 - 0.05s - loss: 1.0924 - acc: 0.3752 - val_loss: 1.0992 - val_acc: 0.3482\n",
            "Epoch 83/100 - 0.05s - loss: 1.0923 - acc: 0.3763 - val_loss: 1.0991 - val_acc: 0.3502\n",
            "Epoch 84/100 - 0.05s - loss: 1.0922 - acc: 0.3758 - val_loss: 1.0990 - val_acc: 0.3522\n",
            "Epoch 85/100 - 0.05s - loss: 1.0921 - acc: 0.3765 - val_loss: 1.0989 - val_acc: 0.3563\n",
            "Epoch 86/100 - 0.05s - loss: 1.0920 - acc: 0.3776 - val_loss: 1.0989 - val_acc: 0.3603\n",
            "Epoch 87/100 - 0.06s - loss: 1.0919 - acc: 0.3785 - val_loss: 1.0988 - val_acc: 0.3583\n",
            "Epoch 88/100 - 0.06s - loss: 1.0918 - acc: 0.3794 - val_loss: 1.0987 - val_acc: 0.3583\n",
            "Epoch 89/100 - 0.06s - loss: 1.0917 - acc: 0.3808 - val_loss: 1.0986 - val_acc: 0.3603\n",
            "Epoch 90/100 - 0.06s - loss: 1.0916 - acc: 0.3821 - val_loss: 1.0986 - val_acc: 0.3623\n",
            "Epoch 91/100 - 0.07s - loss: 1.0916 - acc: 0.3830 - val_loss: 1.0985 - val_acc: 0.3644\n",
            "Epoch 92/100 - 0.05s - loss: 1.0915 - acc: 0.3821 - val_loss: 1.0984 - val_acc: 0.3603\n",
            "Epoch 93/100 - 0.05s - loss: 1.0914 - acc: 0.3810 - val_loss: 1.0984 - val_acc: 0.3644\n",
            "Epoch 94/100 - 0.05s - loss: 1.0913 - acc: 0.3806 - val_loss: 1.0983 - val_acc: 0.3623\n",
            "Epoch 95/100 - 0.05s - loss: 1.0912 - acc: 0.3801 - val_loss: 1.0982 - val_acc: 0.3623\n",
            "Epoch 96/100 - 0.05s - loss: 1.0911 - acc: 0.3790 - val_loss: 1.0982 - val_acc: 0.3623\n",
            "Epoch 97/100 - 0.05s - loss: 1.0910 - acc: 0.3790 - val_loss: 1.0981 - val_acc: 0.3644\n",
            "Epoch 98/100 - 0.05s - loss: 1.0910 - acc: 0.3772 - val_loss: 1.0980 - val_acc: 0.3603\n",
            "Epoch 99/100 - 0.05s - loss: 1.0909 - acc: 0.3783 - val_loss: 1.0980 - val_acc: 0.3603\n",
            "Epoch 100/100 - 0.05s - loss: 1.0908 - acc: 0.3781 - val_loss: 1.0979 - val_acc: 0.3603\n",
            "\n",
            "Combination 54/252:\n",
            "Hidden Layers: [128, 64], Activation: relu, Learning Rate: 0.0001, Batch Size: 64, Epochs: 150\n",
            "Epoch 1/150 - 0.05s - loss: 1.1440 - acc: 0.3243 - val_loss: 1.1383 - val_acc: 0.3340\n",
            "Epoch 2/150 - 0.05s - loss: 1.1368 - acc: 0.3239 - val_loss: 1.1317 - val_acc: 0.3320\n",
            "Epoch 3/150 - 0.05s - loss: 1.1306 - acc: 0.3257 - val_loss: 1.1261 - val_acc: 0.3401\n",
            "Epoch 4/150 - 0.05s - loss: 1.1253 - acc: 0.3293 - val_loss: 1.1214 - val_acc: 0.3360\n",
            "Epoch 5/150 - 0.05s - loss: 1.1208 - acc: 0.3322 - val_loss: 1.1173 - val_acc: 0.3340\n",
            "Epoch 6/150 - 0.05s - loss: 1.1169 - acc: 0.3351 - val_loss: 1.1138 - val_acc: 0.3381\n",
            "Epoch 7/150 - 0.05s - loss: 1.1136 - acc: 0.3367 - val_loss: 1.1109 - val_acc: 0.3381\n",
            "Epoch 8/150 - 0.05s - loss: 1.1106 - acc: 0.3403 - val_loss: 1.1083 - val_acc: 0.3421\n",
            "Epoch 9/150 - 0.05s - loss: 1.1081 - acc: 0.3405 - val_loss: 1.1061 - val_acc: 0.3421\n",
            "Epoch 10/150 - 0.05s - loss: 1.1059 - acc: 0.3417 - val_loss: 1.1042 - val_acc: 0.3381\n",
            "Epoch 11/150 - 0.05s - loss: 1.1040 - acc: 0.3432 - val_loss: 1.1026 - val_acc: 0.3502\n",
            "Epoch 12/150 - 0.05s - loss: 1.1024 - acc: 0.3473 - val_loss: 1.1012 - val_acc: 0.3563\n",
            "Epoch 13/150 - 0.05s - loss: 1.1009 - acc: 0.3504 - val_loss: 1.1000 - val_acc: 0.3543\n",
            "Epoch 14/150 - 0.06s - loss: 1.0996 - acc: 0.3507 - val_loss: 1.0989 - val_acc: 0.3543\n",
            "Epoch 15/150 - 0.06s - loss: 1.0985 - acc: 0.3545 - val_loss: 1.0980 - val_acc: 0.3623\n",
            "Epoch 16/150 - 0.05s - loss: 1.0975 - acc: 0.3545 - val_loss: 1.0972 - val_acc: 0.3603\n",
            "Epoch 17/150 - 0.05s - loss: 1.0966 - acc: 0.3599 - val_loss: 1.0964 - val_acc: 0.3563\n",
            "Epoch 18/150 - 0.05s - loss: 1.0958 - acc: 0.3621 - val_loss: 1.0958 - val_acc: 0.3563\n",
            "Epoch 19/150 - 0.05s - loss: 1.0951 - acc: 0.3623 - val_loss: 1.0952 - val_acc: 0.3664\n",
            "Epoch 20/150 - 0.05s - loss: 1.0945 - acc: 0.3635 - val_loss: 1.0947 - val_acc: 0.3745\n",
            "Epoch 21/150 - 0.05s - loss: 1.0939 - acc: 0.3648 - val_loss: 1.0943 - val_acc: 0.3664\n",
            "Epoch 22/150 - 0.05s - loss: 1.0934 - acc: 0.3653 - val_loss: 1.0939 - val_acc: 0.3745\n",
            "Epoch 23/150 - 0.06s - loss: 1.0929 - acc: 0.3668 - val_loss: 1.0935 - val_acc: 0.3765\n",
            "Epoch 24/150 - 0.05s - loss: 1.0925 - acc: 0.3675 - val_loss: 1.0932 - val_acc: 0.3806\n",
            "Epoch 25/150 - 0.05s - loss: 1.0921 - acc: 0.3682 - val_loss: 1.0929 - val_acc: 0.3765\n",
            "Epoch 26/150 - 0.06s - loss: 1.0918 - acc: 0.3689 - val_loss: 1.0927 - val_acc: 0.3745\n",
            "Epoch 27/150 - 0.05s - loss: 1.0914 - acc: 0.3695 - val_loss: 1.0924 - val_acc: 0.3684\n",
            "Epoch 28/150 - 0.06s - loss: 1.0912 - acc: 0.3711 - val_loss: 1.0922 - val_acc: 0.3745\n",
            "Epoch 29/150 - 0.05s - loss: 1.0909 - acc: 0.3722 - val_loss: 1.0920 - val_acc: 0.3806\n",
            "Epoch 30/150 - 0.05s - loss: 1.0906 - acc: 0.3754 - val_loss: 1.0918 - val_acc: 0.3927\n",
            "Epoch 31/150 - 0.05s - loss: 1.0904 - acc: 0.3783 - val_loss: 1.0916 - val_acc: 0.3907\n",
            "Epoch 32/150 - 0.05s - loss: 1.0901 - acc: 0.3772 - val_loss: 1.0914 - val_acc: 0.3927\n",
            "Epoch 33/150 - 0.05s - loss: 1.0899 - acc: 0.3765 - val_loss: 1.0912 - val_acc: 0.3846\n",
            "Epoch 34/150 - 0.07s - loss: 1.0897 - acc: 0.3783 - val_loss: 1.0911 - val_acc: 0.3806\n",
            "Epoch 35/150 - 0.05s - loss: 1.0895 - acc: 0.3792 - val_loss: 1.0909 - val_acc: 0.3806\n",
            "Epoch 36/150 - 0.06s - loss: 1.0893 - acc: 0.3812 - val_loss: 1.0908 - val_acc: 0.3846\n",
            "Epoch 37/150 - 0.05s - loss: 1.0891 - acc: 0.3808 - val_loss: 1.0906 - val_acc: 0.3806\n",
            "Epoch 38/150 - 0.05s - loss: 1.0889 - acc: 0.3817 - val_loss: 1.0905 - val_acc: 0.3785\n",
            "Epoch 39/150 - 0.05s - loss: 1.0888 - acc: 0.3826 - val_loss: 1.0904 - val_acc: 0.3785\n",
            "Epoch 40/150 - 0.05s - loss: 1.0886 - acc: 0.3839 - val_loss: 1.0902 - val_acc: 0.3806\n",
            "Epoch 41/150 - 0.05s - loss: 1.0884 - acc: 0.3839 - val_loss: 1.0901 - val_acc: 0.3826\n",
            "Epoch 42/150 - 0.05s - loss: 1.0883 - acc: 0.3851 - val_loss: 1.0900 - val_acc: 0.3785\n",
            "Epoch 43/150 - 0.05s - loss: 1.0881 - acc: 0.3851 - val_loss: 1.0899 - val_acc: 0.3826\n",
            "Epoch 44/150 - 0.05s - loss: 1.0880 - acc: 0.3862 - val_loss: 1.0897 - val_acc: 0.3846\n",
            "Epoch 45/150 - 0.05s - loss: 1.0878 - acc: 0.3853 - val_loss: 1.0896 - val_acc: 0.3826\n",
            "Epoch 46/150 - 0.05s - loss: 1.0877 - acc: 0.3855 - val_loss: 1.0895 - val_acc: 0.3826\n",
            "Epoch 47/150 - 0.05s - loss: 1.0875 - acc: 0.3855 - val_loss: 1.0894 - val_acc: 0.3826\n",
            "Epoch 48/150 - 0.05s - loss: 1.0874 - acc: 0.3855 - val_loss: 1.0893 - val_acc: 0.3846\n",
            "Epoch 49/150 - 0.05s - loss: 1.0872 - acc: 0.3851 - val_loss: 1.0892 - val_acc: 0.3785\n",
            "Epoch 50/150 - 0.05s - loss: 1.0871 - acc: 0.3857 - val_loss: 1.0890 - val_acc: 0.3745\n",
            "Epoch 51/150 - 0.05s - loss: 1.0870 - acc: 0.3871 - val_loss: 1.0889 - val_acc: 0.3765\n",
            "Epoch 52/150 - 0.05s - loss: 1.0868 - acc: 0.3857 - val_loss: 1.0888 - val_acc: 0.3765\n",
            "Epoch 53/150 - 0.05s - loss: 1.0867 - acc: 0.3855 - val_loss: 1.0887 - val_acc: 0.3765\n",
            "Epoch 54/150 - 0.07s - loss: 1.0866 - acc: 0.3866 - val_loss: 1.0886 - val_acc: 0.3806\n",
            "Epoch 55/150 - 0.10s - loss: 1.0864 - acc: 0.3869 - val_loss: 1.0885 - val_acc: 0.3806\n",
            "Epoch 56/150 - 0.05s - loss: 1.0863 - acc: 0.3862 - val_loss: 1.0884 - val_acc: 0.3806\n",
            "Epoch 57/150 - 0.05s - loss: 1.0862 - acc: 0.3857 - val_loss: 1.0883 - val_acc: 0.3806\n",
            "Epoch 58/150 - 0.06s - loss: 1.0860 - acc: 0.3846 - val_loss: 1.0881 - val_acc: 0.3826\n",
            "Epoch 59/150 - 0.05s - loss: 1.0859 - acc: 0.3835 - val_loss: 1.0880 - val_acc: 0.3846\n",
            "Epoch 60/150 - 0.05s - loss: 1.0858 - acc: 0.3830 - val_loss: 1.0879 - val_acc: 0.3846\n",
            "Epoch 61/150 - 0.05s - loss: 1.0857 - acc: 0.3833 - val_loss: 1.0878 - val_acc: 0.3866\n",
            "Epoch 62/150 - 0.05s - loss: 1.0855 - acc: 0.3830 - val_loss: 1.0877 - val_acc: 0.3887\n",
            "Epoch 63/150 - 0.05s - loss: 1.0854 - acc: 0.3824 - val_loss: 1.0876 - val_acc: 0.3887\n",
            "Epoch 64/150 - 0.05s - loss: 1.0853 - acc: 0.3837 - val_loss: 1.0875 - val_acc: 0.3887\n",
            "Epoch 65/150 - 0.05s - loss: 1.0852 - acc: 0.3839 - val_loss: 1.0874 - val_acc: 0.3887\n",
            "Epoch 66/150 - 0.05s - loss: 1.0851 - acc: 0.3848 - val_loss: 1.0873 - val_acc: 0.3866\n",
            "Epoch 67/150 - 0.05s - loss: 1.0849 - acc: 0.3864 - val_loss: 1.0872 - val_acc: 0.3866\n",
            "Epoch 68/150 - 0.05s - loss: 1.0848 - acc: 0.3857 - val_loss: 1.0870 - val_acc: 0.3866\n",
            "Epoch 69/150 - 0.05s - loss: 1.0847 - acc: 0.3866 - val_loss: 1.0869 - val_acc: 0.3866\n",
            "Epoch 70/150 - 0.05s - loss: 1.0846 - acc: 0.3869 - val_loss: 1.0868 - val_acc: 0.3887\n",
            "Epoch 71/150 - 0.05s - loss: 1.0845 - acc: 0.3880 - val_loss: 1.0867 - val_acc: 0.3887\n",
            "Epoch 72/150 - 0.05s - loss: 1.0843 - acc: 0.3893 - val_loss: 1.0866 - val_acc: 0.3887\n",
            "Epoch 73/150 - 0.05s - loss: 1.0842 - acc: 0.3893 - val_loss: 1.0865 - val_acc: 0.3907\n",
            "Epoch 74/150 - 0.05s - loss: 1.0841 - acc: 0.3900 - val_loss: 1.0864 - val_acc: 0.3907\n",
            "Epoch 75/150 - 0.06s - loss: 1.0840 - acc: 0.3900 - val_loss: 1.0863 - val_acc: 0.3907\n",
            "Epoch 76/150 - 0.06s - loss: 1.0839 - acc: 0.3902 - val_loss: 1.0862 - val_acc: 0.3907\n",
            "Epoch 77/150 - 0.05s - loss: 1.0838 - acc: 0.3911 - val_loss: 1.0861 - val_acc: 0.3887\n",
            "Epoch 78/150 - 0.05s - loss: 1.0837 - acc: 0.3914 - val_loss: 1.0860 - val_acc: 0.3907\n",
            "Epoch 79/150 - 0.05s - loss: 1.0835 - acc: 0.3911 - val_loss: 1.0859 - val_acc: 0.3907\n",
            "Epoch 80/150 - 0.06s - loss: 1.0834 - acc: 0.3914 - val_loss: 1.0858 - val_acc: 0.3907\n",
            "Epoch 81/150 - 0.05s - loss: 1.0833 - acc: 0.3918 - val_loss: 1.0857 - val_acc: 0.3927\n",
            "Epoch 82/150 - 0.05s - loss: 1.0832 - acc: 0.3923 - val_loss: 1.0856 - val_acc: 0.3907\n",
            "Epoch 83/150 - 0.05s - loss: 1.0831 - acc: 0.3920 - val_loss: 1.0855 - val_acc: 0.3887\n",
            "Epoch 84/150 - 0.05s - loss: 1.0830 - acc: 0.3941 - val_loss: 1.0854 - val_acc: 0.3887\n",
            "Epoch 85/150 - 0.05s - loss: 1.0829 - acc: 0.3934 - val_loss: 1.0853 - val_acc: 0.3887\n",
            "Epoch 86/150 - 0.05s - loss: 1.0828 - acc: 0.3941 - val_loss: 1.0852 - val_acc: 0.3927\n",
            "Epoch 87/150 - 0.05s - loss: 1.0826 - acc: 0.3947 - val_loss: 1.0851 - val_acc: 0.3907\n",
            "Epoch 88/150 - 0.06s - loss: 1.0825 - acc: 0.3952 - val_loss: 1.0850 - val_acc: 0.3907\n",
            "Epoch 89/150 - 0.05s - loss: 1.0824 - acc: 0.3956 - val_loss: 1.0849 - val_acc: 0.3907\n",
            "Epoch 90/150 - 0.05s - loss: 1.0823 - acc: 0.3959 - val_loss: 1.0848 - val_acc: 0.3927\n",
            "Epoch 91/150 - 0.05s - loss: 1.0822 - acc: 0.3963 - val_loss: 1.0847 - val_acc: 0.3947\n",
            "Epoch 92/150 - 0.05s - loss: 1.0821 - acc: 0.3970 - val_loss: 1.0846 - val_acc: 0.3947\n",
            "Epoch 93/150 - 0.05s - loss: 1.0820 - acc: 0.3963 - val_loss: 1.0845 - val_acc: 0.3968\n",
            "Epoch 94/150 - 0.05s - loss: 1.0819 - acc: 0.3965 - val_loss: 1.0844 - val_acc: 0.3968\n",
            "Epoch 95/150 - 0.05s - loss: 1.0818 - acc: 0.3972 - val_loss: 1.0843 - val_acc: 0.3968\n",
            "Epoch 96/150 - 0.05s - loss: 1.0817 - acc: 0.3974 - val_loss: 1.0842 - val_acc: 0.3968\n",
            "Epoch 97/150 - 0.05s - loss: 1.0816 - acc: 0.3974 - val_loss: 1.0841 - val_acc: 0.3947\n",
            "Epoch 98/150 - 0.05s - loss: 1.0814 - acc: 0.3979 - val_loss: 1.0840 - val_acc: 0.3968\n",
            "Epoch 99/150 - 0.05s - loss: 1.0813 - acc: 0.3990 - val_loss: 1.0839 - val_acc: 0.3988\n",
            "Epoch 100/150 - 0.05s - loss: 1.0812 - acc: 0.3988 - val_loss: 1.0838 - val_acc: 0.3988\n",
            "Epoch 101/150 - 0.05s - loss: 1.0811 - acc: 0.3988 - val_loss: 1.0837 - val_acc: 0.3968\n",
            "Epoch 102/150 - 0.06s - loss: 1.0810 - acc: 0.3995 - val_loss: 1.0836 - val_acc: 0.3988\n",
            "Epoch 103/150 - 0.05s - loss: 1.0809 - acc: 0.3988 - val_loss: 1.0835 - val_acc: 0.3988\n",
            "Epoch 104/150 - 0.05s - loss: 1.0808 - acc: 0.3995 - val_loss: 1.0834 - val_acc: 0.4008\n",
            "Epoch 105/150 - 0.05s - loss: 1.0807 - acc: 0.3997 - val_loss: 1.0833 - val_acc: 0.4028\n",
            "Epoch 106/150 - 0.05s - loss: 1.0806 - acc: 0.3997 - val_loss: 1.0832 - val_acc: 0.4049\n",
            "Epoch 107/150 - 0.05s - loss: 1.0805 - acc: 0.3999 - val_loss: 1.0831 - val_acc: 0.4049\n",
            "Epoch 108/150 - 0.05s - loss: 1.0804 - acc: 0.4008 - val_loss: 1.0830 - val_acc: 0.4049\n",
            "Epoch 109/150 - 0.05s - loss: 1.0803 - acc: 0.4019 - val_loss: 1.0829 - val_acc: 0.4049\n",
            "Epoch 110/150 - 0.05s - loss: 1.0802 - acc: 0.4026 - val_loss: 1.0828 - val_acc: 0.4069\n",
            "Epoch 111/150 - 0.05s - loss: 1.0801 - acc: 0.4026 - val_loss: 1.0827 - val_acc: 0.4069\n",
            "Epoch 112/150 - 0.05s - loss: 1.0800 - acc: 0.4031 - val_loss: 1.0826 - val_acc: 0.4069\n",
            "Epoch 113/150 - 0.05s - loss: 1.0799 - acc: 0.4024 - val_loss: 1.0825 - val_acc: 0.4109\n",
            "Epoch 114/150 - 0.05s - loss: 1.0798 - acc: 0.4019 - val_loss: 1.0824 - val_acc: 0.4109\n",
            "Epoch 115/150 - 0.05s - loss: 1.0797 - acc: 0.4033 - val_loss: 1.0823 - val_acc: 0.4109\n",
            "Epoch 116/150 - 0.05s - loss: 1.0796 - acc: 0.4028 - val_loss: 1.0822 - val_acc: 0.4089\n",
            "Epoch 117/150 - 0.05s - loss: 1.0795 - acc: 0.4033 - val_loss: 1.0821 - val_acc: 0.4089\n",
            "Epoch 118/150 - 0.05s - loss: 1.0794 - acc: 0.4042 - val_loss: 1.0821 - val_acc: 0.4109\n",
            "Epoch 119/150 - 0.05s - loss: 1.0793 - acc: 0.4042 - val_loss: 1.0820 - val_acc: 0.4109\n",
            "Epoch 120/150 - 0.05s - loss: 1.0792 - acc: 0.4046 - val_loss: 1.0819 - val_acc: 0.4130\n",
            "Epoch 121/150 - 0.05s - loss: 1.0791 - acc: 0.4055 - val_loss: 1.0818 - val_acc: 0.4130\n",
            "Epoch 122/150 - 0.05s - loss: 1.0790 - acc: 0.4055 - val_loss: 1.0817 - val_acc: 0.4109\n",
            "Epoch 123/150 - 0.06s - loss: 1.0789 - acc: 0.4053 - val_loss: 1.0816 - val_acc: 0.4130\n",
            "Epoch 124/150 - 0.06s - loss: 1.0788 - acc: 0.4064 - val_loss: 1.0815 - val_acc: 0.4150\n",
            "Epoch 125/150 - 0.06s - loss: 1.0787 - acc: 0.4069 - val_loss: 1.0814 - val_acc: 0.4190\n",
            "Epoch 126/150 - 0.06s - loss: 1.0786 - acc: 0.4073 - val_loss: 1.0813 - val_acc: 0.4150\n",
            "Epoch 127/150 - 0.06s - loss: 1.0785 - acc: 0.4085 - val_loss: 1.0812 - val_acc: 0.4170\n",
            "Epoch 128/150 - 0.05s - loss: 1.0784 - acc: 0.4091 - val_loss: 1.0812 - val_acc: 0.4211\n",
            "Epoch 129/150 - 0.05s - loss: 1.0783 - acc: 0.4098 - val_loss: 1.0811 - val_acc: 0.4211\n",
            "Epoch 130/150 - 0.05s - loss: 1.0782 - acc: 0.4103 - val_loss: 1.0810 - val_acc: 0.4231\n",
            "Epoch 131/150 - 0.05s - loss: 1.0781 - acc: 0.4100 - val_loss: 1.0809 - val_acc: 0.4251\n",
            "Epoch 132/150 - 0.05s - loss: 1.0780 - acc: 0.4096 - val_loss: 1.0808 - val_acc: 0.4271\n",
            "Epoch 133/150 - 0.05s - loss: 1.0779 - acc: 0.4094 - val_loss: 1.0807 - val_acc: 0.4251\n",
            "Epoch 134/150 - 0.05s - loss: 1.0778 - acc: 0.4105 - val_loss: 1.0806 - val_acc: 0.4211\n",
            "Epoch 135/150 - 0.05s - loss: 1.0777 - acc: 0.4103 - val_loss: 1.0805 - val_acc: 0.4211\n",
            "Epoch 136/150 - 0.05s - loss: 1.0776 - acc: 0.4105 - val_loss: 1.0805 - val_acc: 0.4251\n",
            "Epoch 137/150 - 0.05s - loss: 1.0775 - acc: 0.4105 - val_loss: 1.0804 - val_acc: 0.4291\n",
            "Epoch 138/150 - 0.05s - loss: 1.0774 - acc: 0.4103 - val_loss: 1.0803 - val_acc: 0.4291\n",
            "Epoch 139/150 - 0.05s - loss: 1.0774 - acc: 0.4100 - val_loss: 1.0802 - val_acc: 0.4231\n",
            "Epoch 140/150 - 0.05s - loss: 1.0773 - acc: 0.4105 - val_loss: 1.0801 - val_acc: 0.4211\n",
            "Epoch 141/150 - 0.05s - loss: 1.0772 - acc: 0.4125 - val_loss: 1.0800 - val_acc: 0.4211\n",
            "Epoch 142/150 - 0.05s - loss: 1.0771 - acc: 0.4123 - val_loss: 1.0799 - val_acc: 0.4211\n",
            "Epoch 143/150 - 0.05s - loss: 1.0770 - acc: 0.4127 - val_loss: 1.0799 - val_acc: 0.4150\n",
            "Epoch 144/150 - 0.05s - loss: 1.0769 - acc: 0.4139 - val_loss: 1.0798 - val_acc: 0.4130\n",
            "Epoch 145/150 - 0.05s - loss: 1.0768 - acc: 0.4134 - val_loss: 1.0797 - val_acc: 0.4170\n",
            "Epoch 146/150 - 0.05s - loss: 1.0767 - acc: 0.4139 - val_loss: 1.0796 - val_acc: 0.4190\n",
            "Epoch 147/150 - 0.05s - loss: 1.0766 - acc: 0.4136 - val_loss: 1.0795 - val_acc: 0.4211\n",
            "Epoch 148/150 - 0.05s - loss: 1.0765 - acc: 0.4148 - val_loss: 1.0794 - val_acc: 0.4190\n",
            "Epoch 149/150 - 0.05s - loss: 1.0764 - acc: 0.4150 - val_loss: 1.0794 - val_acc: 0.4211\n",
            "Epoch 150/150 - 0.06s - loss: 1.0763 - acc: 0.4163 - val_loss: 1.0793 - val_acc: 0.4211\n",
            "\n",
            "Combination 55/252:\n",
            "Hidden Layers: [128, 64], Activation: tanh, Learning Rate: 0.01, Batch Size: 32, Epochs: 50\n",
            "Epoch 1/50 - 0.09s - loss: 1.0804 - acc: 0.4170 - val_loss: 1.0841 - val_acc: 0.3866\n",
            "Epoch 2/50 - 0.09s - loss: 1.0671 - acc: 0.4429 - val_loss: 1.0745 - val_acc: 0.3988\n",
            "Epoch 3/50 - 0.10s - loss: 1.0579 - acc: 0.4460 - val_loss: 1.0678 - val_acc: 0.4555\n",
            "Epoch 4/50 - 0.09s - loss: 1.0478 - acc: 0.4701 - val_loss: 1.0595 - val_acc: 0.4514\n",
            "Epoch 5/50 - 0.10s - loss: 1.0414 - acc: 0.4710 - val_loss: 1.0538 - val_acc: 0.4534\n",
            "Epoch 6/50 - 0.09s - loss: 1.0332 - acc: 0.4822 - val_loss: 1.0492 - val_acc: 0.4838\n",
            "Epoch 7/50 - 0.09s - loss: 1.0309 - acc: 0.4737 - val_loss: 1.0496 - val_acc: 0.4595\n",
            "Epoch 8/50 - 0.09s - loss: 1.0195 - acc: 0.4962 - val_loss: 1.0399 - val_acc: 0.5000\n",
            "Epoch 9/50 - 0.09s - loss: 1.0134 - acc: 0.4993 - val_loss: 1.0356 - val_acc: 0.5121\n",
            "Epoch 10/50 - 0.09s - loss: 1.0119 - acc: 0.4928 - val_loss: 1.0352 - val_acc: 0.4960\n",
            "Epoch 11/50 - 0.09s - loss: 1.0013 - acc: 0.5142 - val_loss: 1.0255 - val_acc: 0.5000\n",
            "Epoch 12/50 - 0.09s - loss: 0.9939 - acc: 0.5184 - val_loss: 1.0199 - val_acc: 0.5223\n",
            "Epoch 13/50 - 0.09s - loss: 0.9960 - acc: 0.5076 - val_loss: 1.0256 - val_acc: 0.5000\n",
            "Epoch 14/50 - 0.09s - loss: 0.9835 - acc: 0.5223 - val_loss: 1.0110 - val_acc: 0.5202\n",
            "Epoch 15/50 - 0.10s - loss: 0.9780 - acc: 0.5272 - val_loss: 1.0080 - val_acc: 0.5324\n",
            "Epoch 16/50 - 0.09s - loss: 0.9757 - acc: 0.5299 - val_loss: 1.0061 - val_acc: 0.5445\n",
            "Epoch 17/50 - 0.10s - loss: 0.9698 - acc: 0.5315 - val_loss: 1.0001 - val_acc: 0.5223\n",
            "Epoch 18/50 - 0.09s - loss: 0.9627 - acc: 0.5389 - val_loss: 0.9954 - val_acc: 0.5466\n",
            "Epoch 19/50 - 0.10s - loss: 0.9631 - acc: 0.5403 - val_loss: 0.9953 - val_acc: 0.5547\n",
            "Epoch 20/50 - 0.09s - loss: 0.9551 - acc: 0.5481 - val_loss: 0.9894 - val_acc: 0.5587\n",
            "Epoch 21/50 - 0.09s - loss: 0.9588 - acc: 0.5351 - val_loss: 0.9950 - val_acc: 0.5081\n",
            "Epoch 22/50 - 0.09s - loss: 0.9473 - acc: 0.5524 - val_loss: 0.9842 - val_acc: 0.5547\n",
            "Epoch 23/50 - 0.09s - loss: 0.9435 - acc: 0.5560 - val_loss: 0.9830 - val_acc: 0.5445\n",
            "Epoch 24/50 - 0.09s - loss: 0.9380 - acc: 0.5601 - val_loss: 0.9770 - val_acc: 0.5506\n",
            "Epoch 25/50 - 0.09s - loss: 0.9372 - acc: 0.5538 - val_loss: 0.9760 - val_acc: 0.5567\n",
            "Epoch 26/50 - 0.09s - loss: 0.9334 - acc: 0.5670 - val_loss: 0.9744 - val_acc: 0.5607\n",
            "Epoch 27/50 - 0.09s - loss: 0.9275 - acc: 0.5655 - val_loss: 0.9701 - val_acc: 0.5486\n",
            "Epoch 28/50 - 0.08s - loss: 0.9316 - acc: 0.5605 - val_loss: 0.9776 - val_acc: 0.5445\n",
            "Epoch 29/50 - 0.09s - loss: 0.9240 - acc: 0.5592 - val_loss: 0.9672 - val_acc: 0.5445\n",
            "Epoch 30/50 - 0.09s - loss: 0.9191 - acc: 0.5726 - val_loss: 0.9652 - val_acc: 0.5486\n",
            "Epoch 31/50 - 0.09s - loss: 0.9216 - acc: 0.5589 - val_loss: 0.9704 - val_acc: 0.5445\n",
            "Epoch 32/50 - 0.09s - loss: 0.9136 - acc: 0.5673 - val_loss: 0.9632 - val_acc: 0.5547\n",
            "Epoch 33/50 - 0.09s - loss: 0.9147 - acc: 0.5801 - val_loss: 0.9658 - val_acc: 0.5709\n",
            "Epoch 34/50 - 0.09s - loss: 0.9108 - acc: 0.5749 - val_loss: 0.9655 - val_acc: 0.5506\n",
            "Epoch 35/50 - 0.09s - loss: 0.9151 - acc: 0.5637 - val_loss: 0.9638 - val_acc: 0.5547\n",
            "Epoch 36/50 - 0.09s - loss: 0.9090 - acc: 0.5789 - val_loss: 0.9607 - val_acc: 0.5729\n",
            "Epoch 37/50 - 0.09s - loss: 0.9067 - acc: 0.5664 - val_loss: 0.9619 - val_acc: 0.5405\n",
            "Epoch 38/50 - 0.09s - loss: 0.9006 - acc: 0.5762 - val_loss: 0.9562 - val_acc: 0.5506\n",
            "Epoch 39/50 - 0.09s - loss: 0.9107 - acc: 0.5780 - val_loss: 0.9712 - val_acc: 0.5344\n",
            "Epoch 40/50 - 0.09s - loss: 0.8990 - acc: 0.5852 - val_loss: 0.9582 - val_acc: 0.5749\n",
            "Epoch 41/50 - 0.10s - loss: 0.8936 - acc: 0.5789 - val_loss: 0.9561 - val_acc: 0.5567\n",
            "Epoch 42/50 - 0.10s - loss: 0.8948 - acc: 0.5816 - val_loss: 0.9583 - val_acc: 0.5607\n",
            "Epoch 43/50 - 0.10s - loss: 0.8903 - acc: 0.5859 - val_loss: 0.9550 - val_acc: 0.5567\n",
            "Epoch 44/50 - 0.11s - loss: 0.8945 - acc: 0.5751 - val_loss: 0.9579 - val_acc: 0.5425\n",
            "Epoch 45/50 - 0.09s - loss: 0.9031 - acc: 0.5641 - val_loss: 0.9752 - val_acc: 0.5202\n",
            "Epoch 46/50 - 0.10s - loss: 0.9050 - acc: 0.5621 - val_loss: 0.9796 - val_acc: 0.5162\n",
            "Epoch 47/50 - 0.09s - loss: 0.8835 - acc: 0.5920 - val_loss: 0.9524 - val_acc: 0.5668\n",
            "Epoch 48/50 - 0.09s - loss: 0.8848 - acc: 0.5868 - val_loss: 0.9599 - val_acc: 0.5283\n",
            "Epoch 49/50 - 0.09s - loss: 0.8807 - acc: 0.5888 - val_loss: 0.9529 - val_acc: 0.5466\n",
            "Epoch 50/50 - 0.09s - loss: 0.8782 - acc: 0.5936 - val_loss: 0.9538 - val_acc: 0.5587\n",
            "\n",
            "Combination 56/252:\n",
            "Hidden Layers: [128, 64], Activation: tanh, Learning Rate: 0.01, Batch Size: 32, Epochs: 100\n",
            "Epoch 1/100 - 0.09s - loss: 1.0835 - acc: 0.4188 - val_loss: 1.0870 - val_acc: 0.4049\n",
            "Epoch 2/100 - 0.09s - loss: 1.0692 - acc: 0.4514 - val_loss: 1.0758 - val_acc: 0.4251\n",
            "Epoch 3/100 - 0.09s - loss: 1.0587 - acc: 0.4663 - val_loss: 1.0677 - val_acc: 0.4413\n",
            "Epoch 4/100 - 0.09s - loss: 1.0506 - acc: 0.4685 - val_loss: 1.0630 - val_acc: 0.4393\n",
            "Epoch 5/100 - 0.10s - loss: 1.0425 - acc: 0.4789 - val_loss: 1.0569 - val_acc: 0.4372\n",
            "Epoch 6/100 - 0.09s - loss: 1.0354 - acc: 0.4867 - val_loss: 1.0508 - val_acc: 0.4555\n",
            "Epoch 7/100 - 0.09s - loss: 1.0283 - acc: 0.4935 - val_loss: 1.0460 - val_acc: 0.4656\n",
            "Epoch 8/100 - 0.09s - loss: 1.0231 - acc: 0.4849 - val_loss: 1.0422 - val_acc: 0.4757\n",
            "Epoch 9/100 - 0.10s - loss: 1.0155 - acc: 0.5036 - val_loss: 1.0357 - val_acc: 0.5000\n",
            "Epoch 10/100 - 0.09s - loss: 1.0091 - acc: 0.5072 - val_loss: 1.0307 - val_acc: 0.5000\n",
            "Epoch 11/100 - 0.09s - loss: 1.0055 - acc: 0.5083 - val_loss: 1.0275 - val_acc: 0.5081\n",
            "Epoch 12/100 - 0.09s - loss: 0.9988 - acc: 0.5142 - val_loss: 1.0208 - val_acc: 0.5081\n",
            "Epoch 13/100 - 0.09s - loss: 0.9916 - acc: 0.5166 - val_loss: 1.0152 - val_acc: 0.5202\n",
            "Epoch 14/100 - 0.09s - loss: 0.9860 - acc: 0.5214 - val_loss: 1.0102 - val_acc: 0.5101\n",
            "Epoch 15/100 - 0.09s - loss: 0.9864 - acc: 0.5193 - val_loss: 1.0095 - val_acc: 0.5202\n",
            "Epoch 16/100 - 0.09s - loss: 0.9764 - acc: 0.5301 - val_loss: 1.0015 - val_acc: 0.5202\n",
            "Epoch 17/100 - 0.09s - loss: 0.9730 - acc: 0.5297 - val_loss: 0.9980 - val_acc: 0.5283\n",
            "Epoch 18/100 - 0.09s - loss: 0.9657 - acc: 0.5353 - val_loss: 0.9929 - val_acc: 0.5243\n",
            "Epoch 19/100 - 0.09s - loss: 0.9612 - acc: 0.5364 - val_loss: 0.9886 - val_acc: 0.5324\n",
            "Epoch 20/100 - 0.09s - loss: 0.9573 - acc: 0.5448 - val_loss: 0.9864 - val_acc: 0.5344\n",
            "Epoch 21/100 - 0.09s - loss: 0.9532 - acc: 0.5470 - val_loss: 0.9828 - val_acc: 0.5405\n",
            "Epoch 22/100 - 0.09s - loss: 0.9590 - acc: 0.5349 - val_loss: 0.9875 - val_acc: 0.5142\n",
            "Epoch 23/100 - 0.09s - loss: 0.9477 - acc: 0.5461 - val_loss: 0.9776 - val_acc: 0.5587\n",
            "Epoch 24/100 - 0.09s - loss: 0.9444 - acc: 0.5486 - val_loss: 0.9742 - val_acc: 0.5547\n",
            "Epoch 25/100 - 0.09s - loss: 0.9420 - acc: 0.5477 - val_loss: 0.9735 - val_acc: 0.5587\n",
            "Epoch 26/100 - 0.09s - loss: 0.9353 - acc: 0.5598 - val_loss: 0.9690 - val_acc: 0.5506\n",
            "Epoch 27/100 - 0.09s - loss: 0.9357 - acc: 0.5544 - val_loss: 0.9689 - val_acc: 0.5547\n",
            "Epoch 28/100 - 0.09s - loss: 0.9472 - acc: 0.5495 - val_loss: 0.9825 - val_acc: 0.5506\n",
            "Epoch 29/100 - 0.09s - loss: 0.9349 - acc: 0.5601 - val_loss: 0.9715 - val_acc: 0.5486\n",
            "Epoch 30/100 - 0.09s - loss: 0.9259 - acc: 0.5594 - val_loss: 0.9621 - val_acc: 0.5668\n",
            "Epoch 31/100 - 0.09s - loss: 0.9219 - acc: 0.5673 - val_loss: 0.9594 - val_acc: 0.5587\n",
            "Epoch 32/100 - 0.10s - loss: 0.9367 - acc: 0.5571 - val_loss: 0.9723 - val_acc: 0.5628\n",
            "Epoch 33/100 - 0.09s - loss: 0.9158 - acc: 0.5688 - val_loss: 0.9550 - val_acc: 0.5587\n",
            "Epoch 34/100 - 0.09s - loss: 0.9235 - acc: 0.5612 - val_loss: 0.9640 - val_acc: 0.5364\n",
            "Epoch 35/100 - 0.09s - loss: 0.9099 - acc: 0.5706 - val_loss: 0.9516 - val_acc: 0.5567\n",
            "Epoch 36/100 - 0.09s - loss: 0.9111 - acc: 0.5706 - val_loss: 0.9579 - val_acc: 0.5486\n",
            "Epoch 37/100 - 0.09s - loss: 0.9109 - acc: 0.5693 - val_loss: 0.9564 - val_acc: 0.5526\n",
            "Epoch 38/100 - 0.09s - loss: 0.9033 - acc: 0.5747 - val_loss: 0.9511 - val_acc: 0.5506\n",
            "Epoch 39/100 - 0.09s - loss: 0.9029 - acc: 0.5778 - val_loss: 0.9506 - val_acc: 0.5466\n",
            "Epoch 40/100 - 0.09s - loss: 0.9095 - acc: 0.5695 - val_loss: 0.9628 - val_acc: 0.5243\n",
            "Epoch 41/100 - 0.09s - loss: 0.8984 - acc: 0.5783 - val_loss: 0.9486 - val_acc: 0.5769\n",
            "Epoch 42/100 - 0.09s - loss: 0.9000 - acc: 0.5760 - val_loss: 0.9535 - val_acc: 0.5324\n",
            "Epoch 43/100 - 0.09s - loss: 0.8962 - acc: 0.5789 - val_loss: 0.9522 - val_acc: 0.5506\n",
            "Epoch 44/100 - 0.09s - loss: 0.9061 - acc: 0.5686 - val_loss: 0.9569 - val_acc: 0.5405\n",
            "Epoch 45/100 - 0.09s - loss: 0.8935 - acc: 0.5810 - val_loss: 0.9515 - val_acc: 0.5263\n",
            "Epoch 46/100 - 0.09s - loss: 0.8904 - acc: 0.5810 - val_loss: 0.9464 - val_acc: 0.5668\n",
            "Epoch 47/100 - 0.09s - loss: 0.8905 - acc: 0.5803 - val_loss: 0.9539 - val_acc: 0.5263\n",
            "Epoch 48/100 - 0.10s - loss: 0.8911 - acc: 0.5848 - val_loss: 0.9492 - val_acc: 0.5668\n",
            "Epoch 49/100 - 0.09s - loss: 0.9013 - acc: 0.5713 - val_loss: 0.9647 - val_acc: 0.5263\n",
            "Epoch 50/100 - 0.10s - loss: 0.8855 - acc: 0.5812 - val_loss: 0.9523 - val_acc: 0.5243\n",
            "Epoch 51/100 - 0.11s - loss: 0.8952 - acc: 0.5884 - val_loss: 0.9588 - val_acc: 0.5567\n",
            "Epoch 52/100 - 0.10s - loss: 0.8859 - acc: 0.5900 - val_loss: 0.9516 - val_acc: 0.5607\n",
            "Epoch 53/100 - 0.10s - loss: 0.8772 - acc: 0.5915 - val_loss: 0.9472 - val_acc: 0.5405\n",
            "Epoch 54/100 - 0.11s - loss: 0.8813 - acc: 0.5911 - val_loss: 0.9475 - val_acc: 0.5668\n",
            "Epoch 55/100 - 0.09s - loss: 0.8772 - acc: 0.5900 - val_loss: 0.9489 - val_acc: 0.5283\n",
            "Epoch 56/100 - 0.09s - loss: 0.8744 - acc: 0.5927 - val_loss: 0.9485 - val_acc: 0.5425\n",
            "Epoch 57/100 - 0.10s - loss: 0.8720 - acc: 0.5938 - val_loss: 0.9435 - val_acc: 0.5466\n",
            "Epoch 58/100 - 0.09s - loss: 0.8706 - acc: 0.5978 - val_loss: 0.9452 - val_acc: 0.5506\n",
            "Epoch 59/100 - 0.09s - loss: 0.8823 - acc: 0.5960 - val_loss: 0.9550 - val_acc: 0.5668\n",
            "Epoch 60/100 - 0.10s - loss: 0.8783 - acc: 0.5981 - val_loss: 0.9544 - val_acc: 0.5526\n",
            "Epoch 61/100 - 0.09s - loss: 0.8859 - acc: 0.5780 - val_loss: 0.9582 - val_acc: 0.5526\n",
            "Epoch 62/100 - 0.09s - loss: 0.8675 - acc: 0.5927 - val_loss: 0.9485 - val_acc: 0.5466\n",
            "Epoch 63/100 - 0.10s - loss: 0.8759 - acc: 0.5949 - val_loss: 0.9626 - val_acc: 0.5243\n",
            "Epoch 64/100 - 0.09s - loss: 0.8842 - acc: 0.5927 - val_loss: 0.9623 - val_acc: 0.5547\n",
            "Epoch 65/100 - 0.09s - loss: 0.8896 - acc: 0.5738 - val_loss: 0.9649 - val_acc: 0.5405\n",
            "Epoch 66/100 - 0.10s - loss: 0.8834 - acc: 0.5929 - val_loss: 0.9632 - val_acc: 0.5526\n",
            "Epoch 67/100 - 0.09s - loss: 0.8643 - acc: 0.5981 - val_loss: 0.9535 - val_acc: 0.5304\n",
            "Epoch 68/100 - 0.09s - loss: 0.8687 - acc: 0.5965 - val_loss: 0.9577 - val_acc: 0.5223\n",
            "Epoch 69/100 - 0.11s - loss: 0.8897 - acc: 0.5893 - val_loss: 0.9718 - val_acc: 0.5526\n",
            "Epoch 70/100 - 0.09s - loss: 0.8729 - acc: 0.5897 - val_loss: 0.9568 - val_acc: 0.5587\n",
            "Epoch 71/100 - 0.09s - loss: 0.8900 - acc: 0.5859 - val_loss: 0.9716 - val_acc: 0.5587\n",
            "Epoch 72/100 - 0.12s - loss: 0.8638 - acc: 0.5958 - val_loss: 0.9527 - val_acc: 0.5587\n",
            "Epoch 73/100 - 0.11s - loss: 0.8789 - acc: 0.5852 - val_loss: 0.9823 - val_acc: 0.5040\n",
            "Epoch 74/100 - 0.12s - loss: 0.8589 - acc: 0.6023 - val_loss: 0.9532 - val_acc: 0.5283\n",
            "Epoch 75/100 - 0.11s - loss: 0.8575 - acc: 0.6030 - val_loss: 0.9538 - val_acc: 0.5405\n",
            "Epoch 76/100 - 0.09s - loss: 0.8638 - acc: 0.6041 - val_loss: 0.9645 - val_acc: 0.5385\n",
            "Epoch 77/100 - 0.10s - loss: 0.8581 - acc: 0.5999 - val_loss: 0.9621 - val_acc: 0.5304\n",
            "Epoch 78/100 - 0.10s - loss: 0.8550 - acc: 0.6091 - val_loss: 0.9512 - val_acc: 0.5587\n",
            "Epoch 79/100 - 0.09s - loss: 0.8548 - acc: 0.6109 - val_loss: 0.9588 - val_acc: 0.5344\n",
            "Epoch 80/100 - 0.10s - loss: 0.8690 - acc: 0.6017 - val_loss: 0.9770 - val_acc: 0.5162\n",
            "Epoch 81/100 - 0.09s - loss: 0.8533 - acc: 0.6104 - val_loss: 0.9586 - val_acc: 0.5466\n",
            "Epoch 82/100 - 0.09s - loss: 0.8801 - acc: 0.5933 - val_loss: 0.9738 - val_acc: 0.5587\n",
            "Epoch 83/100 - 0.11s - loss: 0.8522 - acc: 0.6100 - val_loss: 0.9623 - val_acc: 0.5263\n",
            "Epoch 84/100 - 0.09s - loss: 0.8509 - acc: 0.6077 - val_loss: 0.9564 - val_acc: 0.5344\n",
            "Epoch 85/100 - 0.09s - loss: 0.8504 - acc: 0.6048 - val_loss: 0.9570 - val_acc: 0.5405\n",
            "Epoch 86/100 - 0.10s - loss: 0.8494 - acc: 0.6100 - val_loss: 0.9518 - val_acc: 0.5486\n",
            "Epoch 87/100 - 0.09s - loss: 0.8494 - acc: 0.6120 - val_loss: 0.9530 - val_acc: 0.5567\n",
            "Epoch 88/100 - 0.09s - loss: 0.8583 - acc: 0.6093 - val_loss: 0.9632 - val_acc: 0.5607\n",
            "Epoch 89/100 - 0.10s - loss: 0.8724 - acc: 0.5929 - val_loss: 0.9928 - val_acc: 0.5040\n",
            "Epoch 90/100 - 0.10s - loss: 0.8507 - acc: 0.6131 - val_loss: 0.9604 - val_acc: 0.5587\n",
            "Epoch 91/100 - 0.10s - loss: 0.8676 - acc: 0.6080 - val_loss: 0.9748 - val_acc: 0.5526\n",
            "Epoch 92/100 - 0.10s - loss: 0.8540 - acc: 0.6017 - val_loss: 0.9593 - val_acc: 0.5587\n",
            "Epoch 93/100 - 0.10s - loss: 0.8529 - acc: 0.6028 - val_loss: 0.9595 - val_acc: 0.5587\n",
            "Epoch 94/100 - 0.09s - loss: 0.8573 - acc: 0.5985 - val_loss: 0.9775 - val_acc: 0.5283\n",
            "Epoch 95/100 - 0.10s - loss: 0.8947 - acc: 0.5792 - val_loss: 1.0097 - val_acc: 0.5162\n",
            "Epoch 96/100 - 0.09s - loss: 0.8459 - acc: 0.6181 - val_loss: 0.9607 - val_acc: 0.5547\n",
            "Epoch 97/100 - 0.09s - loss: 0.8449 - acc: 0.6098 - val_loss: 0.9604 - val_acc: 0.5405\n",
            "Epoch 98/100 - 0.12s - loss: 0.9018 - acc: 0.5749 - val_loss: 1.0174 - val_acc: 0.5223\n",
            "Epoch 99/100 - 0.09s - loss: 0.8868 - acc: 0.5729 - val_loss: 0.9902 - val_acc: 0.5486\n",
            "Epoch 100/100 - 0.10s - loss: 0.8447 - acc: 0.6098 - val_loss: 0.9646 - val_acc: 0.5425\n",
            "\n",
            "Combination 57/252:\n",
            "Hidden Layers: [128, 64], Activation: tanh, Learning Rate: 0.01, Batch Size: 32, Epochs: 150\n",
            "Epoch 1/150 - 0.10s - loss: 1.0822 - acc: 0.3941 - val_loss: 1.0867 - val_acc: 0.3623\n",
            "Epoch 2/150 - 0.09s - loss: 1.0688 - acc: 0.4438 - val_loss: 1.0753 - val_acc: 0.4494\n",
            "Epoch 3/150 - 0.09s - loss: 1.0593 - acc: 0.4541 - val_loss: 1.0700 - val_acc: 0.4190\n",
            "Epoch 4/150 - 0.10s - loss: 1.0535 - acc: 0.4462 - val_loss: 1.0665 - val_acc: 0.4130\n",
            "Epoch 5/150 - 0.09s - loss: 1.0427 - acc: 0.4701 - val_loss: 1.0562 - val_acc: 0.4595\n",
            "Epoch 6/150 - 0.09s - loss: 1.0362 - acc: 0.4798 - val_loss: 1.0521 - val_acc: 0.4534\n",
            "Epoch 7/150 - 0.10s - loss: 1.0302 - acc: 0.4773 - val_loss: 1.0485 - val_acc: 0.4777\n",
            "Epoch 8/150 - 0.10s - loss: 1.0213 - acc: 0.4933 - val_loss: 1.0415 - val_acc: 0.4818\n",
            "Epoch 9/150 - 0.09s - loss: 1.0171 - acc: 0.4973 - val_loss: 1.0398 - val_acc: 0.4676\n",
            "Epoch 10/150 - 0.10s - loss: 1.0094 - acc: 0.5067 - val_loss: 1.0330 - val_acc: 0.5000\n",
            "Epoch 11/150 - 0.10s - loss: 1.0042 - acc: 0.5099 - val_loss: 1.0291 - val_acc: 0.4939\n",
            "Epoch 12/150 - 0.10s - loss: 1.0004 - acc: 0.5072 - val_loss: 1.0254 - val_acc: 0.4939\n",
            "Epoch 13/150 - 0.11s - loss: 0.9911 - acc: 0.5214 - val_loss: 1.0174 - val_acc: 0.5061\n",
            "Epoch 14/150 - 0.09s - loss: 0.9854 - acc: 0.5281 - val_loss: 1.0124 - val_acc: 0.5081\n",
            "Epoch 15/150 - 0.10s - loss: 0.9835 - acc: 0.5243 - val_loss: 1.0113 - val_acc: 0.5020\n",
            "Epoch 16/150 - 0.10s - loss: 0.9784 - acc: 0.5297 - val_loss: 1.0062 - val_acc: 0.5263\n",
            "Epoch 17/150 - 0.10s - loss: 0.9744 - acc: 0.5328 - val_loss: 1.0055 - val_acc: 0.5182\n",
            "Epoch 18/150 - 0.10s - loss: 0.9677 - acc: 0.5364 - val_loss: 0.9974 - val_acc: 0.5142\n",
            "Epoch 19/150 - 0.10s - loss: 0.9634 - acc: 0.5468 - val_loss: 0.9936 - val_acc: 0.5547\n",
            "Epoch 20/150 - 0.10s - loss: 0.9584 - acc: 0.5506 - val_loss: 0.9888 - val_acc: 0.5486\n",
            "Epoch 21/150 - 0.09s - loss: 0.9531 - acc: 0.5475 - val_loss: 0.9847 - val_acc: 0.5526\n",
            "Epoch 22/150 - 0.10s - loss: 0.9495 - acc: 0.5472 - val_loss: 0.9820 - val_acc: 0.5364\n",
            "Epoch 23/150 - 0.10s - loss: 0.9487 - acc: 0.5515 - val_loss: 0.9813 - val_acc: 0.5486\n",
            "Epoch 24/150 - 0.09s - loss: 0.9569 - acc: 0.5434 - val_loss: 0.9877 - val_acc: 0.5405\n",
            "Epoch 25/150 - 0.10s - loss: 0.9397 - acc: 0.5547 - val_loss: 0.9734 - val_acc: 0.5385\n",
            "Epoch 26/150 - 0.09s - loss: 0.9376 - acc: 0.5567 - val_loss: 0.9726 - val_acc: 0.5506\n",
            "Epoch 27/150 - 0.09s - loss: 0.9565 - acc: 0.5504 - val_loss: 0.9905 - val_acc: 0.5486\n",
            "Epoch 28/150 - 0.10s - loss: 0.9306 - acc: 0.5650 - val_loss: 0.9692 - val_acc: 0.5466\n",
            "Epoch 29/150 - 0.10s - loss: 0.9371 - acc: 0.5639 - val_loss: 0.9734 - val_acc: 0.5607\n",
            "Epoch 30/150 - 0.09s - loss: 0.9319 - acc: 0.5646 - val_loss: 0.9696 - val_acc: 0.5628\n",
            "Epoch 31/150 - 0.11s - loss: 0.9246 - acc: 0.5704 - val_loss: 0.9650 - val_acc: 0.5526\n",
            "Epoch 32/150 - 0.10s - loss: 0.9229 - acc: 0.5641 - val_loss: 0.9610 - val_acc: 0.5486\n",
            "Epoch 33/150 - 0.09s - loss: 0.9232 - acc: 0.5616 - val_loss: 0.9645 - val_acc: 0.5425\n",
            "Epoch 34/150 - 0.10s - loss: 0.9142 - acc: 0.5726 - val_loss: 0.9587 - val_acc: 0.5567\n",
            "Epoch 35/150 - 0.09s - loss: 0.9119 - acc: 0.5758 - val_loss: 0.9562 - val_acc: 0.5506\n",
            "Epoch 36/150 - 0.10s - loss: 0.9101 - acc: 0.5769 - val_loss: 0.9570 - val_acc: 0.5526\n",
            "Epoch 37/150 - 0.10s - loss: 0.9151 - acc: 0.5630 - val_loss: 0.9616 - val_acc: 0.5405\n",
            "Epoch 38/150 - 0.12s - loss: 0.9115 - acc: 0.5675 - val_loss: 0.9616 - val_acc: 0.5486\n",
            "Epoch 39/150 - 0.11s - loss: 0.9068 - acc: 0.5771 - val_loss: 0.9553 - val_acc: 0.5567\n",
            "Epoch 40/150 - 0.11s - loss: 0.9015 - acc: 0.5848 - val_loss: 0.9539 - val_acc: 0.5547\n",
            "Epoch 41/150 - 0.10s - loss: 0.9498 - acc: 0.5324 - val_loss: 0.9922 - val_acc: 0.5202\n",
            "Epoch 42/150 - 0.11s - loss: 0.9212 - acc: 0.5571 - val_loss: 0.9784 - val_acc: 0.5162\n",
            "Epoch 43/150 - 0.10s - loss: 0.8991 - acc: 0.5852 - val_loss: 0.9561 - val_acc: 0.5344\n",
            "Epoch 44/150 - 0.11s - loss: 0.8960 - acc: 0.5893 - val_loss: 0.9511 - val_acc: 0.5587\n",
            "Epoch 45/150 - 0.12s - loss: 0.9134 - acc: 0.5630 - val_loss: 0.9750 - val_acc: 0.5283\n",
            "Epoch 46/150 - 0.10s - loss: 0.9004 - acc: 0.5866 - val_loss: 0.9616 - val_acc: 0.5324\n",
            "Epoch 47/150 - 0.10s - loss: 0.8951 - acc: 0.5783 - val_loss: 0.9554 - val_acc: 0.5466\n",
            "Epoch 48/150 - 0.10s - loss: 0.8876 - acc: 0.5902 - val_loss: 0.9497 - val_acc: 0.5506\n",
            "Epoch 49/150 - 0.12s - loss: 0.8887 - acc: 0.5904 - val_loss: 0.9534 - val_acc: 0.5385\n",
            "Epoch 50/150 - 0.12s - loss: 0.8847 - acc: 0.6001 - val_loss: 0.9480 - val_acc: 0.5587\n",
            "Epoch 51/150 - 0.11s - loss: 0.8850 - acc: 0.5938 - val_loss: 0.9520 - val_acc: 0.5344\n",
            "Epoch 52/150 - 0.10s - loss: 0.9196 - acc: 0.5601 - val_loss: 0.9939 - val_acc: 0.4980\n",
            "Epoch 53/150 - 0.10s - loss: 0.9025 - acc: 0.5735 - val_loss: 0.9764 - val_acc: 0.5182\n",
            "Epoch 54/150 - 0.11s - loss: 0.8949 - acc: 0.5731 - val_loss: 0.9598 - val_acc: 0.5466\n",
            "Epoch 55/150 - 0.10s - loss: 0.8807 - acc: 0.5904 - val_loss: 0.9487 - val_acc: 0.5486\n",
            "Epoch 56/150 - 0.10s - loss: 0.8888 - acc: 0.5965 - val_loss: 0.9590 - val_acc: 0.5587\n",
            "Epoch 57/150 - 0.10s - loss: 0.8818 - acc: 0.6014 - val_loss: 0.9556 - val_acc: 0.5526\n",
            "Epoch 58/150 - 0.10s - loss: 0.8728 - acc: 0.6021 - val_loss: 0.9496 - val_acc: 0.5506\n",
            "Epoch 59/150 - 0.10s - loss: 0.8805 - acc: 0.6008 - val_loss: 0.9552 - val_acc: 0.5628\n",
            "Epoch 60/150 - 0.10s - loss: 0.8724 - acc: 0.5999 - val_loss: 0.9524 - val_acc: 0.5385\n",
            "Epoch 61/150 - 0.10s - loss: 0.8716 - acc: 0.6068 - val_loss: 0.9499 - val_acc: 0.5668\n",
            "Epoch 62/150 - 0.12s - loss: 0.8790 - acc: 0.6010 - val_loss: 0.9632 - val_acc: 0.5425\n",
            "Epoch 63/150 - 0.12s - loss: 0.8676 - acc: 0.6048 - val_loss: 0.9484 - val_acc: 0.5405\n",
            "Epoch 64/150 - 0.09s - loss: 0.8690 - acc: 0.6003 - val_loss: 0.9527 - val_acc: 0.5405\n",
            "Epoch 65/150 - 0.10s - loss: 0.8769 - acc: 0.5879 - val_loss: 0.9579 - val_acc: 0.5364\n",
            "Epoch 66/150 - 0.09s - loss: 0.8670 - acc: 0.5996 - val_loss: 0.9541 - val_acc: 0.5385\n",
            "Epoch 67/150 - 0.10s - loss: 0.8801 - acc: 0.5879 - val_loss: 0.9740 - val_acc: 0.5182\n",
            "Epoch 68/150 - 0.10s - loss: 0.8632 - acc: 0.6037 - val_loss: 0.9507 - val_acc: 0.5466\n",
            "Epoch 69/150 - 0.10s - loss: 0.8653 - acc: 0.6057 - val_loss: 0.9589 - val_acc: 0.5486\n",
            "Epoch 70/150 - 0.10s - loss: 0.8635 - acc: 0.6055 - val_loss: 0.9534 - val_acc: 0.5526\n",
            "Epoch 71/150 - 0.09s - loss: 0.8632 - acc: 0.6053 - val_loss: 0.9566 - val_acc: 0.5385\n",
            "Epoch 72/150 - 0.10s - loss: 0.8668 - acc: 0.5954 - val_loss: 0.9577 - val_acc: 0.5526\n",
            "Epoch 73/150 - 0.10s - loss: 0.8647 - acc: 0.6073 - val_loss: 0.9662 - val_acc: 0.5486\n",
            "Epoch 74/150 - 0.10s - loss: 0.8781 - acc: 0.5960 - val_loss: 0.9825 - val_acc: 0.5223\n",
            "Epoch 75/150 - 0.10s - loss: 0.9160 - acc: 0.5623 - val_loss: 1.0195 - val_acc: 0.5000\n",
            "Epoch 76/150 - 0.10s - loss: 0.8673 - acc: 0.5927 - val_loss: 0.9609 - val_acc: 0.5385\n",
            "Epoch 77/150 - 0.10s - loss: 0.8568 - acc: 0.6082 - val_loss: 0.9561 - val_acc: 0.5445\n",
            "Epoch 78/150 - 0.09s - loss: 0.8787 - acc: 0.5902 - val_loss: 0.9848 - val_acc: 0.5223\n",
            "Epoch 79/150 - 0.10s - loss: 0.8851 - acc: 0.5814 - val_loss: 0.9867 - val_acc: 0.5202\n",
            "Epoch 80/150 - 0.09s - loss: 0.8681 - acc: 0.6055 - val_loss: 0.9629 - val_acc: 0.5567\n",
            "Epoch 81/150 - 0.10s - loss: 0.8517 - acc: 0.6098 - val_loss: 0.9556 - val_acc: 0.5405\n",
            "Epoch 82/150 - 0.11s - loss: 0.8572 - acc: 0.6080 - val_loss: 0.9666 - val_acc: 0.5364\n",
            "Epoch 83/150 - 0.09s - loss: 0.8699 - acc: 0.6021 - val_loss: 0.9660 - val_acc: 0.5587\n",
            "Epoch 84/150 - 0.11s - loss: 0.8823 - acc: 0.5803 - val_loss: 0.9768 - val_acc: 0.5466\n",
            "Epoch 85/150 - 0.11s - loss: 0.8558 - acc: 0.6064 - val_loss: 0.9623 - val_acc: 0.5364\n",
            "Epoch 86/150 - 0.09s - loss: 0.8503 - acc: 0.6098 - val_loss: 0.9600 - val_acc: 0.5587\n",
            "Epoch 87/150 - 0.09s - loss: 0.8553 - acc: 0.6127 - val_loss: 0.9581 - val_acc: 0.5709\n",
            "Epoch 88/150 - 0.09s - loss: 0.8494 - acc: 0.6093 - val_loss: 0.9566 - val_acc: 0.5587\n",
            "Epoch 89/150 - 0.09s - loss: 0.8607 - acc: 0.6084 - val_loss: 0.9664 - val_acc: 0.5547\n",
            "Epoch 90/150 - 0.08s - loss: 0.8681 - acc: 0.6035 - val_loss: 0.9725 - val_acc: 0.5547\n",
            "Epoch 91/150 - 0.09s - loss: 0.8561 - acc: 0.6039 - val_loss: 0.9638 - val_acc: 0.5445\n",
            "Epoch 92/150 - 0.09s - loss: 0.8450 - acc: 0.6172 - val_loss: 0.9572 - val_acc: 0.5506\n",
            "Epoch 93/150 - 0.09s - loss: 0.8454 - acc: 0.6201 - val_loss: 0.9592 - val_acc: 0.5547\n",
            "Epoch 94/150 - 0.09s - loss: 0.8540 - acc: 0.6050 - val_loss: 0.9733 - val_acc: 0.5405\n",
            "Epoch 95/150 - 0.08s - loss: 0.8482 - acc: 0.6197 - val_loss: 0.9619 - val_acc: 0.5648\n",
            "Epoch 96/150 - 0.09s - loss: 0.8571 - acc: 0.6008 - val_loss: 0.9724 - val_acc: 0.5223\n",
            "Epoch 97/150 - 0.09s - loss: 0.8619 - acc: 0.6014 - val_loss: 0.9815 - val_acc: 0.5182\n",
            "Epoch 98/150 - 0.09s - loss: 0.8475 - acc: 0.6071 - val_loss: 0.9598 - val_acc: 0.5567\n",
            "Epoch 99/150 - 0.09s - loss: 0.8631 - acc: 0.5967 - val_loss: 0.9744 - val_acc: 0.5385\n",
            "Epoch 100/150 - 0.09s - loss: 0.8670 - acc: 0.6046 - val_loss: 0.9743 - val_acc: 0.5547\n",
            "Epoch 101/150 - 0.09s - loss: 0.8572 - acc: 0.5992 - val_loss: 0.9703 - val_acc: 0.5466\n",
            "Epoch 102/150 - 0.09s - loss: 0.8449 - acc: 0.6217 - val_loss: 0.9625 - val_acc: 0.5709\n",
            "Epoch 103/150 - 0.09s - loss: 0.8652 - acc: 0.5963 - val_loss: 0.9757 - val_acc: 0.5506\n",
            "Epoch 104/150 - 0.09s - loss: 0.8405 - acc: 0.6181 - val_loss: 0.9643 - val_acc: 0.5466\n",
            "Epoch 105/150 - 0.08s - loss: 0.8389 - acc: 0.6203 - val_loss: 0.9621 - val_acc: 0.5506\n",
            "Epoch 106/150 - 0.09s - loss: 0.8449 - acc: 0.6185 - val_loss: 0.9647 - val_acc: 0.5648\n",
            "Epoch 107/150 - 0.09s - loss: 0.8488 - acc: 0.6057 - val_loss: 0.9706 - val_acc: 0.5324\n",
            "Epoch 108/150 - 0.09s - loss: 0.8517 - acc: 0.6118 - val_loss: 0.9783 - val_acc: 0.5445\n",
            "Epoch 109/150 - 0.09s - loss: 0.8518 - acc: 0.6077 - val_loss: 0.9785 - val_acc: 0.5304\n",
            "Epoch 110/150 - 0.08s - loss: 0.8410 - acc: 0.6161 - val_loss: 0.9696 - val_acc: 0.5506\n",
            "Epoch 111/150 - 0.09s - loss: 0.8547 - acc: 0.6071 - val_loss: 0.9873 - val_acc: 0.5344\n",
            "Epoch 112/150 - 0.09s - loss: 0.8472 - acc: 0.6100 - val_loss: 0.9758 - val_acc: 0.5344\n",
            "Epoch 113/150 - 0.09s - loss: 0.8409 - acc: 0.6230 - val_loss: 0.9700 - val_acc: 0.5648\n",
            "Epoch 114/150 - 0.09s - loss: 0.8473 - acc: 0.6152 - val_loss: 0.9693 - val_acc: 0.5587\n",
            "Epoch 115/150 - 0.09s - loss: 0.8412 - acc: 0.6199 - val_loss: 0.9642 - val_acc: 0.5607\n",
            "Epoch 116/150 - 0.09s - loss: 0.8363 - acc: 0.6239 - val_loss: 0.9627 - val_acc: 0.5607\n",
            "Epoch 117/150 - 0.09s - loss: 0.8460 - acc: 0.6210 - val_loss: 0.9717 - val_acc: 0.5648\n",
            "Epoch 118/150 - 0.09s - loss: 0.8546 - acc: 0.6044 - val_loss: 0.9779 - val_acc: 0.5405\n",
            "Epoch 119/150 - 0.09s - loss: 0.8343 - acc: 0.6147 - val_loss: 0.9632 - val_acc: 0.5607\n",
            "Epoch 120/150 - 0.08s - loss: 0.8367 - acc: 0.6242 - val_loss: 0.9644 - val_acc: 0.5567\n",
            "Epoch 121/150 - 0.09s - loss: 0.8592 - acc: 0.6120 - val_loss: 0.9807 - val_acc: 0.5607\n",
            "Epoch 122/150 - 0.08s - loss: 0.8364 - acc: 0.6212 - val_loss: 0.9697 - val_acc: 0.5587\n",
            "Epoch 123/150 - 0.09s - loss: 0.8450 - acc: 0.6104 - val_loss: 0.9817 - val_acc: 0.5385\n",
            "Epoch 124/150 - 0.09s - loss: 0.8361 - acc: 0.6248 - val_loss: 0.9681 - val_acc: 0.5587\n",
            "Epoch 125/150 - 0.08s - loss: 0.8487 - acc: 0.6163 - val_loss: 0.9820 - val_acc: 0.5324\n",
            "Epoch 126/150 - 0.09s - loss: 0.8454 - acc: 0.6188 - val_loss: 0.9753 - val_acc: 0.5688\n",
            "Epoch 127/150 - 0.10s - loss: 0.8616 - acc: 0.6001 - val_loss: 1.0074 - val_acc: 0.5182\n",
            "Epoch 128/150 - 0.09s - loss: 0.8301 - acc: 0.6253 - val_loss: 0.9638 - val_acc: 0.5567\n",
            "Epoch 129/150 - 0.08s - loss: 0.8346 - acc: 0.6179 - val_loss: 0.9756 - val_acc: 0.5587\n",
            "Epoch 130/150 - 0.09s - loss: 0.8601 - acc: 0.5972 - val_loss: 0.9843 - val_acc: 0.5486\n",
            "Epoch 131/150 - 0.09s - loss: 0.8369 - acc: 0.6215 - val_loss: 0.9666 - val_acc: 0.5506\n",
            "Epoch 132/150 - 0.08s - loss: 0.8309 - acc: 0.6320 - val_loss: 0.9661 - val_acc: 0.5648\n",
            "Epoch 133/150 - 0.09s - loss: 0.8428 - acc: 0.6134 - val_loss: 0.9695 - val_acc: 0.5466\n",
            "Epoch 134/150 - 0.09s - loss: 0.8302 - acc: 0.6262 - val_loss: 0.9651 - val_acc: 0.5648\n",
            "Epoch 135/150 - 0.09s - loss: 0.8468 - acc: 0.6062 - val_loss: 0.9899 - val_acc: 0.5324\n",
            "Epoch 136/150 - 0.09s - loss: 0.8608 - acc: 0.5978 - val_loss: 0.9869 - val_acc: 0.5405\n",
            "Epoch 137/150 - 0.09s - loss: 0.8293 - acc: 0.6278 - val_loss: 0.9635 - val_acc: 0.5607\n",
            "Epoch 138/150 - 0.08s - loss: 0.8307 - acc: 0.6192 - val_loss: 0.9720 - val_acc: 0.5567\n",
            "Epoch 139/150 - 0.10s - loss: 0.8710 - acc: 0.5886 - val_loss: 1.0188 - val_acc: 0.5101\n",
            "Epoch 140/150 - 0.10s - loss: 0.8273 - acc: 0.6278 - val_loss: 0.9646 - val_acc: 0.5547\n",
            "Epoch 141/150 - 0.09s - loss: 0.8572 - acc: 0.6136 - val_loss: 0.9864 - val_acc: 0.5506\n",
            "Epoch 142/150 - 0.10s - loss: 0.8324 - acc: 0.6183 - val_loss: 0.9785 - val_acc: 0.5506\n",
            "Epoch 143/150 - 0.09s - loss: 0.8371 - acc: 0.6239 - val_loss: 0.9837 - val_acc: 0.5385\n",
            "Epoch 144/150 - 0.09s - loss: 0.8343 - acc: 0.6278 - val_loss: 0.9692 - val_acc: 0.5587\n",
            "Epoch 145/150 - 0.09s - loss: 0.8275 - acc: 0.6251 - val_loss: 0.9725 - val_acc: 0.5607\n",
            "Epoch 146/150 - 0.09s - loss: 0.8266 - acc: 0.6237 - val_loss: 0.9741 - val_acc: 0.5526\n",
            "Epoch 147/150 - 0.08s - loss: 0.8754 - acc: 0.5893 - val_loss: 1.0274 - val_acc: 0.5040\n",
            "Epoch 148/150 - 0.09s - loss: 0.8272 - acc: 0.6327 - val_loss: 0.9704 - val_acc: 0.5628\n",
            "Epoch 149/150 - 0.09s - loss: 0.8490 - acc: 0.6030 - val_loss: 0.9892 - val_acc: 0.5243\n",
            "Epoch 150/150 - 0.09s - loss: 0.8280 - acc: 0.6298 - val_loss: 0.9680 - val_acc: 0.5526\n",
            "\n",
            "Combination 58/252:\n",
            "Hidden Layers: [128, 64], Activation: tanh, Learning Rate: 0.01, Batch Size: 64, Epochs: 50\n",
            "Epoch 1/50 - 0.08s - loss: 1.0899 - acc: 0.3767 - val_loss: 1.0871 - val_acc: 0.3846\n",
            "Epoch 2/50 - 0.08s - loss: 1.0813 - acc: 0.4098 - val_loss: 1.0794 - val_acc: 0.4109\n",
            "Epoch 3/50 - 0.08s - loss: 1.0739 - acc: 0.4431 - val_loss: 1.0740 - val_acc: 0.4595\n",
            "Epoch 4/50 - 0.08s - loss: 1.0678 - acc: 0.4480 - val_loss: 1.0685 - val_acc: 0.4615\n",
            "Epoch 5/50 - 0.08s - loss: 1.0623 - acc: 0.4604 - val_loss: 1.0652 - val_acc: 0.4575\n",
            "Epoch 6/50 - 0.08s - loss: 1.0572 - acc: 0.4606 - val_loss: 1.0614 - val_acc: 0.4676\n",
            "Epoch 7/50 - 0.08s - loss: 1.0526 - acc: 0.4705 - val_loss: 1.0578 - val_acc: 0.4757\n",
            "Epoch 8/50 - 0.08s - loss: 1.0485 - acc: 0.4777 - val_loss: 1.0556 - val_acc: 0.4676\n",
            "Epoch 9/50 - 0.07s - loss: 1.0447 - acc: 0.4798 - val_loss: 1.0531 - val_acc: 0.4656\n",
            "Epoch 10/50 - 0.07s - loss: 1.0410 - acc: 0.4854 - val_loss: 1.0506 - val_acc: 0.4696\n",
            "Epoch 11/50 - 0.08s - loss: 1.0370 - acc: 0.4876 - val_loss: 1.0474 - val_acc: 0.4615\n",
            "Epoch 12/50 - 0.07s - loss: 1.0346 - acc: 0.4784 - val_loss: 1.0458 - val_acc: 0.4757\n",
            "Epoch 13/50 - 0.07s - loss: 1.0303 - acc: 0.4897 - val_loss: 1.0420 - val_acc: 0.4737\n",
            "Epoch 14/50 - 0.08s - loss: 1.0272 - acc: 0.4946 - val_loss: 1.0406 - val_acc: 0.4858\n",
            "Epoch 15/50 - 0.07s - loss: 1.0265 - acc: 0.4980 - val_loss: 1.0425 - val_acc: 0.4777\n",
            "Epoch 16/50 - 0.07s - loss: 1.0201 - acc: 0.4973 - val_loss: 1.0357 - val_acc: 0.4919\n",
            "Epoch 17/50 - 0.08s - loss: 1.0170 - acc: 0.5007 - val_loss: 1.0334 - val_acc: 0.4919\n",
            "Epoch 18/50 - 0.07s - loss: 1.0139 - acc: 0.5081 - val_loss: 1.0315 - val_acc: 0.4919\n",
            "Epoch 19/50 - 0.07s - loss: 1.0126 - acc: 0.5002 - val_loss: 1.0290 - val_acc: 0.4919\n",
            "Epoch 20/50 - 0.08s - loss: 1.0094 - acc: 0.5013 - val_loss: 1.0271 - val_acc: 0.5020\n",
            "Epoch 21/50 - 0.07s - loss: 1.0047 - acc: 0.5153 - val_loss: 1.0236 - val_acc: 0.5020\n",
            "Epoch 22/50 - 0.08s - loss: 1.0020 - acc: 0.5153 - val_loss: 1.0225 - val_acc: 0.5304\n",
            "Epoch 23/50 - 0.08s - loss: 0.9989 - acc: 0.5196 - val_loss: 1.0197 - val_acc: 0.5324\n",
            "Epoch 24/50 - 0.07s - loss: 0.9960 - acc: 0.5184 - val_loss: 1.0162 - val_acc: 0.5121\n",
            "Epoch 25/50 - 0.08s - loss: 0.9963 - acc: 0.5142 - val_loss: 1.0163 - val_acc: 0.5182\n",
            "Epoch 26/50 - 0.07s - loss: 0.9922 - acc: 0.5191 - val_loss: 1.0129 - val_acc: 0.5243\n",
            "Epoch 27/50 - 0.07s - loss: 0.9871 - acc: 0.5283 - val_loss: 1.0094 - val_acc: 0.5182\n",
            "Epoch 28/50 - 0.07s - loss: 0.9866 - acc: 0.5254 - val_loss: 1.0110 - val_acc: 0.5121\n",
            "Epoch 29/50 - 0.08s - loss: 0.9832 - acc: 0.5335 - val_loss: 1.0074 - val_acc: 0.5344\n",
            "Epoch 30/50 - 0.07s - loss: 0.9802 - acc: 0.5353 - val_loss: 1.0035 - val_acc: 0.5364\n",
            "Epoch 31/50 - 0.07s - loss: 0.9766 - acc: 0.5344 - val_loss: 1.0006 - val_acc: 0.5142\n",
            "Epoch 32/50 - 0.07s - loss: 0.9726 - acc: 0.5432 - val_loss: 0.9973 - val_acc: 0.5283\n",
            "Epoch 33/50 - 0.07s - loss: 0.9700 - acc: 0.5450 - val_loss: 0.9952 - val_acc: 0.5344\n",
            "Epoch 34/50 - 0.07s - loss: 0.9677 - acc: 0.5436 - val_loss: 0.9932 - val_acc: 0.5283\n",
            "Epoch 35/50 - 0.08s - loss: 0.9653 - acc: 0.5479 - val_loss: 0.9920 - val_acc: 0.5425\n",
            "Epoch 36/50 - 0.07s - loss: 0.9639 - acc: 0.5427 - val_loss: 0.9910 - val_acc: 0.5263\n",
            "Epoch 37/50 - 0.08s - loss: 0.9639 - acc: 0.5385 - val_loss: 0.9896 - val_acc: 0.5101\n",
            "Epoch 38/50 - 0.08s - loss: 0.9620 - acc: 0.5434 - val_loss: 0.9882 - val_acc: 0.5405\n",
            "Epoch 39/50 - 0.07s - loss: 0.9567 - acc: 0.5506 - val_loss: 0.9850 - val_acc: 0.5506\n",
            "Epoch 40/50 - 0.07s - loss: 0.9554 - acc: 0.5466 - val_loss: 0.9837 - val_acc: 0.5466\n",
            "Epoch 41/50 - 0.08s - loss: 0.9531 - acc: 0.5484 - val_loss: 0.9817 - val_acc: 0.5506\n",
            "Epoch 42/50 - 0.07s - loss: 0.9555 - acc: 0.5479 - val_loss: 0.9845 - val_acc: 0.5567\n",
            "Epoch 43/50 - 0.07s - loss: 0.9489 - acc: 0.5506 - val_loss: 0.9803 - val_acc: 0.5385\n",
            "Epoch 44/50 - 0.08s - loss: 0.9465 - acc: 0.5517 - val_loss: 0.9773 - val_acc: 0.5405\n",
            "Epoch 45/50 - 0.08s - loss: 0.9443 - acc: 0.5540 - val_loss: 0.9753 - val_acc: 0.5466\n",
            "Epoch 46/50 - 0.08s - loss: 0.9440 - acc: 0.5576 - val_loss: 0.9764 - val_acc: 0.5526\n",
            "Epoch 47/50 - 0.08s - loss: 0.9432 - acc: 0.5515 - val_loss: 0.9748 - val_acc: 0.5304\n",
            "Epoch 48/50 - 0.07s - loss: 0.9390 - acc: 0.5551 - val_loss: 0.9718 - val_acc: 0.5486\n",
            "Epoch 49/50 - 0.08s - loss: 0.9389 - acc: 0.5592 - val_loss: 0.9716 - val_acc: 0.5607\n",
            "Epoch 50/50 - 0.08s - loss: 0.9365 - acc: 0.5565 - val_loss: 0.9706 - val_acc: 0.5405\n",
            "\n",
            "Combination 59/252:\n",
            "Hidden Layers: [128, 64], Activation: tanh, Learning Rate: 0.01, Batch Size: 64, Epochs: 100\n",
            "Epoch 1/100 - 0.08s - loss: 1.0902 - acc: 0.3963 - val_loss: 1.0951 - val_acc: 0.3907\n",
            "Epoch 2/100 - 0.09s - loss: 1.0814 - acc: 0.4181 - val_loss: 1.0864 - val_acc: 0.4109\n",
            "Epoch 3/100 - 0.08s - loss: 1.0738 - acc: 0.4291 - val_loss: 1.0809 - val_acc: 0.4150\n",
            "Epoch 4/100 - 0.08s - loss: 1.0679 - acc: 0.4424 - val_loss: 1.0763 - val_acc: 0.4453\n",
            "Epoch 5/100 - 0.08s - loss: 1.0633 - acc: 0.4485 - val_loss: 1.0732 - val_acc: 0.4251\n",
            "Epoch 6/100 - 0.08s - loss: 1.0577 - acc: 0.4602 - val_loss: 1.0688 - val_acc: 0.4494\n",
            "Epoch 7/100 - 0.08s - loss: 1.0533 - acc: 0.4577 - val_loss: 1.0653 - val_acc: 0.4453\n",
            "Epoch 8/100 - 0.08s - loss: 1.0503 - acc: 0.4627 - val_loss: 1.0639 - val_acc: 0.4433\n",
            "Epoch 9/100 - 0.08s - loss: 1.0446 - acc: 0.4685 - val_loss: 1.0590 - val_acc: 0.4656\n",
            "Epoch 10/100 - 0.08s - loss: 1.0415 - acc: 0.4708 - val_loss: 1.0564 - val_acc: 0.4595\n",
            "Epoch 11/100 - 0.08s - loss: 1.0370 - acc: 0.4813 - val_loss: 1.0541 - val_acc: 0.4717\n",
            "Epoch 12/100 - 0.08s - loss: 1.0348 - acc: 0.4845 - val_loss: 1.0525 - val_acc: 0.4534\n",
            "Epoch 13/100 - 0.08s - loss: 1.0303 - acc: 0.4888 - val_loss: 1.0494 - val_acc: 0.4696\n",
            "Epoch 14/100 - 0.08s - loss: 1.0273 - acc: 0.4903 - val_loss: 1.0477 - val_acc: 0.4696\n",
            "Epoch 15/100 - 0.08s - loss: 1.0241 - acc: 0.5000 - val_loss: 1.0465 - val_acc: 0.5081\n",
            "Epoch 16/100 - 0.07s - loss: 1.0201 - acc: 0.4876 - val_loss: 1.0425 - val_acc: 0.5061\n",
            "Epoch 17/100 - 0.07s - loss: 1.0164 - acc: 0.5007 - val_loss: 1.0397 - val_acc: 0.5101\n",
            "Epoch 18/100 - 0.08s - loss: 1.0138 - acc: 0.5047 - val_loss: 1.0372 - val_acc: 0.4858\n",
            "Epoch 19/100 - 0.07s - loss: 1.0095 - acc: 0.5076 - val_loss: 1.0341 - val_acc: 0.5162\n",
            "Epoch 20/100 - 0.07s - loss: 1.0064 - acc: 0.5106 - val_loss: 1.0320 - val_acc: 0.5202\n",
            "Epoch 21/100 - 0.08s - loss: 1.0052 - acc: 0.5099 - val_loss: 1.0320 - val_acc: 0.5202\n",
            "Epoch 22/100 - 0.07s - loss: 1.0000 - acc: 0.5133 - val_loss: 1.0264 - val_acc: 0.5202\n",
            "Epoch 23/100 - 0.07s - loss: 0.9972 - acc: 0.5180 - val_loss: 1.0250 - val_acc: 0.5061\n",
            "Epoch 24/100 - 0.08s - loss: 0.9940 - acc: 0.5205 - val_loss: 1.0220 - val_acc: 0.5243\n",
            "Epoch 25/100 - 0.07s - loss: 0.9941 - acc: 0.5175 - val_loss: 1.0214 - val_acc: 0.4798\n",
            "Epoch 26/100 - 0.08s - loss: 0.9925 - acc: 0.5205 - val_loss: 1.0225 - val_acc: 0.5101\n",
            "Epoch 27/100 - 0.08s - loss: 0.9867 - acc: 0.5263 - val_loss: 1.0163 - val_acc: 0.4939\n",
            "Epoch 28/100 - 0.08s - loss: 0.9836 - acc: 0.5299 - val_loss: 1.0147 - val_acc: 0.5061\n",
            "Epoch 29/100 - 0.08s - loss: 0.9832 - acc: 0.5288 - val_loss: 1.0146 - val_acc: 0.4980\n",
            "Epoch 30/100 - 0.08s - loss: 0.9798 - acc: 0.5315 - val_loss: 1.0102 - val_acc: 0.5324\n",
            "Epoch 31/100 - 0.08s - loss: 0.9740 - acc: 0.5324 - val_loss: 1.0045 - val_acc: 0.5405\n",
            "Epoch 32/100 - 0.08s - loss: 0.9719 - acc: 0.5335 - val_loss: 1.0022 - val_acc: 0.5344\n",
            "Epoch 33/100 - 0.08s - loss: 0.9807 - acc: 0.5148 - val_loss: 1.0125 - val_acc: 0.4696\n",
            "Epoch 34/100 - 0.08s - loss: 0.9672 - acc: 0.5364 - val_loss: 0.9989 - val_acc: 0.5142\n",
            "Epoch 35/100 - 0.07s - loss: 0.9736 - acc: 0.5297 - val_loss: 1.0076 - val_acc: 0.4757\n",
            "Epoch 36/100 - 0.08s - loss: 0.9633 - acc: 0.5425 - val_loss: 0.9956 - val_acc: 0.5405\n",
            "Epoch 37/100 - 0.08s - loss: 0.9618 - acc: 0.5432 - val_loss: 0.9943 - val_acc: 0.5364\n",
            "Epoch 38/100 - 0.08s - loss: 0.9715 - acc: 0.5191 - val_loss: 1.0045 - val_acc: 0.4838\n",
            "Epoch 39/100 - 0.08s - loss: 0.9565 - acc: 0.5454 - val_loss: 0.9898 - val_acc: 0.5364\n",
            "Epoch 40/100 - 0.08s - loss: 0.9565 - acc: 0.5436 - val_loss: 0.9894 - val_acc: 0.5304\n",
            "Epoch 41/100 - 0.08s - loss: 0.9544 - acc: 0.5479 - val_loss: 0.9888 - val_acc: 0.5364\n",
            "Epoch 42/100 - 0.08s - loss: 0.9506 - acc: 0.5495 - val_loss: 0.9867 - val_acc: 0.5283\n",
            "Epoch 43/100 - 0.08s - loss: 0.9477 - acc: 0.5529 - val_loss: 0.9846 - val_acc: 0.5364\n",
            "Epoch 44/100 - 0.08s - loss: 0.9448 - acc: 0.5540 - val_loss: 0.9811 - val_acc: 0.5385\n",
            "Epoch 45/100 - 0.09s - loss: 0.9489 - acc: 0.5499 - val_loss: 0.9878 - val_acc: 0.5162\n",
            "Epoch 46/100 - 0.08s - loss: 0.9426 - acc: 0.5558 - val_loss: 0.9815 - val_acc: 0.5263\n",
            "Epoch 47/100 - 0.09s - loss: 0.9527 - acc: 0.5486 - val_loss: 0.9883 - val_acc: 0.5445\n",
            "Epoch 48/100 - 0.08s - loss: 0.9389 - acc: 0.5578 - val_loss: 0.9781 - val_acc: 0.5162\n",
            "Epoch 49/100 - 0.08s - loss: 0.9381 - acc: 0.5560 - val_loss: 0.9756 - val_acc: 0.5344\n",
            "Epoch 50/100 - 0.08s - loss: 0.9383 - acc: 0.5556 - val_loss: 0.9762 - val_acc: 0.5466\n",
            "Epoch 51/100 - 0.08s - loss: 0.9335 - acc: 0.5625 - val_loss: 0.9743 - val_acc: 0.5364\n",
            "Epoch 52/100 - 0.08s - loss: 0.9423 - acc: 0.5594 - val_loss: 0.9814 - val_acc: 0.5445\n",
            "Epoch 53/100 - 0.09s - loss: 0.9308 - acc: 0.5643 - val_loss: 0.9718 - val_acc: 0.5486\n",
            "Epoch 54/100 - 0.08s - loss: 0.9284 - acc: 0.5659 - val_loss: 0.9703 - val_acc: 0.5506\n",
            "Epoch 55/100 - 0.07s - loss: 0.9382 - acc: 0.5547 - val_loss: 0.9768 - val_acc: 0.5466\n",
            "Epoch 56/100 - 0.07s - loss: 0.9405 - acc: 0.5457 - val_loss: 0.9850 - val_acc: 0.5020\n",
            "Epoch 57/100 - 0.08s - loss: 0.9242 - acc: 0.5684 - val_loss: 0.9671 - val_acc: 0.5425\n",
            "Epoch 58/100 - 0.08s - loss: 0.9336 - acc: 0.5623 - val_loss: 0.9752 - val_acc: 0.5263\n",
            "Epoch 59/100 - 0.09s - loss: 0.9263 - acc: 0.5668 - val_loss: 0.9688 - val_acc: 0.5486\n",
            "Epoch 60/100 - 0.08s - loss: 0.9422 - acc: 0.5567 - val_loss: 0.9833 - val_acc: 0.5587\n",
            "Epoch 61/100 - 0.08s - loss: 0.9347 - acc: 0.5497 - val_loss: 0.9828 - val_acc: 0.5000\n",
            "Epoch 62/100 - 0.08s - loss: 0.9241 - acc: 0.5711 - val_loss: 0.9690 - val_acc: 0.5547\n",
            "Epoch 63/100 - 0.08s - loss: 0.9194 - acc: 0.5648 - val_loss: 0.9653 - val_acc: 0.5405\n",
            "Epoch 64/100 - 0.08s - loss: 0.9168 - acc: 0.5724 - val_loss: 0.9658 - val_acc: 0.5607\n",
            "Epoch 65/100 - 0.08s - loss: 0.9139 - acc: 0.5724 - val_loss: 0.9607 - val_acc: 0.5506\n",
            "Epoch 66/100 - 0.08s - loss: 0.9159 - acc: 0.5715 - val_loss: 0.9622 - val_acc: 0.5466\n",
            "Epoch 67/100 - 0.07s - loss: 0.9121 - acc: 0.5724 - val_loss: 0.9602 - val_acc: 0.5445\n",
            "Epoch 68/100 - 0.07s - loss: 0.9167 - acc: 0.5702 - val_loss: 0.9682 - val_acc: 0.5445\n",
            "Epoch 69/100 - 0.08s - loss: 0.9178 - acc: 0.5751 - val_loss: 0.9683 - val_acc: 0.5567\n",
            "Epoch 70/100 - 0.07s - loss: 0.9120 - acc: 0.5704 - val_loss: 0.9599 - val_acc: 0.5486\n",
            "Epoch 71/100 - 0.07s - loss: 0.9191 - acc: 0.5742 - val_loss: 0.9682 - val_acc: 0.5425\n",
            "Epoch 72/100 - 0.08s - loss: 0.9048 - acc: 0.5783 - val_loss: 0.9568 - val_acc: 0.5486\n",
            "Epoch 73/100 - 0.07s - loss: 0.9186 - acc: 0.5715 - val_loss: 0.9702 - val_acc: 0.5425\n",
            "Epoch 74/100 - 0.07s - loss: 0.9081 - acc: 0.5713 - val_loss: 0.9620 - val_acc: 0.5223\n",
            "Epoch 75/100 - 0.08s - loss: 0.9125 - acc: 0.5673 - val_loss: 0.9691 - val_acc: 0.5040\n",
            "Epoch 76/100 - 0.07s - loss: 0.9040 - acc: 0.5751 - val_loss: 0.9599 - val_acc: 0.5243\n",
            "Epoch 77/100 - 0.07s - loss: 0.9039 - acc: 0.5814 - val_loss: 0.9578 - val_acc: 0.5607\n",
            "Epoch 78/100 - 0.08s - loss: 0.9384 - acc: 0.5434 - val_loss: 0.9985 - val_acc: 0.5040\n",
            "Epoch 79/100 - 0.07s - loss: 0.9106 - acc: 0.5760 - val_loss: 0.9687 - val_acc: 0.5324\n",
            "Epoch 80/100 - 0.07s - loss: 0.9001 - acc: 0.5832 - val_loss: 0.9555 - val_acc: 0.5628\n",
            "Epoch 81/100 - 0.08s - loss: 0.8960 - acc: 0.5816 - val_loss: 0.9553 - val_acc: 0.5385\n",
            "Epoch 82/100 - 0.07s - loss: 0.9229 - acc: 0.5729 - val_loss: 0.9808 - val_acc: 0.5324\n",
            "Epoch 83/100 - 0.07s - loss: 0.8942 - acc: 0.5805 - val_loss: 0.9540 - val_acc: 0.5547\n",
            "Epoch 84/100 - 0.09s - loss: 0.8958 - acc: 0.5767 - val_loss: 0.9575 - val_acc: 0.5324\n",
            "Epoch 85/100 - 0.07s - loss: 0.8949 - acc: 0.5866 - val_loss: 0.9570 - val_acc: 0.5486\n",
            "Epoch 86/100 - 0.07s - loss: 0.8927 - acc: 0.5803 - val_loss: 0.9555 - val_acc: 0.5385\n",
            "Epoch 87/100 - 0.08s - loss: 0.8919 - acc: 0.5868 - val_loss: 0.9533 - val_acc: 0.5688\n",
            "Epoch 88/100 - 0.07s - loss: 0.8931 - acc: 0.5893 - val_loss: 0.9578 - val_acc: 0.5486\n",
            "Epoch 89/100 - 0.07s - loss: 0.8881 - acc: 0.5843 - val_loss: 0.9523 - val_acc: 0.5628\n",
            "Epoch 90/100 - 0.08s - loss: 0.8960 - acc: 0.5751 - val_loss: 0.9641 - val_acc: 0.5061\n",
            "Epoch 91/100 - 0.08s - loss: 0.8870 - acc: 0.5891 - val_loss: 0.9537 - val_acc: 0.5405\n",
            "Epoch 92/100 - 0.07s - loss: 0.8970 - acc: 0.5861 - val_loss: 0.9613 - val_acc: 0.5688\n",
            "Epoch 93/100 - 0.09s - loss: 0.8856 - acc: 0.5846 - val_loss: 0.9525 - val_acc: 0.5405\n",
            "Epoch 94/100 - 0.08s - loss: 0.9070 - acc: 0.5789 - val_loss: 0.9742 - val_acc: 0.5466\n",
            "Epoch 95/100 - 0.08s - loss: 0.8987 - acc: 0.5726 - val_loss: 0.9697 - val_acc: 0.5101\n",
            "Epoch 96/100 - 0.08s - loss: 0.8843 - acc: 0.5936 - val_loss: 0.9549 - val_acc: 0.5364\n",
            "Epoch 97/100 - 0.08s - loss: 0.8887 - acc: 0.5810 - val_loss: 0.9563 - val_acc: 0.5344\n",
            "Epoch 98/100 - 0.08s - loss: 0.9056 - acc: 0.5803 - val_loss: 0.9694 - val_acc: 0.5607\n",
            "Epoch 99/100 - 0.08s - loss: 0.8853 - acc: 0.5870 - val_loss: 0.9525 - val_acc: 0.5466\n",
            "Epoch 100/100 - 0.08s - loss: 0.8809 - acc: 0.5906 - val_loss: 0.9536 - val_acc: 0.5324\n",
            "\n",
            "Combination 60/252:\n",
            "Hidden Layers: [128, 64], Activation: tanh, Learning Rate: 0.01, Batch Size: 64, Epochs: 150\n",
            "Epoch 1/150 - 0.08s - loss: 1.0959 - acc: 0.3462 - val_loss: 1.0966 - val_acc: 0.3603\n",
            "Epoch 2/150 - 0.08s - loss: 1.0839 - acc: 0.4060 - val_loss: 1.0843 - val_acc: 0.3927\n",
            "Epoch 3/150 - 0.08s - loss: 1.0766 - acc: 0.4181 - val_loss: 1.0800 - val_acc: 0.3927\n",
            "Epoch 4/150 - 0.08s - loss: 1.0691 - acc: 0.4429 - val_loss: 1.0734 - val_acc: 0.4312\n",
            "Epoch 5/150 - 0.08s - loss: 1.0632 - acc: 0.4568 - val_loss: 1.0685 - val_acc: 0.4615\n",
            "Epoch 6/150 - 0.08s - loss: 1.0584 - acc: 0.4647 - val_loss: 1.0652 - val_acc: 0.4555\n",
            "Epoch 7/150 - 0.08s - loss: 1.0550 - acc: 0.4573 - val_loss: 1.0633 - val_acc: 0.4514\n",
            "Epoch 8/150 - 0.08s - loss: 1.0497 - acc: 0.4755 - val_loss: 1.0583 - val_acc: 0.4595\n",
            "Epoch 9/150 - 0.08s - loss: 1.0468 - acc: 0.4676 - val_loss: 1.0554 - val_acc: 0.4696\n",
            "Epoch 10/150 - 0.08s - loss: 1.0429 - acc: 0.4840 - val_loss: 1.0539 - val_acc: 0.4798\n",
            "Epoch 11/150 - 0.08s - loss: 1.0393 - acc: 0.4811 - val_loss: 1.0512 - val_acc: 0.4798\n",
            "Epoch 12/150 - 0.08s - loss: 1.0360 - acc: 0.4827 - val_loss: 1.0488 - val_acc: 0.4818\n",
            "Epoch 13/150 - 0.07s - loss: 1.0336 - acc: 0.4854 - val_loss: 1.0462 - val_acc: 0.4858\n",
            "Epoch 14/150 - 0.08s - loss: 1.0298 - acc: 0.4888 - val_loss: 1.0442 - val_acc: 0.4858\n",
            "Epoch 15/150 - 0.07s - loss: 1.0276 - acc: 0.4919 - val_loss: 1.0440 - val_acc: 0.4939\n",
            "Epoch 16/150 - 0.08s - loss: 1.0236 - acc: 0.4998 - val_loss: 1.0402 - val_acc: 0.5081\n",
            "Epoch 17/150 - 0.08s - loss: 1.0211 - acc: 0.4978 - val_loss: 1.0388 - val_acc: 0.4879\n",
            "Epoch 18/150 - 0.07s - loss: 1.0183 - acc: 0.4975 - val_loss: 1.0355 - val_acc: 0.4939\n",
            "Epoch 19/150 - 0.08s - loss: 1.0154 - acc: 0.5040 - val_loss: 1.0352 - val_acc: 0.5081\n",
            "Epoch 20/150 - 0.08s - loss: 1.0119 - acc: 0.5031 - val_loss: 1.0307 - val_acc: 0.5081\n",
            "Epoch 21/150 - 0.07s - loss: 1.0136 - acc: 0.4917 - val_loss: 1.0315 - val_acc: 0.4899\n",
            "Epoch 22/150 - 0.07s - loss: 1.0060 - acc: 0.5133 - val_loss: 1.0273 - val_acc: 0.5101\n",
            "Epoch 23/150 - 0.08s - loss: 1.0021 - acc: 0.5191 - val_loss: 1.0233 - val_acc: 0.5121\n",
            "Epoch 24/150 - 0.07s - loss: 1.0002 - acc: 0.5139 - val_loss: 1.0209 - val_acc: 0.5101\n",
            "Epoch 25/150 - 0.07s - loss: 0.9971 - acc: 0.5198 - val_loss: 1.0184 - val_acc: 0.5223\n",
            "Epoch 26/150 - 0.08s - loss: 0.9937 - acc: 0.5220 - val_loss: 1.0166 - val_acc: 0.5223\n",
            "Epoch 27/150 - 0.08s - loss: 0.9899 - acc: 0.5245 - val_loss: 1.0134 - val_acc: 0.5283\n",
            "Epoch 28/150 - 0.08s - loss: 0.9870 - acc: 0.5277 - val_loss: 1.0110 - val_acc: 0.5243\n",
            "Epoch 29/150 - 0.09s - loss: 0.9845 - acc: 0.5274 - val_loss: 1.0099 - val_acc: 0.5223\n",
            "Epoch 30/150 - 0.08s - loss: 0.9835 - acc: 0.5308 - val_loss: 1.0099 - val_acc: 0.5304\n",
            "Epoch 31/150 - 0.07s - loss: 0.9841 - acc: 0.5243 - val_loss: 1.0122 - val_acc: 0.5182\n",
            "Epoch 32/150 - 0.07s - loss: 0.9792 - acc: 0.5288 - val_loss: 1.0076 - val_acc: 0.5243\n",
            "Epoch 33/150 - 0.07s - loss: 0.9731 - acc: 0.5364 - val_loss: 1.0004 - val_acc: 0.5283\n",
            "Epoch 34/150 - 0.07s - loss: 0.9700 - acc: 0.5391 - val_loss: 0.9965 - val_acc: 0.5445\n",
            "Epoch 35/150 - 0.08s - loss: 0.9673 - acc: 0.5430 - val_loss: 0.9943 - val_acc: 0.5445\n",
            "Epoch 36/150 - 0.08s - loss: 0.9642 - acc: 0.5427 - val_loss: 0.9928 - val_acc: 0.5304\n",
            "Epoch 37/150 - 0.08s - loss: 0.9627 - acc: 0.5427 - val_loss: 0.9921 - val_acc: 0.5324\n",
            "Epoch 38/150 - 0.08s - loss: 0.9603 - acc: 0.5495 - val_loss: 0.9909 - val_acc: 0.5506\n",
            "Epoch 39/150 - 0.07s - loss: 0.9568 - acc: 0.5443 - val_loss: 0.9865 - val_acc: 0.5466\n",
            "Epoch 40/150 - 0.08s - loss: 0.9543 - acc: 0.5484 - val_loss: 0.9846 - val_acc: 0.5506\n",
            "Epoch 41/150 - 0.08s - loss: 0.9585 - acc: 0.5508 - val_loss: 0.9866 - val_acc: 0.5405\n",
            "Epoch 42/150 - 0.07s - loss: 0.9511 - acc: 0.5522 - val_loss: 0.9812 - val_acc: 0.5425\n",
            "Epoch 43/150 - 0.07s - loss: 0.9483 - acc: 0.5538 - val_loss: 0.9809 - val_acc: 0.5628\n",
            "Epoch 44/150 - 0.08s - loss: 0.9556 - acc: 0.5513 - val_loss: 0.9844 - val_acc: 0.5445\n",
            "Epoch 45/150 - 0.07s - loss: 0.9441 - acc: 0.5585 - val_loss: 0.9784 - val_acc: 0.5385\n",
            "Epoch 46/150 - 0.07s - loss: 0.9413 - acc: 0.5533 - val_loss: 0.9748 - val_acc: 0.5628\n",
            "Epoch 47/150 - 0.07s - loss: 0.9399 - acc: 0.5567 - val_loss: 0.9734 - val_acc: 0.5385\n",
            "Epoch 48/150 - 0.07s - loss: 0.9407 - acc: 0.5607 - val_loss: 0.9776 - val_acc: 0.5405\n",
            "Epoch 49/150 - 0.08s - loss: 0.9442 - acc: 0.5493 - val_loss: 0.9828 - val_acc: 0.5344\n",
            "Epoch 50/150 - 0.08s - loss: 0.9437 - acc: 0.5522 - val_loss: 0.9841 - val_acc: 0.5324\n",
            "Epoch 51/150 - 0.07s - loss: 0.9370 - acc: 0.5596 - val_loss: 0.9765 - val_acc: 0.5304\n",
            "Epoch 52/150 - 0.07s - loss: 0.9316 - acc: 0.5652 - val_loss: 0.9686 - val_acc: 0.5648\n",
            "Epoch 53/150 - 0.08s - loss: 0.9283 - acc: 0.5628 - val_loss: 0.9669 - val_acc: 0.5506\n",
            "Epoch 54/150 - 0.07s - loss: 0.9358 - acc: 0.5691 - val_loss: 0.9716 - val_acc: 0.5587\n",
            "Epoch 55/150 - 0.08s - loss: 0.9250 - acc: 0.5630 - val_loss: 0.9651 - val_acc: 0.5567\n",
            "Epoch 56/150 - 0.08s - loss: 0.9284 - acc: 0.5612 - val_loss: 0.9718 - val_acc: 0.5405\n",
            "Epoch 57/150 - 0.08s - loss: 0.9231 - acc: 0.5666 - val_loss: 0.9659 - val_acc: 0.5425\n",
            "Epoch 58/150 - 0.08s - loss: 0.9262 - acc: 0.5574 - val_loss: 0.9680 - val_acc: 0.5385\n",
            "Epoch 59/150 - 0.08s - loss: 0.9207 - acc: 0.5704 - val_loss: 0.9620 - val_acc: 0.5789\n",
            "Epoch 60/150 - 0.07s - loss: 0.9172 - acc: 0.5726 - val_loss: 0.9611 - val_acc: 0.5587\n",
            "Epoch 61/150 - 0.07s - loss: 0.9190 - acc: 0.5717 - val_loss: 0.9656 - val_acc: 0.5506\n",
            "Epoch 62/150 - 0.08s - loss: 0.9225 - acc: 0.5605 - val_loss: 0.9710 - val_acc: 0.5344\n",
            "Epoch 63/150 - 0.07s - loss: 0.9433 - acc: 0.5459 - val_loss: 0.9951 - val_acc: 0.5061\n",
            "Epoch 64/150 - 0.07s - loss: 0.9126 - acc: 0.5733 - val_loss: 0.9600 - val_acc: 0.5506\n",
            "Epoch 65/150 - 0.08s - loss: 0.9117 - acc: 0.5812 - val_loss: 0.9591 - val_acc: 0.5648\n",
            "Epoch 66/150 - 0.08s - loss: 0.9165 - acc: 0.5679 - val_loss: 0.9681 - val_acc: 0.5263\n",
            "Epoch 67/150 - 0.08s - loss: 0.9096 - acc: 0.5756 - val_loss: 0.9563 - val_acc: 0.5547\n",
            "Epoch 68/150 - 0.08s - loss: 0.9060 - acc: 0.5753 - val_loss: 0.9551 - val_acc: 0.5587\n",
            "Epoch 69/150 - 0.07s - loss: 0.9348 - acc: 0.5499 - val_loss: 0.9905 - val_acc: 0.5202\n",
            "Epoch 70/150 - 0.07s - loss: 0.9220 - acc: 0.5677 - val_loss: 0.9714 - val_acc: 0.5466\n",
            "Epoch 71/150 - 0.08s - loss: 0.9026 - acc: 0.5801 - val_loss: 0.9527 - val_acc: 0.5648\n",
            "Epoch 72/150 - 0.07s - loss: 0.9114 - acc: 0.5652 - val_loss: 0.9676 - val_acc: 0.5364\n",
            "Epoch 73/150 - 0.07s - loss: 0.9117 - acc: 0.5798 - val_loss: 0.9607 - val_acc: 0.5607\n",
            "Epoch 74/150 - 0.08s - loss: 0.9086 - acc: 0.5846 - val_loss: 0.9595 - val_acc: 0.5709\n",
            "Epoch 75/150 - 0.07s - loss: 0.8990 - acc: 0.5794 - val_loss: 0.9541 - val_acc: 0.5445\n",
            "Epoch 76/150 - 0.07s - loss: 0.9187 - acc: 0.5607 - val_loss: 0.9801 - val_acc: 0.5223\n",
            "Epoch 77/150 - 0.08s - loss: 0.8995 - acc: 0.5897 - val_loss: 0.9551 - val_acc: 0.5729\n",
            "Epoch 78/150 - 0.07s - loss: 0.8942 - acc: 0.5812 - val_loss: 0.9522 - val_acc: 0.5607\n",
            "Epoch 79/150 - 0.07s - loss: 0.8942 - acc: 0.5927 - val_loss: 0.9518 - val_acc: 0.5749\n",
            "Epoch 80/150 - 0.08s - loss: 0.8939 - acc: 0.5924 - val_loss: 0.9531 - val_acc: 0.5567\n",
            "Epoch 81/150 - 0.07s - loss: 0.8922 - acc: 0.5843 - val_loss: 0.9542 - val_acc: 0.5364\n",
            "Epoch 82/150 - 0.07s - loss: 0.8917 - acc: 0.5922 - val_loss: 0.9521 - val_acc: 0.5648\n",
            "Epoch 83/150 - 0.08s - loss: 0.8898 - acc: 0.5807 - val_loss: 0.9519 - val_acc: 0.5587\n",
            "Epoch 84/150 - 0.07s - loss: 0.8910 - acc: 0.5949 - val_loss: 0.9528 - val_acc: 0.5810\n",
            "Epoch 85/150 - 0.07s - loss: 0.8973 - acc: 0.5758 - val_loss: 0.9672 - val_acc: 0.5142\n",
            "Epoch 86/150 - 0.08s - loss: 0.8893 - acc: 0.5819 - val_loss: 0.9563 - val_acc: 0.5526\n",
            "Epoch 87/150 - 0.07s - loss: 0.8859 - acc: 0.5938 - val_loss: 0.9516 - val_acc: 0.5547\n",
            "Epoch 88/150 - 0.07s - loss: 0.9052 - acc: 0.5670 - val_loss: 0.9752 - val_acc: 0.5162\n",
            "Epoch 89/150 - 0.08s - loss: 0.8864 - acc: 0.5915 - val_loss: 0.9523 - val_acc: 0.5729\n",
            "Epoch 90/150 - 0.07s - loss: 0.8824 - acc: 0.5924 - val_loss: 0.9510 - val_acc: 0.5607\n",
            "Epoch 91/150 - 0.07s - loss: 0.8951 - acc: 0.5888 - val_loss: 0.9591 - val_acc: 0.5810\n",
            "Epoch 92/150 - 0.08s - loss: 0.8815 - acc: 0.5938 - val_loss: 0.9537 - val_acc: 0.5445\n",
            "Epoch 93/150 - 0.07s - loss: 0.8957 - acc: 0.5785 - val_loss: 0.9732 - val_acc: 0.5202\n",
            "Epoch 94/150 - 0.07s - loss: 0.9019 - acc: 0.5855 - val_loss: 0.9679 - val_acc: 0.5729\n",
            "Epoch 95/150 - 0.08s - loss: 0.8954 - acc: 0.5794 - val_loss: 0.9764 - val_acc: 0.5040\n",
            "Epoch 96/150 - 0.07s - loss: 0.8814 - acc: 0.5967 - val_loss: 0.9579 - val_acc: 0.5486\n",
            "Epoch 97/150 - 0.07s - loss: 0.8793 - acc: 0.5942 - val_loss: 0.9577 - val_acc: 0.5385\n",
            "Epoch 98/150 - 0.08s - loss: 0.8764 - acc: 0.5915 - val_loss: 0.9526 - val_acc: 0.5506\n",
            "Epoch 99/150 - 0.07s - loss: 0.8912 - acc: 0.5807 - val_loss: 0.9737 - val_acc: 0.5142\n",
            "Epoch 100/150 - 0.08s - loss: 0.8754 - acc: 0.5938 - val_loss: 0.9549 - val_acc: 0.5466\n",
            "Epoch 101/150 - 0.07s - loss: 0.9011 - acc: 0.5792 - val_loss: 0.9701 - val_acc: 0.5526\n",
            "Epoch 102/150 - 0.07s - loss: 0.8744 - acc: 0.5992 - val_loss: 0.9561 - val_acc: 0.5283\n",
            "Epoch 103/150 - 0.07s - loss: 0.9057 - acc: 0.5711 - val_loss: 0.9891 - val_acc: 0.5263\n",
            "Epoch 104/150 - 0.08s - loss: 0.8783 - acc: 0.5895 - val_loss: 0.9604 - val_acc: 0.5263\n",
            "Epoch 105/150 - 0.07s - loss: 0.9084 - acc: 0.5666 - val_loss: 0.9995 - val_acc: 0.4757\n",
            "Epoch 106/150 - 0.07s - loss: 0.8780 - acc: 0.6005 - val_loss: 0.9568 - val_acc: 0.5668\n",
            "Epoch 107/150 - 0.07s - loss: 0.8704 - acc: 0.5978 - val_loss: 0.9552 - val_acc: 0.5405\n",
            "Epoch 108/150 - 0.07s - loss: 0.8780 - acc: 0.5877 - val_loss: 0.9573 - val_acc: 0.5607\n",
            "Epoch 109/150 - 0.07s - loss: 0.8755 - acc: 0.5902 - val_loss: 0.9632 - val_acc: 0.5202\n",
            "Epoch 110/150 - 0.08s - loss: 0.8780 - acc: 0.5884 - val_loss: 0.9602 - val_acc: 0.5486\n",
            "Epoch 111/150 - 0.07s - loss: 0.8687 - acc: 0.5945 - val_loss: 0.9555 - val_acc: 0.5445\n",
            "Epoch 112/150 - 0.07s - loss: 0.9235 - acc: 0.5553 - val_loss: 1.0162 - val_acc: 0.5142\n",
            "Epoch 113/150 - 0.08s - loss: 0.8757 - acc: 0.6026 - val_loss: 0.9646 - val_acc: 0.5445\n",
            "Epoch 114/150 - 0.07s - loss: 0.8656 - acc: 0.6012 - val_loss: 0.9565 - val_acc: 0.5405\n",
            "Epoch 115/150 - 0.07s - loss: 0.8698 - acc: 0.5947 - val_loss: 0.9547 - val_acc: 0.5648\n",
            "Epoch 116/150 - 0.08s - loss: 0.8772 - acc: 0.5879 - val_loss: 0.9608 - val_acc: 0.5668\n",
            "Epoch 117/150 - 0.07s - loss: 0.8941 - acc: 0.5778 - val_loss: 0.9947 - val_acc: 0.4858\n",
            "Epoch 118/150 - 0.07s - loss: 0.8703 - acc: 0.6035 - val_loss: 0.9592 - val_acc: 0.5607\n",
            "Epoch 119/150 - 0.08s - loss: 0.8697 - acc: 0.5990 - val_loss: 0.9672 - val_acc: 0.5202\n",
            "Epoch 120/150 - 0.07s - loss: 0.8951 - acc: 0.5873 - val_loss: 0.9796 - val_acc: 0.5526\n",
            "Epoch 121/150 - 0.07s - loss: 0.8844 - acc: 0.5812 - val_loss: 0.9814 - val_acc: 0.5142\n",
            "Epoch 122/150 - 0.08s - loss: 0.8794 - acc: 0.6003 - val_loss: 0.9733 - val_acc: 0.5466\n",
            "Epoch 123/150 - 0.07s - loss: 0.8738 - acc: 0.6062 - val_loss: 0.9660 - val_acc: 0.5648\n",
            "Epoch 124/150 - 0.07s - loss: 0.8611 - acc: 0.6001 - val_loss: 0.9579 - val_acc: 0.5385\n",
            "Epoch 125/150 - 0.07s - loss: 0.8655 - acc: 0.5965 - val_loss: 0.9586 - val_acc: 0.5607\n",
            "Epoch 126/150 - 0.07s - loss: 0.8587 - acc: 0.6041 - val_loss: 0.9547 - val_acc: 0.5506\n",
            "Epoch 127/150 - 0.07s - loss: 0.8909 - acc: 0.5834 - val_loss: 0.9793 - val_acc: 0.5628\n",
            "Epoch 128/150 - 0.08s - loss: 0.8796 - acc: 0.5884 - val_loss: 0.9818 - val_acc: 0.5223\n",
            "Epoch 129/150 - 0.09s - loss: 0.8877 - acc: 0.5913 - val_loss: 0.9893 - val_acc: 0.5243\n",
            "Epoch 130/150 - 0.08s - loss: 0.8667 - acc: 0.6089 - val_loss: 0.9639 - val_acc: 0.5567\n",
            "Epoch 131/150 - 0.07s - loss: 0.8607 - acc: 0.6102 - val_loss: 0.9631 - val_acc: 0.5526\n",
            "Epoch 132/150 - 0.07s - loss: 0.8613 - acc: 0.5978 - val_loss: 0.9644 - val_acc: 0.5283\n",
            "Epoch 133/150 - 0.07s - loss: 0.8736 - acc: 0.5879 - val_loss: 0.9803 - val_acc: 0.5081\n",
            "Epoch 134/150 - 0.08s - loss: 0.8690 - acc: 0.5942 - val_loss: 0.9767 - val_acc: 0.5202\n",
            "Epoch 135/150 - 0.07s - loss: 0.8591 - acc: 0.6005 - val_loss: 0.9627 - val_acc: 0.5405\n",
            "Epoch 136/150 - 0.07s - loss: 0.8677 - acc: 0.5972 - val_loss: 0.9646 - val_acc: 0.5628\n",
            "Epoch 137/150 - 0.08s - loss: 0.8947 - acc: 0.5785 - val_loss: 1.0089 - val_acc: 0.5000\n",
            "Epoch 138/150 - 0.08s - loss: 0.8998 - acc: 0.5756 - val_loss: 1.0164 - val_acc: 0.4899\n",
            "Epoch 139/150 - 0.07s - loss: 0.8816 - acc: 0.5976 - val_loss: 0.9773 - val_acc: 0.5506\n",
            "Epoch 140/150 - 0.08s - loss: 0.8557 - acc: 0.6116 - val_loss: 0.9641 - val_acc: 0.5466\n",
            "Epoch 141/150 - 0.07s - loss: 0.8658 - acc: 0.6021 - val_loss: 0.9675 - val_acc: 0.5607\n",
            "Epoch 142/150 - 0.07s - loss: 0.8595 - acc: 0.6118 - val_loss: 0.9701 - val_acc: 0.5445\n",
            "Epoch 143/150 - 0.08s - loss: 0.8564 - acc: 0.6053 - val_loss: 0.9658 - val_acc: 0.5385\n",
            "Epoch 144/150 - 0.07s - loss: 0.8558 - acc: 0.6068 - val_loss: 0.9613 - val_acc: 0.5486\n",
            "Epoch 145/150 - 0.07s - loss: 0.8907 - acc: 0.5812 - val_loss: 0.9883 - val_acc: 0.5547\n",
            "Epoch 146/150 - 0.08s - loss: 0.8613 - acc: 0.6001 - val_loss: 0.9673 - val_acc: 0.5506\n",
            "Epoch 147/150 - 0.07s - loss: 0.8704 - acc: 0.5922 - val_loss: 0.9726 - val_acc: 0.5769\n",
            "Epoch 148/150 - 0.08s - loss: 0.8545 - acc: 0.6037 - val_loss: 0.9614 - val_acc: 0.5486\n",
            "Epoch 149/150 - 0.08s - loss: 0.8914 - acc: 0.5760 - val_loss: 1.0128 - val_acc: 0.4960\n",
            "Epoch 150/150 - 0.07s - loss: 0.8742 - acc: 0.6012 - val_loss: 0.9858 - val_acc: 0.5425\n",
            "\n",
            "Combination 61/252:\n",
            "Hidden Layers: [128, 64], Activation: tanh, Learning Rate: 0.001, Batch Size: 32, Epochs: 50\n",
            "Epoch 1/50 - 0.09s - loss: 1.1053 - acc: 0.3196 - val_loss: 1.1060 - val_acc: 0.3117\n",
            "Epoch 2/50 - 0.09s - loss: 1.1012 - acc: 0.3261 - val_loss: 1.1022 - val_acc: 0.3300\n",
            "Epoch 3/50 - 0.09s - loss: 1.0987 - acc: 0.3385 - val_loss: 1.1000 - val_acc: 0.3401\n",
            "Epoch 4/50 - 0.09s - loss: 1.0967 - acc: 0.3516 - val_loss: 1.0981 - val_acc: 0.3279\n",
            "Epoch 5/50 - 0.09s - loss: 1.0948 - acc: 0.3637 - val_loss: 1.0965 - val_acc: 0.3381\n",
            "Epoch 6/50 - 0.08s - loss: 1.0930 - acc: 0.3716 - val_loss: 1.0950 - val_acc: 0.3583\n",
            "Epoch 7/50 - 0.09s - loss: 1.0913 - acc: 0.3794 - val_loss: 1.0936 - val_acc: 0.3664\n",
            "Epoch 8/50 - 0.09s - loss: 1.0897 - acc: 0.3873 - val_loss: 1.0921 - val_acc: 0.3704\n",
            "Epoch 9/50 - 0.08s - loss: 1.0881 - acc: 0.3925 - val_loss: 1.0908 - val_acc: 0.3745\n",
            "Epoch 10/50 - 0.09s - loss: 1.0866 - acc: 0.3970 - val_loss: 1.0896 - val_acc: 0.3765\n",
            "Epoch 11/50 - 0.09s - loss: 1.0851 - acc: 0.4078 - val_loss: 1.0883 - val_acc: 0.3846\n",
            "Epoch 12/50 - 0.08s - loss: 1.0837 - acc: 0.4067 - val_loss: 1.0873 - val_acc: 0.3968\n",
            "Epoch 13/50 - 0.09s - loss: 1.0823 - acc: 0.4100 - val_loss: 1.0860 - val_acc: 0.3968\n",
            "Epoch 14/50 - 0.09s - loss: 1.0810 - acc: 0.4154 - val_loss: 1.0850 - val_acc: 0.4049\n",
            "Epoch 15/50 - 0.08s - loss: 1.0797 - acc: 0.4204 - val_loss: 1.0839 - val_acc: 0.4109\n",
            "Epoch 16/50 - 0.09s - loss: 1.0785 - acc: 0.4222 - val_loss: 1.0830 - val_acc: 0.4170\n",
            "Epoch 17/50 - 0.09s - loss: 1.0773 - acc: 0.4260 - val_loss: 1.0821 - val_acc: 0.4109\n",
            "Epoch 18/50 - 0.08s - loss: 1.0761 - acc: 0.4336 - val_loss: 1.0809 - val_acc: 0.4271\n",
            "Epoch 19/50 - 0.09s - loss: 1.0749 - acc: 0.4375 - val_loss: 1.0801 - val_acc: 0.4271\n",
            "Epoch 20/50 - 0.09s - loss: 1.0738 - acc: 0.4390 - val_loss: 1.0792 - val_acc: 0.4312\n",
            "Epoch 21/50 - 0.09s - loss: 1.0727 - acc: 0.4395 - val_loss: 1.0782 - val_acc: 0.4332\n",
            "Epoch 22/50 - 0.10s - loss: 1.0716 - acc: 0.4415 - val_loss: 1.0774 - val_acc: 0.4271\n",
            "Epoch 23/50 - 0.09s - loss: 1.0706 - acc: 0.4426 - val_loss: 1.0765 - val_acc: 0.4150\n",
            "Epoch 24/50 - 0.09s - loss: 1.0696 - acc: 0.4453 - val_loss: 1.0758 - val_acc: 0.4211\n",
            "Epoch 25/50 - 0.09s - loss: 1.0686 - acc: 0.4456 - val_loss: 1.0750 - val_acc: 0.4251\n",
            "Epoch 26/50 - 0.09s - loss: 1.0676 - acc: 0.4465 - val_loss: 1.0742 - val_acc: 0.4291\n",
            "Epoch 27/50 - 0.09s - loss: 1.0666 - acc: 0.4485 - val_loss: 1.0734 - val_acc: 0.4291\n",
            "Epoch 28/50 - 0.09s - loss: 1.0657 - acc: 0.4505 - val_loss: 1.0727 - val_acc: 0.4332\n",
            "Epoch 29/50 - 0.09s - loss: 1.0648 - acc: 0.4521 - val_loss: 1.0720 - val_acc: 0.4413\n",
            "Epoch 30/50 - 0.09s - loss: 1.0639 - acc: 0.4530 - val_loss: 1.0713 - val_acc: 0.4372\n",
            "Epoch 31/50 - 0.09s - loss: 1.0630 - acc: 0.4539 - val_loss: 1.0707 - val_acc: 0.4474\n",
            "Epoch 32/50 - 0.09s - loss: 1.0621 - acc: 0.4539 - val_loss: 1.0699 - val_acc: 0.4453\n",
            "Epoch 33/50 - 0.08s - loss: 1.0612 - acc: 0.4550 - val_loss: 1.0693 - val_acc: 0.4433\n",
            "Epoch 34/50 - 0.09s - loss: 1.0604 - acc: 0.4573 - val_loss: 1.0687 - val_acc: 0.4433\n",
            "Epoch 35/50 - 0.09s - loss: 1.0596 - acc: 0.4577 - val_loss: 1.0680 - val_acc: 0.4393\n",
            "Epoch 36/50 - 0.09s - loss: 1.0588 - acc: 0.4573 - val_loss: 1.0675 - val_acc: 0.4494\n",
            "Epoch 37/50 - 0.09s - loss: 1.0580 - acc: 0.4591 - val_loss: 1.0669 - val_acc: 0.4474\n",
            "Epoch 38/50 - 0.09s - loss: 1.0572 - acc: 0.4602 - val_loss: 1.0662 - val_acc: 0.4474\n",
            "Epoch 39/50 - 0.09s - loss: 1.0564 - acc: 0.4595 - val_loss: 1.0657 - val_acc: 0.4474\n",
            "Epoch 40/50 - 0.09s - loss: 1.0556 - acc: 0.4620 - val_loss: 1.0652 - val_acc: 0.4514\n",
            "Epoch 41/50 - 0.08s - loss: 1.0549 - acc: 0.4613 - val_loss: 1.0645 - val_acc: 0.4575\n",
            "Epoch 42/50 - 0.08s - loss: 1.0541 - acc: 0.4631 - val_loss: 1.0640 - val_acc: 0.4595\n",
            "Epoch 43/50 - 0.09s - loss: 1.0534 - acc: 0.4638 - val_loss: 1.0633 - val_acc: 0.4534\n",
            "Epoch 44/50 - 0.09s - loss: 1.0527 - acc: 0.4647 - val_loss: 1.0627 - val_acc: 0.4575\n",
            "Epoch 45/50 - 0.09s - loss: 1.0520 - acc: 0.4683 - val_loss: 1.0624 - val_acc: 0.4615\n",
            "Epoch 46/50 - 0.09s - loss: 1.0513 - acc: 0.4674 - val_loss: 1.0618 - val_acc: 0.4575\n",
            "Epoch 47/50 - 0.09s - loss: 1.0506 - acc: 0.4687 - val_loss: 1.0615 - val_acc: 0.4595\n",
            "Epoch 48/50 - 0.09s - loss: 1.0499 - acc: 0.4705 - val_loss: 1.0609 - val_acc: 0.4636\n",
            "Epoch 49/50 - 0.09s - loss: 1.0492 - acc: 0.4712 - val_loss: 1.0603 - val_acc: 0.4595\n",
            "Epoch 50/50 - 0.09s - loss: 1.0485 - acc: 0.4728 - val_loss: 1.0598 - val_acc: 0.4595\n",
            "\n",
            "Combination 62/252:\n",
            "Hidden Layers: [128, 64], Activation: tanh, Learning Rate: 0.001, Batch Size: 32, Epochs: 100\n",
            "Epoch 1/100 - 0.09s - loss: 1.0943 - acc: 0.3621 - val_loss: 1.0969 - val_acc: 0.3340\n",
            "Epoch 2/100 - 0.09s - loss: 1.0912 - acc: 0.3808 - val_loss: 1.0934 - val_acc: 0.3725\n",
            "Epoch 3/100 - 0.09s - loss: 1.0895 - acc: 0.3968 - val_loss: 1.0915 - val_acc: 0.3583\n",
            "Epoch 4/100 - 0.09s - loss: 1.0881 - acc: 0.4022 - val_loss: 1.0903 - val_acc: 0.3785\n",
            "Epoch 5/100 - 0.09s - loss: 1.0868 - acc: 0.4031 - val_loss: 1.0893 - val_acc: 0.3785\n",
            "Epoch 6/100 - 0.08s - loss: 1.0856 - acc: 0.4100 - val_loss: 1.0883 - val_acc: 0.3806\n",
            "Epoch 7/100 - 0.09s - loss: 1.0844 - acc: 0.4132 - val_loss: 1.0873 - val_acc: 0.3846\n",
            "Epoch 8/100 - 0.09s - loss: 1.0833 - acc: 0.4143 - val_loss: 1.0864 - val_acc: 0.3846\n",
            "Epoch 9/100 - 0.08s - loss: 1.0822 - acc: 0.4166 - val_loss: 1.0855 - val_acc: 0.3846\n",
            "Epoch 10/100 - 0.09s - loss: 1.0811 - acc: 0.4159 - val_loss: 1.0848 - val_acc: 0.3846\n",
            "Epoch 11/100 - 0.09s - loss: 1.0801 - acc: 0.4186 - val_loss: 1.0839 - val_acc: 0.4028\n",
            "Epoch 12/100 - 0.09s - loss: 1.0790 - acc: 0.4204 - val_loss: 1.0830 - val_acc: 0.4049\n",
            "Epoch 13/100 - 0.09s - loss: 1.0781 - acc: 0.4242 - val_loss: 1.0821 - val_acc: 0.4089\n",
            "Epoch 14/100 - 0.09s - loss: 1.0771 - acc: 0.4276 - val_loss: 1.0814 - val_acc: 0.4069\n",
            "Epoch 15/100 - 0.09s - loss: 1.0762 - acc: 0.4274 - val_loss: 1.0808 - val_acc: 0.4130\n",
            "Epoch 16/100 - 0.09s - loss: 1.0753 - acc: 0.4305 - val_loss: 1.0800 - val_acc: 0.4190\n",
            "Epoch 17/100 - 0.10s - loss: 1.0743 - acc: 0.4298 - val_loss: 1.0793 - val_acc: 0.4251\n",
            "Epoch 18/100 - 0.09s - loss: 1.0735 - acc: 0.4323 - val_loss: 1.0786 - val_acc: 0.4170\n",
            "Epoch 19/100 - 0.09s - loss: 1.0726 - acc: 0.4354 - val_loss: 1.0779 - val_acc: 0.4150\n",
            "Epoch 20/100 - 0.09s - loss: 1.0717 - acc: 0.4384 - val_loss: 1.0771 - val_acc: 0.4170\n",
            "Epoch 21/100 - 0.09s - loss: 1.0709 - acc: 0.4386 - val_loss: 1.0765 - val_acc: 0.4190\n",
            "Epoch 22/100 - 0.09s - loss: 1.0701 - acc: 0.4422 - val_loss: 1.0758 - val_acc: 0.4231\n",
            "Epoch 23/100 - 0.09s - loss: 1.0693 - acc: 0.4415 - val_loss: 1.0752 - val_acc: 0.4312\n",
            "Epoch 24/100 - 0.09s - loss: 1.0685 - acc: 0.4458 - val_loss: 1.0747 - val_acc: 0.4291\n",
            "Epoch 25/100 - 0.09s - loss: 1.0677 - acc: 0.4480 - val_loss: 1.0740 - val_acc: 0.4332\n",
            "Epoch 26/100 - 0.09s - loss: 1.0669 - acc: 0.4485 - val_loss: 1.0734 - val_acc: 0.4372\n",
            "Epoch 27/100 - 0.09s - loss: 1.0661 - acc: 0.4496 - val_loss: 1.0727 - val_acc: 0.4413\n",
            "Epoch 28/100 - 0.09s - loss: 1.0654 - acc: 0.4496 - val_loss: 1.0721 - val_acc: 0.4433\n",
            "Epoch 29/100 - 0.09s - loss: 1.0646 - acc: 0.4507 - val_loss: 1.0716 - val_acc: 0.4393\n",
            "Epoch 30/100 - 0.09s - loss: 1.0639 - acc: 0.4512 - val_loss: 1.0711 - val_acc: 0.4413\n",
            "Epoch 31/100 - 0.09s - loss: 1.0632 - acc: 0.4507 - val_loss: 1.0704 - val_acc: 0.4393\n",
            "Epoch 32/100 - 0.10s - loss: 1.0624 - acc: 0.4519 - val_loss: 1.0698 - val_acc: 0.4413\n",
            "Epoch 33/100 - 0.09s - loss: 1.0617 - acc: 0.4537 - val_loss: 1.0692 - val_acc: 0.4474\n",
            "Epoch 34/100 - 0.09s - loss: 1.0610 - acc: 0.4537 - val_loss: 1.0686 - val_acc: 0.4453\n",
            "Epoch 35/100 - 0.09s - loss: 1.0602 - acc: 0.4555 - val_loss: 1.0681 - val_acc: 0.4393\n",
            "Epoch 36/100 - 0.09s - loss: 1.0596 - acc: 0.4552 - val_loss: 1.0675 - val_acc: 0.4413\n",
            "Epoch 37/100 - 0.09s - loss: 1.0588 - acc: 0.4564 - val_loss: 1.0669 - val_acc: 0.4433\n",
            "Epoch 38/100 - 0.09s - loss: 1.0581 - acc: 0.4582 - val_loss: 1.0664 - val_acc: 0.4433\n",
            "Epoch 39/100 - 0.09s - loss: 1.0574 - acc: 0.4573 - val_loss: 1.0658 - val_acc: 0.4372\n",
            "Epoch 40/100 - 0.09s - loss: 1.0567 - acc: 0.4597 - val_loss: 1.0653 - val_acc: 0.4352\n",
            "Epoch 41/100 - 0.09s - loss: 1.0561 - acc: 0.4606 - val_loss: 1.0648 - val_acc: 0.4413\n",
            "Epoch 42/100 - 0.09s - loss: 1.0554 - acc: 0.4606 - val_loss: 1.0643 - val_acc: 0.4474\n",
            "Epoch 43/100 - 0.09s - loss: 1.0547 - acc: 0.4633 - val_loss: 1.0637 - val_acc: 0.4413\n",
            "Epoch 44/100 - 0.09s - loss: 1.0540 - acc: 0.4638 - val_loss: 1.0631 - val_acc: 0.4413\n",
            "Epoch 45/100 - 0.09s - loss: 1.0534 - acc: 0.4649 - val_loss: 1.0626 - val_acc: 0.4413\n",
            "Epoch 46/100 - 0.09s - loss: 1.0527 - acc: 0.4631 - val_loss: 1.0619 - val_acc: 0.4474\n",
            "Epoch 47/100 - 0.09s - loss: 1.0520 - acc: 0.4658 - val_loss: 1.0615 - val_acc: 0.4453\n",
            "Epoch 48/100 - 0.09s - loss: 1.0514 - acc: 0.4656 - val_loss: 1.0611 - val_acc: 0.4413\n",
            "Epoch 49/100 - 0.09s - loss: 1.0507 - acc: 0.4645 - val_loss: 1.0605 - val_acc: 0.4474\n",
            "Epoch 50/100 - 0.09s - loss: 1.0501 - acc: 0.4656 - val_loss: 1.0600 - val_acc: 0.4494\n",
            "Epoch 51/100 - 0.09s - loss: 1.0494 - acc: 0.4701 - val_loss: 1.0594 - val_acc: 0.4433\n",
            "Epoch 52/100 - 0.09s - loss: 1.0488 - acc: 0.4703 - val_loss: 1.0589 - val_acc: 0.4474\n",
            "Epoch 53/100 - 0.09s - loss: 1.0481 - acc: 0.4699 - val_loss: 1.0585 - val_acc: 0.4494\n",
            "Epoch 54/100 - 0.09s - loss: 1.0475 - acc: 0.4712 - val_loss: 1.0580 - val_acc: 0.4534\n",
            "Epoch 55/100 - 0.09s - loss: 1.0468 - acc: 0.4710 - val_loss: 1.0575 - val_acc: 0.4494\n",
            "Epoch 56/100 - 0.09s - loss: 1.0462 - acc: 0.4708 - val_loss: 1.0569 - val_acc: 0.4474\n",
            "Epoch 57/100 - 0.09s - loss: 1.0456 - acc: 0.4714 - val_loss: 1.0564 - val_acc: 0.4474\n",
            "Epoch 58/100 - 0.09s - loss: 1.0449 - acc: 0.4732 - val_loss: 1.0559 - val_acc: 0.4514\n",
            "Epoch 59/100 - 0.09s - loss: 1.0443 - acc: 0.4732 - val_loss: 1.0554 - val_acc: 0.4494\n",
            "Epoch 60/100 - 0.09s - loss: 1.0437 - acc: 0.4739 - val_loss: 1.0550 - val_acc: 0.4555\n",
            "Epoch 61/100 - 0.09s - loss: 1.0430 - acc: 0.4753 - val_loss: 1.0544 - val_acc: 0.4595\n",
            "Epoch 62/100 - 0.09s - loss: 1.0424 - acc: 0.4753 - val_loss: 1.0539 - val_acc: 0.4555\n",
            "Epoch 63/100 - 0.09s - loss: 1.0418 - acc: 0.4741 - val_loss: 1.0533 - val_acc: 0.4494\n",
            "Epoch 64/100 - 0.09s - loss: 1.0412 - acc: 0.4755 - val_loss: 1.0530 - val_acc: 0.4534\n",
            "Epoch 65/100 - 0.09s - loss: 1.0405 - acc: 0.4764 - val_loss: 1.0525 - val_acc: 0.4555\n",
            "Epoch 66/100 - 0.09s - loss: 1.0399 - acc: 0.4773 - val_loss: 1.0519 - val_acc: 0.4555\n",
            "Epoch 67/100 - 0.09s - loss: 1.0393 - acc: 0.4775 - val_loss: 1.0515 - val_acc: 0.4555\n",
            "Epoch 68/100 - 0.09s - loss: 1.0387 - acc: 0.4777 - val_loss: 1.0511 - val_acc: 0.4595\n",
            "Epoch 69/100 - 0.10s - loss: 1.0381 - acc: 0.4784 - val_loss: 1.0506 - val_acc: 0.4636\n",
            "Epoch 70/100 - 0.09s - loss: 1.0375 - acc: 0.4784 - val_loss: 1.0500 - val_acc: 0.4676\n",
            "Epoch 71/100 - 0.09s - loss: 1.0369 - acc: 0.4800 - val_loss: 1.0496 - val_acc: 0.4676\n",
            "Epoch 72/100 - 0.09s - loss: 1.0362 - acc: 0.4804 - val_loss: 1.0490 - val_acc: 0.4676\n",
            "Epoch 73/100 - 0.09s - loss: 1.0356 - acc: 0.4804 - val_loss: 1.0485 - val_acc: 0.4676\n",
            "Epoch 74/100 - 0.09s - loss: 1.0350 - acc: 0.4816 - val_loss: 1.0481 - val_acc: 0.4656\n",
            "Epoch 75/100 - 0.09s - loss: 1.0345 - acc: 0.4800 - val_loss: 1.0476 - val_acc: 0.4676\n",
            "Epoch 76/100 - 0.09s - loss: 1.0338 - acc: 0.4811 - val_loss: 1.0471 - val_acc: 0.4717\n",
            "Epoch 77/100 - 0.09s - loss: 1.0332 - acc: 0.4809 - val_loss: 1.0466 - val_acc: 0.4737\n",
            "Epoch 78/100 - 0.09s - loss: 1.0327 - acc: 0.4798 - val_loss: 1.0461 - val_acc: 0.4717\n",
            "Epoch 79/100 - 0.09s - loss: 1.0320 - acc: 0.4818 - val_loss: 1.0456 - val_acc: 0.4757\n",
            "Epoch 80/100 - 0.11s - loss: 1.0314 - acc: 0.4818 - val_loss: 1.0452 - val_acc: 0.4777\n",
            "Epoch 81/100 - 0.11s - loss: 1.0308 - acc: 0.4818 - val_loss: 1.0447 - val_acc: 0.4757\n",
            "Epoch 82/100 - 0.09s - loss: 1.0302 - acc: 0.4840 - val_loss: 1.0442 - val_acc: 0.4838\n",
            "Epoch 83/100 - 0.09s - loss: 1.0296 - acc: 0.4827 - val_loss: 1.0437 - val_acc: 0.4798\n",
            "Epoch 84/100 - 0.09s - loss: 1.0290 - acc: 0.4831 - val_loss: 1.0432 - val_acc: 0.4777\n",
            "Epoch 85/100 - 0.09s - loss: 1.0284 - acc: 0.4849 - val_loss: 1.0428 - val_acc: 0.4777\n",
            "Epoch 86/100 - 0.09s - loss: 1.0279 - acc: 0.4856 - val_loss: 1.0424 - val_acc: 0.4818\n",
            "Epoch 87/100 - 0.09s - loss: 1.0272 - acc: 0.4870 - val_loss: 1.0419 - val_acc: 0.4798\n",
            "Epoch 88/100 - 0.09s - loss: 1.0267 - acc: 0.4883 - val_loss: 1.0414 - val_acc: 0.4838\n",
            "Epoch 89/100 - 0.09s - loss: 1.0261 - acc: 0.4901 - val_loss: 1.0409 - val_acc: 0.4777\n",
            "Epoch 90/100 - 0.09s - loss: 1.0255 - acc: 0.4890 - val_loss: 1.0404 - val_acc: 0.4818\n",
            "Epoch 91/100 - 0.10s - loss: 1.0249 - acc: 0.4883 - val_loss: 1.0400 - val_acc: 0.4858\n",
            "Epoch 92/100 - 0.09s - loss: 1.0243 - acc: 0.4917 - val_loss: 1.0395 - val_acc: 0.4838\n",
            "Epoch 93/100 - 0.09s - loss: 1.0237 - acc: 0.4917 - val_loss: 1.0391 - val_acc: 0.4858\n",
            "Epoch 94/100 - 0.09s - loss: 1.0231 - acc: 0.4933 - val_loss: 1.0386 - val_acc: 0.4858\n",
            "Epoch 95/100 - 0.09s - loss: 1.0225 - acc: 0.4928 - val_loss: 1.0379 - val_acc: 0.4798\n",
            "Epoch 96/100 - 0.09s - loss: 1.0219 - acc: 0.4946 - val_loss: 1.0376 - val_acc: 0.4858\n",
            "Epoch 97/100 - 0.09s - loss: 1.0213 - acc: 0.4946 - val_loss: 1.0370 - val_acc: 0.4838\n",
            "Epoch 98/100 - 0.09s - loss: 1.0207 - acc: 0.4962 - val_loss: 1.0366 - val_acc: 0.4858\n",
            "Epoch 99/100 - 0.09s - loss: 1.0202 - acc: 0.4951 - val_loss: 1.0360 - val_acc: 0.4858\n",
            "Epoch 100/100 - 0.11s - loss: 1.0196 - acc: 0.4948 - val_loss: 1.0356 - val_acc: 0.4879\n",
            "\n",
            "Combination 63/252:\n",
            "Hidden Layers: [128, 64], Activation: tanh, Learning Rate: 0.001, Batch Size: 32, Epochs: 150\n",
            "Epoch 1/150 - 0.09s - loss: 1.1009 - acc: 0.3432 - val_loss: 1.1041 - val_acc: 0.3320\n",
            "Epoch 2/150 - 0.09s - loss: 1.0981 - acc: 0.3547 - val_loss: 1.1012 - val_acc: 0.3300\n",
            "Epoch 3/150 - 0.10s - loss: 1.0956 - acc: 0.3632 - val_loss: 1.0987 - val_acc: 0.3401\n",
            "Epoch 4/150 - 0.09s - loss: 1.0933 - acc: 0.3695 - val_loss: 1.0967 - val_acc: 0.3482\n",
            "Epoch 5/150 - 0.09s - loss: 1.0911 - acc: 0.3837 - val_loss: 1.0946 - val_acc: 0.3563\n",
            "Epoch 6/150 - 0.09s - loss: 1.0890 - acc: 0.3914 - val_loss: 1.0929 - val_acc: 0.3644\n",
            "Epoch 7/150 - 0.09s - loss: 1.0871 - acc: 0.3981 - val_loss: 1.0916 - val_acc: 0.3644\n",
            "Epoch 8/150 - 0.09s - loss: 1.0852 - acc: 0.4046 - val_loss: 1.0898 - val_acc: 0.3745\n",
            "Epoch 9/150 - 0.09s - loss: 1.0833 - acc: 0.4100 - val_loss: 1.0880 - val_acc: 0.3866\n",
            "Epoch 10/150 - 0.09s - loss: 1.0816 - acc: 0.4179 - val_loss: 1.0865 - val_acc: 0.3765\n",
            "Epoch 11/150 - 0.09s - loss: 1.0800 - acc: 0.4202 - val_loss: 1.0851 - val_acc: 0.3806\n",
            "Epoch 12/150 - 0.09s - loss: 1.0784 - acc: 0.4213 - val_loss: 1.0837 - val_acc: 0.3846\n",
            "Epoch 13/150 - 0.09s - loss: 1.0769 - acc: 0.4256 - val_loss: 1.0824 - val_acc: 0.3968\n",
            "Epoch 14/150 - 0.09s - loss: 1.0754 - acc: 0.4276 - val_loss: 1.0812 - val_acc: 0.4049\n",
            "Epoch 15/150 - 0.09s - loss: 1.0740 - acc: 0.4271 - val_loss: 1.0802 - val_acc: 0.3907\n",
            "Epoch 16/150 - 0.08s - loss: 1.0727 - acc: 0.4332 - val_loss: 1.0791 - val_acc: 0.4008\n",
            "Epoch 17/150 - 0.09s - loss: 1.0714 - acc: 0.4336 - val_loss: 1.0781 - val_acc: 0.4008\n",
            "Epoch 18/150 - 0.10s - loss: 1.0702 - acc: 0.4388 - val_loss: 1.0769 - val_acc: 0.4150\n",
            "Epoch 19/150 - 0.09s - loss: 1.0690 - acc: 0.4377 - val_loss: 1.0759 - val_acc: 0.4231\n",
            "Epoch 20/150 - 0.09s - loss: 1.0678 - acc: 0.4399 - val_loss: 1.0750 - val_acc: 0.4190\n",
            "Epoch 21/150 - 0.09s - loss: 1.0667 - acc: 0.4438 - val_loss: 1.0741 - val_acc: 0.4211\n",
            "Epoch 22/150 - 0.09s - loss: 1.0656 - acc: 0.4424 - val_loss: 1.0732 - val_acc: 0.4352\n",
            "Epoch 23/150 - 0.09s - loss: 1.0645 - acc: 0.4449 - val_loss: 1.0722 - val_acc: 0.4271\n",
            "Epoch 24/150 - 0.09s - loss: 1.0635 - acc: 0.4460 - val_loss: 1.0717 - val_acc: 0.4332\n",
            "Epoch 25/150 - 0.09s - loss: 1.0625 - acc: 0.4489 - val_loss: 1.0707 - val_acc: 0.4332\n",
            "Epoch 26/150 - 0.09s - loss: 1.0615 - acc: 0.4476 - val_loss: 1.0701 - val_acc: 0.4312\n",
            "Epoch 27/150 - 0.09s - loss: 1.0606 - acc: 0.4525 - val_loss: 1.0691 - val_acc: 0.4352\n",
            "Epoch 28/150 - 0.09s - loss: 1.0596 - acc: 0.4541 - val_loss: 1.0684 - val_acc: 0.4413\n",
            "Epoch 29/150 - 0.09s - loss: 1.0587 - acc: 0.4555 - val_loss: 1.0677 - val_acc: 0.4393\n",
            "Epoch 30/150 - 0.09s - loss: 1.0578 - acc: 0.4570 - val_loss: 1.0671 - val_acc: 0.4372\n",
            "Epoch 31/150 - 0.09s - loss: 1.0570 - acc: 0.4566 - val_loss: 1.0664 - val_acc: 0.4453\n",
            "Epoch 32/150 - 0.09s - loss: 1.0561 - acc: 0.4577 - val_loss: 1.0657 - val_acc: 0.4534\n",
            "Epoch 33/150 - 0.09s - loss: 1.0553 - acc: 0.4588 - val_loss: 1.0652 - val_acc: 0.4453\n",
            "Epoch 34/150 - 0.09s - loss: 1.0545 - acc: 0.4577 - val_loss: 1.0646 - val_acc: 0.4494\n",
            "Epoch 35/150 - 0.09s - loss: 1.0538 - acc: 0.4584 - val_loss: 1.0642 - val_acc: 0.4453\n",
            "Epoch 36/150 - 0.09s - loss: 1.0529 - acc: 0.4615 - val_loss: 1.0635 - val_acc: 0.4433\n",
            "Epoch 37/150 - 0.09s - loss: 1.0522 - acc: 0.4613 - val_loss: 1.0627 - val_acc: 0.4534\n",
            "Epoch 38/150 - 0.09s - loss: 1.0514 - acc: 0.4615 - val_loss: 1.0622 - val_acc: 0.4575\n",
            "Epoch 39/150 - 0.09s - loss: 1.0507 - acc: 0.4640 - val_loss: 1.0616 - val_acc: 0.4615\n",
            "Epoch 40/150 - 0.09s - loss: 1.0499 - acc: 0.4647 - val_loss: 1.0611 - val_acc: 0.4615\n",
            "Epoch 41/150 - 0.09s - loss: 1.0492 - acc: 0.4640 - val_loss: 1.0606 - val_acc: 0.4636\n",
            "Epoch 42/150 - 0.09s - loss: 1.0485 - acc: 0.4658 - val_loss: 1.0600 - val_acc: 0.4595\n",
            "Epoch 43/150 - 0.09s - loss: 1.0478 - acc: 0.4647 - val_loss: 1.0597 - val_acc: 0.4615\n",
            "Epoch 44/150 - 0.09s - loss: 1.0471 - acc: 0.4674 - val_loss: 1.0591 - val_acc: 0.4656\n",
            "Epoch 45/150 - 0.09s - loss: 1.0465 - acc: 0.4667 - val_loss: 1.0584 - val_acc: 0.4615\n",
            "Epoch 46/150 - 0.09s - loss: 1.0458 - acc: 0.4676 - val_loss: 1.0583 - val_acc: 0.4636\n",
            "Epoch 47/150 - 0.09s - loss: 1.0451 - acc: 0.4649 - val_loss: 1.0577 - val_acc: 0.4676\n",
            "Epoch 48/150 - 0.09s - loss: 1.0444 - acc: 0.4667 - val_loss: 1.0571 - val_acc: 0.4676\n",
            "Epoch 49/150 - 0.09s - loss: 1.0437 - acc: 0.4681 - val_loss: 1.0566 - val_acc: 0.4676\n",
            "Epoch 50/150 - 0.08s - loss: 1.0432 - acc: 0.4687 - val_loss: 1.0560 - val_acc: 0.4595\n",
            "Epoch 51/150 - 0.09s - loss: 1.0425 - acc: 0.4694 - val_loss: 1.0559 - val_acc: 0.4656\n",
            "Epoch 52/150 - 0.09s - loss: 1.0418 - acc: 0.4690 - val_loss: 1.0554 - val_acc: 0.4656\n",
            "Epoch 53/150 - 0.09s - loss: 1.0412 - acc: 0.4710 - val_loss: 1.0548 - val_acc: 0.4696\n",
            "Epoch 54/150 - 0.09s - loss: 1.0406 - acc: 0.4705 - val_loss: 1.0542 - val_acc: 0.4717\n",
            "Epoch 55/150 - 0.09s - loss: 1.0400 - acc: 0.4708 - val_loss: 1.0537 - val_acc: 0.4717\n",
            "Epoch 56/150 - 0.09s - loss: 1.0393 - acc: 0.4723 - val_loss: 1.0534 - val_acc: 0.4737\n",
            "Epoch 57/150 - 0.09s - loss: 1.0387 - acc: 0.4744 - val_loss: 1.0531 - val_acc: 0.4717\n",
            "Epoch 58/150 - 0.09s - loss: 1.0381 - acc: 0.4726 - val_loss: 1.0527 - val_acc: 0.4696\n",
            "Epoch 59/150 - 0.09s - loss: 1.0376 - acc: 0.4764 - val_loss: 1.0527 - val_acc: 0.4696\n",
            "Epoch 60/150 - 0.09s - loss: 1.0369 - acc: 0.4746 - val_loss: 1.0516 - val_acc: 0.4737\n",
            "Epoch 61/150 - 0.08s - loss: 1.0363 - acc: 0.4766 - val_loss: 1.0514 - val_acc: 0.4737\n",
            "Epoch 62/150 - 0.09s - loss: 1.0357 - acc: 0.4791 - val_loss: 1.0511 - val_acc: 0.4717\n",
            "Epoch 63/150 - 0.09s - loss: 1.0351 - acc: 0.4795 - val_loss: 1.0508 - val_acc: 0.4777\n",
            "Epoch 64/150 - 0.09s - loss: 1.0345 - acc: 0.4766 - val_loss: 1.0500 - val_acc: 0.4757\n",
            "Epoch 65/150 - 0.09s - loss: 1.0339 - acc: 0.4741 - val_loss: 1.0496 - val_acc: 0.4798\n",
            "Epoch 66/150 - 0.09s - loss: 1.0333 - acc: 0.4793 - val_loss: 1.0494 - val_acc: 0.4777\n",
            "Epoch 67/150 - 0.08s - loss: 1.0327 - acc: 0.4802 - val_loss: 1.0489 - val_acc: 0.4777\n",
            "Epoch 68/150 - 0.09s - loss: 1.0321 - acc: 0.4791 - val_loss: 1.0484 - val_acc: 0.4818\n",
            "Epoch 69/150 - 0.09s - loss: 1.0316 - acc: 0.4816 - val_loss: 1.0481 - val_acc: 0.4838\n",
            "Epoch 70/150 - 0.09s - loss: 1.0310 - acc: 0.4820 - val_loss: 1.0476 - val_acc: 0.4818\n",
            "Epoch 71/150 - 0.09s - loss: 1.0304 - acc: 0.4827 - val_loss: 1.0473 - val_acc: 0.4858\n",
            "Epoch 72/150 - 0.09s - loss: 1.0299 - acc: 0.4852 - val_loss: 1.0470 - val_acc: 0.4919\n",
            "Epoch 73/150 - 0.09s - loss: 1.0292 - acc: 0.4831 - val_loss: 1.0463 - val_acc: 0.4879\n",
            "Epoch 74/150 - 0.09s - loss: 1.0287 - acc: 0.4856 - val_loss: 1.0459 - val_acc: 0.4899\n",
            "Epoch 75/150 - 0.09s - loss: 1.0281 - acc: 0.4849 - val_loss: 1.0453 - val_acc: 0.4858\n",
            "Epoch 76/150 - 0.09s - loss: 1.0275 - acc: 0.4872 - val_loss: 1.0450 - val_acc: 0.4858\n",
            "Epoch 77/150 - 0.09s - loss: 1.0270 - acc: 0.4867 - val_loss: 1.0447 - val_acc: 0.4879\n",
            "Epoch 78/150 - 0.10s - loss: 1.0264 - acc: 0.4847 - val_loss: 1.0442 - val_acc: 0.4838\n",
            "Epoch 79/150 - 0.09s - loss: 1.0258 - acc: 0.4879 - val_loss: 1.0439 - val_acc: 0.4960\n",
            "Epoch 80/150 - 0.09s - loss: 1.0253 - acc: 0.4899 - val_loss: 1.0437 - val_acc: 0.4960\n",
            "Epoch 81/150 - 0.09s - loss: 1.0247 - acc: 0.4910 - val_loss: 1.0433 - val_acc: 0.4960\n",
            "Epoch 82/150 - 0.09s - loss: 1.0242 - acc: 0.4903 - val_loss: 1.0423 - val_acc: 0.4879\n",
            "Epoch 83/150 - 0.09s - loss: 1.0236 - acc: 0.4912 - val_loss: 1.0424 - val_acc: 0.5040\n",
            "Epoch 84/150 - 0.10s - loss: 1.0230 - acc: 0.4906 - val_loss: 1.0416 - val_acc: 0.5020\n",
            "Epoch 85/150 - 0.10s - loss: 1.0224 - acc: 0.4915 - val_loss: 1.0414 - val_acc: 0.5040\n",
            "Epoch 86/150 - 0.09s - loss: 1.0219 - acc: 0.4901 - val_loss: 1.0410 - val_acc: 0.5020\n",
            "Epoch 87/150 - 0.09s - loss: 1.0213 - acc: 0.4906 - val_loss: 1.0405 - val_acc: 0.5040\n",
            "Epoch 88/150 - 0.09s - loss: 1.0207 - acc: 0.4917 - val_loss: 1.0400 - val_acc: 0.5020\n",
            "Epoch 89/150 - 0.09s - loss: 1.0202 - acc: 0.4930 - val_loss: 1.0396 - val_acc: 0.5121\n",
            "Epoch 90/150 - 0.09s - loss: 1.0197 - acc: 0.4939 - val_loss: 1.0390 - val_acc: 0.5142\n",
            "Epoch 91/150 - 0.09s - loss: 1.0191 - acc: 0.4924 - val_loss: 1.0388 - val_acc: 0.5081\n",
            "Epoch 92/150 - 0.09s - loss: 1.0185 - acc: 0.4926 - val_loss: 1.0383 - val_acc: 0.5081\n",
            "Epoch 93/150 - 0.09s - loss: 1.0181 - acc: 0.4966 - val_loss: 1.0384 - val_acc: 0.5040\n",
            "Epoch 94/150 - 0.09s - loss: 1.0174 - acc: 0.4971 - val_loss: 1.0375 - val_acc: 0.5000\n",
            "Epoch 95/150 - 0.09s - loss: 1.0170 - acc: 0.4993 - val_loss: 1.0375 - val_acc: 0.5081\n",
            "Epoch 96/150 - 0.09s - loss: 1.0164 - acc: 0.5009 - val_loss: 1.0370 - val_acc: 0.5061\n",
            "Epoch 97/150 - 0.09s - loss: 1.0157 - acc: 0.4973 - val_loss: 1.0360 - val_acc: 0.5081\n",
            "Epoch 98/150 - 0.09s - loss: 1.0152 - acc: 0.4982 - val_loss: 1.0360 - val_acc: 0.5061\n",
            "Epoch 99/150 - 0.10s - loss: 1.0146 - acc: 0.5007 - val_loss: 1.0354 - val_acc: 0.5020\n",
            "Epoch 100/150 - 0.09s - loss: 1.0142 - acc: 0.4987 - val_loss: 1.0347 - val_acc: 0.5121\n",
            "Epoch 101/150 - 0.09s - loss: 1.0135 - acc: 0.5022 - val_loss: 1.0344 - val_acc: 0.5101\n",
            "Epoch 102/150 - 0.09s - loss: 1.0130 - acc: 0.5038 - val_loss: 1.0341 - val_acc: 0.5101\n",
            "Epoch 103/150 - 0.09s - loss: 1.0124 - acc: 0.5054 - val_loss: 1.0338 - val_acc: 0.5121\n",
            "Epoch 104/150 - 0.09s - loss: 1.0119 - acc: 0.5031 - val_loss: 1.0332 - val_acc: 0.5162\n",
            "Epoch 105/150 - 0.09s - loss: 1.0113 - acc: 0.5056 - val_loss: 1.0329 - val_acc: 0.5142\n",
            "Epoch 106/150 - 0.09s - loss: 1.0107 - acc: 0.5043 - val_loss: 1.0322 - val_acc: 0.5142\n",
            "Epoch 107/150 - 0.09s - loss: 1.0102 - acc: 0.5038 - val_loss: 1.0318 - val_acc: 0.5162\n",
            "Epoch 108/150 - 0.09s - loss: 1.0097 - acc: 0.5047 - val_loss: 1.0314 - val_acc: 0.5142\n",
            "Epoch 109/150 - 0.09s - loss: 1.0091 - acc: 0.5020 - val_loss: 1.0306 - val_acc: 0.5223\n",
            "Epoch 110/150 - 0.09s - loss: 1.0085 - acc: 0.5063 - val_loss: 1.0304 - val_acc: 0.5202\n",
            "Epoch 111/150 - 0.09s - loss: 1.0080 - acc: 0.5031 - val_loss: 1.0299 - val_acc: 0.5223\n",
            "Epoch 112/150 - 0.09s - loss: 1.0074 - acc: 0.5043 - val_loss: 1.0294 - val_acc: 0.5223\n",
            "Epoch 113/150 - 0.08s - loss: 1.0070 - acc: 0.5049 - val_loss: 1.0288 - val_acc: 0.5243\n",
            "Epoch 114/150 - 0.09s - loss: 1.0063 - acc: 0.5088 - val_loss: 1.0286 - val_acc: 0.5223\n",
            "Epoch 115/150 - 0.09s - loss: 1.0057 - acc: 0.5092 - val_loss: 1.0281 - val_acc: 0.5243\n",
            "Epoch 116/150 - 0.09s - loss: 1.0052 - acc: 0.5110 - val_loss: 1.0277 - val_acc: 0.5202\n",
            "Epoch 117/150 - 0.09s - loss: 1.0046 - acc: 0.5099 - val_loss: 1.0274 - val_acc: 0.5223\n",
            "Epoch 118/150 - 0.09s - loss: 1.0041 - acc: 0.5119 - val_loss: 1.0270 - val_acc: 0.5202\n",
            "Epoch 119/150 - 0.09s - loss: 1.0036 - acc: 0.5119 - val_loss: 1.0268 - val_acc: 0.5162\n",
            "Epoch 120/150 - 0.09s - loss: 1.0030 - acc: 0.5117 - val_loss: 1.0260 - val_acc: 0.5202\n",
            "Epoch 121/150 - 0.09s - loss: 1.0025 - acc: 0.5139 - val_loss: 1.0254 - val_acc: 0.5243\n",
            "Epoch 122/150 - 0.09s - loss: 1.0019 - acc: 0.5130 - val_loss: 1.0253 - val_acc: 0.5243\n",
            "Epoch 123/150 - 0.09s - loss: 1.0013 - acc: 0.5153 - val_loss: 1.0245 - val_acc: 0.5243\n",
            "Epoch 124/150 - 0.09s - loss: 1.0008 - acc: 0.5133 - val_loss: 1.0242 - val_acc: 0.5243\n",
            "Epoch 125/150 - 0.09s - loss: 1.0002 - acc: 0.5166 - val_loss: 1.0237 - val_acc: 0.5243\n",
            "Epoch 126/150 - 0.09s - loss: 0.9997 - acc: 0.5164 - val_loss: 1.0232 - val_acc: 0.5283\n",
            "Epoch 127/150 - 0.09s - loss: 0.9991 - acc: 0.5146 - val_loss: 1.0225 - val_acc: 0.5304\n",
            "Epoch 128/150 - 0.08s - loss: 0.9985 - acc: 0.5166 - val_loss: 1.0221 - val_acc: 0.5324\n",
            "Epoch 129/150 - 0.09s - loss: 0.9980 - acc: 0.5178 - val_loss: 1.0219 - val_acc: 0.5243\n",
            "Epoch 130/150 - 0.09s - loss: 0.9975 - acc: 0.5162 - val_loss: 1.0214 - val_acc: 0.5263\n",
            "Epoch 131/150 - 0.09s - loss: 0.9969 - acc: 0.5182 - val_loss: 1.0208 - val_acc: 0.5283\n",
            "Epoch 132/150 - 0.09s - loss: 0.9965 - acc: 0.5166 - val_loss: 1.0201 - val_acc: 0.5364\n",
            "Epoch 133/150 - 0.09s - loss: 0.9959 - acc: 0.5193 - val_loss: 1.0202 - val_acc: 0.5243\n",
            "Epoch 134/150 - 0.12s - loss: 0.9954 - acc: 0.5198 - val_loss: 1.0197 - val_acc: 0.5243\n",
            "Epoch 135/150 - 0.12s - loss: 0.9947 - acc: 0.5200 - val_loss: 1.0191 - val_acc: 0.5304\n",
            "Epoch 136/150 - 0.10s - loss: 0.9942 - acc: 0.5189 - val_loss: 1.0186 - val_acc: 0.5304\n",
            "Epoch 137/150 - 0.10s - loss: 0.9937 - acc: 0.5216 - val_loss: 1.0184 - val_acc: 0.5243\n",
            "Epoch 138/150 - 0.10s - loss: 0.9931 - acc: 0.5209 - val_loss: 1.0178 - val_acc: 0.5283\n",
            "Epoch 139/150 - 0.12s - loss: 0.9925 - acc: 0.5205 - val_loss: 1.0170 - val_acc: 0.5324\n",
            "Epoch 140/150 - 0.10s - loss: 0.9922 - acc: 0.5207 - val_loss: 1.0175 - val_acc: 0.5182\n",
            "Epoch 141/150 - 0.09s - loss: 0.9915 - acc: 0.5216 - val_loss: 1.0163 - val_acc: 0.5304\n",
            "Epoch 142/150 - 0.09s - loss: 0.9910 - acc: 0.5227 - val_loss: 1.0156 - val_acc: 0.5324\n",
            "Epoch 143/150 - 0.09s - loss: 0.9904 - acc: 0.5232 - val_loss: 1.0152 - val_acc: 0.5304\n",
            "Epoch 144/150 - 0.09s - loss: 0.9899 - acc: 0.5250 - val_loss: 1.0149 - val_acc: 0.5304\n",
            "Epoch 145/150 - 0.09s - loss: 0.9894 - acc: 0.5234 - val_loss: 1.0146 - val_acc: 0.5324\n",
            "Epoch 146/150 - 0.09s - loss: 0.9889 - acc: 0.5243 - val_loss: 1.0145 - val_acc: 0.5283\n",
            "Epoch 147/150 - 0.09s - loss: 0.9882 - acc: 0.5241 - val_loss: 1.0133 - val_acc: 0.5385\n",
            "Epoch 148/150 - 0.08s - loss: 0.9877 - acc: 0.5238 - val_loss: 1.0128 - val_acc: 0.5364\n",
            "Epoch 149/150 - 0.09s - loss: 0.9872 - acc: 0.5243 - val_loss: 1.0126 - val_acc: 0.5364\n",
            "Epoch 150/150 - 0.09s - loss: 0.9866 - acc: 0.5252 - val_loss: 1.0117 - val_acc: 0.5405\n",
            "\n",
            "Combination 64/252:\n",
            "Hidden Layers: [128, 64], Activation: tanh, Learning Rate: 0.001, Batch Size: 64, Epochs: 50\n",
            "Epoch 1/50 - 0.08s - loss: 1.1207 - acc: 0.2834 - val_loss: 1.1205 - val_acc: 0.3077\n",
            "Epoch 2/50 - 0.08s - loss: 1.1177 - acc: 0.2755 - val_loss: 1.1169 - val_acc: 0.3219\n",
            "Epoch 3/50 - 0.08s - loss: 1.1154 - acc: 0.2753 - val_loss: 1.1144 - val_acc: 0.3117\n",
            "Epoch 4/50 - 0.07s - loss: 1.1135 - acc: 0.2780 - val_loss: 1.1124 - val_acc: 0.3178\n",
            "Epoch 5/50 - 0.07s - loss: 1.1119 - acc: 0.2839 - val_loss: 1.1107 - val_acc: 0.3198\n",
            "Epoch 6/50 - 0.09s - loss: 1.1103 - acc: 0.2926 - val_loss: 1.1094 - val_acc: 0.3219\n",
            "Epoch 7/50 - 0.09s - loss: 1.1088 - acc: 0.2982 - val_loss: 1.1080 - val_acc: 0.3259\n",
            "Epoch 8/50 - 0.10s - loss: 1.1074 - acc: 0.3059 - val_loss: 1.1067 - val_acc: 0.3441\n",
            "Epoch 9/50 - 0.09s - loss: 1.1060 - acc: 0.3124 - val_loss: 1.1054 - val_acc: 0.3502\n",
            "Epoch 10/50 - 0.08s - loss: 1.1046 - acc: 0.3185 - val_loss: 1.1043 - val_acc: 0.3502\n",
            "Epoch 11/50 - 0.08s - loss: 1.1033 - acc: 0.3284 - val_loss: 1.1032 - val_acc: 0.3462\n",
            "Epoch 12/50 - 0.08s - loss: 1.1021 - acc: 0.3342 - val_loss: 1.1021 - val_acc: 0.3360\n",
            "Epoch 13/50 - 0.08s - loss: 1.1008 - acc: 0.3401 - val_loss: 1.1011 - val_acc: 0.3462\n",
            "Epoch 14/50 - 0.08s - loss: 1.0996 - acc: 0.3446 - val_loss: 1.1001 - val_acc: 0.3381\n",
            "Epoch 15/50 - 0.08s - loss: 1.0985 - acc: 0.3468 - val_loss: 1.0992 - val_acc: 0.3401\n",
            "Epoch 16/50 - 0.07s - loss: 1.0973 - acc: 0.3527 - val_loss: 1.0982 - val_acc: 0.3441\n",
            "Epoch 17/50 - 0.07s - loss: 1.0962 - acc: 0.3558 - val_loss: 1.0973 - val_acc: 0.3482\n",
            "Epoch 18/50 - 0.08s - loss: 1.0951 - acc: 0.3621 - val_loss: 1.0964 - val_acc: 0.3462\n",
            "Epoch 19/50 - 0.08s - loss: 1.0940 - acc: 0.3650 - val_loss: 1.0955 - val_acc: 0.3583\n",
            "Epoch 20/50 - 0.07s - loss: 1.0930 - acc: 0.3734 - val_loss: 1.0946 - val_acc: 0.3583\n",
            "Epoch 21/50 - 0.08s - loss: 1.0920 - acc: 0.3743 - val_loss: 1.0938 - val_acc: 0.3644\n",
            "Epoch 22/50 - 0.07s - loss: 1.0910 - acc: 0.3806 - val_loss: 1.0930 - val_acc: 0.3704\n",
            "Epoch 23/50 - 0.08s - loss: 1.0901 - acc: 0.3873 - val_loss: 1.0923 - val_acc: 0.3725\n",
            "Epoch 24/50 - 0.08s - loss: 1.0891 - acc: 0.3909 - val_loss: 1.0915 - val_acc: 0.3745\n",
            "Epoch 25/50 - 0.08s - loss: 1.0882 - acc: 0.3932 - val_loss: 1.0908 - val_acc: 0.3846\n",
            "Epoch 26/50 - 0.08s - loss: 1.0873 - acc: 0.3995 - val_loss: 1.0900 - val_acc: 0.3866\n",
            "Epoch 27/50 - 0.08s - loss: 1.0864 - acc: 0.4031 - val_loss: 1.0893 - val_acc: 0.3866\n",
            "Epoch 28/50 - 0.08s - loss: 1.0855 - acc: 0.4076 - val_loss: 1.0886 - val_acc: 0.3826\n",
            "Epoch 29/50 - 0.08s - loss: 1.0847 - acc: 0.4105 - val_loss: 1.0879 - val_acc: 0.3887\n",
            "Epoch 30/50 - 0.09s - loss: 1.0839 - acc: 0.4136 - val_loss: 1.0873 - val_acc: 0.3846\n",
            "Epoch 31/50 - 0.08s - loss: 1.0830 - acc: 0.4150 - val_loss: 1.0866 - val_acc: 0.3846\n",
            "Epoch 32/50 - 0.08s - loss: 1.0822 - acc: 0.4206 - val_loss: 1.0860 - val_acc: 0.3887\n",
            "Epoch 33/50 - 0.08s - loss: 1.0815 - acc: 0.4204 - val_loss: 1.0854 - val_acc: 0.3947\n",
            "Epoch 34/50 - 0.08s - loss: 1.0807 - acc: 0.4235 - val_loss: 1.0848 - val_acc: 0.4028\n",
            "Epoch 35/50 - 0.08s - loss: 1.0799 - acc: 0.4240 - val_loss: 1.0842 - val_acc: 0.4089\n",
            "Epoch 36/50 - 0.08s - loss: 1.0792 - acc: 0.4280 - val_loss: 1.0836 - val_acc: 0.4170\n",
            "Epoch 37/50 - 0.08s - loss: 1.0785 - acc: 0.4283 - val_loss: 1.0831 - val_acc: 0.4190\n",
            "Epoch 38/50 - 0.08s - loss: 1.0778 - acc: 0.4278 - val_loss: 1.0825 - val_acc: 0.4231\n",
            "Epoch 39/50 - 0.08s - loss: 1.0770 - acc: 0.4267 - val_loss: 1.0819 - val_acc: 0.4332\n",
            "Epoch 40/50 - 0.08s - loss: 1.0764 - acc: 0.4287 - val_loss: 1.0814 - val_acc: 0.4312\n",
            "Epoch 41/50 - 0.08s - loss: 1.0757 - acc: 0.4305 - val_loss: 1.0809 - val_acc: 0.4312\n",
            "Epoch 42/50 - 0.09s - loss: 1.0750 - acc: 0.4312 - val_loss: 1.0804 - val_acc: 0.4271\n",
            "Epoch 43/50 - 0.08s - loss: 1.0743 - acc: 0.4357 - val_loss: 1.0798 - val_acc: 0.4271\n",
            "Epoch 44/50 - 0.08s - loss: 1.0737 - acc: 0.4359 - val_loss: 1.0793 - val_acc: 0.4271\n",
            "Epoch 45/50 - 0.08s - loss: 1.0730 - acc: 0.4343 - val_loss: 1.0789 - val_acc: 0.4291\n",
            "Epoch 46/50 - 0.08s - loss: 1.0724 - acc: 0.4363 - val_loss: 1.0784 - val_acc: 0.4271\n",
            "Epoch 47/50 - 0.08s - loss: 1.0718 - acc: 0.4381 - val_loss: 1.0779 - val_acc: 0.4291\n",
            "Epoch 48/50 - 0.08s - loss: 1.0712 - acc: 0.4420 - val_loss: 1.0774 - val_acc: 0.4312\n",
            "Epoch 49/50 - 0.08s - loss: 1.0706 - acc: 0.4426 - val_loss: 1.0769 - val_acc: 0.4271\n",
            "Epoch 50/50 - 0.08s - loss: 1.0700 - acc: 0.4424 - val_loss: 1.0765 - val_acc: 0.4291\n",
            "\n",
            "Combination 65/252:\n",
            "Hidden Layers: [128, 64], Activation: tanh, Learning Rate: 0.001, Batch Size: 64, Epochs: 100\n",
            "Epoch 1/100 - 0.08s - loss: 1.1044 - acc: 0.3480 - val_loss: 1.1031 - val_acc: 0.3198\n",
            "Epoch 2/100 - 0.08s - loss: 1.1014 - acc: 0.3581 - val_loss: 1.0996 - val_acc: 0.3462\n",
            "Epoch 3/100 - 0.08s - loss: 1.0996 - acc: 0.3531 - val_loss: 1.0974 - val_acc: 0.3583\n",
            "Epoch 4/100 - 0.10s - loss: 1.0984 - acc: 0.3491 - val_loss: 1.0960 - val_acc: 0.3684\n",
            "Epoch 5/100 - 0.08s - loss: 1.0974 - acc: 0.3495 - val_loss: 1.0949 - val_acc: 0.3644\n",
            "Epoch 6/100 - 0.08s - loss: 1.0966 - acc: 0.3511 - val_loss: 1.0941 - val_acc: 0.3725\n",
            "Epoch 7/100 - 0.09s - loss: 1.0958 - acc: 0.3563 - val_loss: 1.0934 - val_acc: 0.3806\n",
            "Epoch 8/100 - 0.08s - loss: 1.0951 - acc: 0.3587 - val_loss: 1.0927 - val_acc: 0.3704\n",
            "Epoch 9/100 - 0.08s - loss: 1.0943 - acc: 0.3623 - val_loss: 1.0921 - val_acc: 0.3725\n",
            "Epoch 10/100 - 0.07s - loss: 1.0936 - acc: 0.3671 - val_loss: 1.0915 - val_acc: 0.3745\n",
            "Epoch 11/100 - 0.07s - loss: 1.0929 - acc: 0.3704 - val_loss: 1.0909 - val_acc: 0.3785\n",
            "Epoch 12/100 - 0.07s - loss: 1.0923 - acc: 0.3736 - val_loss: 1.0904 - val_acc: 0.3765\n",
            "Epoch 13/100 - 0.08s - loss: 1.0916 - acc: 0.3774 - val_loss: 1.0899 - val_acc: 0.3826\n",
            "Epoch 14/100 - 0.08s - loss: 1.0910 - acc: 0.3819 - val_loss: 1.0894 - val_acc: 0.3765\n",
            "Epoch 15/100 - 0.08s - loss: 1.0903 - acc: 0.3842 - val_loss: 1.0889 - val_acc: 0.3704\n",
            "Epoch 16/100 - 0.08s - loss: 1.0897 - acc: 0.3844 - val_loss: 1.0884 - val_acc: 0.3745\n",
            "Epoch 17/100 - 0.08s - loss: 1.0891 - acc: 0.3848 - val_loss: 1.0879 - val_acc: 0.3725\n",
            "Epoch 18/100 - 0.08s - loss: 1.0885 - acc: 0.3882 - val_loss: 1.0874 - val_acc: 0.3765\n",
            "Epoch 19/100 - 0.08s - loss: 1.0879 - acc: 0.3889 - val_loss: 1.0870 - val_acc: 0.3704\n",
            "Epoch 20/100 - 0.08s - loss: 1.0873 - acc: 0.3907 - val_loss: 1.0865 - val_acc: 0.3725\n",
            "Epoch 21/100 - 0.08s - loss: 1.0867 - acc: 0.3920 - val_loss: 1.0861 - val_acc: 0.3745\n",
            "Epoch 22/100 - 0.09s - loss: 1.0862 - acc: 0.3970 - val_loss: 1.0857 - val_acc: 0.3745\n",
            "Epoch 23/100 - 0.07s - loss: 1.0856 - acc: 0.4017 - val_loss: 1.0853 - val_acc: 0.3806\n",
            "Epoch 24/100 - 0.08s - loss: 1.0850 - acc: 0.4046 - val_loss: 1.0848 - val_acc: 0.3927\n",
            "Epoch 25/100 - 0.07s - loss: 1.0845 - acc: 0.4058 - val_loss: 1.0845 - val_acc: 0.3866\n",
            "Epoch 26/100 - 0.08s - loss: 1.0840 - acc: 0.4094 - val_loss: 1.0840 - val_acc: 0.3988\n",
            "Epoch 27/100 - 0.08s - loss: 1.0834 - acc: 0.4123 - val_loss: 1.0837 - val_acc: 0.4049\n",
            "Epoch 28/100 - 0.08s - loss: 1.0829 - acc: 0.4114 - val_loss: 1.0833 - val_acc: 0.4028\n",
            "Epoch 29/100 - 0.08s - loss: 1.0824 - acc: 0.4141 - val_loss: 1.0829 - val_acc: 0.4130\n",
            "Epoch 30/100 - 0.08s - loss: 1.0819 - acc: 0.4152 - val_loss: 1.0825 - val_acc: 0.4109\n",
            "Epoch 31/100 - 0.08s - loss: 1.0814 - acc: 0.4152 - val_loss: 1.0821 - val_acc: 0.4109\n",
            "Epoch 32/100 - 0.08s - loss: 1.0809 - acc: 0.4179 - val_loss: 1.0817 - val_acc: 0.4109\n",
            "Epoch 33/100 - 0.07s - loss: 1.0804 - acc: 0.4181 - val_loss: 1.0813 - val_acc: 0.4089\n",
            "Epoch 34/100 - 0.08s - loss: 1.0799 - acc: 0.4220 - val_loss: 1.0810 - val_acc: 0.4069\n",
            "Epoch 35/100 - 0.07s - loss: 1.0794 - acc: 0.4224 - val_loss: 1.0806 - val_acc: 0.4069\n",
            "Epoch 36/100 - 0.08s - loss: 1.0789 - acc: 0.4238 - val_loss: 1.0802 - val_acc: 0.4089\n",
            "Epoch 37/100 - 0.08s - loss: 1.0784 - acc: 0.4258 - val_loss: 1.0799 - val_acc: 0.4089\n",
            "Epoch 38/100 - 0.08s - loss: 1.0779 - acc: 0.4274 - val_loss: 1.0795 - val_acc: 0.4049\n",
            "Epoch 39/100 - 0.08s - loss: 1.0775 - acc: 0.4280 - val_loss: 1.0792 - val_acc: 0.4069\n",
            "Epoch 40/100 - 0.08s - loss: 1.0770 - acc: 0.4294 - val_loss: 1.0789 - val_acc: 0.4089\n",
            "Epoch 41/100 - 0.08s - loss: 1.0765 - acc: 0.4300 - val_loss: 1.0785 - val_acc: 0.4150\n",
            "Epoch 42/100 - 0.08s - loss: 1.0761 - acc: 0.4309 - val_loss: 1.0782 - val_acc: 0.4190\n",
            "Epoch 43/100 - 0.08s - loss: 1.0756 - acc: 0.4300 - val_loss: 1.0778 - val_acc: 0.4150\n",
            "Epoch 44/100 - 0.08s - loss: 1.0752 - acc: 0.4303 - val_loss: 1.0775 - val_acc: 0.4150\n",
            "Epoch 45/100 - 0.08s - loss: 1.0747 - acc: 0.4341 - val_loss: 1.0772 - val_acc: 0.4130\n",
            "Epoch 46/100 - 0.08s - loss: 1.0743 - acc: 0.4359 - val_loss: 1.0769 - val_acc: 0.4089\n",
            "Epoch 47/100 - 0.07s - loss: 1.0738 - acc: 0.4345 - val_loss: 1.0766 - val_acc: 0.4109\n",
            "Epoch 48/100 - 0.08s - loss: 1.0734 - acc: 0.4350 - val_loss: 1.0763 - val_acc: 0.4170\n",
            "Epoch 49/100 - 0.08s - loss: 1.0730 - acc: 0.4332 - val_loss: 1.0759 - val_acc: 0.4190\n",
            "Epoch 50/100 - 0.08s - loss: 1.0725 - acc: 0.4348 - val_loss: 1.0756 - val_acc: 0.4190\n",
            "Epoch 51/100 - 0.07s - loss: 1.0721 - acc: 0.4375 - val_loss: 1.0753 - val_acc: 0.4190\n",
            "Epoch 52/100 - 0.08s - loss: 1.0717 - acc: 0.4390 - val_loss: 1.0750 - val_acc: 0.4190\n",
            "Epoch 53/100 - 0.07s - loss: 1.0712 - acc: 0.4431 - val_loss: 1.0747 - val_acc: 0.4312\n",
            "Epoch 54/100 - 0.08s - loss: 1.0708 - acc: 0.4442 - val_loss: 1.0744 - val_acc: 0.4332\n",
            "Epoch 55/100 - 0.08s - loss: 1.0704 - acc: 0.4444 - val_loss: 1.0740 - val_acc: 0.4312\n",
            "Epoch 56/100 - 0.08s - loss: 1.0700 - acc: 0.4451 - val_loss: 1.0737 - val_acc: 0.4312\n",
            "Epoch 57/100 - 0.08s - loss: 1.0696 - acc: 0.4449 - val_loss: 1.0734 - val_acc: 0.4312\n",
            "Epoch 58/100 - 0.08s - loss: 1.0691 - acc: 0.4442 - val_loss: 1.0731 - val_acc: 0.4312\n",
            "Epoch 59/100 - 0.07s - loss: 1.0687 - acc: 0.4465 - val_loss: 1.0728 - val_acc: 0.4352\n",
            "Epoch 60/100 - 0.08s - loss: 1.0683 - acc: 0.4485 - val_loss: 1.0725 - val_acc: 0.4393\n",
            "Epoch 61/100 - 0.07s - loss: 1.0679 - acc: 0.4489 - val_loss: 1.0722 - val_acc: 0.4332\n",
            "Epoch 62/100 - 0.07s - loss: 1.0675 - acc: 0.4498 - val_loss: 1.0719 - val_acc: 0.4372\n",
            "Epoch 63/100 - 0.08s - loss: 1.0671 - acc: 0.4507 - val_loss: 1.0716 - val_acc: 0.4433\n",
            "Epoch 64/100 - 0.08s - loss: 1.0667 - acc: 0.4512 - val_loss: 1.0713 - val_acc: 0.4413\n",
            "Epoch 65/100 - 0.08s - loss: 1.0663 - acc: 0.4514 - val_loss: 1.0710 - val_acc: 0.4393\n",
            "Epoch 66/100 - 0.08s - loss: 1.0658 - acc: 0.4530 - val_loss: 1.0707 - val_acc: 0.4372\n",
            "Epoch 67/100 - 0.08s - loss: 1.0654 - acc: 0.4519 - val_loss: 1.0704 - val_acc: 0.4372\n",
            "Epoch 68/100 - 0.08s - loss: 1.0650 - acc: 0.4525 - val_loss: 1.0701 - val_acc: 0.4372\n",
            "Epoch 69/100 - 0.08s - loss: 1.0646 - acc: 0.4541 - val_loss: 1.0698 - val_acc: 0.4312\n",
            "Epoch 70/100 - 0.08s - loss: 1.0642 - acc: 0.4550 - val_loss: 1.0696 - val_acc: 0.4352\n",
            "Epoch 71/100 - 0.08s - loss: 1.0638 - acc: 0.4548 - val_loss: 1.0693 - val_acc: 0.4312\n",
            "Epoch 72/100 - 0.08s - loss: 1.0634 - acc: 0.4584 - val_loss: 1.0690 - val_acc: 0.4332\n",
            "Epoch 73/100 - 0.08s - loss: 1.0630 - acc: 0.4593 - val_loss: 1.0687 - val_acc: 0.4332\n",
            "Epoch 74/100 - 0.08s - loss: 1.0626 - acc: 0.4600 - val_loss: 1.0684 - val_acc: 0.4372\n",
            "Epoch 75/100 - 0.07s - loss: 1.0622 - acc: 0.4629 - val_loss: 1.0681 - val_acc: 0.4372\n",
            "Epoch 76/100 - 0.08s - loss: 1.0619 - acc: 0.4615 - val_loss: 1.0679 - val_acc: 0.4352\n",
            "Epoch 77/100 - 0.08s - loss: 1.0615 - acc: 0.4633 - val_loss: 1.0676 - val_acc: 0.4332\n",
            "Epoch 78/100 - 0.08s - loss: 1.0611 - acc: 0.4620 - val_loss: 1.0673 - val_acc: 0.4352\n",
            "Epoch 79/100 - 0.08s - loss: 1.0607 - acc: 0.4624 - val_loss: 1.0670 - val_acc: 0.4372\n",
            "Epoch 80/100 - 0.08s - loss: 1.0603 - acc: 0.4631 - val_loss: 1.0667 - val_acc: 0.4352\n",
            "Epoch 81/100 - 0.08s - loss: 1.0599 - acc: 0.4645 - val_loss: 1.0665 - val_acc: 0.4393\n",
            "Epoch 82/100 - 0.08s - loss: 1.0595 - acc: 0.4654 - val_loss: 1.0662 - val_acc: 0.4433\n",
            "Epoch 83/100 - 0.07s - loss: 1.0591 - acc: 0.4647 - val_loss: 1.0659 - val_acc: 0.4413\n",
            "Epoch 84/100 - 0.08s - loss: 1.0587 - acc: 0.4640 - val_loss: 1.0656 - val_acc: 0.4433\n",
            "Epoch 85/100 - 0.08s - loss: 1.0583 - acc: 0.4629 - val_loss: 1.0653 - val_acc: 0.4433\n",
            "Epoch 86/100 - 0.08s - loss: 1.0579 - acc: 0.4636 - val_loss: 1.0650 - val_acc: 0.4453\n",
            "Epoch 87/100 - 0.08s - loss: 1.0576 - acc: 0.4654 - val_loss: 1.0648 - val_acc: 0.4453\n",
            "Epoch 88/100 - 0.08s - loss: 1.0572 - acc: 0.4651 - val_loss: 1.0645 - val_acc: 0.4494\n",
            "Epoch 89/100 - 0.08s - loss: 1.0568 - acc: 0.4638 - val_loss: 1.0642 - val_acc: 0.4393\n",
            "Epoch 90/100 - 0.07s - loss: 1.0564 - acc: 0.4656 - val_loss: 1.0640 - val_acc: 0.4433\n",
            "Epoch 91/100 - 0.08s - loss: 1.0560 - acc: 0.4663 - val_loss: 1.0637 - val_acc: 0.4474\n",
            "Epoch 92/100 - 0.08s - loss: 1.0556 - acc: 0.4663 - val_loss: 1.0634 - val_acc: 0.4433\n",
            "Epoch 93/100 - 0.08s - loss: 1.0553 - acc: 0.4669 - val_loss: 1.0631 - val_acc: 0.4413\n",
            "Epoch 94/100 - 0.07s - loss: 1.0549 - acc: 0.4667 - val_loss: 1.0629 - val_acc: 0.4453\n",
            "Epoch 95/100 - 0.08s - loss: 1.0545 - acc: 0.4683 - val_loss: 1.0626 - val_acc: 0.4474\n",
            "Epoch 96/100 - 0.07s - loss: 1.0541 - acc: 0.4674 - val_loss: 1.0623 - val_acc: 0.4555\n",
            "Epoch 97/100 - 0.08s - loss: 1.0537 - acc: 0.4687 - val_loss: 1.0621 - val_acc: 0.4494\n",
            "Epoch 98/100 - 0.08s - loss: 1.0533 - acc: 0.4674 - val_loss: 1.0618 - val_acc: 0.4534\n",
            "Epoch 99/100 - 0.08s - loss: 1.0530 - acc: 0.4703 - val_loss: 1.0615 - val_acc: 0.4494\n",
            "Epoch 100/100 - 0.08s - loss: 1.0526 - acc: 0.4703 - val_loss: 1.0613 - val_acc: 0.4534\n",
            "\n",
            "Combination 66/252:\n",
            "Hidden Layers: [128, 64], Activation: tanh, Learning Rate: 0.001, Batch Size: 64, Epochs: 150\n",
            "Epoch 1/150 - 0.08s - loss: 1.1267 - acc: 0.3500 - val_loss: 1.1266 - val_acc: 0.3502\n",
            "Epoch 2/150 - 0.08s - loss: 1.1129 - acc: 0.3466 - val_loss: 1.1135 - val_acc: 0.3522\n",
            "Epoch 3/150 - 0.08s - loss: 1.1072 - acc: 0.3412 - val_loss: 1.1081 - val_acc: 0.3543\n",
            "Epoch 4/150 - 0.08s - loss: 1.1043 - acc: 0.3450 - val_loss: 1.1054 - val_acc: 0.3522\n",
            "Epoch 5/150 - 0.07s - loss: 1.1024 - acc: 0.3475 - val_loss: 1.1037 - val_acc: 0.3401\n",
            "Epoch 6/150 - 0.08s - loss: 1.1010 - acc: 0.3500 - val_loss: 1.1024 - val_acc: 0.3441\n",
            "Epoch 7/150 - 0.07s - loss: 1.0997 - acc: 0.3545 - val_loss: 1.1012 - val_acc: 0.3401\n",
            "Epoch 8/150 - 0.08s - loss: 1.0985 - acc: 0.3590 - val_loss: 1.1003 - val_acc: 0.3401\n",
            "Epoch 9/150 - 0.08s - loss: 1.0974 - acc: 0.3601 - val_loss: 1.0993 - val_acc: 0.3381\n",
            "Epoch 10/150 - 0.08s - loss: 1.0963 - acc: 0.3644 - val_loss: 1.0983 - val_acc: 0.3421\n",
            "Epoch 11/150 - 0.08s - loss: 1.0953 - acc: 0.3675 - val_loss: 1.0974 - val_acc: 0.3543\n",
            "Epoch 12/150 - 0.08s - loss: 1.0942 - acc: 0.3709 - val_loss: 1.0965 - val_acc: 0.3603\n",
            "Epoch 13/150 - 0.07s - loss: 1.0932 - acc: 0.3725 - val_loss: 1.0957 - val_acc: 0.3603\n",
            "Epoch 14/150 - 0.07s - loss: 1.0923 - acc: 0.3752 - val_loss: 1.0949 - val_acc: 0.3603\n",
            "Epoch 15/150 - 0.08s - loss: 1.0913 - acc: 0.3783 - val_loss: 1.0941 - val_acc: 0.3704\n",
            "Epoch 16/150 - 0.07s - loss: 1.0904 - acc: 0.3792 - val_loss: 1.0933 - val_acc: 0.3785\n",
            "Epoch 17/150 - 0.07s - loss: 1.0895 - acc: 0.3806 - val_loss: 1.0925 - val_acc: 0.3947\n",
            "Epoch 18/150 - 0.08s - loss: 1.0886 - acc: 0.3855 - val_loss: 1.0918 - val_acc: 0.3947\n",
            "Epoch 19/150 - 0.07s - loss: 1.0877 - acc: 0.3900 - val_loss: 1.0911 - val_acc: 0.3968\n",
            "Epoch 20/150 - 0.07s - loss: 1.0868 - acc: 0.3925 - val_loss: 1.0904 - val_acc: 0.3968\n",
            "Epoch 21/150 - 0.07s - loss: 1.0860 - acc: 0.3943 - val_loss: 1.0896 - val_acc: 0.4069\n",
            "Epoch 22/150 - 0.07s - loss: 1.0852 - acc: 0.3968 - val_loss: 1.0889 - val_acc: 0.4069\n",
            "Epoch 23/150 - 0.07s - loss: 1.0844 - acc: 0.3997 - val_loss: 1.0882 - val_acc: 0.4089\n",
            "Epoch 24/150 - 0.10s - loss: 1.0836 - acc: 0.4044 - val_loss: 1.0877 - val_acc: 0.4069\n",
            "Epoch 25/150 - 0.07s - loss: 1.0828 - acc: 0.4067 - val_loss: 1.0871 - val_acc: 0.4028\n",
            "Epoch 26/150 - 0.08s - loss: 1.0820 - acc: 0.4121 - val_loss: 1.0864 - val_acc: 0.3988\n",
            "Epoch 27/150 - 0.07s - loss: 1.0813 - acc: 0.4109 - val_loss: 1.0859 - val_acc: 0.4008\n",
            "Epoch 28/150 - 0.07s - loss: 1.0806 - acc: 0.4159 - val_loss: 1.0852 - val_acc: 0.4028\n",
            "Epoch 29/150 - 0.07s - loss: 1.0798 - acc: 0.4224 - val_loss: 1.0845 - val_acc: 0.4049\n",
            "Epoch 30/150 - 0.08s - loss: 1.0791 - acc: 0.4256 - val_loss: 1.0840 - val_acc: 0.4069\n",
            "Epoch 31/150 - 0.07s - loss: 1.0784 - acc: 0.4242 - val_loss: 1.0834 - val_acc: 0.4130\n",
            "Epoch 32/150 - 0.07s - loss: 1.0778 - acc: 0.4256 - val_loss: 1.0828 - val_acc: 0.4150\n",
            "Epoch 33/150 - 0.08s - loss: 1.0771 - acc: 0.4271 - val_loss: 1.0822 - val_acc: 0.4150\n",
            "Epoch 34/150 - 0.07s - loss: 1.0764 - acc: 0.4287 - val_loss: 1.0817 - val_acc: 0.4150\n",
            "Epoch 35/150 - 0.07s - loss: 1.0758 - acc: 0.4300 - val_loss: 1.0812 - val_acc: 0.4130\n",
            "Epoch 36/150 - 0.07s - loss: 1.0751 - acc: 0.4325 - val_loss: 1.0806 - val_acc: 0.4089\n",
            "Epoch 37/150 - 0.07s - loss: 1.0745 - acc: 0.4341 - val_loss: 1.0802 - val_acc: 0.4109\n",
            "Epoch 38/150 - 0.07s - loss: 1.0739 - acc: 0.4352 - val_loss: 1.0797 - val_acc: 0.4109\n",
            "Epoch 39/150 - 0.08s - loss: 1.0732 - acc: 0.4339 - val_loss: 1.0791 - val_acc: 0.4109\n",
            "Epoch 40/150 - 0.07s - loss: 1.0726 - acc: 0.4361 - val_loss: 1.0787 - val_acc: 0.4089\n",
            "Epoch 41/150 - 0.07s - loss: 1.0720 - acc: 0.4363 - val_loss: 1.0782 - val_acc: 0.4150\n",
            "Epoch 42/150 - 0.08s - loss: 1.0714 - acc: 0.4377 - val_loss: 1.0778 - val_acc: 0.4170\n",
            "Epoch 43/150 - 0.07s - loss: 1.0709 - acc: 0.4381 - val_loss: 1.0773 - val_acc: 0.4170\n",
            "Epoch 44/150 - 0.07s - loss: 1.0703 - acc: 0.4422 - val_loss: 1.0768 - val_acc: 0.4231\n",
            "Epoch 45/150 - 0.08s - loss: 1.0697 - acc: 0.4424 - val_loss: 1.0764 - val_acc: 0.4251\n",
            "Epoch 46/150 - 0.08s - loss: 1.0691 - acc: 0.4440 - val_loss: 1.0759 - val_acc: 0.4231\n",
            "Epoch 47/150 - 0.08s - loss: 1.0686 - acc: 0.4451 - val_loss: 1.0754 - val_acc: 0.4170\n",
            "Epoch 48/150 - 0.08s - loss: 1.0680 - acc: 0.4498 - val_loss: 1.0750 - val_acc: 0.4251\n",
            "Epoch 49/150 - 0.07s - loss: 1.0675 - acc: 0.4496 - val_loss: 1.0746 - val_acc: 0.4190\n",
            "Epoch 50/150 - 0.08s - loss: 1.0670 - acc: 0.4501 - val_loss: 1.0742 - val_acc: 0.4231\n",
            "Epoch 51/150 - 0.08s - loss: 1.0664 - acc: 0.4510 - val_loss: 1.0738 - val_acc: 0.4211\n",
            "Epoch 52/150 - 0.07s - loss: 1.0659 - acc: 0.4528 - val_loss: 1.0734 - val_acc: 0.4170\n",
            "Epoch 53/150 - 0.07s - loss: 1.0654 - acc: 0.4532 - val_loss: 1.0730 - val_acc: 0.4251\n",
            "Epoch 54/150 - 0.07s - loss: 1.0649 - acc: 0.4530 - val_loss: 1.0726 - val_acc: 0.4251\n",
            "Epoch 55/150 - 0.07s - loss: 1.0644 - acc: 0.4548 - val_loss: 1.0722 - val_acc: 0.4251\n",
            "Epoch 56/150 - 0.07s - loss: 1.0638 - acc: 0.4543 - val_loss: 1.0717 - val_acc: 0.4231\n",
            "Epoch 57/150 - 0.08s - loss: 1.0633 - acc: 0.4548 - val_loss: 1.0714 - val_acc: 0.4291\n",
            "Epoch 58/150 - 0.08s - loss: 1.0628 - acc: 0.4546 - val_loss: 1.0710 - val_acc: 0.4231\n",
            "Epoch 59/150 - 0.08s - loss: 1.0624 - acc: 0.4550 - val_loss: 1.0706 - val_acc: 0.4251\n",
            "Epoch 60/150 - 0.08s - loss: 1.0619 - acc: 0.4557 - val_loss: 1.0702 - val_acc: 0.4251\n",
            "Epoch 61/150 - 0.08s - loss: 1.0614 - acc: 0.4566 - val_loss: 1.0699 - val_acc: 0.4291\n",
            "Epoch 62/150 - 0.08s - loss: 1.0609 - acc: 0.4561 - val_loss: 1.0695 - val_acc: 0.4271\n",
            "Epoch 63/150 - 0.08s - loss: 1.0604 - acc: 0.4575 - val_loss: 1.0692 - val_acc: 0.4332\n",
            "Epoch 64/150 - 0.08s - loss: 1.0600 - acc: 0.4600 - val_loss: 1.0688 - val_acc: 0.4271\n",
            "Epoch 65/150 - 0.08s - loss: 1.0595 - acc: 0.4602 - val_loss: 1.0685 - val_acc: 0.4291\n",
            "Epoch 66/150 - 0.08s - loss: 1.0590 - acc: 0.4622 - val_loss: 1.0681 - val_acc: 0.4312\n",
            "Epoch 67/150 - 0.08s - loss: 1.0586 - acc: 0.4609 - val_loss: 1.0678 - val_acc: 0.4291\n",
            "Epoch 68/150 - 0.08s - loss: 1.0581 - acc: 0.4640 - val_loss: 1.0674 - val_acc: 0.4291\n",
            "Epoch 69/150 - 0.08s - loss: 1.0577 - acc: 0.4651 - val_loss: 1.0670 - val_acc: 0.4271\n",
            "Epoch 70/150 - 0.07s - loss: 1.0572 - acc: 0.4669 - val_loss: 1.0667 - val_acc: 0.4332\n",
            "Epoch 71/150 - 0.08s - loss: 1.0568 - acc: 0.4665 - val_loss: 1.0663 - val_acc: 0.4352\n",
            "Epoch 72/150 - 0.08s - loss: 1.0563 - acc: 0.4685 - val_loss: 1.0660 - val_acc: 0.4312\n",
            "Epoch 73/150 - 0.08s - loss: 1.0559 - acc: 0.4685 - val_loss: 1.0657 - val_acc: 0.4312\n",
            "Epoch 74/150 - 0.08s - loss: 1.0554 - acc: 0.4694 - val_loss: 1.0654 - val_acc: 0.4372\n",
            "Epoch 75/150 - 0.08s - loss: 1.0550 - acc: 0.4701 - val_loss: 1.0651 - val_acc: 0.4352\n",
            "Epoch 76/150 - 0.08s - loss: 1.0546 - acc: 0.4696 - val_loss: 1.0647 - val_acc: 0.4332\n",
            "Epoch 77/150 - 0.08s - loss: 1.0541 - acc: 0.4719 - val_loss: 1.0644 - val_acc: 0.4352\n",
            "Epoch 78/150 - 0.08s - loss: 1.0537 - acc: 0.4694 - val_loss: 1.0641 - val_acc: 0.4332\n",
            "Epoch 79/150 - 0.08s - loss: 1.0533 - acc: 0.4699 - val_loss: 1.0638 - val_acc: 0.4332\n",
            "Epoch 80/150 - 0.08s - loss: 1.0529 - acc: 0.4701 - val_loss: 1.0634 - val_acc: 0.4393\n",
            "Epoch 81/150 - 0.08s - loss: 1.0525 - acc: 0.4699 - val_loss: 1.0630 - val_acc: 0.4393\n",
            "Epoch 82/150 - 0.08s - loss: 1.0520 - acc: 0.4705 - val_loss: 1.0627 - val_acc: 0.4433\n",
            "Epoch 83/150 - 0.08s - loss: 1.0516 - acc: 0.4714 - val_loss: 1.0625 - val_acc: 0.4352\n",
            "Epoch 84/150 - 0.08s - loss: 1.0512 - acc: 0.4723 - val_loss: 1.0622 - val_acc: 0.4352\n",
            "Epoch 85/150 - 0.08s - loss: 1.0508 - acc: 0.4732 - val_loss: 1.0620 - val_acc: 0.4352\n",
            "Epoch 86/150 - 0.09s - loss: 1.0504 - acc: 0.4735 - val_loss: 1.0617 - val_acc: 0.4352\n",
            "Epoch 87/150 - 0.08s - loss: 1.0500 - acc: 0.4746 - val_loss: 1.0614 - val_acc: 0.4413\n",
            "Epoch 88/150 - 0.08s - loss: 1.0496 - acc: 0.4748 - val_loss: 1.0611 - val_acc: 0.4413\n",
            "Epoch 89/150 - 0.08s - loss: 1.0492 - acc: 0.4739 - val_loss: 1.0608 - val_acc: 0.4453\n",
            "Epoch 90/150 - 0.08s - loss: 1.0488 - acc: 0.4741 - val_loss: 1.0604 - val_acc: 0.4474\n",
            "Epoch 91/150 - 0.08s - loss: 1.0484 - acc: 0.4755 - val_loss: 1.0602 - val_acc: 0.4433\n",
            "Epoch 92/150 - 0.08s - loss: 1.0480 - acc: 0.4757 - val_loss: 1.0599 - val_acc: 0.4474\n",
            "Epoch 93/150 - 0.08s - loss: 1.0476 - acc: 0.4748 - val_loss: 1.0595 - val_acc: 0.4494\n",
            "Epoch 94/150 - 0.08s - loss: 1.0472 - acc: 0.4757 - val_loss: 1.0593 - val_acc: 0.4514\n",
            "Epoch 95/150 - 0.08s - loss: 1.0468 - acc: 0.4773 - val_loss: 1.0590 - val_acc: 0.4494\n",
            "Epoch 96/150 - 0.08s - loss: 1.0464 - acc: 0.4766 - val_loss: 1.0588 - val_acc: 0.4514\n",
            "Epoch 97/150 - 0.08s - loss: 1.0460 - acc: 0.4795 - val_loss: 1.0585 - val_acc: 0.4494\n",
            "Epoch 98/150 - 0.08s - loss: 1.0457 - acc: 0.4802 - val_loss: 1.0581 - val_acc: 0.4494\n",
            "Epoch 99/150 - 0.08s - loss: 1.0453 - acc: 0.4773 - val_loss: 1.0580 - val_acc: 0.4514\n",
            "Epoch 100/150 - 0.08s - loss: 1.0449 - acc: 0.4773 - val_loss: 1.0578 - val_acc: 0.4494\n",
            "Epoch 101/150 - 0.08s - loss: 1.0445 - acc: 0.4802 - val_loss: 1.0575 - val_acc: 0.4514\n",
            "Epoch 102/150 - 0.08s - loss: 1.0441 - acc: 0.4813 - val_loss: 1.0571 - val_acc: 0.4514\n",
            "Epoch 103/150 - 0.08s - loss: 1.0437 - acc: 0.4825 - val_loss: 1.0568 - val_acc: 0.4514\n",
            "Epoch 104/150 - 0.08s - loss: 1.0434 - acc: 0.4836 - val_loss: 1.0565 - val_acc: 0.4514\n",
            "Epoch 105/150 - 0.08s - loss: 1.0430 - acc: 0.4827 - val_loss: 1.0562 - val_acc: 0.4534\n",
            "Epoch 106/150 - 0.08s - loss: 1.0426 - acc: 0.4827 - val_loss: 1.0561 - val_acc: 0.4514\n",
            "Epoch 107/150 - 0.08s - loss: 1.0422 - acc: 0.4834 - val_loss: 1.0558 - val_acc: 0.4474\n",
            "Epoch 108/150 - 0.08s - loss: 1.0419 - acc: 0.4831 - val_loss: 1.0555 - val_acc: 0.4474\n",
            "Epoch 109/150 - 0.08s - loss: 1.0415 - acc: 0.4818 - val_loss: 1.0551 - val_acc: 0.4534\n",
            "Epoch 110/150 - 0.08s - loss: 1.0411 - acc: 0.4849 - val_loss: 1.0550 - val_acc: 0.4494\n",
            "Epoch 111/150 - 0.09s - loss: 1.0407 - acc: 0.4852 - val_loss: 1.0547 - val_acc: 0.4494\n",
            "Epoch 112/150 - 0.08s - loss: 1.0404 - acc: 0.4856 - val_loss: 1.0543 - val_acc: 0.4615\n",
            "Epoch 113/150 - 0.08s - loss: 1.0400 - acc: 0.4874 - val_loss: 1.0542 - val_acc: 0.4575\n",
            "Epoch 114/150 - 0.08s - loss: 1.0396 - acc: 0.4849 - val_loss: 1.0539 - val_acc: 0.4534\n",
            "Epoch 115/150 - 0.08s - loss: 1.0393 - acc: 0.4845 - val_loss: 1.0537 - val_acc: 0.4555\n",
            "Epoch 116/150 - 0.08s - loss: 1.0389 - acc: 0.4858 - val_loss: 1.0534 - val_acc: 0.4595\n",
            "Epoch 117/150 - 0.08s - loss: 1.0385 - acc: 0.4849 - val_loss: 1.0531 - val_acc: 0.4575\n",
            "Epoch 118/150 - 0.08s - loss: 1.0382 - acc: 0.4863 - val_loss: 1.0528 - val_acc: 0.4676\n",
            "Epoch 119/150 - 0.08s - loss: 1.0378 - acc: 0.4883 - val_loss: 1.0526 - val_acc: 0.4656\n",
            "Epoch 120/150 - 0.08s - loss: 1.0375 - acc: 0.4892 - val_loss: 1.0524 - val_acc: 0.4636\n",
            "Epoch 121/150 - 0.07s - loss: 1.0371 - acc: 0.4874 - val_loss: 1.0521 - val_acc: 0.4696\n",
            "Epoch 122/150 - 0.08s - loss: 1.0367 - acc: 0.4894 - val_loss: 1.0519 - val_acc: 0.4717\n",
            "Epoch 123/150 - 0.10s - loss: 1.0364 - acc: 0.4888 - val_loss: 1.0517 - val_acc: 0.4717\n",
            "Epoch 124/150 - 0.07s - loss: 1.0360 - acc: 0.4876 - val_loss: 1.0512 - val_acc: 0.4737\n",
            "Epoch 125/150 - 0.08s - loss: 1.0357 - acc: 0.4876 - val_loss: 1.0510 - val_acc: 0.4737\n",
            "Epoch 126/150 - 0.07s - loss: 1.0353 - acc: 0.4865 - val_loss: 1.0507 - val_acc: 0.4757\n",
            "Epoch 127/150 - 0.08s - loss: 1.0350 - acc: 0.4870 - val_loss: 1.0505 - val_acc: 0.4757\n",
            "Epoch 128/150 - 0.07s - loss: 1.0346 - acc: 0.4894 - val_loss: 1.0504 - val_acc: 0.4696\n",
            "Epoch 129/150 - 0.07s - loss: 1.0342 - acc: 0.4883 - val_loss: 1.0501 - val_acc: 0.4757\n",
            "Epoch 130/150 - 0.07s - loss: 1.0339 - acc: 0.4890 - val_loss: 1.0500 - val_acc: 0.4717\n",
            "Epoch 131/150 - 0.08s - loss: 1.0335 - acc: 0.4876 - val_loss: 1.0496 - val_acc: 0.4777\n",
            "Epoch 132/150 - 0.08s - loss: 1.0332 - acc: 0.4894 - val_loss: 1.0494 - val_acc: 0.4818\n",
            "Epoch 133/150 - 0.08s - loss: 1.0328 - acc: 0.4901 - val_loss: 1.0493 - val_acc: 0.4798\n",
            "Epoch 134/150 - 0.08s - loss: 1.0325 - acc: 0.4890 - val_loss: 1.0490 - val_acc: 0.4798\n",
            "Epoch 135/150 - 0.09s - loss: 1.0321 - acc: 0.4903 - val_loss: 1.0486 - val_acc: 0.4858\n",
            "Epoch 136/150 - 0.08s - loss: 1.0318 - acc: 0.4908 - val_loss: 1.0485 - val_acc: 0.4838\n",
            "Epoch 137/150 - 0.08s - loss: 1.0314 - acc: 0.4912 - val_loss: 1.0482 - val_acc: 0.4818\n",
            "Epoch 138/150 - 0.08s - loss: 1.0311 - acc: 0.4937 - val_loss: 1.0480 - val_acc: 0.4858\n",
            "Epoch 139/150 - 0.07s - loss: 1.0307 - acc: 0.4937 - val_loss: 1.0478 - val_acc: 0.4818\n",
            "Epoch 140/150 - 0.08s - loss: 1.0304 - acc: 0.4942 - val_loss: 1.0475 - val_acc: 0.4818\n",
            "Epoch 141/150 - 0.08s - loss: 1.0300 - acc: 0.4928 - val_loss: 1.0472 - val_acc: 0.4838\n",
            "Epoch 142/150 - 0.08s - loss: 1.0297 - acc: 0.4912 - val_loss: 1.0470 - val_acc: 0.4798\n",
            "Epoch 143/150 - 0.08s - loss: 1.0293 - acc: 0.4888 - val_loss: 1.0468 - val_acc: 0.4757\n",
            "Epoch 144/150 - 0.08s - loss: 1.0289 - acc: 0.4926 - val_loss: 1.0465 - val_acc: 0.4818\n",
            "Epoch 145/150 - 0.08s - loss: 1.0286 - acc: 0.4928 - val_loss: 1.0463 - val_acc: 0.4838\n",
            "Epoch 146/150 - 0.08s - loss: 1.0283 - acc: 0.4930 - val_loss: 1.0459 - val_acc: 0.4858\n",
            "Epoch 147/150 - 0.09s - loss: 1.0279 - acc: 0.4933 - val_loss: 1.0457 - val_acc: 0.4879\n",
            "Epoch 148/150 - 0.08s - loss: 1.0276 - acc: 0.4944 - val_loss: 1.0453 - val_acc: 0.4798\n",
            "Epoch 149/150 - 0.08s - loss: 1.0272 - acc: 0.4946 - val_loss: 1.0452 - val_acc: 0.4858\n",
            "Epoch 150/150 - 0.08s - loss: 1.0269 - acc: 0.4953 - val_loss: 1.0449 - val_acc: 0.4818\n",
            "\n",
            "Combination 67/252:\n",
            "Hidden Layers: [128, 64], Activation: tanh, Learning Rate: 0.0001, Batch Size: 32, Epochs: 50\n",
            "Epoch 1/50 - 0.09s - loss: 1.1411 - acc: 0.3266 - val_loss: 1.1448 - val_acc: 0.3178\n",
            "Epoch 2/50 - 0.09s - loss: 1.1361 - acc: 0.3248 - val_loss: 1.1393 - val_acc: 0.3239\n",
            "Epoch 3/50 - 0.09s - loss: 1.1318 - acc: 0.3250 - val_loss: 1.1346 - val_acc: 0.3441\n",
            "Epoch 4/50 - 0.09s - loss: 1.1282 - acc: 0.3252 - val_loss: 1.1306 - val_acc: 0.3462\n",
            "Epoch 5/50 - 0.09s - loss: 1.1252 - acc: 0.3221 - val_loss: 1.1271 - val_acc: 0.3441\n",
            "Epoch 6/50 - 0.09s - loss: 1.1225 - acc: 0.3205 - val_loss: 1.1241 - val_acc: 0.3320\n",
            "Epoch 7/50 - 0.09s - loss: 1.1202 - acc: 0.3192 - val_loss: 1.1215 - val_acc: 0.3259\n",
            "Epoch 8/50 - 0.10s - loss: 1.1183 - acc: 0.3153 - val_loss: 1.1193 - val_acc: 0.3279\n",
            "Epoch 9/50 - 0.09s - loss: 1.1166 - acc: 0.3174 - val_loss: 1.1173 - val_acc: 0.3320\n",
            "Epoch 10/50 - 0.09s - loss: 1.1151 - acc: 0.3142 - val_loss: 1.1156 - val_acc: 0.3219\n",
            "Epoch 11/50 - 0.09s - loss: 1.1139 - acc: 0.3135 - val_loss: 1.1141 - val_acc: 0.3138\n",
            "Epoch 12/50 - 0.09s - loss: 1.1128 - acc: 0.3142 - val_loss: 1.1128 - val_acc: 0.3178\n",
            "Epoch 13/50 - 0.09s - loss: 1.1118 - acc: 0.3115 - val_loss: 1.1117 - val_acc: 0.3219\n",
            "Epoch 14/50 - 0.09s - loss: 1.1110 - acc: 0.3122 - val_loss: 1.1106 - val_acc: 0.3259\n",
            "Epoch 15/50 - 0.09s - loss: 1.1102 - acc: 0.3086 - val_loss: 1.1097 - val_acc: 0.3198\n",
            "Epoch 16/50 - 0.09s - loss: 1.1095 - acc: 0.3070 - val_loss: 1.1089 - val_acc: 0.3279\n",
            "Epoch 17/50 - 0.09s - loss: 1.1089 - acc: 0.3066 - val_loss: 1.1082 - val_acc: 0.3279\n",
            "Epoch 18/50 - 0.09s - loss: 1.1084 - acc: 0.3048 - val_loss: 1.1076 - val_acc: 0.3279\n",
            "Epoch 19/50 - 0.09s - loss: 1.1079 - acc: 0.3072 - val_loss: 1.1070 - val_acc: 0.3219\n",
            "Epoch 20/50 - 0.10s - loss: 1.1075 - acc: 0.3079 - val_loss: 1.1064 - val_acc: 0.3219\n",
            "Epoch 21/50 - 0.09s - loss: 1.1071 - acc: 0.3066 - val_loss: 1.1059 - val_acc: 0.3239\n",
            "Epoch 22/50 - 0.09s - loss: 1.1067 - acc: 0.3077 - val_loss: 1.1055 - val_acc: 0.3219\n",
            "Epoch 23/50 - 0.09s - loss: 1.1063 - acc: 0.3088 - val_loss: 1.1051 - val_acc: 0.3219\n",
            "Epoch 24/50 - 0.09s - loss: 1.1060 - acc: 0.3090 - val_loss: 1.1047 - val_acc: 0.3239\n",
            "Epoch 25/50 - 0.09s - loss: 1.1057 - acc: 0.3097 - val_loss: 1.1043 - val_acc: 0.3259\n",
            "Epoch 26/50 - 0.09s - loss: 1.1054 - acc: 0.3111 - val_loss: 1.1040 - val_acc: 0.3300\n",
            "Epoch 27/50 - 0.09s - loss: 1.1051 - acc: 0.3111 - val_loss: 1.1037 - val_acc: 0.3381\n",
            "Epoch 28/50 - 0.09s - loss: 1.1049 - acc: 0.3111 - val_loss: 1.1034 - val_acc: 0.3401\n",
            "Epoch 29/50 - 0.09s - loss: 1.1046 - acc: 0.3115 - val_loss: 1.1031 - val_acc: 0.3381\n",
            "Epoch 30/50 - 0.09s - loss: 1.1044 - acc: 0.3126 - val_loss: 1.1029 - val_acc: 0.3320\n",
            "Epoch 31/50 - 0.09s - loss: 1.1042 - acc: 0.3140 - val_loss: 1.1026 - val_acc: 0.3320\n",
            "Epoch 32/50 - 0.10s - loss: 1.1039 - acc: 0.3144 - val_loss: 1.1024 - val_acc: 0.3360\n",
            "Epoch 33/50 - 0.09s - loss: 1.1037 - acc: 0.3151 - val_loss: 1.1021 - val_acc: 0.3360\n",
            "Epoch 34/50 - 0.09s - loss: 1.1035 - acc: 0.3165 - val_loss: 1.1019 - val_acc: 0.3401\n",
            "Epoch 35/50 - 0.09s - loss: 1.1033 - acc: 0.3176 - val_loss: 1.1017 - val_acc: 0.3421\n",
            "Epoch 36/50 - 0.09s - loss: 1.1031 - acc: 0.3171 - val_loss: 1.1015 - val_acc: 0.3462\n",
            "Epoch 37/50 - 0.09s - loss: 1.1029 - acc: 0.3158 - val_loss: 1.1013 - val_acc: 0.3482\n",
            "Epoch 38/50 - 0.09s - loss: 1.1027 - acc: 0.3183 - val_loss: 1.1011 - val_acc: 0.3522\n",
            "Epoch 39/50 - 0.09s - loss: 1.1025 - acc: 0.3185 - val_loss: 1.1009 - val_acc: 0.3482\n",
            "Epoch 40/50 - 0.09s - loss: 1.1023 - acc: 0.3198 - val_loss: 1.1007 - val_acc: 0.3482\n",
            "Epoch 41/50 - 0.09s - loss: 1.1021 - acc: 0.3207 - val_loss: 1.1005 - val_acc: 0.3462\n",
            "Epoch 42/50 - 0.09s - loss: 1.1019 - acc: 0.3219 - val_loss: 1.1003 - val_acc: 0.3482\n",
            "Epoch 43/50 - 0.09s - loss: 1.1017 - acc: 0.3221 - val_loss: 1.1001 - val_acc: 0.3462\n",
            "Epoch 44/50 - 0.10s - loss: 1.1015 - acc: 0.3228 - val_loss: 1.0999 - val_acc: 0.3482\n",
            "Epoch 45/50 - 0.09s - loss: 1.1013 - acc: 0.3237 - val_loss: 1.0998 - val_acc: 0.3482\n",
            "Epoch 46/50 - 0.09s - loss: 1.1011 - acc: 0.3241 - val_loss: 1.0996 - val_acc: 0.3482\n",
            "Epoch 47/50 - 0.09s - loss: 1.1010 - acc: 0.3252 - val_loss: 1.0994 - val_acc: 0.3441\n",
            "Epoch 48/50 - 0.09s - loss: 1.1008 - acc: 0.3243 - val_loss: 1.0992 - val_acc: 0.3462\n",
            "Epoch 49/50 - 0.09s - loss: 1.1006 - acc: 0.3241 - val_loss: 1.0991 - val_acc: 0.3441\n",
            "Epoch 50/50 - 0.09s - loss: 1.1004 - acc: 0.3250 - val_loss: 1.0989 - val_acc: 0.3543\n",
            "\n",
            "Combination 68/252:\n",
            "Hidden Layers: [128, 64], Activation: tanh, Learning Rate: 0.0001, Batch Size: 32, Epochs: 100\n",
            "Epoch 1/100 - 0.09s - loss: 1.1072 - acc: 0.3500 - val_loss: 1.1109 - val_acc: 0.3502\n",
            "Epoch 2/100 - 0.09s - loss: 1.1065 - acc: 0.3480 - val_loss: 1.1103 - val_acc: 0.3543\n",
            "Epoch 3/100 - 0.09s - loss: 1.1058 - acc: 0.3462 - val_loss: 1.1097 - val_acc: 0.3381\n",
            "Epoch 4/100 - 0.09s - loss: 1.1053 - acc: 0.3453 - val_loss: 1.1093 - val_acc: 0.3320\n",
            "Epoch 5/100 - 0.09s - loss: 1.1048 - acc: 0.3468 - val_loss: 1.1089 - val_acc: 0.3279\n",
            "Epoch 6/100 - 0.10s - loss: 1.1043 - acc: 0.3430 - val_loss: 1.1085 - val_acc: 0.3198\n",
            "Epoch 7/100 - 0.09s - loss: 1.1039 - acc: 0.3430 - val_loss: 1.1081 - val_acc: 0.3178\n",
            "Epoch 8/100 - 0.09s - loss: 1.1035 - acc: 0.3412 - val_loss: 1.1078 - val_acc: 0.3219\n",
            "Epoch 9/100 - 0.09s - loss: 1.1031 - acc: 0.3417 - val_loss: 1.1075 - val_acc: 0.3279\n",
            "Epoch 10/100 - 0.09s - loss: 1.1028 - acc: 0.3412 - val_loss: 1.1072 - val_acc: 0.3259\n",
            "Epoch 11/100 - 0.10s - loss: 1.1025 - acc: 0.3439 - val_loss: 1.1069 - val_acc: 0.3219\n",
            "Epoch 12/100 - 0.10s - loss: 1.1021 - acc: 0.3437 - val_loss: 1.1067 - val_acc: 0.3219\n",
            "Epoch 13/100 - 0.09s - loss: 1.1018 - acc: 0.3444 - val_loss: 1.1064 - val_acc: 0.3198\n",
            "Epoch 14/100 - 0.09s - loss: 1.1015 - acc: 0.3450 - val_loss: 1.1062 - val_acc: 0.3219\n",
            "Epoch 15/100 - 0.09s - loss: 1.1012 - acc: 0.3441 - val_loss: 1.1059 - val_acc: 0.3198\n",
            "Epoch 16/100 - 0.09s - loss: 1.1009 - acc: 0.3455 - val_loss: 1.1057 - val_acc: 0.3198\n",
            "Epoch 17/100 - 0.09s - loss: 1.1006 - acc: 0.3475 - val_loss: 1.1054 - val_acc: 0.3239\n",
            "Epoch 18/100 - 0.11s - loss: 1.1004 - acc: 0.3477 - val_loss: 1.1052 - val_acc: 0.3259\n",
            "Epoch 19/100 - 0.09s - loss: 1.1001 - acc: 0.3480 - val_loss: 1.1049 - val_acc: 0.3259\n",
            "Epoch 20/100 - 0.09s - loss: 1.0998 - acc: 0.3464 - val_loss: 1.1047 - val_acc: 0.3239\n",
            "Epoch 21/100 - 0.09s - loss: 1.0995 - acc: 0.3466 - val_loss: 1.1045 - val_acc: 0.3259\n",
            "Epoch 22/100 - 0.09s - loss: 1.0993 - acc: 0.3466 - val_loss: 1.1042 - val_acc: 0.3239\n",
            "Epoch 23/100 - 0.09s - loss: 1.0990 - acc: 0.3484 - val_loss: 1.1040 - val_acc: 0.3320\n",
            "Epoch 24/100 - 0.09s - loss: 1.0987 - acc: 0.3482 - val_loss: 1.1038 - val_acc: 0.3279\n",
            "Epoch 25/100 - 0.09s - loss: 1.0985 - acc: 0.3459 - val_loss: 1.1036 - val_acc: 0.3279\n",
            "Epoch 26/100 - 0.09s - loss: 1.0982 - acc: 0.3473 - val_loss: 1.1033 - val_acc: 0.3259\n",
            "Epoch 27/100 - 0.09s - loss: 1.0980 - acc: 0.3482 - val_loss: 1.1031 - val_acc: 0.3300\n",
            "Epoch 28/100 - 0.09s - loss: 1.0977 - acc: 0.3500 - val_loss: 1.1029 - val_acc: 0.3279\n",
            "Epoch 29/100 - 0.09s - loss: 1.0974 - acc: 0.3516 - val_loss: 1.1027 - val_acc: 0.3300\n",
            "Epoch 30/100 - 0.10s - loss: 1.0972 - acc: 0.3513 - val_loss: 1.1024 - val_acc: 0.3360\n",
            "Epoch 31/100 - 0.09s - loss: 1.0969 - acc: 0.3520 - val_loss: 1.1022 - val_acc: 0.3401\n",
            "Epoch 32/100 - 0.09s - loss: 1.0967 - acc: 0.3536 - val_loss: 1.1020 - val_acc: 0.3401\n",
            "Epoch 33/100 - 0.09s - loss: 1.0964 - acc: 0.3565 - val_loss: 1.1018 - val_acc: 0.3421\n",
            "Epoch 34/100 - 0.09s - loss: 1.0962 - acc: 0.3578 - val_loss: 1.1016 - val_acc: 0.3441\n",
            "Epoch 35/100 - 0.09s - loss: 1.0959 - acc: 0.3576 - val_loss: 1.1014 - val_acc: 0.3441\n",
            "Epoch 36/100 - 0.09s - loss: 1.0957 - acc: 0.3581 - val_loss: 1.1012 - val_acc: 0.3482\n",
            "Epoch 37/100 - 0.09s - loss: 1.0955 - acc: 0.3581 - val_loss: 1.1009 - val_acc: 0.3482\n",
            "Epoch 38/100 - 0.09s - loss: 1.0952 - acc: 0.3594 - val_loss: 1.1007 - val_acc: 0.3462\n",
            "Epoch 39/100 - 0.09s - loss: 1.0950 - acc: 0.3592 - val_loss: 1.1005 - val_acc: 0.3482\n",
            "Epoch 40/100 - 0.09s - loss: 1.0947 - acc: 0.3599 - val_loss: 1.1003 - val_acc: 0.3482\n",
            "Epoch 41/100 - 0.09s - loss: 1.0945 - acc: 0.3599 - val_loss: 1.1001 - val_acc: 0.3462\n",
            "Epoch 42/100 - 0.10s - loss: 1.0943 - acc: 0.3601 - val_loss: 1.0999 - val_acc: 0.3502\n",
            "Epoch 43/100 - 0.09s - loss: 1.0940 - acc: 0.3605 - val_loss: 1.0997 - val_acc: 0.3522\n",
            "Epoch 44/100 - 0.09s - loss: 1.0938 - acc: 0.3619 - val_loss: 1.0995 - val_acc: 0.3543\n",
            "Epoch 45/100 - 0.09s - loss: 1.0936 - acc: 0.3644 - val_loss: 1.0993 - val_acc: 0.3522\n",
            "Epoch 46/100 - 0.09s - loss: 1.0933 - acc: 0.3644 - val_loss: 1.0991 - val_acc: 0.3522\n",
            "Epoch 47/100 - 0.09s - loss: 1.0931 - acc: 0.3650 - val_loss: 1.0989 - val_acc: 0.3522\n",
            "Epoch 48/100 - 0.09s - loss: 1.0929 - acc: 0.3675 - val_loss: 1.0987 - val_acc: 0.3522\n",
            "Epoch 49/100 - 0.09s - loss: 1.0927 - acc: 0.3680 - val_loss: 1.0985 - val_acc: 0.3522\n",
            "Epoch 50/100 - 0.09s - loss: 1.0924 - acc: 0.3682 - val_loss: 1.0983 - val_acc: 0.3543\n",
            "Epoch 51/100 - 0.09s - loss: 1.0922 - acc: 0.3698 - val_loss: 1.0981 - val_acc: 0.3563\n",
            "Epoch 52/100 - 0.09s - loss: 1.0920 - acc: 0.3709 - val_loss: 1.0979 - val_acc: 0.3563\n",
            "Epoch 53/100 - 0.09s - loss: 1.0918 - acc: 0.3718 - val_loss: 1.0977 - val_acc: 0.3563\n",
            "Epoch 54/100 - 0.10s - loss: 1.0916 - acc: 0.3720 - val_loss: 1.0975 - val_acc: 0.3563\n",
            "Epoch 55/100 - 0.09s - loss: 1.0913 - acc: 0.3720 - val_loss: 1.0973 - val_acc: 0.3563\n",
            "Epoch 56/100 - 0.09s - loss: 1.0911 - acc: 0.3725 - val_loss: 1.0971 - val_acc: 0.3563\n",
            "Epoch 57/100 - 0.09s - loss: 1.0909 - acc: 0.3745 - val_loss: 1.0969 - val_acc: 0.3583\n",
            "Epoch 58/100 - 0.09s - loss: 1.0907 - acc: 0.3761 - val_loss: 1.0968 - val_acc: 0.3623\n",
            "Epoch 59/100 - 0.09s - loss: 1.0905 - acc: 0.3770 - val_loss: 1.0966 - val_acc: 0.3623\n",
            "Epoch 60/100 - 0.09s - loss: 1.0903 - acc: 0.3776 - val_loss: 1.0964 - val_acc: 0.3644\n",
            "Epoch 61/100 - 0.09s - loss: 1.0900 - acc: 0.3788 - val_loss: 1.0962 - val_acc: 0.3684\n",
            "Epoch 62/100 - 0.09s - loss: 1.0898 - acc: 0.3783 - val_loss: 1.0960 - val_acc: 0.3644\n",
            "Epoch 63/100 - 0.09s - loss: 1.0896 - acc: 0.3785 - val_loss: 1.0958 - val_acc: 0.3644\n",
            "Epoch 64/100 - 0.09s - loss: 1.0894 - acc: 0.3797 - val_loss: 1.0957 - val_acc: 0.3623\n",
            "Epoch 65/100 - 0.09s - loss: 1.0892 - acc: 0.3817 - val_loss: 1.0955 - val_acc: 0.3623\n",
            "Epoch 66/100 - 0.10s - loss: 1.0890 - acc: 0.3830 - val_loss: 1.0953 - val_acc: 0.3623\n",
            "Epoch 67/100 - 0.09s - loss: 1.0888 - acc: 0.3846 - val_loss: 1.0951 - val_acc: 0.3583\n",
            "Epoch 68/100 - 0.09s - loss: 1.0886 - acc: 0.3864 - val_loss: 1.0949 - val_acc: 0.3603\n",
            "Epoch 69/100 - 0.09s - loss: 1.0884 - acc: 0.3857 - val_loss: 1.0947 - val_acc: 0.3563\n",
            "Epoch 70/100 - 0.09s - loss: 1.0882 - acc: 0.3864 - val_loss: 1.0946 - val_acc: 0.3603\n",
            "Epoch 71/100 - 0.09s - loss: 1.0880 - acc: 0.3878 - val_loss: 1.0944 - val_acc: 0.3623\n",
            "Epoch 72/100 - 0.09s - loss: 1.0878 - acc: 0.3884 - val_loss: 1.0942 - val_acc: 0.3623\n",
            "Epoch 73/100 - 0.09s - loss: 1.0876 - acc: 0.3887 - val_loss: 1.0941 - val_acc: 0.3623\n",
            "Epoch 74/100 - 0.09s - loss: 1.0874 - acc: 0.3896 - val_loss: 1.0939 - val_acc: 0.3623\n",
            "Epoch 75/100 - 0.09s - loss: 1.0872 - acc: 0.3893 - val_loss: 1.0937 - val_acc: 0.3603\n",
            "Epoch 76/100 - 0.09s - loss: 1.0870 - acc: 0.3898 - val_loss: 1.0935 - val_acc: 0.3603\n",
            "Epoch 77/100 - 0.09s - loss: 1.0868 - acc: 0.3916 - val_loss: 1.0934 - val_acc: 0.3623\n",
            "Epoch 78/100 - 0.09s - loss: 1.0866 - acc: 0.3918 - val_loss: 1.0932 - val_acc: 0.3664\n",
            "Epoch 79/100 - 0.09s - loss: 1.0864 - acc: 0.3936 - val_loss: 1.0930 - val_acc: 0.3725\n",
            "Epoch 80/100 - 0.09s - loss: 1.0862 - acc: 0.3947 - val_loss: 1.0929 - val_acc: 0.3765\n",
            "Epoch 81/100 - 0.09s - loss: 1.0860 - acc: 0.3945 - val_loss: 1.0927 - val_acc: 0.3765\n",
            "Epoch 82/100 - 0.09s - loss: 1.0858 - acc: 0.3947 - val_loss: 1.0925 - val_acc: 0.3785\n",
            "Epoch 83/100 - 0.09s - loss: 1.0856 - acc: 0.3965 - val_loss: 1.0924 - val_acc: 0.3806\n",
            "Epoch 84/100 - 0.09s - loss: 1.0855 - acc: 0.3968 - val_loss: 1.0922 - val_acc: 0.3785\n",
            "Epoch 85/100 - 0.09s - loss: 1.0853 - acc: 0.3974 - val_loss: 1.0921 - val_acc: 0.3785\n",
            "Epoch 86/100 - 0.09s - loss: 1.0851 - acc: 0.3977 - val_loss: 1.0919 - val_acc: 0.3765\n",
            "Epoch 87/100 - 0.09s - loss: 1.0849 - acc: 0.3983 - val_loss: 1.0917 - val_acc: 0.3785\n",
            "Epoch 88/100 - 0.09s - loss: 1.0847 - acc: 0.3999 - val_loss: 1.0916 - val_acc: 0.3806\n",
            "Epoch 89/100 - 0.09s - loss: 1.0845 - acc: 0.4006 - val_loss: 1.0914 - val_acc: 0.3785\n",
            "Epoch 90/100 - 0.10s - loss: 1.0843 - acc: 0.4015 - val_loss: 1.0913 - val_acc: 0.3785\n",
            "Epoch 91/100 - 0.09s - loss: 1.0842 - acc: 0.4022 - val_loss: 1.0911 - val_acc: 0.3846\n",
            "Epoch 92/100 - 0.09s - loss: 1.0840 - acc: 0.4024 - val_loss: 1.0909 - val_acc: 0.3826\n",
            "Epoch 93/100 - 0.09s - loss: 1.0838 - acc: 0.4035 - val_loss: 1.0908 - val_acc: 0.3866\n",
            "Epoch 94/100 - 0.09s - loss: 1.0836 - acc: 0.4040 - val_loss: 1.0906 - val_acc: 0.3866\n",
            "Epoch 95/100 - 0.09s - loss: 1.0834 - acc: 0.4037 - val_loss: 1.0905 - val_acc: 0.3907\n",
            "Epoch 96/100 - 0.09s - loss: 1.0833 - acc: 0.4033 - val_loss: 1.0903 - val_acc: 0.3907\n",
            "Epoch 97/100 - 0.09s - loss: 1.0831 - acc: 0.4051 - val_loss: 1.0902 - val_acc: 0.3907\n",
            "Epoch 98/100 - 0.09s - loss: 1.0829 - acc: 0.4060 - val_loss: 1.0900 - val_acc: 0.3927\n",
            "Epoch 99/100 - 0.09s - loss: 1.0827 - acc: 0.4064 - val_loss: 1.0899 - val_acc: 0.3927\n",
            "Epoch 100/100 - 0.09s - loss: 1.0826 - acc: 0.4062 - val_loss: 1.0897 - val_acc: 0.3927\n",
            "\n",
            "Combination 69/252:\n",
            "Hidden Layers: [128, 64], Activation: tanh, Learning Rate: 0.0001, Batch Size: 32, Epochs: 150\n",
            "Epoch 1/150 - 0.09s - loss: 1.1169 - acc: 0.3297 - val_loss: 1.1125 - val_acc: 0.3219\n",
            "Epoch 2/150 - 0.09s - loss: 1.1140 - acc: 0.3302 - val_loss: 1.1102 - val_acc: 0.3300\n",
            "Epoch 3/150 - 0.09s - loss: 1.1116 - acc: 0.3309 - val_loss: 1.1083 - val_acc: 0.3462\n",
            "Epoch 4/150 - 0.09s - loss: 1.1095 - acc: 0.3360 - val_loss: 1.1067 - val_acc: 0.3462\n",
            "Epoch 5/150 - 0.09s - loss: 1.1077 - acc: 0.3378 - val_loss: 1.1054 - val_acc: 0.3543\n",
            "Epoch 6/150 - 0.09s - loss: 1.1062 - acc: 0.3428 - val_loss: 1.1043 - val_acc: 0.3482\n",
            "Epoch 7/150 - 0.09s - loss: 1.1049 - acc: 0.3455 - val_loss: 1.1034 - val_acc: 0.3502\n",
            "Epoch 8/150 - 0.09s - loss: 1.1038 - acc: 0.3498 - val_loss: 1.1026 - val_acc: 0.3441\n",
            "Epoch 9/150 - 0.09s - loss: 1.1028 - acc: 0.3509 - val_loss: 1.1019 - val_acc: 0.3583\n",
            "Epoch 10/150 - 0.09s - loss: 1.1020 - acc: 0.3466 - val_loss: 1.1014 - val_acc: 0.3482\n",
            "Epoch 11/150 - 0.09s - loss: 1.1013 - acc: 0.3466 - val_loss: 1.1009 - val_acc: 0.3563\n",
            "Epoch 12/150 - 0.09s - loss: 1.1006 - acc: 0.3482 - val_loss: 1.1005 - val_acc: 0.3684\n",
            "Epoch 13/150 - 0.09s - loss: 1.1000 - acc: 0.3516 - val_loss: 1.1001 - val_acc: 0.3623\n",
            "Epoch 14/150 - 0.11s - loss: 1.0995 - acc: 0.3518 - val_loss: 1.0998 - val_acc: 0.3583\n",
            "Epoch 15/150 - 0.10s - loss: 1.0991 - acc: 0.3527 - val_loss: 1.0996 - val_acc: 0.3522\n",
            "Epoch 16/150 - 0.09s - loss: 1.0986 - acc: 0.3549 - val_loss: 1.0993 - val_acc: 0.3563\n",
            "Epoch 17/150 - 0.09s - loss: 1.0983 - acc: 0.3567 - val_loss: 1.0991 - val_acc: 0.3543\n",
            "Epoch 18/150 - 0.09s - loss: 1.0979 - acc: 0.3576 - val_loss: 1.0989 - val_acc: 0.3522\n",
            "Epoch 19/150 - 0.09s - loss: 1.0976 - acc: 0.3599 - val_loss: 1.0987 - val_acc: 0.3583\n",
            "Epoch 20/150 - 0.09s - loss: 1.0973 - acc: 0.3623 - val_loss: 1.0985 - val_acc: 0.3543\n",
            "Epoch 21/150 - 0.09s - loss: 1.0970 - acc: 0.3648 - val_loss: 1.0983 - val_acc: 0.3502\n",
            "Epoch 22/150 - 0.09s - loss: 1.0967 - acc: 0.3666 - val_loss: 1.0982 - val_acc: 0.3462\n",
            "Epoch 23/150 - 0.09s - loss: 1.0964 - acc: 0.3662 - val_loss: 1.0980 - val_acc: 0.3522\n",
            "Epoch 24/150 - 0.09s - loss: 1.0962 - acc: 0.3666 - val_loss: 1.0979 - val_acc: 0.3502\n",
            "Epoch 25/150 - 0.09s - loss: 1.0959 - acc: 0.3662 - val_loss: 1.0977 - val_acc: 0.3502\n",
            "Epoch 26/150 - 0.10s - loss: 1.0957 - acc: 0.3664 - val_loss: 1.0975 - val_acc: 0.3522\n",
            "Epoch 27/150 - 0.09s - loss: 1.0955 - acc: 0.3689 - val_loss: 1.0974 - val_acc: 0.3563\n",
            "Epoch 28/150 - 0.09s - loss: 1.0953 - acc: 0.3684 - val_loss: 1.0972 - val_acc: 0.3502\n",
            "Epoch 29/150 - 0.09s - loss: 1.0950 - acc: 0.3689 - val_loss: 1.0971 - val_acc: 0.3522\n",
            "Epoch 30/150 - 0.10s - loss: 1.0948 - acc: 0.3698 - val_loss: 1.0969 - val_acc: 0.3522\n",
            "Epoch 31/150 - 0.09s - loss: 1.0946 - acc: 0.3707 - val_loss: 1.0968 - val_acc: 0.3522\n",
            "Epoch 32/150 - 0.10s - loss: 1.0944 - acc: 0.3709 - val_loss: 1.0966 - val_acc: 0.3563\n",
            "Epoch 33/150 - 0.10s - loss: 1.0942 - acc: 0.3709 - val_loss: 1.0965 - val_acc: 0.3543\n",
            "Epoch 34/150 - 0.10s - loss: 1.0940 - acc: 0.3736 - val_loss: 1.0963 - val_acc: 0.3543\n",
            "Epoch 35/150 - 0.10s - loss: 1.0938 - acc: 0.3738 - val_loss: 1.0962 - val_acc: 0.3563\n",
            "Epoch 36/150 - 0.09s - loss: 1.0936 - acc: 0.3747 - val_loss: 1.0960 - val_acc: 0.3563\n",
            "Epoch 37/150 - 0.09s - loss: 1.0934 - acc: 0.3752 - val_loss: 1.0959 - val_acc: 0.3563\n",
            "Epoch 38/150 - 0.10s - loss: 1.0932 - acc: 0.3763 - val_loss: 1.0957 - val_acc: 0.3563\n",
            "Epoch 39/150 - 0.09s - loss: 1.0930 - acc: 0.3781 - val_loss: 1.0956 - val_acc: 0.3543\n",
            "Epoch 40/150 - 0.09s - loss: 1.0928 - acc: 0.3794 - val_loss: 1.0954 - val_acc: 0.3543\n",
            "Epoch 41/150 - 0.09s - loss: 1.0926 - acc: 0.3797 - val_loss: 1.0953 - val_acc: 0.3603\n",
            "Epoch 42/150 - 0.09s - loss: 1.0924 - acc: 0.3792 - val_loss: 1.0951 - val_acc: 0.3603\n",
            "Epoch 43/150 - 0.09s - loss: 1.0922 - acc: 0.3788 - val_loss: 1.0950 - val_acc: 0.3603\n",
            "Epoch 44/150 - 0.10s - loss: 1.0920 - acc: 0.3788 - val_loss: 1.0948 - val_acc: 0.3603\n",
            "Epoch 45/150 - 0.09s - loss: 1.0918 - acc: 0.3799 - val_loss: 1.0947 - val_acc: 0.3603\n",
            "Epoch 46/150 - 0.10s - loss: 1.0916 - acc: 0.3799 - val_loss: 1.0945 - val_acc: 0.3583\n",
            "Epoch 47/150 - 0.10s - loss: 1.0915 - acc: 0.3810 - val_loss: 1.0944 - val_acc: 0.3583\n",
            "Epoch 48/150 - 0.10s - loss: 1.0913 - acc: 0.3815 - val_loss: 1.0942 - val_acc: 0.3583\n",
            "Epoch 49/150 - 0.10s - loss: 1.0911 - acc: 0.3826 - val_loss: 1.0941 - val_acc: 0.3583\n",
            "Epoch 50/150 - 0.10s - loss: 1.0909 - acc: 0.3828 - val_loss: 1.0939 - val_acc: 0.3583\n",
            "Epoch 51/150 - 0.09s - loss: 1.0907 - acc: 0.3824 - val_loss: 1.0938 - val_acc: 0.3583\n",
            "Epoch 52/150 - 0.09s - loss: 1.0905 - acc: 0.3821 - val_loss: 1.0936 - val_acc: 0.3583\n",
            "Epoch 53/150 - 0.09s - loss: 1.0904 - acc: 0.3828 - val_loss: 1.0935 - val_acc: 0.3583\n",
            "Epoch 54/150 - 0.09s - loss: 1.0902 - acc: 0.3835 - val_loss: 1.0933 - val_acc: 0.3603\n",
            "Epoch 55/150 - 0.09s - loss: 1.0900 - acc: 0.3837 - val_loss: 1.0932 - val_acc: 0.3583\n",
            "Epoch 56/150 - 0.11s - loss: 1.0898 - acc: 0.3844 - val_loss: 1.0930 - val_acc: 0.3543\n",
            "Epoch 57/150 - 0.12s - loss: 1.0896 - acc: 0.3848 - val_loss: 1.0929 - val_acc: 0.3543\n",
            "Epoch 58/150 - 0.10s - loss: 1.0895 - acc: 0.3857 - val_loss: 1.0927 - val_acc: 0.3563\n",
            "Epoch 59/150 - 0.10s - loss: 1.0893 - acc: 0.3848 - val_loss: 1.0926 - val_acc: 0.3563\n",
            "Epoch 60/150 - 0.09s - loss: 1.0891 - acc: 0.3848 - val_loss: 1.0925 - val_acc: 0.3603\n",
            "Epoch 61/150 - 0.10s - loss: 1.0889 - acc: 0.3853 - val_loss: 1.0923 - val_acc: 0.3603\n",
            "Epoch 62/150 - 0.10s - loss: 1.0888 - acc: 0.3864 - val_loss: 1.0922 - val_acc: 0.3623\n",
            "Epoch 63/150 - 0.10s - loss: 1.0886 - acc: 0.3862 - val_loss: 1.0920 - val_acc: 0.3644\n",
            "Epoch 64/150 - 0.09s - loss: 1.0884 - acc: 0.3866 - val_loss: 1.0919 - val_acc: 0.3644\n",
            "Epoch 65/150 - 0.09s - loss: 1.0882 - acc: 0.3882 - val_loss: 1.0917 - val_acc: 0.3644\n",
            "Epoch 66/150 - 0.09s - loss: 1.0881 - acc: 0.3889 - val_loss: 1.0916 - val_acc: 0.3644\n",
            "Epoch 67/150 - 0.12s - loss: 1.0879 - acc: 0.3889 - val_loss: 1.0915 - val_acc: 0.3664\n",
            "Epoch 68/150 - 0.12s - loss: 1.0877 - acc: 0.3893 - val_loss: 1.0913 - val_acc: 0.3664\n",
            "Epoch 69/150 - 0.12s - loss: 1.0876 - acc: 0.3902 - val_loss: 1.0912 - val_acc: 0.3684\n",
            "Epoch 70/150 - 0.10s - loss: 1.0874 - acc: 0.3900 - val_loss: 1.0910 - val_acc: 0.3664\n",
            "Epoch 71/150 - 0.10s - loss: 1.0872 - acc: 0.3907 - val_loss: 1.0909 - val_acc: 0.3664\n",
            "Epoch 72/150 - 0.10s - loss: 1.0871 - acc: 0.3914 - val_loss: 1.0908 - val_acc: 0.3664\n",
            "Epoch 73/150 - 0.09s - loss: 1.0869 - acc: 0.3918 - val_loss: 1.0906 - val_acc: 0.3684\n",
            "Epoch 74/150 - 0.09s - loss: 1.0867 - acc: 0.3916 - val_loss: 1.0905 - val_acc: 0.3684\n",
            "Epoch 75/150 - 0.12s - loss: 1.0866 - acc: 0.3916 - val_loss: 1.0904 - val_acc: 0.3704\n",
            "Epoch 76/150 - 0.12s - loss: 1.0864 - acc: 0.3918 - val_loss: 1.0902 - val_acc: 0.3684\n",
            "Epoch 77/150 - 0.10s - loss: 1.0862 - acc: 0.3932 - val_loss: 1.0901 - val_acc: 0.3684\n",
            "Epoch 78/150 - 0.11s - loss: 1.0861 - acc: 0.3938 - val_loss: 1.0900 - val_acc: 0.3664\n",
            "Epoch 79/150 - 0.10s - loss: 1.0859 - acc: 0.3938 - val_loss: 1.0898 - val_acc: 0.3664\n",
            "Epoch 80/150 - 0.10s - loss: 1.0858 - acc: 0.3943 - val_loss: 1.0897 - val_acc: 0.3644\n",
            "Epoch 81/150 - 0.09s - loss: 1.0856 - acc: 0.3954 - val_loss: 1.0896 - val_acc: 0.3644\n",
            "Epoch 82/150 - 0.10s - loss: 1.0854 - acc: 0.3961 - val_loss: 1.0894 - val_acc: 0.3684\n",
            "Epoch 83/150 - 0.09s - loss: 1.0853 - acc: 0.3963 - val_loss: 1.0893 - val_acc: 0.3684\n",
            "Epoch 84/150 - 0.14s - loss: 1.0851 - acc: 0.3968 - val_loss: 1.0892 - val_acc: 0.3684\n",
            "Epoch 85/150 - 0.13s - loss: 1.0850 - acc: 0.3979 - val_loss: 1.0891 - val_acc: 0.3684\n",
            "Epoch 86/150 - 0.12s - loss: 1.0848 - acc: 0.3983 - val_loss: 1.0889 - val_acc: 0.3684\n",
            "Epoch 87/150 - 0.09s - loss: 1.0847 - acc: 0.3986 - val_loss: 1.0888 - val_acc: 0.3684\n",
            "Epoch 88/150 - 0.09s - loss: 1.0845 - acc: 0.3992 - val_loss: 1.0887 - val_acc: 0.3684\n",
            "Epoch 89/150 - 0.09s - loss: 1.0843 - acc: 0.3992 - val_loss: 1.0886 - val_acc: 0.3704\n",
            "Epoch 90/150 - 0.09s - loss: 1.0842 - acc: 0.4001 - val_loss: 1.0884 - val_acc: 0.3765\n",
            "Epoch 91/150 - 0.09s - loss: 1.0840 - acc: 0.4010 - val_loss: 1.0883 - val_acc: 0.3765\n",
            "Epoch 92/150 - 0.09s - loss: 1.0839 - acc: 0.4015 - val_loss: 1.0882 - val_acc: 0.3765\n",
            "Epoch 93/150 - 0.09s - loss: 1.0837 - acc: 0.4019 - val_loss: 1.0880 - val_acc: 0.3725\n",
            "Epoch 94/150 - 0.09s - loss: 1.0836 - acc: 0.4026 - val_loss: 1.0879 - val_acc: 0.3765\n",
            "Epoch 95/150 - 0.09s - loss: 1.0834 - acc: 0.4033 - val_loss: 1.0878 - val_acc: 0.3785\n",
            "Epoch 96/150 - 0.09s - loss: 1.0833 - acc: 0.4033 - val_loss: 1.0877 - val_acc: 0.3785\n",
            "Epoch 97/150 - 0.09s - loss: 1.0831 - acc: 0.4046 - val_loss: 1.0876 - val_acc: 0.3765\n",
            "Epoch 98/150 - 0.09s - loss: 1.0830 - acc: 0.4051 - val_loss: 1.0874 - val_acc: 0.3765\n",
            "Epoch 99/150 - 0.09s - loss: 1.0828 - acc: 0.4055 - val_loss: 1.0873 - val_acc: 0.3765\n",
            "Epoch 100/150 - 0.09s - loss: 1.0827 - acc: 0.4055 - val_loss: 1.0872 - val_acc: 0.3765\n",
            "Epoch 101/150 - 0.09s - loss: 1.0825 - acc: 0.4051 - val_loss: 1.0871 - val_acc: 0.3765\n",
            "Epoch 102/150 - 0.10s - loss: 1.0824 - acc: 0.4058 - val_loss: 1.0870 - val_acc: 0.3765\n",
            "Epoch 103/150 - 0.09s - loss: 1.0822 - acc: 0.4071 - val_loss: 1.0868 - val_acc: 0.3765\n",
            "Epoch 104/150 - 0.09s - loss: 1.0821 - acc: 0.4080 - val_loss: 1.0867 - val_acc: 0.3785\n",
            "Epoch 105/150 - 0.09s - loss: 1.0820 - acc: 0.4082 - val_loss: 1.0866 - val_acc: 0.3806\n",
            "Epoch 106/150 - 0.09s - loss: 1.0818 - acc: 0.4080 - val_loss: 1.0865 - val_acc: 0.3806\n",
            "Epoch 107/150 - 0.09s - loss: 1.0817 - acc: 0.4096 - val_loss: 1.0864 - val_acc: 0.3826\n",
            "Epoch 108/150 - 0.09s - loss: 1.0815 - acc: 0.4098 - val_loss: 1.0863 - val_acc: 0.3826\n",
            "Epoch 109/150 - 0.09s - loss: 1.0814 - acc: 0.4107 - val_loss: 1.0861 - val_acc: 0.3846\n",
            "Epoch 110/150 - 0.09s - loss: 1.0812 - acc: 0.4116 - val_loss: 1.0860 - val_acc: 0.3846\n",
            "Epoch 111/150 - 0.09s - loss: 1.0811 - acc: 0.4118 - val_loss: 1.0859 - val_acc: 0.3826\n",
            "Epoch 112/150 - 0.09s - loss: 1.0810 - acc: 0.4125 - val_loss: 1.0858 - val_acc: 0.3826\n",
            "Epoch 113/150 - 0.09s - loss: 1.0808 - acc: 0.4136 - val_loss: 1.0857 - val_acc: 0.3846\n",
            "Epoch 114/150 - 0.09s - loss: 1.0807 - acc: 0.4139 - val_loss: 1.0856 - val_acc: 0.3866\n",
            "Epoch 115/150 - 0.09s - loss: 1.0805 - acc: 0.4152 - val_loss: 1.0855 - val_acc: 0.3887\n",
            "Epoch 116/150 - 0.09s - loss: 1.0804 - acc: 0.4161 - val_loss: 1.0854 - val_acc: 0.3927\n",
            "Epoch 117/150 - 0.09s - loss: 1.0803 - acc: 0.4157 - val_loss: 1.0852 - val_acc: 0.3927\n",
            "Epoch 118/150 - 0.08s - loss: 1.0801 - acc: 0.4163 - val_loss: 1.0851 - val_acc: 0.3968\n",
            "Epoch 119/150 - 0.09s - loss: 1.0800 - acc: 0.4170 - val_loss: 1.0850 - val_acc: 0.3988\n",
            "Epoch 120/150 - 0.09s - loss: 1.0798 - acc: 0.4168 - val_loss: 1.0849 - val_acc: 0.3988\n",
            "Epoch 121/150 - 0.09s - loss: 1.0797 - acc: 0.4175 - val_loss: 1.0848 - val_acc: 0.4008\n",
            "Epoch 122/150 - 0.09s - loss: 1.0796 - acc: 0.4175 - val_loss: 1.0847 - val_acc: 0.3988\n",
            "Epoch 123/150 - 0.09s - loss: 1.0794 - acc: 0.4179 - val_loss: 1.0846 - val_acc: 0.3968\n",
            "Epoch 124/150 - 0.09s - loss: 1.0793 - acc: 0.4186 - val_loss: 1.0845 - val_acc: 0.3947\n",
            "Epoch 125/150 - 0.09s - loss: 1.0792 - acc: 0.4193 - val_loss: 1.0844 - val_acc: 0.3968\n",
            "Epoch 126/150 - 0.09s - loss: 1.0790 - acc: 0.4197 - val_loss: 1.0843 - val_acc: 0.3968\n",
            "Epoch 127/150 - 0.09s - loss: 1.0789 - acc: 0.4204 - val_loss: 1.0842 - val_acc: 0.3927\n",
            "Epoch 128/150 - 0.09s - loss: 1.0788 - acc: 0.4206 - val_loss: 1.0840 - val_acc: 0.3907\n",
            "Epoch 129/150 - 0.09s - loss: 1.0786 - acc: 0.4213 - val_loss: 1.0839 - val_acc: 0.3907\n",
            "Epoch 130/150 - 0.09s - loss: 1.0785 - acc: 0.4220 - val_loss: 1.0838 - val_acc: 0.3907\n",
            "Epoch 131/150 - 0.09s - loss: 1.0784 - acc: 0.4222 - val_loss: 1.0837 - val_acc: 0.3907\n",
            "Epoch 132/150 - 0.09s - loss: 1.0782 - acc: 0.4220 - val_loss: 1.0836 - val_acc: 0.3907\n",
            "Epoch 133/150 - 0.09s - loss: 1.0781 - acc: 0.4213 - val_loss: 1.0835 - val_acc: 0.3907\n",
            "Epoch 134/150 - 0.09s - loss: 1.0780 - acc: 0.4215 - val_loss: 1.0834 - val_acc: 0.3887\n",
            "Epoch 135/150 - 0.09s - loss: 1.0778 - acc: 0.4224 - val_loss: 1.0833 - val_acc: 0.3866\n",
            "Epoch 136/150 - 0.08s - loss: 1.0777 - acc: 0.4222 - val_loss: 1.0832 - val_acc: 0.3866\n",
            "Epoch 137/150 - 0.09s - loss: 1.0776 - acc: 0.4231 - val_loss: 1.0831 - val_acc: 0.3866\n",
            "Epoch 138/150 - 0.09s - loss: 1.0774 - acc: 0.4231 - val_loss: 1.0830 - val_acc: 0.3887\n",
            "Epoch 139/150 - 0.09s - loss: 1.0773 - acc: 0.4220 - val_loss: 1.0829 - val_acc: 0.3907\n",
            "Epoch 140/150 - 0.09s - loss: 1.0772 - acc: 0.4233 - val_loss: 1.0828 - val_acc: 0.3927\n",
            "Epoch 141/150 - 0.08s - loss: 1.0771 - acc: 0.4233 - val_loss: 1.0827 - val_acc: 0.3927\n",
            "Epoch 142/150 - 0.09s - loss: 1.0769 - acc: 0.4238 - val_loss: 1.0826 - val_acc: 0.3927\n",
            "Epoch 143/150 - 0.09s - loss: 1.0768 - acc: 0.4242 - val_loss: 1.0825 - val_acc: 0.3947\n",
            "Epoch 144/150 - 0.09s - loss: 1.0767 - acc: 0.4249 - val_loss: 1.0824 - val_acc: 0.3927\n",
            "Epoch 145/150 - 0.09s - loss: 1.0766 - acc: 0.4262 - val_loss: 1.0823 - val_acc: 0.3947\n",
            "Epoch 146/150 - 0.09s - loss: 1.0764 - acc: 0.4265 - val_loss: 1.0822 - val_acc: 0.3968\n",
            "Epoch 147/150 - 0.09s - loss: 1.0763 - acc: 0.4267 - val_loss: 1.0821 - val_acc: 0.3968\n",
            "Epoch 148/150 - 0.09s - loss: 1.0762 - acc: 0.4274 - val_loss: 1.0820 - val_acc: 0.3968\n",
            "Epoch 149/150 - 0.09s - loss: 1.0760 - acc: 0.4278 - val_loss: 1.0819 - val_acc: 0.3988\n",
            "Epoch 150/150 - 0.09s - loss: 1.0759 - acc: 0.4283 - val_loss: 1.0818 - val_acc: 0.3988\n",
            "\n",
            "Combination 70/252:\n",
            "Hidden Layers: [128, 64], Activation: tanh, Learning Rate: 0.0001, Batch Size: 64, Epochs: 50\n",
            "Epoch 1/50 - 0.08s - loss: 1.1103 - acc: 0.3135 - val_loss: 1.1123 - val_acc: 0.3138\n",
            "Epoch 2/50 - 0.09s - loss: 1.1098 - acc: 0.3138 - val_loss: 1.1118 - val_acc: 0.3178\n",
            "Epoch 3/50 - 0.09s - loss: 1.1095 - acc: 0.3120 - val_loss: 1.1113 - val_acc: 0.3117\n",
            "Epoch 4/50 - 0.08s - loss: 1.1091 - acc: 0.3131 - val_loss: 1.1109 - val_acc: 0.3117\n",
            "Epoch 5/50 - 0.08s - loss: 1.1087 - acc: 0.3133 - val_loss: 1.1104 - val_acc: 0.3158\n",
            "Epoch 6/50 - 0.08s - loss: 1.1084 - acc: 0.3115 - val_loss: 1.1100 - val_acc: 0.3158\n",
            "Epoch 7/50 - 0.08s - loss: 1.1081 - acc: 0.3102 - val_loss: 1.1097 - val_acc: 0.3198\n",
            "Epoch 8/50 - 0.11s - loss: 1.1078 - acc: 0.3115 - val_loss: 1.1093 - val_acc: 0.3198\n",
            "Epoch 9/50 - 0.08s - loss: 1.1075 - acc: 0.3117 - val_loss: 1.1090 - val_acc: 0.3178\n",
            "Epoch 10/50 - 0.08s - loss: 1.1072 - acc: 0.3106 - val_loss: 1.1087 - val_acc: 0.3219\n",
            "Epoch 11/50 - 0.08s - loss: 1.1070 - acc: 0.3113 - val_loss: 1.1084 - val_acc: 0.3219\n",
            "Epoch 12/50 - 0.08s - loss: 1.1067 - acc: 0.3095 - val_loss: 1.1081 - val_acc: 0.3239\n",
            "Epoch 13/50 - 0.08s - loss: 1.1065 - acc: 0.3072 - val_loss: 1.1078 - val_acc: 0.3259\n",
            "Epoch 14/50 - 0.08s - loss: 1.1063 - acc: 0.3063 - val_loss: 1.1075 - val_acc: 0.3320\n",
            "Epoch 15/50 - 0.08s - loss: 1.1061 - acc: 0.3052 - val_loss: 1.1073 - val_acc: 0.3279\n",
            "Epoch 16/50 - 0.08s - loss: 1.1059 - acc: 0.3039 - val_loss: 1.1070 - val_acc: 0.3259\n",
            "Epoch 17/50 - 0.08s - loss: 1.1057 - acc: 0.3041 - val_loss: 1.1068 - val_acc: 0.3279\n",
            "Epoch 18/50 - 0.08s - loss: 1.1055 - acc: 0.3036 - val_loss: 1.1066 - val_acc: 0.3279\n",
            "Epoch 19/50 - 0.08s - loss: 1.1053 - acc: 0.3009 - val_loss: 1.1064 - val_acc: 0.3300\n",
            "Epoch 20/50 - 0.08s - loss: 1.1051 - acc: 0.3025 - val_loss: 1.1062 - val_acc: 0.3300\n",
            "Epoch 21/50 - 0.08s - loss: 1.1049 - acc: 0.3016 - val_loss: 1.1060 - val_acc: 0.3300\n",
            "Epoch 22/50 - 0.08s - loss: 1.1048 - acc: 0.3048 - val_loss: 1.1058 - val_acc: 0.3279\n",
            "Epoch 23/50 - 0.08s - loss: 1.1046 - acc: 0.3045 - val_loss: 1.1056 - val_acc: 0.3239\n",
            "Epoch 24/50 - 0.09s - loss: 1.1045 - acc: 0.3063 - val_loss: 1.1054 - val_acc: 0.3178\n",
            "Epoch 25/50 - 0.11s - loss: 1.1043 - acc: 0.3061 - val_loss: 1.1053 - val_acc: 0.3178\n",
            "Epoch 26/50 - 0.11s - loss: 1.1042 - acc: 0.3070 - val_loss: 1.1051 - val_acc: 0.3198\n",
            "Epoch 27/50 - 0.09s - loss: 1.1040 - acc: 0.3057 - val_loss: 1.1049 - val_acc: 0.3198\n",
            "Epoch 28/50 - 0.08s - loss: 1.1039 - acc: 0.3052 - val_loss: 1.1048 - val_acc: 0.3117\n",
            "Epoch 29/50 - 0.08s - loss: 1.1038 - acc: 0.3059 - val_loss: 1.1046 - val_acc: 0.3097\n",
            "Epoch 30/50 - 0.08s - loss: 1.1036 - acc: 0.3077 - val_loss: 1.1045 - val_acc: 0.3097\n",
            "Epoch 31/50 - 0.08s - loss: 1.1035 - acc: 0.3079 - val_loss: 1.1044 - val_acc: 0.3077\n",
            "Epoch 32/50 - 0.08s - loss: 1.1034 - acc: 0.3081 - val_loss: 1.1042 - val_acc: 0.3117\n",
            "Epoch 33/50 - 0.07s - loss: 1.1032 - acc: 0.3066 - val_loss: 1.1041 - val_acc: 0.3138\n",
            "Epoch 34/50 - 0.08s - loss: 1.1031 - acc: 0.3081 - val_loss: 1.1039 - val_acc: 0.3158\n",
            "Epoch 35/50 - 0.07s - loss: 1.1030 - acc: 0.3077 - val_loss: 1.1038 - val_acc: 0.3219\n",
            "Epoch 36/50 - 0.08s - loss: 1.1029 - acc: 0.3086 - val_loss: 1.1037 - val_acc: 0.3198\n",
            "Epoch 37/50 - 0.07s - loss: 1.1027 - acc: 0.3090 - val_loss: 1.1036 - val_acc: 0.3178\n",
            "Epoch 38/50 - 0.08s - loss: 1.1026 - acc: 0.3104 - val_loss: 1.1035 - val_acc: 0.3178\n",
            "Epoch 39/50 - 0.08s - loss: 1.1025 - acc: 0.3117 - val_loss: 1.1033 - val_acc: 0.3178\n",
            "Epoch 40/50 - 0.08s - loss: 1.1024 - acc: 0.3122 - val_loss: 1.1032 - val_acc: 0.3178\n",
            "Epoch 41/50 - 0.07s - loss: 1.1023 - acc: 0.3133 - val_loss: 1.1031 - val_acc: 0.3158\n",
            "Epoch 42/50 - 0.08s - loss: 1.1022 - acc: 0.3142 - val_loss: 1.1030 - val_acc: 0.3077\n",
            "Epoch 43/50 - 0.07s - loss: 1.1021 - acc: 0.3162 - val_loss: 1.1029 - val_acc: 0.3097\n",
            "Epoch 44/50 - 0.07s - loss: 1.1020 - acc: 0.3160 - val_loss: 1.1028 - val_acc: 0.3077\n",
            "Epoch 45/50 - 0.10s - loss: 1.1018 - acc: 0.3165 - val_loss: 1.1027 - val_acc: 0.3057\n",
            "Epoch 46/50 - 0.08s - loss: 1.1017 - acc: 0.3160 - val_loss: 1.1026 - val_acc: 0.3036\n",
            "Epoch 47/50 - 0.08s - loss: 1.1016 - acc: 0.3176 - val_loss: 1.1024 - val_acc: 0.2996\n",
            "Epoch 48/50 - 0.08s - loss: 1.1015 - acc: 0.3176 - val_loss: 1.1023 - val_acc: 0.2996\n",
            "Epoch 49/50 - 0.07s - loss: 1.1014 - acc: 0.3171 - val_loss: 1.1022 - val_acc: 0.3016\n",
            "Epoch 50/50 - 0.08s - loss: 1.1013 - acc: 0.3176 - val_loss: 1.1021 - val_acc: 0.3016\n",
            "\n",
            "Combination 71/252:\n",
            "Hidden Layers: [128, 64], Activation: tanh, Learning Rate: 0.0001, Batch Size: 64, Epochs: 100\n",
            "Epoch 1/100 - 0.08s - loss: 1.1121 - acc: 0.3259 - val_loss: 1.1120 - val_acc: 0.3360\n",
            "Epoch 2/100 - 0.07s - loss: 1.1118 - acc: 0.3268 - val_loss: 1.1118 - val_acc: 0.3360\n",
            "Epoch 3/100 - 0.08s - loss: 1.1114 - acc: 0.3248 - val_loss: 1.1116 - val_acc: 0.3340\n",
            "Epoch 4/100 - 0.09s - loss: 1.1111 - acc: 0.3250 - val_loss: 1.1113 - val_acc: 0.3401\n",
            "Epoch 5/100 - 0.07s - loss: 1.1108 - acc: 0.3239 - val_loss: 1.1111 - val_acc: 0.3401\n",
            "Epoch 6/100 - 0.08s - loss: 1.1105 - acc: 0.3250 - val_loss: 1.1109 - val_acc: 0.3401\n",
            "Epoch 7/100 - 0.09s - loss: 1.1102 - acc: 0.3243 - val_loss: 1.1108 - val_acc: 0.3441\n",
            "Epoch 8/100 - 0.09s - loss: 1.1099 - acc: 0.3237 - val_loss: 1.1106 - val_acc: 0.3421\n",
            "Epoch 9/100 - 0.08s - loss: 1.1097 - acc: 0.3241 - val_loss: 1.1104 - val_acc: 0.3421\n",
            "Epoch 10/100 - 0.08s - loss: 1.1094 - acc: 0.3252 - val_loss: 1.1103 - val_acc: 0.3401\n",
            "Epoch 11/100 - 0.08s - loss: 1.1092 - acc: 0.3246 - val_loss: 1.1101 - val_acc: 0.3401\n",
            "Epoch 12/100 - 0.08s - loss: 1.1089 - acc: 0.3257 - val_loss: 1.1100 - val_acc: 0.3421\n",
            "Epoch 13/100 - 0.08s - loss: 1.1087 - acc: 0.3248 - val_loss: 1.1099 - val_acc: 0.3340\n",
            "Epoch 14/100 - 0.08s - loss: 1.1085 - acc: 0.3252 - val_loss: 1.1097 - val_acc: 0.3340\n",
            "Epoch 15/100 - 0.08s - loss: 1.1083 - acc: 0.3246 - val_loss: 1.1096 - val_acc: 0.3300\n",
            "Epoch 16/100 - 0.08s - loss: 1.1081 - acc: 0.3261 - val_loss: 1.1095 - val_acc: 0.3239\n",
            "Epoch 17/100 - 0.08s - loss: 1.1079 - acc: 0.3270 - val_loss: 1.1094 - val_acc: 0.3239\n",
            "Epoch 18/100 - 0.07s - loss: 1.1077 - acc: 0.3273 - val_loss: 1.1092 - val_acc: 0.3259\n",
            "Epoch 19/100 - 0.08s - loss: 1.1075 - acc: 0.3264 - val_loss: 1.1091 - val_acc: 0.3259\n",
            "Epoch 20/100 - 0.07s - loss: 1.1073 - acc: 0.3266 - val_loss: 1.1090 - val_acc: 0.3219\n",
            "Epoch 21/100 - 0.07s - loss: 1.1071 - acc: 0.3270 - val_loss: 1.1089 - val_acc: 0.3239\n",
            "Epoch 22/100 - 0.08s - loss: 1.1070 - acc: 0.3255 - val_loss: 1.1088 - val_acc: 0.3219\n",
            "Epoch 23/100 - 0.08s - loss: 1.1068 - acc: 0.3246 - val_loss: 1.1087 - val_acc: 0.3178\n",
            "Epoch 24/100 - 0.07s - loss: 1.1067 - acc: 0.3234 - val_loss: 1.1086 - val_acc: 0.3138\n",
            "Epoch 25/100 - 0.08s - loss: 1.1065 - acc: 0.3219 - val_loss: 1.1086 - val_acc: 0.3158\n",
            "Epoch 26/100 - 0.07s - loss: 1.1063 - acc: 0.3219 - val_loss: 1.1085 - val_acc: 0.3117\n",
            "Epoch 27/100 - 0.07s - loss: 1.1062 - acc: 0.3210 - val_loss: 1.1084 - val_acc: 0.3097\n",
            "Epoch 28/100 - 0.08s - loss: 1.1060 - acc: 0.3210 - val_loss: 1.1083 - val_acc: 0.3077\n",
            "Epoch 29/100 - 0.07s - loss: 1.1059 - acc: 0.3214 - val_loss: 1.1082 - val_acc: 0.3077\n",
            "Epoch 30/100 - 0.07s - loss: 1.1058 - acc: 0.3214 - val_loss: 1.1081 - val_acc: 0.3077\n",
            "Epoch 31/100 - 0.09s - loss: 1.1056 - acc: 0.3228 - val_loss: 1.1081 - val_acc: 0.3097\n",
            "Epoch 32/100 - 0.09s - loss: 1.1055 - acc: 0.3232 - val_loss: 1.1080 - val_acc: 0.3097\n",
            "Epoch 33/100 - 0.08s - loss: 1.1054 - acc: 0.3219 - val_loss: 1.1079 - val_acc: 0.3117\n",
            "Epoch 34/100 - 0.08s - loss: 1.1052 - acc: 0.3228 - val_loss: 1.1078 - val_acc: 0.3097\n",
            "Epoch 35/100 - 0.07s - loss: 1.1051 - acc: 0.3234 - val_loss: 1.1077 - val_acc: 0.3036\n",
            "Epoch 36/100 - 0.07s - loss: 1.1050 - acc: 0.3216 - val_loss: 1.1077 - val_acc: 0.3016\n",
            "Epoch 37/100 - 0.08s - loss: 1.1048 - acc: 0.3210 - val_loss: 1.1076 - val_acc: 0.3036\n",
            "Epoch 38/100 - 0.08s - loss: 1.1047 - acc: 0.3216 - val_loss: 1.1075 - val_acc: 0.3077\n",
            "Epoch 39/100 - 0.08s - loss: 1.1046 - acc: 0.3214 - val_loss: 1.1075 - val_acc: 0.3036\n",
            "Epoch 40/100 - 0.07s - loss: 1.1045 - acc: 0.3214 - val_loss: 1.1074 - val_acc: 0.3016\n",
            "Epoch 41/100 - 0.08s - loss: 1.1044 - acc: 0.3214 - val_loss: 1.1073 - val_acc: 0.3057\n",
            "Epoch 42/100 - 0.09s - loss: 1.1042 - acc: 0.3216 - val_loss: 1.1072 - val_acc: 0.3036\n",
            "Epoch 43/100 - 0.08s - loss: 1.1041 - acc: 0.3210 - val_loss: 1.1072 - val_acc: 0.2996\n",
            "Epoch 44/100 - 0.08s - loss: 1.1040 - acc: 0.3212 - val_loss: 1.1071 - val_acc: 0.2996\n",
            "Epoch 45/100 - 0.08s - loss: 1.1039 - acc: 0.3216 - val_loss: 1.1070 - val_acc: 0.3016\n",
            "Epoch 46/100 - 0.08s - loss: 1.1038 - acc: 0.3212 - val_loss: 1.1070 - val_acc: 0.3016\n",
            "Epoch 47/100 - 0.08s - loss: 1.1037 - acc: 0.3210 - val_loss: 1.1069 - val_acc: 0.3016\n",
            "Epoch 48/100 - 0.07s - loss: 1.1036 - acc: 0.3207 - val_loss: 1.1068 - val_acc: 0.2996\n",
            "Epoch 49/100 - 0.08s - loss: 1.1035 - acc: 0.3221 - val_loss: 1.1068 - val_acc: 0.3016\n",
            "Epoch 50/100 - 0.07s - loss: 1.1034 - acc: 0.3214 - val_loss: 1.1067 - val_acc: 0.3097\n",
            "Epoch 51/100 - 0.07s - loss: 1.1033 - acc: 0.3225 - val_loss: 1.1066 - val_acc: 0.3097\n",
            "Epoch 52/100 - 0.08s - loss: 1.1032 - acc: 0.3225 - val_loss: 1.1066 - val_acc: 0.3097\n",
            "Epoch 53/100 - 0.07s - loss: 1.1030 - acc: 0.3228 - val_loss: 1.1065 - val_acc: 0.3097\n",
            "Epoch 54/100 - 0.08s - loss: 1.1029 - acc: 0.3221 - val_loss: 1.1064 - val_acc: 0.3117\n",
            "Epoch 55/100 - 0.09s - loss: 1.1028 - acc: 0.3225 - val_loss: 1.1064 - val_acc: 0.3097\n",
            "Epoch 56/100 - 0.07s - loss: 1.1027 - acc: 0.3230 - val_loss: 1.1063 - val_acc: 0.3097\n",
            "Epoch 57/100 - 0.08s - loss: 1.1026 - acc: 0.3230 - val_loss: 1.1062 - val_acc: 0.3097\n",
            "Epoch 58/100 - 0.08s - loss: 1.1025 - acc: 0.3232 - val_loss: 1.1062 - val_acc: 0.3077\n",
            "Epoch 59/100 - 0.07s - loss: 1.1024 - acc: 0.3232 - val_loss: 1.1061 - val_acc: 0.3097\n",
            "Epoch 60/100 - 0.08s - loss: 1.1023 - acc: 0.3241 - val_loss: 1.1060 - val_acc: 0.3097\n",
            "Epoch 61/100 - 0.08s - loss: 1.1022 - acc: 0.3248 - val_loss: 1.1060 - val_acc: 0.3077\n",
            "Epoch 62/100 - 0.07s - loss: 1.1021 - acc: 0.3248 - val_loss: 1.1059 - val_acc: 0.3016\n",
            "Epoch 63/100 - 0.07s - loss: 1.1020 - acc: 0.3257 - val_loss: 1.1058 - val_acc: 0.3077\n",
            "Epoch 64/100 - 0.07s - loss: 1.1019 - acc: 0.3255 - val_loss: 1.1058 - val_acc: 0.3097\n",
            "Epoch 65/100 - 0.07s - loss: 1.1018 - acc: 0.3259 - val_loss: 1.1057 - val_acc: 0.3097\n",
            "Epoch 66/100 - 0.07s - loss: 1.1017 - acc: 0.3261 - val_loss: 1.1056 - val_acc: 0.3097\n",
            "Epoch 67/100 - 0.08s - loss: 1.1016 - acc: 0.3255 - val_loss: 1.1056 - val_acc: 0.3097\n",
            "Epoch 68/100 - 0.07s - loss: 1.1016 - acc: 0.3266 - val_loss: 1.1055 - val_acc: 0.3117\n",
            "Epoch 69/100 - 0.07s - loss: 1.1015 - acc: 0.3270 - val_loss: 1.1054 - val_acc: 0.3117\n",
            "Epoch 70/100 - 0.08s - loss: 1.1014 - acc: 0.3282 - val_loss: 1.1054 - val_acc: 0.3117\n",
            "Epoch 71/100 - 0.07s - loss: 1.1013 - acc: 0.3279 - val_loss: 1.1053 - val_acc: 0.3117\n",
            "Epoch 72/100 - 0.07s - loss: 1.1012 - acc: 0.3279 - val_loss: 1.1052 - val_acc: 0.3117\n",
            "Epoch 73/100 - 0.08s - loss: 1.1011 - acc: 0.3279 - val_loss: 1.1052 - val_acc: 0.3117\n",
            "Epoch 74/100 - 0.07s - loss: 1.1010 - acc: 0.3277 - val_loss: 1.1051 - val_acc: 0.3138\n",
            "Epoch 75/100 - 0.07s - loss: 1.1009 - acc: 0.3286 - val_loss: 1.1050 - val_acc: 0.3138\n",
            "Epoch 76/100 - 0.08s - loss: 1.1008 - acc: 0.3297 - val_loss: 1.1050 - val_acc: 0.3138\n",
            "Epoch 77/100 - 0.07s - loss: 1.1007 - acc: 0.3302 - val_loss: 1.1049 - val_acc: 0.3138\n",
            "Epoch 78/100 - 0.07s - loss: 1.1006 - acc: 0.3306 - val_loss: 1.1048 - val_acc: 0.3138\n",
            "Epoch 79/100 - 0.08s - loss: 1.1005 - acc: 0.3311 - val_loss: 1.1048 - val_acc: 0.3158\n",
            "Epoch 80/100 - 0.09s - loss: 1.1004 - acc: 0.3306 - val_loss: 1.1047 - val_acc: 0.3138\n",
            "Epoch 81/100 - 0.10s - loss: 1.1003 - acc: 0.3304 - val_loss: 1.1046 - val_acc: 0.3158\n",
            "Epoch 82/100 - 0.10s - loss: 1.1002 - acc: 0.3311 - val_loss: 1.1046 - val_acc: 0.3178\n",
            "Epoch 83/100 - 0.08s - loss: 1.1002 - acc: 0.3304 - val_loss: 1.1045 - val_acc: 0.3178\n",
            "Epoch 84/100 - 0.08s - loss: 1.1001 - acc: 0.3304 - val_loss: 1.1044 - val_acc: 0.3198\n",
            "Epoch 85/100 - 0.08s - loss: 1.1000 - acc: 0.3302 - val_loss: 1.1044 - val_acc: 0.3158\n",
            "Epoch 86/100 - 0.07s - loss: 1.0999 - acc: 0.3302 - val_loss: 1.1043 - val_acc: 0.3178\n",
            "Epoch 87/100 - 0.07s - loss: 1.0998 - acc: 0.3302 - val_loss: 1.1042 - val_acc: 0.3178\n",
            "Epoch 88/100 - 0.08s - loss: 1.0997 - acc: 0.3311 - val_loss: 1.1042 - val_acc: 0.3178\n",
            "Epoch 89/100 - 0.09s - loss: 1.0996 - acc: 0.3313 - val_loss: 1.1041 - val_acc: 0.3198\n",
            "Epoch 90/100 - 0.09s - loss: 1.0995 - acc: 0.3318 - val_loss: 1.1040 - val_acc: 0.3198\n",
            "Epoch 91/100 - 0.08s - loss: 1.0994 - acc: 0.3324 - val_loss: 1.1040 - val_acc: 0.3198\n",
            "Epoch 92/100 - 0.08s - loss: 1.0993 - acc: 0.3322 - val_loss: 1.1039 - val_acc: 0.3198\n",
            "Epoch 93/100 - 0.08s - loss: 1.0992 - acc: 0.3327 - val_loss: 1.1039 - val_acc: 0.3198\n",
            "Epoch 94/100 - 0.08s - loss: 1.0992 - acc: 0.3336 - val_loss: 1.1038 - val_acc: 0.3198\n",
            "Epoch 95/100 - 0.07s - loss: 1.0991 - acc: 0.3340 - val_loss: 1.1037 - val_acc: 0.3178\n",
            "Epoch 96/100 - 0.07s - loss: 1.0990 - acc: 0.3342 - val_loss: 1.1037 - val_acc: 0.3178\n",
            "Epoch 97/100 - 0.08s - loss: 1.0989 - acc: 0.3351 - val_loss: 1.1036 - val_acc: 0.3178\n",
            "Epoch 98/100 - 0.07s - loss: 1.0988 - acc: 0.3351 - val_loss: 1.1035 - val_acc: 0.3158\n",
            "Epoch 99/100 - 0.07s - loss: 1.0987 - acc: 0.3356 - val_loss: 1.1035 - val_acc: 0.3158\n",
            "Epoch 100/100 - 0.08s - loss: 1.0986 - acc: 0.3356 - val_loss: 1.1034 - val_acc: 0.3158\n",
            "\n",
            "Combination 72/252:\n",
            "Hidden Layers: [128, 64], Activation: tanh, Learning Rate: 0.0001, Batch Size: 64, Epochs: 150\n",
            "Epoch 1/150 - 0.07s - loss: 1.1156 - acc: 0.3446 - val_loss: 1.1108 - val_acc: 0.3704\n",
            "Epoch 2/150 - 0.08s - loss: 1.1148 - acc: 0.3441 - val_loss: 1.1102 - val_acc: 0.3785\n",
            "Epoch 3/150 - 0.07s - loss: 1.1140 - acc: 0.3455 - val_loss: 1.1096 - val_acc: 0.3846\n",
            "Epoch 4/150 - 0.07s - loss: 1.1133 - acc: 0.3466 - val_loss: 1.1091 - val_acc: 0.3887\n",
            "Epoch 5/150 - 0.08s - loss: 1.1127 - acc: 0.3471 - val_loss: 1.1087 - val_acc: 0.3887\n",
            "Epoch 6/150 - 0.08s - loss: 1.1121 - acc: 0.3441 - val_loss: 1.1082 - val_acc: 0.3927\n",
            "Epoch 7/150 - 0.08s - loss: 1.1115 - acc: 0.3439 - val_loss: 1.1078 - val_acc: 0.3947\n",
            "Epoch 8/150 - 0.08s - loss: 1.1110 - acc: 0.3457 - val_loss: 1.1074 - val_acc: 0.3988\n",
            "Epoch 9/150 - 0.09s - loss: 1.1105 - acc: 0.3446 - val_loss: 1.1071 - val_acc: 0.4008\n",
            "Epoch 10/150 - 0.07s - loss: 1.1100 - acc: 0.3439 - val_loss: 1.1068 - val_acc: 0.3988\n",
            "Epoch 11/150 - 0.07s - loss: 1.1096 - acc: 0.3432 - val_loss: 1.1065 - val_acc: 0.4008\n",
            "Epoch 12/150 - 0.07s - loss: 1.1092 - acc: 0.3437 - val_loss: 1.1062 - val_acc: 0.4008\n",
            "Epoch 13/150 - 0.07s - loss: 1.1088 - acc: 0.3441 - val_loss: 1.1059 - val_acc: 0.3968\n",
            "Epoch 14/150 - 0.07s - loss: 1.1084 - acc: 0.3435 - val_loss: 1.1057 - val_acc: 0.3947\n",
            "Epoch 15/150 - 0.07s - loss: 1.1081 - acc: 0.3439 - val_loss: 1.1054 - val_acc: 0.3866\n",
            "Epoch 16/150 - 0.07s - loss: 1.1077 - acc: 0.3435 - val_loss: 1.1052 - val_acc: 0.3887\n",
            "Epoch 17/150 - 0.07s - loss: 1.1074 - acc: 0.3432 - val_loss: 1.1050 - val_acc: 0.3826\n",
            "Epoch 18/150 - 0.08s - loss: 1.1071 - acc: 0.3414 - val_loss: 1.1048 - val_acc: 0.3887\n",
            "Epoch 19/150 - 0.07s - loss: 1.1068 - acc: 0.3419 - val_loss: 1.1046 - val_acc: 0.3826\n",
            "Epoch 20/150 - 0.07s - loss: 1.1065 - acc: 0.3421 - val_loss: 1.1044 - val_acc: 0.3765\n",
            "Epoch 21/150 - 0.08s - loss: 1.1063 - acc: 0.3401 - val_loss: 1.1042 - val_acc: 0.3704\n",
            "Epoch 22/150 - 0.07s - loss: 1.1060 - acc: 0.3396 - val_loss: 1.1041 - val_acc: 0.3704\n",
            "Epoch 23/150 - 0.07s - loss: 1.1058 - acc: 0.3399 - val_loss: 1.1039 - val_acc: 0.3644\n",
            "Epoch 24/150 - 0.08s - loss: 1.1055 - acc: 0.3410 - val_loss: 1.1037 - val_acc: 0.3603\n",
            "Epoch 25/150 - 0.07s - loss: 1.1053 - acc: 0.3428 - val_loss: 1.1036 - val_acc: 0.3603\n",
            "Epoch 26/150 - 0.08s - loss: 1.1051 - acc: 0.3448 - val_loss: 1.1034 - val_acc: 0.3644\n",
            "Epoch 27/150 - 0.08s - loss: 1.1048 - acc: 0.3453 - val_loss: 1.1032 - val_acc: 0.3684\n",
            "Epoch 28/150 - 0.08s - loss: 1.1046 - acc: 0.3439 - val_loss: 1.1031 - val_acc: 0.3664\n",
            "Epoch 29/150 - 0.07s - loss: 1.1044 - acc: 0.3444 - val_loss: 1.1029 - val_acc: 0.3664\n",
            "Epoch 30/150 - 0.07s - loss: 1.1042 - acc: 0.3432 - val_loss: 1.1028 - val_acc: 0.3623\n",
            "Epoch 31/150 - 0.07s - loss: 1.1040 - acc: 0.3426 - val_loss: 1.1027 - val_acc: 0.3603\n",
            "Epoch 32/150 - 0.07s - loss: 1.1038 - acc: 0.3410 - val_loss: 1.1025 - val_acc: 0.3603\n",
            "Epoch 33/150 - 0.08s - loss: 1.1036 - acc: 0.3426 - val_loss: 1.1024 - val_acc: 0.3644\n",
            "Epoch 34/150 - 0.07s - loss: 1.1034 - acc: 0.3417 - val_loss: 1.1022 - val_acc: 0.3603\n",
            "Epoch 35/150 - 0.08s - loss: 1.1032 - acc: 0.3435 - val_loss: 1.1021 - val_acc: 0.3603\n",
            "Epoch 36/150 - 0.08s - loss: 1.1031 - acc: 0.3423 - val_loss: 1.1019 - val_acc: 0.3603\n",
            "Epoch 37/150 - 0.07s - loss: 1.1029 - acc: 0.3430 - val_loss: 1.1018 - val_acc: 0.3623\n",
            "Epoch 38/150 - 0.08s - loss: 1.1027 - acc: 0.3432 - val_loss: 1.1017 - val_acc: 0.3623\n",
            "Epoch 39/150 - 0.07s - loss: 1.1025 - acc: 0.3430 - val_loss: 1.1015 - val_acc: 0.3603\n",
            "Epoch 40/150 - 0.07s - loss: 1.1023 - acc: 0.3428 - val_loss: 1.1014 - val_acc: 0.3583\n",
            "Epoch 41/150 - 0.07s - loss: 1.1022 - acc: 0.3417 - val_loss: 1.1013 - val_acc: 0.3583\n",
            "Epoch 42/150 - 0.07s - loss: 1.1020 - acc: 0.3405 - val_loss: 1.1011 - val_acc: 0.3603\n",
            "Epoch 43/150 - 0.07s - loss: 1.1018 - acc: 0.3405 - val_loss: 1.1010 - val_acc: 0.3603\n",
            "Epoch 44/150 - 0.07s - loss: 1.1017 - acc: 0.3408 - val_loss: 1.1009 - val_acc: 0.3623\n",
            "Epoch 45/150 - 0.08s - loss: 1.1015 - acc: 0.3399 - val_loss: 1.1007 - val_acc: 0.3623\n",
            "Epoch 46/150 - 0.09s - loss: 1.1013 - acc: 0.3405 - val_loss: 1.1006 - val_acc: 0.3603\n",
            "Epoch 47/150 - 0.08s - loss: 1.1012 - acc: 0.3394 - val_loss: 1.1004 - val_acc: 0.3603\n",
            "Epoch 48/150 - 0.08s - loss: 1.1010 - acc: 0.3396 - val_loss: 1.1003 - val_acc: 0.3563\n",
            "Epoch 49/150 - 0.09s - loss: 1.1008 - acc: 0.3392 - val_loss: 1.1002 - val_acc: 0.3543\n",
            "Epoch 50/150 - 0.09s - loss: 1.1007 - acc: 0.3399 - val_loss: 1.1000 - val_acc: 0.3563\n",
            "Epoch 51/150 - 0.08s - loss: 1.1005 - acc: 0.3410 - val_loss: 1.0999 - val_acc: 0.3563\n",
            "Epoch 52/150 - 0.08s - loss: 1.1004 - acc: 0.3414 - val_loss: 1.0998 - val_acc: 0.3583\n",
            "Epoch 53/150 - 0.07s - loss: 1.1002 - acc: 0.3417 - val_loss: 1.0996 - val_acc: 0.3583\n",
            "Epoch 54/150 - 0.08s - loss: 1.1001 - acc: 0.3423 - val_loss: 1.0995 - val_acc: 0.3583\n",
            "Epoch 55/150 - 0.07s - loss: 1.0999 - acc: 0.3428 - val_loss: 1.0994 - val_acc: 0.3603\n",
            "Epoch 56/150 - 0.07s - loss: 1.0997 - acc: 0.3423 - val_loss: 1.0993 - val_acc: 0.3603\n",
            "Epoch 57/150 - 0.08s - loss: 1.0996 - acc: 0.3439 - val_loss: 1.0991 - val_acc: 0.3603\n",
            "Epoch 58/150 - 0.07s - loss: 1.0994 - acc: 0.3450 - val_loss: 1.0990 - val_acc: 0.3583\n",
            "Epoch 59/150 - 0.08s - loss: 1.0993 - acc: 0.3455 - val_loss: 1.0989 - val_acc: 0.3583\n",
            "Epoch 60/150 - 0.09s - loss: 1.0991 - acc: 0.3468 - val_loss: 1.0987 - val_acc: 0.3583\n",
            "Epoch 61/150 - 0.09s - loss: 1.0990 - acc: 0.3471 - val_loss: 1.0986 - val_acc: 0.3583\n",
            "Epoch 62/150 - 0.08s - loss: 1.0988 - acc: 0.3471 - val_loss: 1.0985 - val_acc: 0.3583\n",
            "Epoch 63/150 - 0.08s - loss: 1.0987 - acc: 0.3475 - val_loss: 1.0984 - val_acc: 0.3543\n",
            "Epoch 64/150 - 0.08s - loss: 1.0985 - acc: 0.3475 - val_loss: 1.0982 - val_acc: 0.3563\n",
            "Epoch 65/150 - 0.08s - loss: 1.0984 - acc: 0.3475 - val_loss: 1.0981 - val_acc: 0.3563\n",
            "Epoch 66/150 - 0.08s - loss: 1.0983 - acc: 0.3473 - val_loss: 1.0980 - val_acc: 0.3583\n",
            "Epoch 67/150 - 0.07s - loss: 1.0981 - acc: 0.3482 - val_loss: 1.0978 - val_acc: 0.3623\n",
            "Epoch 68/150 - 0.07s - loss: 1.0980 - acc: 0.3486 - val_loss: 1.0977 - val_acc: 0.3583\n",
            "Epoch 69/150 - 0.08s - loss: 1.0978 - acc: 0.3486 - val_loss: 1.0976 - val_acc: 0.3603\n",
            "Epoch 70/150 - 0.07s - loss: 1.0977 - acc: 0.3491 - val_loss: 1.0975 - val_acc: 0.3603\n",
            "Epoch 71/150 - 0.08s - loss: 1.0975 - acc: 0.3489 - val_loss: 1.0973 - val_acc: 0.3623\n",
            "Epoch 72/150 - 0.07s - loss: 1.0974 - acc: 0.3491 - val_loss: 1.0972 - val_acc: 0.3623\n",
            "Epoch 73/150 - 0.07s - loss: 1.0972 - acc: 0.3493 - val_loss: 1.0971 - val_acc: 0.3644\n",
            "Epoch 74/150 - 0.08s - loss: 1.0971 - acc: 0.3495 - val_loss: 1.0970 - val_acc: 0.3644\n",
            "Epoch 75/150 - 0.08s - loss: 1.0970 - acc: 0.3495 - val_loss: 1.0968 - val_acc: 0.3664\n",
            "Epoch 76/150 - 0.07s - loss: 1.0968 - acc: 0.3498 - val_loss: 1.0967 - val_acc: 0.3684\n",
            "Epoch 77/150 - 0.07s - loss: 1.0967 - acc: 0.3509 - val_loss: 1.0966 - val_acc: 0.3684\n",
            "Epoch 78/150 - 0.08s - loss: 1.0965 - acc: 0.3516 - val_loss: 1.0965 - val_acc: 0.3623\n",
            "Epoch 79/150 - 0.07s - loss: 1.0964 - acc: 0.3516 - val_loss: 1.0963 - val_acc: 0.3644\n",
            "Epoch 80/150 - 0.07s - loss: 1.0963 - acc: 0.3516 - val_loss: 1.0962 - val_acc: 0.3664\n",
            "Epoch 81/150 - 0.09s - loss: 1.0961 - acc: 0.3518 - val_loss: 1.0961 - val_acc: 0.3684\n",
            "Epoch 82/150 - 0.08s - loss: 1.0960 - acc: 0.3534 - val_loss: 1.0960 - val_acc: 0.3684\n",
            "Epoch 83/150 - 0.08s - loss: 1.0959 - acc: 0.3547 - val_loss: 1.0959 - val_acc: 0.3684\n",
            "Epoch 84/150 - 0.08s - loss: 1.0957 - acc: 0.3547 - val_loss: 1.0958 - val_acc: 0.3704\n",
            "Epoch 85/150 - 0.08s - loss: 1.0956 - acc: 0.3549 - val_loss: 1.0956 - val_acc: 0.3684\n",
            "Epoch 86/150 - 0.08s - loss: 1.0954 - acc: 0.3563 - val_loss: 1.0955 - val_acc: 0.3684\n",
            "Epoch 87/150 - 0.08s - loss: 1.0953 - acc: 0.3570 - val_loss: 1.0954 - val_acc: 0.3684\n",
            "Epoch 88/150 - 0.08s - loss: 1.0952 - acc: 0.3574 - val_loss: 1.0953 - val_acc: 0.3704\n",
            "Epoch 89/150 - 0.08s - loss: 1.0950 - acc: 0.3585 - val_loss: 1.0952 - val_acc: 0.3704\n",
            "Epoch 90/150 - 0.08s - loss: 1.0949 - acc: 0.3592 - val_loss: 1.0950 - val_acc: 0.3684\n",
            "Epoch 91/150 - 0.08s - loss: 1.0948 - acc: 0.3594 - val_loss: 1.0949 - val_acc: 0.3664\n",
            "Epoch 92/150 - 0.08s - loss: 1.0946 - acc: 0.3599 - val_loss: 1.0948 - val_acc: 0.3745\n",
            "Epoch 93/150 - 0.08s - loss: 1.0945 - acc: 0.3599 - val_loss: 1.0947 - val_acc: 0.3765\n",
            "Epoch 94/150 - 0.09s - loss: 1.0944 - acc: 0.3601 - val_loss: 1.0946 - val_acc: 0.3785\n",
            "Epoch 95/150 - 0.10s - loss: 1.0943 - acc: 0.3605 - val_loss: 1.0945 - val_acc: 0.3765\n",
            "Epoch 96/150 - 0.08s - loss: 1.0941 - acc: 0.3608 - val_loss: 1.0943 - val_acc: 0.3745\n",
            "Epoch 97/150 - 0.08s - loss: 1.0940 - acc: 0.3614 - val_loss: 1.0942 - val_acc: 0.3765\n",
            "Epoch 98/150 - 0.08s - loss: 1.0939 - acc: 0.3628 - val_loss: 1.0941 - val_acc: 0.3785\n",
            "Epoch 99/150 - 0.07s - loss: 1.0937 - acc: 0.3626 - val_loss: 1.0940 - val_acc: 0.3765\n",
            "Epoch 100/150 - 0.07s - loss: 1.0936 - acc: 0.3626 - val_loss: 1.0939 - val_acc: 0.3725\n",
            "Epoch 101/150 - 0.07s - loss: 1.0935 - acc: 0.3646 - val_loss: 1.0938 - val_acc: 0.3725\n",
            "Epoch 102/150 - 0.07s - loss: 1.0934 - acc: 0.3657 - val_loss: 1.0937 - val_acc: 0.3704\n",
            "Epoch 103/150 - 0.07s - loss: 1.0932 - acc: 0.3659 - val_loss: 1.0935 - val_acc: 0.3745\n",
            "Epoch 104/150 - 0.08s - loss: 1.0931 - acc: 0.3691 - val_loss: 1.0934 - val_acc: 0.3765\n",
            "Epoch 105/150 - 0.08s - loss: 1.0930 - acc: 0.3695 - val_loss: 1.0933 - val_acc: 0.3785\n",
            "Epoch 106/150 - 0.08s - loss: 1.0929 - acc: 0.3695 - val_loss: 1.0932 - val_acc: 0.3826\n",
            "Epoch 107/150 - 0.08s - loss: 1.0927 - acc: 0.3700 - val_loss: 1.0931 - val_acc: 0.3826\n",
            "Epoch 108/150 - 0.07s - loss: 1.0926 - acc: 0.3709 - val_loss: 1.0930 - val_acc: 0.3826\n",
            "Epoch 109/150 - 0.08s - loss: 1.0925 - acc: 0.3718 - val_loss: 1.0929 - val_acc: 0.3826\n",
            "Epoch 110/150 - 0.07s - loss: 1.0924 - acc: 0.3745 - val_loss: 1.0928 - val_acc: 0.3806\n",
            "Epoch 111/150 - 0.08s - loss: 1.0922 - acc: 0.3761 - val_loss: 1.0926 - val_acc: 0.3785\n",
            "Epoch 112/150 - 0.08s - loss: 1.0921 - acc: 0.3770 - val_loss: 1.0925 - val_acc: 0.3765\n",
            "Epoch 113/150 - 0.08s - loss: 1.0920 - acc: 0.3788 - val_loss: 1.0924 - val_acc: 0.3725\n",
            "Epoch 114/150 - 0.08s - loss: 1.0919 - acc: 0.3792 - val_loss: 1.0923 - val_acc: 0.3765\n",
            "Epoch 115/150 - 0.08s - loss: 1.0918 - acc: 0.3801 - val_loss: 1.0922 - val_acc: 0.3806\n",
            "Epoch 116/150 - 0.08s - loss: 1.0916 - acc: 0.3801 - val_loss: 1.0921 - val_acc: 0.3806\n",
            "Epoch 117/150 - 0.08s - loss: 1.0915 - acc: 0.3808 - val_loss: 1.0920 - val_acc: 0.3806\n",
            "Epoch 118/150 - 0.08s - loss: 1.0914 - acc: 0.3801 - val_loss: 1.0919 - val_acc: 0.3826\n",
            "Epoch 119/150 - 0.08s - loss: 1.0913 - acc: 0.3808 - val_loss: 1.0918 - val_acc: 0.3846\n",
            "Epoch 120/150 - 0.07s - loss: 1.0912 - acc: 0.3815 - val_loss: 1.0917 - val_acc: 0.3846\n",
            "Epoch 121/150 - 0.07s - loss: 1.0910 - acc: 0.3824 - val_loss: 1.0916 - val_acc: 0.3846\n",
            "Epoch 122/150 - 0.07s - loss: 1.0909 - acc: 0.3833 - val_loss: 1.0915 - val_acc: 0.3846\n",
            "Epoch 123/150 - 0.08s - loss: 1.0908 - acc: 0.3851 - val_loss: 1.0914 - val_acc: 0.3846\n",
            "Epoch 124/150 - 0.07s - loss: 1.0907 - acc: 0.3860 - val_loss: 1.0913 - val_acc: 0.3846\n",
            "Epoch 125/150 - 0.07s - loss: 1.0906 - acc: 0.3869 - val_loss: 1.0912 - val_acc: 0.3866\n",
            "Epoch 126/150 - 0.08s - loss: 1.0904 - acc: 0.3880 - val_loss: 1.0911 - val_acc: 0.3866\n",
            "Epoch 127/150 - 0.08s - loss: 1.0903 - acc: 0.3909 - val_loss: 1.0909 - val_acc: 0.3866\n",
            "Epoch 128/150 - 0.08s - loss: 1.0902 - acc: 0.3920 - val_loss: 1.0908 - val_acc: 0.3907\n",
            "Epoch 129/150 - 0.08s - loss: 1.0901 - acc: 0.3932 - val_loss: 1.0907 - val_acc: 0.3927\n",
            "Epoch 130/150 - 0.08s - loss: 1.0900 - acc: 0.3938 - val_loss: 1.0906 - val_acc: 0.3866\n",
            "Epoch 131/150 - 0.08s - loss: 1.0899 - acc: 0.3947 - val_loss: 1.0905 - val_acc: 0.3866\n",
            "Epoch 132/150 - 0.08s - loss: 1.0898 - acc: 0.3965 - val_loss: 1.0904 - val_acc: 0.3846\n",
            "Epoch 133/150 - 0.08s - loss: 1.0897 - acc: 0.3963 - val_loss: 1.0903 - val_acc: 0.3846\n",
            "Epoch 134/150 - 0.08s - loss: 1.0895 - acc: 0.3959 - val_loss: 1.0902 - val_acc: 0.3887\n",
            "Epoch 135/150 - 0.08s - loss: 1.0894 - acc: 0.3961 - val_loss: 1.0901 - val_acc: 0.3887\n",
            "Epoch 136/150 - 0.08s - loss: 1.0893 - acc: 0.3968 - val_loss: 1.0900 - val_acc: 0.3927\n",
            "Epoch 137/150 - 0.08s - loss: 1.0892 - acc: 0.3979 - val_loss: 1.0899 - val_acc: 0.3947\n",
            "Epoch 138/150 - 0.08s - loss: 1.0891 - acc: 0.3968 - val_loss: 1.0898 - val_acc: 0.3968\n",
            "Epoch 139/150 - 0.09s - loss: 1.0890 - acc: 0.3970 - val_loss: 1.0897 - val_acc: 0.3947\n",
            "Epoch 140/150 - 0.12s - loss: 1.0889 - acc: 0.3968 - val_loss: 1.0896 - val_acc: 0.3947\n",
            "Epoch 141/150 - 0.08s - loss: 1.0888 - acc: 0.3977 - val_loss: 1.0895 - val_acc: 0.3968\n",
            "Epoch 142/150 - 0.08s - loss: 1.0886 - acc: 0.3983 - val_loss: 1.0894 - val_acc: 0.4008\n",
            "Epoch 143/150 - 0.08s - loss: 1.0885 - acc: 0.3986 - val_loss: 1.0893 - val_acc: 0.3988\n",
            "Epoch 144/150 - 0.08s - loss: 1.0884 - acc: 0.3997 - val_loss: 1.0892 - val_acc: 0.3988\n",
            "Epoch 145/150 - 0.08s - loss: 1.0883 - acc: 0.4010 - val_loss: 1.0891 - val_acc: 0.4008\n",
            "Epoch 146/150 - 0.08s - loss: 1.0882 - acc: 0.4004 - val_loss: 1.0891 - val_acc: 0.3988\n",
            "Epoch 147/150 - 0.08s - loss: 1.0881 - acc: 0.4017 - val_loss: 1.0890 - val_acc: 0.4008\n",
            "Epoch 148/150 - 0.08s - loss: 1.0880 - acc: 0.4017 - val_loss: 1.0889 - val_acc: 0.4049\n",
            "Epoch 149/150 - 0.08s - loss: 1.0879 - acc: 0.4026 - val_loss: 1.0888 - val_acc: 0.4049\n",
            "Epoch 150/150 - 0.07s - loss: 1.0878 - acc: 0.4028 - val_loss: 1.0887 - val_acc: 0.4049\n",
            "\n",
            "Combination 73/252:\n",
            "Hidden Layers: [128, 128], Activation: relu, Learning Rate: 0.01, Batch Size: 32, Epochs: 50\n",
            "Epoch 1/50 - 0.07s - loss: 1.0900 - acc: 0.3794 - val_loss: 1.0908 - val_acc: 0.3826\n",
            "Epoch 2/50 - 0.08s - loss: 1.0799 - acc: 0.4145 - val_loss: 1.0810 - val_acc: 0.4150\n",
            "Epoch 3/50 - 0.08s - loss: 1.0723 - acc: 0.4343 - val_loss: 1.0738 - val_acc: 0.4393\n",
            "Epoch 4/50 - 0.07s - loss: 1.0638 - acc: 0.4460 - val_loss: 1.0699 - val_acc: 0.4453\n",
            "Epoch 5/50 - 0.07s - loss: 1.0560 - acc: 0.4516 - val_loss: 1.0628 - val_acc: 0.4555\n",
            "Epoch 6/50 - 0.08s - loss: 1.0498 - acc: 0.4575 - val_loss: 1.0584 - val_acc: 0.4555\n",
            "Epoch 7/50 - 0.08s - loss: 1.0428 - acc: 0.4685 - val_loss: 1.0546 - val_acc: 0.4696\n",
            "Epoch 8/50 - 0.07s - loss: 1.0393 - acc: 0.4699 - val_loss: 1.0520 - val_acc: 0.4474\n",
            "Epoch 9/50 - 0.08s - loss: 1.0309 - acc: 0.4818 - val_loss: 1.0483 - val_acc: 0.4777\n",
            "Epoch 10/50 - 0.08s - loss: 1.0254 - acc: 0.4888 - val_loss: 1.0439 - val_acc: 0.4656\n",
            "Epoch 11/50 - 0.08s - loss: 1.0191 - acc: 0.4973 - val_loss: 1.0410 - val_acc: 0.4737\n",
            "Epoch 12/50 - 0.07s - loss: 1.0130 - acc: 0.5000 - val_loss: 1.0375 - val_acc: 0.4757\n",
            "Epoch 13/50 - 0.07s - loss: 1.0073 - acc: 0.5070 - val_loss: 1.0346 - val_acc: 0.4798\n",
            "Epoch 14/50 - 0.08s - loss: 1.0036 - acc: 0.5081 - val_loss: 1.0332 - val_acc: 0.4838\n",
            "Epoch 15/50 - 0.08s - loss: 0.9964 - acc: 0.5151 - val_loss: 1.0263 - val_acc: 0.5000\n",
            "Epoch 16/50 - 0.07s - loss: 0.9913 - acc: 0.5166 - val_loss: 1.0227 - val_acc: 0.5000\n",
            "Epoch 17/50 - 0.08s - loss: 0.9865 - acc: 0.5238 - val_loss: 1.0220 - val_acc: 0.5020\n",
            "Epoch 18/50 - 0.07s - loss: 0.9861 - acc: 0.5211 - val_loss: 1.0189 - val_acc: 0.5081\n",
            "Epoch 19/50 - 0.08s - loss: 0.9749 - acc: 0.5317 - val_loss: 1.0124 - val_acc: 0.5061\n",
            "Epoch 20/50 - 0.09s - loss: 0.9697 - acc: 0.5360 - val_loss: 1.0085 - val_acc: 0.5182\n",
            "Epoch 21/50 - 0.08s - loss: 0.9756 - acc: 0.5250 - val_loss: 1.0207 - val_acc: 0.4757\n",
            "Epoch 22/50 - 0.07s - loss: 0.9630 - acc: 0.5445 - val_loss: 1.0029 - val_acc: 0.5263\n",
            "Epoch 23/50 - 0.07s - loss: 0.9581 - acc: 0.5479 - val_loss: 1.0028 - val_acc: 0.5142\n",
            "Epoch 24/50 - 0.08s - loss: 0.9520 - acc: 0.5459 - val_loss: 0.9951 - val_acc: 0.5202\n",
            "Epoch 25/50 - 0.07s - loss: 0.9488 - acc: 0.5499 - val_loss: 0.9981 - val_acc: 0.5223\n",
            "Epoch 26/50 - 0.07s - loss: 0.9446 - acc: 0.5571 - val_loss: 0.9933 - val_acc: 0.5304\n",
            "Epoch 27/50 - 0.08s - loss: 0.9384 - acc: 0.5542 - val_loss: 0.9879 - val_acc: 0.5344\n",
            "Epoch 28/50 - 0.07s - loss: 0.9371 - acc: 0.5628 - val_loss: 0.9885 - val_acc: 0.5344\n",
            "Epoch 29/50 - 0.07s - loss: 0.9377 - acc: 0.5634 - val_loss: 0.9890 - val_acc: 0.5506\n",
            "Epoch 30/50 - 0.07s - loss: 0.9273 - acc: 0.5565 - val_loss: 0.9829 - val_acc: 0.5263\n",
            "Epoch 31/50 - 0.08s - loss: 0.9234 - acc: 0.5661 - val_loss: 0.9821 - val_acc: 0.5304\n",
            "Epoch 32/50 - 0.09s - loss: 0.9290 - acc: 0.5560 - val_loss: 0.9886 - val_acc: 0.5142\n",
            "Epoch 33/50 - 0.09s - loss: 0.9166 - acc: 0.5668 - val_loss: 0.9763 - val_acc: 0.5364\n",
            "Epoch 34/50 - 0.08s - loss: 0.9229 - acc: 0.5621 - val_loss: 0.9876 - val_acc: 0.5385\n",
            "Epoch 35/50 - 0.08s - loss: 0.9152 - acc: 0.5693 - val_loss: 0.9831 - val_acc: 0.5223\n",
            "Epoch 36/50 - 0.08s - loss: 0.9124 - acc: 0.5686 - val_loss: 0.9841 - val_acc: 0.5162\n",
            "Epoch 37/50 - 0.08s - loss: 0.9024 - acc: 0.5783 - val_loss: 0.9698 - val_acc: 0.5486\n",
            "Epoch 38/50 - 0.08s - loss: 0.9027 - acc: 0.5726 - val_loss: 0.9712 - val_acc: 0.5506\n",
            "Epoch 39/50 - 0.08s - loss: 0.9062 - acc: 0.5724 - val_loss: 0.9803 - val_acc: 0.5223\n",
            "Epoch 40/50 - 0.08s - loss: 0.8911 - acc: 0.5828 - val_loss: 0.9642 - val_acc: 0.5526\n",
            "Epoch 41/50 - 0.09s - loss: 0.8936 - acc: 0.5776 - val_loss: 0.9660 - val_acc: 0.5344\n",
            "Epoch 42/50 - 0.09s - loss: 0.8840 - acc: 0.5873 - val_loss: 0.9617 - val_acc: 0.5445\n",
            "Epoch 43/50 - 0.08s - loss: 0.8898 - acc: 0.5765 - val_loss: 0.9666 - val_acc: 0.5405\n",
            "Epoch 44/50 - 0.08s - loss: 0.8787 - acc: 0.5945 - val_loss: 0.9590 - val_acc: 0.5648\n",
            "Epoch 45/50 - 0.08s - loss: 0.8743 - acc: 0.5965 - val_loss: 0.9570 - val_acc: 0.5486\n",
            "Epoch 46/50 - 0.08s - loss: 0.8756 - acc: 0.5902 - val_loss: 0.9567 - val_acc: 0.5547\n",
            "Epoch 47/50 - 0.08s - loss: 0.8683 - acc: 0.6001 - val_loss: 0.9554 - val_acc: 0.5547\n",
            "Epoch 48/50 - 0.09s - loss: 0.8873 - acc: 0.5830 - val_loss: 0.9778 - val_acc: 0.5304\n",
            "Epoch 49/50 - 0.07s - loss: 0.8659 - acc: 0.6019 - val_loss: 0.9592 - val_acc: 0.5607\n",
            "Epoch 50/50 - 0.08s - loss: 0.8829 - acc: 0.5873 - val_loss: 0.9676 - val_acc: 0.5526\n",
            "\n",
            "Combination 74/252:\n",
            "Hidden Layers: [128, 128], Activation: relu, Learning Rate: 0.01, Batch Size: 32, Epochs: 100\n",
            "Epoch 1/100 - 0.08s - loss: 1.0851 - acc: 0.4055 - val_loss: 1.0875 - val_acc: 0.3988\n",
            "Epoch 2/100 - 0.07s - loss: 1.0736 - acc: 0.4372 - val_loss: 1.0787 - val_acc: 0.4332\n",
            "Epoch 3/100 - 0.08s - loss: 1.0633 - acc: 0.4514 - val_loss: 1.0716 - val_acc: 0.4555\n",
            "Epoch 4/100 - 0.08s - loss: 1.0547 - acc: 0.4636 - val_loss: 1.0672 - val_acc: 0.4433\n",
            "Epoch 5/100 - 0.07s - loss: 1.0470 - acc: 0.4690 - val_loss: 1.0612 - val_acc: 0.4757\n",
            "Epoch 6/100 - 0.08s - loss: 1.0416 - acc: 0.4699 - val_loss: 1.0608 - val_acc: 0.4818\n",
            "Epoch 7/100 - 0.08s - loss: 1.0336 - acc: 0.4836 - val_loss: 1.0528 - val_acc: 0.4798\n",
            "Epoch 8/100 - 0.07s - loss: 1.0287 - acc: 0.4892 - val_loss: 1.0506 - val_acc: 0.4777\n",
            "Epoch 9/100 - 0.07s - loss: 1.0218 - acc: 0.4933 - val_loss: 1.0460 - val_acc: 0.4858\n",
            "Epoch 10/100 - 0.08s - loss: 1.0169 - acc: 0.4951 - val_loss: 1.0448 - val_acc: 0.4838\n",
            "Epoch 11/100 - 0.07s - loss: 1.0115 - acc: 0.4971 - val_loss: 1.0419 - val_acc: 0.4818\n",
            "Epoch 12/100 - 0.08s - loss: 1.0053 - acc: 0.5031 - val_loss: 1.0375 - val_acc: 0.4919\n",
            "Epoch 13/100 - 0.09s - loss: 0.9987 - acc: 0.5088 - val_loss: 1.0315 - val_acc: 0.5020\n",
            "Epoch 14/100 - 0.08s - loss: 0.9936 - acc: 0.5200 - val_loss: 1.0260 - val_acc: 0.5061\n",
            "Epoch 15/100 - 0.08s - loss: 0.9884 - acc: 0.5220 - val_loss: 1.0219 - val_acc: 0.5061\n",
            "Epoch 16/100 - 0.08s - loss: 0.9821 - acc: 0.5263 - val_loss: 1.0183 - val_acc: 0.5000\n",
            "Epoch 17/100 - 0.08s - loss: 0.9769 - acc: 0.5297 - val_loss: 1.0150 - val_acc: 0.5061\n",
            "Epoch 18/100 - 0.08s - loss: 0.9793 - acc: 0.5324 - val_loss: 1.0163 - val_acc: 0.5182\n",
            "Epoch 19/100 - 0.08s - loss: 0.9669 - acc: 0.5403 - val_loss: 1.0067 - val_acc: 0.5162\n",
            "Epoch 20/100 - 0.08s - loss: 0.9634 - acc: 0.5333 - val_loss: 1.0052 - val_acc: 0.5040\n",
            "Epoch 21/100 - 0.08s - loss: 0.9574 - acc: 0.5443 - val_loss: 0.9996 - val_acc: 0.5182\n",
            "Epoch 22/100 - 0.08s - loss: 0.9582 - acc: 0.5355 - val_loss: 1.0012 - val_acc: 0.5101\n",
            "Epoch 23/100 - 0.08s - loss: 0.9515 - acc: 0.5450 - val_loss: 0.9945 - val_acc: 0.5202\n",
            "Epoch 24/100 - 0.09s - loss: 0.9445 - acc: 0.5542 - val_loss: 0.9903 - val_acc: 0.5283\n",
            "Epoch 25/100 - 0.08s - loss: 0.9407 - acc: 0.5531 - val_loss: 0.9904 - val_acc: 0.5304\n",
            "Epoch 26/100 - 0.08s - loss: 0.9381 - acc: 0.5517 - val_loss: 0.9906 - val_acc: 0.5263\n",
            "Epoch 27/100 - 0.08s - loss: 0.9327 - acc: 0.5583 - val_loss: 0.9865 - val_acc: 0.5304\n",
            "Epoch 28/100 - 0.08s - loss: 0.9284 - acc: 0.5596 - val_loss: 0.9792 - val_acc: 0.5385\n",
            "Epoch 29/100 - 0.08s - loss: 0.9257 - acc: 0.5646 - val_loss: 0.9791 - val_acc: 0.5344\n",
            "Epoch 30/100 - 0.08s - loss: 0.9201 - acc: 0.5675 - val_loss: 0.9734 - val_acc: 0.5425\n",
            "Epoch 31/100 - 0.08s - loss: 0.9170 - acc: 0.5704 - val_loss: 0.9739 - val_acc: 0.5425\n",
            "Epoch 32/100 - 0.08s - loss: 0.9149 - acc: 0.5666 - val_loss: 0.9735 - val_acc: 0.5385\n",
            "Epoch 33/100 - 0.08s - loss: 0.9086 - acc: 0.5747 - val_loss: 0.9680 - val_acc: 0.5405\n",
            "Epoch 34/100 - 0.08s - loss: 0.9083 - acc: 0.5747 - val_loss: 0.9724 - val_acc: 0.5445\n",
            "Epoch 35/100 - 0.09s - loss: 0.9024 - acc: 0.5767 - val_loss: 0.9645 - val_acc: 0.5405\n",
            "Epoch 36/100 - 0.09s - loss: 0.9028 - acc: 0.5789 - val_loss: 0.9704 - val_acc: 0.5445\n",
            "Epoch 37/100 - 0.08s - loss: 0.9018 - acc: 0.5785 - val_loss: 0.9660 - val_acc: 0.5567\n",
            "Epoch 38/100 - 0.08s - loss: 0.9042 - acc: 0.5771 - val_loss: 0.9711 - val_acc: 0.5547\n",
            "Epoch 39/100 - 0.08s - loss: 0.8926 - acc: 0.5850 - val_loss: 0.9638 - val_acc: 0.5526\n",
            "Epoch 40/100 - 0.07s - loss: 0.8866 - acc: 0.5864 - val_loss: 0.9580 - val_acc: 0.5567\n",
            "Epoch 41/100 - 0.07s - loss: 0.8810 - acc: 0.5911 - val_loss: 0.9575 - val_acc: 0.5526\n",
            "Epoch 42/100 - 0.08s - loss: 0.8817 - acc: 0.5891 - val_loss: 0.9568 - val_acc: 0.5567\n",
            "Epoch 43/100 - 0.08s - loss: 0.9047 - acc: 0.5771 - val_loss: 0.9761 - val_acc: 0.5324\n",
            "Epoch 44/100 - 0.07s - loss: 0.8758 - acc: 0.5931 - val_loss: 0.9567 - val_acc: 0.5628\n",
            "Epoch 45/100 - 0.07s - loss: 0.8719 - acc: 0.6008 - val_loss: 0.9533 - val_acc: 0.5587\n",
            "Epoch 46/100 - 0.07s - loss: 0.8768 - acc: 0.5929 - val_loss: 0.9597 - val_acc: 0.5526\n",
            "Epoch 47/100 - 0.07s - loss: 0.8663 - acc: 0.6021 - val_loss: 0.9562 - val_acc: 0.5283\n",
            "Epoch 48/100 - 0.07s - loss: 0.8598 - acc: 0.6100 - val_loss: 0.9496 - val_acc: 0.5547\n",
            "Epoch 49/100 - 0.08s - loss: 0.8787 - acc: 0.5848 - val_loss: 0.9791 - val_acc: 0.5000\n",
            "Epoch 50/100 - 0.07s - loss: 0.8557 - acc: 0.6057 - val_loss: 0.9511 - val_acc: 0.5283\n",
            "Epoch 51/100 - 0.08s - loss: 0.8577 - acc: 0.6037 - val_loss: 0.9555 - val_acc: 0.5688\n",
            "Epoch 52/100 - 0.08s - loss: 0.8522 - acc: 0.6102 - val_loss: 0.9545 - val_acc: 0.5567\n",
            "Epoch 53/100 - 0.07s - loss: 0.8458 - acc: 0.6158 - val_loss: 0.9490 - val_acc: 0.5526\n",
            "Epoch 54/100 - 0.07s - loss: 0.8522 - acc: 0.6030 - val_loss: 0.9549 - val_acc: 0.5385\n",
            "Epoch 55/100 - 0.08s - loss: 0.8405 - acc: 0.6149 - val_loss: 0.9502 - val_acc: 0.5344\n",
            "Epoch 56/100 - 0.07s - loss: 0.8724 - acc: 0.5994 - val_loss: 0.9749 - val_acc: 0.5486\n",
            "Epoch 57/100 - 0.08s - loss: 0.8315 - acc: 0.6224 - val_loss: 0.9454 - val_acc: 0.5486\n",
            "Epoch 58/100 - 0.07s - loss: 0.8323 - acc: 0.6257 - val_loss: 0.9456 - val_acc: 0.5688\n",
            "Epoch 59/100 - 0.07s - loss: 0.8291 - acc: 0.6244 - val_loss: 0.9472 - val_acc: 0.5607\n",
            "Epoch 60/100 - 0.07s - loss: 0.8244 - acc: 0.6271 - val_loss: 0.9459 - val_acc: 0.5506\n",
            "Epoch 61/100 - 0.08s - loss: 0.8309 - acc: 0.6255 - val_loss: 0.9528 - val_acc: 0.5547\n",
            "Epoch 62/100 - 0.07s - loss: 0.8333 - acc: 0.6143 - val_loss: 0.9650 - val_acc: 0.5526\n",
            "Epoch 63/100 - 0.07s - loss: 0.8330 - acc: 0.6116 - val_loss: 0.9735 - val_acc: 0.5182\n",
            "Epoch 64/100 - 0.08s - loss: 0.8107 - acc: 0.6329 - val_loss: 0.9450 - val_acc: 0.5445\n",
            "Epoch 65/100 - 0.07s - loss: 0.8154 - acc: 0.6314 - val_loss: 0.9583 - val_acc: 0.5324\n",
            "Epoch 66/100 - 0.07s - loss: 0.8144 - acc: 0.6282 - val_loss: 0.9479 - val_acc: 0.5405\n",
            "Epoch 67/100 - 0.08s - loss: 0.8162 - acc: 0.6296 - val_loss: 0.9506 - val_acc: 0.5607\n",
            "Epoch 68/100 - 0.07s - loss: 0.8251 - acc: 0.6284 - val_loss: 0.9634 - val_acc: 0.5526\n",
            "Epoch 69/100 - 0.07s - loss: 0.8159 - acc: 0.6334 - val_loss: 0.9779 - val_acc: 0.5283\n",
            "Epoch 70/100 - 0.07s - loss: 0.8017 - acc: 0.6460 - val_loss: 0.9426 - val_acc: 0.5607\n",
            "Epoch 71/100 - 0.07s - loss: 0.8275 - acc: 0.6244 - val_loss: 0.9729 - val_acc: 0.5445\n",
            "Epoch 72/100 - 0.07s - loss: 0.8195 - acc: 0.6307 - val_loss: 0.9872 - val_acc: 0.5263\n",
            "Epoch 73/100 - 0.08s - loss: 0.8152 - acc: 0.6347 - val_loss: 0.9698 - val_acc: 0.5445\n",
            "Epoch 74/100 - 0.08s - loss: 0.8094 - acc: 0.6314 - val_loss: 0.9756 - val_acc: 0.5263\n",
            "Epoch 75/100 - 0.08s - loss: 0.8138 - acc: 0.6264 - val_loss: 0.9653 - val_acc: 0.5445\n",
            "Epoch 76/100 - 0.07s - loss: 0.8047 - acc: 0.6341 - val_loss: 0.9656 - val_acc: 0.5344\n",
            "Epoch 77/100 - 0.07s - loss: 0.7860 - acc: 0.6496 - val_loss: 0.9641 - val_acc: 0.5223\n",
            "Epoch 78/100 - 0.07s - loss: 0.7955 - acc: 0.6455 - val_loss: 0.9600 - val_acc: 0.5567\n",
            "Epoch 79/100 - 0.08s - loss: 0.7785 - acc: 0.6572 - val_loss: 0.9521 - val_acc: 0.5668\n",
            "Epoch 80/100 - 0.07s - loss: 0.7785 - acc: 0.6500 - val_loss: 0.9545 - val_acc: 0.5506\n",
            "Epoch 81/100 - 0.08s - loss: 0.7761 - acc: 0.6561 - val_loss: 0.9583 - val_acc: 0.5344\n",
            "Epoch 82/100 - 0.08s - loss: 0.7699 - acc: 0.6538 - val_loss: 0.9654 - val_acc: 0.5121\n",
            "Epoch 83/100 - 0.08s - loss: 0.7605 - acc: 0.6680 - val_loss: 0.9517 - val_acc: 0.5344\n",
            "Epoch 84/100 - 0.08s - loss: 0.7674 - acc: 0.6660 - val_loss: 0.9565 - val_acc: 0.5567\n",
            "Epoch 85/100 - 0.08s - loss: 0.7549 - acc: 0.6705 - val_loss: 0.9521 - val_acc: 0.5486\n",
            "Epoch 86/100 - 0.08s - loss: 0.7588 - acc: 0.6709 - val_loss: 0.9447 - val_acc: 0.5749\n",
            "Epoch 87/100 - 0.08s - loss: 0.7497 - acc: 0.6752 - val_loss: 0.9446 - val_acc: 0.5648\n",
            "Epoch 88/100 - 0.08s - loss: 0.7477 - acc: 0.6770 - val_loss: 0.9580 - val_acc: 0.5385\n",
            "Epoch 89/100 - 0.08s - loss: 0.7921 - acc: 0.6404 - val_loss: 1.0092 - val_acc: 0.5304\n",
            "Epoch 90/100 - 0.08s - loss: 0.7477 - acc: 0.6757 - val_loss: 0.9510 - val_acc: 0.5547\n",
            "Epoch 91/100 - 0.09s - loss: 0.7383 - acc: 0.6835 - val_loss: 0.9470 - val_acc: 0.5648\n",
            "Epoch 92/100 - 0.09s - loss: 0.7844 - acc: 0.6448 - val_loss: 0.9824 - val_acc: 0.5405\n",
            "Epoch 93/100 - 0.09s - loss: 0.7357 - acc: 0.6856 - val_loss: 0.9588 - val_acc: 0.5304\n",
            "Epoch 94/100 - 0.09s - loss: 0.8131 - acc: 0.6264 - val_loss: 1.0515 - val_acc: 0.5020\n",
            "Epoch 95/100 - 0.09s - loss: 0.7330 - acc: 0.6878 - val_loss: 0.9566 - val_acc: 0.5526\n",
            "Epoch 96/100 - 0.10s - loss: 0.7263 - acc: 0.6928 - val_loss: 0.9512 - val_acc: 0.5364\n",
            "Epoch 97/100 - 0.08s - loss: 0.7548 - acc: 0.6610 - val_loss: 1.0036 - val_acc: 0.5304\n",
            "Epoch 98/100 - 0.09s - loss: 0.7284 - acc: 0.6824 - val_loss: 0.9560 - val_acc: 0.5587\n",
            "Epoch 99/100 - 0.09s - loss: 0.8510 - acc: 0.5954 - val_loss: 1.0508 - val_acc: 0.5223\n",
            "Epoch 100/100 - 0.11s - loss: 0.7208 - acc: 0.6867 - val_loss: 0.9623 - val_acc: 0.5425\n",
            "\n",
            "Combination 75/252:\n",
            "Hidden Layers: [128, 128], Activation: relu, Learning Rate: 0.01, Batch Size: 32, Epochs: 150\n",
            "Epoch 1/150 - 0.13s - loss: 1.0818 - acc: 0.4213 - val_loss: 1.0842 - val_acc: 0.4089\n",
            "Epoch 2/150 - 0.16s - loss: 1.0678 - acc: 0.4492 - val_loss: 1.0718 - val_acc: 0.4291\n",
            "Epoch 3/150 - 0.17s - loss: 1.0562 - acc: 0.4640 - val_loss: 1.0624 - val_acc: 0.4494\n",
            "Epoch 4/150 - 0.17s - loss: 1.0462 - acc: 0.4746 - val_loss: 1.0545 - val_acc: 0.4595\n",
            "Epoch 5/150 - 0.23s - loss: 1.0374 - acc: 0.4768 - val_loss: 1.0488 - val_acc: 0.4757\n",
            "Epoch 6/150 - 0.14s - loss: 1.0315 - acc: 0.4766 - val_loss: 1.0454 - val_acc: 0.4777\n",
            "Epoch 7/150 - 0.14s - loss: 1.0230 - acc: 0.4836 - val_loss: 1.0376 - val_acc: 0.4960\n",
            "Epoch 8/150 - 0.15s - loss: 1.0157 - acc: 0.4930 - val_loss: 1.0322 - val_acc: 0.4960\n",
            "Epoch 9/150 - 0.17s - loss: 1.0108 - acc: 0.5018 - val_loss: 1.0309 - val_acc: 0.4838\n",
            "Epoch 10/150 - 0.16s - loss: 1.0051 - acc: 0.4955 - val_loss: 1.0237 - val_acc: 0.5061\n",
            "Epoch 11/150 - 0.14s - loss: 0.9945 - acc: 0.5119 - val_loss: 1.0158 - val_acc: 0.4980\n",
            "Epoch 12/150 - 0.15s - loss: 0.9916 - acc: 0.5115 - val_loss: 1.0139 - val_acc: 0.4939\n",
            "Epoch 13/150 - 0.19s - loss: 0.9840 - acc: 0.5198 - val_loss: 1.0077 - val_acc: 0.5000\n",
            "Epoch 14/150 - 0.14s - loss: 0.9796 - acc: 0.5259 - val_loss: 1.0050 - val_acc: 0.4960\n",
            "Epoch 15/150 - 0.15s - loss: 0.9698 - acc: 0.5344 - val_loss: 0.9953 - val_acc: 0.5182\n",
            "Epoch 16/150 - 0.15s - loss: 0.9649 - acc: 0.5367 - val_loss: 0.9915 - val_acc: 0.5364\n",
            "Epoch 17/150 - 0.17s - loss: 0.9588 - acc: 0.5423 - val_loss: 0.9871 - val_acc: 0.5304\n",
            "Epoch 18/150 - 0.15s - loss: 0.9567 - acc: 0.5445 - val_loss: 0.9861 - val_acc: 0.5182\n",
            "Epoch 19/150 - 0.18s - loss: 0.9541 - acc: 0.5409 - val_loss: 0.9866 - val_acc: 0.5344\n",
            "Epoch 20/150 - 0.18s - loss: 0.9475 - acc: 0.5452 - val_loss: 0.9794 - val_acc: 0.5223\n",
            "Epoch 21/150 - 0.20s - loss: 0.9460 - acc: 0.5468 - val_loss: 0.9803 - val_acc: 0.5445\n",
            "Epoch 22/150 - 0.16s - loss: 0.9365 - acc: 0.5540 - val_loss: 0.9721 - val_acc: 0.5304\n",
            "Epoch 23/150 - 0.15s - loss: 0.9330 - acc: 0.5544 - val_loss: 0.9692 - val_acc: 0.5445\n",
            "Epoch 24/150 - 0.10s - loss: 0.9284 - acc: 0.5580 - val_loss: 0.9675 - val_acc: 0.5385\n",
            "Epoch 25/150 - 0.09s - loss: 0.9252 - acc: 0.5628 - val_loss: 0.9648 - val_acc: 0.5263\n",
            "Epoch 26/150 - 0.10s - loss: 0.9216 - acc: 0.5661 - val_loss: 0.9630 - val_acc: 0.5223\n",
            "Epoch 27/150 - 0.09s - loss: 0.9183 - acc: 0.5650 - val_loss: 0.9603 - val_acc: 0.5628\n",
            "Epoch 28/150 - 0.08s - loss: 0.9190 - acc: 0.5652 - val_loss: 0.9675 - val_acc: 0.5425\n",
            "Epoch 29/150 - 0.10s - loss: 0.9175 - acc: 0.5722 - val_loss: 0.9625 - val_acc: 0.5749\n",
            "Epoch 30/150 - 0.09s - loss: 0.9096 - acc: 0.5729 - val_loss: 0.9564 - val_acc: 0.5688\n",
            "Epoch 31/150 - 0.09s - loss: 0.9085 - acc: 0.5695 - val_loss: 0.9598 - val_acc: 0.5607\n",
            "Epoch 32/150 - 0.10s - loss: 0.8990 - acc: 0.5796 - val_loss: 0.9506 - val_acc: 0.5628\n",
            "Epoch 33/150 - 0.08s - loss: 0.8978 - acc: 0.5738 - val_loss: 0.9480 - val_acc: 0.5587\n",
            "Epoch 34/150 - 0.08s - loss: 0.9034 - acc: 0.5787 - val_loss: 0.9564 - val_acc: 0.5607\n",
            "Epoch 35/150 - 0.09s - loss: 0.8932 - acc: 0.5787 - val_loss: 0.9502 - val_acc: 0.5547\n",
            "Epoch 36/150 - 0.08s - loss: 0.9051 - acc: 0.5682 - val_loss: 0.9577 - val_acc: 0.5547\n",
            "Epoch 37/150 - 0.10s - loss: 0.8827 - acc: 0.5924 - val_loss: 0.9461 - val_acc: 0.5567\n",
            "Epoch 38/150 - 0.11s - loss: 0.8874 - acc: 0.5857 - val_loss: 0.9536 - val_acc: 0.5445\n",
            "Epoch 39/150 - 0.11s - loss: 0.8777 - acc: 0.5911 - val_loss: 0.9425 - val_acc: 0.5526\n",
            "Epoch 40/150 - 0.10s - loss: 0.8711 - acc: 0.5911 - val_loss: 0.9373 - val_acc: 0.5769\n",
            "Epoch 41/150 - 0.09s - loss: 0.8785 - acc: 0.5866 - val_loss: 0.9435 - val_acc: 0.5688\n",
            "Epoch 42/150 - 0.10s - loss: 0.9168 - acc: 0.5587 - val_loss: 0.9952 - val_acc: 0.4960\n",
            "Epoch 43/150 - 0.10s - loss: 0.8677 - acc: 0.5985 - val_loss: 0.9434 - val_acc: 0.5789\n",
            "Epoch 44/150 - 0.10s - loss: 0.8677 - acc: 0.5996 - val_loss: 0.9442 - val_acc: 0.5769\n",
            "Epoch 45/150 - 0.09s - loss: 0.8611 - acc: 0.6003 - val_loss: 0.9382 - val_acc: 0.5810\n",
            "Epoch 46/150 - 0.09s - loss: 0.8525 - acc: 0.6048 - val_loss: 0.9341 - val_acc: 0.5668\n",
            "Epoch 47/150 - 0.09s - loss: 0.8524 - acc: 0.6048 - val_loss: 0.9345 - val_acc: 0.5688\n",
            "Epoch 48/150 - 0.09s - loss: 0.8614 - acc: 0.6082 - val_loss: 0.9502 - val_acc: 0.5567\n",
            "Epoch 49/150 - 0.09s - loss: 0.8458 - acc: 0.6104 - val_loss: 0.9344 - val_acc: 0.5668\n",
            "Epoch 50/150 - 0.09s - loss: 0.8426 - acc: 0.6131 - val_loss: 0.9377 - val_acc: 0.5749\n",
            "Epoch 51/150 - 0.08s - loss: 0.8386 - acc: 0.6192 - val_loss: 0.9376 - val_acc: 0.5810\n",
            "Epoch 52/150 - 0.09s - loss: 0.8455 - acc: 0.6118 - val_loss: 0.9447 - val_acc: 0.5405\n",
            "Epoch 53/150 - 0.10s - loss: 0.8446 - acc: 0.6095 - val_loss: 0.9475 - val_acc: 0.5385\n",
            "Epoch 54/150 - 0.09s - loss: 0.8297 - acc: 0.6224 - val_loss: 0.9317 - val_acc: 0.5769\n",
            "Epoch 55/150 - 0.09s - loss: 0.8292 - acc: 0.6260 - val_loss: 0.9373 - val_acc: 0.5769\n",
            "Epoch 56/150 - 0.11s - loss: 0.8369 - acc: 0.6131 - val_loss: 0.9395 - val_acc: 0.5769\n",
            "Epoch 57/150 - 0.09s - loss: 0.8242 - acc: 0.6201 - val_loss: 0.9364 - val_acc: 0.5648\n",
            "Epoch 58/150 - 0.09s - loss: 0.8499 - acc: 0.5985 - val_loss: 0.9625 - val_acc: 0.5283\n",
            "Epoch 59/150 - 0.11s - loss: 0.8161 - acc: 0.6338 - val_loss: 0.9315 - val_acc: 0.5789\n",
            "Epoch 60/150 - 0.09s - loss: 0.8145 - acc: 0.6296 - val_loss: 0.9341 - val_acc: 0.5729\n",
            "Epoch 61/150 - 0.08s - loss: 0.8581 - acc: 0.5956 - val_loss: 0.9869 - val_acc: 0.5000\n",
            "Epoch 62/150 - 0.09s - loss: 0.8082 - acc: 0.6430 - val_loss: 0.9339 - val_acc: 0.5769\n",
            "Epoch 63/150 - 0.09s - loss: 0.8173 - acc: 0.6298 - val_loss: 0.9496 - val_acc: 0.5385\n",
            "Epoch 64/150 - 0.09s - loss: 0.8159 - acc: 0.6226 - val_loss: 0.9457 - val_acc: 0.5466\n",
            "Epoch 65/150 - 0.09s - loss: 0.8052 - acc: 0.6437 - val_loss: 0.9365 - val_acc: 0.5830\n",
            "Epoch 66/150 - 0.09s - loss: 0.7993 - acc: 0.6426 - val_loss: 0.9284 - val_acc: 0.5931\n",
            "Epoch 67/150 - 0.09s - loss: 0.8243 - acc: 0.6287 - val_loss: 0.9608 - val_acc: 0.5385\n",
            "Epoch 68/150 - 0.10s - loss: 0.7957 - acc: 0.6466 - val_loss: 0.9315 - val_acc: 0.5850\n",
            "Epoch 69/150 - 0.09s - loss: 0.7904 - acc: 0.6536 - val_loss: 0.9327 - val_acc: 0.5749\n",
            "Epoch 70/150 - 0.08s - loss: 0.8037 - acc: 0.6399 - val_loss: 0.9566 - val_acc: 0.5364\n",
            "Epoch 71/150 - 0.09s - loss: 0.7881 - acc: 0.6511 - val_loss: 0.9334 - val_acc: 0.5850\n",
            "Epoch 72/150 - 0.09s - loss: 0.8009 - acc: 0.6399 - val_loss: 0.9595 - val_acc: 0.5304\n",
            "Epoch 73/150 - 0.08s - loss: 0.7840 - acc: 0.6541 - val_loss: 0.9379 - val_acc: 0.5830\n",
            "Epoch 74/150 - 0.09s - loss: 0.7789 - acc: 0.6570 - val_loss: 0.9367 - val_acc: 0.5648\n",
            "Epoch 75/150 - 0.08s - loss: 0.7904 - acc: 0.6457 - val_loss: 0.9476 - val_acc: 0.5709\n",
            "Epoch 76/150 - 0.08s - loss: 0.7847 - acc: 0.6520 - val_loss: 0.9541 - val_acc: 0.5547\n",
            "Epoch 77/150 - 0.09s - loss: 0.7728 - acc: 0.6604 - val_loss: 0.9477 - val_acc: 0.5648\n",
            "Epoch 78/150 - 0.09s - loss: 0.8218 - acc: 0.6131 - val_loss: 1.0043 - val_acc: 0.5020\n",
            "Epoch 79/150 - 0.08s - loss: 0.7848 - acc: 0.6478 - val_loss: 0.9490 - val_acc: 0.5729\n",
            "Epoch 80/150 - 0.10s - loss: 0.8029 - acc: 0.6374 - val_loss: 0.9633 - val_acc: 0.5709\n",
            "Epoch 81/150 - 0.09s - loss: 0.7781 - acc: 0.6525 - val_loss: 0.9676 - val_acc: 0.5486\n",
            "Epoch 82/150 - 0.08s - loss: 0.7990 - acc: 0.6392 - val_loss: 0.9670 - val_acc: 0.5607\n",
            "Epoch 83/150 - 0.09s - loss: 0.7585 - acc: 0.6685 - val_loss: 0.9465 - val_acc: 0.5648\n",
            "Epoch 84/150 - 0.08s - loss: 0.7659 - acc: 0.6622 - val_loss: 0.9524 - val_acc: 0.5668\n",
            "Epoch 85/150 - 0.08s - loss: 0.7738 - acc: 0.6545 - val_loss: 0.9722 - val_acc: 0.5364\n",
            "Epoch 86/150 - 0.09s - loss: 0.7625 - acc: 0.6570 - val_loss: 0.9487 - val_acc: 0.5769\n",
            "Epoch 87/150 - 0.08s - loss: 0.7880 - acc: 0.6448 - val_loss: 0.9801 - val_acc: 0.5445\n",
            "Epoch 88/150 - 0.09s - loss: 0.7542 - acc: 0.6725 - val_loss: 0.9500 - val_acc: 0.5709\n",
            "Epoch 89/150 - 0.09s - loss: 0.7401 - acc: 0.6768 - val_loss: 0.9432 - val_acc: 0.5648\n",
            "Epoch 90/150 - 0.09s - loss: 0.7419 - acc: 0.6743 - val_loss: 0.9526 - val_acc: 0.5567\n",
            "Epoch 91/150 - 0.08s - loss: 0.7366 - acc: 0.6804 - val_loss: 0.9460 - val_acc: 0.5628\n",
            "Epoch 92/150 - 0.10s - loss: 0.7678 - acc: 0.6520 - val_loss: 0.9893 - val_acc: 0.5263\n",
            "Epoch 93/150 - 0.09s - loss: 0.7364 - acc: 0.6802 - val_loss: 0.9497 - val_acc: 0.5567\n",
            "Epoch 94/150 - 0.08s - loss: 0.7368 - acc: 0.6806 - val_loss: 0.9484 - val_acc: 0.5709\n",
            "Epoch 95/150 - 0.09s - loss: 0.7456 - acc: 0.6709 - val_loss: 0.9548 - val_acc: 0.5688\n",
            "Epoch 96/150 - 0.09s - loss: 0.7411 - acc: 0.6799 - val_loss: 0.9576 - val_acc: 0.5769\n",
            "Epoch 97/150 - 0.09s - loss: 0.7334 - acc: 0.6817 - val_loss: 0.9646 - val_acc: 0.5567\n",
            "Epoch 98/150 - 0.09s - loss: 0.7135 - acc: 0.6961 - val_loss: 0.9422 - val_acc: 0.5709\n",
            "Epoch 99/150 - 0.09s - loss: 0.7749 - acc: 0.6415 - val_loss: 1.0248 - val_acc: 0.5081\n",
            "Epoch 100/150 - 0.10s - loss: 0.7621 - acc: 0.6561 - val_loss: 1.0112 - val_acc: 0.5263\n",
            "Epoch 101/150 - 0.10s - loss: 0.7198 - acc: 0.6930 - val_loss: 0.9629 - val_acc: 0.5506\n",
            "Epoch 102/150 - 0.09s - loss: 0.7156 - acc: 0.6883 - val_loss: 0.9653 - val_acc: 0.5385\n",
            "Epoch 103/150 - 0.09s - loss: 0.7361 - acc: 0.6694 - val_loss: 0.9919 - val_acc: 0.5324\n",
            "Epoch 104/150 - 0.10s - loss: 0.7173 - acc: 0.6925 - val_loss: 0.9532 - val_acc: 0.5749\n",
            "Epoch 105/150 - 0.09s - loss: 0.6963 - acc: 0.7056 - val_loss: 0.9472 - val_acc: 0.5607\n",
            "Epoch 106/150 - 0.09s - loss: 0.7172 - acc: 0.6883 - val_loss: 0.9755 - val_acc: 0.5324\n",
            "Epoch 107/150 - 0.10s - loss: 0.6917 - acc: 0.7029 - val_loss: 0.9599 - val_acc: 0.5567\n",
            "Epoch 108/150 - 0.09s - loss: 0.6984 - acc: 0.7011 - val_loss: 0.9501 - val_acc: 0.5709\n",
            "Epoch 109/150 - 0.09s - loss: 0.6979 - acc: 0.7045 - val_loss: 0.9594 - val_acc: 0.5607\n",
            "Epoch 110/150 - 0.10s - loss: 0.6889 - acc: 0.7081 - val_loss: 0.9517 - val_acc: 0.5810\n",
            "Epoch 111/150 - 0.09s - loss: 0.6957 - acc: 0.7000 - val_loss: 0.9554 - val_acc: 0.5607\n",
            "Epoch 112/150 - 0.09s - loss: 0.6753 - acc: 0.7143 - val_loss: 0.9523 - val_acc: 0.5709\n",
            "Epoch 113/150 - 0.10s - loss: 0.6714 - acc: 0.7222 - val_loss: 0.9526 - val_acc: 0.5445\n",
            "Epoch 114/150 - 0.10s - loss: 0.6930 - acc: 0.7065 - val_loss: 0.9749 - val_acc: 0.5486\n",
            "Epoch 115/150 - 0.09s - loss: 0.6637 - acc: 0.7285 - val_loss: 0.9436 - val_acc: 0.5648\n",
            "Epoch 116/150 - 0.11s - loss: 0.6708 - acc: 0.7173 - val_loss: 0.9670 - val_acc: 0.5405\n",
            "Epoch 117/150 - 0.09s - loss: 0.6780 - acc: 0.7130 - val_loss: 0.9626 - val_acc: 0.5628\n",
            "Epoch 118/150 - 0.09s - loss: 0.6787 - acc: 0.7110 - val_loss: 0.9754 - val_acc: 0.5547\n",
            "Epoch 119/150 - 0.09s - loss: 0.7104 - acc: 0.6930 - val_loss: 1.0164 - val_acc: 0.5304\n",
            "Epoch 120/150 - 0.09s - loss: 0.6494 - acc: 0.7384 - val_loss: 0.9451 - val_acc: 0.5607\n",
            "Epoch 121/150 - 0.09s - loss: 0.6499 - acc: 0.7348 - val_loss: 0.9518 - val_acc: 0.5567\n",
            "Epoch 122/150 - 0.09s - loss: 0.6490 - acc: 0.7346 - val_loss: 0.9671 - val_acc: 0.5466\n",
            "Epoch 123/150 - 0.09s - loss: 0.6832 - acc: 0.7060 - val_loss: 1.0106 - val_acc: 0.5344\n",
            "Epoch 124/150 - 0.09s - loss: 0.6785 - acc: 0.7013 - val_loss: 0.9794 - val_acc: 0.5810\n",
            "Epoch 125/150 - 0.09s - loss: 0.6616 - acc: 0.7108 - val_loss: 0.9897 - val_acc: 0.5425\n",
            "Epoch 126/150 - 0.08s - loss: 0.6843 - acc: 0.7013 - val_loss: 0.9902 - val_acc: 0.5789\n",
            "Epoch 127/150 - 0.09s - loss: 0.6556 - acc: 0.7308 - val_loss: 0.9950 - val_acc: 0.5324\n",
            "Epoch 128/150 - 0.10s - loss: 0.6362 - acc: 0.7391 - val_loss: 0.9624 - val_acc: 0.5709\n",
            "Epoch 129/150 - 0.09s - loss: 0.6211 - acc: 0.7517 - val_loss: 0.9578 - val_acc: 0.5769\n",
            "Epoch 130/150 - 0.09s - loss: 0.6190 - acc: 0.7584 - val_loss: 0.9489 - val_acc: 0.5648\n",
            "Epoch 131/150 - 0.09s - loss: 0.7806 - acc: 0.6408 - val_loss: 1.1138 - val_acc: 0.5162\n",
            "Epoch 132/150 - 0.09s - loss: 0.6805 - acc: 0.6905 - val_loss: 1.0345 - val_acc: 0.5202\n",
            "Epoch 133/150 - 0.09s - loss: 0.6421 - acc: 0.7299 - val_loss: 0.9818 - val_acc: 0.5668\n",
            "Epoch 134/150 - 0.10s - loss: 0.7308 - acc: 0.6617 - val_loss: 1.0668 - val_acc: 0.5506\n",
            "Epoch 135/150 - 0.09s - loss: 0.6736 - acc: 0.7135 - val_loss: 1.0126 - val_acc: 0.5648\n",
            "Epoch 136/150 - 0.09s - loss: 0.6167 - acc: 0.7526 - val_loss: 0.9859 - val_acc: 0.5466\n",
            "Epoch 137/150 - 0.09s - loss: 0.5978 - acc: 0.7614 - val_loss: 0.9619 - val_acc: 0.5668\n",
            "Epoch 138/150 - 0.09s - loss: 0.6538 - acc: 0.7146 - val_loss: 1.0526 - val_acc: 0.5324\n",
            "Epoch 139/150 - 0.08s - loss: 0.6372 - acc: 0.7303 - val_loss: 0.9985 - val_acc: 0.5628\n",
            "Epoch 140/150 - 0.10s - loss: 0.5791 - acc: 0.7796 - val_loss: 0.9548 - val_acc: 0.5628\n",
            "Epoch 141/150 - 0.09s - loss: 0.6136 - acc: 0.7382 - val_loss: 1.0097 - val_acc: 0.5324\n",
            "Epoch 142/150 - 0.09s - loss: 0.5727 - acc: 0.7791 - val_loss: 0.9705 - val_acc: 0.5385\n",
            "Epoch 143/150 - 0.09s - loss: 0.5890 - acc: 0.7672 - val_loss: 0.9703 - val_acc: 0.5729\n",
            "Epoch 144/150 - 0.09s - loss: 0.6006 - acc: 0.7503 - val_loss: 1.0105 - val_acc: 0.5243\n",
            "Epoch 145/150 - 0.09s - loss: 0.7178 - acc: 0.6779 - val_loss: 1.0927 - val_acc: 0.5223\n",
            "Epoch 146/150 - 0.09s - loss: 0.5669 - acc: 0.7848 - val_loss: 0.9815 - val_acc: 0.5506\n",
            "Epoch 147/150 - 0.09s - loss: 0.6427 - acc: 0.7078 - val_loss: 1.0270 - val_acc: 0.5567\n",
            "Epoch 148/150 - 0.09s - loss: 0.5754 - acc: 0.7699 - val_loss: 0.9936 - val_acc: 0.5547\n",
            "Epoch 149/150 - 0.09s - loss: 0.6027 - acc: 0.7389 - val_loss: 1.0274 - val_acc: 0.5364\n",
            "Epoch 150/150 - 0.08s - loss: 0.5469 - acc: 0.7899 - val_loss: 0.9799 - val_acc: 0.5405\n",
            "\n",
            "Combination 76/252:\n",
            "Hidden Layers: [128, 128], Activation: relu, Learning Rate: 0.01, Batch Size: 64, Epochs: 50\n",
            "Epoch 1/50 - 0.06s - loss: 1.0947 - acc: 0.3664 - val_loss: 1.0971 - val_acc: 0.3543\n",
            "Epoch 2/50 - 0.06s - loss: 1.0862 - acc: 0.4076 - val_loss: 1.0903 - val_acc: 0.3846\n",
            "Epoch 3/50 - 0.07s - loss: 1.0798 - acc: 0.4294 - val_loss: 1.0849 - val_acc: 0.3866\n",
            "Epoch 4/50 - 0.06s - loss: 1.0738 - acc: 0.4372 - val_loss: 1.0791 - val_acc: 0.4312\n",
            "Epoch 5/50 - 0.06s - loss: 1.0682 - acc: 0.4528 - val_loss: 1.0750 - val_acc: 0.4312\n",
            "Epoch 6/50 - 0.07s - loss: 1.0635 - acc: 0.4568 - val_loss: 1.0716 - val_acc: 0.4352\n",
            "Epoch 7/50 - 0.06s - loss: 1.0593 - acc: 0.4575 - val_loss: 1.0683 - val_acc: 0.4393\n",
            "Epoch 8/50 - 0.06s - loss: 1.0554 - acc: 0.4573 - val_loss: 1.0651 - val_acc: 0.4636\n",
            "Epoch 9/50 - 0.06s - loss: 1.0517 - acc: 0.4582 - val_loss: 1.0627 - val_acc: 0.4676\n",
            "Epoch 10/50 - 0.07s - loss: 1.0481 - acc: 0.4645 - val_loss: 1.0604 - val_acc: 0.4636\n",
            "Epoch 11/50 - 0.08s - loss: 1.0448 - acc: 0.4717 - val_loss: 1.0581 - val_acc: 0.4595\n",
            "Epoch 12/50 - 0.06s - loss: 1.0422 - acc: 0.4669 - val_loss: 1.0572 - val_acc: 0.4636\n",
            "Epoch 13/50 - 0.06s - loss: 1.0397 - acc: 0.4692 - val_loss: 1.0538 - val_acc: 0.4737\n",
            "Epoch 14/50 - 0.07s - loss: 1.0362 - acc: 0.4786 - val_loss: 1.0526 - val_acc: 0.4676\n",
            "Epoch 15/50 - 0.06s - loss: 1.0330 - acc: 0.4782 - val_loss: 1.0508 - val_acc: 0.4818\n",
            "Epoch 16/50 - 0.06s - loss: 1.0299 - acc: 0.4858 - val_loss: 1.0483 - val_acc: 0.4717\n",
            "Epoch 17/50 - 0.06s - loss: 1.0284 - acc: 0.4813 - val_loss: 1.0476 - val_acc: 0.4838\n",
            "Epoch 18/50 - 0.08s - loss: 1.0257 - acc: 0.4849 - val_loss: 1.0468 - val_acc: 0.4879\n",
            "Epoch 19/50 - 0.06s - loss: 1.0236 - acc: 0.4870 - val_loss: 1.0457 - val_acc: 0.4818\n",
            "Epoch 20/50 - 0.06s - loss: 1.0188 - acc: 0.4944 - val_loss: 1.0402 - val_acc: 0.4858\n",
            "Epoch 21/50 - 0.06s - loss: 1.0169 - acc: 0.4944 - val_loss: 1.0402 - val_acc: 0.4899\n",
            "Epoch 22/50 - 0.07s - loss: 1.0128 - acc: 0.5013 - val_loss: 1.0362 - val_acc: 0.4980\n",
            "Epoch 23/50 - 0.06s - loss: 1.0101 - acc: 0.5025 - val_loss: 1.0351 - val_acc: 0.5061\n",
            "Epoch 24/50 - 0.06s - loss: 1.0073 - acc: 0.5067 - val_loss: 1.0330 - val_acc: 0.5061\n",
            "Epoch 25/50 - 0.06s - loss: 1.0049 - acc: 0.5065 - val_loss: 1.0311 - val_acc: 0.5061\n",
            "Epoch 26/50 - 0.07s - loss: 1.0015 - acc: 0.5094 - val_loss: 1.0286 - val_acc: 0.5101\n",
            "Epoch 27/50 - 0.06s - loss: 0.9996 - acc: 0.5126 - val_loss: 1.0270 - val_acc: 0.5081\n",
            "Epoch 28/50 - 0.06s - loss: 0.9978 - acc: 0.5139 - val_loss: 1.0265 - val_acc: 0.4939\n",
            "Epoch 29/50 - 0.06s - loss: 0.9934 - acc: 0.5173 - val_loss: 1.0223 - val_acc: 0.5162\n",
            "Epoch 30/50 - 0.07s - loss: 0.9911 - acc: 0.5207 - val_loss: 1.0203 - val_acc: 0.5162\n",
            "Epoch 31/50 - 0.07s - loss: 0.9880 - acc: 0.5223 - val_loss: 1.0179 - val_acc: 0.5182\n",
            "Epoch 32/50 - 0.07s - loss: 0.9863 - acc: 0.5234 - val_loss: 1.0161 - val_acc: 0.5121\n",
            "Epoch 33/50 - 0.06s - loss: 0.9867 - acc: 0.5189 - val_loss: 1.0188 - val_acc: 0.5061\n",
            "Epoch 34/50 - 0.08s - loss: 0.9803 - acc: 0.5297 - val_loss: 1.0118 - val_acc: 0.5223\n",
            "Epoch 35/50 - 0.07s - loss: 0.9821 - acc: 0.5236 - val_loss: 1.0119 - val_acc: 0.5263\n",
            "Epoch 36/50 - 0.07s - loss: 0.9755 - acc: 0.5326 - val_loss: 1.0081 - val_acc: 0.5304\n",
            "Epoch 37/50 - 0.07s - loss: 0.9741 - acc: 0.5310 - val_loss: 1.0061 - val_acc: 0.5223\n",
            "Epoch 38/50 - 0.07s - loss: 0.9709 - acc: 0.5349 - val_loss: 1.0040 - val_acc: 0.5182\n",
            "Epoch 39/50 - 0.06s - loss: 0.9725 - acc: 0.5360 - val_loss: 1.0081 - val_acc: 0.5304\n",
            "Epoch 40/50 - 0.06s - loss: 0.9664 - acc: 0.5396 - val_loss: 1.0007 - val_acc: 0.5223\n",
            "Epoch 41/50 - 0.06s - loss: 0.9634 - acc: 0.5418 - val_loss: 0.9978 - val_acc: 0.5202\n",
            "Epoch 42/50 - 0.07s - loss: 0.9643 - acc: 0.5405 - val_loss: 0.9977 - val_acc: 0.5243\n",
            "Epoch 43/50 - 0.06s - loss: 0.9611 - acc: 0.5403 - val_loss: 0.9954 - val_acc: 0.5243\n",
            "Epoch 44/50 - 0.06s - loss: 0.9579 - acc: 0.5466 - val_loss: 0.9926 - val_acc: 0.5223\n",
            "Epoch 45/50 - 0.06s - loss: 0.9561 - acc: 0.5439 - val_loss: 0.9913 - val_acc: 0.5243\n",
            "Epoch 46/50 - 0.07s - loss: 0.9563 - acc: 0.5425 - val_loss: 0.9933 - val_acc: 0.5263\n",
            "Epoch 47/50 - 0.06s - loss: 0.9575 - acc: 0.5407 - val_loss: 0.9956 - val_acc: 0.5283\n",
            "Epoch 48/50 - 0.06s - loss: 0.9522 - acc: 0.5450 - val_loss: 0.9895 - val_acc: 0.5324\n",
            "Epoch 49/50 - 0.06s - loss: 0.9473 - acc: 0.5470 - val_loss: 0.9858 - val_acc: 0.5283\n",
            "Epoch 50/50 - 0.07s - loss: 0.9487 - acc: 0.5468 - val_loss: 0.9882 - val_acc: 0.5344\n",
            "\n",
            "Combination 77/252:\n",
            "Hidden Layers: [128, 128], Activation: relu, Learning Rate: 0.01, Batch Size: 64, Epochs: 100\n",
            "Epoch 1/100 - 0.06s - loss: 1.0899 - acc: 0.3929 - val_loss: 1.0906 - val_acc: 0.3826\n",
            "Epoch 2/100 - 0.06s - loss: 1.0801 - acc: 0.4278 - val_loss: 1.0832 - val_acc: 0.3927\n",
            "Epoch 3/100 - 0.06s - loss: 1.0740 - acc: 0.4071 - val_loss: 1.0794 - val_acc: 0.4251\n",
            "Epoch 4/100 - 0.07s - loss: 1.0663 - acc: 0.4573 - val_loss: 1.0721 - val_acc: 0.4534\n",
            "Epoch 5/100 - 0.06s - loss: 1.0611 - acc: 0.4642 - val_loss: 1.0681 - val_acc: 0.4514\n",
            "Epoch 6/100 - 0.06s - loss: 1.0561 - acc: 0.4726 - val_loss: 1.0637 - val_acc: 0.4656\n",
            "Epoch 7/100 - 0.06s - loss: 1.0519 - acc: 0.4723 - val_loss: 1.0595 - val_acc: 0.4696\n",
            "Epoch 8/100 - 0.07s - loss: 1.0489 - acc: 0.4737 - val_loss: 1.0585 - val_acc: 0.4656\n",
            "Epoch 9/100 - 0.07s - loss: 1.0448 - acc: 0.4708 - val_loss: 1.0533 - val_acc: 0.4575\n",
            "Epoch 10/100 - 0.06s - loss: 1.0412 - acc: 0.4753 - val_loss: 1.0506 - val_acc: 0.4798\n",
            "Epoch 11/100 - 0.06s - loss: 1.0365 - acc: 0.4912 - val_loss: 1.0488 - val_acc: 0.4960\n",
            "Epoch 12/100 - 0.07s - loss: 1.0333 - acc: 0.4928 - val_loss: 1.0468 - val_acc: 0.4818\n",
            "Epoch 13/100 - 0.07s - loss: 1.0297 - acc: 0.4960 - val_loss: 1.0446 - val_acc: 0.4838\n",
            "Epoch 14/100 - 0.07s - loss: 1.0279 - acc: 0.4883 - val_loss: 1.0417 - val_acc: 0.4798\n",
            "Epoch 15/100 - 0.07s - loss: 1.0232 - acc: 0.5038 - val_loss: 1.0409 - val_acc: 0.4939\n",
            "Epoch 16/100 - 0.08s - loss: 1.0203 - acc: 0.4969 - val_loss: 1.0375 - val_acc: 0.5020\n",
            "Epoch 17/100 - 0.06s - loss: 1.0176 - acc: 0.5099 - val_loss: 1.0381 - val_acc: 0.4939\n",
            "Epoch 18/100 - 0.06s - loss: 1.0141 - acc: 0.5047 - val_loss: 1.0346 - val_acc: 0.5000\n",
            "Epoch 19/100 - 0.06s - loss: 1.0099 - acc: 0.5153 - val_loss: 1.0310 - val_acc: 0.5081\n",
            "Epoch 20/100 - 0.07s - loss: 1.0063 - acc: 0.5175 - val_loss: 1.0282 - val_acc: 0.5162\n",
            "Epoch 21/100 - 0.07s - loss: 1.0032 - acc: 0.5169 - val_loss: 1.0256 - val_acc: 0.5223\n",
            "Epoch 22/100 - 0.06s - loss: 1.0002 - acc: 0.5207 - val_loss: 1.0235 - val_acc: 0.5283\n",
            "Epoch 23/100 - 0.06s - loss: 0.9970 - acc: 0.5223 - val_loss: 1.0219 - val_acc: 0.5263\n",
            "Epoch 24/100 - 0.07s - loss: 0.9938 - acc: 0.5259 - val_loss: 1.0199 - val_acc: 0.5324\n",
            "Epoch 25/100 - 0.07s - loss: 0.9926 - acc: 0.5254 - val_loss: 1.0212 - val_acc: 0.5061\n",
            "Epoch 26/100 - 0.08s - loss: 0.9894 - acc: 0.5270 - val_loss: 1.0177 - val_acc: 0.5121\n",
            "Epoch 27/100 - 0.06s - loss: 0.9846 - acc: 0.5292 - val_loss: 1.0124 - val_acc: 0.5304\n",
            "Epoch 28/100 - 0.07s - loss: 0.9854 - acc: 0.5299 - val_loss: 1.0150 - val_acc: 0.5182\n",
            "Epoch 29/100 - 0.08s - loss: 0.9790 - acc: 0.5362 - val_loss: 1.0099 - val_acc: 0.5263\n",
            "Epoch 30/100 - 0.16s - loss: 0.9774 - acc: 0.5362 - val_loss: 1.0089 - val_acc: 0.5182\n",
            "Epoch 31/100 - 0.08s - loss: 0.9753 - acc: 0.5322 - val_loss: 1.0059 - val_acc: 0.5162\n",
            "Epoch 32/100 - 0.07s - loss: 0.9768 - acc: 0.5270 - val_loss: 1.0116 - val_acc: 0.5101\n",
            "Epoch 33/100 - 0.07s - loss: 0.9678 - acc: 0.5436 - val_loss: 1.0009 - val_acc: 0.5344\n",
            "Epoch 34/100 - 0.07s - loss: 0.9666 - acc: 0.5484 - val_loss: 1.0010 - val_acc: 0.5263\n",
            "Epoch 35/100 - 0.07s - loss: 0.9669 - acc: 0.5463 - val_loss: 1.0008 - val_acc: 0.5405\n",
            "Epoch 36/100 - 0.06s - loss: 0.9626 - acc: 0.5497 - val_loss: 0.9976 - val_acc: 0.5283\n",
            "Epoch 37/100 - 0.07s - loss: 0.9601 - acc: 0.5443 - val_loss: 0.9978 - val_acc: 0.5385\n",
            "Epoch 38/100 - 0.07s - loss: 0.9550 - acc: 0.5520 - val_loss: 0.9922 - val_acc: 0.5385\n",
            "Epoch 39/100 - 0.06s - loss: 0.9526 - acc: 0.5508 - val_loss: 0.9891 - val_acc: 0.5385\n",
            "Epoch 40/100 - 0.06s - loss: 0.9510 - acc: 0.5538 - val_loss: 0.9885 - val_acc: 0.5425\n",
            "Epoch 41/100 - 0.07s - loss: 0.9485 - acc: 0.5560 - val_loss: 0.9880 - val_acc: 0.5425\n",
            "Epoch 42/100 - 0.07s - loss: 0.9480 - acc: 0.5538 - val_loss: 0.9892 - val_acc: 0.5486\n",
            "Epoch 43/100 - 0.07s - loss: 0.9509 - acc: 0.5531 - val_loss: 0.9914 - val_acc: 0.5445\n",
            "Epoch 44/100 - 0.07s - loss: 0.9428 - acc: 0.5583 - val_loss: 0.9817 - val_acc: 0.5405\n",
            "Epoch 45/100 - 0.08s - loss: 0.9419 - acc: 0.5571 - val_loss: 0.9809 - val_acc: 0.5506\n",
            "Epoch 46/100 - 0.06s - loss: 0.9377 - acc: 0.5641 - val_loss: 0.9792 - val_acc: 0.5607\n",
            "Epoch 47/100 - 0.07s - loss: 0.9359 - acc: 0.5628 - val_loss: 0.9792 - val_acc: 0.5344\n",
            "Epoch 48/100 - 0.06s - loss: 0.9343 - acc: 0.5619 - val_loss: 0.9790 - val_acc: 0.5587\n",
            "Epoch 49/100 - 0.07s - loss: 0.9303 - acc: 0.5668 - val_loss: 0.9750 - val_acc: 0.5607\n",
            "Epoch 50/100 - 0.06s - loss: 0.9322 - acc: 0.5650 - val_loss: 0.9795 - val_acc: 0.5243\n",
            "Epoch 51/100 - 0.06s - loss: 0.9320 - acc: 0.5569 - val_loss: 0.9810 - val_acc: 0.5425\n",
            "Epoch 52/100 - 0.07s - loss: 0.9295 - acc: 0.5657 - val_loss: 0.9742 - val_acc: 0.5729\n",
            "Epoch 53/100 - 0.08s - loss: 0.9260 - acc: 0.5670 - val_loss: 0.9754 - val_acc: 0.5324\n",
            "Epoch 54/100 - 0.07s - loss: 0.9271 - acc: 0.5693 - val_loss: 0.9736 - val_acc: 0.5688\n",
            "Epoch 55/100 - 0.06s - loss: 0.9199 - acc: 0.5691 - val_loss: 0.9705 - val_acc: 0.5628\n",
            "Epoch 56/100 - 0.07s - loss: 0.9210 - acc: 0.5659 - val_loss: 0.9680 - val_acc: 0.5587\n",
            "Epoch 57/100 - 0.07s - loss: 0.9200 - acc: 0.5726 - val_loss: 0.9729 - val_acc: 0.5648\n",
            "Epoch 58/100 - 0.07s - loss: 0.9150 - acc: 0.5765 - val_loss: 0.9650 - val_acc: 0.5668\n",
            "Epoch 59/100 - 0.07s - loss: 0.9126 - acc: 0.5724 - val_loss: 0.9647 - val_acc: 0.5405\n",
            "Epoch 60/100 - 0.07s - loss: 0.9131 - acc: 0.5693 - val_loss: 0.9654 - val_acc: 0.5364\n",
            "Epoch 61/100 - 0.08s - loss: 0.9146 - acc: 0.5697 - val_loss: 0.9681 - val_acc: 0.5324\n",
            "Epoch 62/100 - 0.07s - loss: 0.9075 - acc: 0.5765 - val_loss: 0.9619 - val_acc: 0.5526\n",
            "Epoch 63/100 - 0.06s - loss: 0.9161 - acc: 0.5704 - val_loss: 0.9672 - val_acc: 0.5668\n",
            "Epoch 64/100 - 0.06s - loss: 0.9064 - acc: 0.5776 - val_loss: 0.9654 - val_acc: 0.5364\n",
            "Epoch 65/100 - 0.07s - loss: 0.9050 - acc: 0.5846 - val_loss: 0.9615 - val_acc: 0.5688\n",
            "Epoch 66/100 - 0.06s - loss: 0.9135 - acc: 0.5594 - val_loss: 0.9669 - val_acc: 0.5405\n",
            "Epoch 67/100 - 0.06s - loss: 0.9002 - acc: 0.5832 - val_loss: 0.9588 - val_acc: 0.5628\n",
            "Epoch 68/100 - 0.06s - loss: 0.9225 - acc: 0.5625 - val_loss: 0.9745 - val_acc: 0.5506\n",
            "Epoch 69/100 - 0.07s - loss: 0.8945 - acc: 0.5810 - val_loss: 0.9574 - val_acc: 0.5526\n",
            "Epoch 70/100 - 0.07s - loss: 0.8947 - acc: 0.5843 - val_loss: 0.9573 - val_acc: 0.5405\n",
            "Epoch 71/100 - 0.06s - loss: 0.8922 - acc: 0.5873 - val_loss: 0.9535 - val_acc: 0.5607\n",
            "Epoch 72/100 - 0.06s - loss: 0.8889 - acc: 0.5868 - val_loss: 0.9534 - val_acc: 0.5547\n",
            "Epoch 73/100 - 0.07s - loss: 0.8902 - acc: 0.5834 - val_loss: 0.9553 - val_acc: 0.5445\n",
            "Epoch 74/100 - 0.06s - loss: 0.8890 - acc: 0.5859 - val_loss: 0.9566 - val_acc: 0.5385\n",
            "Epoch 75/100 - 0.07s - loss: 0.8850 - acc: 0.5886 - val_loss: 0.9518 - val_acc: 0.5526\n",
            "Epoch 76/100 - 0.08s - loss: 0.8851 - acc: 0.5855 - val_loss: 0.9537 - val_acc: 0.5405\n",
            "Epoch 77/100 - 0.10s - loss: 0.8838 - acc: 0.5893 - val_loss: 0.9549 - val_acc: 0.5709\n",
            "Epoch 78/100 - 0.09s - loss: 0.8956 - acc: 0.5774 - val_loss: 0.9714 - val_acc: 0.5263\n",
            "Epoch 79/100 - 0.09s - loss: 0.8888 - acc: 0.5834 - val_loss: 0.9616 - val_acc: 0.5304\n",
            "Epoch 80/100 - 0.09s - loss: 0.8790 - acc: 0.5969 - val_loss: 0.9490 - val_acc: 0.5688\n",
            "Epoch 81/100 - 0.08s - loss: 0.8939 - acc: 0.5776 - val_loss: 0.9743 - val_acc: 0.5324\n",
            "Epoch 82/100 - 0.08s - loss: 0.8754 - acc: 0.5940 - val_loss: 0.9493 - val_acc: 0.5385\n",
            "Epoch 83/100 - 0.08s - loss: 0.8797 - acc: 0.5897 - val_loss: 0.9513 - val_acc: 0.5628\n",
            "Epoch 84/100 - 0.09s - loss: 0.8841 - acc: 0.6028 - val_loss: 0.9586 - val_acc: 0.5506\n",
            "Epoch 85/100 - 0.07s - loss: 0.8737 - acc: 0.5900 - val_loss: 0.9541 - val_acc: 0.5425\n",
            "Epoch 86/100 - 0.07s - loss: 0.8883 - acc: 0.5776 - val_loss: 0.9650 - val_acc: 0.5263\n",
            "Epoch 87/100 - 0.08s - loss: 0.8725 - acc: 0.5931 - val_loss: 0.9482 - val_acc: 0.5628\n",
            "Epoch 88/100 - 0.07s - loss: 0.8645 - acc: 0.5954 - val_loss: 0.9458 - val_acc: 0.5587\n",
            "Epoch 89/100 - 0.07s - loss: 0.8751 - acc: 0.5857 - val_loss: 0.9552 - val_acc: 0.5324\n",
            "Epoch 90/100 - 0.08s - loss: 0.8692 - acc: 0.5922 - val_loss: 0.9521 - val_acc: 0.5283\n",
            "Epoch 91/100 - 0.07s - loss: 0.8756 - acc: 0.5904 - val_loss: 0.9661 - val_acc: 0.5385\n",
            "Epoch 92/100 - 0.07s - loss: 0.8701 - acc: 0.5929 - val_loss: 0.9614 - val_acc: 0.5526\n",
            "Epoch 93/100 - 0.07s - loss: 0.8634 - acc: 0.6017 - val_loss: 0.9465 - val_acc: 0.5668\n",
            "Epoch 94/100 - 0.07s - loss: 0.9001 - acc: 0.5911 - val_loss: 0.9784 - val_acc: 0.5709\n",
            "Epoch 95/100 - 0.06s - loss: 0.8784 - acc: 0.5852 - val_loss: 0.9594 - val_acc: 0.5486\n",
            "Epoch 96/100 - 0.07s - loss: 0.8532 - acc: 0.6059 - val_loss: 0.9435 - val_acc: 0.5729\n",
            "Epoch 97/100 - 0.07s - loss: 0.8517 - acc: 0.6118 - val_loss: 0.9461 - val_acc: 0.5688\n",
            "Epoch 98/100 - 0.07s - loss: 0.8523 - acc: 0.6050 - val_loss: 0.9434 - val_acc: 0.5506\n",
            "Epoch 99/100 - 0.07s - loss: 0.8766 - acc: 0.6032 - val_loss: 0.9631 - val_acc: 0.5628\n",
            "Epoch 100/100 - 0.07s - loss: 0.8498 - acc: 0.6104 - val_loss: 0.9480 - val_acc: 0.5607\n",
            "\n",
            "Combination 78/252:\n",
            "Hidden Layers: [128, 128], Activation: relu, Learning Rate: 0.01, Batch Size: 64, Epochs: 150\n",
            "Epoch 1/150 - 0.07s - loss: 1.0823 - acc: 0.4132 - val_loss: 1.0863 - val_acc: 0.3947\n",
            "Epoch 2/150 - 0.07s - loss: 1.0751 - acc: 0.4345 - val_loss: 1.0802 - val_acc: 0.4109\n",
            "Epoch 3/150 - 0.07s - loss: 1.0690 - acc: 0.4460 - val_loss: 1.0758 - val_acc: 0.4170\n",
            "Epoch 4/150 - 0.08s - loss: 1.0638 - acc: 0.4512 - val_loss: 1.0714 - val_acc: 0.4291\n",
            "Epoch 5/150 - 0.07s - loss: 1.0590 - acc: 0.4611 - val_loss: 1.0681 - val_acc: 0.4332\n",
            "Epoch 6/150 - 0.07s - loss: 1.0549 - acc: 0.4656 - val_loss: 1.0662 - val_acc: 0.4251\n",
            "Epoch 7/150 - 0.07s - loss: 1.0507 - acc: 0.4717 - val_loss: 1.0629 - val_acc: 0.4372\n",
            "Epoch 8/150 - 0.07s - loss: 1.0469 - acc: 0.4741 - val_loss: 1.0599 - val_acc: 0.4514\n",
            "Epoch 9/150 - 0.07s - loss: 1.0434 - acc: 0.4701 - val_loss: 1.0582 - val_acc: 0.4534\n",
            "Epoch 10/150 - 0.07s - loss: 1.0397 - acc: 0.4789 - val_loss: 1.0552 - val_acc: 0.4514\n",
            "Epoch 11/150 - 0.07s - loss: 1.0364 - acc: 0.4795 - val_loss: 1.0537 - val_acc: 0.4534\n",
            "Epoch 12/150 - 0.07s - loss: 1.0328 - acc: 0.4829 - val_loss: 1.0508 - val_acc: 0.4555\n",
            "Epoch 13/150 - 0.07s - loss: 1.0296 - acc: 0.4894 - val_loss: 1.0482 - val_acc: 0.4595\n",
            "Epoch 14/150 - 0.07s - loss: 1.0272 - acc: 0.4892 - val_loss: 1.0486 - val_acc: 0.4615\n",
            "Epoch 15/150 - 0.07s - loss: 1.0229 - acc: 0.4917 - val_loss: 1.0448 - val_acc: 0.4777\n",
            "Epoch 16/150 - 0.07s - loss: 1.0195 - acc: 0.4984 - val_loss: 1.0420 - val_acc: 0.4899\n",
            "Epoch 17/150 - 0.06s - loss: 1.0167 - acc: 0.5029 - val_loss: 1.0394 - val_acc: 0.4838\n",
            "Epoch 18/150 - 0.07s - loss: 1.0131 - acc: 0.5058 - val_loss: 1.0372 - val_acc: 0.4858\n",
            "Epoch 19/150 - 0.07s - loss: 1.0100 - acc: 0.5085 - val_loss: 1.0346 - val_acc: 0.4858\n",
            "Epoch 20/150 - 0.07s - loss: 1.0074 - acc: 0.5070 - val_loss: 1.0339 - val_acc: 0.4919\n",
            "Epoch 21/150 - 0.06s - loss: 1.0042 - acc: 0.5130 - val_loss: 1.0315 - val_acc: 0.5000\n",
            "Epoch 22/150 - 0.07s - loss: 1.0008 - acc: 0.5169 - val_loss: 1.0273 - val_acc: 0.5000\n",
            "Epoch 23/150 - 0.07s - loss: 1.0034 - acc: 0.5022 - val_loss: 1.0285 - val_acc: 0.4939\n",
            "Epoch 24/150 - 0.06s - loss: 0.9947 - acc: 0.5241 - val_loss: 1.0229 - val_acc: 0.5121\n",
            "Epoch 25/150 - 0.06s - loss: 0.9915 - acc: 0.5216 - val_loss: 1.0211 - val_acc: 0.5142\n",
            "Epoch 26/150 - 0.07s - loss: 0.9893 - acc: 0.5247 - val_loss: 1.0184 - val_acc: 0.5142\n",
            "Epoch 27/150 - 0.06s - loss: 0.9856 - acc: 0.5265 - val_loss: 1.0165 - val_acc: 0.5182\n",
            "Epoch 28/150 - 0.06s - loss: 0.9830 - acc: 0.5297 - val_loss: 1.0132 - val_acc: 0.5182\n",
            "Epoch 29/150 - 0.06s - loss: 0.9816 - acc: 0.5268 - val_loss: 1.0145 - val_acc: 0.5101\n",
            "Epoch 30/150 - 0.07s - loss: 0.9768 - acc: 0.5308 - val_loss: 1.0088 - val_acc: 0.5182\n",
            "Epoch 31/150 - 0.06s - loss: 0.9742 - acc: 0.5331 - val_loss: 1.0062 - val_acc: 0.5223\n",
            "Epoch 32/150 - 0.06s - loss: 0.9731 - acc: 0.5340 - val_loss: 1.0058 - val_acc: 0.5263\n",
            "Epoch 33/150 - 0.06s - loss: 0.9693 - acc: 0.5346 - val_loss: 1.0034 - val_acc: 0.5283\n",
            "Epoch 34/150 - 0.07s - loss: 0.9659 - acc: 0.5358 - val_loss: 1.0001 - val_acc: 0.5182\n",
            "Epoch 35/150 - 0.06s - loss: 0.9650 - acc: 0.5344 - val_loss: 0.9990 - val_acc: 0.5283\n",
            "Epoch 36/150 - 0.06s - loss: 0.9606 - acc: 0.5416 - val_loss: 0.9969 - val_acc: 0.5304\n",
            "Epoch 37/150 - 0.06s - loss: 0.9603 - acc: 0.5425 - val_loss: 0.9960 - val_acc: 0.5283\n",
            "Epoch 38/150 - 0.07s - loss: 0.9558 - acc: 0.5418 - val_loss: 0.9917 - val_acc: 0.5202\n",
            "Epoch 39/150 - 0.06s - loss: 0.9554 - acc: 0.5454 - val_loss: 0.9927 - val_acc: 0.5425\n",
            "Epoch 40/150 - 0.06s - loss: 0.9512 - acc: 0.5441 - val_loss: 0.9878 - val_acc: 0.5283\n",
            "Epoch 41/150 - 0.06s - loss: 0.9525 - acc: 0.5459 - val_loss: 0.9927 - val_acc: 0.5385\n",
            "Epoch 42/150 - 0.07s - loss: 0.9465 - acc: 0.5495 - val_loss: 0.9845 - val_acc: 0.5263\n",
            "Epoch 43/150 - 0.08s - loss: 0.9514 - acc: 0.5499 - val_loss: 0.9899 - val_acc: 0.5324\n",
            "Epoch 44/150 - 0.07s - loss: 0.9436 - acc: 0.5488 - val_loss: 0.9832 - val_acc: 0.5445\n",
            "Epoch 45/150 - 0.06s - loss: 0.9390 - acc: 0.5574 - val_loss: 0.9806 - val_acc: 0.5466\n",
            "Epoch 46/150 - 0.07s - loss: 0.9403 - acc: 0.5488 - val_loss: 0.9833 - val_acc: 0.5445\n",
            "Epoch 47/150 - 0.06s - loss: 0.9373 - acc: 0.5535 - val_loss: 0.9829 - val_acc: 0.5405\n",
            "Epoch 48/150 - 0.06s - loss: 0.9332 - acc: 0.5558 - val_loss: 0.9755 - val_acc: 0.5486\n",
            "Epoch 49/150 - 0.07s - loss: 0.9300 - acc: 0.5601 - val_loss: 0.9748 - val_acc: 0.5405\n",
            "Epoch 50/150 - 0.06s - loss: 0.9294 - acc: 0.5621 - val_loss: 0.9746 - val_acc: 0.5405\n",
            "Epoch 51/150 - 0.06s - loss: 0.9287 - acc: 0.5623 - val_loss: 0.9741 - val_acc: 0.5486\n",
            "Epoch 52/150 - 0.06s - loss: 0.9251 - acc: 0.5639 - val_loss: 0.9719 - val_acc: 0.5567\n",
            "Epoch 53/150 - 0.07s - loss: 0.9219 - acc: 0.5641 - val_loss: 0.9714 - val_acc: 0.5445\n",
            "Epoch 54/150 - 0.06s - loss: 0.9253 - acc: 0.5679 - val_loss: 0.9744 - val_acc: 0.5405\n",
            "Epoch 55/150 - 0.06s - loss: 0.9240 - acc: 0.5670 - val_loss: 0.9719 - val_acc: 0.5486\n",
            "Epoch 56/150 - 0.06s - loss: 0.9162 - acc: 0.5709 - val_loss: 0.9668 - val_acc: 0.5385\n",
            "Epoch 57/150 - 0.07s - loss: 0.9135 - acc: 0.5693 - val_loss: 0.9650 - val_acc: 0.5567\n",
            "Epoch 58/150 - 0.06s - loss: 0.9219 - acc: 0.5697 - val_loss: 0.9745 - val_acc: 0.5324\n",
            "Epoch 59/150 - 0.06s - loss: 0.9099 - acc: 0.5693 - val_loss: 0.9631 - val_acc: 0.5607\n",
            "Epoch 60/150 - 0.06s - loss: 0.9088 - acc: 0.5774 - val_loss: 0.9646 - val_acc: 0.5466\n",
            "Epoch 61/150 - 0.07s - loss: 0.9086 - acc: 0.5744 - val_loss: 0.9623 - val_acc: 0.5587\n",
            "Epoch 62/150 - 0.06s - loss: 0.9095 - acc: 0.5789 - val_loss: 0.9640 - val_acc: 0.5547\n",
            "Epoch 63/150 - 0.06s - loss: 0.9036 - acc: 0.5722 - val_loss: 0.9599 - val_acc: 0.5628\n",
            "Epoch 64/150 - 0.06s - loss: 0.9022 - acc: 0.5789 - val_loss: 0.9607 - val_acc: 0.5506\n",
            "Epoch 65/150 - 0.07s - loss: 0.9092 - acc: 0.5673 - val_loss: 0.9692 - val_acc: 0.5344\n",
            "Epoch 66/150 - 0.06s - loss: 0.8958 - acc: 0.5801 - val_loss: 0.9584 - val_acc: 0.5587\n",
            "Epoch 67/150 - 0.06s - loss: 0.8937 - acc: 0.5832 - val_loss: 0.9582 - val_acc: 0.5526\n",
            "Epoch 68/150 - 0.06s - loss: 0.8988 - acc: 0.5720 - val_loss: 0.9600 - val_acc: 0.5486\n",
            "Epoch 69/150 - 0.07s - loss: 0.8970 - acc: 0.5731 - val_loss: 0.9580 - val_acc: 0.5607\n",
            "Epoch 70/150 - 0.06s - loss: 0.9067 - acc: 0.5749 - val_loss: 0.9678 - val_acc: 0.5486\n",
            "Epoch 71/150 - 0.06s - loss: 0.8920 - acc: 0.5780 - val_loss: 0.9587 - val_acc: 0.5425\n",
            "Epoch 72/150 - 0.06s - loss: 0.8834 - acc: 0.5904 - val_loss: 0.9530 - val_acc: 0.5628\n",
            "Epoch 73/150 - 0.07s - loss: 0.8824 - acc: 0.5900 - val_loss: 0.9503 - val_acc: 0.5607\n",
            "Epoch 74/150 - 0.07s - loss: 0.8805 - acc: 0.5922 - val_loss: 0.9505 - val_acc: 0.5648\n",
            "Epoch 75/150 - 0.06s - loss: 0.8828 - acc: 0.5868 - val_loss: 0.9548 - val_acc: 0.5486\n",
            "Epoch 76/150 - 0.06s - loss: 0.8818 - acc: 0.5994 - val_loss: 0.9531 - val_acc: 0.5648\n",
            "Epoch 77/150 - 0.07s - loss: 0.8841 - acc: 0.5992 - val_loss: 0.9565 - val_acc: 0.5648\n",
            "Epoch 78/150 - 0.07s - loss: 0.8734 - acc: 0.5956 - val_loss: 0.9471 - val_acc: 0.5668\n",
            "Epoch 79/150 - 0.08s - loss: 0.8790 - acc: 0.5877 - val_loss: 0.9572 - val_acc: 0.5486\n",
            "Epoch 80/150 - 0.07s - loss: 0.8800 - acc: 0.5879 - val_loss: 0.9608 - val_acc: 0.5344\n",
            "Epoch 81/150 - 0.07s - loss: 0.8730 - acc: 0.5900 - val_loss: 0.9486 - val_acc: 0.5506\n",
            "Epoch 82/150 - 0.06s - loss: 0.8808 - acc: 0.5852 - val_loss: 0.9694 - val_acc: 0.5202\n",
            "Epoch 83/150 - 0.06s - loss: 0.8633 - acc: 0.6057 - val_loss: 0.9458 - val_acc: 0.5628\n",
            "Epoch 84/150 - 0.07s - loss: 0.8626 - acc: 0.6059 - val_loss: 0.9454 - val_acc: 0.5688\n",
            "Epoch 85/150 - 0.06s - loss: 0.8604 - acc: 0.6091 - val_loss: 0.9459 - val_acc: 0.5567\n",
            "Epoch 86/150 - 0.06s - loss: 0.8598 - acc: 0.6111 - val_loss: 0.9472 - val_acc: 0.5668\n",
            "Epoch 87/150 - 0.06s - loss: 0.8564 - acc: 0.6100 - val_loss: 0.9437 - val_acc: 0.5688\n",
            "Epoch 88/150 - 0.07s - loss: 0.8564 - acc: 0.6086 - val_loss: 0.9497 - val_acc: 0.5526\n",
            "Epoch 89/150 - 0.07s - loss: 0.8546 - acc: 0.6073 - val_loss: 0.9437 - val_acc: 0.5709\n",
            "Epoch 90/150 - 0.06s - loss: 0.8515 - acc: 0.6167 - val_loss: 0.9443 - val_acc: 0.5709\n",
            "Epoch 91/150 - 0.06s - loss: 0.8661 - acc: 0.5936 - val_loss: 0.9662 - val_acc: 0.5364\n",
            "Epoch 92/150 - 0.07s - loss: 0.8520 - acc: 0.6111 - val_loss: 0.9509 - val_acc: 0.5425\n",
            "Epoch 93/150 - 0.06s - loss: 0.8469 - acc: 0.6167 - val_loss: 0.9439 - val_acc: 0.5567\n",
            "Epoch 94/150 - 0.06s - loss: 0.8472 - acc: 0.6183 - val_loss: 0.9447 - val_acc: 0.5628\n",
            "Epoch 95/150 - 0.06s - loss: 0.9022 - acc: 0.5693 - val_loss: 1.0086 - val_acc: 0.5040\n",
            "Epoch 96/150 - 0.07s - loss: 0.8493 - acc: 0.6118 - val_loss: 0.9549 - val_acc: 0.5364\n",
            "Epoch 97/150 - 0.06s - loss: 0.8555 - acc: 0.5985 - val_loss: 0.9513 - val_acc: 0.5425\n",
            "Epoch 98/150 - 0.06s - loss: 0.8397 - acc: 0.6176 - val_loss: 0.9465 - val_acc: 0.5506\n",
            "Epoch 99/150 - 0.06s - loss: 0.8456 - acc: 0.6120 - val_loss: 0.9465 - val_acc: 0.5648\n",
            "Epoch 100/150 - 0.07s - loss: 0.8346 - acc: 0.6262 - val_loss: 0.9427 - val_acc: 0.5567\n",
            "Epoch 101/150 - 0.07s - loss: 0.8405 - acc: 0.6235 - val_loss: 0.9453 - val_acc: 0.5729\n",
            "Epoch 102/150 - 0.06s - loss: 0.8313 - acc: 0.6251 - val_loss: 0.9405 - val_acc: 0.5587\n",
            "Epoch 103/150 - 0.06s - loss: 0.8365 - acc: 0.6260 - val_loss: 0.9497 - val_acc: 0.5729\n",
            "Epoch 104/150 - 0.07s - loss: 0.8448 - acc: 0.6073 - val_loss: 0.9634 - val_acc: 0.5364\n",
            "Epoch 105/150 - 0.08s - loss: 0.8267 - acc: 0.6309 - val_loss: 0.9441 - val_acc: 0.5547\n",
            "Epoch 106/150 - 0.06s - loss: 0.8395 - acc: 0.6208 - val_loss: 0.9530 - val_acc: 0.5709\n",
            "Epoch 107/150 - 0.06s - loss: 0.8284 - acc: 0.6208 - val_loss: 0.9418 - val_acc: 0.5688\n",
            "Epoch 108/150 - 0.07s - loss: 0.8257 - acc: 0.6332 - val_loss: 0.9465 - val_acc: 0.5628\n",
            "Epoch 109/150 - 0.06s - loss: 0.8196 - acc: 0.6343 - val_loss: 0.9403 - val_acc: 0.5688\n",
            "Epoch 110/150 - 0.06s - loss: 0.8223 - acc: 0.6325 - val_loss: 0.9500 - val_acc: 0.5466\n",
            "Epoch 111/150 - 0.07s - loss: 0.8522 - acc: 0.6174 - val_loss: 0.9687 - val_acc: 0.5830\n",
            "Epoch 112/150 - 0.07s - loss: 0.8203 - acc: 0.6379 - val_loss: 0.9492 - val_acc: 0.5486\n",
            "Epoch 113/150 - 0.07s - loss: 0.8169 - acc: 0.6284 - val_loss: 0.9457 - val_acc: 0.5486\n",
            "Epoch 114/150 - 0.06s - loss: 0.8127 - acc: 0.6406 - val_loss: 0.9446 - val_acc: 0.5628\n",
            "Epoch 115/150 - 0.07s - loss: 0.8126 - acc: 0.6372 - val_loss: 0.9396 - val_acc: 0.5587\n",
            "Epoch 116/150 - 0.07s - loss: 0.8107 - acc: 0.6377 - val_loss: 0.9461 - val_acc: 0.5587\n",
            "Epoch 117/150 - 0.07s - loss: 0.8183 - acc: 0.6341 - val_loss: 0.9471 - val_acc: 0.5668\n",
            "Epoch 118/150 - 0.08s - loss: 0.8143 - acc: 0.6293 - val_loss: 0.9568 - val_acc: 0.5324\n",
            "Epoch 119/150 - 0.07s - loss: 0.8106 - acc: 0.6329 - val_loss: 0.9437 - val_acc: 0.5607\n",
            "Epoch 120/150 - 0.07s - loss: 0.8300 - acc: 0.6170 - val_loss: 0.9755 - val_acc: 0.5243\n",
            "Epoch 121/150 - 0.07s - loss: 0.8386 - acc: 0.6068 - val_loss: 0.9659 - val_acc: 0.5607\n",
            "Epoch 122/150 - 0.06s - loss: 0.8133 - acc: 0.6377 - val_loss: 0.9600 - val_acc: 0.5364\n",
            "Epoch 123/150 - 0.07s - loss: 0.8100 - acc: 0.6334 - val_loss: 0.9510 - val_acc: 0.5547\n",
            "Epoch 124/150 - 0.08s - loss: 0.8059 - acc: 0.6374 - val_loss: 0.9515 - val_acc: 0.5425\n",
            "Epoch 125/150 - 0.07s - loss: 0.7935 - acc: 0.6482 - val_loss: 0.9407 - val_acc: 0.5607\n",
            "Epoch 126/150 - 0.06s - loss: 0.8257 - acc: 0.6163 - val_loss: 0.9824 - val_acc: 0.5385\n",
            "Epoch 127/150 - 0.06s - loss: 0.8041 - acc: 0.6426 - val_loss: 0.9544 - val_acc: 0.5466\n",
            "Epoch 128/150 - 0.07s - loss: 0.7931 - acc: 0.6478 - val_loss: 0.9472 - val_acc: 0.5445\n",
            "Epoch 129/150 - 0.06s - loss: 0.7945 - acc: 0.6446 - val_loss: 0.9512 - val_acc: 0.5385\n",
            "Epoch 130/150 - 0.06s - loss: 0.8742 - acc: 0.5861 - val_loss: 1.0364 - val_acc: 0.5121\n",
            "Epoch 131/150 - 0.06s - loss: 0.7884 - acc: 0.6507 - val_loss: 0.9488 - val_acc: 0.5466\n",
            "Epoch 132/150 - 0.07s - loss: 0.7831 - acc: 0.6572 - val_loss: 0.9412 - val_acc: 0.5547\n",
            "Epoch 133/150 - 0.07s - loss: 0.8037 - acc: 0.6359 - val_loss: 0.9535 - val_acc: 0.5668\n",
            "Epoch 134/150 - 0.06s - loss: 0.7971 - acc: 0.6435 - val_loss: 0.9651 - val_acc: 0.5445\n",
            "Epoch 135/150 - 0.06s - loss: 0.7901 - acc: 0.6437 - val_loss: 0.9618 - val_acc: 0.5304\n",
            "Epoch 136/150 - 0.07s - loss: 0.8046 - acc: 0.6415 - val_loss: 0.9699 - val_acc: 0.5486\n",
            "Epoch 137/150 - 0.06s - loss: 0.7754 - acc: 0.6597 - val_loss: 0.9457 - val_acc: 0.5648\n",
            "Epoch 138/150 - 0.06s - loss: 0.7790 - acc: 0.6640 - val_loss: 0.9460 - val_acc: 0.5789\n",
            "Epoch 139/150 - 0.07s - loss: 0.8007 - acc: 0.6374 - val_loss: 0.9597 - val_acc: 0.5628\n",
            "Epoch 140/150 - 0.08s - loss: 0.8177 - acc: 0.6377 - val_loss: 0.9778 - val_acc: 0.5729\n",
            "Epoch 141/150 - 0.07s - loss: 0.7853 - acc: 0.6487 - val_loss: 0.9633 - val_acc: 0.5587\n",
            "Epoch 142/150 - 0.07s - loss: 0.8257 - acc: 0.6325 - val_loss: 0.9876 - val_acc: 0.5749\n",
            "Epoch 143/150 - 0.06s - loss: 0.7702 - acc: 0.6604 - val_loss: 0.9527 - val_acc: 0.5567\n",
            "Epoch 144/150 - 0.07s - loss: 0.7945 - acc: 0.6430 - val_loss: 0.9761 - val_acc: 0.5344\n",
            "Epoch 145/150 - 0.06s - loss: 0.8055 - acc: 0.6318 - val_loss: 0.9942 - val_acc: 0.5162\n",
            "Epoch 146/150 - 0.06s - loss: 0.7656 - acc: 0.6655 - val_loss: 0.9475 - val_acc: 0.5547\n",
            "Epoch 147/150 - 0.06s - loss: 0.7710 - acc: 0.6617 - val_loss: 0.9611 - val_acc: 0.5324\n",
            "Epoch 148/150 - 0.07s - loss: 0.7847 - acc: 0.6491 - val_loss: 0.9683 - val_acc: 0.5607\n",
            "Epoch 149/150 - 0.06s - loss: 0.7824 - acc: 0.6559 - val_loss: 0.9729 - val_acc: 0.5506\n",
            "Epoch 150/150 - 0.06s - loss: 0.8093 - acc: 0.6300 - val_loss: 1.0074 - val_acc: 0.5081\n",
            "\n",
            "Combination 79/252:\n",
            "Hidden Layers: [128, 128], Activation: relu, Learning Rate: 0.001, Batch Size: 32, Epochs: 50\n",
            "Epoch 1/50 - 0.08s - loss: 1.0995 - acc: 0.3495 - val_loss: 1.1015 - val_acc: 0.3239\n",
            "Epoch 2/50 - 0.09s - loss: 1.0960 - acc: 0.3525 - val_loss: 1.0978 - val_acc: 0.3360\n",
            "Epoch 3/50 - 0.08s - loss: 1.0939 - acc: 0.3614 - val_loss: 1.0959 - val_acc: 0.3583\n",
            "Epoch 4/50 - 0.09s - loss: 1.0920 - acc: 0.3709 - val_loss: 1.0942 - val_acc: 0.3563\n",
            "Epoch 5/50 - 0.09s - loss: 1.0903 - acc: 0.3772 - val_loss: 1.0928 - val_acc: 0.3684\n",
            "Epoch 6/50 - 0.10s - loss: 1.0887 - acc: 0.3846 - val_loss: 1.0916 - val_acc: 0.3785\n",
            "Epoch 7/50 - 0.10s - loss: 1.0871 - acc: 0.3916 - val_loss: 1.0903 - val_acc: 0.3806\n",
            "Epoch 8/50 - 0.09s - loss: 1.0856 - acc: 0.3929 - val_loss: 1.0892 - val_acc: 0.3765\n",
            "Epoch 9/50 - 0.10s - loss: 1.0841 - acc: 0.3986 - val_loss: 1.0880 - val_acc: 0.3785\n",
            "Epoch 10/50 - 0.11s - loss: 1.0827 - acc: 0.4042 - val_loss: 1.0869 - val_acc: 0.3846\n",
            "Epoch 11/50 - 0.09s - loss: 1.0814 - acc: 0.4067 - val_loss: 1.0859 - val_acc: 0.3907\n",
            "Epoch 12/50 - 0.08s - loss: 1.0801 - acc: 0.4127 - val_loss: 1.0849 - val_acc: 0.3927\n",
            "Epoch 13/50 - 0.09s - loss: 1.0788 - acc: 0.4184 - val_loss: 1.0842 - val_acc: 0.3826\n",
            "Epoch 14/50 - 0.09s - loss: 1.0776 - acc: 0.4195 - val_loss: 1.0831 - val_acc: 0.3866\n",
            "Epoch 15/50 - 0.09s - loss: 1.0764 - acc: 0.4186 - val_loss: 1.0819 - val_acc: 0.3866\n",
            "Epoch 16/50 - 0.10s - loss: 1.0752 - acc: 0.4229 - val_loss: 1.0812 - val_acc: 0.3866\n",
            "Epoch 17/50 - 0.09s - loss: 1.0741 - acc: 0.4267 - val_loss: 1.0803 - val_acc: 0.3887\n",
            "Epoch 18/50 - 0.09s - loss: 1.0730 - acc: 0.4271 - val_loss: 1.0794 - val_acc: 0.3907\n",
            "Epoch 19/50 - 0.10s - loss: 1.0719 - acc: 0.4285 - val_loss: 1.0789 - val_acc: 0.3927\n",
            "Epoch 20/50 - 0.09s - loss: 1.0708 - acc: 0.4291 - val_loss: 1.0780 - val_acc: 0.3927\n",
            "Epoch 21/50 - 0.09s - loss: 1.0697 - acc: 0.4327 - val_loss: 1.0772 - val_acc: 0.3968\n",
            "Epoch 22/50 - 0.09s - loss: 1.0686 - acc: 0.4336 - val_loss: 1.0764 - val_acc: 0.3927\n",
            "Epoch 23/50 - 0.09s - loss: 1.0676 - acc: 0.4386 - val_loss: 1.0755 - val_acc: 0.3988\n",
            "Epoch 24/50 - 0.09s - loss: 1.0665 - acc: 0.4395 - val_loss: 1.0747 - val_acc: 0.3988\n",
            "Epoch 25/50 - 0.09s - loss: 1.0655 - acc: 0.4404 - val_loss: 1.0740 - val_acc: 0.4049\n",
            "Epoch 26/50 - 0.09s - loss: 1.0645 - acc: 0.4415 - val_loss: 1.0733 - val_acc: 0.4109\n",
            "Epoch 27/50 - 0.08s - loss: 1.0635 - acc: 0.4438 - val_loss: 1.0726 - val_acc: 0.4130\n",
            "Epoch 28/50 - 0.10s - loss: 1.0626 - acc: 0.4465 - val_loss: 1.0721 - val_acc: 0.4130\n",
            "Epoch 29/50 - 0.08s - loss: 1.0616 - acc: 0.4465 - val_loss: 1.0714 - val_acc: 0.4150\n",
            "Epoch 30/50 - 0.08s - loss: 1.0607 - acc: 0.4453 - val_loss: 1.0707 - val_acc: 0.4211\n",
            "Epoch 31/50 - 0.09s - loss: 1.0597 - acc: 0.4467 - val_loss: 1.0701 - val_acc: 0.4231\n",
            "Epoch 32/50 - 0.09s - loss: 1.0588 - acc: 0.4489 - val_loss: 1.0695 - val_acc: 0.4231\n",
            "Epoch 33/50 - 0.08s - loss: 1.0579 - acc: 0.4483 - val_loss: 1.0688 - val_acc: 0.4190\n",
            "Epoch 34/50 - 0.09s - loss: 1.0570 - acc: 0.4512 - val_loss: 1.0683 - val_acc: 0.4271\n",
            "Epoch 35/50 - 0.08s - loss: 1.0561 - acc: 0.4510 - val_loss: 1.0677 - val_acc: 0.4251\n",
            "Epoch 36/50 - 0.08s - loss: 1.0553 - acc: 0.4521 - val_loss: 1.0672 - val_acc: 0.4291\n",
            "Epoch 37/50 - 0.09s - loss: 1.0544 - acc: 0.4541 - val_loss: 1.0667 - val_acc: 0.4251\n",
            "Epoch 38/50 - 0.08s - loss: 1.0535 - acc: 0.4561 - val_loss: 1.0661 - val_acc: 0.4251\n",
            "Epoch 39/50 - 0.08s - loss: 1.0527 - acc: 0.4575 - val_loss: 1.0653 - val_acc: 0.4231\n",
            "Epoch 40/50 - 0.10s - loss: 1.0518 - acc: 0.4568 - val_loss: 1.0647 - val_acc: 0.4291\n",
            "Epoch 41/50 - 0.09s - loss: 1.0510 - acc: 0.4595 - val_loss: 1.0642 - val_acc: 0.4312\n",
            "Epoch 42/50 - 0.09s - loss: 1.0501 - acc: 0.4609 - val_loss: 1.0639 - val_acc: 0.4332\n",
            "Epoch 43/50 - 0.10s - loss: 1.0493 - acc: 0.4611 - val_loss: 1.0633 - val_acc: 0.4312\n",
            "Epoch 44/50 - 0.09s - loss: 1.0485 - acc: 0.4618 - val_loss: 1.0626 - val_acc: 0.4332\n",
            "Epoch 45/50 - 0.08s - loss: 1.0476 - acc: 0.4638 - val_loss: 1.0621 - val_acc: 0.4271\n",
            "Epoch 46/50 - 0.09s - loss: 1.0468 - acc: 0.4645 - val_loss: 1.0616 - val_acc: 0.4291\n",
            "Epoch 47/50 - 0.10s - loss: 1.0460 - acc: 0.4663 - val_loss: 1.0611 - val_acc: 0.4291\n",
            "Epoch 48/50 - 0.09s - loss: 1.0452 - acc: 0.4681 - val_loss: 1.0605 - val_acc: 0.4332\n",
            "Epoch 49/50 - 0.11s - loss: 1.0444 - acc: 0.4678 - val_loss: 1.0598 - val_acc: 0.4332\n",
            "Epoch 50/50 - 0.09s - loss: 1.0436 - acc: 0.4685 - val_loss: 1.0596 - val_acc: 0.4312\n",
            "\n",
            "Combination 80/252:\n",
            "Hidden Layers: [128, 128], Activation: relu, Learning Rate: 0.001, Batch Size: 32, Epochs: 100\n",
            "Epoch 1/100 - 0.09s - loss: 1.1009 - acc: 0.3329 - val_loss: 1.0998 - val_acc: 0.3381\n",
            "Epoch 2/100 - 0.10s - loss: 1.0965 - acc: 0.3583 - val_loss: 1.0970 - val_acc: 0.3381\n",
            "Epoch 3/100 - 0.09s - loss: 1.0934 - acc: 0.3745 - val_loss: 1.0949 - val_acc: 0.3603\n",
            "Epoch 4/100 - 0.09s - loss: 1.0907 - acc: 0.3871 - val_loss: 1.0930 - val_acc: 0.3806\n",
            "Epoch 5/100 - 0.09s - loss: 1.0881 - acc: 0.3943 - val_loss: 1.0913 - val_acc: 0.3745\n",
            "Epoch 6/100 - 0.09s - loss: 1.0858 - acc: 0.4013 - val_loss: 1.0896 - val_acc: 0.3866\n",
            "Epoch 7/100 - 0.09s - loss: 1.0836 - acc: 0.4085 - val_loss: 1.0881 - val_acc: 0.3765\n",
            "Epoch 8/100 - 0.09s - loss: 1.0815 - acc: 0.4123 - val_loss: 1.0866 - val_acc: 0.3887\n",
            "Epoch 9/100 - 0.08s - loss: 1.0795 - acc: 0.4184 - val_loss: 1.0851 - val_acc: 0.3988\n",
            "Epoch 10/100 - 0.09s - loss: 1.0775 - acc: 0.4177 - val_loss: 1.0837 - val_acc: 0.3826\n",
            "Epoch 11/100 - 0.10s - loss: 1.0756 - acc: 0.4238 - val_loss: 1.0824 - val_acc: 0.3907\n",
            "Epoch 12/100 - 0.09s - loss: 1.0739 - acc: 0.4370 - val_loss: 1.0810 - val_acc: 0.4049\n",
            "Epoch 13/100 - 0.08s - loss: 1.0721 - acc: 0.4397 - val_loss: 1.0799 - val_acc: 0.4109\n",
            "Epoch 14/100 - 0.10s - loss: 1.0705 - acc: 0.4424 - val_loss: 1.0786 - val_acc: 0.4130\n",
            "Epoch 15/100 - 0.09s - loss: 1.0688 - acc: 0.4460 - val_loss: 1.0776 - val_acc: 0.4130\n",
            "Epoch 16/100 - 0.09s - loss: 1.0673 - acc: 0.4480 - val_loss: 1.0765 - val_acc: 0.4170\n",
            "Epoch 17/100 - 0.09s - loss: 1.0658 - acc: 0.4480 - val_loss: 1.0755 - val_acc: 0.4271\n",
            "Epoch 18/100 - 0.10s - loss: 1.0644 - acc: 0.4523 - val_loss: 1.0744 - val_acc: 0.4332\n",
            "Epoch 19/100 - 0.10s - loss: 1.0630 - acc: 0.4532 - val_loss: 1.0735 - val_acc: 0.4332\n",
            "Epoch 20/100 - 0.10s - loss: 1.0616 - acc: 0.4557 - val_loss: 1.0726 - val_acc: 0.4291\n",
            "Epoch 21/100 - 0.09s - loss: 1.0603 - acc: 0.4586 - val_loss: 1.0716 - val_acc: 0.4312\n",
            "Epoch 22/100 - 0.09s - loss: 1.0590 - acc: 0.4582 - val_loss: 1.0708 - val_acc: 0.4372\n",
            "Epoch 23/100 - 0.09s - loss: 1.0578 - acc: 0.4597 - val_loss: 1.0699 - val_acc: 0.4413\n",
            "Epoch 24/100 - 0.09s - loss: 1.0565 - acc: 0.4609 - val_loss: 1.0691 - val_acc: 0.4413\n",
            "Epoch 25/100 - 0.09s - loss: 1.0553 - acc: 0.4600 - val_loss: 1.0681 - val_acc: 0.4474\n",
            "Epoch 26/100 - 0.11s - loss: 1.0541 - acc: 0.4606 - val_loss: 1.0674 - val_acc: 0.4453\n",
            "Epoch 27/100 - 0.09s - loss: 1.0530 - acc: 0.4658 - val_loss: 1.0666 - val_acc: 0.4575\n",
            "Epoch 28/100 - 0.09s - loss: 1.0519 - acc: 0.4681 - val_loss: 1.0658 - val_acc: 0.4534\n",
            "Epoch 29/100 - 0.09s - loss: 1.0508 - acc: 0.4678 - val_loss: 1.0651 - val_acc: 0.4494\n",
            "Epoch 30/100 - 0.09s - loss: 1.0497 - acc: 0.4683 - val_loss: 1.0645 - val_acc: 0.4575\n",
            "Epoch 31/100 - 0.09s - loss: 1.0487 - acc: 0.4690 - val_loss: 1.0638 - val_acc: 0.4453\n",
            "Epoch 32/100 - 0.09s - loss: 1.0476 - acc: 0.4690 - val_loss: 1.0631 - val_acc: 0.4534\n",
            "Epoch 33/100 - 0.09s - loss: 1.0466 - acc: 0.4714 - val_loss: 1.0623 - val_acc: 0.4534\n",
            "Epoch 34/100 - 0.09s - loss: 1.0456 - acc: 0.4721 - val_loss: 1.0617 - val_acc: 0.4494\n",
            "Epoch 35/100 - 0.09s - loss: 1.0446 - acc: 0.4741 - val_loss: 1.0610 - val_acc: 0.4555\n",
            "Epoch 36/100 - 0.09s - loss: 1.0436 - acc: 0.4746 - val_loss: 1.0605 - val_acc: 0.4534\n",
            "Epoch 37/100 - 0.09s - loss: 1.0427 - acc: 0.4766 - val_loss: 1.0598 - val_acc: 0.4555\n",
            "Epoch 38/100 - 0.10s - loss: 1.0417 - acc: 0.4753 - val_loss: 1.0592 - val_acc: 0.4595\n",
            "Epoch 39/100 - 0.09s - loss: 1.0408 - acc: 0.4795 - val_loss: 1.0587 - val_acc: 0.4615\n",
            "Epoch 40/100 - 0.09s - loss: 1.0399 - acc: 0.4798 - val_loss: 1.0581 - val_acc: 0.4575\n",
            "Epoch 41/100 - 0.09s - loss: 1.0390 - acc: 0.4804 - val_loss: 1.0576 - val_acc: 0.4656\n",
            "Epoch 42/100 - 0.09s - loss: 1.0381 - acc: 0.4791 - val_loss: 1.0569 - val_acc: 0.4656\n",
            "Epoch 43/100 - 0.09s - loss: 1.0372 - acc: 0.4822 - val_loss: 1.0563 - val_acc: 0.4615\n",
            "Epoch 44/100 - 0.11s - loss: 1.0363 - acc: 0.4804 - val_loss: 1.0556 - val_acc: 0.4696\n",
            "Epoch 45/100 - 0.10s - loss: 1.0354 - acc: 0.4845 - val_loss: 1.0551 - val_acc: 0.4737\n",
            "Epoch 46/100 - 0.09s - loss: 1.0346 - acc: 0.4836 - val_loss: 1.0544 - val_acc: 0.4757\n",
            "Epoch 47/100 - 0.09s - loss: 1.0338 - acc: 0.4838 - val_loss: 1.0538 - val_acc: 0.4798\n",
            "Epoch 48/100 - 0.09s - loss: 1.0329 - acc: 0.4867 - val_loss: 1.0534 - val_acc: 0.4757\n",
            "Epoch 49/100 - 0.09s - loss: 1.0322 - acc: 0.4865 - val_loss: 1.0530 - val_acc: 0.4798\n",
            "Epoch 50/100 - 0.10s - loss: 1.0313 - acc: 0.4881 - val_loss: 1.0523 - val_acc: 0.4777\n",
            "Epoch 51/100 - 0.09s - loss: 1.0305 - acc: 0.4858 - val_loss: 1.0516 - val_acc: 0.4818\n",
            "Epoch 52/100 - 0.09s - loss: 1.0297 - acc: 0.4872 - val_loss: 1.0511 - val_acc: 0.4818\n",
            "Epoch 53/100 - 0.09s - loss: 1.0289 - acc: 0.4863 - val_loss: 1.0505 - val_acc: 0.4798\n",
            "Epoch 54/100 - 0.09s - loss: 1.0282 - acc: 0.4881 - val_loss: 1.0500 - val_acc: 0.4838\n",
            "Epoch 55/100 - 0.08s - loss: 1.0274 - acc: 0.4883 - val_loss: 1.0495 - val_acc: 0.4838\n",
            "Epoch 56/100 - 0.09s - loss: 1.0266 - acc: 0.4890 - val_loss: 1.0491 - val_acc: 0.4798\n",
            "Epoch 57/100 - 0.09s - loss: 1.0259 - acc: 0.4888 - val_loss: 1.0485 - val_acc: 0.4858\n",
            "Epoch 58/100 - 0.09s - loss: 1.0251 - acc: 0.4906 - val_loss: 1.0479 - val_acc: 0.4818\n",
            "Epoch 59/100 - 0.09s - loss: 1.0244 - acc: 0.4903 - val_loss: 1.0474 - val_acc: 0.4858\n",
            "Epoch 60/100 - 0.09s - loss: 1.0237 - acc: 0.4910 - val_loss: 1.0468 - val_acc: 0.4777\n",
            "Epoch 61/100 - 0.09s - loss: 1.0229 - acc: 0.4910 - val_loss: 1.0463 - val_acc: 0.4798\n",
            "Epoch 62/100 - 0.10s - loss: 1.0222 - acc: 0.4919 - val_loss: 1.0460 - val_acc: 0.4858\n",
            "Epoch 63/100 - 0.09s - loss: 1.0214 - acc: 0.4921 - val_loss: 1.0453 - val_acc: 0.4838\n",
            "Epoch 64/100 - 0.09s - loss: 1.0208 - acc: 0.4930 - val_loss: 1.0449 - val_acc: 0.4919\n",
            "Epoch 65/100 - 0.09s - loss: 1.0200 - acc: 0.4951 - val_loss: 1.0442 - val_acc: 0.4919\n",
            "Epoch 66/100 - 0.09s - loss: 1.0193 - acc: 0.4933 - val_loss: 1.0437 - val_acc: 0.4838\n",
            "Epoch 67/100 - 0.09s - loss: 1.0186 - acc: 0.4937 - val_loss: 1.0433 - val_acc: 0.4838\n",
            "Epoch 68/100 - 0.09s - loss: 1.0179 - acc: 0.4957 - val_loss: 1.0425 - val_acc: 0.4960\n",
            "Epoch 69/100 - 0.09s - loss: 1.0172 - acc: 0.4962 - val_loss: 1.0422 - val_acc: 0.5040\n",
            "Epoch 70/100 - 0.09s - loss: 1.0165 - acc: 0.4966 - val_loss: 1.0415 - val_acc: 0.4960\n",
            "Epoch 71/100 - 0.09s - loss: 1.0160 - acc: 0.4971 - val_loss: 1.0410 - val_acc: 0.4939\n",
            "Epoch 72/100 - 0.09s - loss: 1.0151 - acc: 0.4980 - val_loss: 1.0405 - val_acc: 0.4980\n",
            "Epoch 73/100 - 0.09s - loss: 1.0145 - acc: 0.4984 - val_loss: 1.0402 - val_acc: 0.5020\n",
            "Epoch 74/100 - 0.11s - loss: 1.0138 - acc: 0.4980 - val_loss: 1.0397 - val_acc: 0.4980\n",
            "Epoch 75/100 - 0.10s - loss: 1.0131 - acc: 0.4987 - val_loss: 1.0390 - val_acc: 0.5020\n",
            "Epoch 76/100 - 0.09s - loss: 1.0123 - acc: 0.4998 - val_loss: 1.0386 - val_acc: 0.4980\n",
            "Epoch 77/100 - 0.09s - loss: 1.0117 - acc: 0.4998 - val_loss: 1.0381 - val_acc: 0.4980\n",
            "Epoch 78/100 - 0.09s - loss: 1.0110 - acc: 0.5000 - val_loss: 1.0377 - val_acc: 0.5000\n",
            "Epoch 79/100 - 0.09s - loss: 1.0103 - acc: 0.5004 - val_loss: 1.0371 - val_acc: 0.5040\n",
            "Epoch 80/100 - 0.09s - loss: 1.0097 - acc: 0.4996 - val_loss: 1.0366 - val_acc: 0.5000\n",
            "Epoch 81/100 - 0.10s - loss: 1.0090 - acc: 0.5022 - val_loss: 1.0360 - val_acc: 0.5101\n",
            "Epoch 82/100 - 0.09s - loss: 1.0084 - acc: 0.5029 - val_loss: 1.0356 - val_acc: 0.5061\n",
            "Epoch 83/100 - 0.09s - loss: 1.0077 - acc: 0.5034 - val_loss: 1.0350 - val_acc: 0.5061\n",
            "Epoch 84/100 - 0.09s - loss: 1.0073 - acc: 0.5061 - val_loss: 1.0350 - val_acc: 0.5040\n",
            "Epoch 85/100 - 0.09s - loss: 1.0064 - acc: 0.5036 - val_loss: 1.0341 - val_acc: 0.5000\n",
            "Epoch 86/100 - 0.09s - loss: 1.0058 - acc: 0.5063 - val_loss: 1.0339 - val_acc: 0.4980\n",
            "Epoch 87/100 - 0.09s - loss: 1.0051 - acc: 0.5038 - val_loss: 1.0331 - val_acc: 0.5040\n",
            "Epoch 88/100 - 0.09s - loss: 1.0045 - acc: 0.5052 - val_loss: 1.0327 - val_acc: 0.5061\n",
            "Epoch 89/100 - 0.09s - loss: 1.0038 - acc: 0.5034 - val_loss: 1.0321 - val_acc: 0.5142\n",
            "Epoch 90/100 - 0.08s - loss: 1.0032 - acc: 0.5029 - val_loss: 1.0316 - val_acc: 0.5121\n",
            "Epoch 91/100 - 0.08s - loss: 1.0026 - acc: 0.5013 - val_loss: 1.0315 - val_acc: 0.5142\n",
            "Epoch 92/100 - 0.09s - loss: 1.0020 - acc: 0.5043 - val_loss: 1.0310 - val_acc: 0.5061\n",
            "Epoch 93/100 - 0.10s - loss: 1.0013 - acc: 0.5067 - val_loss: 1.0301 - val_acc: 0.5142\n",
            "Epoch 94/100 - 0.09s - loss: 1.0007 - acc: 0.5067 - val_loss: 1.0297 - val_acc: 0.5142\n",
            "Epoch 95/100 - 0.09s - loss: 1.0002 - acc: 0.5063 - val_loss: 1.0294 - val_acc: 0.5081\n",
            "Epoch 96/100 - 0.08s - loss: 0.9995 - acc: 0.5056 - val_loss: 1.0287 - val_acc: 0.5162\n",
            "Epoch 97/100 - 0.09s - loss: 0.9988 - acc: 0.5065 - val_loss: 1.0283 - val_acc: 0.5142\n",
            "Epoch 98/100 - 0.09s - loss: 0.9983 - acc: 0.5063 - val_loss: 1.0276 - val_acc: 0.5243\n",
            "Epoch 99/100 - 0.09s - loss: 0.9978 - acc: 0.5063 - val_loss: 1.0271 - val_acc: 0.5243\n",
            "Epoch 100/100 - 0.09s - loss: 0.9972 - acc: 0.5074 - val_loss: 1.0270 - val_acc: 0.5081\n",
            "\n",
            "Combination 81/252:\n",
            "Hidden Layers: [128, 128], Activation: relu, Learning Rate: 0.001, Batch Size: 32, Epochs: 150\n",
            "Epoch 1/150 - 0.09s - loss: 1.0999 - acc: 0.3783 - val_loss: 1.0941 - val_acc: 0.3927\n",
            "Epoch 2/150 - 0.09s - loss: 1.0905 - acc: 0.3866 - val_loss: 1.0882 - val_acc: 0.4150\n",
            "Epoch 3/150 - 0.10s - loss: 1.0868 - acc: 0.3900 - val_loss: 1.0865 - val_acc: 0.4089\n",
            "Epoch 4/150 - 0.10s - loss: 1.0843 - acc: 0.3974 - val_loss: 1.0849 - val_acc: 0.4170\n",
            "Epoch 5/150 - 0.09s - loss: 1.0818 - acc: 0.4085 - val_loss: 1.0832 - val_acc: 0.4170\n",
            "Epoch 6/150 - 0.09s - loss: 1.0795 - acc: 0.4157 - val_loss: 1.0816 - val_acc: 0.4251\n",
            "Epoch 7/150 - 0.10s - loss: 1.0774 - acc: 0.4222 - val_loss: 1.0800 - val_acc: 0.4251\n",
            "Epoch 8/150 - 0.09s - loss: 1.0752 - acc: 0.4287 - val_loss: 1.0787 - val_acc: 0.4150\n",
            "Epoch 9/150 - 0.09s - loss: 1.0732 - acc: 0.4316 - val_loss: 1.0772 - val_acc: 0.4170\n",
            "Epoch 10/150 - 0.10s - loss: 1.0713 - acc: 0.4327 - val_loss: 1.0760 - val_acc: 0.4231\n",
            "Epoch 11/150 - 0.09s - loss: 1.0695 - acc: 0.4402 - val_loss: 1.0745 - val_acc: 0.4271\n",
            "Epoch 12/150 - 0.10s - loss: 1.0677 - acc: 0.4417 - val_loss: 1.0734 - val_acc: 0.4332\n",
            "Epoch 13/150 - 0.10s - loss: 1.0659 - acc: 0.4449 - val_loss: 1.0722 - val_acc: 0.4352\n",
            "Epoch 14/150 - 0.10s - loss: 1.0643 - acc: 0.4496 - val_loss: 1.0710 - val_acc: 0.4393\n",
            "Epoch 15/150 - 0.10s - loss: 1.0626 - acc: 0.4501 - val_loss: 1.0700 - val_acc: 0.4413\n",
            "Epoch 16/150 - 0.11s - loss: 1.0611 - acc: 0.4516 - val_loss: 1.0691 - val_acc: 0.4372\n",
            "Epoch 17/150 - 0.10s - loss: 1.0596 - acc: 0.4510 - val_loss: 1.0678 - val_acc: 0.4393\n",
            "Epoch 18/150 - 0.11s - loss: 1.0581 - acc: 0.4530 - val_loss: 1.0667 - val_acc: 0.4514\n",
            "Epoch 19/150 - 0.11s - loss: 1.0567 - acc: 0.4552 - val_loss: 1.0658 - val_acc: 0.4453\n",
            "Epoch 20/150 - 0.09s - loss: 1.0553 - acc: 0.4561 - val_loss: 1.0651 - val_acc: 0.4413\n",
            "Epoch 21/150 - 0.11s - loss: 1.0539 - acc: 0.4561 - val_loss: 1.0641 - val_acc: 0.4494\n",
            "Epoch 22/150 - 0.09s - loss: 1.0526 - acc: 0.4600 - val_loss: 1.0633 - val_acc: 0.4494\n",
            "Epoch 23/150 - 0.09s - loss: 1.0513 - acc: 0.4631 - val_loss: 1.0622 - val_acc: 0.4534\n",
            "Epoch 24/150 - 0.09s - loss: 1.0501 - acc: 0.4622 - val_loss: 1.0615 - val_acc: 0.4494\n",
            "Epoch 25/150 - 0.09s - loss: 1.0489 - acc: 0.4629 - val_loss: 1.0609 - val_acc: 0.4494\n",
            "Epoch 26/150 - 0.09s - loss: 1.0478 - acc: 0.4656 - val_loss: 1.0599 - val_acc: 0.4555\n",
            "Epoch 27/150 - 0.09s - loss: 1.0466 - acc: 0.4676 - val_loss: 1.0591 - val_acc: 0.4575\n",
            "Epoch 28/150 - 0.09s - loss: 1.0455 - acc: 0.4669 - val_loss: 1.0584 - val_acc: 0.4717\n",
            "Epoch 29/150 - 0.09s - loss: 1.0444 - acc: 0.4696 - val_loss: 1.0578 - val_acc: 0.4737\n",
            "Epoch 30/150 - 0.09s - loss: 1.0434 - acc: 0.4690 - val_loss: 1.0570 - val_acc: 0.4696\n",
            "Epoch 31/150 - 0.09s - loss: 1.0423 - acc: 0.4710 - val_loss: 1.0564 - val_acc: 0.4717\n",
            "Epoch 32/150 - 0.09s - loss: 1.0413 - acc: 0.4723 - val_loss: 1.0557 - val_acc: 0.4777\n",
            "Epoch 33/150 - 0.10s - loss: 1.0403 - acc: 0.4735 - val_loss: 1.0548 - val_acc: 0.4737\n",
            "Epoch 34/150 - 0.09s - loss: 1.0393 - acc: 0.4732 - val_loss: 1.0541 - val_acc: 0.4737\n",
            "Epoch 35/150 - 0.09s - loss: 1.0384 - acc: 0.4768 - val_loss: 1.0534 - val_acc: 0.4777\n",
            "Epoch 36/150 - 0.09s - loss: 1.0374 - acc: 0.4746 - val_loss: 1.0528 - val_acc: 0.4798\n",
            "Epoch 37/150 - 0.09s - loss: 1.0365 - acc: 0.4798 - val_loss: 1.0522 - val_acc: 0.4798\n",
            "Epoch 38/150 - 0.09s - loss: 1.0356 - acc: 0.4764 - val_loss: 1.0513 - val_acc: 0.4899\n",
            "Epoch 39/150 - 0.09s - loss: 1.0346 - acc: 0.4789 - val_loss: 1.0508 - val_acc: 0.4858\n",
            "Epoch 40/150 - 0.10s - loss: 1.0338 - acc: 0.4768 - val_loss: 1.0500 - val_acc: 0.4899\n",
            "Epoch 41/150 - 0.10s - loss: 1.0329 - acc: 0.4813 - val_loss: 1.0497 - val_acc: 0.4879\n",
            "Epoch 42/150 - 0.09s - loss: 1.0320 - acc: 0.4800 - val_loss: 1.0490 - val_acc: 0.4919\n",
            "Epoch 43/150 - 0.09s - loss: 1.0311 - acc: 0.4834 - val_loss: 1.0484 - val_acc: 0.4939\n",
            "Epoch 44/150 - 0.09s - loss: 1.0303 - acc: 0.4856 - val_loss: 1.0477 - val_acc: 0.4858\n",
            "Epoch 45/150 - 0.11s - loss: 1.0294 - acc: 0.4816 - val_loss: 1.0471 - val_acc: 0.4899\n",
            "Epoch 46/150 - 0.09s - loss: 1.0286 - acc: 0.4836 - val_loss: 1.0464 - val_acc: 0.4939\n",
            "Epoch 47/150 - 0.09s - loss: 1.0280 - acc: 0.4809 - val_loss: 1.0458 - val_acc: 0.5000\n",
            "Epoch 48/150 - 0.09s - loss: 1.0269 - acc: 0.4874 - val_loss: 1.0452 - val_acc: 0.4899\n",
            "Epoch 49/150 - 0.09s - loss: 1.0261 - acc: 0.4852 - val_loss: 1.0448 - val_acc: 0.4879\n",
            "Epoch 50/150 - 0.09s - loss: 1.0253 - acc: 0.4840 - val_loss: 1.0439 - val_acc: 0.4960\n",
            "Epoch 51/150 - 0.09s - loss: 1.0245 - acc: 0.4861 - val_loss: 1.0433 - val_acc: 0.4879\n",
            "Epoch 52/150 - 0.09s - loss: 1.0237 - acc: 0.4836 - val_loss: 1.0429 - val_acc: 0.4980\n",
            "Epoch 53/150 - 0.09s - loss: 1.0229 - acc: 0.4885 - val_loss: 1.0422 - val_acc: 0.4879\n",
            "Epoch 54/150 - 0.09s - loss: 1.0221 - acc: 0.4894 - val_loss: 1.0415 - val_acc: 0.4879\n",
            "Epoch 55/150 - 0.09s - loss: 1.0213 - acc: 0.4867 - val_loss: 1.0410 - val_acc: 0.4960\n",
            "Epoch 56/150 - 0.09s - loss: 1.0206 - acc: 0.4897 - val_loss: 1.0407 - val_acc: 0.4980\n",
            "Epoch 57/150 - 0.10s - loss: 1.0197 - acc: 0.4915 - val_loss: 1.0399 - val_acc: 0.5000\n",
            "Epoch 58/150 - 0.09s - loss: 1.0190 - acc: 0.4935 - val_loss: 1.0395 - val_acc: 0.4919\n",
            "Epoch 59/150 - 0.09s - loss: 1.0181 - acc: 0.4926 - val_loss: 1.0387 - val_acc: 0.5000\n",
            "Epoch 60/150 - 0.10s - loss: 1.0173 - acc: 0.4935 - val_loss: 1.0382 - val_acc: 0.5000\n",
            "Epoch 61/150 - 0.09s - loss: 1.0165 - acc: 0.4948 - val_loss: 1.0376 - val_acc: 0.4980\n",
            "Epoch 62/150 - 0.09s - loss: 1.0157 - acc: 0.4971 - val_loss: 1.0370 - val_acc: 0.5040\n",
            "Epoch 63/150 - 0.09s - loss: 1.0150 - acc: 0.4930 - val_loss: 1.0362 - val_acc: 0.5000\n",
            "Epoch 64/150 - 0.09s - loss: 1.0145 - acc: 0.4935 - val_loss: 1.0358 - val_acc: 0.5000\n",
            "Epoch 65/150 - 0.09s - loss: 1.0134 - acc: 0.4962 - val_loss: 1.0350 - val_acc: 0.5020\n",
            "Epoch 66/150 - 0.10s - loss: 1.0126 - acc: 0.4989 - val_loss: 1.0347 - val_acc: 0.5040\n",
            "Epoch 67/150 - 0.09s - loss: 1.0119 - acc: 0.4998 - val_loss: 1.0341 - val_acc: 0.5081\n",
            "Epoch 68/150 - 0.09s - loss: 1.0112 - acc: 0.5000 - val_loss: 1.0337 - val_acc: 0.5040\n",
            "Epoch 69/150 - 0.10s - loss: 1.0103 - acc: 0.4996 - val_loss: 1.0327 - val_acc: 0.5081\n",
            "Epoch 70/150 - 0.09s - loss: 1.0096 - acc: 0.5020 - val_loss: 1.0321 - val_acc: 0.5061\n",
            "Epoch 71/150 - 0.09s - loss: 1.0088 - acc: 0.5011 - val_loss: 1.0315 - val_acc: 0.5061\n",
            "Epoch 72/150 - 0.09s - loss: 1.0081 - acc: 0.5027 - val_loss: 1.0310 - val_acc: 0.5081\n",
            "Epoch 73/150 - 0.09s - loss: 1.0073 - acc: 0.5045 - val_loss: 1.0305 - val_acc: 0.5061\n",
            "Epoch 74/150 - 0.09s - loss: 1.0066 - acc: 0.5040 - val_loss: 1.0297 - val_acc: 0.5040\n",
            "Epoch 75/150 - 0.10s - loss: 1.0058 - acc: 0.5043 - val_loss: 1.0291 - val_acc: 0.5101\n",
            "Epoch 76/150 - 0.09s - loss: 1.0053 - acc: 0.5040 - val_loss: 1.0289 - val_acc: 0.5000\n",
            "Epoch 77/150 - 0.09s - loss: 1.0043 - acc: 0.5047 - val_loss: 1.0278 - val_acc: 0.5020\n",
            "Epoch 78/150 - 0.10s - loss: 1.0036 - acc: 0.5043 - val_loss: 1.0271 - val_acc: 0.5061\n",
            "Epoch 79/150 - 0.10s - loss: 1.0028 - acc: 0.5074 - val_loss: 1.0268 - val_acc: 0.5101\n",
            "Epoch 80/150 - 0.10s - loss: 1.0024 - acc: 0.5054 - val_loss: 1.0262 - val_acc: 0.5121\n",
            "Epoch 81/150 - 0.11s - loss: 1.0014 - acc: 0.5058 - val_loss: 1.0254 - val_acc: 0.5040\n",
            "Epoch 82/150 - 0.09s - loss: 1.0008 - acc: 0.5061 - val_loss: 1.0251 - val_acc: 0.5101\n",
            "Epoch 83/150 - 0.09s - loss: 1.0000 - acc: 0.5094 - val_loss: 1.0247 - val_acc: 0.5142\n",
            "Epoch 84/150 - 0.11s - loss: 0.9993 - acc: 0.5106 - val_loss: 1.0238 - val_acc: 0.5101\n",
            "Epoch 85/150 - 0.09s - loss: 0.9986 - acc: 0.5092 - val_loss: 1.0234 - val_acc: 0.5101\n",
            "Epoch 86/150 - 0.09s - loss: 0.9979 - acc: 0.5094 - val_loss: 1.0228 - val_acc: 0.5121\n",
            "Epoch 87/150 - 0.09s - loss: 0.9972 - acc: 0.5106 - val_loss: 1.0224 - val_acc: 0.5061\n",
            "Epoch 88/150 - 0.09s - loss: 0.9970 - acc: 0.5072 - val_loss: 1.0218 - val_acc: 0.5182\n",
            "Epoch 89/150 - 0.09s - loss: 0.9960 - acc: 0.5108 - val_loss: 1.0210 - val_acc: 0.5182\n",
            "Epoch 90/150 - 0.10s - loss: 0.9951 - acc: 0.5124 - val_loss: 1.0202 - val_acc: 0.5081\n",
            "Epoch 91/150 - 0.09s - loss: 0.9944 - acc: 0.5119 - val_loss: 1.0198 - val_acc: 0.5101\n",
            "Epoch 92/150 - 0.09s - loss: 0.9938 - acc: 0.5128 - val_loss: 1.0191 - val_acc: 0.5121\n",
            "Epoch 93/150 - 0.10s - loss: 0.9935 - acc: 0.5099 - val_loss: 1.0192 - val_acc: 0.5081\n",
            "Epoch 94/150 - 0.09s - loss: 0.9925 - acc: 0.5142 - val_loss: 1.0178 - val_acc: 0.5081\n",
            "Epoch 95/150 - 0.09s - loss: 0.9917 - acc: 0.5153 - val_loss: 1.0175 - val_acc: 0.5081\n",
            "Epoch 96/150 - 0.10s - loss: 0.9913 - acc: 0.5135 - val_loss: 1.0171 - val_acc: 0.5243\n",
            "Epoch 97/150 - 0.09s - loss: 0.9904 - acc: 0.5153 - val_loss: 1.0163 - val_acc: 0.5162\n",
            "Epoch 98/150 - 0.09s - loss: 0.9898 - acc: 0.5155 - val_loss: 1.0159 - val_acc: 0.5081\n",
            "Epoch 99/150 - 0.10s - loss: 0.9891 - acc: 0.5164 - val_loss: 1.0153 - val_acc: 0.5121\n",
            "Epoch 100/150 - 0.10s - loss: 0.9885 - acc: 0.5182 - val_loss: 1.0150 - val_acc: 0.5162\n",
            "Epoch 101/150 - 0.10s - loss: 0.9878 - acc: 0.5189 - val_loss: 1.0141 - val_acc: 0.5121\n",
            "Epoch 102/150 - 0.10s - loss: 0.9873 - acc: 0.5175 - val_loss: 1.0137 - val_acc: 0.5182\n",
            "Epoch 103/150 - 0.10s - loss: 0.9865 - acc: 0.5182 - val_loss: 1.0132 - val_acc: 0.5101\n",
            "Epoch 104/150 - 0.09s - loss: 0.9858 - acc: 0.5171 - val_loss: 1.0126 - val_acc: 0.5101\n",
            "Epoch 105/150 - 0.10s - loss: 0.9852 - acc: 0.5191 - val_loss: 1.0119 - val_acc: 0.5101\n",
            "Epoch 106/150 - 0.09s - loss: 0.9848 - acc: 0.5229 - val_loss: 1.0114 - val_acc: 0.5202\n",
            "Epoch 107/150 - 0.09s - loss: 0.9843 - acc: 0.5209 - val_loss: 1.0111 - val_acc: 0.5283\n",
            "Epoch 108/150 - 0.10s - loss: 0.9833 - acc: 0.5214 - val_loss: 1.0103 - val_acc: 0.5081\n",
            "Epoch 109/150 - 0.09s - loss: 0.9827 - acc: 0.5223 - val_loss: 1.0100 - val_acc: 0.5101\n",
            "Epoch 110/150 - 0.09s - loss: 0.9821 - acc: 0.5225 - val_loss: 1.0093 - val_acc: 0.5101\n",
            "Epoch 111/150 - 0.10s - loss: 0.9823 - acc: 0.5157 - val_loss: 1.0101 - val_acc: 0.5101\n",
            "Epoch 112/150 - 0.09s - loss: 0.9815 - acc: 0.5241 - val_loss: 1.0094 - val_acc: 0.5304\n",
            "Epoch 113/150 - 0.09s - loss: 0.9802 - acc: 0.5241 - val_loss: 1.0080 - val_acc: 0.5142\n",
            "Epoch 114/150 - 0.10s - loss: 0.9796 - acc: 0.5247 - val_loss: 1.0077 - val_acc: 0.5162\n",
            "Epoch 115/150 - 0.09s - loss: 0.9791 - acc: 0.5261 - val_loss: 1.0077 - val_acc: 0.5182\n",
            "Epoch 116/150 - 0.09s - loss: 0.9783 - acc: 0.5250 - val_loss: 1.0068 - val_acc: 0.5162\n",
            "Epoch 117/150 - 0.11s - loss: 0.9778 - acc: 0.5274 - val_loss: 1.0066 - val_acc: 0.5142\n",
            "Epoch 118/150 - 0.09s - loss: 0.9771 - acc: 0.5265 - val_loss: 1.0057 - val_acc: 0.5162\n",
            "Epoch 119/150 - 0.09s - loss: 0.9768 - acc: 0.5214 - val_loss: 1.0056 - val_acc: 0.5121\n",
            "Epoch 120/150 - 0.10s - loss: 0.9762 - acc: 0.5241 - val_loss: 1.0051 - val_acc: 0.5121\n",
            "Epoch 121/150 - 0.09s - loss: 0.9754 - acc: 0.5281 - val_loss: 1.0044 - val_acc: 0.5162\n",
            "Epoch 122/150 - 0.09s - loss: 0.9749 - acc: 0.5223 - val_loss: 1.0042 - val_acc: 0.5162\n",
            "Epoch 123/150 - 0.09s - loss: 0.9747 - acc: 0.5290 - val_loss: 1.0042 - val_acc: 0.5283\n",
            "Epoch 124/150 - 0.09s - loss: 0.9737 - acc: 0.5304 - val_loss: 1.0031 - val_acc: 0.5263\n",
            "Epoch 125/150 - 0.09s - loss: 0.9732 - acc: 0.5252 - val_loss: 1.0031 - val_acc: 0.5142\n",
            "Epoch 126/150 - 0.10s - loss: 0.9724 - acc: 0.5286 - val_loss: 1.0022 - val_acc: 0.5182\n",
            "Epoch 127/150 - 0.09s - loss: 0.9719 - acc: 0.5299 - val_loss: 1.0021 - val_acc: 0.5263\n",
            "Epoch 128/150 - 0.09s - loss: 0.9713 - acc: 0.5290 - val_loss: 1.0015 - val_acc: 0.5182\n",
            "Epoch 129/150 - 0.10s - loss: 0.9707 - acc: 0.5304 - val_loss: 1.0009 - val_acc: 0.5223\n",
            "Epoch 130/150 - 0.09s - loss: 0.9703 - acc: 0.5317 - val_loss: 1.0006 - val_acc: 0.5263\n",
            "Epoch 131/150 - 0.09s - loss: 0.9697 - acc: 0.5313 - val_loss: 1.0002 - val_acc: 0.5263\n",
            "Epoch 132/150 - 0.11s - loss: 0.9690 - acc: 0.5304 - val_loss: 0.9998 - val_acc: 0.5243\n",
            "Epoch 133/150 - 0.09s - loss: 0.9684 - acc: 0.5304 - val_loss: 0.9993 - val_acc: 0.5243\n",
            "Epoch 134/150 - 0.09s - loss: 0.9680 - acc: 0.5333 - val_loss: 0.9991 - val_acc: 0.5304\n",
            "Epoch 135/150 - 0.09s - loss: 0.9674 - acc: 0.5317 - val_loss: 0.9982 - val_acc: 0.5304\n",
            "Epoch 136/150 - 0.09s - loss: 0.9667 - acc: 0.5326 - val_loss: 0.9979 - val_acc: 0.5283\n",
            "Epoch 137/150 - 0.09s - loss: 0.9662 - acc: 0.5299 - val_loss: 0.9979 - val_acc: 0.5263\n",
            "Epoch 138/150 - 0.09s - loss: 0.9659 - acc: 0.5301 - val_loss: 0.9977 - val_acc: 0.5344\n",
            "Epoch 139/150 - 0.10s - loss: 0.9656 - acc: 0.5299 - val_loss: 0.9977 - val_acc: 0.5385\n",
            "Epoch 140/150 - 0.09s - loss: 0.9645 - acc: 0.5344 - val_loss: 0.9963 - val_acc: 0.5263\n",
            "Epoch 141/150 - 0.11s - loss: 0.9640 - acc: 0.5337 - val_loss: 0.9961 - val_acc: 0.5283\n",
            "Epoch 142/150 - 0.09s - loss: 0.9634 - acc: 0.5364 - val_loss: 0.9954 - val_acc: 0.5364\n",
            "Epoch 143/150 - 0.09s - loss: 0.9629 - acc: 0.5358 - val_loss: 0.9951 - val_acc: 0.5283\n",
            "Epoch 144/150 - 0.09s - loss: 0.9623 - acc: 0.5342 - val_loss: 0.9950 - val_acc: 0.5344\n",
            "Epoch 145/150 - 0.09s - loss: 0.9620 - acc: 0.5376 - val_loss: 0.9947 - val_acc: 0.5344\n",
            "Epoch 146/150 - 0.09s - loss: 0.9616 - acc: 0.5342 - val_loss: 0.9945 - val_acc: 0.5364\n",
            "Epoch 147/150 - 0.09s - loss: 0.9608 - acc: 0.5373 - val_loss: 0.9937 - val_acc: 0.5405\n",
            "Epoch 148/150 - 0.09s - loss: 0.9609 - acc: 0.5418 - val_loss: 0.9937 - val_acc: 0.5385\n",
            "Epoch 149/150 - 0.09s - loss: 0.9598 - acc: 0.5378 - val_loss: 0.9931 - val_acc: 0.5385\n",
            "Epoch 150/150 - 0.09s - loss: 0.9593 - acc: 0.5369 - val_loss: 0.9929 - val_acc: 0.5405\n",
            "\n",
            "Combination 82/252:\n",
            "Hidden Layers: [128, 128], Activation: relu, Learning Rate: 0.001, Batch Size: 64, Epochs: 50\n",
            "Epoch 1/50 - 0.07s - loss: 1.1107 - acc: 0.3210 - val_loss: 1.1058 - val_acc: 0.3401\n",
            "Epoch 2/50 - 0.07s - loss: 1.1074 - acc: 0.3180 - val_loss: 1.1031 - val_acc: 0.3381\n",
            "Epoch 3/50 - 0.07s - loss: 1.1051 - acc: 0.3288 - val_loss: 1.1014 - val_acc: 0.3603\n",
            "Epoch 4/50 - 0.08s - loss: 1.1033 - acc: 0.3300 - val_loss: 1.1001 - val_acc: 0.3664\n",
            "Epoch 5/50 - 0.07s - loss: 1.1019 - acc: 0.3381 - val_loss: 1.0991 - val_acc: 0.3765\n",
            "Epoch 6/50 - 0.07s - loss: 1.1007 - acc: 0.3444 - val_loss: 1.0982 - val_acc: 0.3745\n",
            "Epoch 7/50 - 0.07s - loss: 1.0996 - acc: 0.3430 - val_loss: 1.0974 - val_acc: 0.3623\n",
            "Epoch 8/50 - 0.07s - loss: 1.0985 - acc: 0.3441 - val_loss: 1.0967 - val_acc: 0.3482\n",
            "Epoch 9/50 - 0.07s - loss: 1.0975 - acc: 0.3491 - val_loss: 1.0960 - val_acc: 0.3421\n",
            "Epoch 10/50 - 0.07s - loss: 1.0966 - acc: 0.3522 - val_loss: 1.0953 - val_acc: 0.3522\n",
            "Epoch 11/50 - 0.07s - loss: 1.0956 - acc: 0.3552 - val_loss: 1.0946 - val_acc: 0.3603\n",
            "Epoch 12/50 - 0.07s - loss: 1.0947 - acc: 0.3565 - val_loss: 1.0940 - val_acc: 0.3684\n",
            "Epoch 13/50 - 0.07s - loss: 1.0939 - acc: 0.3614 - val_loss: 1.0934 - val_acc: 0.3704\n",
            "Epoch 14/50 - 0.07s - loss: 1.0930 - acc: 0.3623 - val_loss: 1.0927 - val_acc: 0.3704\n",
            "Epoch 15/50 - 0.07s - loss: 1.0922 - acc: 0.3668 - val_loss: 1.0922 - val_acc: 0.3725\n",
            "Epoch 16/50 - 0.07s - loss: 1.0914 - acc: 0.3713 - val_loss: 1.0916 - val_acc: 0.3725\n",
            "Epoch 17/50 - 0.07s - loss: 1.0906 - acc: 0.3758 - val_loss: 1.0910 - val_acc: 0.3765\n",
            "Epoch 18/50 - 0.07s - loss: 1.0899 - acc: 0.3812 - val_loss: 1.0905 - val_acc: 0.3785\n",
            "Epoch 19/50 - 0.08s - loss: 1.0891 - acc: 0.3848 - val_loss: 1.0900 - val_acc: 0.3887\n",
            "Epoch 20/50 - 0.07s - loss: 1.0884 - acc: 0.3873 - val_loss: 1.0895 - val_acc: 0.3907\n",
            "Epoch 21/50 - 0.07s - loss: 1.0877 - acc: 0.3911 - val_loss: 1.0890 - val_acc: 0.3927\n",
            "Epoch 22/50 - 0.07s - loss: 1.0870 - acc: 0.3938 - val_loss: 1.0885 - val_acc: 0.3887\n",
            "Epoch 23/50 - 0.07s - loss: 1.0863 - acc: 0.3968 - val_loss: 1.0880 - val_acc: 0.3907\n",
            "Epoch 24/50 - 0.07s - loss: 1.0857 - acc: 0.3961 - val_loss: 1.0875 - val_acc: 0.3866\n",
            "Epoch 25/50 - 0.07s - loss: 1.0850 - acc: 0.3995 - val_loss: 1.0870 - val_acc: 0.3866\n",
            "Epoch 26/50 - 0.07s - loss: 1.0844 - acc: 0.3995 - val_loss: 1.0865 - val_acc: 0.3887\n",
            "Epoch 27/50 - 0.07s - loss: 1.0837 - acc: 0.4028 - val_loss: 1.0860 - val_acc: 0.3927\n",
            "Epoch 28/50 - 0.07s - loss: 1.0831 - acc: 0.4037 - val_loss: 1.0856 - val_acc: 0.3988\n",
            "Epoch 29/50 - 0.07s - loss: 1.0825 - acc: 0.4046 - val_loss: 1.0852 - val_acc: 0.4049\n",
            "Epoch 30/50 - 0.07s - loss: 1.0819 - acc: 0.4069 - val_loss: 1.0848 - val_acc: 0.3968\n",
            "Epoch 31/50 - 0.07s - loss: 1.0813 - acc: 0.4094 - val_loss: 1.0843 - val_acc: 0.3988\n",
            "Epoch 32/50 - 0.07s - loss: 1.0808 - acc: 0.4116 - val_loss: 1.0839 - val_acc: 0.4028\n",
            "Epoch 33/50 - 0.08s - loss: 1.0802 - acc: 0.4141 - val_loss: 1.0834 - val_acc: 0.4089\n",
            "Epoch 34/50 - 0.08s - loss: 1.0796 - acc: 0.4168 - val_loss: 1.0831 - val_acc: 0.4049\n",
            "Epoch 35/50 - 0.07s - loss: 1.0790 - acc: 0.4190 - val_loss: 1.0827 - val_acc: 0.4049\n",
            "Epoch 36/50 - 0.07s - loss: 1.0785 - acc: 0.4204 - val_loss: 1.0823 - val_acc: 0.4049\n",
            "Epoch 37/50 - 0.07s - loss: 1.0780 - acc: 0.4204 - val_loss: 1.0819 - val_acc: 0.4028\n",
            "Epoch 38/50 - 0.07s - loss: 1.0774 - acc: 0.4220 - val_loss: 1.0815 - val_acc: 0.4069\n",
            "Epoch 39/50 - 0.07s - loss: 1.0769 - acc: 0.4233 - val_loss: 1.0812 - val_acc: 0.4069\n",
            "Epoch 40/50 - 0.07s - loss: 1.0763 - acc: 0.4247 - val_loss: 1.0808 - val_acc: 0.4049\n",
            "Epoch 41/50 - 0.07s - loss: 1.0758 - acc: 0.4269 - val_loss: 1.0804 - val_acc: 0.4069\n",
            "Epoch 42/50 - 0.07s - loss: 1.0753 - acc: 0.4303 - val_loss: 1.0800 - val_acc: 0.4069\n",
            "Epoch 43/50 - 0.07s - loss: 1.0748 - acc: 0.4296 - val_loss: 1.0797 - val_acc: 0.4089\n",
            "Epoch 44/50 - 0.07s - loss: 1.0743 - acc: 0.4316 - val_loss: 1.0793 - val_acc: 0.4150\n",
            "Epoch 45/50 - 0.07s - loss: 1.0738 - acc: 0.4305 - val_loss: 1.0790 - val_acc: 0.4190\n",
            "Epoch 46/50 - 0.09s - loss: 1.0732 - acc: 0.4332 - val_loss: 1.0786 - val_acc: 0.4190\n",
            "Epoch 47/50 - 0.07s - loss: 1.0727 - acc: 0.4343 - val_loss: 1.0782 - val_acc: 0.4231\n",
            "Epoch 48/50 - 0.07s - loss: 1.0722 - acc: 0.4359 - val_loss: 1.0779 - val_acc: 0.4211\n",
            "Epoch 49/50 - 0.07s - loss: 1.0718 - acc: 0.4350 - val_loss: 1.0775 - val_acc: 0.4150\n",
            "Epoch 50/50 - 0.07s - loss: 1.0713 - acc: 0.4368 - val_loss: 1.0772 - val_acc: 0.4170\n",
            "\n",
            "Combination 83/252:\n",
            "Hidden Layers: [128, 128], Activation: relu, Learning Rate: 0.001, Batch Size: 64, Epochs: 100\n",
            "Epoch 1/100 - 0.07s - loss: 1.1074 - acc: 0.3140 - val_loss: 1.1080 - val_acc: 0.3016\n",
            "Epoch 2/100 - 0.07s - loss: 1.1047 - acc: 0.3133 - val_loss: 1.1061 - val_acc: 0.3036\n",
            "Epoch 3/100 - 0.07s - loss: 1.1029 - acc: 0.3185 - val_loss: 1.1049 - val_acc: 0.3077\n",
            "Epoch 4/100 - 0.07s - loss: 1.1016 - acc: 0.3230 - val_loss: 1.1040 - val_acc: 0.3178\n",
            "Epoch 5/100 - 0.08s - loss: 1.1004 - acc: 0.3342 - val_loss: 1.1032 - val_acc: 0.3239\n",
            "Epoch 6/100 - 0.07s - loss: 1.0993 - acc: 0.3446 - val_loss: 1.1025 - val_acc: 0.3178\n",
            "Epoch 7/100 - 0.07s - loss: 1.0983 - acc: 0.3522 - val_loss: 1.1018 - val_acc: 0.3279\n",
            "Epoch 8/100 - 0.07s - loss: 1.0973 - acc: 0.3531 - val_loss: 1.1011 - val_acc: 0.3300\n",
            "Epoch 9/100 - 0.08s - loss: 1.0964 - acc: 0.3594 - val_loss: 1.1004 - val_acc: 0.3360\n",
            "Epoch 10/100 - 0.07s - loss: 1.0955 - acc: 0.3610 - val_loss: 1.0997 - val_acc: 0.3259\n",
            "Epoch 11/100 - 0.07s - loss: 1.0946 - acc: 0.3648 - val_loss: 1.0991 - val_acc: 0.3300\n",
            "Epoch 12/100 - 0.08s - loss: 1.0938 - acc: 0.3682 - val_loss: 1.0984 - val_acc: 0.3340\n",
            "Epoch 13/100 - 0.07s - loss: 1.0930 - acc: 0.3713 - val_loss: 1.0977 - val_acc: 0.3421\n",
            "Epoch 14/100 - 0.07s - loss: 1.0921 - acc: 0.3740 - val_loss: 1.0971 - val_acc: 0.3421\n",
            "Epoch 15/100 - 0.07s - loss: 1.0913 - acc: 0.3799 - val_loss: 1.0964 - val_acc: 0.3381\n",
            "Epoch 16/100 - 0.07s - loss: 1.0905 - acc: 0.3839 - val_loss: 1.0958 - val_acc: 0.3421\n",
            "Epoch 17/100 - 0.07s - loss: 1.0897 - acc: 0.3873 - val_loss: 1.0952 - val_acc: 0.3522\n",
            "Epoch 18/100 - 0.07s - loss: 1.0889 - acc: 0.3911 - val_loss: 1.0946 - val_acc: 0.3522\n",
            "Epoch 19/100 - 0.07s - loss: 1.0881 - acc: 0.3943 - val_loss: 1.0940 - val_acc: 0.3583\n",
            "Epoch 20/100 - 0.07s - loss: 1.0874 - acc: 0.3999 - val_loss: 1.0934 - val_acc: 0.3583\n",
            "Epoch 21/100 - 0.07s - loss: 1.0866 - acc: 0.4026 - val_loss: 1.0928 - val_acc: 0.3583\n",
            "Epoch 22/100 - 0.08s - loss: 1.0859 - acc: 0.4078 - val_loss: 1.0923 - val_acc: 0.3603\n",
            "Epoch 23/100 - 0.07s - loss: 1.0852 - acc: 0.4127 - val_loss: 1.0918 - val_acc: 0.3603\n",
            "Epoch 24/100 - 0.07s - loss: 1.0845 - acc: 0.4166 - val_loss: 1.0912 - val_acc: 0.3644\n",
            "Epoch 25/100 - 0.07s - loss: 1.0838 - acc: 0.4195 - val_loss: 1.0907 - val_acc: 0.3563\n",
            "Epoch 26/100 - 0.07s - loss: 1.0831 - acc: 0.4208 - val_loss: 1.0902 - val_acc: 0.3522\n",
            "Epoch 27/100 - 0.07s - loss: 1.0825 - acc: 0.4226 - val_loss: 1.0897 - val_acc: 0.3522\n",
            "Epoch 28/100 - 0.07s - loss: 1.0818 - acc: 0.4269 - val_loss: 1.0892 - val_acc: 0.3623\n",
            "Epoch 29/100 - 0.07s - loss: 1.0811 - acc: 0.4303 - val_loss: 1.0887 - val_acc: 0.3623\n",
            "Epoch 30/100 - 0.07s - loss: 1.0805 - acc: 0.4291 - val_loss: 1.0882 - val_acc: 0.3644\n",
            "Epoch 31/100 - 0.07s - loss: 1.0799 - acc: 0.4323 - val_loss: 1.0878 - val_acc: 0.3664\n",
            "Epoch 32/100 - 0.07s - loss: 1.0792 - acc: 0.4327 - val_loss: 1.0873 - val_acc: 0.3704\n",
            "Epoch 33/100 - 0.09s - loss: 1.0786 - acc: 0.4332 - val_loss: 1.0868 - val_acc: 0.3684\n",
            "Epoch 34/100 - 0.07s - loss: 1.0780 - acc: 0.4327 - val_loss: 1.0863 - val_acc: 0.3725\n",
            "Epoch 35/100 - 0.07s - loss: 1.0774 - acc: 0.4350 - val_loss: 1.0859 - val_acc: 0.3704\n",
            "Epoch 36/100 - 0.08s - loss: 1.0768 - acc: 0.4363 - val_loss: 1.0855 - val_acc: 0.3725\n",
            "Epoch 37/100 - 0.07s - loss: 1.0762 - acc: 0.4366 - val_loss: 1.0851 - val_acc: 0.3664\n",
            "Epoch 38/100 - 0.07s - loss: 1.0756 - acc: 0.4388 - val_loss: 1.0846 - val_acc: 0.3664\n",
            "Epoch 39/100 - 0.07s - loss: 1.0750 - acc: 0.4397 - val_loss: 1.0842 - val_acc: 0.3684\n",
            "Epoch 40/100 - 0.07s - loss: 1.0745 - acc: 0.4386 - val_loss: 1.0838 - val_acc: 0.3644\n",
            "Epoch 41/100 - 0.07s - loss: 1.0739 - acc: 0.4395 - val_loss: 1.0833 - val_acc: 0.3704\n",
            "Epoch 42/100 - 0.07s - loss: 1.0734 - acc: 0.4440 - val_loss: 1.0829 - val_acc: 0.3765\n",
            "Epoch 43/100 - 0.07s - loss: 1.0728 - acc: 0.4465 - val_loss: 1.0825 - val_acc: 0.3765\n",
            "Epoch 44/100 - 0.07s - loss: 1.0723 - acc: 0.4469 - val_loss: 1.0821 - val_acc: 0.3826\n",
            "Epoch 45/100 - 0.07s - loss: 1.0718 - acc: 0.4471 - val_loss: 1.0817 - val_acc: 0.3826\n",
            "Epoch 46/100 - 0.07s - loss: 1.0712 - acc: 0.4485 - val_loss: 1.0814 - val_acc: 0.3826\n",
            "Epoch 47/100 - 0.07s - loss: 1.0707 - acc: 0.4480 - val_loss: 1.0810 - val_acc: 0.3826\n",
            "Epoch 48/100 - 0.07s - loss: 1.0702 - acc: 0.4487 - val_loss: 1.0806 - val_acc: 0.3866\n",
            "Epoch 49/100 - 0.07s - loss: 1.0697 - acc: 0.4487 - val_loss: 1.0803 - val_acc: 0.3866\n",
            "Epoch 50/100 - 0.08s - loss: 1.0692 - acc: 0.4507 - val_loss: 1.0799 - val_acc: 0.3866\n",
            "Epoch 51/100 - 0.07s - loss: 1.0688 - acc: 0.4523 - val_loss: 1.0796 - val_acc: 0.3866\n",
            "Epoch 52/100 - 0.07s - loss: 1.0683 - acc: 0.4534 - val_loss: 1.0792 - val_acc: 0.3907\n",
            "Epoch 53/100 - 0.07s - loss: 1.0678 - acc: 0.4559 - val_loss: 1.0789 - val_acc: 0.3968\n",
            "Epoch 54/100 - 0.07s - loss: 1.0673 - acc: 0.4555 - val_loss: 1.0784 - val_acc: 0.4008\n",
            "Epoch 55/100 - 0.07s - loss: 1.0669 - acc: 0.4548 - val_loss: 1.0780 - val_acc: 0.4069\n",
            "Epoch 56/100 - 0.07s - loss: 1.0664 - acc: 0.4582 - val_loss: 1.0777 - val_acc: 0.4069\n",
            "Epoch 57/100 - 0.07s - loss: 1.0660 - acc: 0.4595 - val_loss: 1.0774 - val_acc: 0.4069\n",
            "Epoch 58/100 - 0.07s - loss: 1.0655 - acc: 0.4611 - val_loss: 1.0771 - val_acc: 0.4008\n",
            "Epoch 59/100 - 0.07s - loss: 1.0651 - acc: 0.4618 - val_loss: 1.0768 - val_acc: 0.4049\n",
            "Epoch 60/100 - 0.07s - loss: 1.0646 - acc: 0.4631 - val_loss: 1.0764 - val_acc: 0.4089\n",
            "Epoch 61/100 - 0.07s - loss: 1.0642 - acc: 0.4636 - val_loss: 1.0761 - val_acc: 0.4130\n",
            "Epoch 62/100 - 0.07s - loss: 1.0637 - acc: 0.4629 - val_loss: 1.0758 - val_acc: 0.4130\n",
            "Epoch 63/100 - 0.07s - loss: 1.0633 - acc: 0.4620 - val_loss: 1.0755 - val_acc: 0.4190\n",
            "Epoch 64/100 - 0.08s - loss: 1.0629 - acc: 0.4624 - val_loss: 1.0752 - val_acc: 0.4211\n",
            "Epoch 65/100 - 0.07s - loss: 1.0624 - acc: 0.4627 - val_loss: 1.0749 - val_acc: 0.4231\n",
            "Epoch 66/100 - 0.07s - loss: 1.0620 - acc: 0.4633 - val_loss: 1.0746 - val_acc: 0.4251\n",
            "Epoch 67/100 - 0.07s - loss: 1.0616 - acc: 0.4638 - val_loss: 1.0743 - val_acc: 0.4251\n",
            "Epoch 68/100 - 0.07s - loss: 1.0611 - acc: 0.4645 - val_loss: 1.0741 - val_acc: 0.4231\n",
            "Epoch 69/100 - 0.07s - loss: 1.0607 - acc: 0.4656 - val_loss: 1.0737 - val_acc: 0.4190\n",
            "Epoch 70/100 - 0.07s - loss: 1.0603 - acc: 0.4658 - val_loss: 1.0735 - val_acc: 0.4251\n",
            "Epoch 71/100 - 0.07s - loss: 1.0599 - acc: 0.4656 - val_loss: 1.0733 - val_acc: 0.4231\n",
            "Epoch 72/100 - 0.07s - loss: 1.0594 - acc: 0.4660 - val_loss: 1.0730 - val_acc: 0.4231\n",
            "Epoch 73/100 - 0.07s - loss: 1.0590 - acc: 0.4658 - val_loss: 1.0727 - val_acc: 0.4211\n",
            "Epoch 74/100 - 0.07s - loss: 1.0586 - acc: 0.4663 - val_loss: 1.0724 - val_acc: 0.4211\n",
            "Epoch 75/100 - 0.07s - loss: 1.0582 - acc: 0.4681 - val_loss: 1.0720 - val_acc: 0.4271\n",
            "Epoch 76/100 - 0.07s - loss: 1.0578 - acc: 0.4683 - val_loss: 1.0718 - val_acc: 0.4271\n",
            "Epoch 77/100 - 0.09s - loss: 1.0574 - acc: 0.4678 - val_loss: 1.0715 - val_acc: 0.4251\n",
            "Epoch 78/100 - 0.07s - loss: 1.0570 - acc: 0.4703 - val_loss: 1.0713 - val_acc: 0.4312\n",
            "Epoch 79/100 - 0.07s - loss: 1.0566 - acc: 0.4703 - val_loss: 1.0710 - val_acc: 0.4312\n",
            "Epoch 80/100 - 0.07s - loss: 1.0562 - acc: 0.4701 - val_loss: 1.0707 - val_acc: 0.4271\n",
            "Epoch 81/100 - 0.07s - loss: 1.0558 - acc: 0.4728 - val_loss: 1.0704 - val_acc: 0.4332\n",
            "Epoch 82/100 - 0.07s - loss: 1.0554 - acc: 0.4705 - val_loss: 1.0702 - val_acc: 0.4312\n",
            "Epoch 83/100 - 0.08s - loss: 1.0550 - acc: 0.4726 - val_loss: 1.0699 - val_acc: 0.4332\n",
            "Epoch 84/100 - 0.08s - loss: 1.0546 - acc: 0.4735 - val_loss: 1.0697 - val_acc: 0.4352\n",
            "Epoch 85/100 - 0.07s - loss: 1.0542 - acc: 0.4730 - val_loss: 1.0694 - val_acc: 0.4332\n",
            "Epoch 86/100 - 0.07s - loss: 1.0538 - acc: 0.4726 - val_loss: 1.0691 - val_acc: 0.4332\n",
            "Epoch 87/100 - 0.07s - loss: 1.0535 - acc: 0.4732 - val_loss: 1.0689 - val_acc: 0.4352\n",
            "Epoch 88/100 - 0.07s - loss: 1.0531 - acc: 0.4726 - val_loss: 1.0687 - val_acc: 0.4352\n",
            "Epoch 89/100 - 0.07s - loss: 1.0527 - acc: 0.4723 - val_loss: 1.0685 - val_acc: 0.4332\n",
            "Epoch 90/100 - 0.08s - loss: 1.0523 - acc: 0.4728 - val_loss: 1.0682 - val_acc: 0.4332\n",
            "Epoch 91/100 - 0.07s - loss: 1.0519 - acc: 0.4721 - val_loss: 1.0679 - val_acc: 0.4372\n",
            "Epoch 92/100 - 0.07s - loss: 1.0515 - acc: 0.4728 - val_loss: 1.0677 - val_acc: 0.4352\n",
            "Epoch 93/100 - 0.07s - loss: 1.0512 - acc: 0.4721 - val_loss: 1.0675 - val_acc: 0.4352\n",
            "Epoch 94/100 - 0.07s - loss: 1.0508 - acc: 0.4728 - val_loss: 1.0673 - val_acc: 0.4372\n",
            "Epoch 95/100 - 0.07s - loss: 1.0504 - acc: 0.4730 - val_loss: 1.0671 - val_acc: 0.4312\n",
            "Epoch 96/100 - 0.07s - loss: 1.0500 - acc: 0.4719 - val_loss: 1.0669 - val_acc: 0.4352\n",
            "Epoch 97/100 - 0.07s - loss: 1.0496 - acc: 0.4717 - val_loss: 1.0666 - val_acc: 0.4312\n",
            "Epoch 98/100 - 0.07s - loss: 1.0493 - acc: 0.4721 - val_loss: 1.0663 - val_acc: 0.4352\n",
            "Epoch 99/100 - 0.07s - loss: 1.0489 - acc: 0.4726 - val_loss: 1.0662 - val_acc: 0.4312\n",
            "Epoch 100/100 - 0.07s - loss: 1.0485 - acc: 0.4726 - val_loss: 1.0659 - val_acc: 0.4332\n",
            "\n",
            "Combination 84/252:\n",
            "Hidden Layers: [128, 128], Activation: relu, Learning Rate: 0.001, Batch Size: 64, Epochs: 150\n",
            "Epoch 1/150 - 0.07s - loss: 1.1155 - acc: 0.3234 - val_loss: 1.1216 - val_acc: 0.3117\n",
            "Epoch 2/150 - 0.07s - loss: 1.1098 - acc: 0.3196 - val_loss: 1.1149 - val_acc: 0.3057\n",
            "Epoch 3/150 - 0.08s - loss: 1.1064 - acc: 0.3194 - val_loss: 1.1108 - val_acc: 0.2996\n",
            "Epoch 4/150 - 0.07s - loss: 1.1041 - acc: 0.3230 - val_loss: 1.1080 - val_acc: 0.2976\n",
            "Epoch 5/150 - 0.07s - loss: 1.1023 - acc: 0.3255 - val_loss: 1.1060 - val_acc: 0.3117\n",
            "Epoch 6/150 - 0.07s - loss: 1.1007 - acc: 0.3363 - val_loss: 1.1043 - val_acc: 0.3279\n",
            "Epoch 7/150 - 0.07s - loss: 1.0993 - acc: 0.3421 - val_loss: 1.1029 - val_acc: 0.3219\n",
            "Epoch 8/150 - 0.07s - loss: 1.0980 - acc: 0.3525 - val_loss: 1.1016 - val_acc: 0.3219\n",
            "Epoch 9/150 - 0.07s - loss: 1.0967 - acc: 0.3545 - val_loss: 1.1005 - val_acc: 0.3239\n",
            "Epoch 10/150 - 0.07s - loss: 1.0956 - acc: 0.3587 - val_loss: 1.0995 - val_acc: 0.3300\n",
            "Epoch 11/150 - 0.08s - loss: 1.0945 - acc: 0.3650 - val_loss: 1.0986 - val_acc: 0.3360\n",
            "Epoch 12/150 - 0.07s - loss: 1.0934 - acc: 0.3729 - val_loss: 1.0977 - val_acc: 0.3462\n",
            "Epoch 13/150 - 0.07s - loss: 1.0923 - acc: 0.3754 - val_loss: 1.0969 - val_acc: 0.3502\n",
            "Epoch 14/150 - 0.07s - loss: 1.0913 - acc: 0.3815 - val_loss: 1.0961 - val_acc: 0.3543\n",
            "Epoch 15/150 - 0.08s - loss: 1.0904 - acc: 0.3866 - val_loss: 1.0954 - val_acc: 0.3603\n",
            "Epoch 16/150 - 0.07s - loss: 1.0894 - acc: 0.3889 - val_loss: 1.0946 - val_acc: 0.3664\n",
            "Epoch 17/150 - 0.08s - loss: 1.0884 - acc: 0.3941 - val_loss: 1.0939 - val_acc: 0.3725\n",
            "Epoch 18/150 - 0.08s - loss: 1.0875 - acc: 0.3965 - val_loss: 1.0932 - val_acc: 0.3725\n",
            "Epoch 19/150 - 0.07s - loss: 1.0866 - acc: 0.4035 - val_loss: 1.0925 - val_acc: 0.3765\n",
            "Epoch 20/150 - 0.07s - loss: 1.0857 - acc: 0.4069 - val_loss: 1.0918 - val_acc: 0.3704\n",
            "Epoch 21/150 - 0.08s - loss: 1.0849 - acc: 0.4080 - val_loss: 1.0913 - val_acc: 0.3745\n",
            "Epoch 22/150 - 0.07s - loss: 1.0840 - acc: 0.4112 - val_loss: 1.0907 - val_acc: 0.3806\n",
            "Epoch 23/150 - 0.07s - loss: 1.0832 - acc: 0.4112 - val_loss: 1.0900 - val_acc: 0.3846\n",
            "Epoch 24/150 - 0.07s - loss: 1.0824 - acc: 0.4154 - val_loss: 1.0894 - val_acc: 0.3887\n",
            "Epoch 25/150 - 0.07s - loss: 1.0816 - acc: 0.4195 - val_loss: 1.0888 - val_acc: 0.3826\n",
            "Epoch 26/150 - 0.07s - loss: 1.0808 - acc: 0.4226 - val_loss: 1.0883 - val_acc: 0.3927\n",
            "Epoch 27/150 - 0.07s - loss: 1.0800 - acc: 0.4244 - val_loss: 1.0877 - val_acc: 0.3927\n",
            "Epoch 28/150 - 0.07s - loss: 1.0793 - acc: 0.4260 - val_loss: 1.0871 - val_acc: 0.3947\n",
            "Epoch 29/150 - 0.07s - loss: 1.0785 - acc: 0.4269 - val_loss: 1.0866 - val_acc: 0.3947\n",
            "Epoch 30/150 - 0.08s - loss: 1.0778 - acc: 0.4289 - val_loss: 1.0860 - val_acc: 0.3927\n",
            "Epoch 31/150 - 0.07s - loss: 1.0771 - acc: 0.4312 - val_loss: 1.0855 - val_acc: 0.3988\n",
            "Epoch 32/150 - 0.08s - loss: 1.0764 - acc: 0.4314 - val_loss: 1.0850 - val_acc: 0.3988\n",
            "Epoch 33/150 - 0.07s - loss: 1.0757 - acc: 0.4357 - val_loss: 1.0845 - val_acc: 0.4008\n",
            "Epoch 34/150 - 0.07s - loss: 1.0750 - acc: 0.4375 - val_loss: 1.0841 - val_acc: 0.3988\n",
            "Epoch 35/150 - 0.07s - loss: 1.0743 - acc: 0.4402 - val_loss: 1.0836 - val_acc: 0.4028\n",
            "Epoch 36/150 - 0.07s - loss: 1.0736 - acc: 0.4408 - val_loss: 1.0831 - val_acc: 0.3988\n",
            "Epoch 37/150 - 0.10s - loss: 1.0729 - acc: 0.4449 - val_loss: 1.0826 - val_acc: 0.3988\n",
            "Epoch 38/150 - 0.08s - loss: 1.0723 - acc: 0.4456 - val_loss: 1.0822 - val_acc: 0.4008\n",
            "Epoch 39/150 - 0.07s - loss: 1.0716 - acc: 0.4451 - val_loss: 1.0817 - val_acc: 0.4049\n",
            "Epoch 40/150 - 0.08s - loss: 1.0710 - acc: 0.4462 - val_loss: 1.0812 - val_acc: 0.4069\n",
            "Epoch 41/150 - 0.08s - loss: 1.0703 - acc: 0.4467 - val_loss: 1.0808 - val_acc: 0.4109\n",
            "Epoch 42/150 - 0.07s - loss: 1.0697 - acc: 0.4471 - val_loss: 1.0803 - val_acc: 0.4170\n",
            "Epoch 43/150 - 0.07s - loss: 1.0691 - acc: 0.4496 - val_loss: 1.0799 - val_acc: 0.4231\n",
            "Epoch 44/150 - 0.08s - loss: 1.0685 - acc: 0.4505 - val_loss: 1.0794 - val_acc: 0.4231\n",
            "Epoch 45/150 - 0.07s - loss: 1.0679 - acc: 0.4512 - val_loss: 1.0790 - val_acc: 0.4271\n",
            "Epoch 46/150 - 0.07s - loss: 1.0673 - acc: 0.4537 - val_loss: 1.0785 - val_acc: 0.4251\n",
            "Epoch 47/150 - 0.08s - loss: 1.0667 - acc: 0.4543 - val_loss: 1.0782 - val_acc: 0.4251\n",
            "Epoch 48/150 - 0.07s - loss: 1.0661 - acc: 0.4577 - val_loss: 1.0776 - val_acc: 0.4312\n",
            "Epoch 49/150 - 0.07s - loss: 1.0655 - acc: 0.4584 - val_loss: 1.0772 - val_acc: 0.4332\n",
            "Epoch 50/150 - 0.07s - loss: 1.0650 - acc: 0.4597 - val_loss: 1.0769 - val_acc: 0.4352\n",
            "Epoch 51/150 - 0.07s - loss: 1.0644 - acc: 0.4593 - val_loss: 1.0765 - val_acc: 0.4332\n",
            "Epoch 52/150 - 0.07s - loss: 1.0638 - acc: 0.4597 - val_loss: 1.0761 - val_acc: 0.4352\n",
            "Epoch 53/150 - 0.07s - loss: 1.0633 - acc: 0.4611 - val_loss: 1.0757 - val_acc: 0.4352\n",
            "Epoch 54/150 - 0.08s - loss: 1.0627 - acc: 0.4620 - val_loss: 1.0753 - val_acc: 0.4352\n",
            "Epoch 55/150 - 0.11s - loss: 1.0622 - acc: 0.4615 - val_loss: 1.0749 - val_acc: 0.4352\n",
            "Epoch 56/150 - 0.08s - loss: 1.0616 - acc: 0.4640 - val_loss: 1.0745 - val_acc: 0.4332\n",
            "Epoch 57/150 - 0.08s - loss: 1.0611 - acc: 0.4640 - val_loss: 1.0741 - val_acc: 0.4413\n",
            "Epoch 58/150 - 0.08s - loss: 1.0605 - acc: 0.4663 - val_loss: 1.0738 - val_acc: 0.4332\n",
            "Epoch 59/150 - 0.08s - loss: 1.0600 - acc: 0.4663 - val_loss: 1.0734 - val_acc: 0.4393\n",
            "Epoch 60/150 - 0.07s - loss: 1.0594 - acc: 0.4665 - val_loss: 1.0731 - val_acc: 0.4453\n",
            "Epoch 61/150 - 0.08s - loss: 1.0589 - acc: 0.4674 - val_loss: 1.0727 - val_acc: 0.4453\n",
            "Epoch 62/150 - 0.07s - loss: 1.0583 - acc: 0.4685 - val_loss: 1.0723 - val_acc: 0.4453\n",
            "Epoch 63/150 - 0.07s - loss: 1.0578 - acc: 0.4685 - val_loss: 1.0720 - val_acc: 0.4413\n",
            "Epoch 64/150 - 0.08s - loss: 1.0573 - acc: 0.4705 - val_loss: 1.0716 - val_acc: 0.4413\n",
            "Epoch 65/150 - 0.08s - loss: 1.0568 - acc: 0.4699 - val_loss: 1.0713 - val_acc: 0.4393\n",
            "Epoch 66/150 - 0.08s - loss: 1.0562 - acc: 0.4699 - val_loss: 1.0710 - val_acc: 0.4453\n",
            "Epoch 67/150 - 0.08s - loss: 1.0557 - acc: 0.4687 - val_loss: 1.0707 - val_acc: 0.4413\n",
            "Epoch 68/150 - 0.07s - loss: 1.0552 - acc: 0.4714 - val_loss: 1.0703 - val_acc: 0.4433\n",
            "Epoch 69/150 - 0.07s - loss: 1.0547 - acc: 0.4739 - val_loss: 1.0699 - val_acc: 0.4494\n",
            "Epoch 70/150 - 0.08s - loss: 1.0542 - acc: 0.4741 - val_loss: 1.0696 - val_acc: 0.4474\n",
            "Epoch 71/150 - 0.07s - loss: 1.0537 - acc: 0.4730 - val_loss: 1.0693 - val_acc: 0.4474\n",
            "Epoch 72/150 - 0.07s - loss: 1.0532 - acc: 0.4750 - val_loss: 1.0689 - val_acc: 0.4474\n",
            "Epoch 73/150 - 0.07s - loss: 1.0527 - acc: 0.4782 - val_loss: 1.0685 - val_acc: 0.4494\n",
            "Epoch 74/150 - 0.07s - loss: 1.0522 - acc: 0.4786 - val_loss: 1.0682 - val_acc: 0.4494\n",
            "Epoch 75/150 - 0.07s - loss: 1.0517 - acc: 0.4804 - val_loss: 1.0679 - val_acc: 0.4474\n",
            "Epoch 76/150 - 0.07s - loss: 1.0512 - acc: 0.4809 - val_loss: 1.0676 - val_acc: 0.4534\n",
            "Epoch 77/150 - 0.07s - loss: 1.0508 - acc: 0.4813 - val_loss: 1.0673 - val_acc: 0.4534\n",
            "Epoch 78/150 - 0.07s - loss: 1.0503 - acc: 0.4816 - val_loss: 1.0670 - val_acc: 0.4534\n",
            "Epoch 79/150 - 0.08s - loss: 1.0498 - acc: 0.4836 - val_loss: 1.0667 - val_acc: 0.4575\n",
            "Epoch 80/150 - 0.07s - loss: 1.0493 - acc: 0.4845 - val_loss: 1.0663 - val_acc: 0.4514\n",
            "Epoch 81/150 - 0.07s - loss: 1.0489 - acc: 0.4852 - val_loss: 1.0660 - val_acc: 0.4555\n",
            "Epoch 82/150 - 0.09s - loss: 1.0484 - acc: 0.4831 - val_loss: 1.0658 - val_acc: 0.4453\n",
            "Epoch 83/150 - 0.07s - loss: 1.0479 - acc: 0.4849 - val_loss: 1.0655 - val_acc: 0.4534\n",
            "Epoch 84/150 - 0.08s - loss: 1.0474 - acc: 0.4858 - val_loss: 1.0652 - val_acc: 0.4555\n",
            "Epoch 85/150 - 0.07s - loss: 1.0470 - acc: 0.4852 - val_loss: 1.0649 - val_acc: 0.4534\n",
            "Epoch 86/150 - 0.07s - loss: 1.0465 - acc: 0.4861 - val_loss: 1.0646 - val_acc: 0.4534\n",
            "Epoch 87/150 - 0.06s - loss: 1.0461 - acc: 0.4856 - val_loss: 1.0643 - val_acc: 0.4514\n",
            "Epoch 88/150 - 0.07s - loss: 1.0456 - acc: 0.4863 - val_loss: 1.0640 - val_acc: 0.4514\n",
            "Epoch 89/150 - 0.06s - loss: 1.0451 - acc: 0.4858 - val_loss: 1.0637 - val_acc: 0.4514\n",
            "Epoch 90/150 - 0.07s - loss: 1.0447 - acc: 0.4865 - val_loss: 1.0634 - val_acc: 0.4534\n",
            "Epoch 91/150 - 0.07s - loss: 1.0442 - acc: 0.4870 - val_loss: 1.0631 - val_acc: 0.4534\n",
            "Epoch 92/150 - 0.06s - loss: 1.0438 - acc: 0.4881 - val_loss: 1.0628 - val_acc: 0.4514\n",
            "Epoch 93/150 - 0.06s - loss: 1.0433 - acc: 0.4876 - val_loss: 1.0625 - val_acc: 0.4514\n",
            "Epoch 94/150 - 0.06s - loss: 1.0429 - acc: 0.4888 - val_loss: 1.0623 - val_acc: 0.4514\n",
            "Epoch 95/150 - 0.07s - loss: 1.0424 - acc: 0.4906 - val_loss: 1.0620 - val_acc: 0.4494\n",
            "Epoch 96/150 - 0.07s - loss: 1.0420 - acc: 0.4899 - val_loss: 1.0616 - val_acc: 0.4534\n",
            "Epoch 97/150 - 0.06s - loss: 1.0415 - acc: 0.4917 - val_loss: 1.0614 - val_acc: 0.4555\n",
            "Epoch 98/150 - 0.06s - loss: 1.0411 - acc: 0.4912 - val_loss: 1.0610 - val_acc: 0.4534\n",
            "Epoch 99/150 - 0.07s - loss: 1.0407 - acc: 0.4933 - val_loss: 1.0607 - val_acc: 0.4555\n",
            "Epoch 100/150 - 0.06s - loss: 1.0402 - acc: 0.4930 - val_loss: 1.0604 - val_acc: 0.4595\n",
            "Epoch 101/150 - 0.06s - loss: 1.0398 - acc: 0.4935 - val_loss: 1.0601 - val_acc: 0.4575\n",
            "Epoch 102/150 - 0.06s - loss: 1.0393 - acc: 0.4933 - val_loss: 1.0598 - val_acc: 0.4555\n",
            "Epoch 103/150 - 0.07s - loss: 1.0389 - acc: 0.4937 - val_loss: 1.0594 - val_acc: 0.4615\n",
            "Epoch 104/150 - 0.06s - loss: 1.0385 - acc: 0.4937 - val_loss: 1.0591 - val_acc: 0.4595\n",
            "Epoch 105/150 - 0.06s - loss: 1.0380 - acc: 0.4939 - val_loss: 1.0588 - val_acc: 0.4595\n",
            "Epoch 106/150 - 0.06s - loss: 1.0376 - acc: 0.4948 - val_loss: 1.0586 - val_acc: 0.4615\n",
            "Epoch 107/150 - 0.07s - loss: 1.0372 - acc: 0.4930 - val_loss: 1.0583 - val_acc: 0.4555\n",
            "Epoch 108/150 - 0.06s - loss: 1.0368 - acc: 0.4939 - val_loss: 1.0580 - val_acc: 0.4575\n",
            "Epoch 109/150 - 0.06s - loss: 1.0363 - acc: 0.4944 - val_loss: 1.0576 - val_acc: 0.4575\n",
            "Epoch 110/150 - 0.06s - loss: 1.0359 - acc: 0.4953 - val_loss: 1.0573 - val_acc: 0.4615\n",
            "Epoch 111/150 - 0.07s - loss: 1.0355 - acc: 0.4951 - val_loss: 1.0571 - val_acc: 0.4636\n",
            "Epoch 112/150 - 0.07s - loss: 1.0351 - acc: 0.4962 - val_loss: 1.0568 - val_acc: 0.4636\n",
            "Epoch 113/150 - 0.06s - loss: 1.0346 - acc: 0.4973 - val_loss: 1.0566 - val_acc: 0.4656\n",
            "Epoch 114/150 - 0.06s - loss: 1.0342 - acc: 0.4975 - val_loss: 1.0563 - val_acc: 0.4636\n",
            "Epoch 115/150 - 0.07s - loss: 1.0338 - acc: 0.4957 - val_loss: 1.0560 - val_acc: 0.4676\n",
            "Epoch 116/150 - 0.06s - loss: 1.0334 - acc: 0.4987 - val_loss: 1.0557 - val_acc: 0.4656\n",
            "Epoch 117/150 - 0.06s - loss: 1.0330 - acc: 0.4984 - val_loss: 1.0554 - val_acc: 0.4696\n",
            "Epoch 118/150 - 0.06s - loss: 1.0326 - acc: 0.4998 - val_loss: 1.0552 - val_acc: 0.4737\n",
            "Epoch 119/150 - 0.07s - loss: 1.0321 - acc: 0.5000 - val_loss: 1.0549 - val_acc: 0.4696\n",
            "Epoch 120/150 - 0.07s - loss: 1.0317 - acc: 0.4993 - val_loss: 1.0546 - val_acc: 0.4696\n",
            "Epoch 121/150 - 0.07s - loss: 1.0313 - acc: 0.5007 - val_loss: 1.0543 - val_acc: 0.4696\n",
            "Epoch 122/150 - 0.07s - loss: 1.0309 - acc: 0.5013 - val_loss: 1.0541 - val_acc: 0.4696\n",
            "Epoch 123/150 - 0.07s - loss: 1.0305 - acc: 0.4993 - val_loss: 1.0538 - val_acc: 0.4717\n",
            "Epoch 124/150 - 0.06s - loss: 1.0300 - acc: 0.5016 - val_loss: 1.0535 - val_acc: 0.4717\n",
            "Epoch 125/150 - 0.06s - loss: 1.0296 - acc: 0.4991 - val_loss: 1.0532 - val_acc: 0.4757\n",
            "Epoch 126/150 - 0.06s - loss: 1.0292 - acc: 0.5018 - val_loss: 1.0530 - val_acc: 0.4737\n",
            "Epoch 127/150 - 0.08s - loss: 1.0288 - acc: 0.5020 - val_loss: 1.0527 - val_acc: 0.4717\n",
            "Epoch 128/150 - 0.06s - loss: 1.0284 - acc: 0.5018 - val_loss: 1.0524 - val_acc: 0.4737\n",
            "Epoch 129/150 - 0.06s - loss: 1.0280 - acc: 0.5031 - val_loss: 1.0522 - val_acc: 0.4777\n",
            "Epoch 130/150 - 0.07s - loss: 1.0276 - acc: 0.5038 - val_loss: 1.0519 - val_acc: 0.4676\n",
            "Epoch 131/150 - 0.08s - loss: 1.0271 - acc: 0.5040 - val_loss: 1.0516 - val_acc: 0.4777\n",
            "Epoch 132/150 - 0.08s - loss: 1.0267 - acc: 0.5054 - val_loss: 1.0513 - val_acc: 0.4676\n",
            "Epoch 133/150 - 0.07s - loss: 1.0263 - acc: 0.5061 - val_loss: 1.0511 - val_acc: 0.4696\n",
            "Epoch 134/150 - 0.07s - loss: 1.0259 - acc: 0.5054 - val_loss: 1.0508 - val_acc: 0.4717\n",
            "Epoch 135/150 - 0.09s - loss: 1.0255 - acc: 0.5056 - val_loss: 1.0505 - val_acc: 0.4696\n",
            "Epoch 136/150 - 0.08s - loss: 1.0251 - acc: 0.5054 - val_loss: 1.0502 - val_acc: 0.4696\n",
            "Epoch 137/150 - 0.09s - loss: 1.0247 - acc: 0.5061 - val_loss: 1.0500 - val_acc: 0.4696\n",
            "Epoch 138/150 - 0.10s - loss: 1.0243 - acc: 0.5083 - val_loss: 1.0498 - val_acc: 0.4737\n",
            "Epoch 139/150 - 0.07s - loss: 1.0239 - acc: 0.5056 - val_loss: 1.0495 - val_acc: 0.4717\n",
            "Epoch 140/150 - 0.08s - loss: 1.0235 - acc: 0.5043 - val_loss: 1.0492 - val_acc: 0.4737\n",
            "Epoch 141/150 - 0.07s - loss: 1.0231 - acc: 0.5083 - val_loss: 1.0490 - val_acc: 0.4757\n",
            "Epoch 142/150 - 0.07s - loss: 1.0227 - acc: 0.5049 - val_loss: 1.0487 - val_acc: 0.4717\n",
            "Epoch 143/150 - 0.07s - loss: 1.0223 - acc: 0.5094 - val_loss: 1.0485 - val_acc: 0.4737\n",
            "Epoch 144/150 - 0.07s - loss: 1.0219 - acc: 0.5101 - val_loss: 1.0483 - val_acc: 0.4757\n",
            "Epoch 145/150 - 0.07s - loss: 1.0215 - acc: 0.5081 - val_loss: 1.0480 - val_acc: 0.4757\n",
            "Epoch 146/150 - 0.07s - loss: 1.0211 - acc: 0.5074 - val_loss: 1.0477 - val_acc: 0.4777\n",
            "Epoch 147/150 - 0.07s - loss: 1.0207 - acc: 0.5101 - val_loss: 1.0475 - val_acc: 0.4717\n",
            "Epoch 148/150 - 0.07s - loss: 1.0203 - acc: 0.5110 - val_loss: 1.0472 - val_acc: 0.4737\n",
            "Epoch 149/150 - 0.07s - loss: 1.0199 - acc: 0.5070 - val_loss: 1.0469 - val_acc: 0.4777\n",
            "Epoch 150/150 - 0.07s - loss: 1.0195 - acc: 0.5090 - val_loss: 1.0467 - val_acc: 0.4717\n",
            "\n",
            "Combination 85/252:\n",
            "Hidden Layers: [128, 128], Activation: relu, Learning Rate: 0.0001, Batch Size: 32, Epochs: 50\n",
            "Epoch 1/50 - 0.09s - loss: 1.1099 - acc: 0.3318 - val_loss: 1.1061 - val_acc: 0.3259\n",
            "Epoch 2/50 - 0.09s - loss: 1.1092 - acc: 0.3306 - val_loss: 1.1054 - val_acc: 0.3279\n",
            "Epoch 3/50 - 0.10s - loss: 1.1086 - acc: 0.3306 - val_loss: 1.1048 - val_acc: 0.3320\n",
            "Epoch 4/50 - 0.09s - loss: 1.1081 - acc: 0.3295 - val_loss: 1.1041 - val_acc: 0.3360\n",
            "Epoch 5/50 - 0.09s - loss: 1.1075 - acc: 0.3302 - val_loss: 1.1036 - val_acc: 0.3360\n",
            "Epoch 6/50 - 0.10s - loss: 1.1070 - acc: 0.3306 - val_loss: 1.1030 - val_acc: 0.3320\n",
            "Epoch 7/50 - 0.09s - loss: 1.1065 - acc: 0.3309 - val_loss: 1.1025 - val_acc: 0.3340\n",
            "Epoch 8/50 - 0.09s - loss: 1.1061 - acc: 0.3315 - val_loss: 1.1020 - val_acc: 0.3320\n",
            "Epoch 9/50 - 0.10s - loss: 1.1056 - acc: 0.3322 - val_loss: 1.1016 - val_acc: 0.3340\n",
            "Epoch 10/50 - 0.09s - loss: 1.1052 - acc: 0.3329 - val_loss: 1.1012 - val_acc: 0.3360\n",
            "Epoch 11/50 - 0.09s - loss: 1.1048 - acc: 0.3331 - val_loss: 1.1007 - val_acc: 0.3360\n",
            "Epoch 12/50 - 0.10s - loss: 1.1044 - acc: 0.3333 - val_loss: 1.1003 - val_acc: 0.3360\n",
            "Epoch 13/50 - 0.09s - loss: 1.1040 - acc: 0.3345 - val_loss: 1.0999 - val_acc: 0.3360\n",
            "Epoch 14/50 - 0.09s - loss: 1.1036 - acc: 0.3342 - val_loss: 1.0996 - val_acc: 0.3381\n",
            "Epoch 15/50 - 0.09s - loss: 1.1032 - acc: 0.3360 - val_loss: 1.0992 - val_acc: 0.3381\n",
            "Epoch 16/50 - 0.09s - loss: 1.1029 - acc: 0.3365 - val_loss: 1.0989 - val_acc: 0.3381\n",
            "Epoch 17/50 - 0.09s - loss: 1.1025 - acc: 0.3385 - val_loss: 1.0986 - val_acc: 0.3381\n",
            "Epoch 18/50 - 0.10s - loss: 1.1022 - acc: 0.3392 - val_loss: 1.0982 - val_acc: 0.3421\n",
            "Epoch 19/50 - 0.09s - loss: 1.1019 - acc: 0.3408 - val_loss: 1.0979 - val_acc: 0.3421\n",
            "Epoch 20/50 - 0.10s - loss: 1.1015 - acc: 0.3414 - val_loss: 1.0976 - val_acc: 0.3401\n",
            "Epoch 21/50 - 0.10s - loss: 1.1012 - acc: 0.3419 - val_loss: 1.0973 - val_acc: 0.3401\n",
            "Epoch 22/50 - 0.09s - loss: 1.1009 - acc: 0.3421 - val_loss: 1.0971 - val_acc: 0.3381\n",
            "Epoch 23/50 - 0.09s - loss: 1.1006 - acc: 0.3432 - val_loss: 1.0968 - val_acc: 0.3401\n",
            "Epoch 24/50 - 0.10s - loss: 1.1003 - acc: 0.3439 - val_loss: 1.0965 - val_acc: 0.3401\n",
            "Epoch 25/50 - 0.09s - loss: 1.1000 - acc: 0.3432 - val_loss: 1.0963 - val_acc: 0.3421\n",
            "Epoch 26/50 - 0.09s - loss: 1.0997 - acc: 0.3437 - val_loss: 1.0960 - val_acc: 0.3482\n",
            "Epoch 27/50 - 0.10s - loss: 1.0994 - acc: 0.3455 - val_loss: 1.0958 - val_acc: 0.3502\n",
            "Epoch 28/50 - 0.09s - loss: 1.0991 - acc: 0.3459 - val_loss: 1.0955 - val_acc: 0.3502\n",
            "Epoch 29/50 - 0.10s - loss: 1.0988 - acc: 0.3464 - val_loss: 1.0953 - val_acc: 0.3543\n",
            "Epoch 30/50 - 0.10s - loss: 1.0986 - acc: 0.3462 - val_loss: 1.0951 - val_acc: 0.3543\n",
            "Epoch 31/50 - 0.10s - loss: 1.0983 - acc: 0.3482 - val_loss: 1.0948 - val_acc: 0.3543\n",
            "Epoch 32/50 - 0.09s - loss: 1.0980 - acc: 0.3480 - val_loss: 1.0946 - val_acc: 0.3623\n",
            "Epoch 33/50 - 0.11s - loss: 1.0977 - acc: 0.3484 - val_loss: 1.0944 - val_acc: 0.3644\n",
            "Epoch 34/50 - 0.10s - loss: 1.0975 - acc: 0.3489 - val_loss: 1.0942 - val_acc: 0.3664\n",
            "Epoch 35/50 - 0.09s - loss: 1.0972 - acc: 0.3500 - val_loss: 1.0939 - val_acc: 0.3644\n",
            "Epoch 36/50 - 0.09s - loss: 1.0969 - acc: 0.3513 - val_loss: 1.0937 - val_acc: 0.3664\n",
            "Epoch 37/50 - 0.09s - loss: 1.0967 - acc: 0.3513 - val_loss: 1.0935 - val_acc: 0.3684\n",
            "Epoch 38/50 - 0.09s - loss: 1.0964 - acc: 0.3511 - val_loss: 1.0933 - val_acc: 0.3704\n",
            "Epoch 39/50 - 0.10s - loss: 1.0962 - acc: 0.3520 - val_loss: 1.0931 - val_acc: 0.3684\n",
            "Epoch 40/50 - 0.09s - loss: 1.0959 - acc: 0.3538 - val_loss: 1.0929 - val_acc: 0.3704\n",
            "Epoch 41/50 - 0.09s - loss: 1.0957 - acc: 0.3543 - val_loss: 1.0927 - val_acc: 0.3684\n",
            "Epoch 42/50 - 0.10s - loss: 1.0954 - acc: 0.3547 - val_loss: 1.0925 - val_acc: 0.3704\n",
            "Epoch 43/50 - 0.10s - loss: 1.0952 - acc: 0.3561 - val_loss: 1.0923 - val_acc: 0.3704\n",
            "Epoch 44/50 - 0.09s - loss: 1.0949 - acc: 0.3590 - val_loss: 1.0921 - val_acc: 0.3623\n",
            "Epoch 45/50 - 0.10s - loss: 1.0947 - acc: 0.3578 - val_loss: 1.0919 - val_acc: 0.3644\n",
            "Epoch 46/50 - 0.09s - loss: 1.0944 - acc: 0.3590 - val_loss: 1.0918 - val_acc: 0.3644\n",
            "Epoch 47/50 - 0.09s - loss: 1.0942 - acc: 0.3594 - val_loss: 1.0916 - val_acc: 0.3664\n",
            "Epoch 48/50 - 0.10s - loss: 1.0939 - acc: 0.3623 - val_loss: 1.0914 - val_acc: 0.3623\n",
            "Epoch 49/50 - 0.09s - loss: 1.0937 - acc: 0.3630 - val_loss: 1.0912 - val_acc: 0.3644\n",
            "Epoch 50/50 - 0.10s - loss: 1.0935 - acc: 0.3657 - val_loss: 1.0910 - val_acc: 0.3664\n",
            "\n",
            "Combination 86/252:\n",
            "Hidden Layers: [128, 128], Activation: relu, Learning Rate: 0.0001, Batch Size: 32, Epochs: 100\n",
            "Epoch 1/100 - 0.10s - loss: 1.1136 - acc: 0.2854 - val_loss: 1.1134 - val_acc: 0.2955\n",
            "Epoch 2/100 - 0.09s - loss: 1.1127 - acc: 0.2865 - val_loss: 1.1128 - val_acc: 0.2976\n",
            "Epoch 3/100 - 0.10s - loss: 1.1120 - acc: 0.2908 - val_loss: 1.1122 - val_acc: 0.2955\n",
            "Epoch 4/100 - 0.11s - loss: 1.1113 - acc: 0.2913 - val_loss: 1.1116 - val_acc: 0.2874\n",
            "Epoch 5/100 - 0.09s - loss: 1.1107 - acc: 0.2928 - val_loss: 1.1111 - val_acc: 0.2996\n",
            "Epoch 6/100 - 0.10s - loss: 1.1102 - acc: 0.2926 - val_loss: 1.1106 - val_acc: 0.3077\n",
            "Epoch 7/100 - 0.11s - loss: 1.1096 - acc: 0.2960 - val_loss: 1.1102 - val_acc: 0.3097\n",
            "Epoch 8/100 - 0.09s - loss: 1.1091 - acc: 0.3016 - val_loss: 1.1098 - val_acc: 0.3178\n",
            "Epoch 9/100 - 0.10s - loss: 1.1086 - acc: 0.3039 - val_loss: 1.1094 - val_acc: 0.3198\n",
            "Epoch 10/100 - 0.10s - loss: 1.1082 - acc: 0.3061 - val_loss: 1.1090 - val_acc: 0.3198\n",
            "Epoch 11/100 - 0.09s - loss: 1.1078 - acc: 0.3099 - val_loss: 1.1087 - val_acc: 0.3279\n",
            "Epoch 12/100 - 0.09s - loss: 1.1074 - acc: 0.3111 - val_loss: 1.1083 - val_acc: 0.3401\n",
            "Epoch 13/100 - 0.10s - loss: 1.1070 - acc: 0.3126 - val_loss: 1.1080 - val_acc: 0.3421\n",
            "Epoch 14/100 - 0.09s - loss: 1.1066 - acc: 0.3142 - val_loss: 1.1077 - val_acc: 0.3421\n",
            "Epoch 15/100 - 0.09s - loss: 1.1063 - acc: 0.3169 - val_loss: 1.1074 - val_acc: 0.3421\n",
            "Epoch 16/100 - 0.10s - loss: 1.1060 - acc: 0.3194 - val_loss: 1.1072 - val_acc: 0.3360\n",
            "Epoch 17/100 - 0.10s - loss: 1.1056 - acc: 0.3212 - val_loss: 1.1069 - val_acc: 0.3441\n",
            "Epoch 18/100 - 0.09s - loss: 1.1053 - acc: 0.3257 - val_loss: 1.1066 - val_acc: 0.3502\n",
            "Epoch 19/100 - 0.10s - loss: 1.1050 - acc: 0.3284 - val_loss: 1.1064 - val_acc: 0.3482\n",
            "Epoch 20/100 - 0.09s - loss: 1.1047 - acc: 0.3286 - val_loss: 1.1062 - val_acc: 0.3482\n",
            "Epoch 21/100 - 0.09s - loss: 1.1044 - acc: 0.3306 - val_loss: 1.1059 - val_acc: 0.3563\n",
            "Epoch 22/100 - 0.10s - loss: 1.1042 - acc: 0.3315 - val_loss: 1.1057 - val_acc: 0.3583\n",
            "Epoch 23/100 - 0.10s - loss: 1.1039 - acc: 0.3329 - val_loss: 1.1055 - val_acc: 0.3563\n",
            "Epoch 24/100 - 0.10s - loss: 1.1036 - acc: 0.3342 - val_loss: 1.1052 - val_acc: 0.3563\n",
            "Epoch 25/100 - 0.10s - loss: 1.1033 - acc: 0.3369 - val_loss: 1.1050 - val_acc: 0.3522\n",
            "Epoch 26/100 - 0.09s - loss: 1.1031 - acc: 0.3367 - val_loss: 1.1048 - val_acc: 0.3583\n",
            "Epoch 27/100 - 0.09s - loss: 1.1028 - acc: 0.3363 - val_loss: 1.1046 - val_acc: 0.3543\n",
            "Epoch 28/100 - 0.10s - loss: 1.1026 - acc: 0.3383 - val_loss: 1.1043 - val_acc: 0.3522\n",
            "Epoch 29/100 - 0.11s - loss: 1.1023 - acc: 0.3387 - val_loss: 1.1041 - val_acc: 0.3522\n",
            "Epoch 30/100 - 0.10s - loss: 1.1020 - acc: 0.3399 - val_loss: 1.1039 - val_acc: 0.3522\n",
            "Epoch 31/100 - 0.10s - loss: 1.1018 - acc: 0.3423 - val_loss: 1.1037 - val_acc: 0.3583\n",
            "Epoch 32/100 - 0.09s - loss: 1.1016 - acc: 0.3430 - val_loss: 1.1035 - val_acc: 0.3583\n",
            "Epoch 33/100 - 0.09s - loss: 1.1013 - acc: 0.3446 - val_loss: 1.1033 - val_acc: 0.3603\n",
            "Epoch 34/100 - 0.10s - loss: 1.1011 - acc: 0.3453 - val_loss: 1.1030 - val_acc: 0.3623\n",
            "Epoch 35/100 - 0.10s - loss: 1.1008 - acc: 0.3466 - val_loss: 1.1028 - val_acc: 0.3644\n",
            "Epoch 36/100 - 0.10s - loss: 1.1006 - acc: 0.3489 - val_loss: 1.1026 - val_acc: 0.3644\n",
            "Epoch 37/100 - 0.11s - loss: 1.1004 - acc: 0.3489 - val_loss: 1.1024 - val_acc: 0.3664\n",
            "Epoch 38/100 - 0.10s - loss: 1.1002 - acc: 0.3504 - val_loss: 1.1022 - val_acc: 0.3664\n",
            "Epoch 39/100 - 0.09s - loss: 1.0999 - acc: 0.3511 - val_loss: 1.1020 - val_acc: 0.3684\n",
            "Epoch 40/100 - 0.11s - loss: 1.0997 - acc: 0.3520 - val_loss: 1.1018 - val_acc: 0.3664\n",
            "Epoch 41/100 - 0.09s - loss: 1.0995 - acc: 0.3525 - val_loss: 1.1016 - val_acc: 0.3684\n",
            "Epoch 42/100 - 0.10s - loss: 1.0993 - acc: 0.3534 - val_loss: 1.1015 - val_acc: 0.3684\n",
            "Epoch 43/100 - 0.11s - loss: 1.0990 - acc: 0.3549 - val_loss: 1.1013 - val_acc: 0.3684\n",
            "Epoch 44/100 - 0.09s - loss: 1.0988 - acc: 0.3554 - val_loss: 1.1011 - val_acc: 0.3664\n",
            "Epoch 45/100 - 0.09s - loss: 1.0986 - acc: 0.3554 - val_loss: 1.1009 - val_acc: 0.3664\n",
            "Epoch 46/100 - 0.10s - loss: 1.0984 - acc: 0.3574 - val_loss: 1.1007 - val_acc: 0.3684\n",
            "Epoch 47/100 - 0.10s - loss: 1.0982 - acc: 0.3581 - val_loss: 1.1005 - val_acc: 0.3684\n",
            "Epoch 48/100 - 0.09s - loss: 1.0980 - acc: 0.3587 - val_loss: 1.1004 - val_acc: 0.3704\n",
            "Epoch 49/100 - 0.11s - loss: 1.0978 - acc: 0.3592 - val_loss: 1.1002 - val_acc: 0.3704\n",
            "Epoch 50/100 - 0.10s - loss: 1.0976 - acc: 0.3610 - val_loss: 1.1000 - val_acc: 0.3684\n",
            "Epoch 51/100 - 0.09s - loss: 1.0974 - acc: 0.3605 - val_loss: 1.0998 - val_acc: 0.3644\n",
            "Epoch 52/100 - 0.09s - loss: 1.0972 - acc: 0.3632 - val_loss: 1.0997 - val_acc: 0.3623\n",
            "Epoch 53/100 - 0.09s - loss: 1.0970 - acc: 0.3630 - val_loss: 1.0995 - val_acc: 0.3623\n",
            "Epoch 54/100 - 0.10s - loss: 1.0968 - acc: 0.3650 - val_loss: 1.0993 - val_acc: 0.3644\n",
            "Epoch 55/100 - 0.11s - loss: 1.0966 - acc: 0.3648 - val_loss: 1.0992 - val_acc: 0.3644\n",
            "Epoch 56/100 - 0.10s - loss: 1.0964 - acc: 0.3664 - val_loss: 1.0990 - val_acc: 0.3644\n",
            "Epoch 57/100 - 0.10s - loss: 1.0962 - acc: 0.3664 - val_loss: 1.0988 - val_acc: 0.3664\n",
            "Epoch 58/100 - 0.11s - loss: 1.0960 - acc: 0.3659 - val_loss: 1.0987 - val_acc: 0.3664\n",
            "Epoch 59/100 - 0.09s - loss: 1.0958 - acc: 0.3668 - val_loss: 1.0985 - val_acc: 0.3644\n",
            "Epoch 60/100 - 0.09s - loss: 1.0957 - acc: 0.3675 - val_loss: 1.0983 - val_acc: 0.3664\n",
            "Epoch 61/100 - 0.10s - loss: 1.0955 - acc: 0.3682 - val_loss: 1.0982 - val_acc: 0.3684\n",
            "Epoch 62/100 - 0.09s - loss: 1.0953 - acc: 0.3675 - val_loss: 1.0980 - val_acc: 0.3684\n",
            "Epoch 63/100 - 0.09s - loss: 1.0951 - acc: 0.3675 - val_loss: 1.0979 - val_acc: 0.3704\n",
            "Epoch 64/100 - 0.10s - loss: 1.0949 - acc: 0.3682 - val_loss: 1.0977 - val_acc: 0.3684\n",
            "Epoch 65/100 - 0.09s - loss: 1.0947 - acc: 0.3689 - val_loss: 1.0976 - val_acc: 0.3684\n",
            "Epoch 66/100 - 0.09s - loss: 1.0946 - acc: 0.3698 - val_loss: 1.0974 - val_acc: 0.3684\n",
            "Epoch 67/100 - 0.10s - loss: 1.0944 - acc: 0.3718 - val_loss: 1.0973 - val_acc: 0.3725\n",
            "Epoch 68/100 - 0.09s - loss: 1.0942 - acc: 0.3725 - val_loss: 1.0971 - val_acc: 0.3745\n",
            "Epoch 69/100 - 0.09s - loss: 1.0940 - acc: 0.3718 - val_loss: 1.0970 - val_acc: 0.3745\n",
            "Epoch 70/100 - 0.10s - loss: 1.0938 - acc: 0.3731 - val_loss: 1.0968 - val_acc: 0.3745\n",
            "Epoch 71/100 - 0.09s - loss: 1.0937 - acc: 0.3734 - val_loss: 1.0967 - val_acc: 0.3765\n",
            "Epoch 72/100 - 0.09s - loss: 1.0935 - acc: 0.3736 - val_loss: 1.0965 - val_acc: 0.3806\n",
            "Epoch 73/100 - 0.11s - loss: 1.0933 - acc: 0.3745 - val_loss: 1.0964 - val_acc: 0.3806\n",
            "Epoch 74/100 - 0.09s - loss: 1.0931 - acc: 0.3749 - val_loss: 1.0962 - val_acc: 0.3826\n",
            "Epoch 75/100 - 0.09s - loss: 1.0930 - acc: 0.3758 - val_loss: 1.0961 - val_acc: 0.3846\n",
            "Epoch 76/100 - 0.10s - loss: 1.0928 - acc: 0.3763 - val_loss: 1.0960 - val_acc: 0.3846\n",
            "Epoch 77/100 - 0.11s - loss: 1.0926 - acc: 0.3772 - val_loss: 1.0958 - val_acc: 0.3826\n",
            "Epoch 78/100 - 0.10s - loss: 1.0925 - acc: 0.3779 - val_loss: 1.0957 - val_acc: 0.3846\n",
            "Epoch 79/100 - 0.12s - loss: 1.0923 - acc: 0.3779 - val_loss: 1.0956 - val_acc: 0.3846\n",
            "Epoch 80/100 - 0.11s - loss: 1.0921 - acc: 0.3790 - val_loss: 1.0954 - val_acc: 0.3887\n",
            "Epoch 81/100 - 0.10s - loss: 1.0920 - acc: 0.3799 - val_loss: 1.0953 - val_acc: 0.3887\n",
            "Epoch 82/100 - 0.10s - loss: 1.0918 - acc: 0.3801 - val_loss: 1.0952 - val_acc: 0.3907\n",
            "Epoch 83/100 - 0.10s - loss: 1.0916 - acc: 0.3806 - val_loss: 1.0950 - val_acc: 0.3927\n",
            "Epoch 84/100 - 0.09s - loss: 1.0915 - acc: 0.3815 - val_loss: 1.0949 - val_acc: 0.3927\n",
            "Epoch 85/100 - 0.10s - loss: 1.0913 - acc: 0.3828 - val_loss: 1.0948 - val_acc: 0.3907\n",
            "Epoch 86/100 - 0.09s - loss: 1.0912 - acc: 0.3837 - val_loss: 1.0946 - val_acc: 0.3927\n",
            "Epoch 87/100 - 0.09s - loss: 1.0910 - acc: 0.3844 - val_loss: 1.0945 - val_acc: 0.3907\n",
            "Epoch 88/100 - 0.10s - loss: 1.0909 - acc: 0.3855 - val_loss: 1.0944 - val_acc: 0.3907\n",
            "Epoch 89/100 - 0.09s - loss: 1.0907 - acc: 0.3855 - val_loss: 1.0942 - val_acc: 0.3907\n",
            "Epoch 90/100 - 0.09s - loss: 1.0905 - acc: 0.3853 - val_loss: 1.0941 - val_acc: 0.3907\n",
            "Epoch 91/100 - 0.10s - loss: 1.0904 - acc: 0.3857 - val_loss: 1.0940 - val_acc: 0.3887\n",
            "Epoch 92/100 - 0.10s - loss: 1.0902 - acc: 0.3866 - val_loss: 1.0939 - val_acc: 0.3866\n",
            "Epoch 93/100 - 0.09s - loss: 1.0901 - acc: 0.3871 - val_loss: 1.0937 - val_acc: 0.3866\n",
            "Epoch 94/100 - 0.10s - loss: 1.0899 - acc: 0.3875 - val_loss: 1.0936 - val_acc: 0.3846\n",
            "Epoch 95/100 - 0.09s - loss: 1.0898 - acc: 0.3875 - val_loss: 1.0935 - val_acc: 0.3866\n",
            "Epoch 96/100 - 0.09s - loss: 1.0896 - acc: 0.3884 - val_loss: 1.0934 - val_acc: 0.3866\n",
            "Epoch 97/100 - 0.10s - loss: 1.0895 - acc: 0.3889 - val_loss: 1.0932 - val_acc: 0.3866\n",
            "Epoch 98/100 - 0.09s - loss: 1.0893 - acc: 0.3891 - val_loss: 1.0931 - val_acc: 0.3866\n",
            "Epoch 99/100 - 0.09s - loss: 1.0892 - acc: 0.3893 - val_loss: 1.0930 - val_acc: 0.3846\n",
            "Epoch 100/100 - 0.10s - loss: 1.0891 - acc: 0.3918 - val_loss: 1.0929 - val_acc: 0.3846\n",
            "\n",
            "Combination 87/252:\n",
            "Hidden Layers: [128, 128], Activation: relu, Learning Rate: 0.0001, Batch Size: 32, Epochs: 150\n",
            "Epoch 1/150 - 0.09s - loss: 1.1155 - acc: 0.3455 - val_loss: 1.1114 - val_acc: 0.3623\n",
            "Epoch 2/150 - 0.09s - loss: 1.1131 - acc: 0.3473 - val_loss: 1.1095 - val_acc: 0.3664\n",
            "Epoch 3/150 - 0.10s - loss: 1.1111 - acc: 0.3441 - val_loss: 1.1079 - val_acc: 0.3684\n",
            "Epoch 4/150 - 0.09s - loss: 1.1092 - acc: 0.3446 - val_loss: 1.1064 - val_acc: 0.3644\n",
            "Epoch 5/150 - 0.10s - loss: 1.1076 - acc: 0.3495 - val_loss: 1.1051 - val_acc: 0.3623\n",
            "Epoch 6/150 - 0.11s - loss: 1.1061 - acc: 0.3522 - val_loss: 1.1040 - val_acc: 0.3644\n",
            "Epoch 7/150 - 0.09s - loss: 1.1048 - acc: 0.3511 - val_loss: 1.1030 - val_acc: 0.3684\n",
            "Epoch 8/150 - 0.09s - loss: 1.1037 - acc: 0.3538 - val_loss: 1.1022 - val_acc: 0.3745\n",
            "Epoch 9/150 - 0.10s - loss: 1.1026 - acc: 0.3576 - val_loss: 1.1014 - val_acc: 0.3745\n",
            "Epoch 10/150 - 0.09s - loss: 1.1017 - acc: 0.3567 - val_loss: 1.1008 - val_acc: 0.3785\n",
            "Epoch 11/150 - 0.09s - loss: 1.1009 - acc: 0.3561 - val_loss: 1.1002 - val_acc: 0.3725\n",
            "Epoch 12/150 - 0.10s - loss: 1.1001 - acc: 0.3545 - val_loss: 1.0996 - val_acc: 0.3725\n",
            "Epoch 13/150 - 0.09s - loss: 1.0994 - acc: 0.3554 - val_loss: 1.0992 - val_acc: 0.3745\n",
            "Epoch 14/150 - 0.09s - loss: 1.0988 - acc: 0.3547 - val_loss: 1.0988 - val_acc: 0.3704\n",
            "Epoch 15/150 - 0.10s - loss: 1.0983 - acc: 0.3583 - val_loss: 1.0984 - val_acc: 0.3725\n",
            "Epoch 16/150 - 0.10s - loss: 1.0977 - acc: 0.3581 - val_loss: 1.0981 - val_acc: 0.3745\n",
            "Epoch 17/150 - 0.09s - loss: 1.0973 - acc: 0.3594 - val_loss: 1.0978 - val_acc: 0.3745\n",
            "Epoch 18/150 - 0.11s - loss: 1.0968 - acc: 0.3603 - val_loss: 1.0975 - val_acc: 0.3745\n",
            "Epoch 19/150 - 0.09s - loss: 1.0964 - acc: 0.3601 - val_loss: 1.0973 - val_acc: 0.3725\n",
            "Epoch 20/150 - 0.09s - loss: 1.0961 - acc: 0.3608 - val_loss: 1.0971 - val_acc: 0.3704\n",
            "Epoch 21/150 - 0.10s - loss: 1.0957 - acc: 0.3635 - val_loss: 1.0968 - val_acc: 0.3644\n",
            "Epoch 22/150 - 0.09s - loss: 1.0954 - acc: 0.3639 - val_loss: 1.0967 - val_acc: 0.3563\n",
            "Epoch 23/150 - 0.09s - loss: 1.0951 - acc: 0.3655 - val_loss: 1.0965 - val_acc: 0.3644\n",
            "Epoch 24/150 - 0.10s - loss: 1.0948 - acc: 0.3657 - val_loss: 1.0963 - val_acc: 0.3664\n",
            "Epoch 25/150 - 0.09s - loss: 1.0946 - acc: 0.3666 - val_loss: 1.0961 - val_acc: 0.3623\n",
            "Epoch 26/150 - 0.09s - loss: 1.0943 - acc: 0.3702 - val_loss: 1.0960 - val_acc: 0.3704\n",
            "Epoch 27/150 - 0.10s - loss: 1.0941 - acc: 0.3743 - val_loss: 1.0959 - val_acc: 0.3684\n",
            "Epoch 28/150 - 0.11s - loss: 1.0938 - acc: 0.3763 - val_loss: 1.0957 - val_acc: 0.3664\n",
            "Epoch 29/150 - 0.10s - loss: 1.0936 - acc: 0.3749 - val_loss: 1.0956 - val_acc: 0.3725\n",
            "Epoch 30/150 - 0.09s - loss: 1.0934 - acc: 0.3770 - val_loss: 1.0955 - val_acc: 0.3745\n",
            "Epoch 31/150 - 0.09s - loss: 1.0932 - acc: 0.3790 - val_loss: 1.0953 - val_acc: 0.3785\n",
            "Epoch 32/150 - 0.10s - loss: 1.0930 - acc: 0.3799 - val_loss: 1.0952 - val_acc: 0.3806\n",
            "Epoch 33/150 - 0.10s - loss: 1.0928 - acc: 0.3817 - val_loss: 1.0951 - val_acc: 0.3745\n",
            "Epoch 34/150 - 0.09s - loss: 1.0926 - acc: 0.3821 - val_loss: 1.0950 - val_acc: 0.3725\n",
            "Epoch 35/150 - 0.10s - loss: 1.0924 - acc: 0.3839 - val_loss: 1.0949 - val_acc: 0.3745\n",
            "Epoch 36/150 - 0.09s - loss: 1.0923 - acc: 0.3846 - val_loss: 1.0947 - val_acc: 0.3765\n",
            "Epoch 37/150 - 0.09s - loss: 1.0921 - acc: 0.3855 - val_loss: 1.0946 - val_acc: 0.3806\n",
            "Epoch 38/150 - 0.10s - loss: 1.0919 - acc: 0.3864 - val_loss: 1.0945 - val_acc: 0.3826\n",
            "Epoch 39/150 - 0.09s - loss: 1.0917 - acc: 0.3873 - val_loss: 1.0944 - val_acc: 0.3806\n",
            "Epoch 40/150 - 0.09s - loss: 1.0916 - acc: 0.3875 - val_loss: 1.0943 - val_acc: 0.3745\n",
            "Epoch 41/150 - 0.11s - loss: 1.0914 - acc: 0.3855 - val_loss: 1.0942 - val_acc: 0.3765\n",
            "Epoch 42/150 - 0.09s - loss: 1.0913 - acc: 0.3851 - val_loss: 1.0941 - val_acc: 0.3745\n",
            "Epoch 43/150 - 0.09s - loss: 1.0911 - acc: 0.3853 - val_loss: 1.0940 - val_acc: 0.3664\n",
            "Epoch 44/150 - 0.10s - loss: 1.0909 - acc: 0.3851 - val_loss: 1.0939 - val_acc: 0.3725\n",
            "Epoch 45/150 - 0.09s - loss: 1.0908 - acc: 0.3848 - val_loss: 1.0938 - val_acc: 0.3704\n",
            "Epoch 46/150 - 0.09s - loss: 1.0906 - acc: 0.3866 - val_loss: 1.0937 - val_acc: 0.3684\n",
            "Epoch 47/150 - 0.10s - loss: 1.0905 - acc: 0.3842 - val_loss: 1.0936 - val_acc: 0.3684\n",
            "Epoch 48/150 - 0.09s - loss: 1.0903 - acc: 0.3835 - val_loss: 1.0935 - val_acc: 0.3684\n",
            "Epoch 49/150 - 0.09s - loss: 1.0902 - acc: 0.3842 - val_loss: 1.0934 - val_acc: 0.3704\n",
            "Epoch 50/150 - 0.10s - loss: 1.0900 - acc: 0.3860 - val_loss: 1.0932 - val_acc: 0.3684\n",
            "Epoch 51/150 - 0.09s - loss: 1.0899 - acc: 0.3869 - val_loss: 1.0931 - val_acc: 0.3704\n",
            "Epoch 52/150 - 0.09s - loss: 1.0898 - acc: 0.3884 - val_loss: 1.0930 - val_acc: 0.3725\n",
            "Epoch 53/150 - 0.10s - loss: 1.0896 - acc: 0.3889 - val_loss: 1.0929 - val_acc: 0.3745\n",
            "Epoch 54/150 - 0.09s - loss: 1.0895 - acc: 0.3891 - val_loss: 1.0928 - val_acc: 0.3745\n",
            "Epoch 55/150 - 0.09s - loss: 1.0893 - acc: 0.3898 - val_loss: 1.0927 - val_acc: 0.3745\n",
            "Epoch 56/150 - 0.09s - loss: 1.0892 - acc: 0.3907 - val_loss: 1.0926 - val_acc: 0.3745\n",
            "Epoch 57/150 - 0.09s - loss: 1.0890 - acc: 0.3909 - val_loss: 1.0925 - val_acc: 0.3785\n",
            "Epoch 58/150 - 0.09s - loss: 1.0889 - acc: 0.3907 - val_loss: 1.0924 - val_acc: 0.3826\n",
            "Epoch 59/150 - 0.09s - loss: 1.0888 - acc: 0.3916 - val_loss: 1.0923 - val_acc: 0.3806\n",
            "Epoch 60/150 - 0.09s - loss: 1.0886 - acc: 0.3936 - val_loss: 1.0922 - val_acc: 0.3806\n",
            "Epoch 61/150 - 0.09s - loss: 1.0885 - acc: 0.3938 - val_loss: 1.0921 - val_acc: 0.3806\n",
            "Epoch 62/150 - 0.10s - loss: 1.0883 - acc: 0.3950 - val_loss: 1.0920 - val_acc: 0.3785\n",
            "Epoch 63/150 - 0.09s - loss: 1.0882 - acc: 0.3936 - val_loss: 1.0919 - val_acc: 0.3745\n",
            "Epoch 64/150 - 0.09s - loss: 1.0881 - acc: 0.3952 - val_loss: 1.0918 - val_acc: 0.3745\n",
            "Epoch 65/150 - 0.10s - loss: 1.0879 - acc: 0.3952 - val_loss: 1.0917 - val_acc: 0.3745\n",
            "Epoch 66/150 - 0.09s - loss: 1.0878 - acc: 0.3954 - val_loss: 1.0916 - val_acc: 0.3745\n",
            "Epoch 67/150 - 0.09s - loss: 1.0877 - acc: 0.3954 - val_loss: 1.0915 - val_acc: 0.3745\n",
            "Epoch 68/150 - 0.09s - loss: 1.0875 - acc: 0.3961 - val_loss: 1.0914 - val_acc: 0.3745\n",
            "Epoch 69/150 - 0.09s - loss: 1.0874 - acc: 0.3956 - val_loss: 1.0913 - val_acc: 0.3725\n",
            "Epoch 70/150 - 0.09s - loss: 1.0873 - acc: 0.3974 - val_loss: 1.0912 - val_acc: 0.3745\n",
            "Epoch 71/150 - 0.10s - loss: 1.0871 - acc: 0.3990 - val_loss: 1.0911 - val_acc: 0.3745\n",
            "Epoch 72/150 - 0.09s - loss: 1.0870 - acc: 0.3988 - val_loss: 1.0910 - val_acc: 0.3765\n",
            "Epoch 73/150 - 0.09s - loss: 1.0869 - acc: 0.3977 - val_loss: 1.0909 - val_acc: 0.3765\n",
            "Epoch 74/150 - 0.09s - loss: 1.0867 - acc: 0.3977 - val_loss: 1.0908 - val_acc: 0.3765\n",
            "Epoch 75/150 - 0.09s - loss: 1.0866 - acc: 0.3981 - val_loss: 1.0907 - val_acc: 0.3785\n",
            "Epoch 76/150 - 0.09s - loss: 1.0865 - acc: 0.4001 - val_loss: 1.0906 - val_acc: 0.3785\n",
            "Epoch 77/150 - 0.09s - loss: 1.0863 - acc: 0.4013 - val_loss: 1.0905 - val_acc: 0.3806\n",
            "Epoch 78/150 - 0.09s - loss: 1.0862 - acc: 0.4028 - val_loss: 1.0904 - val_acc: 0.3826\n",
            "Epoch 79/150 - 0.09s - loss: 1.0861 - acc: 0.4037 - val_loss: 1.0903 - val_acc: 0.3826\n",
            "Epoch 80/150 - 0.10s - loss: 1.0860 - acc: 0.4046 - val_loss: 1.0902 - val_acc: 0.3826\n",
            "Epoch 81/150 - 0.09s - loss: 1.0858 - acc: 0.4053 - val_loss: 1.0901 - val_acc: 0.3866\n",
            "Epoch 82/150 - 0.09s - loss: 1.0857 - acc: 0.4060 - val_loss: 1.0900 - val_acc: 0.3887\n",
            "Epoch 83/150 - 0.10s - loss: 1.0856 - acc: 0.4069 - val_loss: 1.0899 - val_acc: 0.3907\n",
            "Epoch 84/150 - 0.09s - loss: 1.0855 - acc: 0.4085 - val_loss: 1.0898 - val_acc: 0.3907\n",
            "Epoch 85/150 - 0.09s - loss: 1.0853 - acc: 0.4096 - val_loss: 1.0897 - val_acc: 0.3927\n",
            "Epoch 86/150 - 0.09s - loss: 1.0852 - acc: 0.4098 - val_loss: 1.0896 - val_acc: 0.3927\n",
            "Epoch 87/150 - 0.09s - loss: 1.0851 - acc: 0.4105 - val_loss: 1.0895 - val_acc: 0.3907\n",
            "Epoch 88/150 - 0.09s - loss: 1.0849 - acc: 0.4107 - val_loss: 1.0894 - val_acc: 0.3907\n",
            "Epoch 89/150 - 0.10s - loss: 1.0848 - acc: 0.4114 - val_loss: 1.0893 - val_acc: 0.3907\n",
            "Epoch 90/150 - 0.10s - loss: 1.0847 - acc: 0.4116 - val_loss: 1.0892 - val_acc: 0.3907\n",
            "Epoch 91/150 - 0.10s - loss: 1.0846 - acc: 0.4125 - val_loss: 1.0891 - val_acc: 0.3907\n",
            "Epoch 92/150 - 0.10s - loss: 1.0845 - acc: 0.4123 - val_loss: 1.0890 - val_acc: 0.3907\n",
            "Epoch 93/150 - 0.09s - loss: 1.0843 - acc: 0.4141 - val_loss: 1.0889 - val_acc: 0.3907\n",
            "Epoch 94/150 - 0.09s - loss: 1.0842 - acc: 0.4143 - val_loss: 1.0888 - val_acc: 0.3927\n",
            "Epoch 95/150 - 0.10s - loss: 1.0841 - acc: 0.4136 - val_loss: 1.0887 - val_acc: 0.3947\n",
            "Epoch 96/150 - 0.09s - loss: 1.0840 - acc: 0.4141 - val_loss: 1.0886 - val_acc: 0.3947\n",
            "Epoch 97/150 - 0.09s - loss: 1.0838 - acc: 0.4154 - val_loss: 1.0885 - val_acc: 0.3968\n",
            "Epoch 98/150 - 0.11s - loss: 1.0837 - acc: 0.4157 - val_loss: 1.0884 - val_acc: 0.3968\n",
            "Epoch 99/150 - 0.10s - loss: 1.0836 - acc: 0.4159 - val_loss: 1.0883 - val_acc: 0.3968\n",
            "Epoch 100/150 - 0.09s - loss: 1.0835 - acc: 0.4157 - val_loss: 1.0883 - val_acc: 0.3968\n",
            "Epoch 101/150 - 0.10s - loss: 1.0834 - acc: 0.4163 - val_loss: 1.0882 - val_acc: 0.3968\n",
            "Epoch 102/150 - 0.09s - loss: 1.0832 - acc: 0.4172 - val_loss: 1.0881 - val_acc: 0.3947\n",
            "Epoch 103/150 - 0.09s - loss: 1.0831 - acc: 0.4184 - val_loss: 1.0880 - val_acc: 0.3947\n",
            "Epoch 104/150 - 0.10s - loss: 1.0830 - acc: 0.4193 - val_loss: 1.0879 - val_acc: 0.3947\n",
            "Epoch 105/150 - 0.09s - loss: 1.0829 - acc: 0.4193 - val_loss: 1.0878 - val_acc: 0.3947\n",
            "Epoch 106/150 - 0.09s - loss: 1.0828 - acc: 0.4197 - val_loss: 1.0877 - val_acc: 0.3968\n",
            "Epoch 107/150 - 0.10s - loss: 1.0826 - acc: 0.4190 - val_loss: 1.0876 - val_acc: 0.3968\n",
            "Epoch 108/150 - 0.11s - loss: 1.0825 - acc: 0.4190 - val_loss: 1.0875 - val_acc: 0.3947\n",
            "Epoch 109/150 - 0.10s - loss: 1.0824 - acc: 0.4208 - val_loss: 1.0874 - val_acc: 0.3947\n",
            "Epoch 110/150 - 0.11s - loss: 1.0823 - acc: 0.4202 - val_loss: 1.0873 - val_acc: 0.3968\n",
            "Epoch 111/150 - 0.09s - loss: 1.0822 - acc: 0.4206 - val_loss: 1.0872 - val_acc: 0.3988\n",
            "Epoch 112/150 - 0.09s - loss: 1.0821 - acc: 0.4204 - val_loss: 1.0871 - val_acc: 0.3968\n",
            "Epoch 113/150 - 0.10s - loss: 1.0819 - acc: 0.4204 - val_loss: 1.0870 - val_acc: 0.3968\n",
            "Epoch 114/150 - 0.10s - loss: 1.0818 - acc: 0.4202 - val_loss: 1.0869 - val_acc: 0.3968\n",
            "Epoch 115/150 - 0.10s - loss: 1.0817 - acc: 0.4211 - val_loss: 1.0868 - val_acc: 0.3968\n",
            "Epoch 116/150 - 0.10s - loss: 1.0816 - acc: 0.4220 - val_loss: 1.0867 - val_acc: 0.3968\n",
            "Epoch 117/150 - 0.10s - loss: 1.0815 - acc: 0.4226 - val_loss: 1.0867 - val_acc: 0.3988\n",
            "Epoch 118/150 - 0.10s - loss: 1.0814 - acc: 0.4238 - val_loss: 1.0866 - val_acc: 0.3988\n",
            "Epoch 119/150 - 0.10s - loss: 1.0812 - acc: 0.4233 - val_loss: 1.0865 - val_acc: 0.3988\n",
            "Epoch 120/150 - 0.09s - loss: 1.0811 - acc: 0.4224 - val_loss: 1.0864 - val_acc: 0.3988\n",
            "Epoch 121/150 - 0.09s - loss: 1.0810 - acc: 0.4226 - val_loss: 1.0863 - val_acc: 0.3988\n",
            "Epoch 122/150 - 0.10s - loss: 1.0809 - acc: 0.4229 - val_loss: 1.0862 - val_acc: 0.3988\n",
            "Epoch 123/150 - 0.10s - loss: 1.0808 - acc: 0.4231 - val_loss: 1.0861 - val_acc: 0.3988\n",
            "Epoch 124/150 - 0.09s - loss: 1.0807 - acc: 0.4240 - val_loss: 1.0860 - val_acc: 0.4008\n",
            "Epoch 125/150 - 0.09s - loss: 1.0806 - acc: 0.4253 - val_loss: 1.0859 - val_acc: 0.4008\n",
            "Epoch 126/150 - 0.09s - loss: 1.0805 - acc: 0.4258 - val_loss: 1.0858 - val_acc: 0.4008\n",
            "Epoch 127/150 - 0.09s - loss: 1.0803 - acc: 0.4265 - val_loss: 1.0858 - val_acc: 0.4028\n",
            "Epoch 128/150 - 0.10s - loss: 1.0802 - acc: 0.4271 - val_loss: 1.0857 - val_acc: 0.4028\n",
            "Epoch 129/150 - 0.09s - loss: 1.0801 - acc: 0.4271 - val_loss: 1.0856 - val_acc: 0.4008\n",
            "Epoch 130/150 - 0.09s - loss: 1.0800 - acc: 0.4271 - val_loss: 1.0855 - val_acc: 0.4008\n",
            "Epoch 131/150 - 0.10s - loss: 1.0799 - acc: 0.4287 - val_loss: 1.0854 - val_acc: 0.4008\n",
            "Epoch 132/150 - 0.09s - loss: 1.0798 - acc: 0.4294 - val_loss: 1.0853 - val_acc: 0.4028\n",
            "Epoch 133/150 - 0.09s - loss: 1.0797 - acc: 0.4291 - val_loss: 1.0852 - val_acc: 0.4049\n",
            "Epoch 134/150 - 0.11s - loss: 1.0796 - acc: 0.4298 - val_loss: 1.0852 - val_acc: 0.4069\n",
            "Epoch 135/150 - 0.10s - loss: 1.0795 - acc: 0.4305 - val_loss: 1.0851 - val_acc: 0.4069\n",
            "Epoch 136/150 - 0.10s - loss: 1.0793 - acc: 0.4312 - val_loss: 1.0850 - val_acc: 0.4069\n",
            "Epoch 137/150 - 0.10s - loss: 1.0792 - acc: 0.4314 - val_loss: 1.0849 - val_acc: 0.4089\n",
            "Epoch 138/150 - 0.10s - loss: 1.0791 - acc: 0.4321 - val_loss: 1.0848 - val_acc: 0.4089\n",
            "Epoch 139/150 - 0.10s - loss: 1.0790 - acc: 0.4325 - val_loss: 1.0847 - val_acc: 0.4069\n",
            "Epoch 140/150 - 0.10s - loss: 1.0789 - acc: 0.4332 - val_loss: 1.0847 - val_acc: 0.4069\n",
            "Epoch 141/150 - 0.09s - loss: 1.0788 - acc: 0.4339 - val_loss: 1.0846 - val_acc: 0.4069\n",
            "Epoch 142/150 - 0.10s - loss: 1.0787 - acc: 0.4341 - val_loss: 1.0845 - val_acc: 0.4089\n",
            "Epoch 143/150 - 0.10s - loss: 1.0786 - acc: 0.4345 - val_loss: 1.0844 - val_acc: 0.4109\n",
            "Epoch 144/150 - 0.10s - loss: 1.0785 - acc: 0.4350 - val_loss: 1.0843 - val_acc: 0.4109\n",
            "Epoch 145/150 - 0.10s - loss: 1.0784 - acc: 0.4357 - val_loss: 1.0842 - val_acc: 0.4130\n",
            "Epoch 146/150 - 0.10s - loss: 1.0783 - acc: 0.4350 - val_loss: 1.0842 - val_acc: 0.4130\n",
            "Epoch 147/150 - 0.10s - loss: 1.0781 - acc: 0.4345 - val_loss: 1.0841 - val_acc: 0.4130\n",
            "Epoch 148/150 - 0.09s - loss: 1.0780 - acc: 0.4341 - val_loss: 1.0840 - val_acc: 0.4130\n",
            "Epoch 149/150 - 0.11s - loss: 1.0779 - acc: 0.4345 - val_loss: 1.0839 - val_acc: 0.4130\n",
            "Epoch 150/150 - 0.10s - loss: 1.0778 - acc: 0.4348 - val_loss: 1.0838 - val_acc: 0.4150\n",
            "\n",
            "Combination 88/252:\n",
            "Hidden Layers: [128, 128], Activation: relu, Learning Rate: 0.0001, Batch Size: 64, Epochs: 50\n",
            "Epoch 1/50 - 0.08s - loss: 1.1106 - acc: 0.3412 - val_loss: 1.1075 - val_acc: 0.3623\n",
            "Epoch 2/50 - 0.08s - loss: 1.1089 - acc: 0.3423 - val_loss: 1.1062 - val_acc: 0.3704\n",
            "Epoch 3/50 - 0.08s - loss: 1.1074 - acc: 0.3464 - val_loss: 1.1049 - val_acc: 0.3765\n",
            "Epoch 4/50 - 0.08s - loss: 1.1060 - acc: 0.3486 - val_loss: 1.1038 - val_acc: 0.3866\n",
            "Epoch 5/50 - 0.07s - loss: 1.1047 - acc: 0.3507 - val_loss: 1.1028 - val_acc: 0.3887\n",
            "Epoch 6/50 - 0.08s - loss: 1.1036 - acc: 0.3516 - val_loss: 1.1019 - val_acc: 0.3866\n",
            "Epoch 7/50 - 0.07s - loss: 1.1025 - acc: 0.3558 - val_loss: 1.1010 - val_acc: 0.3785\n",
            "Epoch 8/50 - 0.07s - loss: 1.1015 - acc: 0.3590 - val_loss: 1.1003 - val_acc: 0.3704\n",
            "Epoch 9/50 - 0.07s - loss: 1.1006 - acc: 0.3605 - val_loss: 1.0996 - val_acc: 0.3725\n",
            "Epoch 10/50 - 0.07s - loss: 1.0998 - acc: 0.3623 - val_loss: 1.0989 - val_acc: 0.3704\n",
            "Epoch 11/50 - 0.07s - loss: 1.0990 - acc: 0.3639 - val_loss: 1.0984 - val_acc: 0.3765\n",
            "Epoch 12/50 - 0.08s - loss: 1.0983 - acc: 0.3664 - val_loss: 1.0978 - val_acc: 0.3745\n",
            "Epoch 13/50 - 0.08s - loss: 1.0976 - acc: 0.3666 - val_loss: 1.0974 - val_acc: 0.3765\n",
            "Epoch 14/50 - 0.08s - loss: 1.0970 - acc: 0.3684 - val_loss: 1.0969 - val_acc: 0.3725\n",
            "Epoch 15/50 - 0.08s - loss: 1.0965 - acc: 0.3702 - val_loss: 1.0965 - val_acc: 0.3704\n",
            "Epoch 16/50 - 0.07s - loss: 1.0959 - acc: 0.3709 - val_loss: 1.0961 - val_acc: 0.3745\n",
            "Epoch 17/50 - 0.07s - loss: 1.0955 - acc: 0.3734 - val_loss: 1.0958 - val_acc: 0.3765\n",
            "Epoch 18/50 - 0.08s - loss: 1.0950 - acc: 0.3758 - val_loss: 1.0955 - val_acc: 0.3785\n",
            "Epoch 19/50 - 0.07s - loss: 1.0946 - acc: 0.3765 - val_loss: 1.0952 - val_acc: 0.3806\n",
            "Epoch 20/50 - 0.07s - loss: 1.0942 - acc: 0.3790 - val_loss: 1.0949 - val_acc: 0.3765\n",
            "Epoch 21/50 - 0.08s - loss: 1.0939 - acc: 0.3794 - val_loss: 1.0947 - val_acc: 0.3745\n",
            "Epoch 22/50 - 0.07s - loss: 1.0935 - acc: 0.3824 - val_loss: 1.0945 - val_acc: 0.3765\n",
            "Epoch 23/50 - 0.07s - loss: 1.0932 - acc: 0.3824 - val_loss: 1.0943 - val_acc: 0.3806\n",
            "Epoch 24/50 - 0.09s - loss: 1.0929 - acc: 0.3817 - val_loss: 1.0941 - val_acc: 0.3785\n",
            "Epoch 25/50 - 0.07s - loss: 1.0926 - acc: 0.3815 - val_loss: 1.0939 - val_acc: 0.3846\n",
            "Epoch 26/50 - 0.08s - loss: 1.0924 - acc: 0.3817 - val_loss: 1.0937 - val_acc: 0.3846\n",
            "Epoch 27/50 - 0.09s - loss: 1.0921 - acc: 0.3824 - val_loss: 1.0936 - val_acc: 0.3866\n",
            "Epoch 28/50 - 0.09s - loss: 1.0919 - acc: 0.3810 - val_loss: 1.0934 - val_acc: 0.3887\n",
            "Epoch 29/50 - 0.08s - loss: 1.0917 - acc: 0.3812 - val_loss: 1.0933 - val_acc: 0.3927\n",
            "Epoch 30/50 - 0.08s - loss: 1.0915 - acc: 0.3826 - val_loss: 1.0931 - val_acc: 0.3846\n",
            "Epoch 31/50 - 0.08s - loss: 1.0913 - acc: 0.3821 - val_loss: 1.0930 - val_acc: 0.3846\n",
            "Epoch 32/50 - 0.08s - loss: 1.0911 - acc: 0.3848 - val_loss: 1.0929 - val_acc: 0.3785\n",
            "Epoch 33/50 - 0.09s - loss: 1.0909 - acc: 0.3864 - val_loss: 1.0928 - val_acc: 0.3745\n",
            "Epoch 34/50 - 0.08s - loss: 1.0907 - acc: 0.3844 - val_loss: 1.0927 - val_acc: 0.3745\n",
            "Epoch 35/50 - 0.08s - loss: 1.0905 - acc: 0.3857 - val_loss: 1.0926 - val_acc: 0.3745\n",
            "Epoch 36/50 - 0.07s - loss: 1.0904 - acc: 0.3873 - val_loss: 1.0925 - val_acc: 0.3765\n",
            "Epoch 37/50 - 0.07s - loss: 1.0902 - acc: 0.3864 - val_loss: 1.0924 - val_acc: 0.3745\n",
            "Epoch 38/50 - 0.08s - loss: 1.0901 - acc: 0.3851 - val_loss: 1.0923 - val_acc: 0.3725\n",
            "Epoch 39/50 - 0.08s - loss: 1.0899 - acc: 0.3848 - val_loss: 1.0922 - val_acc: 0.3704\n",
            "Epoch 40/50 - 0.07s - loss: 1.0898 - acc: 0.3855 - val_loss: 1.0921 - val_acc: 0.3704\n",
            "Epoch 41/50 - 0.07s - loss: 1.0896 - acc: 0.3864 - val_loss: 1.0920 - val_acc: 0.3725\n",
            "Epoch 42/50 - 0.08s - loss: 1.0895 - acc: 0.3889 - val_loss: 1.0920 - val_acc: 0.3725\n",
            "Epoch 43/50 - 0.07s - loss: 1.0894 - acc: 0.3880 - val_loss: 1.0919 - val_acc: 0.3704\n",
            "Epoch 44/50 - 0.07s - loss: 1.0893 - acc: 0.3889 - val_loss: 1.0918 - val_acc: 0.3704\n",
            "Epoch 45/50 - 0.08s - loss: 1.0891 - acc: 0.3905 - val_loss: 1.0917 - val_acc: 0.3725\n",
            "Epoch 46/50 - 0.07s - loss: 1.0890 - acc: 0.3902 - val_loss: 1.0917 - val_acc: 0.3704\n",
            "Epoch 47/50 - 0.07s - loss: 1.0889 - acc: 0.3911 - val_loss: 1.0916 - val_acc: 0.3704\n",
            "Epoch 48/50 - 0.07s - loss: 1.0888 - acc: 0.3891 - val_loss: 1.0915 - val_acc: 0.3704\n",
            "Epoch 49/50 - 0.07s - loss: 1.0887 - acc: 0.3907 - val_loss: 1.0914 - val_acc: 0.3704\n",
            "Epoch 50/50 - 0.08s - loss: 1.0886 - acc: 0.3911 - val_loss: 1.0914 - val_acc: 0.3704\n",
            "\n",
            "Combination 89/252:\n",
            "Hidden Layers: [128, 128], Activation: relu, Learning Rate: 0.0001, Batch Size: 64, Epochs: 100\n",
            "Epoch 1/100 - 0.08s - loss: 1.1010 - acc: 0.3522 - val_loss: 1.1057 - val_acc: 0.3441\n",
            "Epoch 2/100 - 0.07s - loss: 1.1008 - acc: 0.3522 - val_loss: 1.1055 - val_acc: 0.3441\n",
            "Epoch 3/100 - 0.08s - loss: 1.1006 - acc: 0.3511 - val_loss: 1.1054 - val_acc: 0.3381\n",
            "Epoch 4/100 - 0.08s - loss: 1.1005 - acc: 0.3513 - val_loss: 1.1052 - val_acc: 0.3360\n",
            "Epoch 5/100 - 0.07s - loss: 1.1003 - acc: 0.3518 - val_loss: 1.1051 - val_acc: 0.3320\n",
            "Epoch 6/100 - 0.07s - loss: 1.1001 - acc: 0.3480 - val_loss: 1.1050 - val_acc: 0.3401\n",
            "Epoch 7/100 - 0.07s - loss: 1.0999 - acc: 0.3473 - val_loss: 1.1048 - val_acc: 0.3340\n",
            "Epoch 8/100 - 0.08s - loss: 1.0998 - acc: 0.3482 - val_loss: 1.1047 - val_acc: 0.3219\n",
            "Epoch 9/100 - 0.07s - loss: 1.0996 - acc: 0.3489 - val_loss: 1.1046 - val_acc: 0.3198\n",
            "Epoch 10/100 - 0.08s - loss: 1.0995 - acc: 0.3466 - val_loss: 1.1045 - val_acc: 0.3239\n",
            "Epoch 11/100 - 0.07s - loss: 1.0993 - acc: 0.3464 - val_loss: 1.1044 - val_acc: 0.3219\n",
            "Epoch 12/100 - 0.07s - loss: 1.0992 - acc: 0.3455 - val_loss: 1.1043 - val_acc: 0.3300\n",
            "Epoch 13/100 - 0.10s - loss: 1.0990 - acc: 0.3464 - val_loss: 1.1042 - val_acc: 0.3340\n",
            "Epoch 14/100 - 0.07s - loss: 1.0989 - acc: 0.3441 - val_loss: 1.1041 - val_acc: 0.3340\n",
            "Epoch 15/100 - 0.08s - loss: 1.0988 - acc: 0.3457 - val_loss: 1.1040 - val_acc: 0.3401\n",
            "Epoch 16/100 - 0.07s - loss: 1.0987 - acc: 0.3439 - val_loss: 1.1039 - val_acc: 0.3482\n",
            "Epoch 17/100 - 0.07s - loss: 1.0985 - acc: 0.3450 - val_loss: 1.1038 - val_acc: 0.3502\n",
            "Epoch 18/100 - 0.07s - loss: 1.0984 - acc: 0.3464 - val_loss: 1.1037 - val_acc: 0.3462\n",
            "Epoch 19/100 - 0.08s - loss: 1.0983 - acc: 0.3468 - val_loss: 1.1036 - val_acc: 0.3462\n",
            "Epoch 20/100 - 0.07s - loss: 1.0982 - acc: 0.3462 - val_loss: 1.1035 - val_acc: 0.3462\n",
            "Epoch 21/100 - 0.07s - loss: 1.0981 - acc: 0.3464 - val_loss: 1.1035 - val_acc: 0.3563\n",
            "Epoch 22/100 - 0.07s - loss: 1.0980 - acc: 0.3482 - val_loss: 1.1034 - val_acc: 0.3543\n",
            "Epoch 23/100 - 0.07s - loss: 1.0979 - acc: 0.3475 - val_loss: 1.1033 - val_acc: 0.3543\n",
            "Epoch 24/100 - 0.07s - loss: 1.0977 - acc: 0.3477 - val_loss: 1.1032 - val_acc: 0.3502\n",
            "Epoch 25/100 - 0.07s - loss: 1.0976 - acc: 0.3457 - val_loss: 1.1031 - val_acc: 0.3522\n",
            "Epoch 26/100 - 0.08s - loss: 1.0975 - acc: 0.3441 - val_loss: 1.1031 - val_acc: 0.3522\n",
            "Epoch 27/100 - 0.07s - loss: 1.0974 - acc: 0.3437 - val_loss: 1.1030 - val_acc: 0.3482\n",
            "Epoch 28/100 - 0.08s - loss: 1.0974 - acc: 0.3446 - val_loss: 1.1029 - val_acc: 0.3522\n",
            "Epoch 29/100 - 0.08s - loss: 1.0973 - acc: 0.3441 - val_loss: 1.1028 - val_acc: 0.3502\n",
            "Epoch 30/100 - 0.07s - loss: 1.0972 - acc: 0.3439 - val_loss: 1.1027 - val_acc: 0.3502\n",
            "Epoch 31/100 - 0.07s - loss: 1.0971 - acc: 0.3439 - val_loss: 1.1027 - val_acc: 0.3482\n",
            "Epoch 32/100 - 0.08s - loss: 1.0970 - acc: 0.3435 - val_loss: 1.1026 - val_acc: 0.3482\n",
            "Epoch 33/100 - 0.07s - loss: 1.0969 - acc: 0.3437 - val_loss: 1.1025 - val_acc: 0.3462\n",
            "Epoch 34/100 - 0.07s - loss: 1.0968 - acc: 0.3432 - val_loss: 1.1024 - val_acc: 0.3462\n",
            "Epoch 35/100 - 0.07s - loss: 1.0967 - acc: 0.3432 - val_loss: 1.1024 - val_acc: 0.3441\n",
            "Epoch 36/100 - 0.07s - loss: 1.0966 - acc: 0.3435 - val_loss: 1.1023 - val_acc: 0.3462\n",
            "Epoch 37/100 - 0.08s - loss: 1.0965 - acc: 0.3446 - val_loss: 1.1022 - val_acc: 0.3462\n",
            "Epoch 38/100 - 0.08s - loss: 1.0964 - acc: 0.3453 - val_loss: 1.1021 - val_acc: 0.3462\n",
            "Epoch 39/100 - 0.07s - loss: 1.0963 - acc: 0.3450 - val_loss: 1.1021 - val_acc: 0.3462\n",
            "Epoch 40/100 - 0.06s - loss: 1.0963 - acc: 0.3466 - val_loss: 1.1020 - val_acc: 0.3441\n",
            "Epoch 41/100 - 0.07s - loss: 1.0962 - acc: 0.3462 - val_loss: 1.1019 - val_acc: 0.3462\n",
            "Epoch 42/100 - 0.06s - loss: 1.0961 - acc: 0.3464 - val_loss: 1.1019 - val_acc: 0.3462\n",
            "Epoch 43/100 - 0.06s - loss: 1.0960 - acc: 0.3462 - val_loss: 1.1018 - val_acc: 0.3462\n",
            "Epoch 44/100 - 0.07s - loss: 1.0959 - acc: 0.3475 - val_loss: 1.1017 - val_acc: 0.3462\n",
            "Epoch 45/100 - 0.07s - loss: 1.0958 - acc: 0.3471 - val_loss: 1.1016 - val_acc: 0.3441\n",
            "Epoch 46/100 - 0.06s - loss: 1.0958 - acc: 0.3475 - val_loss: 1.1016 - val_acc: 0.3441\n",
            "Epoch 47/100 - 0.06s - loss: 1.0957 - acc: 0.3480 - val_loss: 1.1015 - val_acc: 0.3441\n",
            "Epoch 48/100 - 0.07s - loss: 1.0956 - acc: 0.3489 - val_loss: 1.1014 - val_acc: 0.3441\n",
            "Epoch 49/100 - 0.06s - loss: 1.0955 - acc: 0.3489 - val_loss: 1.1014 - val_acc: 0.3462\n",
            "Epoch 50/100 - 0.06s - loss: 1.0954 - acc: 0.3482 - val_loss: 1.1013 - val_acc: 0.3482\n",
            "Epoch 51/100 - 0.06s - loss: 1.0953 - acc: 0.3489 - val_loss: 1.1012 - val_acc: 0.3482\n",
            "Epoch 52/100 - 0.06s - loss: 1.0953 - acc: 0.3500 - val_loss: 1.1012 - val_acc: 0.3462\n",
            "Epoch 53/100 - 0.06s - loss: 1.0952 - acc: 0.3507 - val_loss: 1.1011 - val_acc: 0.3482\n",
            "Epoch 54/100 - 0.06s - loss: 1.0951 - acc: 0.3511 - val_loss: 1.1010 - val_acc: 0.3482\n",
            "Epoch 55/100 - 0.07s - loss: 1.0950 - acc: 0.3518 - val_loss: 1.1009 - val_acc: 0.3482\n",
            "Epoch 56/100 - 0.06s - loss: 1.0949 - acc: 0.3525 - val_loss: 1.1009 - val_acc: 0.3482\n",
            "Epoch 57/100 - 0.07s - loss: 1.0949 - acc: 0.3525 - val_loss: 1.1008 - val_acc: 0.3482\n",
            "Epoch 58/100 - 0.06s - loss: 1.0948 - acc: 0.3529 - val_loss: 1.1007 - val_acc: 0.3462\n",
            "Epoch 59/100 - 0.06s - loss: 1.0947 - acc: 0.3534 - val_loss: 1.1007 - val_acc: 0.3462\n",
            "Epoch 60/100 - 0.07s - loss: 1.0946 - acc: 0.3540 - val_loss: 1.1006 - val_acc: 0.3482\n",
            "Epoch 61/100 - 0.06s - loss: 1.0946 - acc: 0.3536 - val_loss: 1.1005 - val_acc: 0.3482\n",
            "Epoch 62/100 - 0.06s - loss: 1.0945 - acc: 0.3534 - val_loss: 1.1005 - val_acc: 0.3482\n",
            "Epoch 63/100 - 0.06s - loss: 1.0944 - acc: 0.3536 - val_loss: 1.1004 - val_acc: 0.3502\n",
            "Epoch 64/100 - 0.07s - loss: 1.0943 - acc: 0.3540 - val_loss: 1.1003 - val_acc: 0.3522\n",
            "Epoch 65/100 - 0.06s - loss: 1.0942 - acc: 0.3538 - val_loss: 1.1002 - val_acc: 0.3522\n",
            "Epoch 66/100 - 0.06s - loss: 1.0942 - acc: 0.3540 - val_loss: 1.1002 - val_acc: 0.3543\n",
            "Epoch 67/100 - 0.06s - loss: 1.0941 - acc: 0.3543 - val_loss: 1.1001 - val_acc: 0.3502\n",
            "Epoch 68/100 - 0.07s - loss: 1.0940 - acc: 0.3552 - val_loss: 1.1000 - val_acc: 0.3502\n",
            "Epoch 69/100 - 0.06s - loss: 1.0939 - acc: 0.3558 - val_loss: 1.1000 - val_acc: 0.3482\n",
            "Epoch 70/100 - 0.06s - loss: 1.0939 - acc: 0.3554 - val_loss: 1.0999 - val_acc: 0.3502\n",
            "Epoch 71/100 - 0.06s - loss: 1.0938 - acc: 0.3558 - val_loss: 1.0998 - val_acc: 0.3482\n",
            "Epoch 72/100 - 0.07s - loss: 1.0937 - acc: 0.3554 - val_loss: 1.0998 - val_acc: 0.3502\n",
            "Epoch 73/100 - 0.06s - loss: 1.0936 - acc: 0.3554 - val_loss: 1.0997 - val_acc: 0.3502\n",
            "Epoch 74/100 - 0.06s - loss: 1.0935 - acc: 0.3556 - val_loss: 1.0996 - val_acc: 0.3502\n",
            "Epoch 75/100 - 0.06s - loss: 1.0935 - acc: 0.3576 - val_loss: 1.0996 - val_acc: 0.3502\n",
            "Epoch 76/100 - 0.06s - loss: 1.0934 - acc: 0.3578 - val_loss: 1.0995 - val_acc: 0.3522\n",
            "Epoch 77/100 - 0.06s - loss: 1.0933 - acc: 0.3578 - val_loss: 1.0994 - val_acc: 0.3522\n",
            "Epoch 78/100 - 0.06s - loss: 1.0932 - acc: 0.3578 - val_loss: 1.0994 - val_acc: 0.3502\n",
            "Epoch 79/100 - 0.07s - loss: 1.0932 - acc: 0.3578 - val_loss: 1.0993 - val_acc: 0.3502\n",
            "Epoch 80/100 - 0.07s - loss: 1.0931 - acc: 0.3581 - val_loss: 1.0992 - val_acc: 0.3502\n",
            "Epoch 81/100 - 0.07s - loss: 1.0930 - acc: 0.3585 - val_loss: 1.0992 - val_acc: 0.3502\n",
            "Epoch 82/100 - 0.07s - loss: 1.0929 - acc: 0.3592 - val_loss: 1.0991 - val_acc: 0.3502\n",
            "Epoch 83/100 - 0.08s - loss: 1.0929 - acc: 0.3594 - val_loss: 1.0990 - val_acc: 0.3522\n",
            "Epoch 84/100 - 0.08s - loss: 1.0928 - acc: 0.3596 - val_loss: 1.0990 - val_acc: 0.3522\n",
            "Epoch 85/100 - 0.07s - loss: 1.0927 - acc: 0.3594 - val_loss: 1.0989 - val_acc: 0.3522\n",
            "Epoch 86/100 - 0.07s - loss: 1.0927 - acc: 0.3599 - val_loss: 1.0988 - val_acc: 0.3522\n",
            "Epoch 87/100 - 0.08s - loss: 1.0926 - acc: 0.3608 - val_loss: 1.0987 - val_acc: 0.3522\n",
            "Epoch 88/100 - 0.07s - loss: 1.0925 - acc: 0.3614 - val_loss: 1.0987 - val_acc: 0.3522\n",
            "Epoch 89/100 - 0.06s - loss: 1.0924 - acc: 0.3617 - val_loss: 1.0986 - val_acc: 0.3522\n",
            "Epoch 90/100 - 0.07s - loss: 1.0924 - acc: 0.3621 - val_loss: 1.0985 - val_acc: 0.3522\n",
            "Epoch 91/100 - 0.06s - loss: 1.0923 - acc: 0.3626 - val_loss: 1.0985 - val_acc: 0.3543\n",
            "Epoch 92/100 - 0.06s - loss: 1.0922 - acc: 0.3623 - val_loss: 1.0984 - val_acc: 0.3543\n",
            "Epoch 93/100 - 0.07s - loss: 1.0921 - acc: 0.3621 - val_loss: 1.0983 - val_acc: 0.3522\n",
            "Epoch 94/100 - 0.06s - loss: 1.0921 - acc: 0.3628 - val_loss: 1.0983 - val_acc: 0.3522\n",
            "Epoch 95/100 - 0.06s - loss: 1.0920 - acc: 0.3630 - val_loss: 1.0982 - val_acc: 0.3522\n",
            "Epoch 96/100 - 0.06s - loss: 1.0919 - acc: 0.3635 - val_loss: 1.0981 - val_acc: 0.3522\n",
            "Epoch 97/100 - 0.06s - loss: 1.0918 - acc: 0.3635 - val_loss: 1.0981 - val_acc: 0.3522\n",
            "Epoch 98/100 - 0.06s - loss: 1.0918 - acc: 0.3637 - val_loss: 1.0980 - val_acc: 0.3563\n",
            "Epoch 99/100 - 0.06s - loss: 1.0917 - acc: 0.3648 - val_loss: 1.0979 - val_acc: 0.3583\n",
            "Epoch 100/100 - 0.06s - loss: 1.0916 - acc: 0.3648 - val_loss: 1.0979 - val_acc: 0.3583\n",
            "\n",
            "Combination 90/252:\n",
            "Hidden Layers: [128, 128], Activation: relu, Learning Rate: 0.0001, Batch Size: 64, Epochs: 150\n",
            "Epoch 1/150 - 0.07s - loss: 1.0972 - acc: 0.3729 - val_loss: 1.0992 - val_acc: 0.3482\n",
            "Epoch 2/150 - 0.06s - loss: 1.0968 - acc: 0.3767 - val_loss: 1.0989 - val_acc: 0.3421\n",
            "Epoch 3/150 - 0.06s - loss: 1.0964 - acc: 0.3772 - val_loss: 1.0985 - val_acc: 0.3441\n",
            "Epoch 4/150 - 0.07s - loss: 1.0960 - acc: 0.3776 - val_loss: 1.0982 - val_acc: 0.3401\n",
            "Epoch 5/150 - 0.07s - loss: 1.0956 - acc: 0.3772 - val_loss: 1.0980 - val_acc: 0.3462\n",
            "Epoch 6/150 - 0.06s - loss: 1.0953 - acc: 0.3785 - val_loss: 1.0977 - val_acc: 0.3401\n",
            "Epoch 7/150 - 0.06s - loss: 1.0950 - acc: 0.3817 - val_loss: 1.0974 - val_acc: 0.3482\n",
            "Epoch 8/150 - 0.06s - loss: 1.0947 - acc: 0.3830 - val_loss: 1.0972 - val_acc: 0.3502\n",
            "Epoch 9/150 - 0.06s - loss: 1.0944 - acc: 0.3828 - val_loss: 1.0970 - val_acc: 0.3563\n",
            "Epoch 10/150 - 0.06s - loss: 1.0942 - acc: 0.3828 - val_loss: 1.0968 - val_acc: 0.3502\n",
            "Epoch 11/150 - 0.06s - loss: 1.0939 - acc: 0.3833 - val_loss: 1.0966 - val_acc: 0.3543\n",
            "Epoch 12/150 - 0.06s - loss: 1.0937 - acc: 0.3846 - val_loss: 1.0964 - val_acc: 0.3563\n",
            "Epoch 13/150 - 0.08s - loss: 1.0935 - acc: 0.3866 - val_loss: 1.0962 - val_acc: 0.3583\n",
            "Epoch 14/150 - 0.06s - loss: 1.0932 - acc: 0.3860 - val_loss: 1.0961 - val_acc: 0.3623\n",
            "Epoch 15/150 - 0.06s - loss: 1.0930 - acc: 0.3873 - val_loss: 1.0959 - val_acc: 0.3644\n",
            "Epoch 16/150 - 0.06s - loss: 1.0928 - acc: 0.3882 - val_loss: 1.0957 - val_acc: 0.3603\n",
            "Epoch 17/150 - 0.06s - loss: 1.0926 - acc: 0.3871 - val_loss: 1.0956 - val_acc: 0.3583\n",
            "Epoch 18/150 - 0.06s - loss: 1.0925 - acc: 0.3864 - val_loss: 1.0955 - val_acc: 0.3543\n",
            "Epoch 19/150 - 0.06s - loss: 1.0923 - acc: 0.3873 - val_loss: 1.0953 - val_acc: 0.3543\n",
            "Epoch 20/150 - 0.06s - loss: 1.0921 - acc: 0.3884 - val_loss: 1.0952 - val_acc: 0.3583\n",
            "Epoch 21/150 - 0.06s - loss: 1.0920 - acc: 0.3871 - val_loss: 1.0951 - val_acc: 0.3543\n",
            "Epoch 22/150 - 0.06s - loss: 1.0918 - acc: 0.3871 - val_loss: 1.0950 - val_acc: 0.3563\n",
            "Epoch 23/150 - 0.06s - loss: 1.0916 - acc: 0.3875 - val_loss: 1.0949 - val_acc: 0.3543\n",
            "Epoch 24/150 - 0.06s - loss: 1.0915 - acc: 0.3873 - val_loss: 1.0947 - val_acc: 0.3563\n",
            "Epoch 25/150 - 0.07s - loss: 1.0913 - acc: 0.3864 - val_loss: 1.0946 - val_acc: 0.3644\n",
            "Epoch 26/150 - 0.06s - loss: 1.0912 - acc: 0.3869 - val_loss: 1.0945 - val_acc: 0.3664\n",
            "Epoch 27/150 - 0.06s - loss: 1.0911 - acc: 0.3855 - val_loss: 1.0944 - val_acc: 0.3684\n",
            "Epoch 28/150 - 0.06s - loss: 1.0909 - acc: 0.3857 - val_loss: 1.0943 - val_acc: 0.3704\n",
            "Epoch 29/150 - 0.08s - loss: 1.0908 - acc: 0.3866 - val_loss: 1.0942 - val_acc: 0.3704\n",
            "Epoch 30/150 - 0.07s - loss: 1.0907 - acc: 0.3869 - val_loss: 1.0941 - val_acc: 0.3664\n",
            "Epoch 31/150 - 0.06s - loss: 1.0905 - acc: 0.3851 - val_loss: 1.0940 - val_acc: 0.3664\n",
            "Epoch 32/150 - 0.07s - loss: 1.0904 - acc: 0.3828 - val_loss: 1.0939 - val_acc: 0.3684\n",
            "Epoch 33/150 - 0.07s - loss: 1.0903 - acc: 0.3830 - val_loss: 1.0939 - val_acc: 0.3664\n",
            "Epoch 34/150 - 0.07s - loss: 1.0902 - acc: 0.3830 - val_loss: 1.0938 - val_acc: 0.3684\n",
            "Epoch 35/150 - 0.07s - loss: 1.0900 - acc: 0.3839 - val_loss: 1.0937 - val_acc: 0.3664\n",
            "Epoch 36/150 - 0.08s - loss: 1.0899 - acc: 0.3853 - val_loss: 1.0936 - val_acc: 0.3704\n",
            "Epoch 37/150 - 0.08s - loss: 1.0898 - acc: 0.3869 - val_loss: 1.0935 - val_acc: 0.3725\n",
            "Epoch 38/150 - 0.07s - loss: 1.0897 - acc: 0.3875 - val_loss: 1.0934 - val_acc: 0.3745\n",
            "Epoch 39/150 - 0.07s - loss: 1.0896 - acc: 0.3864 - val_loss: 1.0934 - val_acc: 0.3765\n",
            "Epoch 40/150 - 0.08s - loss: 1.0895 - acc: 0.3864 - val_loss: 1.0933 - val_acc: 0.3785\n",
            "Epoch 41/150 - 0.07s - loss: 1.0894 - acc: 0.3860 - val_loss: 1.0932 - val_acc: 0.3765\n",
            "Epoch 42/150 - 0.08s - loss: 1.0893 - acc: 0.3862 - val_loss: 1.0931 - val_acc: 0.3765\n",
            "Epoch 43/150 - 0.08s - loss: 1.0892 - acc: 0.3855 - val_loss: 1.0930 - val_acc: 0.3806\n",
            "Epoch 44/150 - 0.07s - loss: 1.0891 - acc: 0.3866 - val_loss: 1.0930 - val_acc: 0.3785\n",
            "Epoch 45/150 - 0.07s - loss: 1.0889 - acc: 0.3860 - val_loss: 1.0929 - val_acc: 0.3826\n",
            "Epoch 46/150 - 0.07s - loss: 1.0888 - acc: 0.3860 - val_loss: 1.0928 - val_acc: 0.3826\n",
            "Epoch 47/150 - 0.07s - loss: 1.0887 - acc: 0.3862 - val_loss: 1.0927 - val_acc: 0.3887\n",
            "Epoch 48/150 - 0.08s - loss: 1.0886 - acc: 0.3864 - val_loss: 1.0926 - val_acc: 0.3947\n",
            "Epoch 49/150 - 0.08s - loss: 1.0885 - acc: 0.3864 - val_loss: 1.0926 - val_acc: 0.3927\n",
            "Epoch 50/150 - 0.07s - loss: 1.0884 - acc: 0.3862 - val_loss: 1.0925 - val_acc: 0.3927\n",
            "Epoch 51/150 - 0.07s - loss: 1.0883 - acc: 0.3860 - val_loss: 1.0924 - val_acc: 0.3927\n",
            "Epoch 52/150 - 0.08s - loss: 1.0882 - acc: 0.3864 - val_loss: 1.0923 - val_acc: 0.3907\n",
            "Epoch 53/150 - 0.07s - loss: 1.0881 - acc: 0.3871 - val_loss: 1.0923 - val_acc: 0.3927\n",
            "Epoch 54/150 - 0.07s - loss: 1.0880 - acc: 0.3869 - val_loss: 1.0922 - val_acc: 0.3907\n",
            "Epoch 55/150 - 0.07s - loss: 1.0879 - acc: 0.3891 - val_loss: 1.0921 - val_acc: 0.3947\n",
            "Epoch 56/150 - 0.07s - loss: 1.0878 - acc: 0.3889 - val_loss: 1.0921 - val_acc: 0.3988\n",
            "Epoch 57/150 - 0.07s - loss: 1.0878 - acc: 0.3884 - val_loss: 1.0920 - val_acc: 0.4008\n",
            "Epoch 58/150 - 0.08s - loss: 1.0877 - acc: 0.3880 - val_loss: 1.0919 - val_acc: 0.4008\n",
            "Epoch 59/150 - 0.08s - loss: 1.0876 - acc: 0.3884 - val_loss: 1.0918 - val_acc: 0.4008\n",
            "Epoch 60/150 - 0.09s - loss: 1.0875 - acc: 0.3878 - val_loss: 1.0918 - val_acc: 0.4008\n",
            "Epoch 61/150 - 0.09s - loss: 1.0874 - acc: 0.3884 - val_loss: 1.0917 - val_acc: 0.4028\n",
            "Epoch 62/150 - 0.07s - loss: 1.0873 - acc: 0.3889 - val_loss: 1.0916 - val_acc: 0.4028\n",
            "Epoch 63/150 - 0.07s - loss: 1.0872 - acc: 0.3900 - val_loss: 1.0916 - val_acc: 0.4008\n",
            "Epoch 64/150 - 0.07s - loss: 1.0871 - acc: 0.3891 - val_loss: 1.0915 - val_acc: 0.4028\n",
            "Epoch 65/150 - 0.07s - loss: 1.0870 - acc: 0.3891 - val_loss: 1.0914 - val_acc: 0.4028\n",
            "Epoch 66/150 - 0.08s - loss: 1.0869 - acc: 0.3891 - val_loss: 1.0913 - val_acc: 0.4028\n",
            "Epoch 67/150 - 0.08s - loss: 1.0868 - acc: 0.3898 - val_loss: 1.0913 - val_acc: 0.4008\n",
            "Epoch 68/150 - 0.07s - loss: 1.0867 - acc: 0.3898 - val_loss: 1.0912 - val_acc: 0.4008\n",
            "Epoch 69/150 - 0.07s - loss: 1.0866 - acc: 0.3900 - val_loss: 1.0911 - val_acc: 0.3988\n",
            "Epoch 70/150 - 0.08s - loss: 1.0865 - acc: 0.3900 - val_loss: 1.0911 - val_acc: 0.3988\n",
            "Epoch 71/150 - 0.07s - loss: 1.0864 - acc: 0.3898 - val_loss: 1.0910 - val_acc: 0.3988\n",
            "Epoch 72/150 - 0.08s - loss: 1.0863 - acc: 0.3893 - val_loss: 1.0909 - val_acc: 0.3968\n",
            "Epoch 73/150 - 0.08s - loss: 1.0863 - acc: 0.3893 - val_loss: 1.0908 - val_acc: 0.3947\n",
            "Epoch 74/150 - 0.07s - loss: 1.0862 - acc: 0.3896 - val_loss: 1.0908 - val_acc: 0.3947\n",
            "Epoch 75/150 - 0.07s - loss: 1.0861 - acc: 0.3896 - val_loss: 1.0907 - val_acc: 0.3968\n",
            "Epoch 76/150 - 0.09s - loss: 1.0860 - acc: 0.3896 - val_loss: 1.0906 - val_acc: 0.3968\n",
            "Epoch 77/150 - 0.07s - loss: 1.0859 - acc: 0.3896 - val_loss: 1.0906 - val_acc: 0.3947\n",
            "Epoch 78/150 - 0.07s - loss: 1.0858 - acc: 0.3898 - val_loss: 1.0905 - val_acc: 0.3947\n",
            "Epoch 79/150 - 0.07s - loss: 1.0857 - acc: 0.3900 - val_loss: 1.0904 - val_acc: 0.3947\n",
            "Epoch 80/150 - 0.07s - loss: 1.0856 - acc: 0.3898 - val_loss: 1.0904 - val_acc: 0.3947\n",
            "Epoch 81/150 - 0.07s - loss: 1.0855 - acc: 0.3907 - val_loss: 1.0903 - val_acc: 0.3988\n",
            "Epoch 82/150 - 0.07s - loss: 1.0854 - acc: 0.3907 - val_loss: 1.0902 - val_acc: 0.4008\n",
            "Epoch 83/150 - 0.07s - loss: 1.0854 - acc: 0.3907 - val_loss: 1.0901 - val_acc: 0.4008\n",
            "Epoch 84/150 - 0.07s - loss: 1.0853 - acc: 0.3911 - val_loss: 1.0901 - val_acc: 0.4028\n",
            "Epoch 85/150 - 0.08s - loss: 1.0852 - acc: 0.3918 - val_loss: 1.0900 - val_acc: 0.4028\n",
            "Epoch 86/150 - 0.08s - loss: 1.0851 - acc: 0.3920 - val_loss: 1.0899 - val_acc: 0.4028\n",
            "Epoch 87/150 - 0.08s - loss: 1.0850 - acc: 0.3932 - val_loss: 1.0899 - val_acc: 0.4049\n",
            "Epoch 88/150 - 0.08s - loss: 1.0849 - acc: 0.3936 - val_loss: 1.0898 - val_acc: 0.4049\n",
            "Epoch 89/150 - 0.07s - loss: 1.0848 - acc: 0.3936 - val_loss: 1.0897 - val_acc: 0.4049\n",
            "Epoch 90/150 - 0.07s - loss: 1.0847 - acc: 0.3941 - val_loss: 1.0896 - val_acc: 0.4049\n",
            "Epoch 91/150 - 0.07s - loss: 1.0847 - acc: 0.3943 - val_loss: 1.0896 - val_acc: 0.4049\n",
            "Epoch 92/150 - 0.07s - loss: 1.0846 - acc: 0.3959 - val_loss: 1.0895 - val_acc: 0.4049\n",
            "Epoch 93/150 - 0.07s - loss: 1.0845 - acc: 0.3952 - val_loss: 1.0894 - val_acc: 0.4069\n",
            "Epoch 94/150 - 0.08s - loss: 1.0844 - acc: 0.3952 - val_loss: 1.0894 - val_acc: 0.4069\n",
            "Epoch 95/150 - 0.07s - loss: 1.0843 - acc: 0.3968 - val_loss: 1.0893 - val_acc: 0.4069\n",
            "Epoch 96/150 - 0.08s - loss: 1.0842 - acc: 0.3979 - val_loss: 1.0892 - val_acc: 0.4069\n",
            "Epoch 97/150 - 0.08s - loss: 1.0841 - acc: 0.3979 - val_loss: 1.0892 - val_acc: 0.4069\n",
            "Epoch 98/150 - 0.07s - loss: 1.0841 - acc: 0.3979 - val_loss: 1.0891 - val_acc: 0.4069\n",
            "Epoch 99/150 - 0.07s - loss: 1.0840 - acc: 0.3981 - val_loss: 1.0890 - val_acc: 0.4089\n",
            "Epoch 100/150 - 0.07s - loss: 1.0839 - acc: 0.3986 - val_loss: 1.0890 - val_acc: 0.4089\n",
            "Epoch 101/150 - 0.07s - loss: 1.0838 - acc: 0.3990 - val_loss: 1.0889 - val_acc: 0.4089\n",
            "Epoch 102/150 - 0.07s - loss: 1.0837 - acc: 0.3990 - val_loss: 1.0888 - val_acc: 0.4089\n",
            "Epoch 103/150 - 0.08s - loss: 1.0836 - acc: 0.3992 - val_loss: 1.0888 - val_acc: 0.4069\n",
            "Epoch 104/150 - 0.07s - loss: 1.0836 - acc: 0.3992 - val_loss: 1.0887 - val_acc: 0.4069\n",
            "Epoch 105/150 - 0.07s - loss: 1.0835 - acc: 0.3992 - val_loss: 1.0886 - val_acc: 0.4069\n",
            "Epoch 106/150 - 0.09s - loss: 1.0834 - acc: 0.3999 - val_loss: 1.0886 - val_acc: 0.4069\n",
            "Epoch 107/150 - 0.07s - loss: 1.0833 - acc: 0.4001 - val_loss: 1.0885 - val_acc: 0.4069\n",
            "Epoch 108/150 - 0.08s - loss: 1.0832 - acc: 0.4006 - val_loss: 1.0884 - val_acc: 0.4069\n",
            "Epoch 109/150 - 0.07s - loss: 1.0831 - acc: 0.4006 - val_loss: 1.0884 - val_acc: 0.4089\n",
            "Epoch 110/150 - 0.07s - loss: 1.0831 - acc: 0.4008 - val_loss: 1.0883 - val_acc: 0.4089\n",
            "Epoch 111/150 - 0.07s - loss: 1.0830 - acc: 0.4010 - val_loss: 1.0882 - val_acc: 0.4089\n",
            "Epoch 112/150 - 0.08s - loss: 1.0829 - acc: 0.4019 - val_loss: 1.0882 - val_acc: 0.4089\n",
            "Epoch 113/150 - 0.07s - loss: 1.0828 - acc: 0.4026 - val_loss: 1.0881 - val_acc: 0.4089\n",
            "Epoch 114/150 - 0.07s - loss: 1.0827 - acc: 0.4024 - val_loss: 1.0880 - val_acc: 0.4089\n",
            "Epoch 115/150 - 0.07s - loss: 1.0826 - acc: 0.4026 - val_loss: 1.0880 - val_acc: 0.4089\n",
            "Epoch 116/150 - 0.07s - loss: 1.0826 - acc: 0.4037 - val_loss: 1.0879 - val_acc: 0.4089\n",
            "Epoch 117/150 - 0.07s - loss: 1.0825 - acc: 0.4042 - val_loss: 1.0878 - val_acc: 0.4109\n",
            "Epoch 118/150 - 0.07s - loss: 1.0824 - acc: 0.4044 - val_loss: 1.0878 - val_acc: 0.4109\n",
            "Epoch 119/150 - 0.07s - loss: 1.0823 - acc: 0.4042 - val_loss: 1.0877 - val_acc: 0.4109\n",
            "Epoch 120/150 - 0.07s - loss: 1.0822 - acc: 0.4037 - val_loss: 1.0876 - val_acc: 0.4109\n",
            "Epoch 121/150 - 0.07s - loss: 1.0822 - acc: 0.4035 - val_loss: 1.0876 - val_acc: 0.4109\n",
            "Epoch 122/150 - 0.08s - loss: 1.0821 - acc: 0.4040 - val_loss: 1.0875 - val_acc: 0.4130\n",
            "Epoch 123/150 - 0.07s - loss: 1.0820 - acc: 0.4040 - val_loss: 1.0874 - val_acc: 0.4130\n",
            "Epoch 124/150 - 0.07s - loss: 1.0819 - acc: 0.4044 - val_loss: 1.0874 - val_acc: 0.4130\n",
            "Epoch 125/150 - 0.07s - loss: 1.0818 - acc: 0.4046 - val_loss: 1.0873 - val_acc: 0.4130\n",
            "Epoch 126/150 - 0.08s - loss: 1.0818 - acc: 0.4053 - val_loss: 1.0872 - val_acc: 0.4109\n",
            "Epoch 127/150 - 0.07s - loss: 1.0817 - acc: 0.4055 - val_loss: 1.0872 - val_acc: 0.4109\n",
            "Epoch 128/150 - 0.07s - loss: 1.0816 - acc: 0.4055 - val_loss: 1.0871 - val_acc: 0.4109\n",
            "Epoch 129/150 - 0.07s - loss: 1.0815 - acc: 0.4058 - val_loss: 1.0870 - val_acc: 0.4109\n",
            "Epoch 130/150 - 0.07s - loss: 1.0814 - acc: 0.4053 - val_loss: 1.0870 - val_acc: 0.4130\n",
            "Epoch 131/150 - 0.07s - loss: 1.0814 - acc: 0.4069 - val_loss: 1.0869 - val_acc: 0.4109\n",
            "Epoch 132/150 - 0.07s - loss: 1.0813 - acc: 0.4064 - val_loss: 1.0868 - val_acc: 0.4109\n",
            "Epoch 133/150 - 0.07s - loss: 1.0812 - acc: 0.4069 - val_loss: 1.0868 - val_acc: 0.4109\n",
            "Epoch 134/150 - 0.08s - loss: 1.0811 - acc: 0.4071 - val_loss: 1.0867 - val_acc: 0.4109\n",
            "Epoch 135/150 - 0.07s - loss: 1.0810 - acc: 0.4073 - val_loss: 1.0866 - val_acc: 0.4109\n",
            "Epoch 136/150 - 0.07s - loss: 1.0810 - acc: 0.4080 - val_loss: 1.0866 - val_acc: 0.4130\n",
            "Epoch 137/150 - 0.07s - loss: 1.0809 - acc: 0.4087 - val_loss: 1.0865 - val_acc: 0.4130\n",
            "Epoch 138/150 - 0.07s - loss: 1.0808 - acc: 0.4073 - val_loss: 1.0864 - val_acc: 0.4130\n",
            "Epoch 139/150 - 0.07s - loss: 1.0807 - acc: 0.4067 - val_loss: 1.0864 - val_acc: 0.4089\n",
            "Epoch 140/150 - 0.08s - loss: 1.0807 - acc: 0.4069 - val_loss: 1.0863 - val_acc: 0.4089\n",
            "Epoch 141/150 - 0.07s - loss: 1.0806 - acc: 0.4067 - val_loss: 1.0863 - val_acc: 0.4089\n",
            "Epoch 142/150 - 0.07s - loss: 1.0805 - acc: 0.4064 - val_loss: 1.0862 - val_acc: 0.4130\n",
            "Epoch 143/150 - 0.07s - loss: 1.0804 - acc: 0.4062 - val_loss: 1.0861 - val_acc: 0.4130\n",
            "Epoch 144/150 - 0.07s - loss: 1.0804 - acc: 0.4062 - val_loss: 1.0861 - val_acc: 0.4130\n",
            "Epoch 145/150 - 0.08s - loss: 1.0803 - acc: 0.4071 - val_loss: 1.0860 - val_acc: 0.4130\n",
            "Epoch 146/150 - 0.08s - loss: 1.0802 - acc: 0.4069 - val_loss: 1.0859 - val_acc: 0.4130\n",
            "Epoch 147/150 - 0.07s - loss: 1.0801 - acc: 0.4067 - val_loss: 1.0859 - val_acc: 0.4130\n",
            "Epoch 148/150 - 0.07s - loss: 1.0800 - acc: 0.4069 - val_loss: 1.0858 - val_acc: 0.4150\n",
            "Epoch 149/150 - 0.07s - loss: 1.0800 - acc: 0.4073 - val_loss: 1.0858 - val_acc: 0.4150\n",
            "Epoch 150/150 - 0.07s - loss: 1.0799 - acc: 0.4078 - val_loss: 1.0857 - val_acc: 0.4150\n",
            "\n",
            "Combination 91/252:\n",
            "Hidden Layers: [128, 128], Activation: tanh, Learning Rate: 0.01, Batch Size: 32, Epochs: 50\n",
            "Epoch 1/50 - 0.14s - loss: 1.0781 - acc: 0.4318 - val_loss: 1.0819 - val_acc: 0.4170\n",
            "Epoch 2/50 - 0.15s - loss: 1.0639 - acc: 0.4582 - val_loss: 1.0707 - val_acc: 0.4453\n",
            "Epoch 3/50 - 0.13s - loss: 1.0542 - acc: 0.4548 - val_loss: 1.0631 - val_acc: 0.4494\n",
            "Epoch 4/50 - 0.13s - loss: 1.0441 - acc: 0.4717 - val_loss: 1.0577 - val_acc: 0.4595\n",
            "Epoch 5/50 - 0.12s - loss: 1.0342 - acc: 0.4901 - val_loss: 1.0497 - val_acc: 0.4818\n",
            "Epoch 6/50 - 0.13s - loss: 1.0275 - acc: 0.4840 - val_loss: 1.0445 - val_acc: 0.4676\n",
            "Epoch 7/50 - 0.13s - loss: 1.0186 - acc: 0.5097 - val_loss: 1.0392 - val_acc: 0.4960\n",
            "Epoch 8/50 - 0.14s - loss: 1.0134 - acc: 0.5022 - val_loss: 1.0351 - val_acc: 0.4777\n",
            "Epoch 9/50 - 0.12s - loss: 1.0044 - acc: 0.5148 - val_loss: 1.0283 - val_acc: 0.4939\n",
            "Epoch 10/50 - 0.13s - loss: 0.9994 - acc: 0.5164 - val_loss: 1.0247 - val_acc: 0.5121\n",
            "Epoch 11/50 - 0.13s - loss: 0.9940 - acc: 0.5191 - val_loss: 1.0208 - val_acc: 0.5243\n",
            "Epoch 12/50 - 0.15s - loss: 0.9904 - acc: 0.5146 - val_loss: 1.0152 - val_acc: 0.5000\n",
            "Epoch 13/50 - 0.14s - loss: 0.9853 - acc: 0.5225 - val_loss: 1.0135 - val_acc: 0.5101\n",
            "Epoch 14/50 - 0.14s - loss: 0.9744 - acc: 0.5331 - val_loss: 1.0031 - val_acc: 0.5223\n",
            "Epoch 15/50 - 0.13s - loss: 0.9731 - acc: 0.5301 - val_loss: 1.0011 - val_acc: 0.5243\n",
            "Epoch 16/50 - 0.14s - loss: 0.9664 - acc: 0.5331 - val_loss: 0.9948 - val_acc: 0.5121\n",
            "Epoch 17/50 - 0.13s - loss: 0.9602 - acc: 0.5443 - val_loss: 0.9917 - val_acc: 0.5445\n",
            "Epoch 18/50 - 0.13s - loss: 0.9705 - acc: 0.5281 - val_loss: 1.0030 - val_acc: 0.5020\n",
            "Epoch 19/50 - 0.13s - loss: 0.9519 - acc: 0.5481 - val_loss: 0.9852 - val_acc: 0.5445\n",
            "Epoch 20/50 - 0.14s - loss: 0.9593 - acc: 0.5488 - val_loss: 0.9937 - val_acc: 0.5506\n",
            "Epoch 21/50 - 0.13s - loss: 0.9451 - acc: 0.5549 - val_loss: 0.9804 - val_acc: 0.5425\n",
            "Epoch 22/50 - 0.13s - loss: 0.9437 - acc: 0.5526 - val_loss: 0.9800 - val_acc: 0.5445\n",
            "Epoch 23/50 - 0.13s - loss: 0.9378 - acc: 0.5585 - val_loss: 0.9752 - val_acc: 0.5526\n",
            "Epoch 24/50 - 0.13s - loss: 0.9390 - acc: 0.5508 - val_loss: 0.9761 - val_acc: 0.5324\n",
            "Epoch 25/50 - 0.13s - loss: 0.9306 - acc: 0.5612 - val_loss: 0.9678 - val_acc: 0.5587\n",
            "Epoch 26/50 - 0.13s - loss: 0.9294 - acc: 0.5632 - val_loss: 0.9693 - val_acc: 0.5567\n",
            "Epoch 27/50 - 0.13s - loss: 0.9414 - acc: 0.5637 - val_loss: 0.9817 - val_acc: 0.5547\n",
            "Epoch 28/50 - 0.13s - loss: 0.9261 - acc: 0.5684 - val_loss: 0.9695 - val_acc: 0.5526\n",
            "Epoch 29/50 - 0.13s - loss: 0.9262 - acc: 0.5549 - val_loss: 0.9695 - val_acc: 0.5364\n",
            "Epoch 30/50 - 0.13s - loss: 0.9192 - acc: 0.5700 - val_loss: 0.9619 - val_acc: 0.5709\n",
            "Epoch 31/50 - 0.14s - loss: 0.9142 - acc: 0.5666 - val_loss: 0.9600 - val_acc: 0.5587\n",
            "Epoch 32/50 - 0.14s - loss: 0.9241 - acc: 0.5517 - val_loss: 0.9692 - val_acc: 0.5405\n",
            "Epoch 33/50 - 0.13s - loss: 0.9140 - acc: 0.5713 - val_loss: 0.9598 - val_acc: 0.5567\n",
            "Epoch 34/50 - 0.13s - loss: 0.9077 - acc: 0.5742 - val_loss: 0.9593 - val_acc: 0.5526\n",
            "Epoch 35/50 - 0.13s - loss: 0.9066 - acc: 0.5762 - val_loss: 0.9571 - val_acc: 0.5729\n",
            "Epoch 36/50 - 0.13s - loss: 0.9068 - acc: 0.5684 - val_loss: 0.9577 - val_acc: 0.5466\n",
            "Epoch 37/50 - 0.12s - loss: 0.9082 - acc: 0.5726 - val_loss: 0.9643 - val_acc: 0.5385\n",
            "Epoch 38/50 - 0.14s - loss: 0.9056 - acc: 0.5758 - val_loss: 0.9632 - val_acc: 0.5567\n",
            "Epoch 39/50 - 0.13s - loss: 0.8985 - acc: 0.5798 - val_loss: 0.9558 - val_acc: 0.5547\n",
            "Epoch 40/50 - 0.14s - loss: 0.9036 - acc: 0.5670 - val_loss: 0.9610 - val_acc: 0.5364\n",
            "Epoch 41/50 - 0.13s - loss: 0.9039 - acc: 0.5882 - val_loss: 0.9629 - val_acc: 0.5688\n",
            "Epoch 42/50 - 0.13s - loss: 0.8988 - acc: 0.5756 - val_loss: 0.9633 - val_acc: 0.5304\n",
            "Epoch 43/50 - 0.13s - loss: 0.8930 - acc: 0.5794 - val_loss: 0.9572 - val_acc: 0.5364\n",
            "Epoch 44/50 - 0.14s - loss: 0.8876 - acc: 0.5886 - val_loss: 0.9531 - val_acc: 0.5668\n",
            "Epoch 45/50 - 0.13s - loss: 0.8869 - acc: 0.5864 - val_loss: 0.9484 - val_acc: 0.5810\n",
            "Epoch 46/50 - 0.14s - loss: 0.8986 - acc: 0.5819 - val_loss: 0.9694 - val_acc: 0.5243\n",
            "Epoch 47/50 - 0.13s - loss: 0.8829 - acc: 0.5931 - val_loss: 0.9509 - val_acc: 0.5587\n",
            "Epoch 48/50 - 0.13s - loss: 0.8879 - acc: 0.5756 - val_loss: 0.9538 - val_acc: 0.5405\n",
            "Epoch 49/50 - 0.12s - loss: 0.8929 - acc: 0.5954 - val_loss: 0.9611 - val_acc: 0.5870\n",
            "Epoch 50/50 - 0.13s - loss: 0.8876 - acc: 0.5785 - val_loss: 0.9563 - val_acc: 0.5425\n",
            "\n",
            "Combination 92/252:\n",
            "Hidden Layers: [128, 128], Activation: tanh, Learning Rate: 0.01, Batch Size: 32, Epochs: 100\n",
            "Epoch 1/100 - 0.12s - loss: 1.0796 - acc: 0.4076 - val_loss: 1.0846 - val_acc: 0.4028\n",
            "Epoch 2/100 - 0.13s - loss: 1.0690 - acc: 0.4390 - val_loss: 1.0767 - val_acc: 0.4089\n",
            "Epoch 3/100 - 0.13s - loss: 1.0577 - acc: 0.4649 - val_loss: 1.0658 - val_acc: 0.4393\n",
            "Epoch 4/100 - 0.14s - loss: 1.0488 - acc: 0.4777 - val_loss: 1.0593 - val_acc: 0.4555\n",
            "Epoch 5/100 - 0.13s - loss: 1.0424 - acc: 0.4753 - val_loss: 1.0542 - val_acc: 0.4737\n",
            "Epoch 6/100 - 0.14s - loss: 1.0349 - acc: 0.4854 - val_loss: 1.0478 - val_acc: 0.4676\n",
            "Epoch 7/100 - 0.13s - loss: 1.0264 - acc: 0.4928 - val_loss: 1.0429 - val_acc: 0.4696\n",
            "Epoch 8/100 - 0.14s - loss: 1.0194 - acc: 0.4978 - val_loss: 1.0374 - val_acc: 0.5101\n",
            "Epoch 9/100 - 0.13s - loss: 1.0143 - acc: 0.5013 - val_loss: 1.0326 - val_acc: 0.5040\n",
            "Epoch 10/100 - 0.13s - loss: 1.0112 - acc: 0.4930 - val_loss: 1.0313 - val_acc: 0.4777\n",
            "Epoch 11/100 - 0.13s - loss: 1.0001 - acc: 0.5155 - val_loss: 1.0212 - val_acc: 0.5263\n",
            "Epoch 12/100 - 0.13s - loss: 0.9946 - acc: 0.5128 - val_loss: 1.0161 - val_acc: 0.5202\n",
            "Epoch 13/100 - 0.12s - loss: 0.9887 - acc: 0.5182 - val_loss: 1.0113 - val_acc: 0.5223\n",
            "Epoch 14/100 - 0.13s - loss: 0.9828 - acc: 0.5283 - val_loss: 1.0068 - val_acc: 0.5304\n",
            "Epoch 15/100 - 0.13s - loss: 0.9786 - acc: 0.5340 - val_loss: 1.0038 - val_acc: 0.5425\n",
            "Epoch 16/100 - 0.13s - loss: 0.9797 - acc: 0.5288 - val_loss: 1.0037 - val_acc: 0.5324\n",
            "Epoch 17/100 - 0.13s - loss: 0.9712 - acc: 0.5288 - val_loss: 0.9968 - val_acc: 0.5121\n",
            "Epoch 18/100 - 0.13s - loss: 0.9692 - acc: 0.5418 - val_loss: 0.9975 - val_acc: 0.5385\n",
            "Epoch 19/100 - 0.12s - loss: 0.9600 - acc: 0.5466 - val_loss: 0.9872 - val_acc: 0.5425\n",
            "Epoch 20/100 - 0.14s - loss: 0.9562 - acc: 0.5416 - val_loss: 0.9833 - val_acc: 0.5344\n",
            "Epoch 21/100 - 0.13s - loss: 0.9560 - acc: 0.5502 - val_loss: 0.9858 - val_acc: 0.5486\n",
            "Epoch 22/100 - 0.13s - loss: 0.9539 - acc: 0.5535 - val_loss: 0.9842 - val_acc: 0.5466\n",
            "Epoch 23/100 - 0.13s - loss: 0.9443 - acc: 0.5538 - val_loss: 0.9756 - val_acc: 0.5486\n",
            "Epoch 24/100 - 0.13s - loss: 0.9436 - acc: 0.5520 - val_loss: 0.9771 - val_acc: 0.5364\n",
            "Epoch 25/100 - 0.12s - loss: 0.9378 - acc: 0.5574 - val_loss: 0.9704 - val_acc: 0.5547\n",
            "Epoch 26/100 - 0.14s - loss: 0.9352 - acc: 0.5623 - val_loss: 0.9700 - val_acc: 0.5486\n",
            "Epoch 27/100 - 0.13s - loss: 0.9429 - acc: 0.5407 - val_loss: 0.9788 - val_acc: 0.5304\n",
            "Epoch 28/100 - 0.13s - loss: 0.9294 - acc: 0.5670 - val_loss: 0.9683 - val_acc: 0.5587\n",
            "Epoch 29/100 - 0.13s - loss: 0.9332 - acc: 0.5706 - val_loss: 0.9719 - val_acc: 0.5547\n",
            "Epoch 30/100 - 0.13s - loss: 0.9231 - acc: 0.5677 - val_loss: 0.9620 - val_acc: 0.5567\n",
            "Epoch 31/100 - 0.13s - loss: 0.9252 - acc: 0.5650 - val_loss: 0.9678 - val_acc: 0.5506\n",
            "Epoch 32/100 - 0.13s - loss: 0.9220 - acc: 0.5605 - val_loss: 0.9654 - val_acc: 0.5405\n",
            "Epoch 33/100 - 0.13s - loss: 0.9185 - acc: 0.5760 - val_loss: 0.9630 - val_acc: 0.5405\n",
            "Epoch 34/100 - 0.13s - loss: 0.9127 - acc: 0.5722 - val_loss: 0.9560 - val_acc: 0.5445\n",
            "Epoch 35/100 - 0.13s - loss: 0.9212 - acc: 0.5623 - val_loss: 0.9728 - val_acc: 0.5162\n",
            "Epoch 36/100 - 0.14s - loss: 0.9494 - acc: 0.5560 - val_loss: 0.9916 - val_acc: 0.5709\n",
            "Epoch 37/100 - 0.14s - loss: 0.9096 - acc: 0.5749 - val_loss: 0.9601 - val_acc: 0.5324\n",
            "Epoch 38/100 - 0.13s - loss: 0.9191 - acc: 0.5834 - val_loss: 0.9684 - val_acc: 0.5587\n",
            "Epoch 39/100 - 0.13s - loss: 0.9026 - acc: 0.5857 - val_loss: 0.9574 - val_acc: 0.5547\n",
            "Epoch 40/100 - 0.13s - loss: 0.9004 - acc: 0.5805 - val_loss: 0.9538 - val_acc: 0.5486\n",
            "Epoch 41/100 - 0.13s - loss: 0.8984 - acc: 0.5877 - val_loss: 0.9540 - val_acc: 0.5628\n",
            "Epoch 42/100 - 0.13s - loss: 0.8975 - acc: 0.5785 - val_loss: 0.9540 - val_acc: 0.5385\n",
            "Epoch 43/100 - 0.13s - loss: 0.8939 - acc: 0.5855 - val_loss: 0.9518 - val_acc: 0.5486\n",
            "Epoch 44/100 - 0.13s - loss: 0.8911 - acc: 0.5852 - val_loss: 0.9529 - val_acc: 0.5506\n",
            "Epoch 45/100 - 0.13s - loss: 0.9131 - acc: 0.5641 - val_loss: 0.9834 - val_acc: 0.4919\n",
            "Epoch 46/100 - 0.13s - loss: 0.8913 - acc: 0.5807 - val_loss: 0.9583 - val_acc: 0.5324\n",
            "Epoch 47/100 - 0.12s - loss: 0.8897 - acc: 0.5821 - val_loss: 0.9570 - val_acc: 0.5425\n",
            "Epoch 48/100 - 0.13s - loss: 0.8860 - acc: 0.5868 - val_loss: 0.9569 - val_acc: 0.5445\n",
            "Epoch 49/100 - 0.13s - loss: 0.8826 - acc: 0.5918 - val_loss: 0.9533 - val_acc: 0.5364\n",
            "Epoch 50/100 - 0.14s - loss: 0.9008 - acc: 0.5675 - val_loss: 0.9726 - val_acc: 0.5283\n",
            "Epoch 51/100 - 0.12s - loss: 0.9341 - acc: 0.5565 - val_loss: 1.0036 - val_acc: 0.5142\n",
            "Epoch 52/100 - 0.13s - loss: 0.8877 - acc: 0.5807 - val_loss: 0.9582 - val_acc: 0.5445\n",
            "Epoch 53/100 - 0.13s - loss: 0.8849 - acc: 0.5891 - val_loss: 0.9646 - val_acc: 0.5162\n",
            "Epoch 54/100 - 0.13s - loss: 0.8877 - acc: 0.5825 - val_loss: 0.9723 - val_acc: 0.5061\n",
            "Epoch 55/100 - 0.13s - loss: 0.8789 - acc: 0.5866 - val_loss: 0.9581 - val_acc: 0.5445\n",
            "Epoch 56/100 - 0.13s - loss: 0.9193 - acc: 0.5603 - val_loss: 1.0135 - val_acc: 0.4899\n",
            "Epoch 57/100 - 0.13s - loss: 0.8746 - acc: 0.5884 - val_loss: 0.9596 - val_acc: 0.5364\n",
            "Epoch 58/100 - 0.13s - loss: 0.8936 - acc: 0.5717 - val_loss: 0.9736 - val_acc: 0.5283\n",
            "Epoch 59/100 - 0.13s - loss: 0.9017 - acc: 0.5625 - val_loss: 0.9911 - val_acc: 0.5000\n",
            "Epoch 60/100 - 0.14s - loss: 0.8779 - acc: 0.5888 - val_loss: 0.9684 - val_acc: 0.5202\n",
            "Epoch 61/100 - 0.14s - loss: 0.8736 - acc: 0.5931 - val_loss: 0.9616 - val_acc: 0.5344\n",
            "Epoch 62/100 - 0.14s - loss: 0.8808 - acc: 0.5803 - val_loss: 0.9634 - val_acc: 0.5486\n",
            "Epoch 63/100 - 0.13s - loss: 0.8634 - acc: 0.6035 - val_loss: 0.9538 - val_acc: 0.5364\n",
            "Epoch 64/100 - 0.13s - loss: 0.8827 - acc: 0.5864 - val_loss: 0.9840 - val_acc: 0.5101\n",
            "Epoch 65/100 - 0.14s - loss: 0.8626 - acc: 0.6035 - val_loss: 0.9579 - val_acc: 0.5405\n",
            "Epoch 66/100 - 0.15s - loss: 0.8783 - acc: 0.5861 - val_loss: 0.9795 - val_acc: 0.5081\n",
            "Epoch 67/100 - 0.13s - loss: 0.8782 - acc: 0.5900 - val_loss: 0.9824 - val_acc: 0.5040\n",
            "Epoch 68/100 - 0.13s - loss: 0.8815 - acc: 0.5850 - val_loss: 0.9716 - val_acc: 0.5506\n",
            "Epoch 69/100 - 0.13s - loss: 0.8636 - acc: 0.5992 - val_loss: 0.9653 - val_acc: 0.5405\n",
            "Epoch 70/100 - 0.14s - loss: 0.8649 - acc: 0.5994 - val_loss: 0.9713 - val_acc: 0.5223\n",
            "Epoch 71/100 - 0.14s - loss: 0.8848 - acc: 0.5875 - val_loss: 0.9972 - val_acc: 0.5263\n",
            "Epoch 72/100 - 0.14s - loss: 0.8876 - acc: 0.5922 - val_loss: 0.9815 - val_acc: 0.5486\n",
            "Epoch 73/100 - 0.13s - loss: 0.8645 - acc: 0.6032 - val_loss: 0.9764 - val_acc: 0.5182\n",
            "Epoch 74/100 - 0.13s - loss: 0.8543 - acc: 0.6050 - val_loss: 0.9592 - val_acc: 0.5405\n",
            "Epoch 75/100 - 0.12s - loss: 0.8570 - acc: 0.6149 - val_loss: 0.9648 - val_acc: 0.5425\n",
            "Epoch 76/100 - 0.13s - loss: 0.8595 - acc: 0.6127 - val_loss: 0.9666 - val_acc: 0.5364\n",
            "Epoch 77/100 - 0.13s - loss: 0.8637 - acc: 0.5931 - val_loss: 0.9677 - val_acc: 0.5648\n",
            "Epoch 78/100 - 0.14s - loss: 0.8527 - acc: 0.6127 - val_loss: 0.9646 - val_acc: 0.5385\n",
            "Epoch 79/100 - 0.13s - loss: 0.8522 - acc: 0.6100 - val_loss: 0.9676 - val_acc: 0.5466\n",
            "Epoch 80/100 - 0.13s - loss: 0.8614 - acc: 0.5956 - val_loss: 0.9718 - val_acc: 0.5364\n",
            "Epoch 81/100 - 0.14s - loss: 0.8685 - acc: 0.5873 - val_loss: 0.9746 - val_acc: 0.5466\n",
            "Epoch 82/100 - 0.13s - loss: 0.8573 - acc: 0.6095 - val_loss: 0.9722 - val_acc: 0.5324\n",
            "Epoch 83/100 - 0.13s - loss: 0.8528 - acc: 0.6053 - val_loss: 0.9678 - val_acc: 0.5506\n",
            "Epoch 84/100 - 0.15s - loss: 0.8628 - acc: 0.5967 - val_loss: 0.9791 - val_acc: 0.5162\n",
            "Epoch 85/100 - 0.13s - loss: 0.8612 - acc: 0.5963 - val_loss: 0.9804 - val_acc: 0.5081\n",
            "Epoch 86/100 - 0.14s - loss: 0.8570 - acc: 0.5990 - val_loss: 0.9682 - val_acc: 0.5506\n",
            "Epoch 87/100 - 0.13s - loss: 0.8477 - acc: 0.6140 - val_loss: 0.9612 - val_acc: 0.5506\n",
            "Epoch 88/100 - 0.13s - loss: 0.8657 - acc: 0.5929 - val_loss: 0.9785 - val_acc: 0.5344\n",
            "Epoch 89/100 - 0.13s - loss: 0.8670 - acc: 0.5990 - val_loss: 0.9790 - val_acc: 0.5466\n",
            "Epoch 90/100 - 0.13s - loss: 0.8590 - acc: 0.5999 - val_loss: 0.9754 - val_acc: 0.5445\n",
            "Epoch 91/100 - 0.12s - loss: 0.8725 - acc: 0.5915 - val_loss: 0.9830 - val_acc: 0.5587\n",
            "Epoch 92/100 - 0.13s - loss: 0.8560 - acc: 0.6021 - val_loss: 0.9804 - val_acc: 0.5263\n",
            "Epoch 93/100 - 0.13s - loss: 0.8752 - acc: 0.5861 - val_loss: 1.0074 - val_acc: 0.4879\n",
            "Epoch 94/100 - 0.14s - loss: 0.8731 - acc: 0.5942 - val_loss: 1.0048 - val_acc: 0.5243\n",
            "Epoch 95/100 - 0.13s - loss: 0.8481 - acc: 0.6093 - val_loss: 0.9687 - val_acc: 0.5567\n",
            "Epoch 96/100 - 0.14s - loss: 0.8394 - acc: 0.6208 - val_loss: 0.9651 - val_acc: 0.5466\n",
            "Epoch 97/100 - 0.13s - loss: 0.8508 - acc: 0.6136 - val_loss: 0.9779 - val_acc: 0.5425\n",
            "Epoch 98/100 - 0.13s - loss: 0.8858 - acc: 0.5803 - val_loss: 1.0228 - val_acc: 0.4858\n",
            "Epoch 99/100 - 0.13s - loss: 0.8379 - acc: 0.6199 - val_loss: 0.9653 - val_acc: 0.5587\n",
            "Epoch 100/100 - 0.13s - loss: 0.8501 - acc: 0.6107 - val_loss: 0.9817 - val_acc: 0.5344\n",
            "\n",
            "Combination 93/252:\n",
            "Hidden Layers: [128, 128], Activation: tanh, Learning Rate: 0.01, Batch Size: 32, Epochs: 150\n",
            "Epoch 1/150 - 0.13s - loss: 1.0765 - acc: 0.4170 - val_loss: 1.0744 - val_acc: 0.4190\n",
            "Epoch 2/150 - 0.15s - loss: 1.0625 - acc: 0.4372 - val_loss: 1.0642 - val_acc: 0.4271\n",
            "Epoch 3/150 - 0.13s - loss: 1.0545 - acc: 0.4444 - val_loss: 1.0592 - val_acc: 0.4352\n",
            "Epoch 4/150 - 0.13s - loss: 1.0452 - acc: 0.4532 - val_loss: 1.0509 - val_acc: 0.4555\n",
            "Epoch 5/150 - 0.12s - loss: 1.0366 - acc: 0.4717 - val_loss: 1.0434 - val_acc: 0.4696\n",
            "Epoch 6/150 - 0.13s - loss: 1.0374 - acc: 0.4620 - val_loss: 1.0435 - val_acc: 0.4575\n",
            "Epoch 7/150 - 0.12s - loss: 1.0242 - acc: 0.4883 - val_loss: 1.0345 - val_acc: 0.4960\n",
            "Epoch 8/150 - 0.13s - loss: 1.0192 - acc: 0.4849 - val_loss: 1.0314 - val_acc: 0.4879\n",
            "Epoch 9/150 - 0.13s - loss: 1.0119 - acc: 0.4987 - val_loss: 1.0234 - val_acc: 0.5040\n",
            "Epoch 10/150 - 0.13s - loss: 1.0044 - acc: 0.5045 - val_loss: 1.0163 - val_acc: 0.5040\n",
            "Epoch 11/150 - 0.13s - loss: 0.9979 - acc: 0.5133 - val_loss: 1.0115 - val_acc: 0.5223\n",
            "Epoch 12/150 - 0.13s - loss: 0.9948 - acc: 0.5106 - val_loss: 1.0090 - val_acc: 0.4899\n",
            "Epoch 13/150 - 0.12s - loss: 0.9875 - acc: 0.5241 - val_loss: 1.0023 - val_acc: 0.5385\n",
            "Epoch 14/150 - 0.14s - loss: 0.9830 - acc: 0.5259 - val_loss: 0.9977 - val_acc: 0.5405\n",
            "Epoch 15/150 - 0.13s - loss: 0.9762 - acc: 0.5310 - val_loss: 0.9919 - val_acc: 0.5405\n",
            "Epoch 16/150 - 0.13s - loss: 0.9722 - acc: 0.5346 - val_loss: 0.9889 - val_acc: 0.5324\n",
            "Epoch 17/150 - 0.12s - loss: 0.9690 - acc: 0.5369 - val_loss: 0.9863 - val_acc: 0.5405\n",
            "Epoch 18/150 - 0.13s - loss: 0.9677 - acc: 0.5385 - val_loss: 0.9896 - val_acc: 0.5324\n",
            "Epoch 19/150 - 0.13s - loss: 0.9599 - acc: 0.5409 - val_loss: 0.9798 - val_acc: 0.5526\n",
            "Epoch 20/150 - 0.13s - loss: 0.9577 - acc: 0.5463 - val_loss: 0.9789 - val_acc: 0.5567\n",
            "Epoch 21/150 - 0.12s - loss: 0.9567 - acc: 0.5378 - val_loss: 0.9789 - val_acc: 0.5385\n",
            "Epoch 22/150 - 0.13s - loss: 0.9782 - acc: 0.5099 - val_loss: 1.0031 - val_acc: 0.4919\n",
            "Epoch 23/150 - 0.13s - loss: 0.9437 - acc: 0.5569 - val_loss: 0.9693 - val_acc: 0.5628\n",
            "Epoch 24/150 - 0.14s - loss: 0.9559 - acc: 0.5421 - val_loss: 0.9789 - val_acc: 0.5466\n",
            "Epoch 25/150 - 0.15s - loss: 0.9387 - acc: 0.5621 - val_loss: 0.9671 - val_acc: 0.5486\n",
            "Epoch 26/150 - 0.14s - loss: 0.9381 - acc: 0.5675 - val_loss: 0.9660 - val_acc: 0.5466\n",
            "Epoch 27/150 - 0.13s - loss: 0.9295 - acc: 0.5664 - val_loss: 0.9604 - val_acc: 0.5466\n",
            "Epoch 28/150 - 0.13s - loss: 0.9335 - acc: 0.5553 - val_loss: 0.9654 - val_acc: 0.5425\n",
            "Epoch 29/150 - 0.13s - loss: 0.9345 - acc: 0.5650 - val_loss: 0.9651 - val_acc: 0.5567\n",
            "Epoch 30/150 - 0.13s - loss: 0.9254 - acc: 0.5693 - val_loss: 0.9579 - val_acc: 0.5668\n",
            "Epoch 31/150 - 0.13s - loss: 0.9199 - acc: 0.5666 - val_loss: 0.9558 - val_acc: 0.5526\n",
            "Epoch 32/150 - 0.14s - loss: 0.9300 - acc: 0.5520 - val_loss: 0.9666 - val_acc: 0.5283\n",
            "Epoch 33/150 - 0.13s - loss: 0.9129 - acc: 0.5720 - val_loss: 0.9516 - val_acc: 0.5526\n",
            "Epoch 34/150 - 0.13s - loss: 0.9366 - acc: 0.5443 - val_loss: 0.9789 - val_acc: 0.5142\n",
            "Epoch 35/150 - 0.13s - loss: 0.9095 - acc: 0.5850 - val_loss: 0.9510 - val_acc: 0.5587\n",
            "Epoch 36/150 - 0.13s - loss: 0.9052 - acc: 0.5821 - val_loss: 0.9481 - val_acc: 0.5648\n",
            "Epoch 37/150 - 0.12s - loss: 0.9034 - acc: 0.5774 - val_loss: 0.9481 - val_acc: 0.5506\n",
            "Epoch 38/150 - 0.13s - loss: 0.9041 - acc: 0.5866 - val_loss: 0.9496 - val_acc: 0.5668\n",
            "Epoch 39/150 - 0.13s - loss: 0.9035 - acc: 0.5834 - val_loss: 0.9538 - val_acc: 0.5466\n",
            "Epoch 40/150 - 0.13s - loss: 0.9041 - acc: 0.5767 - val_loss: 0.9508 - val_acc: 0.5607\n",
            "Epoch 41/150 - 0.12s - loss: 0.9261 - acc: 0.5576 - val_loss: 0.9826 - val_acc: 0.4980\n",
            "Epoch 42/150 - 0.13s - loss: 0.8945 - acc: 0.5936 - val_loss: 0.9490 - val_acc: 0.5567\n",
            "Epoch 43/150 - 0.12s - loss: 0.8927 - acc: 0.5841 - val_loss: 0.9455 - val_acc: 0.5526\n",
            "Epoch 44/150 - 0.14s - loss: 0.8908 - acc: 0.5879 - val_loss: 0.9439 - val_acc: 0.5567\n",
            "Epoch 45/150 - 0.14s - loss: 0.9054 - acc: 0.5837 - val_loss: 0.9600 - val_acc: 0.5810\n",
            "Epoch 46/150 - 0.13s - loss: 0.8870 - acc: 0.5850 - val_loss: 0.9455 - val_acc: 0.5547\n",
            "Epoch 47/150 - 0.12s - loss: 0.8859 - acc: 0.6014 - val_loss: 0.9498 - val_acc: 0.5567\n",
            "Epoch 48/150 - 0.13s - loss: 0.8858 - acc: 0.5868 - val_loss: 0.9470 - val_acc: 0.5526\n",
            "Epoch 49/150 - 0.13s - loss: 0.8822 - acc: 0.5879 - val_loss: 0.9481 - val_acc: 0.5526\n",
            "Epoch 50/150 - 0.13s - loss: 0.8787 - acc: 0.5940 - val_loss: 0.9423 - val_acc: 0.5506\n",
            "Epoch 51/150 - 0.12s - loss: 0.8855 - acc: 0.5922 - val_loss: 0.9493 - val_acc: 0.5668\n",
            "Epoch 52/150 - 0.13s - loss: 0.8896 - acc: 0.5897 - val_loss: 0.9546 - val_acc: 0.5648\n",
            "Epoch 53/150 - 0.14s - loss: 0.8786 - acc: 0.5915 - val_loss: 0.9497 - val_acc: 0.5425\n",
            "Epoch 54/150 - 0.13s - loss: 0.8826 - acc: 0.6028 - val_loss: 0.9549 - val_acc: 0.5567\n",
            "Epoch 55/150 - 0.13s - loss: 0.8792 - acc: 0.5985 - val_loss: 0.9509 - val_acc: 0.5648\n",
            "Epoch 56/150 - 0.13s - loss: 0.8718 - acc: 0.6028 - val_loss: 0.9462 - val_acc: 0.5628\n",
            "Epoch 57/150 - 0.13s - loss: 0.8855 - acc: 0.5812 - val_loss: 0.9598 - val_acc: 0.5344\n",
            "Epoch 58/150 - 0.13s - loss: 0.8706 - acc: 0.5947 - val_loss: 0.9500 - val_acc: 0.5364\n",
            "Epoch 59/150 - 0.12s - loss: 0.8707 - acc: 0.5938 - val_loss: 0.9496 - val_acc: 0.5445\n",
            "Epoch 60/150 - 0.13s - loss: 0.8994 - acc: 0.5749 - val_loss: 0.9885 - val_acc: 0.5182\n",
            "Epoch 61/150 - 0.12s - loss: 0.9174 - acc: 0.5603 - val_loss: 0.9884 - val_acc: 0.5425\n",
            "Epoch 62/150 - 0.13s - loss: 0.8843 - acc: 0.5785 - val_loss: 0.9706 - val_acc: 0.5223\n",
            "Epoch 63/150 - 0.12s - loss: 0.8845 - acc: 0.6012 - val_loss: 0.9679 - val_acc: 0.5729\n",
            "Epoch 64/150 - 0.13s - loss: 0.8767 - acc: 0.5938 - val_loss: 0.9663 - val_acc: 0.5243\n",
            "Epoch 65/150 - 0.13s - loss: 0.8820 - acc: 0.5938 - val_loss: 0.9633 - val_acc: 0.5526\n",
            "Epoch 66/150 - 0.13s - loss: 0.8678 - acc: 0.6064 - val_loss: 0.9637 - val_acc: 0.5425\n",
            "Epoch 67/150 - 0.13s - loss: 0.8679 - acc: 0.6082 - val_loss: 0.9621 - val_acc: 0.5263\n",
            "Epoch 68/150 - 0.13s - loss: 0.8650 - acc: 0.5960 - val_loss: 0.9579 - val_acc: 0.5364\n",
            "Epoch 69/150 - 0.13s - loss: 0.8655 - acc: 0.6059 - val_loss: 0.9616 - val_acc: 0.5344\n",
            "Epoch 70/150 - 0.13s - loss: 0.9034 - acc: 0.5711 - val_loss: 0.9872 - val_acc: 0.5547\n",
            "Epoch 71/150 - 0.12s - loss: 0.8869 - acc: 0.5909 - val_loss: 0.9917 - val_acc: 0.5081\n",
            "Epoch 72/150 - 0.13s - loss: 0.8758 - acc: 0.5868 - val_loss: 0.9640 - val_acc: 0.5607\n",
            "Epoch 73/150 - 0.13s - loss: 0.8657 - acc: 0.6057 - val_loss: 0.9614 - val_acc: 0.5587\n",
            "Epoch 74/150 - 0.15s - loss: 0.8747 - acc: 0.5963 - val_loss: 0.9820 - val_acc: 0.5061\n",
            "Epoch 75/150 - 0.13s - loss: 0.8576 - acc: 0.6028 - val_loss: 0.9582 - val_acc: 0.5405\n",
            "Epoch 76/150 - 0.14s - loss: 0.8610 - acc: 0.6021 - val_loss: 0.9654 - val_acc: 0.5223\n",
            "Epoch 77/150 - 0.13s - loss: 0.8520 - acc: 0.6104 - val_loss: 0.9535 - val_acc: 0.5526\n",
            "Epoch 78/150 - 0.13s - loss: 0.8607 - acc: 0.6059 - val_loss: 0.9600 - val_acc: 0.5506\n",
            "Epoch 79/150 - 0.13s - loss: 0.8794 - acc: 0.5855 - val_loss: 0.9915 - val_acc: 0.4980\n",
            "Epoch 80/150 - 0.16s - loss: 0.8512 - acc: 0.6100 - val_loss: 0.9581 - val_acc: 0.5526\n",
            "Epoch 81/150 - 0.15s - loss: 0.8609 - acc: 0.6098 - val_loss: 0.9694 - val_acc: 0.5526\n",
            "Epoch 82/150 - 0.13s - loss: 0.8518 - acc: 0.6075 - val_loss: 0.9619 - val_acc: 0.5486\n",
            "Epoch 83/150 - 0.13s - loss: 0.8546 - acc: 0.6125 - val_loss: 0.9646 - val_acc: 0.5486\n",
            "Epoch 84/150 - 0.13s - loss: 0.8540 - acc: 0.6037 - val_loss: 0.9596 - val_acc: 0.5425\n",
            "Epoch 85/150 - 0.13s - loss: 0.8603 - acc: 0.6003 - val_loss: 0.9751 - val_acc: 0.5283\n",
            "Epoch 86/150 - 0.14s - loss: 0.8881 - acc: 0.5785 - val_loss: 1.0011 - val_acc: 0.5121\n",
            "Epoch 87/150 - 0.13s - loss: 0.8627 - acc: 0.5945 - val_loss: 0.9696 - val_acc: 0.5547\n",
            "Epoch 88/150 - 0.13s - loss: 0.8585 - acc: 0.6026 - val_loss: 0.9777 - val_acc: 0.5223\n",
            "Epoch 89/150 - 0.13s - loss: 0.8491 - acc: 0.6100 - val_loss: 0.9658 - val_acc: 0.5506\n",
            "Epoch 90/150 - 0.14s - loss: 0.8563 - acc: 0.6093 - val_loss: 0.9728 - val_acc: 0.5547\n",
            "Epoch 91/150 - 0.13s - loss: 0.8761 - acc: 0.6053 - val_loss: 0.9856 - val_acc: 0.5506\n",
            "Epoch 92/150 - 0.14s - loss: 0.8460 - acc: 0.6154 - val_loss: 0.9605 - val_acc: 0.5587\n",
            "Epoch 93/150 - 0.13s - loss: 0.8532 - acc: 0.6145 - val_loss: 0.9684 - val_acc: 0.5587\n",
            "Epoch 94/150 - 0.13s - loss: 0.8508 - acc: 0.6035 - val_loss: 0.9721 - val_acc: 0.5344\n",
            "Epoch 95/150 - 0.12s - loss: 0.8503 - acc: 0.6145 - val_loss: 0.9675 - val_acc: 0.5607\n",
            "Epoch 96/150 - 0.13s - loss: 0.8533 - acc: 0.6075 - val_loss: 0.9675 - val_acc: 0.5526\n",
            "Epoch 97/150 - 0.13s - loss: 0.8519 - acc: 0.6131 - val_loss: 0.9706 - val_acc: 0.5668\n",
            "Epoch 98/150 - 0.13s - loss: 0.8413 - acc: 0.6172 - val_loss: 0.9616 - val_acc: 0.5486\n",
            "Epoch 99/150 - 0.13s - loss: 0.8704 - acc: 0.5873 - val_loss: 0.9872 - val_acc: 0.5243\n",
            "Epoch 100/150 - 0.13s - loss: 0.8529 - acc: 0.6037 - val_loss: 0.9746 - val_acc: 0.5344\n",
            "Epoch 101/150 - 0.12s - loss: 0.9014 - acc: 0.5661 - val_loss: 1.0303 - val_acc: 0.5040\n",
            "Epoch 102/150 - 0.13s - loss: 0.8474 - acc: 0.6109 - val_loss: 0.9713 - val_acc: 0.5445\n",
            "Epoch 103/150 - 0.13s - loss: 0.8618 - acc: 0.6075 - val_loss: 0.9783 - val_acc: 0.5547\n",
            "Epoch 104/150 - 0.13s - loss: 0.8538 - acc: 0.6152 - val_loss: 0.9735 - val_acc: 0.5587\n",
            "Epoch 105/150 - 0.12s - loss: 0.8583 - acc: 0.6059 - val_loss: 0.9877 - val_acc: 0.5223\n",
            "Epoch 106/150 - 0.13s - loss: 0.8833 - acc: 0.5868 - val_loss: 1.0192 - val_acc: 0.4939\n",
            "Epoch 107/150 - 0.12s - loss: 0.9212 - acc: 0.5549 - val_loss: 1.0543 - val_acc: 0.4939\n",
            "Epoch 108/150 - 0.13s - loss: 0.8468 - acc: 0.6174 - val_loss: 0.9762 - val_acc: 0.5486\n",
            "Epoch 109/150 - 0.14s - loss: 0.8469 - acc: 0.6120 - val_loss: 0.9743 - val_acc: 0.5344\n",
            "Epoch 110/150 - 0.14s - loss: 0.8461 - acc: 0.6131 - val_loss: 0.9699 - val_acc: 0.5405\n",
            "Epoch 111/150 - 0.14s - loss: 0.8472 - acc: 0.6147 - val_loss: 0.9748 - val_acc: 0.5324\n",
            "Epoch 112/150 - 0.13s - loss: 0.8575 - acc: 0.6073 - val_loss: 0.9946 - val_acc: 0.5223\n",
            "Epoch 113/150 - 0.13s - loss: 0.8694 - acc: 0.5992 - val_loss: 1.0089 - val_acc: 0.5101\n",
            "Epoch 114/150 - 0.13s - loss: 0.8369 - acc: 0.6217 - val_loss: 0.9670 - val_acc: 0.5506\n",
            "Epoch 115/150 - 0.13s - loss: 0.8567 - acc: 0.6122 - val_loss: 0.9881 - val_acc: 0.5445\n",
            "Epoch 116/150 - 0.14s - loss: 0.8578 - acc: 0.6161 - val_loss: 0.9849 - val_acc: 0.5506\n",
            "Epoch 117/150 - 0.13s - loss: 0.8712 - acc: 0.5902 - val_loss: 0.9968 - val_acc: 0.5202\n",
            "Epoch 118/150 - 0.13s - loss: 0.8467 - acc: 0.6190 - val_loss: 0.9799 - val_acc: 0.5486\n",
            "Epoch 119/150 - 0.13s - loss: 0.8425 - acc: 0.6113 - val_loss: 0.9698 - val_acc: 0.5547\n",
            "Epoch 120/150 - 0.13s - loss: 0.8458 - acc: 0.6203 - val_loss: 0.9798 - val_acc: 0.5506\n",
            "Epoch 121/150 - 0.13s - loss: 0.8369 - acc: 0.6185 - val_loss: 0.9709 - val_acc: 0.5425\n",
            "Epoch 122/150 - 0.13s - loss: 0.8491 - acc: 0.6138 - val_loss: 0.9888 - val_acc: 0.5304\n",
            "Epoch 123/150 - 0.13s - loss: 0.8361 - acc: 0.6192 - val_loss: 0.9692 - val_acc: 0.5547\n",
            "Epoch 124/150 - 0.13s - loss: 0.8382 - acc: 0.6219 - val_loss: 0.9704 - val_acc: 0.5506\n",
            "Epoch 125/150 - 0.12s - loss: 0.8738 - acc: 0.5895 - val_loss: 0.9933 - val_acc: 0.5445\n",
            "Epoch 126/150 - 0.13s - loss: 0.8424 - acc: 0.6129 - val_loss: 0.9707 - val_acc: 0.5526\n",
            "Epoch 127/150 - 0.12s - loss: 0.8404 - acc: 0.6138 - val_loss: 0.9772 - val_acc: 0.5466\n",
            "Epoch 128/150 - 0.13s - loss: 0.8712 - acc: 0.5902 - val_loss: 0.9929 - val_acc: 0.5445\n",
            "Epoch 129/150 - 0.13s - loss: 0.8334 - acc: 0.6262 - val_loss: 0.9686 - val_acc: 0.5607\n",
            "Epoch 130/150 - 0.13s - loss: 0.8834 - acc: 0.5792 - val_loss: 1.0030 - val_acc: 0.5304\n",
            "Epoch 131/150 - 0.13s - loss: 0.8543 - acc: 0.6026 - val_loss: 0.9877 - val_acc: 0.5263\n",
            "Epoch 132/150 - 0.13s - loss: 0.8360 - acc: 0.6239 - val_loss: 0.9679 - val_acc: 0.5547\n",
            "Epoch 133/150 - 0.13s - loss: 0.8429 - acc: 0.6089 - val_loss: 0.9797 - val_acc: 0.5324\n",
            "Epoch 134/150 - 0.13s - loss: 0.8369 - acc: 0.6167 - val_loss: 0.9757 - val_acc: 0.5405\n",
            "Epoch 135/150 - 0.13s - loss: 0.8331 - acc: 0.6185 - val_loss: 0.9729 - val_acc: 0.5547\n",
            "Epoch 136/150 - 0.13s - loss: 0.8441 - acc: 0.6143 - val_loss: 0.9872 - val_acc: 0.5283\n",
            "Epoch 137/150 - 0.14s - loss: 0.8309 - acc: 0.6269 - val_loss: 0.9671 - val_acc: 0.5648\n",
            "Epoch 138/150 - 0.13s - loss: 0.8307 - acc: 0.6228 - val_loss: 0.9699 - val_acc: 0.5628\n",
            "Epoch 139/150 - 0.13s - loss: 0.8304 - acc: 0.6239 - val_loss: 0.9673 - val_acc: 0.5567\n",
            "Epoch 140/150 - 0.13s - loss: 0.8417 - acc: 0.6122 - val_loss: 0.9844 - val_acc: 0.5385\n",
            "Epoch 141/150 - 0.12s - loss: 0.8303 - acc: 0.6237 - val_loss: 0.9722 - val_acc: 0.5506\n",
            "Epoch 142/150 - 0.13s - loss: 0.8334 - acc: 0.6188 - val_loss: 0.9764 - val_acc: 0.5486\n",
            "Epoch 143/150 - 0.13s - loss: 0.8566 - acc: 0.6053 - val_loss: 1.0039 - val_acc: 0.5202\n",
            "Epoch 144/150 - 0.13s - loss: 0.8433 - acc: 0.6129 - val_loss: 0.9858 - val_acc: 0.5162\n",
            "Epoch 145/150 - 0.12s - loss: 0.8313 - acc: 0.6278 - val_loss: 0.9665 - val_acc: 0.5567\n",
            "Epoch 146/150 - 0.13s - loss: 0.8358 - acc: 0.6188 - val_loss: 0.9812 - val_acc: 0.5547\n",
            "Epoch 147/150 - 0.13s - loss: 0.8557 - acc: 0.5990 - val_loss: 0.9852 - val_acc: 0.5526\n",
            "Epoch 148/150 - 0.13s - loss: 0.8339 - acc: 0.6239 - val_loss: 0.9697 - val_acc: 0.5466\n",
            "Epoch 149/150 - 0.13s - loss: 0.8493 - acc: 0.6055 - val_loss: 0.9996 - val_acc: 0.5081\n",
            "Epoch 150/150 - 0.13s - loss: 0.8259 - acc: 0.6255 - val_loss: 0.9660 - val_acc: 0.5547\n",
            "\n",
            "Combination 94/252:\n",
            "Hidden Layers: [128, 128], Activation: tanh, Learning Rate: 0.01, Batch Size: 64, Epochs: 50\n",
            "Epoch 1/50 - 0.11s - loss: 1.0905 - acc: 0.3869 - val_loss: 1.0904 - val_acc: 0.3826\n",
            "Epoch 2/50 - 0.11s - loss: 1.0816 - acc: 0.4089 - val_loss: 1.0833 - val_acc: 0.3968\n",
            "Epoch 3/50 - 0.11s - loss: 1.0760 - acc: 0.4051 - val_loss: 1.0781 - val_acc: 0.4190\n",
            "Epoch 4/50 - 0.11s - loss: 1.0688 - acc: 0.4314 - val_loss: 1.0726 - val_acc: 0.4312\n",
            "Epoch 5/50 - 0.11s - loss: 1.0628 - acc: 0.4575 - val_loss: 1.0679 - val_acc: 0.4413\n",
            "Epoch 6/50 - 0.11s - loss: 1.0581 - acc: 0.4624 - val_loss: 1.0647 - val_acc: 0.4474\n",
            "Epoch 7/50 - 0.11s - loss: 1.0535 - acc: 0.4683 - val_loss: 1.0607 - val_acc: 0.4575\n",
            "Epoch 8/50 - 0.11s - loss: 1.0496 - acc: 0.4672 - val_loss: 1.0573 - val_acc: 0.4636\n",
            "Epoch 9/50 - 0.11s - loss: 1.0457 - acc: 0.4717 - val_loss: 1.0552 - val_acc: 0.4676\n",
            "Epoch 10/50 - 0.10s - loss: 1.0415 - acc: 0.4739 - val_loss: 1.0510 - val_acc: 0.4798\n",
            "Epoch 11/50 - 0.11s - loss: 1.0377 - acc: 0.4822 - val_loss: 1.0491 - val_acc: 0.4676\n",
            "Epoch 12/50 - 0.11s - loss: 1.0344 - acc: 0.4795 - val_loss: 1.0456 - val_acc: 0.4777\n",
            "Epoch 13/50 - 0.10s - loss: 1.0314 - acc: 0.4899 - val_loss: 1.0439 - val_acc: 0.4757\n",
            "Epoch 14/50 - 0.11s - loss: 1.0279 - acc: 0.4874 - val_loss: 1.0419 - val_acc: 0.4960\n",
            "Epoch 15/50 - 0.11s - loss: 1.0247 - acc: 0.4957 - val_loss: 1.0395 - val_acc: 0.4818\n",
            "Epoch 16/50 - 0.13s - loss: 1.0219 - acc: 0.4946 - val_loss: 1.0376 - val_acc: 0.5020\n",
            "Epoch 17/50 - 0.12s - loss: 1.0190 - acc: 0.4991 - val_loss: 1.0364 - val_acc: 0.5000\n",
            "Epoch 18/50 - 0.11s - loss: 1.0138 - acc: 0.5063 - val_loss: 1.0303 - val_acc: 0.5061\n",
            "Epoch 19/50 - 0.11s - loss: 1.0107 - acc: 0.5101 - val_loss: 1.0279 - val_acc: 0.5142\n",
            "Epoch 20/50 - 0.11s - loss: 1.0076 - acc: 0.5205 - val_loss: 1.0262 - val_acc: 0.5081\n",
            "Epoch 21/50 - 0.11s - loss: 1.0042 - acc: 0.5229 - val_loss: 1.0232 - val_acc: 0.5121\n",
            "Epoch 22/50 - 0.12s - loss: 1.0032 - acc: 0.5112 - val_loss: 1.0224 - val_acc: 0.5162\n",
            "Epoch 23/50 - 0.11s - loss: 0.9999 - acc: 0.5139 - val_loss: 1.0181 - val_acc: 0.5040\n",
            "Epoch 24/50 - 0.11s - loss: 0.9960 - acc: 0.5236 - val_loss: 1.0173 - val_acc: 0.5101\n",
            "Epoch 25/50 - 0.11s - loss: 0.9928 - acc: 0.5277 - val_loss: 1.0144 - val_acc: 0.5101\n",
            "Epoch 26/50 - 0.11s - loss: 0.9898 - acc: 0.5281 - val_loss: 1.0111 - val_acc: 0.5243\n",
            "Epoch 27/50 - 0.10s - loss: 0.9863 - acc: 0.5331 - val_loss: 1.0073 - val_acc: 0.5283\n",
            "Epoch 28/50 - 0.11s - loss: 0.9866 - acc: 0.5283 - val_loss: 1.0078 - val_acc: 0.5223\n",
            "Epoch 29/50 - 0.10s - loss: 0.9869 - acc: 0.5209 - val_loss: 1.0071 - val_acc: 0.5162\n",
            "Epoch 30/50 - 0.11s - loss: 0.9792 - acc: 0.5358 - val_loss: 1.0017 - val_acc: 0.5425\n",
            "Epoch 31/50 - 0.10s - loss: 0.9752 - acc: 0.5407 - val_loss: 0.9984 - val_acc: 0.5466\n",
            "Epoch 32/50 - 0.11s - loss: 0.9762 - acc: 0.5270 - val_loss: 1.0005 - val_acc: 0.5324\n",
            "Epoch 33/50 - 0.11s - loss: 0.9699 - acc: 0.5396 - val_loss: 0.9936 - val_acc: 0.5405\n",
            "Epoch 34/50 - 0.12s - loss: 0.9687 - acc: 0.5351 - val_loss: 0.9936 - val_acc: 0.5283\n",
            "Epoch 35/50 - 0.10s - loss: 0.9651 - acc: 0.5430 - val_loss: 0.9891 - val_acc: 0.5486\n",
            "Epoch 36/50 - 0.12s - loss: 0.9630 - acc: 0.5423 - val_loss: 0.9871 - val_acc: 0.5526\n",
            "Epoch 37/50 - 0.12s - loss: 0.9705 - acc: 0.5268 - val_loss: 0.9957 - val_acc: 0.5121\n",
            "Epoch 38/50 - 0.11s - loss: 0.9592 - acc: 0.5450 - val_loss: 0.9837 - val_acc: 0.5547\n",
            "Epoch 39/50 - 0.11s - loss: 0.9557 - acc: 0.5488 - val_loss: 0.9824 - val_acc: 0.5547\n",
            "Epoch 40/50 - 0.12s - loss: 0.9547 - acc: 0.5499 - val_loss: 0.9808 - val_acc: 0.5668\n",
            "Epoch 41/50 - 0.11s - loss: 0.9536 - acc: 0.5477 - val_loss: 0.9831 - val_acc: 0.5364\n",
            "Epoch 42/50 - 0.12s - loss: 0.9532 - acc: 0.5607 - val_loss: 0.9818 - val_acc: 0.5567\n",
            "Epoch 43/50 - 0.11s - loss: 0.9576 - acc: 0.5504 - val_loss: 0.9846 - val_acc: 0.5486\n",
            "Epoch 44/50 - 0.12s - loss: 0.9451 - acc: 0.5558 - val_loss: 0.9747 - val_acc: 0.5729\n",
            "Epoch 45/50 - 0.11s - loss: 0.9446 - acc: 0.5585 - val_loss: 0.9731 - val_acc: 0.5729\n",
            "Epoch 46/50 - 0.11s - loss: 0.9432 - acc: 0.5614 - val_loss: 0.9727 - val_acc: 0.5709\n",
            "Epoch 47/50 - 0.11s - loss: 0.9411 - acc: 0.5567 - val_loss: 0.9698 - val_acc: 0.5729\n",
            "Epoch 48/50 - 0.11s - loss: 0.9455 - acc: 0.5490 - val_loss: 0.9789 - val_acc: 0.5223\n",
            "Epoch 49/50 - 0.11s - loss: 0.9475 - acc: 0.5614 - val_loss: 0.9775 - val_acc: 0.5567\n",
            "Epoch 50/50 - 0.11s - loss: 0.9392 - acc: 0.5637 - val_loss: 0.9691 - val_acc: 0.5648\n",
            "\n",
            "Combination 95/252:\n",
            "Hidden Layers: [128, 128], Activation: tanh, Learning Rate: 0.01, Batch Size: 64, Epochs: 100\n",
            "Epoch 1/100 - 0.11s - loss: 1.0879 - acc: 0.3844 - val_loss: 1.0919 - val_acc: 0.3927\n",
            "Epoch 2/100 - 0.12s - loss: 1.0797 - acc: 0.4170 - val_loss: 1.0858 - val_acc: 0.3927\n",
            "Epoch 3/100 - 0.11s - loss: 1.0720 - acc: 0.4420 - val_loss: 1.0772 - val_acc: 0.4352\n",
            "Epoch 4/100 - 0.11s - loss: 1.0655 - acc: 0.4404 - val_loss: 1.0743 - val_acc: 0.4170\n",
            "Epoch 5/100 - 0.10s - loss: 1.0600 - acc: 0.4519 - val_loss: 1.0699 - val_acc: 0.4372\n",
            "Epoch 6/100 - 0.11s - loss: 1.0554 - acc: 0.4593 - val_loss: 1.0656 - val_acc: 0.4494\n",
            "Epoch 7/100 - 0.11s - loss: 1.0507 - acc: 0.4701 - val_loss: 1.0630 - val_acc: 0.4676\n",
            "Epoch 8/100 - 0.11s - loss: 1.0464 - acc: 0.4719 - val_loss: 1.0608 - val_acc: 0.4717\n",
            "Epoch 9/100 - 0.11s - loss: 1.0428 - acc: 0.4705 - val_loss: 1.0590 - val_acc: 0.4717\n",
            "Epoch 10/100 - 0.11s - loss: 1.0388 - acc: 0.4773 - val_loss: 1.0556 - val_acc: 0.4636\n",
            "Epoch 11/100 - 0.11s - loss: 1.0367 - acc: 0.4762 - val_loss: 1.0562 - val_acc: 0.4575\n",
            "Epoch 12/100 - 0.13s - loss: 1.0320 - acc: 0.4849 - val_loss: 1.0501 - val_acc: 0.4858\n",
            "Epoch 13/100 - 0.18s - loss: 1.0284 - acc: 0.4897 - val_loss: 1.0495 - val_acc: 0.4656\n",
            "Epoch 14/100 - 0.13s - loss: 1.0239 - acc: 0.4991 - val_loss: 1.0456 - val_acc: 0.4939\n",
            "Epoch 15/100 - 0.11s - loss: 1.0204 - acc: 0.5002 - val_loss: 1.0427 - val_acc: 0.4879\n",
            "Epoch 16/100 - 0.12s - loss: 1.0170 - acc: 0.5029 - val_loss: 1.0401 - val_acc: 0.4899\n",
            "Epoch 17/100 - 0.11s - loss: 1.0147 - acc: 0.5063 - val_loss: 1.0407 - val_acc: 0.4798\n",
            "Epoch 18/100 - 0.11s - loss: 1.0112 - acc: 0.5085 - val_loss: 1.0375 - val_acc: 0.4717\n",
            "Epoch 19/100 - 0.11s - loss: 1.0067 - acc: 0.5101 - val_loss: 1.0329 - val_acc: 0.4858\n",
            "Epoch 20/100 - 0.11s - loss: 1.0047 - acc: 0.5171 - val_loss: 1.0321 - val_acc: 0.5040\n",
            "Epoch 21/100 - 0.14s - loss: 1.0005 - acc: 0.5193 - val_loss: 1.0295 - val_acc: 0.5061\n",
            "Epoch 22/100 - 0.14s - loss: 0.9969 - acc: 0.5209 - val_loss: 1.0257 - val_acc: 0.5121\n",
            "Epoch 23/100 - 0.13s - loss: 0.9930 - acc: 0.5229 - val_loss: 1.0227 - val_acc: 0.5081\n",
            "Epoch 24/100 - 0.14s - loss: 0.9911 - acc: 0.5216 - val_loss: 1.0201 - val_acc: 0.5162\n",
            "Epoch 25/100 - 0.13s - loss: 0.9866 - acc: 0.5297 - val_loss: 1.0175 - val_acc: 0.5142\n",
            "Epoch 26/100 - 0.11s - loss: 0.9863 - acc: 0.5241 - val_loss: 1.0170 - val_acc: 0.5182\n",
            "Epoch 27/100 - 0.11s - loss: 0.9840 - acc: 0.5241 - val_loss: 1.0137 - val_acc: 0.5162\n",
            "Epoch 28/100 - 0.11s - loss: 0.9773 - acc: 0.5337 - val_loss: 1.0101 - val_acc: 0.5243\n",
            "Epoch 29/100 - 0.10s - loss: 0.9769 - acc: 0.5353 - val_loss: 1.0121 - val_acc: 0.5061\n",
            "Epoch 30/100 - 0.12s - loss: 0.9737 - acc: 0.5380 - val_loss: 1.0089 - val_acc: 0.5061\n",
            "Epoch 31/100 - 0.10s - loss: 0.9696 - acc: 0.5430 - val_loss: 1.0026 - val_acc: 0.5243\n",
            "Epoch 32/100 - 0.11s - loss: 0.9735 - acc: 0.5281 - val_loss: 1.0104 - val_acc: 0.4960\n",
            "Epoch 33/100 - 0.11s - loss: 0.9643 - acc: 0.5454 - val_loss: 1.0009 - val_acc: 0.5142\n",
            "Epoch 34/100 - 0.11s - loss: 0.9641 - acc: 0.5423 - val_loss: 0.9993 - val_acc: 0.5385\n",
            "Epoch 35/100 - 0.10s - loss: 0.9643 - acc: 0.5351 - val_loss: 1.0014 - val_acc: 0.5020\n",
            "Epoch 36/100 - 0.11s - loss: 0.9594 - acc: 0.5466 - val_loss: 0.9979 - val_acc: 0.5061\n",
            "Epoch 37/100 - 0.10s - loss: 0.9562 - acc: 0.5463 - val_loss: 0.9961 - val_acc: 0.5263\n",
            "Epoch 38/100 - 0.11s - loss: 0.9519 - acc: 0.5466 - val_loss: 0.9895 - val_acc: 0.5344\n",
            "Epoch 39/100 - 0.11s - loss: 0.9512 - acc: 0.5481 - val_loss: 0.9895 - val_acc: 0.5283\n",
            "Epoch 40/100 - 0.10s - loss: 0.9511 - acc: 0.5508 - val_loss: 0.9884 - val_acc: 0.5486\n",
            "Epoch 41/100 - 0.11s - loss: 0.9451 - acc: 0.5515 - val_loss: 0.9852 - val_acc: 0.5304\n",
            "Epoch 42/100 - 0.11s - loss: 0.9435 - acc: 0.5576 - val_loss: 0.9851 - val_acc: 0.5364\n",
            "Epoch 43/100 - 0.11s - loss: 0.9432 - acc: 0.5585 - val_loss: 0.9865 - val_acc: 0.5304\n",
            "Epoch 44/100 - 0.11s - loss: 0.9393 - acc: 0.5571 - val_loss: 0.9808 - val_acc: 0.5466\n",
            "Epoch 45/100 - 0.11s - loss: 0.9398 - acc: 0.5574 - val_loss: 0.9845 - val_acc: 0.5243\n",
            "Epoch 46/100 - 0.11s - loss: 0.9407 - acc: 0.5565 - val_loss: 0.9869 - val_acc: 0.5081\n",
            "Epoch 47/100 - 0.11s - loss: 0.9453 - acc: 0.5439 - val_loss: 0.9891 - val_acc: 0.5061\n",
            "Epoch 48/100 - 0.11s - loss: 0.9352 - acc: 0.5634 - val_loss: 0.9785 - val_acc: 0.5506\n",
            "Epoch 49/100 - 0.12s - loss: 0.9310 - acc: 0.5655 - val_loss: 0.9748 - val_acc: 0.5587\n",
            "Epoch 50/100 - 0.10s - loss: 0.9320 - acc: 0.5652 - val_loss: 0.9755 - val_acc: 0.5547\n",
            "Epoch 51/100 - 0.11s - loss: 0.9314 - acc: 0.5565 - val_loss: 0.9747 - val_acc: 0.5405\n",
            "Epoch 52/100 - 0.11s - loss: 0.9286 - acc: 0.5664 - val_loss: 0.9756 - val_acc: 0.5668\n",
            "Epoch 53/100 - 0.11s - loss: 0.9270 - acc: 0.5634 - val_loss: 0.9760 - val_acc: 0.5162\n",
            "Epoch 54/100 - 0.10s - loss: 0.9349 - acc: 0.5506 - val_loss: 0.9871 - val_acc: 0.5040\n",
            "Epoch 55/100 - 0.11s - loss: 0.9333 - acc: 0.5675 - val_loss: 0.9813 - val_acc: 0.5385\n",
            "Epoch 56/100 - 0.11s - loss: 0.9223 - acc: 0.5641 - val_loss: 0.9756 - val_acc: 0.5263\n",
            "Epoch 57/100 - 0.13s - loss: 0.9190 - acc: 0.5684 - val_loss: 0.9717 - val_acc: 0.5324\n",
            "Epoch 58/100 - 0.11s - loss: 0.9195 - acc: 0.5670 - val_loss: 0.9742 - val_acc: 0.5243\n",
            "Epoch 59/100 - 0.10s - loss: 0.9164 - acc: 0.5731 - val_loss: 0.9710 - val_acc: 0.5364\n",
            "Epoch 60/100 - 0.12s - loss: 0.9258 - acc: 0.5648 - val_loss: 0.9737 - val_acc: 0.5587\n",
            "Epoch 61/100 - 0.12s - loss: 0.9120 - acc: 0.5789 - val_loss: 0.9651 - val_acc: 0.5688\n",
            "Epoch 62/100 - 0.11s - loss: 0.9103 - acc: 0.5747 - val_loss: 0.9650 - val_acc: 0.5445\n",
            "Epoch 63/100 - 0.11s - loss: 0.9222 - acc: 0.5585 - val_loss: 0.9802 - val_acc: 0.5182\n",
            "Epoch 64/100 - 0.11s - loss: 0.9169 - acc: 0.5769 - val_loss: 0.9697 - val_acc: 0.5628\n",
            "Epoch 65/100 - 0.13s - loss: 0.9180 - acc: 0.5596 - val_loss: 0.9815 - val_acc: 0.4960\n",
            "Epoch 66/100 - 0.12s - loss: 0.9056 - acc: 0.5753 - val_loss: 0.9645 - val_acc: 0.5324\n",
            "Epoch 67/100 - 0.10s - loss: 0.9036 - acc: 0.5821 - val_loss: 0.9640 - val_acc: 0.5486\n",
            "Epoch 68/100 - 0.11s - loss: 0.9018 - acc: 0.5780 - val_loss: 0.9606 - val_acc: 0.5607\n",
            "Epoch 69/100 - 0.12s - loss: 0.9033 - acc: 0.5796 - val_loss: 0.9668 - val_acc: 0.5344\n",
            "Epoch 70/100 - 0.11s - loss: 0.9030 - acc: 0.5843 - val_loss: 0.9660 - val_acc: 0.5364\n",
            "Epoch 71/100 - 0.11s - loss: 0.9024 - acc: 0.5780 - val_loss: 0.9686 - val_acc: 0.5263\n",
            "Epoch 72/100 - 0.12s - loss: 0.9150 - acc: 0.5610 - val_loss: 0.9853 - val_acc: 0.4899\n",
            "Epoch 73/100 - 0.12s - loss: 0.9040 - acc: 0.5700 - val_loss: 0.9632 - val_acc: 0.5385\n",
            "Epoch 74/100 - 0.12s - loss: 0.9054 - acc: 0.5828 - val_loss: 0.9642 - val_acc: 0.5526\n",
            "Epoch 75/100 - 0.12s - loss: 0.9261 - acc: 0.5529 - val_loss: 0.9993 - val_acc: 0.5061\n",
            "Epoch 76/100 - 0.12s - loss: 0.9051 - acc: 0.5700 - val_loss: 0.9779 - val_acc: 0.4939\n",
            "Epoch 77/100 - 0.12s - loss: 0.8956 - acc: 0.5798 - val_loss: 0.9637 - val_acc: 0.5283\n",
            "Epoch 78/100 - 0.14s - loss: 0.8927 - acc: 0.5834 - val_loss: 0.9579 - val_acc: 0.5628\n",
            "Epoch 79/100 - 0.11s - loss: 0.8918 - acc: 0.5843 - val_loss: 0.9594 - val_acc: 0.5243\n",
            "Epoch 80/100 - 0.11s - loss: 0.8981 - acc: 0.5774 - val_loss: 0.9629 - val_acc: 0.5466\n",
            "Epoch 81/100 - 0.11s - loss: 0.9095 - acc: 0.5616 - val_loss: 0.9849 - val_acc: 0.5182\n",
            "Epoch 82/100 - 0.12s - loss: 0.8908 - acc: 0.5832 - val_loss: 0.9670 - val_acc: 0.5243\n",
            "Epoch 83/100 - 0.11s - loss: 0.8919 - acc: 0.5834 - val_loss: 0.9691 - val_acc: 0.5101\n",
            "Epoch 84/100 - 0.11s - loss: 0.8997 - acc: 0.5861 - val_loss: 0.9718 - val_acc: 0.5466\n",
            "Epoch 85/100 - 0.11s - loss: 0.8896 - acc: 0.5915 - val_loss: 0.9588 - val_acc: 0.5567\n",
            "Epoch 86/100 - 0.12s - loss: 0.8924 - acc: 0.5951 - val_loss: 0.9635 - val_acc: 0.5668\n",
            "Epoch 87/100 - 0.11s - loss: 0.8879 - acc: 0.5846 - val_loss: 0.9615 - val_acc: 0.5202\n",
            "Epoch 88/100 - 0.11s - loss: 0.8940 - acc: 0.5891 - val_loss: 0.9656 - val_acc: 0.5567\n",
            "Epoch 89/100 - 0.10s - loss: 0.8882 - acc: 0.5927 - val_loss: 0.9607 - val_acc: 0.5526\n",
            "Epoch 90/100 - 0.12s - loss: 0.8931 - acc: 0.5789 - val_loss: 0.9720 - val_acc: 0.5121\n",
            "Epoch 91/100 - 0.12s - loss: 0.8789 - acc: 0.5969 - val_loss: 0.9563 - val_acc: 0.5567\n",
            "Epoch 92/100 - 0.12s - loss: 0.8902 - acc: 0.5913 - val_loss: 0.9642 - val_acc: 0.5648\n",
            "Epoch 93/100 - 0.14s - loss: 0.9150 - acc: 0.5547 - val_loss: 1.0038 - val_acc: 0.5040\n",
            "Epoch 94/100 - 0.11s - loss: 0.8752 - acc: 0.6005 - val_loss: 0.9558 - val_acc: 0.5506\n",
            "Epoch 95/100 - 0.12s - loss: 0.8756 - acc: 0.5942 - val_loss: 0.9611 - val_acc: 0.5324\n",
            "Epoch 96/100 - 0.12s - loss: 0.8765 - acc: 0.5920 - val_loss: 0.9637 - val_acc: 0.5283\n",
            "Epoch 97/100 - 0.11s - loss: 0.8753 - acc: 0.5947 - val_loss: 0.9578 - val_acc: 0.5506\n",
            "Epoch 98/100 - 0.12s - loss: 0.8722 - acc: 0.5994 - val_loss: 0.9576 - val_acc: 0.5466\n",
            "Epoch 99/100 - 0.11s - loss: 0.8813 - acc: 0.5938 - val_loss: 0.9621 - val_acc: 0.5607\n",
            "Epoch 100/100 - 0.12s - loss: 0.8783 - acc: 0.5902 - val_loss: 0.9613 - val_acc: 0.5405\n",
            "\n",
            "Combination 96/252:\n",
            "Hidden Layers: [128, 128], Activation: tanh, Learning Rate: 0.01, Batch Size: 64, Epochs: 150\n",
            "Epoch 1/150 - 0.10s - loss: 1.0915 - acc: 0.3695 - val_loss: 1.0982 - val_acc: 0.3502\n",
            "Epoch 2/150 - 0.11s - loss: 1.0814 - acc: 0.3950 - val_loss: 1.0905 - val_acc: 0.3785\n",
            "Epoch 3/150 - 0.10s - loss: 1.0731 - acc: 0.4435 - val_loss: 1.0832 - val_acc: 0.4312\n",
            "Epoch 4/150 - 0.12s - loss: 1.0672 - acc: 0.4352 - val_loss: 1.0795 - val_acc: 0.4251\n",
            "Epoch 5/150 - 0.11s - loss: 1.0605 - acc: 0.4665 - val_loss: 1.0733 - val_acc: 0.4211\n",
            "Epoch 6/150 - 0.11s - loss: 1.0554 - acc: 0.4699 - val_loss: 1.0690 - val_acc: 0.4251\n",
            "Epoch 7/150 - 0.12s - loss: 1.0520 - acc: 0.4640 - val_loss: 1.0688 - val_acc: 0.4352\n",
            "Epoch 8/150 - 0.11s - loss: 1.0462 - acc: 0.4746 - val_loss: 1.0626 - val_acc: 0.4413\n",
            "Epoch 9/150 - 0.10s - loss: 1.0423 - acc: 0.4753 - val_loss: 1.0596 - val_acc: 0.4372\n",
            "Epoch 10/150 - 0.11s - loss: 1.0379 - acc: 0.4840 - val_loss: 1.0578 - val_acc: 0.4575\n",
            "Epoch 11/150 - 0.11s - loss: 1.0347 - acc: 0.4881 - val_loss: 1.0561 - val_acc: 0.4555\n",
            "Epoch 12/150 - 0.11s - loss: 1.0302 - acc: 0.4921 - val_loss: 1.0515 - val_acc: 0.4696\n",
            "Epoch 13/150 - 0.11s - loss: 1.0267 - acc: 0.4962 - val_loss: 1.0505 - val_acc: 0.4555\n",
            "Epoch 14/150 - 0.11s - loss: 1.0235 - acc: 0.4978 - val_loss: 1.0477 - val_acc: 0.4858\n",
            "Epoch 15/150 - 0.11s - loss: 1.0192 - acc: 0.5034 - val_loss: 1.0441 - val_acc: 0.4757\n",
            "Epoch 16/150 - 0.11s - loss: 1.0159 - acc: 0.5031 - val_loss: 1.0418 - val_acc: 0.4757\n",
            "Epoch 17/150 - 0.11s - loss: 1.0124 - acc: 0.5110 - val_loss: 1.0395 - val_acc: 0.4919\n",
            "Epoch 18/150 - 0.11s - loss: 1.0099 - acc: 0.5045 - val_loss: 1.0383 - val_acc: 0.4879\n",
            "Epoch 19/150 - 0.11s - loss: 1.0064 - acc: 0.5083 - val_loss: 1.0348 - val_acc: 0.4777\n",
            "Epoch 20/150 - 0.11s - loss: 1.0028 - acc: 0.5178 - val_loss: 1.0327 - val_acc: 0.4960\n",
            "Epoch 21/150 - 0.11s - loss: 0.9992 - acc: 0.5184 - val_loss: 1.0295 - val_acc: 0.5101\n",
            "Epoch 22/150 - 0.11s - loss: 0.9964 - acc: 0.5175 - val_loss: 1.0279 - val_acc: 0.4980\n",
            "Epoch 23/150 - 0.11s - loss: 0.9933 - acc: 0.5232 - val_loss: 1.0247 - val_acc: 0.5142\n",
            "Epoch 24/150 - 0.11s - loss: 0.9906 - acc: 0.5211 - val_loss: 1.0236 - val_acc: 0.5061\n",
            "Epoch 25/150 - 0.10s - loss: 0.9883 - acc: 0.5223 - val_loss: 1.0213 - val_acc: 0.5020\n",
            "Epoch 26/150 - 0.11s - loss: 0.9847 - acc: 0.5243 - val_loss: 1.0177 - val_acc: 0.5121\n",
            "Epoch 27/150 - 0.11s - loss: 0.9825 - acc: 0.5281 - val_loss: 1.0165 - val_acc: 0.5040\n",
            "Epoch 28/150 - 0.11s - loss: 0.9842 - acc: 0.5227 - val_loss: 1.0159 - val_acc: 0.5182\n",
            "Epoch 29/150 - 0.11s - loss: 0.9828 - acc: 0.5209 - val_loss: 1.0193 - val_acc: 0.4980\n",
            "Epoch 30/150 - 0.11s - loss: 0.9772 - acc: 0.5308 - val_loss: 1.0106 - val_acc: 0.5304\n",
            "Epoch 31/150 - 0.10s - loss: 0.9770 - acc: 0.5259 - val_loss: 1.0116 - val_acc: 0.4980\n",
            "Epoch 32/150 - 0.11s - loss: 0.9711 - acc: 0.5398 - val_loss: 1.0078 - val_acc: 0.5101\n",
            "Epoch 33/150 - 0.11s - loss: 0.9702 - acc: 0.5360 - val_loss: 1.0041 - val_acc: 0.5101\n",
            "Epoch 34/150 - 0.10s - loss: 0.9655 - acc: 0.5425 - val_loss: 1.0022 - val_acc: 0.5304\n",
            "Epoch 35/150 - 0.12s - loss: 0.9646 - acc: 0.5416 - val_loss: 1.0003 - val_acc: 0.5445\n",
            "Epoch 36/150 - 0.11s - loss: 0.9620 - acc: 0.5389 - val_loss: 0.9987 - val_acc: 0.5283\n",
            "Epoch 37/150 - 0.11s - loss: 0.9591 - acc: 0.5463 - val_loss: 0.9961 - val_acc: 0.5344\n",
            "Epoch 38/150 - 0.11s - loss: 0.9576 - acc: 0.5445 - val_loss: 0.9955 - val_acc: 0.5243\n",
            "Epoch 39/150 - 0.12s - loss: 0.9552 - acc: 0.5463 - val_loss: 0.9930 - val_acc: 0.5344\n",
            "Epoch 40/150 - 0.11s - loss: 0.9540 - acc: 0.5511 - val_loss: 0.9923 - val_acc: 0.5405\n",
            "Epoch 41/150 - 0.11s - loss: 0.9535 - acc: 0.5448 - val_loss: 0.9904 - val_acc: 0.5364\n",
            "Epoch 42/150 - 0.10s - loss: 0.9509 - acc: 0.5515 - val_loss: 0.9890 - val_acc: 0.5506\n",
            "Epoch 43/150 - 0.11s - loss: 0.9495 - acc: 0.5454 - val_loss: 0.9879 - val_acc: 0.5324\n",
            "Epoch 44/150 - 0.11s - loss: 0.9514 - acc: 0.5472 - val_loss: 0.9897 - val_acc: 0.5567\n",
            "Epoch 45/150 - 0.13s - loss: 0.9468 - acc: 0.5531 - val_loss: 0.9888 - val_acc: 0.5223\n",
            "Epoch 46/150 - 0.11s - loss: 0.9455 - acc: 0.5481 - val_loss: 0.9843 - val_acc: 0.5344\n",
            "Epoch 47/150 - 0.11s - loss: 0.9422 - acc: 0.5549 - val_loss: 0.9824 - val_acc: 0.5547\n",
            "Epoch 48/150 - 0.11s - loss: 0.9395 - acc: 0.5578 - val_loss: 0.9804 - val_acc: 0.5405\n",
            "Epoch 49/150 - 0.11s - loss: 0.9467 - acc: 0.5565 - val_loss: 0.9889 - val_acc: 0.5364\n",
            "Epoch 50/150 - 0.11s - loss: 0.9408 - acc: 0.5594 - val_loss: 0.9831 - val_acc: 0.5385\n",
            "Epoch 51/150 - 0.11s - loss: 0.9384 - acc: 0.5569 - val_loss: 0.9793 - val_acc: 0.5648\n",
            "Epoch 52/150 - 0.10s - loss: 0.9334 - acc: 0.5623 - val_loss: 0.9763 - val_acc: 0.5486\n",
            "Epoch 53/150 - 0.11s - loss: 0.9327 - acc: 0.5648 - val_loss: 0.9762 - val_acc: 0.5364\n",
            "Epoch 54/150 - 0.11s - loss: 0.9328 - acc: 0.5625 - val_loss: 0.9787 - val_acc: 0.5405\n",
            "Epoch 55/150 - 0.11s - loss: 0.9296 - acc: 0.5585 - val_loss: 0.9731 - val_acc: 0.5445\n",
            "Epoch 56/150 - 0.11s - loss: 0.9297 - acc: 0.5623 - val_loss: 0.9766 - val_acc: 0.5405\n",
            "Epoch 57/150 - 0.11s - loss: 0.9259 - acc: 0.5601 - val_loss: 0.9724 - val_acc: 0.5445\n",
            "Epoch 58/150 - 0.11s - loss: 0.9253 - acc: 0.5673 - val_loss: 0.9728 - val_acc: 0.5263\n",
            "Epoch 59/150 - 0.11s - loss: 0.9230 - acc: 0.5704 - val_loss: 0.9698 - val_acc: 0.5364\n",
            "Epoch 60/150 - 0.10s - loss: 0.9225 - acc: 0.5670 - val_loss: 0.9704 - val_acc: 0.5344\n",
            "Epoch 61/150 - 0.12s - loss: 0.9212 - acc: 0.5691 - val_loss: 0.9706 - val_acc: 0.5283\n",
            "Epoch 62/150 - 0.11s - loss: 0.9192 - acc: 0.5711 - val_loss: 0.9690 - val_acc: 0.5364\n",
            "Epoch 63/150 - 0.11s - loss: 0.9196 - acc: 0.5616 - val_loss: 0.9693 - val_acc: 0.5364\n",
            "Epoch 64/150 - 0.10s - loss: 0.9234 - acc: 0.5637 - val_loss: 0.9760 - val_acc: 0.5182\n",
            "Epoch 65/150 - 0.11s - loss: 0.9203 - acc: 0.5726 - val_loss: 0.9689 - val_acc: 0.5607\n",
            "Epoch 66/150 - 0.11s - loss: 0.9198 - acc: 0.5634 - val_loss: 0.9720 - val_acc: 0.5425\n",
            "Epoch 67/150 - 0.11s - loss: 0.9209 - acc: 0.5724 - val_loss: 0.9701 - val_acc: 0.5668\n",
            "Epoch 68/150 - 0.11s - loss: 0.9122 - acc: 0.5702 - val_loss: 0.9638 - val_acc: 0.5385\n",
            "Epoch 69/150 - 0.11s - loss: 0.9240 - acc: 0.5789 - val_loss: 0.9746 - val_acc: 0.5466\n",
            "Epoch 70/150 - 0.11s - loss: 0.9088 - acc: 0.5789 - val_loss: 0.9632 - val_acc: 0.5385\n",
            "Epoch 71/150 - 0.11s - loss: 0.9118 - acc: 0.5722 - val_loss: 0.9695 - val_acc: 0.5263\n",
            "Epoch 72/150 - 0.11s - loss: 0.9111 - acc: 0.5693 - val_loss: 0.9684 - val_acc: 0.5344\n",
            "Epoch 73/150 - 0.11s - loss: 0.9147 - acc: 0.5648 - val_loss: 0.9760 - val_acc: 0.5081\n",
            "Epoch 74/150 - 0.11s - loss: 0.9052 - acc: 0.5774 - val_loss: 0.9642 - val_acc: 0.5243\n",
            "Epoch 75/150 - 0.12s - loss: 0.9036 - acc: 0.5830 - val_loss: 0.9629 - val_acc: 0.5466\n",
            "Epoch 76/150 - 0.11s - loss: 0.9038 - acc: 0.5816 - val_loss: 0.9611 - val_acc: 0.5526\n",
            "Epoch 77/150 - 0.11s - loss: 0.9071 - acc: 0.5747 - val_loss: 0.9634 - val_acc: 0.5445\n",
            "Epoch 78/150 - 0.11s - loss: 0.9070 - acc: 0.5706 - val_loss: 0.9701 - val_acc: 0.5243\n",
            "Epoch 79/150 - 0.11s - loss: 0.8987 - acc: 0.5828 - val_loss: 0.9591 - val_acc: 0.5587\n",
            "Epoch 80/150 - 0.11s - loss: 0.9091 - acc: 0.5688 - val_loss: 0.9717 - val_acc: 0.5243\n",
            "Epoch 81/150 - 0.11s - loss: 0.9002 - acc: 0.5762 - val_loss: 0.9644 - val_acc: 0.5202\n",
            "Epoch 82/150 - 0.11s - loss: 0.9084 - acc: 0.5682 - val_loss: 0.9752 - val_acc: 0.5202\n",
            "Epoch 83/150 - 0.11s - loss: 0.9031 - acc: 0.5724 - val_loss: 0.9704 - val_acc: 0.5182\n",
            "Epoch 84/150 - 0.11s - loss: 0.8944 - acc: 0.5823 - val_loss: 0.9576 - val_acc: 0.5445\n",
            "Epoch 85/150 - 0.11s - loss: 0.9055 - acc: 0.5830 - val_loss: 0.9675 - val_acc: 0.5587\n",
            "Epoch 86/150 - 0.12s - loss: 0.8956 - acc: 0.5906 - val_loss: 0.9645 - val_acc: 0.5324\n",
            "Epoch 87/150 - 0.11s - loss: 0.8908 - acc: 0.5852 - val_loss: 0.9590 - val_acc: 0.5344\n",
            "Epoch 88/150 - 0.12s - loss: 0.8909 - acc: 0.5868 - val_loss: 0.9585 - val_acc: 0.5567\n",
            "Epoch 89/150 - 0.13s - loss: 0.8969 - acc: 0.5769 - val_loss: 0.9642 - val_acc: 0.5324\n",
            "Epoch 90/150 - 0.12s - loss: 0.8921 - acc: 0.5940 - val_loss: 0.9639 - val_acc: 0.5445\n",
            "Epoch 91/150 - 0.12s - loss: 0.9006 - acc: 0.5702 - val_loss: 0.9740 - val_acc: 0.5263\n",
            "Epoch 92/150 - 0.11s - loss: 0.8861 - acc: 0.5877 - val_loss: 0.9561 - val_acc: 0.5445\n",
            "Epoch 93/150 - 0.10s - loss: 0.8968 - acc: 0.5846 - val_loss: 0.9648 - val_acc: 0.5628\n",
            "Epoch 94/150 - 0.11s - loss: 0.8893 - acc: 0.5821 - val_loss: 0.9585 - val_acc: 0.5445\n",
            "Epoch 95/150 - 0.10s - loss: 0.8851 - acc: 0.5891 - val_loss: 0.9593 - val_acc: 0.5364\n",
            "Epoch 96/150 - 0.10s - loss: 0.8912 - acc: 0.5841 - val_loss: 0.9695 - val_acc: 0.5182\n",
            "Epoch 97/150 - 0.10s - loss: 0.9060 - acc: 0.5778 - val_loss: 0.9736 - val_acc: 0.5547\n",
            "Epoch 98/150 - 0.10s - loss: 0.8970 - acc: 0.5884 - val_loss: 0.9703 - val_acc: 0.5526\n",
            "Epoch 99/150 - 0.10s - loss: 0.8797 - acc: 0.5936 - val_loss: 0.9565 - val_acc: 0.5405\n",
            "Epoch 100/150 - 0.10s - loss: 0.9059 - acc: 0.5556 - val_loss: 0.9758 - val_acc: 0.5202\n",
            "Epoch 101/150 - 0.10s - loss: 0.8814 - acc: 0.6010 - val_loss: 0.9614 - val_acc: 0.5445\n",
            "Epoch 102/150 - 0.11s - loss: 0.8791 - acc: 0.5942 - val_loss: 0.9556 - val_acc: 0.5526\n",
            "Epoch 103/150 - 0.10s - loss: 0.8777 - acc: 0.5983 - val_loss: 0.9578 - val_acc: 0.5567\n",
            "Epoch 104/150 - 0.10s - loss: 0.9056 - acc: 0.5664 - val_loss: 0.9873 - val_acc: 0.5081\n",
            "Epoch 105/150 - 0.10s - loss: 0.9033 - acc: 0.5780 - val_loss: 0.9771 - val_acc: 0.5567\n",
            "Epoch 106/150 - 0.10s - loss: 0.8968 - acc: 0.5666 - val_loss: 0.9717 - val_acc: 0.5385\n",
            "Epoch 107/150 - 0.10s - loss: 0.8758 - acc: 0.5929 - val_loss: 0.9569 - val_acc: 0.5547\n",
            "Epoch 108/150 - 0.10s - loss: 0.9161 - acc: 0.5592 - val_loss: 1.0068 - val_acc: 0.5101\n",
            "Epoch 109/150 - 0.10s - loss: 0.8759 - acc: 0.5965 - val_loss: 0.9643 - val_acc: 0.5364\n",
            "Epoch 110/150 - 0.10s - loss: 0.8723 - acc: 0.5956 - val_loss: 0.9581 - val_acc: 0.5466\n",
            "Epoch 111/150 - 0.11s - loss: 0.8862 - acc: 0.5895 - val_loss: 0.9762 - val_acc: 0.5162\n",
            "Epoch 112/150 - 0.10s - loss: 0.8851 - acc: 0.5877 - val_loss: 0.9793 - val_acc: 0.5202\n",
            "Epoch 113/150 - 0.10s - loss: 0.8733 - acc: 0.5976 - val_loss: 0.9576 - val_acc: 0.5607\n",
            "Epoch 114/150 - 0.11s - loss: 0.8713 - acc: 0.6071 - val_loss: 0.9610 - val_acc: 0.5466\n",
            "Epoch 115/150 - 0.10s - loss: 0.8693 - acc: 0.5963 - val_loss: 0.9592 - val_acc: 0.5324\n",
            "Epoch 116/150 - 0.10s - loss: 0.8687 - acc: 0.6041 - val_loss: 0.9576 - val_acc: 0.5526\n",
            "Epoch 117/150 - 0.10s - loss: 0.8718 - acc: 0.5933 - val_loss: 0.9649 - val_acc: 0.5283\n",
            "Epoch 118/150 - 0.10s - loss: 0.8686 - acc: 0.5974 - val_loss: 0.9608 - val_acc: 0.5283\n",
            "Epoch 119/150 - 0.10s - loss: 0.8670 - acc: 0.5985 - val_loss: 0.9577 - val_acc: 0.5486\n",
            "Epoch 120/150 - 0.11s - loss: 0.8670 - acc: 0.6021 - val_loss: 0.9633 - val_acc: 0.5324\n",
            "Epoch 121/150 - 0.10s - loss: 0.8741 - acc: 0.6028 - val_loss: 0.9698 - val_acc: 0.5405\n",
            "Epoch 122/150 - 0.10s - loss: 0.8647 - acc: 0.6062 - val_loss: 0.9602 - val_acc: 0.5547\n",
            "Epoch 123/150 - 0.12s - loss: 0.9435 - acc: 0.5490 - val_loss: 1.0245 - val_acc: 0.5202\n",
            "Epoch 124/150 - 0.10s - loss: 0.8648 - acc: 0.6066 - val_loss: 0.9606 - val_acc: 0.5547\n",
            "Epoch 125/150 - 0.10s - loss: 0.8757 - acc: 0.6005 - val_loss: 0.9720 - val_acc: 0.5547\n",
            "Epoch 126/150 - 0.11s - loss: 0.8802 - acc: 0.5852 - val_loss: 0.9820 - val_acc: 0.5081\n",
            "Epoch 127/150 - 0.10s - loss: 0.8649 - acc: 0.6084 - val_loss: 0.9645 - val_acc: 0.5364\n",
            "Epoch 128/150 - 0.10s - loss: 0.8614 - acc: 0.6041 - val_loss: 0.9631 - val_acc: 0.5304\n",
            "Epoch 129/150 - 0.11s - loss: 0.8646 - acc: 0.6084 - val_loss: 0.9651 - val_acc: 0.5425\n",
            "Epoch 130/150 - 0.10s - loss: 0.8653 - acc: 0.6068 - val_loss: 0.9645 - val_acc: 0.5466\n",
            "Epoch 131/150 - 0.10s - loss: 0.8805 - acc: 0.5960 - val_loss: 0.9912 - val_acc: 0.5121\n",
            "Epoch 132/150 - 0.11s - loss: 0.8584 - acc: 0.6066 - val_loss: 0.9609 - val_acc: 0.5506\n",
            "Epoch 133/150 - 0.10s - loss: 0.8861 - acc: 0.5915 - val_loss: 0.9801 - val_acc: 0.5526\n",
            "Epoch 134/150 - 0.10s - loss: 0.8964 - acc: 0.5724 - val_loss: 0.9944 - val_acc: 0.5202\n",
            "Epoch 135/150 - 0.11s - loss: 0.8801 - acc: 0.5949 - val_loss: 0.9880 - val_acc: 0.5182\n",
            "Epoch 136/150 - 0.10s - loss: 0.8608 - acc: 0.6093 - val_loss: 0.9639 - val_acc: 0.5506\n",
            "Epoch 137/150 - 0.10s - loss: 0.8620 - acc: 0.5994 - val_loss: 0.9645 - val_acc: 0.5587\n",
            "Epoch 138/150 - 0.11s - loss: 0.8602 - acc: 0.6035 - val_loss: 0.9721 - val_acc: 0.5324\n",
            "Epoch 139/150 - 0.10s - loss: 0.8605 - acc: 0.6098 - val_loss: 0.9656 - val_acc: 0.5587\n",
            "Epoch 140/150 - 0.10s - loss: 0.8726 - acc: 0.5992 - val_loss: 0.9888 - val_acc: 0.5182\n",
            "Epoch 141/150 - 0.12s - loss: 0.8573 - acc: 0.6113 - val_loss: 0.9659 - val_acc: 0.5486\n",
            "Epoch 142/150 - 0.10s - loss: 0.8673 - acc: 0.5996 - val_loss: 0.9836 - val_acc: 0.5263\n",
            "Epoch 143/150 - 0.10s - loss: 0.8562 - acc: 0.6064 - val_loss: 0.9704 - val_acc: 0.5263\n",
            "Epoch 144/150 - 0.11s - loss: 0.8605 - acc: 0.6111 - val_loss: 0.9692 - val_acc: 0.5668\n",
            "Epoch 145/150 - 0.10s - loss: 0.8639 - acc: 0.6062 - val_loss: 0.9691 - val_acc: 0.5587\n",
            "Epoch 146/150 - 0.10s - loss: 0.8634 - acc: 0.6030 - val_loss: 0.9800 - val_acc: 0.5324\n",
            "Epoch 147/150 - 0.11s - loss: 0.8637 - acc: 0.5969 - val_loss: 0.9728 - val_acc: 0.5344\n",
            "Epoch 148/150 - 0.10s - loss: 0.8598 - acc: 0.6026 - val_loss: 0.9672 - val_acc: 0.5567\n",
            "Epoch 149/150 - 0.10s - loss: 0.8708 - acc: 0.6037 - val_loss: 0.9855 - val_acc: 0.5364\n",
            "Epoch 150/150 - 0.11s - loss: 0.8944 - acc: 0.5792 - val_loss: 1.0105 - val_acc: 0.5182\n",
            "\n",
            "Combination 97/252:\n",
            "Hidden Layers: [128, 128], Activation: tanh, Learning Rate: 0.001, Batch Size: 32, Epochs: 50\n",
            "Epoch 1/50 - 0.12s - loss: 1.1053 - acc: 0.3171 - val_loss: 1.1028 - val_acc: 0.3300\n",
            "Epoch 2/50 - 0.13s - loss: 1.1005 - acc: 0.3329 - val_loss: 1.0998 - val_acc: 0.3320\n",
            "Epoch 3/50 - 0.13s - loss: 1.0978 - acc: 0.3482 - val_loss: 1.0981 - val_acc: 0.3320\n",
            "Epoch 4/50 - 0.13s - loss: 1.0955 - acc: 0.3578 - val_loss: 1.0965 - val_acc: 0.3462\n",
            "Epoch 5/50 - 0.12s - loss: 1.0933 - acc: 0.3718 - val_loss: 1.0947 - val_acc: 0.3441\n",
            "Epoch 6/50 - 0.12s - loss: 1.0913 - acc: 0.3853 - val_loss: 1.0931 - val_acc: 0.3644\n",
            "Epoch 7/50 - 0.12s - loss: 1.0894 - acc: 0.3927 - val_loss: 1.0914 - val_acc: 0.3745\n",
            "Epoch 8/50 - 0.13s - loss: 1.0876 - acc: 0.3983 - val_loss: 1.0901 - val_acc: 0.3806\n",
            "Epoch 9/50 - 0.14s - loss: 1.0859 - acc: 0.4089 - val_loss: 1.0887 - val_acc: 0.3806\n",
            "Epoch 10/50 - 0.13s - loss: 1.0842 - acc: 0.4022 - val_loss: 1.0877 - val_acc: 0.3907\n",
            "Epoch 11/50 - 0.12s - loss: 1.0826 - acc: 0.4112 - val_loss: 1.0863 - val_acc: 0.3947\n",
            "Epoch 12/50 - 0.13s - loss: 1.0811 - acc: 0.4166 - val_loss: 1.0852 - val_acc: 0.3968\n",
            "Epoch 13/50 - 0.12s - loss: 1.0797 - acc: 0.4159 - val_loss: 1.0841 - val_acc: 0.4008\n",
            "Epoch 14/50 - 0.12s - loss: 1.0783 - acc: 0.4175 - val_loss: 1.0831 - val_acc: 0.4089\n",
            "Epoch 15/50 - 0.13s - loss: 1.0769 - acc: 0.4242 - val_loss: 1.0821 - val_acc: 0.4109\n",
            "Epoch 16/50 - 0.15s - loss: 1.0756 - acc: 0.4321 - val_loss: 1.0810 - val_acc: 0.4089\n",
            "Epoch 17/50 - 0.14s - loss: 1.0744 - acc: 0.4330 - val_loss: 1.0801 - val_acc: 0.4069\n",
            "Epoch 18/50 - 0.14s - loss: 1.0731 - acc: 0.4352 - val_loss: 1.0792 - val_acc: 0.4089\n",
            "Epoch 19/50 - 0.12s - loss: 1.0720 - acc: 0.4343 - val_loss: 1.0785 - val_acc: 0.4049\n",
            "Epoch 20/50 - 0.13s - loss: 1.0708 - acc: 0.4395 - val_loss: 1.0776 - val_acc: 0.4130\n",
            "Epoch 21/50 - 0.12s - loss: 1.0697 - acc: 0.4372 - val_loss: 1.0770 - val_acc: 0.4049\n",
            "Epoch 22/50 - 0.13s - loss: 1.0686 - acc: 0.4465 - val_loss: 1.0759 - val_acc: 0.4211\n",
            "Epoch 23/50 - 0.12s - loss: 1.0675 - acc: 0.4465 - val_loss: 1.0750 - val_acc: 0.4271\n",
            "Epoch 24/50 - 0.13s - loss: 1.0665 - acc: 0.4489 - val_loss: 1.0744 - val_acc: 0.4231\n",
            "Epoch 25/50 - 0.13s - loss: 1.0655 - acc: 0.4492 - val_loss: 1.0737 - val_acc: 0.4251\n",
            "Epoch 26/50 - 0.13s - loss: 1.0645 - acc: 0.4494 - val_loss: 1.0729 - val_acc: 0.4271\n",
            "Epoch 27/50 - 0.13s - loss: 1.0635 - acc: 0.4487 - val_loss: 1.0722 - val_acc: 0.4231\n",
            "Epoch 28/50 - 0.14s - loss: 1.0625 - acc: 0.4505 - val_loss: 1.0716 - val_acc: 0.4312\n",
            "Epoch 29/50 - 0.13s - loss: 1.0616 - acc: 0.4530 - val_loss: 1.0709 - val_acc: 0.4312\n",
            "Epoch 30/50 - 0.13s - loss: 1.0607 - acc: 0.4525 - val_loss: 1.0705 - val_acc: 0.4312\n",
            "Epoch 31/50 - 0.12s - loss: 1.0598 - acc: 0.4539 - val_loss: 1.0696 - val_acc: 0.4312\n",
            "Epoch 32/50 - 0.13s - loss: 1.0589 - acc: 0.4546 - val_loss: 1.0692 - val_acc: 0.4291\n",
            "Epoch 33/50 - 0.12s - loss: 1.0580 - acc: 0.4561 - val_loss: 1.0686 - val_acc: 0.4332\n",
            "Epoch 34/50 - 0.13s - loss: 1.0572 - acc: 0.4570 - val_loss: 1.0679 - val_acc: 0.4352\n",
            "Epoch 35/50 - 0.14s - loss: 1.0563 - acc: 0.4577 - val_loss: 1.0671 - val_acc: 0.4393\n",
            "Epoch 36/50 - 0.14s - loss: 1.0555 - acc: 0.4597 - val_loss: 1.0667 - val_acc: 0.4393\n",
            "Epoch 37/50 - 0.12s - loss: 1.0547 - acc: 0.4622 - val_loss: 1.0662 - val_acc: 0.4393\n",
            "Epoch 38/50 - 0.13s - loss: 1.0539 - acc: 0.4611 - val_loss: 1.0654 - val_acc: 0.4453\n",
            "Epoch 39/50 - 0.12s - loss: 1.0531 - acc: 0.4642 - val_loss: 1.0650 - val_acc: 0.4453\n",
            "Epoch 40/50 - 0.13s - loss: 1.0523 - acc: 0.4636 - val_loss: 1.0644 - val_acc: 0.4494\n",
            "Epoch 41/50 - 0.12s - loss: 1.0515 - acc: 0.4656 - val_loss: 1.0639 - val_acc: 0.4514\n",
            "Epoch 42/50 - 0.13s - loss: 1.0507 - acc: 0.4658 - val_loss: 1.0634 - val_acc: 0.4534\n",
            "Epoch 43/50 - 0.12s - loss: 1.0500 - acc: 0.4667 - val_loss: 1.0628 - val_acc: 0.4453\n",
            "Epoch 44/50 - 0.13s - loss: 1.0492 - acc: 0.4663 - val_loss: 1.0623 - val_acc: 0.4555\n",
            "Epoch 45/50 - 0.12s - loss: 1.0485 - acc: 0.4681 - val_loss: 1.0618 - val_acc: 0.4555\n",
            "Epoch 46/50 - 0.12s - loss: 1.0477 - acc: 0.4685 - val_loss: 1.0613 - val_acc: 0.4595\n",
            "Epoch 47/50 - 0.13s - loss: 1.0470 - acc: 0.4692 - val_loss: 1.0607 - val_acc: 0.4575\n",
            "Epoch 48/50 - 0.13s - loss: 1.0463 - acc: 0.4701 - val_loss: 1.0602 - val_acc: 0.4615\n",
            "Epoch 49/50 - 0.13s - loss: 1.0456 - acc: 0.4687 - val_loss: 1.0599 - val_acc: 0.4575\n",
            "Epoch 50/50 - 0.13s - loss: 1.0449 - acc: 0.4708 - val_loss: 1.0591 - val_acc: 0.4575\n",
            "\n",
            "Combination 98/252:\n",
            "Hidden Layers: [128, 128], Activation: tanh, Learning Rate: 0.001, Batch Size: 32, Epochs: 100\n",
            "Epoch 1/100 - 0.12s - loss: 1.1004 - acc: 0.3392 - val_loss: 1.1003 - val_acc: 0.3603\n",
            "Epoch 2/100 - 0.13s - loss: 1.0968 - acc: 0.3693 - val_loss: 1.0979 - val_acc: 0.3502\n",
            "Epoch 3/100 - 0.13s - loss: 1.0943 - acc: 0.3819 - val_loss: 1.0959 - val_acc: 0.3583\n",
            "Epoch 4/100 - 0.15s - loss: 1.0919 - acc: 0.3896 - val_loss: 1.0942 - val_acc: 0.3482\n",
            "Epoch 5/100 - 0.13s - loss: 1.0898 - acc: 0.3954 - val_loss: 1.0923 - val_acc: 0.3664\n",
            "Epoch 6/100 - 0.13s - loss: 1.0877 - acc: 0.4017 - val_loss: 1.0906 - val_acc: 0.3765\n",
            "Epoch 7/100 - 0.12s - loss: 1.0858 - acc: 0.4098 - val_loss: 1.0890 - val_acc: 0.3866\n",
            "Epoch 8/100 - 0.13s - loss: 1.0839 - acc: 0.4159 - val_loss: 1.0876 - val_acc: 0.3785\n",
            "Epoch 9/100 - 0.13s - loss: 1.0821 - acc: 0.4197 - val_loss: 1.0862 - val_acc: 0.3887\n",
            "Epoch 10/100 - 0.13s - loss: 1.0804 - acc: 0.4199 - val_loss: 1.0849 - val_acc: 0.3927\n",
            "Epoch 11/100 - 0.13s - loss: 1.0788 - acc: 0.4229 - val_loss: 1.0836 - val_acc: 0.4028\n",
            "Epoch 12/100 - 0.14s - loss: 1.0772 - acc: 0.4287 - val_loss: 1.0822 - val_acc: 0.3907\n",
            "Epoch 13/100 - 0.13s - loss: 1.0757 - acc: 0.4341 - val_loss: 1.0809 - val_acc: 0.4008\n",
            "Epoch 14/100 - 0.13s - loss: 1.0743 - acc: 0.4332 - val_loss: 1.0800 - val_acc: 0.3968\n",
            "Epoch 15/100 - 0.12s - loss: 1.0729 - acc: 0.4377 - val_loss: 1.0787 - val_acc: 0.4211\n",
            "Epoch 16/100 - 0.13s - loss: 1.0715 - acc: 0.4422 - val_loss: 1.0777 - val_acc: 0.4190\n",
            "Epoch 17/100 - 0.14s - loss: 1.0702 - acc: 0.4440 - val_loss: 1.0766 - val_acc: 0.4271\n",
            "Epoch 18/100 - 0.13s - loss: 1.0689 - acc: 0.4503 - val_loss: 1.0756 - val_acc: 0.4372\n",
            "Epoch 19/100 - 0.13s - loss: 1.0676 - acc: 0.4505 - val_loss: 1.0746 - val_acc: 0.4271\n",
            "Epoch 20/100 - 0.13s - loss: 1.0664 - acc: 0.4498 - val_loss: 1.0737 - val_acc: 0.4271\n",
            "Epoch 21/100 - 0.12s - loss: 1.0652 - acc: 0.4523 - val_loss: 1.0727 - val_acc: 0.4312\n",
            "Epoch 22/100 - 0.13s - loss: 1.0640 - acc: 0.4532 - val_loss: 1.0716 - val_acc: 0.4372\n",
            "Epoch 23/100 - 0.13s - loss: 1.0628 - acc: 0.4541 - val_loss: 1.0708 - val_acc: 0.4413\n",
            "Epoch 24/100 - 0.13s - loss: 1.0617 - acc: 0.4593 - val_loss: 1.0697 - val_acc: 0.4474\n",
            "Epoch 25/100 - 0.13s - loss: 1.0606 - acc: 0.4564 - val_loss: 1.0691 - val_acc: 0.4494\n",
            "Epoch 26/100 - 0.13s - loss: 1.0595 - acc: 0.4642 - val_loss: 1.0680 - val_acc: 0.4534\n",
            "Epoch 27/100 - 0.12s - loss: 1.0584 - acc: 0.4633 - val_loss: 1.0672 - val_acc: 0.4494\n",
            "Epoch 28/100 - 0.13s - loss: 1.0573 - acc: 0.4629 - val_loss: 1.0664 - val_acc: 0.4514\n",
            "Epoch 29/100 - 0.13s - loss: 1.0563 - acc: 0.4631 - val_loss: 1.0656 - val_acc: 0.4514\n",
            "Epoch 30/100 - 0.13s - loss: 1.0553 - acc: 0.4647 - val_loss: 1.0648 - val_acc: 0.4534\n",
            "Epoch 31/100 - 0.12s - loss: 1.0543 - acc: 0.4649 - val_loss: 1.0640 - val_acc: 0.4696\n",
            "Epoch 32/100 - 0.13s - loss: 1.0533 - acc: 0.4683 - val_loss: 1.0632 - val_acc: 0.4595\n",
            "Epoch 33/100 - 0.14s - loss: 1.0523 - acc: 0.4699 - val_loss: 1.0625 - val_acc: 0.4696\n",
            "Epoch 34/100 - 0.14s - loss: 1.0513 - acc: 0.4721 - val_loss: 1.0618 - val_acc: 0.4696\n",
            "Epoch 35/100 - 0.14s - loss: 1.0503 - acc: 0.4708 - val_loss: 1.0608 - val_acc: 0.4696\n",
            "Epoch 36/100 - 0.15s - loss: 1.0494 - acc: 0.4728 - val_loss: 1.0601 - val_acc: 0.4717\n",
            "Epoch 37/100 - 0.16s - loss: 1.0485 - acc: 0.4712 - val_loss: 1.0592 - val_acc: 0.4656\n",
            "Epoch 38/100 - 0.14s - loss: 1.0475 - acc: 0.4737 - val_loss: 1.0586 - val_acc: 0.4656\n",
            "Epoch 39/100 - 0.12s - loss: 1.0466 - acc: 0.4728 - val_loss: 1.0579 - val_acc: 0.4656\n",
            "Epoch 40/100 - 0.13s - loss: 1.0457 - acc: 0.4753 - val_loss: 1.0572 - val_acc: 0.4717\n",
            "Epoch 41/100 - 0.13s - loss: 1.0448 - acc: 0.4753 - val_loss: 1.0565 - val_acc: 0.4858\n",
            "Epoch 42/100 - 0.13s - loss: 1.0439 - acc: 0.4762 - val_loss: 1.0557 - val_acc: 0.4737\n",
            "Epoch 43/100 - 0.12s - loss: 1.0431 - acc: 0.4755 - val_loss: 1.0550 - val_acc: 0.4757\n",
            "Epoch 44/100 - 0.13s - loss: 1.0422 - acc: 0.4775 - val_loss: 1.0544 - val_acc: 0.4798\n",
            "Epoch 45/100 - 0.12s - loss: 1.0414 - acc: 0.4773 - val_loss: 1.0536 - val_acc: 0.4737\n",
            "Epoch 46/100 - 0.13s - loss: 1.0405 - acc: 0.4791 - val_loss: 1.0529 - val_acc: 0.4757\n",
            "Epoch 47/100 - 0.13s - loss: 1.0397 - acc: 0.4789 - val_loss: 1.0522 - val_acc: 0.4777\n",
            "Epoch 48/100 - 0.13s - loss: 1.0389 - acc: 0.4798 - val_loss: 1.0517 - val_acc: 0.4818\n",
            "Epoch 49/100 - 0.13s - loss: 1.0380 - acc: 0.4809 - val_loss: 1.0509 - val_acc: 0.4838\n",
            "Epoch 50/100 - 0.13s - loss: 1.0372 - acc: 0.4807 - val_loss: 1.0503 - val_acc: 0.4858\n",
            "Epoch 51/100 - 0.12s - loss: 1.0364 - acc: 0.4798 - val_loss: 1.0497 - val_acc: 0.4838\n",
            "Epoch 52/100 - 0.13s - loss: 1.0356 - acc: 0.4827 - val_loss: 1.0492 - val_acc: 0.4919\n",
            "Epoch 53/100 - 0.13s - loss: 1.0348 - acc: 0.4811 - val_loss: 1.0484 - val_acc: 0.4838\n",
            "Epoch 54/100 - 0.13s - loss: 1.0340 - acc: 0.4822 - val_loss: 1.0478 - val_acc: 0.4879\n",
            "Epoch 55/100 - 0.13s - loss: 1.0332 - acc: 0.4843 - val_loss: 1.0473 - val_acc: 0.5000\n",
            "Epoch 56/100 - 0.14s - loss: 1.0325 - acc: 0.4827 - val_loss: 1.0465 - val_acc: 0.4939\n",
            "Epoch 57/100 - 0.13s - loss: 1.0317 - acc: 0.4820 - val_loss: 1.0458 - val_acc: 0.4919\n",
            "Epoch 58/100 - 0.13s - loss: 1.0309 - acc: 0.4843 - val_loss: 1.0453 - val_acc: 0.4939\n",
            "Epoch 59/100 - 0.12s - loss: 1.0302 - acc: 0.4858 - val_loss: 1.0448 - val_acc: 0.4980\n",
            "Epoch 60/100 - 0.13s - loss: 1.0294 - acc: 0.4854 - val_loss: 1.0440 - val_acc: 0.4960\n",
            "Epoch 61/100 - 0.12s - loss: 1.0286 - acc: 0.4858 - val_loss: 1.0435 - val_acc: 0.4980\n",
            "Epoch 62/100 - 0.13s - loss: 1.0279 - acc: 0.4876 - val_loss: 1.0429 - val_acc: 0.4939\n",
            "Epoch 63/100 - 0.14s - loss: 1.0272 - acc: 0.4876 - val_loss: 1.0423 - val_acc: 0.4980\n",
            "Epoch 64/100 - 0.14s - loss: 1.0264 - acc: 0.4906 - val_loss: 1.0418 - val_acc: 0.5040\n",
            "Epoch 65/100 - 0.13s - loss: 1.0258 - acc: 0.4946 - val_loss: 1.0415 - val_acc: 0.5081\n",
            "Epoch 66/100 - 0.13s - loss: 1.0250 - acc: 0.4919 - val_loss: 1.0407 - val_acc: 0.5081\n",
            "Epoch 67/100 - 0.13s - loss: 1.0242 - acc: 0.4917 - val_loss: 1.0400 - val_acc: 0.5061\n",
            "Epoch 68/100 - 0.13s - loss: 1.0235 - acc: 0.4948 - val_loss: 1.0396 - val_acc: 0.5081\n",
            "Epoch 69/100 - 0.13s - loss: 1.0228 - acc: 0.4935 - val_loss: 1.0387 - val_acc: 0.5000\n",
            "Epoch 70/100 - 0.13s - loss: 1.0221 - acc: 0.4957 - val_loss: 1.0384 - val_acc: 0.5081\n",
            "Epoch 71/100 - 0.14s - loss: 1.0214 - acc: 0.4969 - val_loss: 1.0378 - val_acc: 0.5081\n",
            "Epoch 72/100 - 0.14s - loss: 1.0207 - acc: 0.4966 - val_loss: 1.0373 - val_acc: 0.5081\n",
            "Epoch 73/100 - 0.13s - loss: 1.0199 - acc: 0.4980 - val_loss: 1.0367 - val_acc: 0.5101\n",
            "Epoch 74/100 - 0.14s - loss: 1.0193 - acc: 0.4998 - val_loss: 1.0362 - val_acc: 0.5121\n",
            "Epoch 75/100 - 0.13s - loss: 1.0185 - acc: 0.4982 - val_loss: 1.0355 - val_acc: 0.5121\n",
            "Epoch 76/100 - 0.14s - loss: 1.0178 - acc: 0.5002 - val_loss: 1.0350 - val_acc: 0.5101\n",
            "Epoch 77/100 - 0.13s - loss: 1.0171 - acc: 0.4987 - val_loss: 1.0343 - val_acc: 0.5162\n",
            "Epoch 78/100 - 0.13s - loss: 1.0165 - acc: 0.4978 - val_loss: 1.0337 - val_acc: 0.5101\n",
            "Epoch 79/100 - 0.14s - loss: 1.0158 - acc: 0.5022 - val_loss: 1.0333 - val_acc: 0.5101\n",
            "Epoch 80/100 - 0.15s - loss: 1.0150 - acc: 0.5004 - val_loss: 1.0327 - val_acc: 0.5162\n",
            "Epoch 81/100 - 0.13s - loss: 1.0144 - acc: 0.5020 - val_loss: 1.0321 - val_acc: 0.5142\n",
            "Epoch 82/100 - 0.14s - loss: 1.0137 - acc: 0.5013 - val_loss: 1.0316 - val_acc: 0.5162\n",
            "Epoch 83/100 - 0.13s - loss: 1.0130 - acc: 0.5029 - val_loss: 1.0310 - val_acc: 0.5162\n",
            "Epoch 84/100 - 0.15s - loss: 1.0123 - acc: 0.5020 - val_loss: 1.0304 - val_acc: 0.5142\n",
            "Epoch 85/100 - 0.13s - loss: 1.0116 - acc: 0.5031 - val_loss: 1.0299 - val_acc: 0.5223\n",
            "Epoch 86/100 - 0.15s - loss: 1.0110 - acc: 0.5056 - val_loss: 1.0293 - val_acc: 0.5121\n",
            "Epoch 87/100 - 0.13s - loss: 1.0103 - acc: 0.5025 - val_loss: 1.0286 - val_acc: 0.5061\n",
            "Epoch 88/100 - 0.13s - loss: 1.0096 - acc: 0.5047 - val_loss: 1.0282 - val_acc: 0.5162\n",
            "Epoch 89/100 - 0.15s - loss: 1.0089 - acc: 0.5056 - val_loss: 1.0278 - val_acc: 0.5182\n",
            "Epoch 90/100 - 0.14s - loss: 1.0083 - acc: 0.5058 - val_loss: 1.0271 - val_acc: 0.5182\n",
            "Epoch 91/100 - 0.13s - loss: 1.0076 - acc: 0.5085 - val_loss: 1.0266 - val_acc: 0.5162\n",
            "Epoch 92/100 - 0.14s - loss: 1.0069 - acc: 0.5081 - val_loss: 1.0261 - val_acc: 0.5182\n",
            "Epoch 93/100 - 0.14s - loss: 1.0062 - acc: 0.5081 - val_loss: 1.0254 - val_acc: 0.5162\n",
            "Epoch 94/100 - 0.14s - loss: 1.0056 - acc: 0.5074 - val_loss: 1.0248 - val_acc: 0.5101\n",
            "Epoch 95/100 - 0.13s - loss: 1.0049 - acc: 0.5090 - val_loss: 1.0243 - val_acc: 0.5162\n",
            "Epoch 96/100 - 0.14s - loss: 1.0042 - acc: 0.5094 - val_loss: 1.0238 - val_acc: 0.5162\n",
            "Epoch 97/100 - 0.13s - loss: 1.0039 - acc: 0.5117 - val_loss: 1.0238 - val_acc: 0.5040\n",
            "Epoch 98/100 - 0.15s - loss: 1.0029 - acc: 0.5110 - val_loss: 1.0227 - val_acc: 0.5121\n",
            "Epoch 99/100 - 0.14s - loss: 1.0023 - acc: 0.5110 - val_loss: 1.0222 - val_acc: 0.5162\n",
            "Epoch 100/100 - 0.14s - loss: 1.0018 - acc: 0.5088 - val_loss: 1.0216 - val_acc: 0.5162\n",
            "\n",
            "Combination 99/252:\n",
            "Hidden Layers: [128, 128], Activation: tanh, Learning Rate: 0.001, Batch Size: 32, Epochs: 150\n",
            "Epoch 1/150 - 0.13s - loss: 1.0971 - acc: 0.3430 - val_loss: 1.1043 - val_acc: 0.3138\n",
            "Epoch 2/150 - 0.15s - loss: 1.0929 - acc: 0.3639 - val_loss: 1.0997 - val_acc: 0.3340\n",
            "Epoch 3/150 - 0.13s - loss: 1.0903 - acc: 0.3792 - val_loss: 1.0972 - val_acc: 0.3563\n",
            "Epoch 4/150 - 0.15s - loss: 1.0880 - acc: 0.3882 - val_loss: 1.0952 - val_acc: 0.3704\n",
            "Epoch 5/150 - 0.14s - loss: 1.0858 - acc: 0.3988 - val_loss: 1.0933 - val_acc: 0.3664\n",
            "Epoch 6/150 - 0.15s - loss: 1.0838 - acc: 0.4080 - val_loss: 1.0917 - val_acc: 0.3623\n",
            "Epoch 7/150 - 0.13s - loss: 1.0819 - acc: 0.4073 - val_loss: 1.0903 - val_acc: 0.3806\n",
            "Epoch 8/150 - 0.14s - loss: 1.0800 - acc: 0.4116 - val_loss: 1.0888 - val_acc: 0.3907\n",
            "Epoch 9/150 - 0.14s - loss: 1.0782 - acc: 0.4271 - val_loss: 1.0872 - val_acc: 0.3968\n",
            "Epoch 10/150 - 0.15s - loss: 1.0765 - acc: 0.4321 - val_loss: 1.0859 - val_acc: 0.4028\n",
            "Epoch 11/150 - 0.14s - loss: 1.0749 - acc: 0.4433 - val_loss: 1.0847 - val_acc: 0.4109\n",
            "Epoch 12/150 - 0.14s - loss: 1.0734 - acc: 0.4447 - val_loss: 1.0833 - val_acc: 0.4170\n",
            "Epoch 13/150 - 0.13s - loss: 1.0718 - acc: 0.4496 - val_loss: 1.0822 - val_acc: 0.4130\n",
            "Epoch 14/150 - 0.15s - loss: 1.0704 - acc: 0.4498 - val_loss: 1.0809 - val_acc: 0.4291\n",
            "Epoch 15/150 - 0.14s - loss: 1.0690 - acc: 0.4514 - val_loss: 1.0800 - val_acc: 0.4231\n",
            "Epoch 16/150 - 0.15s - loss: 1.0676 - acc: 0.4548 - val_loss: 1.0790 - val_acc: 0.4271\n",
            "Epoch 17/150 - 0.15s - loss: 1.0663 - acc: 0.4566 - val_loss: 1.0779 - val_acc: 0.4291\n",
            "Epoch 18/150 - 0.14s - loss: 1.0650 - acc: 0.4577 - val_loss: 1.0770 - val_acc: 0.4413\n",
            "Epoch 19/150 - 0.13s - loss: 1.0637 - acc: 0.4615 - val_loss: 1.0761 - val_acc: 0.4332\n",
            "Epoch 20/150 - 0.14s - loss: 1.0626 - acc: 0.4620 - val_loss: 1.0753 - val_acc: 0.4453\n",
            "Epoch 21/150 - 0.13s - loss: 1.0614 - acc: 0.4620 - val_loss: 1.0742 - val_acc: 0.4332\n",
            "Epoch 22/150 - 0.15s - loss: 1.0602 - acc: 0.4669 - val_loss: 1.0734 - val_acc: 0.4372\n",
            "Epoch 23/150 - 0.13s - loss: 1.0590 - acc: 0.4663 - val_loss: 1.0724 - val_acc: 0.4453\n",
            "Epoch 24/150 - 0.14s - loss: 1.0579 - acc: 0.4669 - val_loss: 1.0717 - val_acc: 0.4352\n",
            "Epoch 25/150 - 0.14s - loss: 1.0568 - acc: 0.4690 - val_loss: 1.0708 - val_acc: 0.4393\n",
            "Epoch 26/150 - 0.14s - loss: 1.0558 - acc: 0.4699 - val_loss: 1.0701 - val_acc: 0.4372\n",
            "Epoch 27/150 - 0.13s - loss: 1.0548 - acc: 0.4681 - val_loss: 1.0695 - val_acc: 0.4393\n",
            "Epoch 28/150 - 0.14s - loss: 1.0537 - acc: 0.4721 - val_loss: 1.0685 - val_acc: 0.4372\n",
            "Epoch 29/150 - 0.13s - loss: 1.0527 - acc: 0.4717 - val_loss: 1.0677 - val_acc: 0.4332\n",
            "Epoch 30/150 - 0.14s - loss: 1.0517 - acc: 0.4726 - val_loss: 1.0670 - val_acc: 0.4291\n",
            "Epoch 31/150 - 0.14s - loss: 1.0508 - acc: 0.4714 - val_loss: 1.0662 - val_acc: 0.4312\n",
            "Epoch 32/150 - 0.14s - loss: 1.0499 - acc: 0.4730 - val_loss: 1.0654 - val_acc: 0.4352\n",
            "Epoch 33/150 - 0.14s - loss: 1.0489 - acc: 0.4735 - val_loss: 1.0650 - val_acc: 0.4352\n",
            "Epoch 34/150 - 0.15s - loss: 1.0480 - acc: 0.4753 - val_loss: 1.0642 - val_acc: 0.4352\n",
            "Epoch 35/150 - 0.13s - loss: 1.0471 - acc: 0.4768 - val_loss: 1.0636 - val_acc: 0.4352\n",
            "Epoch 36/150 - 0.14s - loss: 1.0463 - acc: 0.4728 - val_loss: 1.0629 - val_acc: 0.4413\n",
            "Epoch 37/150 - 0.14s - loss: 1.0454 - acc: 0.4762 - val_loss: 1.0623 - val_acc: 0.4433\n",
            "Epoch 38/150 - 0.14s - loss: 1.0445 - acc: 0.4766 - val_loss: 1.0616 - val_acc: 0.4413\n",
            "Epoch 39/150 - 0.13s - loss: 1.0436 - acc: 0.4780 - val_loss: 1.0610 - val_acc: 0.4413\n",
            "Epoch 40/150 - 0.14s - loss: 1.0428 - acc: 0.4791 - val_loss: 1.0602 - val_acc: 0.4393\n",
            "Epoch 41/150 - 0.15s - loss: 1.0420 - acc: 0.4780 - val_loss: 1.0596 - val_acc: 0.4474\n",
            "Epoch 42/150 - 0.14s - loss: 1.0412 - acc: 0.4789 - val_loss: 1.0593 - val_acc: 0.4555\n",
            "Epoch 43/150 - 0.13s - loss: 1.0404 - acc: 0.4782 - val_loss: 1.0588 - val_acc: 0.4636\n",
            "Epoch 44/150 - 0.14s - loss: 1.0396 - acc: 0.4775 - val_loss: 1.0580 - val_acc: 0.4494\n",
            "Epoch 45/150 - 0.15s - loss: 1.0388 - acc: 0.4825 - val_loss: 1.0573 - val_acc: 0.4534\n",
            "Epoch 46/150 - 0.15s - loss: 1.0380 - acc: 0.4809 - val_loss: 1.0567 - val_acc: 0.4534\n",
            "Epoch 47/150 - 0.13s - loss: 1.0373 - acc: 0.4818 - val_loss: 1.0562 - val_acc: 0.4575\n",
            "Epoch 48/150 - 0.15s - loss: 1.0365 - acc: 0.4836 - val_loss: 1.0556 - val_acc: 0.4656\n",
            "Epoch 49/150 - 0.13s - loss: 1.0357 - acc: 0.4858 - val_loss: 1.0551 - val_acc: 0.4696\n",
            "Epoch 50/150 - 0.14s - loss: 1.0350 - acc: 0.4831 - val_loss: 1.0544 - val_acc: 0.4656\n",
            "Epoch 51/150 - 0.14s - loss: 1.0342 - acc: 0.4820 - val_loss: 1.0538 - val_acc: 0.4696\n",
            "Epoch 52/150 - 0.14s - loss: 1.0335 - acc: 0.4813 - val_loss: 1.0533 - val_acc: 0.4676\n",
            "Epoch 53/150 - 0.13s - loss: 1.0327 - acc: 0.4836 - val_loss: 1.0528 - val_acc: 0.4696\n",
            "Epoch 54/150 - 0.14s - loss: 1.0321 - acc: 0.4834 - val_loss: 1.0523 - val_acc: 0.4676\n",
            "Epoch 55/150 - 0.14s - loss: 1.0313 - acc: 0.4858 - val_loss: 1.0516 - val_acc: 0.4737\n",
            "Epoch 56/150 - 0.14s - loss: 1.0306 - acc: 0.4831 - val_loss: 1.0510 - val_acc: 0.4717\n",
            "Epoch 57/150 - 0.13s - loss: 1.0299 - acc: 0.4861 - val_loss: 1.0507 - val_acc: 0.4717\n",
            "Epoch 58/150 - 0.15s - loss: 1.0292 - acc: 0.4910 - val_loss: 1.0501 - val_acc: 0.4838\n",
            "Epoch 59/150 - 0.13s - loss: 1.0284 - acc: 0.4890 - val_loss: 1.0495 - val_acc: 0.4777\n",
            "Epoch 60/150 - 0.14s - loss: 1.0278 - acc: 0.4899 - val_loss: 1.0491 - val_acc: 0.4757\n",
            "Epoch 61/150 - 0.13s - loss: 1.0270 - acc: 0.4924 - val_loss: 1.0484 - val_acc: 0.4798\n",
            "Epoch 62/150 - 0.14s - loss: 1.0264 - acc: 0.4939 - val_loss: 1.0478 - val_acc: 0.4818\n",
            "Epoch 63/150 - 0.13s - loss: 1.0257 - acc: 0.4953 - val_loss: 1.0473 - val_acc: 0.4798\n",
            "Epoch 64/150 - 0.15s - loss: 1.0250 - acc: 0.4937 - val_loss: 1.0467 - val_acc: 0.4838\n",
            "Epoch 65/150 - 0.13s - loss: 1.0243 - acc: 0.4928 - val_loss: 1.0463 - val_acc: 0.4777\n",
            "Epoch 66/150 - 0.14s - loss: 1.0236 - acc: 0.4946 - val_loss: 1.0457 - val_acc: 0.4838\n",
            "Epoch 67/150 - 0.15s - loss: 1.0230 - acc: 0.4966 - val_loss: 1.0453 - val_acc: 0.4858\n",
            "Epoch 68/150 - 0.14s - loss: 1.0223 - acc: 0.4996 - val_loss: 1.0445 - val_acc: 0.4899\n",
            "Epoch 69/150 - 0.13s - loss: 1.0216 - acc: 0.4944 - val_loss: 1.0442 - val_acc: 0.4858\n",
            "Epoch 70/150 - 0.14s - loss: 1.0209 - acc: 0.4962 - val_loss: 1.0435 - val_acc: 0.4899\n",
            "Epoch 71/150 - 0.13s - loss: 1.0202 - acc: 0.4973 - val_loss: 1.0430 - val_acc: 0.4838\n",
            "Epoch 72/150 - 0.14s - loss: 1.0196 - acc: 0.4957 - val_loss: 1.0424 - val_acc: 0.4858\n",
            "Epoch 73/150 - 0.13s - loss: 1.0189 - acc: 0.4978 - val_loss: 1.0418 - val_acc: 0.4858\n",
            "Epoch 74/150 - 0.13s - loss: 1.0182 - acc: 0.4996 - val_loss: 1.0414 - val_acc: 0.4879\n",
            "Epoch 75/150 - 0.13s - loss: 1.0176 - acc: 0.4991 - val_loss: 1.0408 - val_acc: 0.4858\n",
            "Epoch 76/150 - 0.14s - loss: 1.0170 - acc: 0.4975 - val_loss: 1.0402 - val_acc: 0.4919\n",
            "Epoch 77/150 - 0.13s - loss: 1.0162 - acc: 0.5020 - val_loss: 1.0397 - val_acc: 0.4858\n",
            "Epoch 78/150 - 0.14s - loss: 1.0156 - acc: 0.5018 - val_loss: 1.0391 - val_acc: 0.4879\n",
            "Epoch 79/150 - 0.13s - loss: 1.0150 - acc: 0.4996 - val_loss: 1.0385 - val_acc: 0.4899\n",
            "Epoch 80/150 - 0.14s - loss: 1.0143 - acc: 0.5040 - val_loss: 1.0381 - val_acc: 0.4858\n",
            "Epoch 81/150 - 0.14s - loss: 1.0136 - acc: 0.5040 - val_loss: 1.0376 - val_acc: 0.4879\n",
            "Epoch 82/150 - 0.14s - loss: 1.0130 - acc: 0.5022 - val_loss: 1.0370 - val_acc: 0.4899\n",
            "Epoch 83/150 - 0.13s - loss: 1.0123 - acc: 0.5022 - val_loss: 1.0365 - val_acc: 0.4899\n",
            "Epoch 84/150 - 0.15s - loss: 1.0117 - acc: 0.5054 - val_loss: 1.0359 - val_acc: 0.4939\n",
            "Epoch 85/150 - 0.14s - loss: 1.0110 - acc: 0.5049 - val_loss: 1.0354 - val_acc: 0.4919\n",
            "Epoch 86/150 - 0.14s - loss: 1.0106 - acc: 0.5034 - val_loss: 1.0348 - val_acc: 0.4939\n",
            "Epoch 87/150 - 0.13s - loss: 1.0097 - acc: 0.5047 - val_loss: 1.0342 - val_acc: 0.4939\n",
            "Epoch 88/150 - 0.15s - loss: 1.0091 - acc: 0.5047 - val_loss: 1.0339 - val_acc: 0.4858\n",
            "Epoch 89/150 - 0.13s - loss: 1.0085 - acc: 0.5043 - val_loss: 1.0331 - val_acc: 0.4960\n",
            "Epoch 90/150 - 0.13s - loss: 1.0078 - acc: 0.5065 - val_loss: 1.0324 - val_acc: 0.4980\n",
            "Epoch 91/150 - 0.13s - loss: 1.0071 - acc: 0.5070 - val_loss: 1.0320 - val_acc: 0.4939\n",
            "Epoch 92/150 - 0.14s - loss: 1.0066 - acc: 0.5074 - val_loss: 1.0315 - val_acc: 0.4939\n",
            "Epoch 93/150 - 0.15s - loss: 1.0061 - acc: 0.5094 - val_loss: 1.0314 - val_acc: 0.4838\n",
            "Epoch 94/150 - 0.14s - loss: 1.0053 - acc: 0.5076 - val_loss: 1.0307 - val_acc: 0.4899\n",
            "Epoch 95/150 - 0.14s - loss: 1.0046 - acc: 0.5090 - val_loss: 1.0299 - val_acc: 0.4879\n",
            "Epoch 96/150 - 0.13s - loss: 1.0040 - acc: 0.5097 - val_loss: 1.0291 - val_acc: 0.5000\n",
            "Epoch 97/150 - 0.13s - loss: 1.0034 - acc: 0.5097 - val_loss: 1.0290 - val_acc: 0.4879\n",
            "Epoch 98/150 - 0.14s - loss: 1.0028 - acc: 0.5126 - val_loss: 1.0284 - val_acc: 0.4879\n",
            "Epoch 99/150 - 0.13s - loss: 1.0020 - acc: 0.5119 - val_loss: 1.0276 - val_acc: 0.4919\n",
            "Epoch 100/150 - 0.14s - loss: 1.0014 - acc: 0.5110 - val_loss: 1.0269 - val_acc: 0.5040\n",
            "Epoch 101/150 - 0.13s - loss: 1.0008 - acc: 0.5133 - val_loss: 1.0263 - val_acc: 0.5040\n",
            "Epoch 102/150 - 0.13s - loss: 1.0003 - acc: 0.5182 - val_loss: 1.0262 - val_acc: 0.4899\n",
            "Epoch 103/150 - 0.13s - loss: 0.9997 - acc: 0.5173 - val_loss: 1.0257 - val_acc: 0.4899\n",
            "Epoch 104/150 - 0.13s - loss: 0.9990 - acc: 0.5144 - val_loss: 1.0246 - val_acc: 0.5061\n",
            "Epoch 105/150 - 0.12s - loss: 0.9984 - acc: 0.5155 - val_loss: 1.0240 - val_acc: 0.5061\n",
            "Epoch 106/150 - 0.13s - loss: 0.9977 - acc: 0.5173 - val_loss: 1.0236 - val_acc: 0.5020\n",
            "Epoch 107/150 - 0.12s - loss: 0.9971 - acc: 0.5169 - val_loss: 1.0230 - val_acc: 0.5081\n",
            "Epoch 108/150 - 0.13s - loss: 0.9964 - acc: 0.5189 - val_loss: 1.0226 - val_acc: 0.5040\n",
            "Epoch 109/150 - 0.12s - loss: 0.9958 - acc: 0.5187 - val_loss: 1.0218 - val_acc: 0.5121\n",
            "Epoch 110/150 - 0.13s - loss: 0.9952 - acc: 0.5196 - val_loss: 1.0215 - val_acc: 0.5040\n",
            "Epoch 111/150 - 0.12s - loss: 0.9947 - acc: 0.5191 - val_loss: 1.0207 - val_acc: 0.5101\n",
            "Epoch 112/150 - 0.14s - loss: 0.9942 - acc: 0.5193 - val_loss: 1.0202 - val_acc: 0.5061\n",
            "Epoch 113/150 - 0.13s - loss: 0.9934 - acc: 0.5225 - val_loss: 1.0197 - val_acc: 0.5121\n",
            "Epoch 114/150 - 0.13s - loss: 0.9929 - acc: 0.5214 - val_loss: 1.0193 - val_acc: 0.5081\n",
            "Epoch 115/150 - 0.12s - loss: 0.9922 - acc: 0.5236 - val_loss: 1.0186 - val_acc: 0.5121\n",
            "Epoch 116/150 - 0.13s - loss: 0.9915 - acc: 0.5238 - val_loss: 1.0182 - val_acc: 0.5142\n",
            "Epoch 117/150 - 0.12s - loss: 0.9910 - acc: 0.5232 - val_loss: 1.0176 - val_acc: 0.5121\n",
            "Epoch 118/150 - 0.14s - loss: 0.9906 - acc: 0.5227 - val_loss: 1.0170 - val_acc: 0.5101\n",
            "Epoch 119/150 - 0.14s - loss: 0.9898 - acc: 0.5254 - val_loss: 1.0166 - val_acc: 0.5182\n",
            "Epoch 120/150 - 0.14s - loss: 0.9892 - acc: 0.5241 - val_loss: 1.0159 - val_acc: 0.5142\n",
            "Epoch 121/150 - 0.13s - loss: 0.9887 - acc: 0.5274 - val_loss: 1.0157 - val_acc: 0.5081\n",
            "Epoch 122/150 - 0.13s - loss: 0.9882 - acc: 0.5247 - val_loss: 1.0148 - val_acc: 0.5202\n",
            "Epoch 123/150 - 0.12s - loss: 0.9874 - acc: 0.5261 - val_loss: 1.0145 - val_acc: 0.5142\n",
            "Epoch 124/150 - 0.13s - loss: 0.9868 - acc: 0.5265 - val_loss: 1.0137 - val_acc: 0.5121\n",
            "Epoch 125/150 - 0.13s - loss: 0.9863 - acc: 0.5259 - val_loss: 1.0133 - val_acc: 0.5202\n",
            "Epoch 126/150 - 0.13s - loss: 0.9859 - acc: 0.5279 - val_loss: 1.0132 - val_acc: 0.5142\n",
            "Epoch 127/150 - 0.12s - loss: 0.9851 - acc: 0.5277 - val_loss: 1.0121 - val_acc: 0.5142\n",
            "Epoch 128/150 - 0.13s - loss: 0.9845 - acc: 0.5279 - val_loss: 1.0114 - val_acc: 0.5182\n",
            "Epoch 129/150 - 0.12s - loss: 0.9842 - acc: 0.5272 - val_loss: 1.0109 - val_acc: 0.5223\n",
            "Epoch 130/150 - 0.13s - loss: 0.9834 - acc: 0.5279 - val_loss: 1.0103 - val_acc: 0.5182\n",
            "Epoch 131/150 - 0.12s - loss: 0.9828 - acc: 0.5304 - val_loss: 1.0099 - val_acc: 0.5162\n",
            "Epoch 132/150 - 0.12s - loss: 0.9824 - acc: 0.5297 - val_loss: 1.0101 - val_acc: 0.5142\n",
            "Epoch 133/150 - 0.12s - loss: 0.9816 - acc: 0.5286 - val_loss: 1.0091 - val_acc: 0.5162\n",
            "Epoch 134/150 - 0.13s - loss: 0.9811 - acc: 0.5290 - val_loss: 1.0086 - val_acc: 0.5182\n",
            "Epoch 135/150 - 0.12s - loss: 0.9806 - acc: 0.5306 - val_loss: 1.0082 - val_acc: 0.5223\n",
            "Epoch 136/150 - 0.13s - loss: 0.9799 - acc: 0.5315 - val_loss: 1.0074 - val_acc: 0.5202\n",
            "Epoch 137/150 - 0.13s - loss: 0.9794 - acc: 0.5328 - val_loss: 1.0068 - val_acc: 0.5202\n",
            "Epoch 138/150 - 0.13s - loss: 0.9788 - acc: 0.5308 - val_loss: 1.0065 - val_acc: 0.5223\n",
            "Epoch 139/150 - 0.12s - loss: 0.9786 - acc: 0.5324 - val_loss: 1.0059 - val_acc: 0.5243\n",
            "Epoch 140/150 - 0.13s - loss: 0.9778 - acc: 0.5319 - val_loss: 1.0056 - val_acc: 0.5223\n",
            "Epoch 141/150 - 0.12s - loss: 0.9774 - acc: 0.5324 - val_loss: 1.0050 - val_acc: 0.5243\n",
            "Epoch 142/150 - 0.13s - loss: 0.9767 - acc: 0.5326 - val_loss: 1.0047 - val_acc: 0.5223\n",
            "Epoch 143/150 - 0.13s - loss: 0.9763 - acc: 0.5349 - val_loss: 1.0044 - val_acc: 0.5223\n",
            "Epoch 144/150 - 0.13s - loss: 0.9756 - acc: 0.5331 - val_loss: 1.0035 - val_acc: 0.5202\n",
            "Epoch 145/150 - 0.13s - loss: 0.9751 - acc: 0.5328 - val_loss: 1.0030 - val_acc: 0.5263\n",
            "Epoch 146/150 - 0.13s - loss: 0.9745 - acc: 0.5326 - val_loss: 1.0024 - val_acc: 0.5223\n",
            "Epoch 147/150 - 0.13s - loss: 0.9741 - acc: 0.5355 - val_loss: 1.0018 - val_acc: 0.5324\n",
            "Epoch 148/150 - 0.13s - loss: 0.9738 - acc: 0.5346 - val_loss: 1.0017 - val_acc: 0.5283\n",
            "Epoch 149/150 - 0.13s - loss: 0.9731 - acc: 0.5346 - val_loss: 1.0013 - val_acc: 0.5223\n",
            "Epoch 150/150 - 0.14s - loss: 0.9724 - acc: 0.5349 - val_loss: 1.0006 - val_acc: 0.5223\n",
            "\n",
            "Combination 100/252:\n",
            "Hidden Layers: [128, 128], Activation: tanh, Learning Rate: 0.001, Batch Size: 64, Epochs: 50\n",
            "Epoch 1/50 - 0.12s - loss: 1.1045 - acc: 0.3255 - val_loss: 1.0996 - val_acc: 0.3381\n",
            "Epoch 2/50 - 0.10s - loss: 1.1021 - acc: 0.3324 - val_loss: 1.0981 - val_acc: 0.3421\n",
            "Epoch 3/50 - 0.10s - loss: 1.1004 - acc: 0.3419 - val_loss: 1.0969 - val_acc: 0.3522\n",
            "Epoch 4/50 - 0.10s - loss: 1.0989 - acc: 0.3473 - val_loss: 1.0959 - val_acc: 0.3522\n",
            "Epoch 5/50 - 0.11s - loss: 1.0976 - acc: 0.3531 - val_loss: 1.0949 - val_acc: 0.3462\n",
            "Epoch 6/50 - 0.10s - loss: 1.0963 - acc: 0.3599 - val_loss: 1.0939 - val_acc: 0.3583\n",
            "Epoch 7/50 - 0.10s - loss: 1.0951 - acc: 0.3628 - val_loss: 1.0929 - val_acc: 0.3563\n",
            "Epoch 8/50 - 0.10s - loss: 1.0939 - acc: 0.3675 - val_loss: 1.0920 - val_acc: 0.3603\n",
            "Epoch 9/50 - 0.10s - loss: 1.0928 - acc: 0.3736 - val_loss: 1.0911 - val_acc: 0.3765\n",
            "Epoch 10/50 - 0.10s - loss: 1.0917 - acc: 0.3754 - val_loss: 1.0903 - val_acc: 0.3765\n",
            "Epoch 11/50 - 0.10s - loss: 1.0906 - acc: 0.3810 - val_loss: 1.0893 - val_acc: 0.3866\n",
            "Epoch 12/50 - 0.10s - loss: 1.0896 - acc: 0.3844 - val_loss: 1.0885 - val_acc: 0.3866\n",
            "Epoch 13/50 - 0.10s - loss: 1.0885 - acc: 0.3878 - val_loss: 1.0877 - val_acc: 0.3866\n",
            "Epoch 14/50 - 0.11s - loss: 1.0876 - acc: 0.3909 - val_loss: 1.0869 - val_acc: 0.3907\n",
            "Epoch 15/50 - 0.10s - loss: 1.0866 - acc: 0.3932 - val_loss: 1.0861 - val_acc: 0.3927\n",
            "Epoch 16/50 - 0.10s - loss: 1.0857 - acc: 0.3961 - val_loss: 1.0853 - val_acc: 0.4008\n",
            "Epoch 17/50 - 0.10s - loss: 1.0848 - acc: 0.3997 - val_loss: 1.0846 - val_acc: 0.4008\n",
            "Epoch 18/50 - 0.10s - loss: 1.0839 - acc: 0.4010 - val_loss: 1.0839 - val_acc: 0.3988\n",
            "Epoch 19/50 - 0.10s - loss: 1.0830 - acc: 0.4071 - val_loss: 1.0833 - val_acc: 0.3988\n",
            "Epoch 20/50 - 0.11s - loss: 1.0822 - acc: 0.4082 - val_loss: 1.0826 - val_acc: 0.4049\n",
            "Epoch 21/50 - 0.10s - loss: 1.0814 - acc: 0.4143 - val_loss: 1.0820 - val_acc: 0.4089\n",
            "Epoch 22/50 - 0.10s - loss: 1.0806 - acc: 0.4159 - val_loss: 1.0814 - val_acc: 0.4069\n",
            "Epoch 23/50 - 0.11s - loss: 1.0798 - acc: 0.4143 - val_loss: 1.0808 - val_acc: 0.4069\n",
            "Epoch 24/50 - 0.10s - loss: 1.0790 - acc: 0.4145 - val_loss: 1.0802 - val_acc: 0.4028\n",
            "Epoch 25/50 - 0.10s - loss: 1.0783 - acc: 0.4161 - val_loss: 1.0796 - val_acc: 0.4028\n",
            "Epoch 26/50 - 0.10s - loss: 1.0776 - acc: 0.4175 - val_loss: 1.0790 - val_acc: 0.4028\n",
            "Epoch 27/50 - 0.10s - loss: 1.0768 - acc: 0.4181 - val_loss: 1.0785 - val_acc: 0.4069\n",
            "Epoch 28/50 - 0.10s - loss: 1.0761 - acc: 0.4224 - val_loss: 1.0779 - val_acc: 0.4089\n",
            "Epoch 29/50 - 0.10s - loss: 1.0755 - acc: 0.4247 - val_loss: 1.0774 - val_acc: 0.4109\n",
            "Epoch 30/50 - 0.12s - loss: 1.0748 - acc: 0.4265 - val_loss: 1.0768 - val_acc: 0.4109\n",
            "Epoch 31/50 - 0.10s - loss: 1.0741 - acc: 0.4265 - val_loss: 1.0763 - val_acc: 0.4130\n",
            "Epoch 32/50 - 0.11s - loss: 1.0735 - acc: 0.4287 - val_loss: 1.0758 - val_acc: 0.4089\n",
            "Epoch 33/50 - 0.10s - loss: 1.0728 - acc: 0.4303 - val_loss: 1.0753 - val_acc: 0.4069\n",
            "Epoch 34/50 - 0.10s - loss: 1.0722 - acc: 0.4343 - val_loss: 1.0748 - val_acc: 0.4109\n",
            "Epoch 35/50 - 0.11s - loss: 1.0716 - acc: 0.4386 - val_loss: 1.0743 - val_acc: 0.4089\n",
            "Epoch 36/50 - 0.11s - loss: 1.0710 - acc: 0.4399 - val_loss: 1.0738 - val_acc: 0.4130\n",
            "Epoch 37/50 - 0.11s - loss: 1.0704 - acc: 0.4408 - val_loss: 1.0734 - val_acc: 0.4130\n",
            "Epoch 38/50 - 0.11s - loss: 1.0698 - acc: 0.4406 - val_loss: 1.0729 - val_acc: 0.4089\n",
            "Epoch 39/50 - 0.12s - loss: 1.0692 - acc: 0.4422 - val_loss: 1.0725 - val_acc: 0.4089\n",
            "Epoch 40/50 - 0.11s - loss: 1.0686 - acc: 0.4442 - val_loss: 1.0720 - val_acc: 0.4109\n",
            "Epoch 41/50 - 0.11s - loss: 1.0681 - acc: 0.4460 - val_loss: 1.0716 - val_acc: 0.4130\n",
            "Epoch 42/50 - 0.10s - loss: 1.0675 - acc: 0.4471 - val_loss: 1.0712 - val_acc: 0.4150\n",
            "Epoch 43/50 - 0.10s - loss: 1.0670 - acc: 0.4480 - val_loss: 1.0708 - val_acc: 0.4170\n",
            "Epoch 44/50 - 0.10s - loss: 1.0664 - acc: 0.4494 - val_loss: 1.0704 - val_acc: 0.4130\n",
            "Epoch 45/50 - 0.11s - loss: 1.0659 - acc: 0.4492 - val_loss: 1.0700 - val_acc: 0.4109\n",
            "Epoch 46/50 - 0.10s - loss: 1.0654 - acc: 0.4503 - val_loss: 1.0696 - val_acc: 0.4170\n",
            "Epoch 47/50 - 0.10s - loss: 1.0649 - acc: 0.4519 - val_loss: 1.0692 - val_acc: 0.4170\n",
            "Epoch 48/50 - 0.10s - loss: 1.0644 - acc: 0.4525 - val_loss: 1.0687 - val_acc: 0.4231\n",
            "Epoch 49/50 - 0.10s - loss: 1.0638 - acc: 0.4519 - val_loss: 1.0684 - val_acc: 0.4190\n",
            "Epoch 50/50 - 0.10s - loss: 1.0633 - acc: 0.4537 - val_loss: 1.0681 - val_acc: 0.4251\n",
            "\n",
            "Combination 101/252:\n",
            "Hidden Layers: [128, 128], Activation: tanh, Learning Rate: 0.001, Batch Size: 64, Epochs: 100\n",
            "Epoch 1/100 - 0.11s - loss: 1.0950 - acc: 0.3417 - val_loss: 1.0951 - val_acc: 0.3279\n",
            "Epoch 2/100 - 0.10s - loss: 1.0916 - acc: 0.3493 - val_loss: 1.0909 - val_acc: 0.3482\n",
            "Epoch 3/100 - 0.10s - loss: 1.0897 - acc: 0.3684 - val_loss: 1.0885 - val_acc: 0.3684\n",
            "Epoch 4/100 - 0.11s - loss: 1.0884 - acc: 0.3763 - val_loss: 1.0871 - val_acc: 0.3644\n",
            "Epoch 5/100 - 0.10s - loss: 1.0873 - acc: 0.3833 - val_loss: 1.0860 - val_acc: 0.3846\n",
            "Epoch 6/100 - 0.10s - loss: 1.0863 - acc: 0.3882 - val_loss: 1.0852 - val_acc: 0.3866\n",
            "Epoch 7/100 - 0.10s - loss: 1.0853 - acc: 0.3950 - val_loss: 1.0844 - val_acc: 0.3927\n",
            "Epoch 8/100 - 0.10s - loss: 1.0843 - acc: 0.3992 - val_loss: 1.0837 - val_acc: 0.3907\n",
            "Epoch 9/100 - 0.11s - loss: 1.0834 - acc: 0.4013 - val_loss: 1.0829 - val_acc: 0.3927\n",
            "Epoch 10/100 - 0.10s - loss: 1.0825 - acc: 0.4015 - val_loss: 1.0823 - val_acc: 0.3947\n",
            "Epoch 11/100 - 0.10s - loss: 1.0817 - acc: 0.4051 - val_loss: 1.0817 - val_acc: 0.3988\n",
            "Epoch 12/100 - 0.11s - loss: 1.0808 - acc: 0.4051 - val_loss: 1.0811 - val_acc: 0.3988\n",
            "Epoch 13/100 - 0.12s - loss: 1.0800 - acc: 0.4089 - val_loss: 1.0805 - val_acc: 0.4089\n",
            "Epoch 14/100 - 0.10s - loss: 1.0792 - acc: 0.4145 - val_loss: 1.0799 - val_acc: 0.4170\n",
            "Epoch 15/100 - 0.10s - loss: 1.0784 - acc: 0.4145 - val_loss: 1.0793 - val_acc: 0.4130\n",
            "Epoch 16/100 - 0.10s - loss: 1.0777 - acc: 0.4161 - val_loss: 1.0788 - val_acc: 0.4211\n",
            "Epoch 17/100 - 0.11s - loss: 1.0769 - acc: 0.4186 - val_loss: 1.0782 - val_acc: 0.4231\n",
            "Epoch 18/100 - 0.10s - loss: 1.0762 - acc: 0.4179 - val_loss: 1.0776 - val_acc: 0.4211\n",
            "Epoch 19/100 - 0.10s - loss: 1.0755 - acc: 0.4206 - val_loss: 1.0771 - val_acc: 0.4251\n",
            "Epoch 20/100 - 0.11s - loss: 1.0748 - acc: 0.4204 - val_loss: 1.0766 - val_acc: 0.4231\n",
            "Epoch 21/100 - 0.10s - loss: 1.0741 - acc: 0.4244 - val_loss: 1.0761 - val_acc: 0.4332\n",
            "Epoch 22/100 - 0.10s - loss: 1.0734 - acc: 0.4249 - val_loss: 1.0757 - val_acc: 0.4332\n",
            "Epoch 23/100 - 0.11s - loss: 1.0728 - acc: 0.4249 - val_loss: 1.0753 - val_acc: 0.4291\n",
            "Epoch 24/100 - 0.10s - loss: 1.0721 - acc: 0.4291 - val_loss: 1.0749 - val_acc: 0.4372\n",
            "Epoch 25/100 - 0.10s - loss: 1.0715 - acc: 0.4303 - val_loss: 1.0744 - val_acc: 0.4413\n",
            "Epoch 26/100 - 0.10s - loss: 1.0709 - acc: 0.4309 - val_loss: 1.0739 - val_acc: 0.4352\n",
            "Epoch 27/100 - 0.10s - loss: 1.0703 - acc: 0.4332 - val_loss: 1.0735 - val_acc: 0.4352\n",
            "Epoch 28/100 - 0.10s - loss: 1.0697 - acc: 0.4368 - val_loss: 1.0730 - val_acc: 0.4372\n",
            "Epoch 29/100 - 0.11s - loss: 1.0691 - acc: 0.4377 - val_loss: 1.0726 - val_acc: 0.4413\n",
            "Epoch 30/100 - 0.10s - loss: 1.0685 - acc: 0.4379 - val_loss: 1.0723 - val_acc: 0.4413\n",
            "Epoch 31/100 - 0.10s - loss: 1.0680 - acc: 0.4393 - val_loss: 1.0718 - val_acc: 0.4413\n",
            "Epoch 32/100 - 0.10s - loss: 1.0674 - acc: 0.4404 - val_loss: 1.0715 - val_acc: 0.4413\n",
            "Epoch 33/100 - 0.10s - loss: 1.0668 - acc: 0.4406 - val_loss: 1.0711 - val_acc: 0.4433\n",
            "Epoch 34/100 - 0.10s - loss: 1.0663 - acc: 0.4413 - val_loss: 1.0707 - val_acc: 0.4433\n",
            "Epoch 35/100 - 0.11s - loss: 1.0658 - acc: 0.4422 - val_loss: 1.0703 - val_acc: 0.4393\n",
            "Epoch 36/100 - 0.10s - loss: 1.0652 - acc: 0.4438 - val_loss: 1.0699 - val_acc: 0.4372\n",
            "Epoch 37/100 - 0.10s - loss: 1.0647 - acc: 0.4426 - val_loss: 1.0695 - val_acc: 0.4352\n",
            "Epoch 38/100 - 0.11s - loss: 1.0642 - acc: 0.4402 - val_loss: 1.0691 - val_acc: 0.4393\n",
            "Epoch 39/100 - 0.10s - loss: 1.0637 - acc: 0.4417 - val_loss: 1.0688 - val_acc: 0.4372\n",
            "Epoch 40/100 - 0.10s - loss: 1.0631 - acc: 0.4408 - val_loss: 1.0684 - val_acc: 0.4352\n",
            "Epoch 41/100 - 0.10s - loss: 1.0626 - acc: 0.4453 - val_loss: 1.0681 - val_acc: 0.4372\n",
            "Epoch 42/100 - 0.11s - loss: 1.0621 - acc: 0.4435 - val_loss: 1.0677 - val_acc: 0.4352\n",
            "Epoch 43/100 - 0.10s - loss: 1.0616 - acc: 0.4444 - val_loss: 1.0674 - val_acc: 0.4352\n",
            "Epoch 44/100 - 0.10s - loss: 1.0611 - acc: 0.4431 - val_loss: 1.0670 - val_acc: 0.4372\n",
            "Epoch 45/100 - 0.11s - loss: 1.0607 - acc: 0.4442 - val_loss: 1.0667 - val_acc: 0.4372\n",
            "Epoch 46/100 - 0.10s - loss: 1.0602 - acc: 0.4444 - val_loss: 1.0664 - val_acc: 0.4352\n",
            "Epoch 47/100 - 0.10s - loss: 1.0597 - acc: 0.4451 - val_loss: 1.0661 - val_acc: 0.4312\n",
            "Epoch 48/100 - 0.12s - loss: 1.0592 - acc: 0.4462 - val_loss: 1.0658 - val_acc: 0.4332\n",
            "Epoch 49/100 - 0.10s - loss: 1.0588 - acc: 0.4458 - val_loss: 1.0654 - val_acc: 0.4352\n",
            "Epoch 50/100 - 0.10s - loss: 1.0583 - acc: 0.4474 - val_loss: 1.0651 - val_acc: 0.4352\n",
            "Epoch 51/100 - 0.10s - loss: 1.0578 - acc: 0.4485 - val_loss: 1.0648 - val_acc: 0.4372\n",
            "Epoch 52/100 - 0.10s - loss: 1.0574 - acc: 0.4485 - val_loss: 1.0644 - val_acc: 0.4393\n",
            "Epoch 53/100 - 0.10s - loss: 1.0569 - acc: 0.4503 - val_loss: 1.0641 - val_acc: 0.4393\n",
            "Epoch 54/100 - 0.11s - loss: 1.0565 - acc: 0.4514 - val_loss: 1.0638 - val_acc: 0.4413\n",
            "Epoch 55/100 - 0.10s - loss: 1.0560 - acc: 0.4514 - val_loss: 1.0635 - val_acc: 0.4413\n",
            "Epoch 56/100 - 0.10s - loss: 1.0556 - acc: 0.4539 - val_loss: 1.0632 - val_acc: 0.4453\n",
            "Epoch 57/100 - 0.10s - loss: 1.0551 - acc: 0.4534 - val_loss: 1.0628 - val_acc: 0.4433\n",
            "Epoch 58/100 - 0.11s - loss: 1.0547 - acc: 0.4559 - val_loss: 1.0626 - val_acc: 0.4453\n",
            "Epoch 59/100 - 0.10s - loss: 1.0543 - acc: 0.4566 - val_loss: 1.0622 - val_acc: 0.4474\n",
            "Epoch 60/100 - 0.10s - loss: 1.0538 - acc: 0.4573 - val_loss: 1.0620 - val_acc: 0.4494\n",
            "Epoch 61/100 - 0.11s - loss: 1.0534 - acc: 0.4575 - val_loss: 1.0616 - val_acc: 0.4514\n",
            "Epoch 62/100 - 0.10s - loss: 1.0530 - acc: 0.4568 - val_loss: 1.0614 - val_acc: 0.4575\n",
            "Epoch 63/100 - 0.10s - loss: 1.0526 - acc: 0.4579 - val_loss: 1.0610 - val_acc: 0.4555\n",
            "Epoch 64/100 - 0.11s - loss: 1.0521 - acc: 0.4588 - val_loss: 1.0607 - val_acc: 0.4555\n",
            "Epoch 65/100 - 0.10s - loss: 1.0517 - acc: 0.4584 - val_loss: 1.0604 - val_acc: 0.4575\n",
            "Epoch 66/100 - 0.10s - loss: 1.0513 - acc: 0.4582 - val_loss: 1.0601 - val_acc: 0.4575\n",
            "Epoch 67/100 - 0.11s - loss: 1.0509 - acc: 0.4579 - val_loss: 1.0598 - val_acc: 0.4595\n",
            "Epoch 68/100 - 0.10s - loss: 1.0505 - acc: 0.4591 - val_loss: 1.0595 - val_acc: 0.4615\n",
            "Epoch 69/100 - 0.10s - loss: 1.0501 - acc: 0.4600 - val_loss: 1.0592 - val_acc: 0.4595\n",
            "Epoch 70/100 - 0.11s - loss: 1.0497 - acc: 0.4611 - val_loss: 1.0589 - val_acc: 0.4636\n",
            "Epoch 71/100 - 0.10s - loss: 1.0493 - acc: 0.4615 - val_loss: 1.0587 - val_acc: 0.4615\n",
            "Epoch 72/100 - 0.11s - loss: 1.0489 - acc: 0.4618 - val_loss: 1.0583 - val_acc: 0.4656\n",
            "Epoch 73/100 - 0.10s - loss: 1.0484 - acc: 0.4615 - val_loss: 1.0581 - val_acc: 0.4636\n",
            "Epoch 74/100 - 0.12s - loss: 1.0480 - acc: 0.4620 - val_loss: 1.0578 - val_acc: 0.4696\n",
            "Epoch 75/100 - 0.10s - loss: 1.0477 - acc: 0.4631 - val_loss: 1.0576 - val_acc: 0.4676\n",
            "Epoch 76/100 - 0.11s - loss: 1.0473 - acc: 0.4647 - val_loss: 1.0574 - val_acc: 0.4615\n",
            "Epoch 77/100 - 0.10s - loss: 1.0469 - acc: 0.4647 - val_loss: 1.0571 - val_acc: 0.4676\n",
            "Epoch 78/100 - 0.10s - loss: 1.0465 - acc: 0.4642 - val_loss: 1.0567 - val_acc: 0.4656\n",
            "Epoch 79/100 - 0.10s - loss: 1.0461 - acc: 0.4663 - val_loss: 1.0564 - val_acc: 0.4676\n",
            "Epoch 80/100 - 0.10s - loss: 1.0457 - acc: 0.4660 - val_loss: 1.0561 - val_acc: 0.4615\n",
            "Epoch 81/100 - 0.12s - loss: 1.0453 - acc: 0.4669 - val_loss: 1.0558 - val_acc: 0.4656\n",
            "Epoch 82/100 - 0.11s - loss: 1.0449 - acc: 0.4672 - val_loss: 1.0555 - val_acc: 0.4656\n",
            "Epoch 83/100 - 0.10s - loss: 1.0445 - acc: 0.4667 - val_loss: 1.0553 - val_acc: 0.4696\n",
            "Epoch 84/100 - 0.10s - loss: 1.0442 - acc: 0.4681 - val_loss: 1.0551 - val_acc: 0.4676\n",
            "Epoch 85/100 - 0.10s - loss: 1.0438 - acc: 0.4694 - val_loss: 1.0548 - val_acc: 0.4656\n",
            "Epoch 86/100 - 0.10s - loss: 1.0434 - acc: 0.4692 - val_loss: 1.0546 - val_acc: 0.4676\n",
            "Epoch 87/100 - 0.10s - loss: 1.0430 - acc: 0.4708 - val_loss: 1.0542 - val_acc: 0.4676\n",
            "Epoch 88/100 - 0.11s - loss: 1.0427 - acc: 0.4705 - val_loss: 1.0539 - val_acc: 0.4676\n",
            "Epoch 89/100 - 0.10s - loss: 1.0423 - acc: 0.4712 - val_loss: 1.0537 - val_acc: 0.4676\n",
            "Epoch 90/100 - 0.10s - loss: 1.0419 - acc: 0.4719 - val_loss: 1.0534 - val_acc: 0.4717\n",
            "Epoch 91/100 - 0.10s - loss: 1.0416 - acc: 0.4726 - val_loss: 1.0531 - val_acc: 0.4737\n",
            "Epoch 92/100 - 0.10s - loss: 1.0412 - acc: 0.4739 - val_loss: 1.0529 - val_acc: 0.4737\n",
            "Epoch 93/100 - 0.10s - loss: 1.0408 - acc: 0.4739 - val_loss: 1.0526 - val_acc: 0.4757\n",
            "Epoch 94/100 - 0.11s - loss: 1.0405 - acc: 0.4750 - val_loss: 1.0524 - val_acc: 0.4757\n",
            "Epoch 95/100 - 0.10s - loss: 1.0401 - acc: 0.4750 - val_loss: 1.0521 - val_acc: 0.4798\n",
            "Epoch 96/100 - 0.10s - loss: 1.0397 - acc: 0.4753 - val_loss: 1.0518 - val_acc: 0.4777\n",
            "Epoch 97/100 - 0.11s - loss: 1.0394 - acc: 0.4753 - val_loss: 1.0516 - val_acc: 0.4798\n",
            "Epoch 98/100 - 0.10s - loss: 1.0390 - acc: 0.4780 - val_loss: 1.0513 - val_acc: 0.4777\n",
            "Epoch 99/100 - 0.10s - loss: 1.0386 - acc: 0.4789 - val_loss: 1.0511 - val_acc: 0.4777\n",
            "Epoch 100/100 - 0.10s - loss: 1.0383 - acc: 0.4782 - val_loss: 1.0509 - val_acc: 0.4777\n",
            "\n",
            "Combination 102/252:\n",
            "Hidden Layers: [128, 128], Activation: tanh, Learning Rate: 0.001, Batch Size: 64, Epochs: 150\n",
            "Epoch 1/150 - 0.10s - loss: 1.1098 - acc: 0.3448 - val_loss: 1.1135 - val_acc: 0.3340\n",
            "Epoch 2/150 - 0.10s - loss: 1.1039 - acc: 0.3428 - val_loss: 1.1080 - val_acc: 0.3300\n",
            "Epoch 3/150 - 0.11s - loss: 1.1009 - acc: 0.3484 - val_loss: 1.1052 - val_acc: 0.3441\n",
            "Epoch 4/150 - 0.10s - loss: 1.0989 - acc: 0.3614 - val_loss: 1.1034 - val_acc: 0.3421\n",
            "Epoch 5/150 - 0.10s - loss: 1.0973 - acc: 0.3623 - val_loss: 1.1021 - val_acc: 0.3320\n",
            "Epoch 6/150 - 0.11s - loss: 1.0958 - acc: 0.3668 - val_loss: 1.1009 - val_acc: 0.3259\n",
            "Epoch 7/150 - 0.10s - loss: 1.0945 - acc: 0.3745 - val_loss: 1.0998 - val_acc: 0.3279\n",
            "Epoch 8/150 - 0.10s - loss: 1.0932 - acc: 0.3772 - val_loss: 1.0987 - val_acc: 0.3300\n",
            "Epoch 9/150 - 0.11s - loss: 1.0920 - acc: 0.3824 - val_loss: 1.0975 - val_acc: 0.3502\n",
            "Epoch 10/150 - 0.12s - loss: 1.0908 - acc: 0.3860 - val_loss: 1.0966 - val_acc: 0.3664\n",
            "Epoch 11/150 - 0.11s - loss: 1.0896 - acc: 0.3911 - val_loss: 1.0956 - val_acc: 0.3745\n",
            "Epoch 12/150 - 0.10s - loss: 1.0885 - acc: 0.3972 - val_loss: 1.0947 - val_acc: 0.3765\n",
            "Epoch 13/150 - 0.10s - loss: 1.0874 - acc: 0.3988 - val_loss: 1.0939 - val_acc: 0.3806\n",
            "Epoch 14/150 - 0.12s - loss: 1.0864 - acc: 0.4026 - val_loss: 1.0929 - val_acc: 0.3866\n",
            "Epoch 15/150 - 0.12s - loss: 1.0853 - acc: 0.4082 - val_loss: 1.0920 - val_acc: 0.3887\n",
            "Epoch 16/150 - 0.10s - loss: 1.0843 - acc: 0.4116 - val_loss: 1.0912 - val_acc: 0.3887\n",
            "Epoch 17/150 - 0.10s - loss: 1.0834 - acc: 0.4127 - val_loss: 1.0905 - val_acc: 0.3927\n",
            "Epoch 18/150 - 0.11s - loss: 1.0824 - acc: 0.4166 - val_loss: 1.0897 - val_acc: 0.3887\n",
            "Epoch 19/150 - 0.10s - loss: 1.0815 - acc: 0.4231 - val_loss: 1.0889 - val_acc: 0.3968\n",
            "Epoch 20/150 - 0.10s - loss: 1.0806 - acc: 0.4258 - val_loss: 1.0882 - val_acc: 0.3947\n",
            "Epoch 21/150 - 0.12s - loss: 1.0798 - acc: 0.4274 - val_loss: 1.0875 - val_acc: 0.4028\n",
            "Epoch 22/150 - 0.10s - loss: 1.0789 - acc: 0.4309 - val_loss: 1.0868 - val_acc: 0.4008\n",
            "Epoch 23/150 - 0.10s - loss: 1.0781 - acc: 0.4289 - val_loss: 1.0862 - val_acc: 0.4130\n",
            "Epoch 24/150 - 0.11s - loss: 1.0772 - acc: 0.4312 - val_loss: 1.0855 - val_acc: 0.4130\n",
            "Epoch 25/150 - 0.10s - loss: 1.0764 - acc: 0.4300 - val_loss: 1.0849 - val_acc: 0.4089\n",
            "Epoch 26/150 - 0.10s - loss: 1.0757 - acc: 0.4316 - val_loss: 1.0842 - val_acc: 0.4231\n",
            "Epoch 27/150 - 0.10s - loss: 1.0749 - acc: 0.4334 - val_loss: 1.0837 - val_acc: 0.4109\n",
            "Epoch 28/150 - 0.10s - loss: 1.0742 - acc: 0.4318 - val_loss: 1.0831 - val_acc: 0.4130\n",
            "Epoch 29/150 - 0.10s - loss: 1.0734 - acc: 0.4318 - val_loss: 1.0825 - val_acc: 0.4271\n",
            "Epoch 30/150 - 0.11s - loss: 1.0727 - acc: 0.4332 - val_loss: 1.0819 - val_acc: 0.4271\n",
            "Epoch 31/150 - 0.10s - loss: 1.0720 - acc: 0.4348 - val_loss: 1.0814 - val_acc: 0.4251\n",
            "Epoch 32/150 - 0.10s - loss: 1.0713 - acc: 0.4366 - val_loss: 1.0808 - val_acc: 0.4332\n",
            "Epoch 33/150 - 0.11s - loss: 1.0706 - acc: 0.4381 - val_loss: 1.0803 - val_acc: 0.4352\n",
            "Epoch 34/150 - 0.10s - loss: 1.0699 - acc: 0.4393 - val_loss: 1.0798 - val_acc: 0.4372\n",
            "Epoch 35/150 - 0.10s - loss: 1.0693 - acc: 0.4390 - val_loss: 1.0793 - val_acc: 0.4332\n",
            "Epoch 36/150 - 0.11s - loss: 1.0686 - acc: 0.4404 - val_loss: 1.0788 - val_acc: 0.4291\n",
            "Epoch 37/150 - 0.10s - loss: 1.0680 - acc: 0.4393 - val_loss: 1.0782 - val_acc: 0.4312\n",
            "Epoch 38/150 - 0.11s - loss: 1.0674 - acc: 0.4393 - val_loss: 1.0778 - val_acc: 0.4312\n",
            "Epoch 39/150 - 0.10s - loss: 1.0668 - acc: 0.4397 - val_loss: 1.0773 - val_acc: 0.4312\n",
            "Epoch 40/150 - 0.11s - loss: 1.0661 - acc: 0.4408 - val_loss: 1.0768 - val_acc: 0.4312\n",
            "Epoch 41/150 - 0.10s - loss: 1.0655 - acc: 0.4413 - val_loss: 1.0764 - val_acc: 0.4291\n",
            "Epoch 42/150 - 0.11s - loss: 1.0650 - acc: 0.4422 - val_loss: 1.0759 - val_acc: 0.4312\n",
            "Epoch 43/150 - 0.10s - loss: 1.0644 - acc: 0.4417 - val_loss: 1.0755 - val_acc: 0.4312\n",
            "Epoch 44/150 - 0.11s - loss: 1.0638 - acc: 0.4438 - val_loss: 1.0751 - val_acc: 0.4312\n",
            "Epoch 45/150 - 0.10s - loss: 1.0632 - acc: 0.4438 - val_loss: 1.0746 - val_acc: 0.4332\n",
            "Epoch 46/150 - 0.10s - loss: 1.0627 - acc: 0.4458 - val_loss: 1.0742 - val_acc: 0.4332\n",
            "Epoch 47/150 - 0.13s - loss: 1.0621 - acc: 0.4458 - val_loss: 1.0738 - val_acc: 0.4312\n",
            "Epoch 48/150 - 0.10s - loss: 1.0615 - acc: 0.4447 - val_loss: 1.0734 - val_acc: 0.4291\n",
            "Epoch 49/150 - 0.10s - loss: 1.0610 - acc: 0.4471 - val_loss: 1.0730 - val_acc: 0.4332\n",
            "Epoch 50/150 - 0.10s - loss: 1.0605 - acc: 0.4487 - val_loss: 1.0726 - val_acc: 0.4352\n",
            "Epoch 51/150 - 0.10s - loss: 1.0599 - acc: 0.4494 - val_loss: 1.0722 - val_acc: 0.4312\n",
            "Epoch 52/150 - 0.10s - loss: 1.0594 - acc: 0.4494 - val_loss: 1.0718 - val_acc: 0.4332\n",
            "Epoch 53/150 - 0.11s - loss: 1.0589 - acc: 0.4519 - val_loss: 1.0713 - val_acc: 0.4332\n",
            "Epoch 54/150 - 0.10s - loss: 1.0584 - acc: 0.4523 - val_loss: 1.0710 - val_acc: 0.4312\n",
            "Epoch 55/150 - 0.10s - loss: 1.0579 - acc: 0.4539 - val_loss: 1.0706 - val_acc: 0.4372\n",
            "Epoch 56/150 - 0.11s - loss: 1.0574 - acc: 0.4543 - val_loss: 1.0702 - val_acc: 0.4372\n",
            "Epoch 57/150 - 0.10s - loss: 1.0569 - acc: 0.4570 - val_loss: 1.0698 - val_acc: 0.4433\n",
            "Epoch 58/150 - 0.10s - loss: 1.0564 - acc: 0.4568 - val_loss: 1.0695 - val_acc: 0.4433\n",
            "Epoch 59/150 - 0.11s - loss: 1.0559 - acc: 0.4586 - val_loss: 1.0691 - val_acc: 0.4413\n",
            "Epoch 60/150 - 0.10s - loss: 1.0554 - acc: 0.4575 - val_loss: 1.0688 - val_acc: 0.4413\n",
            "Epoch 61/150 - 0.10s - loss: 1.0549 - acc: 0.4575 - val_loss: 1.0683 - val_acc: 0.4413\n",
            "Epoch 62/150 - 0.11s - loss: 1.0544 - acc: 0.4591 - val_loss: 1.0680 - val_acc: 0.4433\n",
            "Epoch 63/150 - 0.10s - loss: 1.0539 - acc: 0.4600 - val_loss: 1.0676 - val_acc: 0.4433\n",
            "Epoch 64/150 - 0.10s - loss: 1.0535 - acc: 0.4595 - val_loss: 1.0673 - val_acc: 0.4453\n",
            "Epoch 65/150 - 0.11s - loss: 1.0530 - acc: 0.4584 - val_loss: 1.0670 - val_acc: 0.4453\n",
            "Epoch 66/150 - 0.10s - loss: 1.0525 - acc: 0.4577 - val_loss: 1.0667 - val_acc: 0.4433\n",
            "Epoch 67/150 - 0.10s - loss: 1.0521 - acc: 0.4609 - val_loss: 1.0663 - val_acc: 0.4433\n",
            "Epoch 68/150 - 0.11s - loss: 1.0516 - acc: 0.4613 - val_loss: 1.0660 - val_acc: 0.4474\n",
            "Epoch 69/150 - 0.10s - loss: 1.0512 - acc: 0.4615 - val_loss: 1.0657 - val_acc: 0.4433\n",
            "Epoch 70/150 - 0.10s - loss: 1.0507 - acc: 0.4636 - val_loss: 1.0653 - val_acc: 0.4453\n",
            "Epoch 71/150 - 0.11s - loss: 1.0502 - acc: 0.4620 - val_loss: 1.0650 - val_acc: 0.4433\n",
            "Epoch 72/150 - 0.11s - loss: 1.0498 - acc: 0.4638 - val_loss: 1.0645 - val_acc: 0.4433\n",
            "Epoch 73/150 - 0.10s - loss: 1.0494 - acc: 0.4638 - val_loss: 1.0643 - val_acc: 0.4474\n",
            "Epoch 74/150 - 0.12s - loss: 1.0489 - acc: 0.4647 - val_loss: 1.0640 - val_acc: 0.4494\n",
            "Epoch 75/150 - 0.11s - loss: 1.0485 - acc: 0.4647 - val_loss: 1.0635 - val_acc: 0.4494\n",
            "Epoch 76/150 - 0.10s - loss: 1.0480 - acc: 0.4645 - val_loss: 1.0633 - val_acc: 0.4474\n",
            "Epoch 77/150 - 0.10s - loss: 1.0476 - acc: 0.4654 - val_loss: 1.0630 - val_acc: 0.4494\n",
            "Epoch 78/150 - 0.11s - loss: 1.0472 - acc: 0.4660 - val_loss: 1.0626 - val_acc: 0.4514\n",
            "Epoch 79/150 - 0.11s - loss: 1.0467 - acc: 0.4663 - val_loss: 1.0623 - val_acc: 0.4534\n",
            "Epoch 80/150 - 0.11s - loss: 1.0463 - acc: 0.4674 - val_loss: 1.0620 - val_acc: 0.4555\n",
            "Epoch 81/150 - 0.10s - loss: 1.0459 - acc: 0.4685 - val_loss: 1.0618 - val_acc: 0.4555\n",
            "Epoch 82/150 - 0.12s - loss: 1.0455 - acc: 0.4681 - val_loss: 1.0614 - val_acc: 0.4575\n",
            "Epoch 83/150 - 0.10s - loss: 1.0450 - acc: 0.4694 - val_loss: 1.0610 - val_acc: 0.4656\n",
            "Epoch 84/150 - 0.11s - loss: 1.0446 - acc: 0.4701 - val_loss: 1.0607 - val_acc: 0.4615\n",
            "Epoch 85/150 - 0.10s - loss: 1.0442 - acc: 0.4701 - val_loss: 1.0605 - val_acc: 0.4595\n",
            "Epoch 86/150 - 0.11s - loss: 1.0438 - acc: 0.4723 - val_loss: 1.0601 - val_acc: 0.4717\n",
            "Epoch 87/150 - 0.10s - loss: 1.0434 - acc: 0.4717 - val_loss: 1.0599 - val_acc: 0.4636\n",
            "Epoch 88/150 - 0.11s - loss: 1.0430 - acc: 0.4728 - val_loss: 1.0595 - val_acc: 0.4717\n",
            "Epoch 89/150 - 0.10s - loss: 1.0426 - acc: 0.4728 - val_loss: 1.0593 - val_acc: 0.4696\n",
            "Epoch 90/150 - 0.11s - loss: 1.0422 - acc: 0.4741 - val_loss: 1.0589 - val_acc: 0.4696\n",
            "Epoch 91/150 - 0.12s - loss: 1.0417 - acc: 0.4741 - val_loss: 1.0586 - val_acc: 0.4737\n",
            "Epoch 92/150 - 0.12s - loss: 1.0413 - acc: 0.4750 - val_loss: 1.0584 - val_acc: 0.4757\n",
            "Epoch 93/150 - 0.10s - loss: 1.0409 - acc: 0.4753 - val_loss: 1.0581 - val_acc: 0.4757\n",
            "Epoch 94/150 - 0.11s - loss: 1.0405 - acc: 0.4773 - val_loss: 1.0578 - val_acc: 0.4737\n",
            "Epoch 95/150 - 0.10s - loss: 1.0401 - acc: 0.4773 - val_loss: 1.0575 - val_acc: 0.4757\n",
            "Epoch 96/150 - 0.11s - loss: 1.0397 - acc: 0.4775 - val_loss: 1.0572 - val_acc: 0.4777\n",
            "Epoch 97/150 - 0.10s - loss: 1.0393 - acc: 0.4786 - val_loss: 1.0569 - val_acc: 0.4777\n",
            "Epoch 98/150 - 0.11s - loss: 1.0390 - acc: 0.4780 - val_loss: 1.0565 - val_acc: 0.4818\n",
            "Epoch 99/150 - 0.10s - loss: 1.0386 - acc: 0.4793 - val_loss: 1.0563 - val_acc: 0.4777\n",
            "Epoch 100/150 - 0.11s - loss: 1.0382 - acc: 0.4795 - val_loss: 1.0561 - val_acc: 0.4757\n",
            "Epoch 101/150 - 0.10s - loss: 1.0378 - acc: 0.4802 - val_loss: 1.0558 - val_acc: 0.4757\n",
            "Epoch 102/150 - 0.11s - loss: 1.0374 - acc: 0.4802 - val_loss: 1.0554 - val_acc: 0.4757\n",
            "Epoch 103/150 - 0.10s - loss: 1.0370 - acc: 0.4811 - val_loss: 1.0551 - val_acc: 0.4757\n",
            "Epoch 104/150 - 0.10s - loss: 1.0366 - acc: 0.4804 - val_loss: 1.0548 - val_acc: 0.4757\n",
            "Epoch 105/150 - 0.11s - loss: 1.0363 - acc: 0.4807 - val_loss: 1.0545 - val_acc: 0.4757\n",
            "Epoch 106/150 - 0.10s - loss: 1.0358 - acc: 0.4831 - val_loss: 1.0543 - val_acc: 0.4757\n",
            "Epoch 107/150 - 0.10s - loss: 1.0355 - acc: 0.4836 - val_loss: 1.0540 - val_acc: 0.4757\n",
            "Epoch 108/150 - 0.11s - loss: 1.0351 - acc: 0.4829 - val_loss: 1.0538 - val_acc: 0.4777\n",
            "Epoch 109/150 - 0.10s - loss: 1.0347 - acc: 0.4831 - val_loss: 1.0535 - val_acc: 0.4777\n",
            "Epoch 110/150 - 0.11s - loss: 1.0343 - acc: 0.4831 - val_loss: 1.0533 - val_acc: 0.4777\n",
            "Epoch 111/150 - 0.10s - loss: 1.0339 - acc: 0.4843 - val_loss: 1.0529 - val_acc: 0.4737\n",
            "Epoch 112/150 - 0.10s - loss: 1.0335 - acc: 0.4840 - val_loss: 1.0526 - val_acc: 0.4717\n",
            "Epoch 113/150 - 0.13s - loss: 1.0332 - acc: 0.4847 - val_loss: 1.0524 - val_acc: 0.4777\n",
            "Epoch 114/150 - 0.10s - loss: 1.0328 - acc: 0.4852 - val_loss: 1.0521 - val_acc: 0.4757\n",
            "Epoch 115/150 - 0.10s - loss: 1.0324 - acc: 0.4883 - val_loss: 1.0519 - val_acc: 0.4798\n",
            "Epoch 116/150 - 0.11s - loss: 1.0320 - acc: 0.4863 - val_loss: 1.0515 - val_acc: 0.4777\n",
            "Epoch 117/150 - 0.10s - loss: 1.0317 - acc: 0.4894 - val_loss: 1.0513 - val_acc: 0.4798\n",
            "Epoch 118/150 - 0.10s - loss: 1.0313 - acc: 0.4888 - val_loss: 1.0510 - val_acc: 0.4757\n",
            "Epoch 119/150 - 0.12s - loss: 1.0309 - acc: 0.4901 - val_loss: 1.0507 - val_acc: 0.4798\n",
            "Epoch 120/150 - 0.10s - loss: 1.0306 - acc: 0.4890 - val_loss: 1.0504 - val_acc: 0.4798\n",
            "Epoch 121/150 - 0.10s - loss: 1.0302 - acc: 0.4883 - val_loss: 1.0501 - val_acc: 0.4818\n",
            "Epoch 122/150 - 0.11s - loss: 1.0298 - acc: 0.4903 - val_loss: 1.0499 - val_acc: 0.4798\n",
            "Epoch 123/150 - 0.10s - loss: 1.0294 - acc: 0.4899 - val_loss: 1.0496 - val_acc: 0.4798\n",
            "Epoch 124/150 - 0.10s - loss: 1.0291 - acc: 0.4912 - val_loss: 1.0493 - val_acc: 0.4777\n",
            "Epoch 125/150 - 0.12s - loss: 1.0287 - acc: 0.4903 - val_loss: 1.0490 - val_acc: 0.4798\n",
            "Epoch 126/150 - 0.12s - loss: 1.0283 - acc: 0.4917 - val_loss: 1.0487 - val_acc: 0.4798\n",
            "Epoch 127/150 - 0.11s - loss: 1.0280 - acc: 0.4946 - val_loss: 1.0486 - val_acc: 0.4818\n",
            "Epoch 128/150 - 0.10s - loss: 1.0276 - acc: 0.4953 - val_loss: 1.0483 - val_acc: 0.4818\n",
            "Epoch 129/150 - 0.10s - loss: 1.0272 - acc: 0.4948 - val_loss: 1.0480 - val_acc: 0.4818\n",
            "Epoch 130/150 - 0.11s - loss: 1.0269 - acc: 0.4944 - val_loss: 1.0476 - val_acc: 0.4798\n",
            "Epoch 131/150 - 0.10s - loss: 1.0265 - acc: 0.4948 - val_loss: 1.0473 - val_acc: 0.4798\n",
            "Epoch 132/150 - 0.10s - loss: 1.0261 - acc: 0.4966 - val_loss: 1.0471 - val_acc: 0.4838\n",
            "Epoch 133/150 - 0.10s - loss: 1.0258 - acc: 0.4980 - val_loss: 1.0470 - val_acc: 0.4818\n",
            "Epoch 134/150 - 0.10s - loss: 1.0254 - acc: 0.4993 - val_loss: 1.0467 - val_acc: 0.4838\n",
            "Epoch 135/150 - 0.10s - loss: 1.0251 - acc: 0.4993 - val_loss: 1.0464 - val_acc: 0.4858\n",
            "Epoch 136/150 - 0.10s - loss: 1.0247 - acc: 0.5004 - val_loss: 1.0462 - val_acc: 0.4838\n",
            "Epoch 137/150 - 0.10s - loss: 1.0244 - acc: 0.5009 - val_loss: 1.0460 - val_acc: 0.4838\n",
            "Epoch 138/150 - 0.10s - loss: 1.0240 - acc: 0.4991 - val_loss: 1.0456 - val_acc: 0.4838\n",
            "Epoch 139/150 - 0.11s - loss: 1.0236 - acc: 0.5016 - val_loss: 1.0454 - val_acc: 0.4858\n",
            "Epoch 140/150 - 0.10s - loss: 1.0233 - acc: 0.5020 - val_loss: 1.0452 - val_acc: 0.4858\n",
            "Epoch 141/150 - 0.10s - loss: 1.0229 - acc: 0.5025 - val_loss: 1.0449 - val_acc: 0.4919\n",
            "Epoch 142/150 - 0.10s - loss: 1.0226 - acc: 0.5025 - val_loss: 1.0445 - val_acc: 0.4879\n",
            "Epoch 143/150 - 0.10s - loss: 1.0222 - acc: 0.5025 - val_loss: 1.0442 - val_acc: 0.4899\n",
            "Epoch 144/150 - 0.10s - loss: 1.0218 - acc: 0.5034 - val_loss: 1.0440 - val_acc: 0.4899\n",
            "Epoch 145/150 - 0.10s - loss: 1.0215 - acc: 0.5040 - val_loss: 1.0438 - val_acc: 0.4919\n",
            "Epoch 146/150 - 0.10s - loss: 1.0211 - acc: 0.5040 - val_loss: 1.0435 - val_acc: 0.4899\n",
            "Epoch 147/150 - 0.10s - loss: 1.0208 - acc: 0.5029 - val_loss: 1.0432 - val_acc: 0.4899\n",
            "Epoch 148/150 - 0.11s - loss: 1.0204 - acc: 0.5029 - val_loss: 1.0429 - val_acc: 0.4919\n",
            "Epoch 149/150 - 0.10s - loss: 1.0201 - acc: 0.5034 - val_loss: 1.0427 - val_acc: 0.4919\n",
            "Epoch 150/150 - 0.10s - loss: 1.0197 - acc: 0.5036 - val_loss: 1.0425 - val_acc: 0.4919\n",
            "\n",
            "Combination 103/252:\n",
            "Hidden Layers: [128, 128], Activation: tanh, Learning Rate: 0.0001, Batch Size: 32, Epochs: 50\n",
            "Epoch 1/50 - 0.14s - loss: 1.1122 - acc: 0.3165 - val_loss: 1.1155 - val_acc: 0.2834\n",
            "Epoch 2/50 - 0.12s - loss: 1.1109 - acc: 0.3167 - val_loss: 1.1139 - val_acc: 0.2874\n",
            "Epoch 3/50 - 0.13s - loss: 1.1098 - acc: 0.3113 - val_loss: 1.1125 - val_acc: 0.2895\n",
            "Epoch 4/50 - 0.12s - loss: 1.1088 - acc: 0.3095 - val_loss: 1.1113 - val_acc: 0.2794\n",
            "Epoch 5/50 - 0.12s - loss: 1.1079 - acc: 0.3095 - val_loss: 1.1103 - val_acc: 0.2895\n",
            "Epoch 6/50 - 0.12s - loss: 1.1071 - acc: 0.3097 - val_loss: 1.1093 - val_acc: 0.2834\n",
            "Epoch 7/50 - 0.12s - loss: 1.1064 - acc: 0.3057 - val_loss: 1.1085 - val_acc: 0.2895\n",
            "Epoch 8/50 - 0.12s - loss: 1.1058 - acc: 0.3088 - val_loss: 1.1077 - val_acc: 0.2976\n",
            "Epoch 9/50 - 0.13s - loss: 1.1052 - acc: 0.3090 - val_loss: 1.1071 - val_acc: 0.3016\n",
            "Epoch 10/50 - 0.12s - loss: 1.1046 - acc: 0.3104 - val_loss: 1.1064 - val_acc: 0.3016\n",
            "Epoch 11/50 - 0.12s - loss: 1.1041 - acc: 0.3124 - val_loss: 1.1058 - val_acc: 0.3036\n",
            "Epoch 12/50 - 0.13s - loss: 1.1036 - acc: 0.3129 - val_loss: 1.1053 - val_acc: 0.3036\n",
            "Epoch 13/50 - 0.12s - loss: 1.1032 - acc: 0.3138 - val_loss: 1.1048 - val_acc: 0.3016\n",
            "Epoch 14/50 - 0.12s - loss: 1.1027 - acc: 0.3129 - val_loss: 1.1043 - val_acc: 0.2976\n",
            "Epoch 15/50 - 0.13s - loss: 1.1023 - acc: 0.3158 - val_loss: 1.1039 - val_acc: 0.3036\n",
            "Epoch 16/50 - 0.12s - loss: 1.1018 - acc: 0.3165 - val_loss: 1.1034 - val_acc: 0.3016\n",
            "Epoch 17/50 - 0.13s - loss: 1.1014 - acc: 0.3196 - val_loss: 1.1030 - val_acc: 0.3117\n",
            "Epoch 18/50 - 0.13s - loss: 1.1010 - acc: 0.3207 - val_loss: 1.1026 - val_acc: 0.3158\n",
            "Epoch 19/50 - 0.12s - loss: 1.1006 - acc: 0.3221 - val_loss: 1.1022 - val_acc: 0.3198\n",
            "Epoch 20/50 - 0.12s - loss: 1.1002 - acc: 0.3232 - val_loss: 1.1018 - val_acc: 0.3239\n",
            "Epoch 21/50 - 0.12s - loss: 1.0998 - acc: 0.3234 - val_loss: 1.1015 - val_acc: 0.3300\n",
            "Epoch 22/50 - 0.12s - loss: 1.0995 - acc: 0.3246 - val_loss: 1.1011 - val_acc: 0.3340\n",
            "Epoch 23/50 - 0.13s - loss: 1.0991 - acc: 0.3252 - val_loss: 1.1007 - val_acc: 0.3381\n",
            "Epoch 24/50 - 0.12s - loss: 1.0987 - acc: 0.3264 - val_loss: 1.1004 - val_acc: 0.3381\n",
            "Epoch 25/50 - 0.12s - loss: 1.0983 - acc: 0.3279 - val_loss: 1.1001 - val_acc: 0.3441\n",
            "Epoch 26/50 - 0.12s - loss: 1.0980 - acc: 0.3300 - val_loss: 1.0997 - val_acc: 0.3502\n",
            "Epoch 27/50 - 0.14s - loss: 1.0976 - acc: 0.3315 - val_loss: 1.0994 - val_acc: 0.3543\n",
            "Epoch 28/50 - 0.12s - loss: 1.0973 - acc: 0.3315 - val_loss: 1.0991 - val_acc: 0.3623\n",
            "Epoch 29/50 - 0.12s - loss: 1.0969 - acc: 0.3329 - val_loss: 1.0988 - val_acc: 0.3623\n",
            "Epoch 30/50 - 0.12s - loss: 1.0966 - acc: 0.3342 - val_loss: 1.0985 - val_acc: 0.3583\n",
            "Epoch 31/50 - 0.12s - loss: 1.0962 - acc: 0.3374 - val_loss: 1.0982 - val_acc: 0.3583\n",
            "Epoch 32/50 - 0.12s - loss: 1.0959 - acc: 0.3390 - val_loss: 1.0979 - val_acc: 0.3603\n",
            "Epoch 33/50 - 0.12s - loss: 1.0956 - acc: 0.3399 - val_loss: 1.0976 - val_acc: 0.3603\n",
            "Epoch 34/50 - 0.12s - loss: 1.0952 - acc: 0.3405 - val_loss: 1.0973 - val_acc: 0.3603\n",
            "Epoch 35/50 - 0.12s - loss: 1.0949 - acc: 0.3423 - val_loss: 1.0970 - val_acc: 0.3563\n",
            "Epoch 36/50 - 0.13s - loss: 1.0946 - acc: 0.3435 - val_loss: 1.0967 - val_acc: 0.3563\n",
            "Epoch 37/50 - 0.13s - loss: 1.0943 - acc: 0.3459 - val_loss: 1.0965 - val_acc: 0.3563\n",
            "Epoch 38/50 - 0.13s - loss: 1.0939 - acc: 0.3480 - val_loss: 1.0962 - val_acc: 0.3583\n",
            "Epoch 39/50 - 0.13s - loss: 1.0936 - acc: 0.3477 - val_loss: 1.0959 - val_acc: 0.3583\n",
            "Epoch 40/50 - 0.12s - loss: 1.0933 - acc: 0.3511 - val_loss: 1.0956 - val_acc: 0.3603\n",
            "Epoch 41/50 - 0.12s - loss: 1.0930 - acc: 0.3536 - val_loss: 1.0954 - val_acc: 0.3623\n",
            "Epoch 42/50 - 0.12s - loss: 1.0927 - acc: 0.3529 - val_loss: 1.0951 - val_acc: 0.3704\n",
            "Epoch 43/50 - 0.12s - loss: 1.0924 - acc: 0.3565 - val_loss: 1.0948 - val_acc: 0.3704\n",
            "Epoch 44/50 - 0.12s - loss: 1.0921 - acc: 0.3572 - val_loss: 1.0946 - val_acc: 0.3644\n",
            "Epoch 45/50 - 0.13s - loss: 1.0918 - acc: 0.3585 - val_loss: 1.0943 - val_acc: 0.3623\n",
            "Epoch 46/50 - 0.12s - loss: 1.0915 - acc: 0.3594 - val_loss: 1.0941 - val_acc: 0.3664\n",
            "Epoch 47/50 - 0.13s - loss: 1.0912 - acc: 0.3612 - val_loss: 1.0938 - val_acc: 0.3684\n",
            "Epoch 48/50 - 0.12s - loss: 1.0909 - acc: 0.3617 - val_loss: 1.0936 - val_acc: 0.3704\n",
            "Epoch 49/50 - 0.13s - loss: 1.0906 - acc: 0.3646 - val_loss: 1.0933 - val_acc: 0.3704\n",
            "Epoch 50/50 - 0.13s - loss: 1.0903 - acc: 0.3653 - val_loss: 1.0931 - val_acc: 0.3765\n",
            "\n",
            "Combination 104/252:\n",
            "Hidden Layers: [128, 128], Activation: tanh, Learning Rate: 0.0001, Batch Size: 32, Epochs: 100\n",
            "Epoch 1/100 - 0.14s - loss: 1.0948 - acc: 0.3567 - val_loss: 1.0929 - val_acc: 0.3543\n",
            "Epoch 2/100 - 0.12s - loss: 1.0945 - acc: 0.3621 - val_loss: 1.0926 - val_acc: 0.3583\n",
            "Epoch 3/100 - 0.14s - loss: 1.0942 - acc: 0.3628 - val_loss: 1.0923 - val_acc: 0.3704\n",
            "Epoch 4/100 - 0.14s - loss: 1.0939 - acc: 0.3637 - val_loss: 1.0921 - val_acc: 0.3704\n",
            "Epoch 5/100 - 0.14s - loss: 1.0937 - acc: 0.3664 - val_loss: 1.0919 - val_acc: 0.3725\n",
            "Epoch 6/100 - 0.13s - loss: 1.0934 - acc: 0.3671 - val_loss: 1.0916 - val_acc: 0.3725\n",
            "Epoch 7/100 - 0.13s - loss: 1.0931 - acc: 0.3671 - val_loss: 1.0914 - val_acc: 0.3745\n",
            "Epoch 8/100 - 0.12s - loss: 1.0929 - acc: 0.3691 - val_loss: 1.0912 - val_acc: 0.3806\n",
            "Epoch 9/100 - 0.13s - loss: 1.0926 - acc: 0.3713 - val_loss: 1.0910 - val_acc: 0.3765\n",
            "Epoch 10/100 - 0.13s - loss: 1.0924 - acc: 0.3743 - val_loss: 1.0908 - val_acc: 0.3785\n",
            "Epoch 11/100 - 0.14s - loss: 1.0921 - acc: 0.3754 - val_loss: 1.0905 - val_acc: 0.3745\n",
            "Epoch 12/100 - 0.13s - loss: 1.0919 - acc: 0.3779 - val_loss: 1.0903 - val_acc: 0.3725\n",
            "Epoch 13/100 - 0.13s - loss: 1.0917 - acc: 0.3803 - val_loss: 1.0901 - val_acc: 0.3684\n",
            "Epoch 14/100 - 0.12s - loss: 1.0914 - acc: 0.3815 - val_loss: 1.0899 - val_acc: 0.3684\n",
            "Epoch 15/100 - 0.13s - loss: 1.0912 - acc: 0.3815 - val_loss: 1.0897 - val_acc: 0.3725\n",
            "Epoch 16/100 - 0.13s - loss: 1.0910 - acc: 0.3824 - val_loss: 1.0895 - val_acc: 0.3806\n",
            "Epoch 17/100 - 0.13s - loss: 1.0907 - acc: 0.3819 - val_loss: 1.0893 - val_acc: 0.3846\n",
            "Epoch 18/100 - 0.12s - loss: 1.0905 - acc: 0.3821 - val_loss: 1.0891 - val_acc: 0.3806\n",
            "Epoch 19/100 - 0.13s - loss: 1.0903 - acc: 0.3830 - val_loss: 1.0890 - val_acc: 0.3806\n",
            "Epoch 20/100 - 0.12s - loss: 1.0901 - acc: 0.3824 - val_loss: 1.0888 - val_acc: 0.3887\n",
            "Epoch 21/100 - 0.14s - loss: 1.0899 - acc: 0.3821 - val_loss: 1.0886 - val_acc: 0.3907\n",
            "Epoch 22/100 - 0.13s - loss: 1.0896 - acc: 0.3835 - val_loss: 1.0884 - val_acc: 0.3907\n",
            "Epoch 23/100 - 0.13s - loss: 1.0894 - acc: 0.3842 - val_loss: 1.0882 - val_acc: 0.3907\n",
            "Epoch 24/100 - 0.13s - loss: 1.0892 - acc: 0.3857 - val_loss: 1.0880 - val_acc: 0.3907\n",
            "Epoch 25/100 - 0.13s - loss: 1.0890 - acc: 0.3871 - val_loss: 1.0878 - val_acc: 0.3866\n",
            "Epoch 26/100 - 0.12s - loss: 1.0888 - acc: 0.3884 - val_loss: 1.0876 - val_acc: 0.3866\n",
            "Epoch 27/100 - 0.13s - loss: 1.0886 - acc: 0.3891 - val_loss: 1.0875 - val_acc: 0.3866\n",
            "Epoch 28/100 - 0.13s - loss: 1.0884 - acc: 0.3887 - val_loss: 1.0873 - val_acc: 0.3866\n",
            "Epoch 29/100 - 0.14s - loss: 1.0881 - acc: 0.3898 - val_loss: 1.0871 - val_acc: 0.3887\n",
            "Epoch 30/100 - 0.13s - loss: 1.0879 - acc: 0.3905 - val_loss: 1.0869 - val_acc: 0.3887\n",
            "Epoch 31/100 - 0.13s - loss: 1.0877 - acc: 0.3914 - val_loss: 1.0867 - val_acc: 0.3907\n",
            "Epoch 32/100 - 0.13s - loss: 1.0875 - acc: 0.3927 - val_loss: 1.0866 - val_acc: 0.3907\n",
            "Epoch 33/100 - 0.13s - loss: 1.0873 - acc: 0.3941 - val_loss: 1.0864 - val_acc: 0.3927\n",
            "Epoch 34/100 - 0.13s - loss: 1.0871 - acc: 0.3947 - val_loss: 1.0862 - val_acc: 0.3927\n",
            "Epoch 35/100 - 0.14s - loss: 1.0869 - acc: 0.3959 - val_loss: 1.0860 - val_acc: 0.3927\n",
            "Epoch 36/100 - 0.13s - loss: 1.0867 - acc: 0.3959 - val_loss: 1.0859 - val_acc: 0.3947\n",
            "Epoch 37/100 - 0.13s - loss: 1.0865 - acc: 0.3965 - val_loss: 1.0857 - val_acc: 0.3968\n",
            "Epoch 38/100 - 0.12s - loss: 1.0863 - acc: 0.3986 - val_loss: 1.0855 - val_acc: 0.3968\n",
            "Epoch 39/100 - 0.13s - loss: 1.0861 - acc: 0.3992 - val_loss: 1.0853 - val_acc: 0.3968\n",
            "Epoch 40/100 - 0.12s - loss: 1.0859 - acc: 0.3990 - val_loss: 1.0852 - val_acc: 0.3968\n",
            "Epoch 41/100 - 0.13s - loss: 1.0857 - acc: 0.3983 - val_loss: 1.0850 - val_acc: 0.3947\n",
            "Epoch 42/100 - 0.13s - loss: 1.0856 - acc: 0.3988 - val_loss: 1.0848 - val_acc: 0.3947\n",
            "Epoch 43/100 - 0.13s - loss: 1.0854 - acc: 0.3992 - val_loss: 1.0847 - val_acc: 0.3968\n",
            "Epoch 44/100 - 0.13s - loss: 1.0852 - acc: 0.4001 - val_loss: 1.0845 - val_acc: 0.4008\n",
            "Epoch 45/100 - 0.13s - loss: 1.0850 - acc: 0.4013 - val_loss: 1.0843 - val_acc: 0.4049\n",
            "Epoch 46/100 - 0.13s - loss: 1.0848 - acc: 0.4015 - val_loss: 1.0842 - val_acc: 0.4028\n",
            "Epoch 47/100 - 0.13s - loss: 1.0846 - acc: 0.4026 - val_loss: 1.0840 - val_acc: 0.4049\n",
            "Epoch 48/100 - 0.13s - loss: 1.0844 - acc: 0.4037 - val_loss: 1.0839 - val_acc: 0.4049\n",
            "Epoch 49/100 - 0.14s - loss: 1.0842 - acc: 0.4035 - val_loss: 1.0837 - val_acc: 0.4049\n",
            "Epoch 50/100 - 0.13s - loss: 1.0840 - acc: 0.4031 - val_loss: 1.0835 - val_acc: 0.4049\n",
            "Epoch 51/100 - 0.13s - loss: 1.0839 - acc: 0.4026 - val_loss: 1.0834 - val_acc: 0.4049\n",
            "Epoch 52/100 - 0.12s - loss: 1.0837 - acc: 0.4033 - val_loss: 1.0832 - val_acc: 0.4049\n",
            "Epoch 53/100 - 0.12s - loss: 1.0835 - acc: 0.4024 - val_loss: 1.0831 - val_acc: 0.4049\n",
            "Epoch 54/100 - 0.12s - loss: 1.0833 - acc: 0.4024 - val_loss: 1.0829 - val_acc: 0.4069\n",
            "Epoch 55/100 - 0.12s - loss: 1.0831 - acc: 0.4024 - val_loss: 1.0827 - val_acc: 0.4069\n",
            "Epoch 56/100 - 0.13s - loss: 1.0830 - acc: 0.4031 - val_loss: 1.0826 - val_acc: 0.4069\n",
            "Epoch 57/100 - 0.14s - loss: 1.0828 - acc: 0.4037 - val_loss: 1.0824 - val_acc: 0.4069\n",
            "Epoch 58/100 - 0.12s - loss: 1.0826 - acc: 0.4044 - val_loss: 1.0823 - val_acc: 0.4069\n",
            "Epoch 59/100 - 0.13s - loss: 1.0824 - acc: 0.4042 - val_loss: 1.0821 - val_acc: 0.4049\n",
            "Epoch 60/100 - 0.12s - loss: 1.0822 - acc: 0.4046 - val_loss: 1.0820 - val_acc: 0.4049\n",
            "Epoch 61/100 - 0.12s - loss: 1.0821 - acc: 0.4051 - val_loss: 1.0818 - val_acc: 0.4049\n",
            "Epoch 62/100 - 0.12s - loss: 1.0819 - acc: 0.4046 - val_loss: 1.0817 - val_acc: 0.4028\n",
            "Epoch 63/100 - 0.13s - loss: 1.0817 - acc: 0.4051 - val_loss: 1.0815 - val_acc: 0.4028\n",
            "Epoch 64/100 - 0.12s - loss: 1.0815 - acc: 0.4049 - val_loss: 1.0814 - val_acc: 0.4049\n",
            "Epoch 65/100 - 0.12s - loss: 1.0814 - acc: 0.4053 - val_loss: 1.0812 - val_acc: 0.4028\n",
            "Epoch 66/100 - 0.12s - loss: 1.0812 - acc: 0.4058 - val_loss: 1.0811 - val_acc: 0.4008\n",
            "Epoch 67/100 - 0.13s - loss: 1.0810 - acc: 0.4062 - val_loss: 1.0809 - val_acc: 0.4028\n",
            "Epoch 68/100 - 0.12s - loss: 1.0809 - acc: 0.4060 - val_loss: 1.0808 - val_acc: 0.4028\n",
            "Epoch 69/100 - 0.13s - loss: 1.0807 - acc: 0.4076 - val_loss: 1.0806 - val_acc: 0.4069\n",
            "Epoch 70/100 - 0.12s - loss: 1.0805 - acc: 0.4080 - val_loss: 1.0805 - val_acc: 0.4069\n",
            "Epoch 71/100 - 0.13s - loss: 1.0804 - acc: 0.4100 - val_loss: 1.0804 - val_acc: 0.4049\n",
            "Epoch 72/100 - 0.12s - loss: 1.0802 - acc: 0.4114 - val_loss: 1.0802 - val_acc: 0.4049\n",
            "Epoch 73/100 - 0.13s - loss: 1.0800 - acc: 0.4123 - val_loss: 1.0801 - val_acc: 0.4028\n",
            "Epoch 74/100 - 0.12s - loss: 1.0799 - acc: 0.4118 - val_loss: 1.0799 - val_acc: 0.4049\n",
            "Epoch 75/100 - 0.13s - loss: 1.0797 - acc: 0.4125 - val_loss: 1.0798 - val_acc: 0.4028\n",
            "Epoch 76/100 - 0.14s - loss: 1.0795 - acc: 0.4139 - val_loss: 1.0797 - val_acc: 0.4028\n",
            "Epoch 77/100 - 0.13s - loss: 1.0794 - acc: 0.4139 - val_loss: 1.0795 - val_acc: 0.4028\n",
            "Epoch 78/100 - 0.12s - loss: 1.0792 - acc: 0.4141 - val_loss: 1.0794 - val_acc: 0.4028\n",
            "Epoch 79/100 - 0.12s - loss: 1.0790 - acc: 0.4150 - val_loss: 1.0792 - val_acc: 0.4049\n",
            "Epoch 80/100 - 0.12s - loss: 1.0789 - acc: 0.4159 - val_loss: 1.0791 - val_acc: 0.4069\n",
            "Epoch 81/100 - 0.13s - loss: 1.0787 - acc: 0.4170 - val_loss: 1.0790 - val_acc: 0.4069\n",
            "Epoch 82/100 - 0.13s - loss: 1.0786 - acc: 0.4175 - val_loss: 1.0788 - val_acc: 0.4069\n",
            "Epoch 83/100 - 0.12s - loss: 1.0784 - acc: 0.4184 - val_loss: 1.0787 - val_acc: 0.4069\n",
            "Epoch 84/100 - 0.12s - loss: 1.0783 - acc: 0.4199 - val_loss: 1.0786 - val_acc: 0.4069\n",
            "Epoch 85/100 - 0.12s - loss: 1.0781 - acc: 0.4199 - val_loss: 1.0784 - val_acc: 0.4069\n",
            "Epoch 86/100 - 0.12s - loss: 1.0779 - acc: 0.4199 - val_loss: 1.0783 - val_acc: 0.4089\n",
            "Epoch 87/100 - 0.13s - loss: 1.0778 - acc: 0.4199 - val_loss: 1.0782 - val_acc: 0.4069\n",
            "Epoch 88/100 - 0.12s - loss: 1.0776 - acc: 0.4211 - val_loss: 1.0780 - val_acc: 0.4089\n",
            "Epoch 89/100 - 0.13s - loss: 1.0775 - acc: 0.4224 - val_loss: 1.0779 - val_acc: 0.4089\n",
            "Epoch 90/100 - 0.12s - loss: 1.0773 - acc: 0.4224 - val_loss: 1.0778 - val_acc: 0.4069\n",
            "Epoch 91/100 - 0.12s - loss: 1.0772 - acc: 0.4229 - val_loss: 1.0777 - val_acc: 0.4069\n",
            "Epoch 92/100 - 0.12s - loss: 1.0770 - acc: 0.4242 - val_loss: 1.0775 - val_acc: 0.4028\n",
            "Epoch 93/100 - 0.13s - loss: 1.0769 - acc: 0.4240 - val_loss: 1.0774 - val_acc: 0.4028\n",
            "Epoch 94/100 - 0.12s - loss: 1.0767 - acc: 0.4247 - val_loss: 1.0773 - val_acc: 0.4008\n",
            "Epoch 95/100 - 0.13s - loss: 1.0766 - acc: 0.4258 - val_loss: 1.0771 - val_acc: 0.4008\n",
            "Epoch 96/100 - 0.12s - loss: 1.0764 - acc: 0.4265 - val_loss: 1.0770 - val_acc: 0.4008\n",
            "Epoch 97/100 - 0.12s - loss: 1.0763 - acc: 0.4265 - val_loss: 1.0769 - val_acc: 0.4008\n",
            "Epoch 98/100 - 0.12s - loss: 1.0761 - acc: 0.4262 - val_loss: 1.0768 - val_acc: 0.4008\n",
            "Epoch 99/100 - 0.13s - loss: 1.0760 - acc: 0.4267 - val_loss: 1.0766 - val_acc: 0.4028\n",
            "Epoch 100/100 - 0.14s - loss: 1.0758 - acc: 0.4267 - val_loss: 1.0765 - val_acc: 0.4069\n",
            "\n",
            "Combination 105/252:\n",
            "Hidden Layers: [128, 128], Activation: tanh, Learning Rate: 0.0001, Batch Size: 32, Epochs: 150\n",
            "Epoch 1/150 - 0.13s - loss: 1.0951 - acc: 0.3684 - val_loss: 1.0939 - val_acc: 0.3826\n",
            "Epoch 2/150 - 0.12s - loss: 1.0946 - acc: 0.3664 - val_loss: 1.0934 - val_acc: 0.3826\n",
            "Epoch 3/150 - 0.12s - loss: 1.0942 - acc: 0.3664 - val_loss: 1.0930 - val_acc: 0.3887\n",
            "Epoch 4/150 - 0.12s - loss: 1.0938 - acc: 0.3693 - val_loss: 1.0925 - val_acc: 0.3927\n",
            "Epoch 5/150 - 0.13s - loss: 1.0934 - acc: 0.3725 - val_loss: 1.0922 - val_acc: 0.3927\n",
            "Epoch 6/150 - 0.12s - loss: 1.0931 - acc: 0.3713 - val_loss: 1.0918 - val_acc: 0.3927\n",
            "Epoch 7/150 - 0.13s - loss: 1.0927 - acc: 0.3725 - val_loss: 1.0915 - val_acc: 0.3887\n",
            "Epoch 8/150 - 0.12s - loss: 1.0924 - acc: 0.3713 - val_loss: 1.0912 - val_acc: 0.3947\n",
            "Epoch 9/150 - 0.13s - loss: 1.0921 - acc: 0.3731 - val_loss: 1.0909 - val_acc: 0.3947\n",
            "Epoch 10/150 - 0.12s - loss: 1.0918 - acc: 0.3736 - val_loss: 1.0906 - val_acc: 0.3988\n",
            "Epoch 11/150 - 0.13s - loss: 1.0915 - acc: 0.3745 - val_loss: 1.0903 - val_acc: 0.3988\n",
            "Epoch 12/150 - 0.12s - loss: 1.0912 - acc: 0.3761 - val_loss: 1.0900 - val_acc: 0.4028\n",
            "Epoch 13/150 - 0.13s - loss: 1.0909 - acc: 0.3767 - val_loss: 1.0898 - val_acc: 0.4028\n",
            "Epoch 14/150 - 0.12s - loss: 1.0906 - acc: 0.3803 - val_loss: 1.0895 - val_acc: 0.3968\n",
            "Epoch 15/150 - 0.12s - loss: 1.0903 - acc: 0.3801 - val_loss: 1.0893 - val_acc: 0.3947\n",
            "Epoch 16/150 - 0.12s - loss: 1.0901 - acc: 0.3815 - val_loss: 1.0890 - val_acc: 0.3968\n",
            "Epoch 17/150 - 0.13s - loss: 1.0898 - acc: 0.3830 - val_loss: 1.0888 - val_acc: 0.3968\n",
            "Epoch 18/150 - 0.13s - loss: 1.0895 - acc: 0.3839 - val_loss: 1.0886 - val_acc: 0.3988\n",
            "Epoch 19/150 - 0.14s - loss: 1.0892 - acc: 0.3862 - val_loss: 1.0883 - val_acc: 0.4008\n",
            "Epoch 20/150 - 0.13s - loss: 1.0890 - acc: 0.3880 - val_loss: 1.0881 - val_acc: 0.4089\n",
            "Epoch 21/150 - 0.13s - loss: 1.0887 - acc: 0.3880 - val_loss: 1.0879 - val_acc: 0.4089\n",
            "Epoch 22/150 - 0.12s - loss: 1.0884 - acc: 0.3891 - val_loss: 1.0877 - val_acc: 0.4109\n",
            "Epoch 23/150 - 0.13s - loss: 1.0882 - acc: 0.3907 - val_loss: 1.0875 - val_acc: 0.4130\n",
            "Epoch 24/150 - 0.14s - loss: 1.0879 - acc: 0.3918 - val_loss: 1.0872 - val_acc: 0.4170\n",
            "Epoch 25/150 - 0.13s - loss: 1.0876 - acc: 0.3934 - val_loss: 1.0870 - val_acc: 0.4170\n",
            "Epoch 26/150 - 0.12s - loss: 1.0874 - acc: 0.3954 - val_loss: 1.0868 - val_acc: 0.4190\n",
            "Epoch 27/150 - 0.13s - loss: 1.0871 - acc: 0.3954 - val_loss: 1.0866 - val_acc: 0.4190\n",
            "Epoch 28/150 - 0.12s - loss: 1.0869 - acc: 0.3963 - val_loss: 1.0864 - val_acc: 0.4211\n",
            "Epoch 29/150 - 0.13s - loss: 1.0866 - acc: 0.3952 - val_loss: 1.0862 - val_acc: 0.4211\n",
            "Epoch 30/150 - 0.13s - loss: 1.0864 - acc: 0.3954 - val_loss: 1.0860 - val_acc: 0.4190\n",
            "Epoch 31/150 - 0.12s - loss: 1.0861 - acc: 0.3970 - val_loss: 1.0858 - val_acc: 0.4251\n",
            "Epoch 32/150 - 0.12s - loss: 1.0859 - acc: 0.3983 - val_loss: 1.0856 - val_acc: 0.4251\n",
            "Epoch 33/150 - 0.12s - loss: 1.0856 - acc: 0.3990 - val_loss: 1.0854 - val_acc: 0.4211\n",
            "Epoch 34/150 - 0.13s - loss: 1.0854 - acc: 0.3997 - val_loss: 1.0852 - val_acc: 0.4211\n",
            "Epoch 35/150 - 0.13s - loss: 1.0851 - acc: 0.4006 - val_loss: 1.0850 - val_acc: 0.4170\n",
            "Epoch 36/150 - 0.12s - loss: 1.0849 - acc: 0.4024 - val_loss: 1.0848 - val_acc: 0.4211\n",
            "Epoch 37/150 - 0.13s - loss: 1.0846 - acc: 0.4033 - val_loss: 1.0846 - val_acc: 0.4190\n",
            "Epoch 38/150 - 0.13s - loss: 1.0844 - acc: 0.4051 - val_loss: 1.0844 - val_acc: 0.4170\n",
            "Epoch 39/150 - 0.13s - loss: 1.0842 - acc: 0.4053 - val_loss: 1.0843 - val_acc: 0.4150\n",
            "Epoch 40/150 - 0.12s - loss: 1.0839 - acc: 0.4067 - val_loss: 1.0841 - val_acc: 0.4211\n",
            "Epoch 41/150 - 0.14s - loss: 1.0837 - acc: 0.4064 - val_loss: 1.0839 - val_acc: 0.4211\n",
            "Epoch 42/150 - 0.12s - loss: 1.0835 - acc: 0.4067 - val_loss: 1.0837 - val_acc: 0.4190\n",
            "Epoch 43/150 - 0.13s - loss: 1.0832 - acc: 0.4085 - val_loss: 1.0835 - val_acc: 0.4170\n",
            "Epoch 44/150 - 0.12s - loss: 1.0830 - acc: 0.4087 - val_loss: 1.0833 - val_acc: 0.4170\n",
            "Epoch 45/150 - 0.13s - loss: 1.0828 - acc: 0.4091 - val_loss: 1.0832 - val_acc: 0.4170\n",
            "Epoch 46/150 - 0.13s - loss: 1.0825 - acc: 0.4094 - val_loss: 1.0830 - val_acc: 0.4150\n",
            "Epoch 47/150 - 0.14s - loss: 1.0823 - acc: 0.4105 - val_loss: 1.0828 - val_acc: 0.4190\n",
            "Epoch 48/150 - 0.13s - loss: 1.0821 - acc: 0.4107 - val_loss: 1.0826 - val_acc: 0.4190\n",
            "Epoch 49/150 - 0.13s - loss: 1.0819 - acc: 0.4107 - val_loss: 1.0824 - val_acc: 0.4170\n",
            "Epoch 50/150 - 0.12s - loss: 1.0816 - acc: 0.4123 - val_loss: 1.0823 - val_acc: 0.4190\n",
            "Epoch 51/150 - 0.13s - loss: 1.0814 - acc: 0.4123 - val_loss: 1.0821 - val_acc: 0.4190\n",
            "Epoch 52/150 - 0.12s - loss: 1.0812 - acc: 0.4127 - val_loss: 1.0819 - val_acc: 0.4190\n",
            "Epoch 53/150 - 0.14s - loss: 1.0810 - acc: 0.4143 - val_loss: 1.0818 - val_acc: 0.4170\n",
            "Epoch 54/150 - 0.13s - loss: 1.0807 - acc: 0.4154 - val_loss: 1.0816 - val_acc: 0.4190\n",
            "Epoch 55/150 - 0.14s - loss: 1.0805 - acc: 0.4157 - val_loss: 1.0814 - val_acc: 0.4211\n",
            "Epoch 56/150 - 0.13s - loss: 1.0803 - acc: 0.4159 - val_loss: 1.0812 - val_acc: 0.4231\n",
            "Epoch 57/150 - 0.14s - loss: 1.0801 - acc: 0.4170 - val_loss: 1.0811 - val_acc: 0.4211\n",
            "Epoch 58/150 - 0.13s - loss: 1.0799 - acc: 0.4186 - val_loss: 1.0809 - val_acc: 0.4211\n",
            "Epoch 59/150 - 0.14s - loss: 1.0797 - acc: 0.4190 - val_loss: 1.0807 - val_acc: 0.4211\n",
            "Epoch 60/150 - 0.13s - loss: 1.0794 - acc: 0.4197 - val_loss: 1.0806 - val_acc: 0.4190\n",
            "Epoch 61/150 - 0.13s - loss: 1.0792 - acc: 0.4204 - val_loss: 1.0804 - val_acc: 0.4190\n",
            "Epoch 62/150 - 0.13s - loss: 1.0790 - acc: 0.4204 - val_loss: 1.0803 - val_acc: 0.4211\n",
            "Epoch 63/150 - 0.14s - loss: 1.0788 - acc: 0.4211 - val_loss: 1.0801 - val_acc: 0.4211\n",
            "Epoch 64/150 - 0.13s - loss: 1.0786 - acc: 0.4208 - val_loss: 1.0799 - val_acc: 0.4231\n",
            "Epoch 65/150 - 0.13s - loss: 1.0784 - acc: 0.4229 - val_loss: 1.0798 - val_acc: 0.4231\n",
            "Epoch 66/150 - 0.13s - loss: 1.0782 - acc: 0.4240 - val_loss: 1.0796 - val_acc: 0.4271\n",
            "Epoch 67/150 - 0.13s - loss: 1.0780 - acc: 0.4242 - val_loss: 1.0795 - val_acc: 0.4291\n",
            "Epoch 68/150 - 0.13s - loss: 1.0778 - acc: 0.4244 - val_loss: 1.0793 - val_acc: 0.4312\n",
            "Epoch 69/150 - 0.13s - loss: 1.0776 - acc: 0.4247 - val_loss: 1.0791 - val_acc: 0.4332\n",
            "Epoch 70/150 - 0.13s - loss: 1.0774 - acc: 0.4256 - val_loss: 1.0790 - val_acc: 0.4291\n",
            "Epoch 71/150 - 0.14s - loss: 1.0772 - acc: 0.4262 - val_loss: 1.0788 - val_acc: 0.4291\n",
            "Epoch 72/150 - 0.14s - loss: 1.0770 - acc: 0.4271 - val_loss: 1.0787 - val_acc: 0.4312\n",
            "Epoch 73/150 - 0.13s - loss: 1.0768 - acc: 0.4276 - val_loss: 1.0785 - val_acc: 0.4393\n",
            "Epoch 74/150 - 0.13s - loss: 1.0766 - acc: 0.4278 - val_loss: 1.0784 - val_acc: 0.4393\n",
            "Epoch 75/150 - 0.13s - loss: 1.0764 - acc: 0.4274 - val_loss: 1.0782 - val_acc: 0.4393\n",
            "Epoch 76/150 - 0.12s - loss: 1.0762 - acc: 0.4269 - val_loss: 1.0781 - val_acc: 0.4433\n",
            "Epoch 77/150 - 0.13s - loss: 1.0760 - acc: 0.4271 - val_loss: 1.0779 - val_acc: 0.4413\n",
            "Epoch 78/150 - 0.14s - loss: 1.0758 - acc: 0.4283 - val_loss: 1.0778 - val_acc: 0.4413\n",
            "Epoch 79/150 - 0.14s - loss: 1.0756 - acc: 0.4289 - val_loss: 1.0776 - val_acc: 0.4413\n",
            "Epoch 80/150 - 0.13s - loss: 1.0754 - acc: 0.4300 - val_loss: 1.0775 - val_acc: 0.4433\n",
            "Epoch 81/150 - 0.13s - loss: 1.0752 - acc: 0.4305 - val_loss: 1.0773 - val_acc: 0.4433\n",
            "Epoch 82/150 - 0.13s - loss: 1.0750 - acc: 0.4303 - val_loss: 1.0772 - val_acc: 0.4453\n",
            "Epoch 83/150 - 0.13s - loss: 1.0748 - acc: 0.4316 - val_loss: 1.0770 - val_acc: 0.4453\n",
            "Epoch 84/150 - 0.12s - loss: 1.0746 - acc: 0.4318 - val_loss: 1.0769 - val_acc: 0.4474\n",
            "Epoch 85/150 - 0.12s - loss: 1.0744 - acc: 0.4321 - val_loss: 1.0768 - val_acc: 0.4494\n",
            "Epoch 86/150 - 0.12s - loss: 1.0743 - acc: 0.4321 - val_loss: 1.0766 - val_acc: 0.4494\n",
            "Epoch 87/150 - 0.13s - loss: 1.0741 - acc: 0.4343 - val_loss: 1.0765 - val_acc: 0.4514\n",
            "Epoch 88/150 - 0.13s - loss: 1.0739 - acc: 0.4352 - val_loss: 1.0763 - val_acc: 0.4534\n",
            "Epoch 89/150 - 0.14s - loss: 1.0737 - acc: 0.4352 - val_loss: 1.0762 - val_acc: 0.4534\n",
            "Epoch 90/150 - 0.13s - loss: 1.0735 - acc: 0.4350 - val_loss: 1.0760 - val_acc: 0.4534\n",
            "Epoch 91/150 - 0.13s - loss: 1.0733 - acc: 0.4345 - val_loss: 1.0759 - val_acc: 0.4534\n",
            "Epoch 92/150 - 0.14s - loss: 1.0731 - acc: 0.4343 - val_loss: 1.0758 - val_acc: 0.4534\n",
            "Epoch 93/150 - 0.13s - loss: 1.0730 - acc: 0.4341 - val_loss: 1.0756 - val_acc: 0.4534\n",
            "Epoch 94/150 - 0.13s - loss: 1.0728 - acc: 0.4345 - val_loss: 1.0755 - val_acc: 0.4534\n",
            "Epoch 95/150 - 0.15s - loss: 1.0726 - acc: 0.4354 - val_loss: 1.0753 - val_acc: 0.4514\n",
            "Epoch 96/150 - 0.14s - loss: 1.0724 - acc: 0.4363 - val_loss: 1.0752 - val_acc: 0.4514\n",
            "Epoch 97/150 - 0.13s - loss: 1.0722 - acc: 0.4375 - val_loss: 1.0751 - val_acc: 0.4514\n",
            "Epoch 98/150 - 0.13s - loss: 1.0721 - acc: 0.4381 - val_loss: 1.0749 - val_acc: 0.4534\n",
            "Epoch 99/150 - 0.13s - loss: 1.0719 - acc: 0.4379 - val_loss: 1.0748 - val_acc: 0.4555\n",
            "Epoch 100/150 - 0.13s - loss: 1.0717 - acc: 0.4386 - val_loss: 1.0747 - val_acc: 0.4534\n",
            "Epoch 101/150 - 0.13s - loss: 1.0715 - acc: 0.4381 - val_loss: 1.0745 - val_acc: 0.4514\n",
            "Epoch 102/150 - 0.13s - loss: 1.0713 - acc: 0.4384 - val_loss: 1.0744 - val_acc: 0.4514\n",
            "Epoch 103/150 - 0.13s - loss: 1.0712 - acc: 0.4384 - val_loss: 1.0743 - val_acc: 0.4514\n",
            "Epoch 104/150 - 0.13s - loss: 1.0710 - acc: 0.4384 - val_loss: 1.0741 - val_acc: 0.4534\n",
            "Epoch 105/150 - 0.13s - loss: 1.0708 - acc: 0.4388 - val_loss: 1.0740 - val_acc: 0.4534\n",
            "Epoch 106/150 - 0.12s - loss: 1.0707 - acc: 0.4388 - val_loss: 1.0739 - val_acc: 0.4534\n",
            "Epoch 107/150 - 0.13s - loss: 1.0705 - acc: 0.4388 - val_loss: 1.0738 - val_acc: 0.4534\n",
            "Epoch 108/150 - 0.13s - loss: 1.0703 - acc: 0.4397 - val_loss: 1.0736 - val_acc: 0.4534\n",
            "Epoch 109/150 - 0.13s - loss: 1.0701 - acc: 0.4399 - val_loss: 1.0735 - val_acc: 0.4555\n",
            "Epoch 110/150 - 0.12s - loss: 1.0700 - acc: 0.4399 - val_loss: 1.0734 - val_acc: 0.4534\n",
            "Epoch 111/150 - 0.13s - loss: 1.0698 - acc: 0.4402 - val_loss: 1.0732 - val_acc: 0.4555\n",
            "Epoch 112/150 - 0.12s - loss: 1.0696 - acc: 0.4402 - val_loss: 1.0731 - val_acc: 0.4575\n",
            "Epoch 113/150 - 0.13s - loss: 1.0695 - acc: 0.4422 - val_loss: 1.0730 - val_acc: 0.4595\n",
            "Epoch 114/150 - 0.13s - loss: 1.0693 - acc: 0.4420 - val_loss: 1.0729 - val_acc: 0.4555\n",
            "Epoch 115/150 - 0.13s - loss: 1.0691 - acc: 0.4424 - val_loss: 1.0727 - val_acc: 0.4575\n",
            "Epoch 116/150 - 0.13s - loss: 1.0690 - acc: 0.4431 - val_loss: 1.0726 - val_acc: 0.4575\n",
            "Epoch 117/150 - 0.13s - loss: 1.0688 - acc: 0.4438 - val_loss: 1.0725 - val_acc: 0.4575\n",
            "Epoch 118/150 - 0.12s - loss: 1.0686 - acc: 0.4431 - val_loss: 1.0724 - val_acc: 0.4575\n",
            "Epoch 119/150 - 0.13s - loss: 1.0685 - acc: 0.4447 - val_loss: 1.0722 - val_acc: 0.4575\n",
            "Epoch 120/150 - 0.14s - loss: 1.0683 - acc: 0.4456 - val_loss: 1.0721 - val_acc: 0.4575\n",
            "Epoch 121/150 - 0.13s - loss: 1.0681 - acc: 0.4460 - val_loss: 1.0720 - val_acc: 0.4575\n",
            "Epoch 122/150 - 0.12s - loss: 1.0680 - acc: 0.4447 - val_loss: 1.0719 - val_acc: 0.4575\n",
            "Epoch 123/150 - 0.13s - loss: 1.0678 - acc: 0.4451 - val_loss: 1.0717 - val_acc: 0.4575\n",
            "Epoch 124/150 - 0.12s - loss: 1.0676 - acc: 0.4453 - val_loss: 1.0716 - val_acc: 0.4534\n",
            "Epoch 125/150 - 0.13s - loss: 1.0675 - acc: 0.4453 - val_loss: 1.0715 - val_acc: 0.4534\n",
            "Epoch 126/150 - 0.13s - loss: 1.0673 - acc: 0.4458 - val_loss: 1.0714 - val_acc: 0.4534\n",
            "Epoch 127/150 - 0.13s - loss: 1.0672 - acc: 0.4458 - val_loss: 1.0713 - val_acc: 0.4555\n",
            "Epoch 128/150 - 0.13s - loss: 1.0670 - acc: 0.4474 - val_loss: 1.0711 - val_acc: 0.4575\n",
            "Epoch 129/150 - 0.13s - loss: 1.0668 - acc: 0.4485 - val_loss: 1.0710 - val_acc: 0.4575\n",
            "Epoch 130/150 - 0.13s - loss: 1.0667 - acc: 0.4489 - val_loss: 1.0709 - val_acc: 0.4615\n",
            "Epoch 131/150 - 0.14s - loss: 1.0665 - acc: 0.4503 - val_loss: 1.0708 - val_acc: 0.4615\n",
            "Epoch 132/150 - 0.13s - loss: 1.0664 - acc: 0.4494 - val_loss: 1.0707 - val_acc: 0.4636\n",
            "Epoch 133/150 - 0.13s - loss: 1.0662 - acc: 0.4503 - val_loss: 1.0706 - val_acc: 0.4656\n",
            "Epoch 134/150 - 0.13s - loss: 1.0661 - acc: 0.4510 - val_loss: 1.0704 - val_acc: 0.4636\n",
            "Epoch 135/150 - 0.13s - loss: 1.0659 - acc: 0.4510 - val_loss: 1.0703 - val_acc: 0.4636\n",
            "Epoch 136/150 - 0.12s - loss: 1.0657 - acc: 0.4514 - val_loss: 1.0702 - val_acc: 0.4636\n",
            "Epoch 137/150 - 0.13s - loss: 1.0656 - acc: 0.4519 - val_loss: 1.0701 - val_acc: 0.4595\n",
            "Epoch 138/150 - 0.13s - loss: 1.0654 - acc: 0.4521 - val_loss: 1.0700 - val_acc: 0.4595\n",
            "Epoch 139/150 - 0.13s - loss: 1.0653 - acc: 0.4539 - val_loss: 1.0699 - val_acc: 0.4575\n",
            "Epoch 140/150 - 0.13s - loss: 1.0651 - acc: 0.4543 - val_loss: 1.0698 - val_acc: 0.4575\n",
            "Epoch 141/150 - 0.13s - loss: 1.0650 - acc: 0.4541 - val_loss: 1.0696 - val_acc: 0.4575\n",
            "Epoch 142/150 - 0.12s - loss: 1.0648 - acc: 0.4541 - val_loss: 1.0695 - val_acc: 0.4575\n",
            "Epoch 143/150 - 0.13s - loss: 1.0647 - acc: 0.4543 - val_loss: 1.0694 - val_acc: 0.4575\n",
            "Epoch 144/150 - 0.14s - loss: 1.0645 - acc: 0.4548 - val_loss: 1.0693 - val_acc: 0.4575\n",
            "Epoch 145/150 - 0.13s - loss: 1.0644 - acc: 0.4552 - val_loss: 1.0692 - val_acc: 0.4575\n",
            "Epoch 146/150 - 0.13s - loss: 1.0642 - acc: 0.4555 - val_loss: 1.0691 - val_acc: 0.4555\n",
            "Epoch 147/150 - 0.13s - loss: 1.0641 - acc: 0.4557 - val_loss: 1.0690 - val_acc: 0.4555\n",
            "Epoch 148/150 - 0.12s - loss: 1.0639 - acc: 0.4561 - val_loss: 1.0689 - val_acc: 0.4575\n",
            "Epoch 149/150 - 0.13s - loss: 1.0638 - acc: 0.4561 - val_loss: 1.0687 - val_acc: 0.4555\n",
            "Epoch 150/150 - 0.13s - loss: 1.0636 - acc: 0.4559 - val_loss: 1.0686 - val_acc: 0.4555\n",
            "\n",
            "Combination 106/252:\n",
            "Hidden Layers: [128, 128], Activation: tanh, Learning Rate: 0.0001, Batch Size: 64, Epochs: 50\n",
            "Epoch 1/50 - 0.10s - loss: 1.1091 - acc: 0.3248 - val_loss: 1.1199 - val_acc: 0.2996\n",
            "Epoch 2/50 - 0.11s - loss: 1.1081 - acc: 0.3259 - val_loss: 1.1186 - val_acc: 0.3057\n",
            "Epoch 3/50 - 0.10s - loss: 1.1071 - acc: 0.3266 - val_loss: 1.1174 - val_acc: 0.3016\n",
            "Epoch 4/50 - 0.11s - loss: 1.1062 - acc: 0.3266 - val_loss: 1.1163 - val_acc: 0.3016\n",
            "Epoch 5/50 - 0.11s - loss: 1.1054 - acc: 0.3264 - val_loss: 1.1153 - val_acc: 0.3016\n",
            "Epoch 6/50 - 0.11s - loss: 1.1046 - acc: 0.3275 - val_loss: 1.1144 - val_acc: 0.2976\n",
            "Epoch 7/50 - 0.10s - loss: 1.1039 - acc: 0.3277 - val_loss: 1.1135 - val_acc: 0.3016\n",
            "Epoch 8/50 - 0.11s - loss: 1.1033 - acc: 0.3282 - val_loss: 1.1127 - val_acc: 0.2996\n",
            "Epoch 9/50 - 0.10s - loss: 1.1026 - acc: 0.3279 - val_loss: 1.1120 - val_acc: 0.2996\n",
            "Epoch 10/50 - 0.11s - loss: 1.1021 - acc: 0.3291 - val_loss: 1.1112 - val_acc: 0.2996\n",
            "Epoch 11/50 - 0.10s - loss: 1.1015 - acc: 0.3293 - val_loss: 1.1106 - val_acc: 0.2996\n",
            "Epoch 12/50 - 0.11s - loss: 1.1011 - acc: 0.3284 - val_loss: 1.1100 - val_acc: 0.2996\n",
            "Epoch 13/50 - 0.10s - loss: 1.1006 - acc: 0.3264 - val_loss: 1.1094 - val_acc: 0.2915\n",
            "Epoch 14/50 - 0.10s - loss: 1.1002 - acc: 0.3293 - val_loss: 1.1088 - val_acc: 0.2915\n",
            "Epoch 15/50 - 0.11s - loss: 1.0998 - acc: 0.3284 - val_loss: 1.1083 - val_acc: 0.2935\n",
            "Epoch 16/50 - 0.10s - loss: 1.0994 - acc: 0.3297 - val_loss: 1.1079 - val_acc: 0.2895\n",
            "Epoch 17/50 - 0.11s - loss: 1.0991 - acc: 0.3291 - val_loss: 1.1074 - val_acc: 0.2834\n",
            "Epoch 18/50 - 0.10s - loss: 1.0987 - acc: 0.3288 - val_loss: 1.1070 - val_acc: 0.2854\n",
            "Epoch 19/50 - 0.13s - loss: 1.0984 - acc: 0.3302 - val_loss: 1.1066 - val_acc: 0.2814\n",
            "Epoch 20/50 - 0.10s - loss: 1.0981 - acc: 0.3327 - val_loss: 1.1062 - val_acc: 0.2874\n",
            "Epoch 21/50 - 0.10s - loss: 1.0978 - acc: 0.3300 - val_loss: 1.1058 - val_acc: 0.2874\n",
            "Epoch 22/50 - 0.11s - loss: 1.0976 - acc: 0.3311 - val_loss: 1.1055 - val_acc: 0.2895\n",
            "Epoch 23/50 - 0.10s - loss: 1.0973 - acc: 0.3327 - val_loss: 1.1052 - val_acc: 0.2935\n",
            "Epoch 24/50 - 0.10s - loss: 1.0971 - acc: 0.3331 - val_loss: 1.1049 - val_acc: 0.2915\n",
            "Epoch 25/50 - 0.12s - loss: 1.0968 - acc: 0.3336 - val_loss: 1.1046 - val_acc: 0.2935\n",
            "Epoch 26/50 - 0.11s - loss: 1.0966 - acc: 0.3342 - val_loss: 1.1043 - val_acc: 0.3036\n",
            "Epoch 27/50 - 0.12s - loss: 1.0964 - acc: 0.3351 - val_loss: 1.1040 - val_acc: 0.3057\n",
            "Epoch 28/50 - 0.12s - loss: 1.0962 - acc: 0.3374 - val_loss: 1.1038 - val_acc: 0.3138\n",
            "Epoch 29/50 - 0.11s - loss: 1.0960 - acc: 0.3367 - val_loss: 1.1035 - val_acc: 0.3138\n",
            "Epoch 30/50 - 0.11s - loss: 1.0958 - acc: 0.3367 - val_loss: 1.1033 - val_acc: 0.3158\n",
            "Epoch 31/50 - 0.11s - loss: 1.0956 - acc: 0.3403 - val_loss: 1.1030 - val_acc: 0.3117\n",
            "Epoch 32/50 - 0.11s - loss: 1.0954 - acc: 0.3428 - val_loss: 1.1028 - val_acc: 0.3097\n",
            "Epoch 33/50 - 0.10s - loss: 1.0953 - acc: 0.3430 - val_loss: 1.1026 - val_acc: 0.3117\n",
            "Epoch 34/50 - 0.12s - loss: 1.0951 - acc: 0.3437 - val_loss: 1.1024 - val_acc: 0.3097\n",
            "Epoch 35/50 - 0.11s - loss: 1.0949 - acc: 0.3439 - val_loss: 1.1022 - val_acc: 0.3036\n",
            "Epoch 36/50 - 0.11s - loss: 1.0948 - acc: 0.3459 - val_loss: 1.1020 - val_acc: 0.3097\n",
            "Epoch 37/50 - 0.11s - loss: 1.0946 - acc: 0.3462 - val_loss: 1.1018 - val_acc: 0.3077\n",
            "Epoch 38/50 - 0.11s - loss: 1.0944 - acc: 0.3484 - val_loss: 1.1016 - val_acc: 0.3077\n",
            "Epoch 39/50 - 0.11s - loss: 1.0943 - acc: 0.3504 - val_loss: 1.1015 - val_acc: 0.3097\n",
            "Epoch 40/50 - 0.12s - loss: 1.0941 - acc: 0.3518 - val_loss: 1.1013 - val_acc: 0.3138\n",
            "Epoch 41/50 - 0.11s - loss: 1.0940 - acc: 0.3540 - val_loss: 1.1011 - val_acc: 0.3198\n",
            "Epoch 42/50 - 0.11s - loss: 1.0938 - acc: 0.3540 - val_loss: 1.1010 - val_acc: 0.3198\n",
            "Epoch 43/50 - 0.10s - loss: 1.0937 - acc: 0.3558 - val_loss: 1.1008 - val_acc: 0.3158\n",
            "Epoch 44/50 - 0.11s - loss: 1.0936 - acc: 0.3567 - val_loss: 1.1006 - val_acc: 0.3158\n",
            "Epoch 45/50 - 0.10s - loss: 1.0934 - acc: 0.3576 - val_loss: 1.1005 - val_acc: 0.3219\n",
            "Epoch 46/50 - 0.11s - loss: 1.0933 - acc: 0.3578 - val_loss: 1.1003 - val_acc: 0.3219\n",
            "Epoch 47/50 - 0.11s - loss: 1.0932 - acc: 0.3594 - val_loss: 1.1002 - val_acc: 0.3219\n",
            "Epoch 48/50 - 0.11s - loss: 1.0930 - acc: 0.3610 - val_loss: 1.1000 - val_acc: 0.3219\n",
            "Epoch 49/50 - 0.10s - loss: 1.0929 - acc: 0.3601 - val_loss: 1.0999 - val_acc: 0.3198\n",
            "Epoch 50/50 - 0.11s - loss: 1.0928 - acc: 0.3608 - val_loss: 1.0998 - val_acc: 0.3219\n",
            "\n",
            "Combination 107/252:\n",
            "Hidden Layers: [128, 128], Activation: tanh, Learning Rate: 0.0001, Batch Size: 64, Epochs: 100\n",
            "Epoch 1/100 - 0.10s - loss: 1.1098 - acc: 0.3522 - val_loss: 1.1128 - val_acc: 0.3583\n",
            "Epoch 2/100 - 0.11s - loss: 1.1088 - acc: 0.3538 - val_loss: 1.1120 - val_acc: 0.3603\n",
            "Epoch 3/100 - 0.10s - loss: 1.1080 - acc: 0.3540 - val_loss: 1.1113 - val_acc: 0.3583\n",
            "Epoch 4/100 - 0.11s - loss: 1.1072 - acc: 0.3549 - val_loss: 1.1106 - val_acc: 0.3583\n",
            "Epoch 5/100 - 0.10s - loss: 1.1065 - acc: 0.3543 - val_loss: 1.1100 - val_acc: 0.3563\n",
            "Epoch 6/100 - 0.11s - loss: 1.1059 - acc: 0.3558 - val_loss: 1.1095 - val_acc: 0.3583\n",
            "Epoch 7/100 - 0.10s - loss: 1.1053 - acc: 0.3572 - val_loss: 1.1091 - val_acc: 0.3583\n",
            "Epoch 8/100 - 0.12s - loss: 1.1048 - acc: 0.3581 - val_loss: 1.1086 - val_acc: 0.3502\n",
            "Epoch 9/100 - 0.11s - loss: 1.1043 - acc: 0.3570 - val_loss: 1.1083 - val_acc: 0.3522\n",
            "Epoch 10/100 - 0.12s - loss: 1.1039 - acc: 0.3583 - val_loss: 1.1079 - val_acc: 0.3543\n",
            "Epoch 11/100 - 0.11s - loss: 1.1035 - acc: 0.3574 - val_loss: 1.1076 - val_acc: 0.3522\n",
            "Epoch 12/100 - 0.11s - loss: 1.1031 - acc: 0.3567 - val_loss: 1.1073 - val_acc: 0.3421\n",
            "Epoch 13/100 - 0.11s - loss: 1.1028 - acc: 0.3556 - val_loss: 1.1071 - val_acc: 0.3381\n",
            "Epoch 14/100 - 0.13s - loss: 1.1025 - acc: 0.3534 - val_loss: 1.1068 - val_acc: 0.3340\n",
            "Epoch 15/100 - 0.10s - loss: 1.1022 - acc: 0.3529 - val_loss: 1.1066 - val_acc: 0.3340\n",
            "Epoch 16/100 - 0.11s - loss: 1.1019 - acc: 0.3518 - val_loss: 1.1064 - val_acc: 0.3279\n",
            "Epoch 17/100 - 0.11s - loss: 1.1017 - acc: 0.3520 - val_loss: 1.1061 - val_acc: 0.3259\n",
            "Epoch 18/100 - 0.11s - loss: 1.1014 - acc: 0.3538 - val_loss: 1.1060 - val_acc: 0.3239\n",
            "Epoch 19/100 - 0.11s - loss: 1.1012 - acc: 0.3545 - val_loss: 1.1058 - val_acc: 0.3259\n",
            "Epoch 20/100 - 0.12s - loss: 1.1010 - acc: 0.3556 - val_loss: 1.1056 - val_acc: 0.3300\n",
            "Epoch 21/100 - 0.11s - loss: 1.1008 - acc: 0.3545 - val_loss: 1.1054 - val_acc: 0.3300\n",
            "Epoch 22/100 - 0.10s - loss: 1.1006 - acc: 0.3556 - val_loss: 1.1053 - val_acc: 0.3381\n",
            "Epoch 23/100 - 0.12s - loss: 1.1004 - acc: 0.3540 - val_loss: 1.1051 - val_acc: 0.3360\n",
            "Epoch 24/100 - 0.11s - loss: 1.1002 - acc: 0.3538 - val_loss: 1.1050 - val_acc: 0.3340\n",
            "Epoch 25/100 - 0.11s - loss: 1.1000 - acc: 0.3554 - val_loss: 1.1048 - val_acc: 0.3340\n",
            "Epoch 26/100 - 0.10s - loss: 1.0999 - acc: 0.3556 - val_loss: 1.1047 - val_acc: 0.3441\n",
            "Epoch 27/100 - 0.11s - loss: 1.0997 - acc: 0.3552 - val_loss: 1.1045 - val_acc: 0.3441\n",
            "Epoch 28/100 - 0.11s - loss: 1.0995 - acc: 0.3558 - val_loss: 1.1044 - val_acc: 0.3381\n",
            "Epoch 29/100 - 0.11s - loss: 1.0994 - acc: 0.3570 - val_loss: 1.1043 - val_acc: 0.3401\n",
            "Epoch 30/100 - 0.11s - loss: 1.0992 - acc: 0.3558 - val_loss: 1.1041 - val_acc: 0.3401\n",
            "Epoch 31/100 - 0.11s - loss: 1.0991 - acc: 0.3570 - val_loss: 1.1040 - val_acc: 0.3421\n",
            "Epoch 32/100 - 0.10s - loss: 1.0989 - acc: 0.3565 - val_loss: 1.1039 - val_acc: 0.3421\n",
            "Epoch 33/100 - 0.12s - loss: 1.0987 - acc: 0.3574 - val_loss: 1.1037 - val_acc: 0.3401\n",
            "Epoch 34/100 - 0.11s - loss: 1.0986 - acc: 0.3578 - val_loss: 1.1036 - val_acc: 0.3360\n",
            "Epoch 35/100 - 0.11s - loss: 1.0985 - acc: 0.3578 - val_loss: 1.1035 - val_acc: 0.3340\n",
            "Epoch 36/100 - 0.10s - loss: 1.0983 - acc: 0.3583 - val_loss: 1.1033 - val_acc: 0.3340\n",
            "Epoch 37/100 - 0.11s - loss: 1.0982 - acc: 0.3572 - val_loss: 1.1032 - val_acc: 0.3340\n",
            "Epoch 38/100 - 0.11s - loss: 1.0980 - acc: 0.3552 - val_loss: 1.1031 - val_acc: 0.3320\n",
            "Epoch 39/100 - 0.12s - loss: 1.0979 - acc: 0.3549 - val_loss: 1.1030 - val_acc: 0.3320\n",
            "Epoch 40/100 - 0.11s - loss: 1.0978 - acc: 0.3556 - val_loss: 1.1029 - val_acc: 0.3320\n",
            "Epoch 41/100 - 0.11s - loss: 1.0976 - acc: 0.3549 - val_loss: 1.1027 - val_acc: 0.3320\n",
            "Epoch 42/100 - 0.11s - loss: 1.0975 - acc: 0.3570 - val_loss: 1.1026 - val_acc: 0.3300\n",
            "Epoch 43/100 - 0.11s - loss: 1.0973 - acc: 0.3587 - val_loss: 1.1025 - val_acc: 0.3279\n",
            "Epoch 44/100 - 0.10s - loss: 1.0972 - acc: 0.3578 - val_loss: 1.1024 - val_acc: 0.3279\n",
            "Epoch 45/100 - 0.12s - loss: 1.0971 - acc: 0.3581 - val_loss: 1.1023 - val_acc: 0.3279\n",
            "Epoch 46/100 - 0.11s - loss: 1.0969 - acc: 0.3594 - val_loss: 1.1021 - val_acc: 0.3279\n",
            "Epoch 47/100 - 0.13s - loss: 1.0968 - acc: 0.3587 - val_loss: 1.1020 - val_acc: 0.3279\n",
            "Epoch 48/100 - 0.10s - loss: 1.0967 - acc: 0.3578 - val_loss: 1.1019 - val_acc: 0.3300\n",
            "Epoch 49/100 - 0.11s - loss: 1.0965 - acc: 0.3578 - val_loss: 1.1018 - val_acc: 0.3279\n",
            "Epoch 50/100 - 0.11s - loss: 1.0964 - acc: 0.3587 - val_loss: 1.1017 - val_acc: 0.3279\n",
            "Epoch 51/100 - 0.13s - loss: 1.0963 - acc: 0.3599 - val_loss: 1.1016 - val_acc: 0.3300\n",
            "Epoch 52/100 - 0.11s - loss: 1.0962 - acc: 0.3585 - val_loss: 1.1014 - val_acc: 0.3300\n",
            "Epoch 53/100 - 0.10s - loss: 1.0960 - acc: 0.3585 - val_loss: 1.1013 - val_acc: 0.3300\n",
            "Epoch 54/100 - 0.11s - loss: 1.0959 - acc: 0.3587 - val_loss: 1.1012 - val_acc: 0.3320\n",
            "Epoch 55/100 - 0.11s - loss: 1.0958 - acc: 0.3592 - val_loss: 1.1011 - val_acc: 0.3320\n",
            "Epoch 56/100 - 0.11s - loss: 1.0956 - acc: 0.3605 - val_loss: 1.1010 - val_acc: 0.3320\n",
            "Epoch 57/100 - 0.12s - loss: 1.0955 - acc: 0.3612 - val_loss: 1.1009 - val_acc: 0.3320\n",
            "Epoch 58/100 - 0.11s - loss: 1.0954 - acc: 0.3608 - val_loss: 1.1008 - val_acc: 0.3320\n",
            "Epoch 59/100 - 0.11s - loss: 1.0953 - acc: 0.3628 - val_loss: 1.1007 - val_acc: 0.3320\n",
            "Epoch 60/100 - 0.10s - loss: 1.0952 - acc: 0.3628 - val_loss: 1.1005 - val_acc: 0.3320\n",
            "Epoch 61/100 - 0.12s - loss: 1.0950 - acc: 0.3639 - val_loss: 1.1004 - val_acc: 0.3340\n",
            "Epoch 62/100 - 0.11s - loss: 1.0949 - acc: 0.3644 - val_loss: 1.1003 - val_acc: 0.3340\n",
            "Epoch 63/100 - 0.12s - loss: 1.0948 - acc: 0.3648 - val_loss: 1.1002 - val_acc: 0.3360\n",
            "Epoch 64/100 - 0.11s - loss: 1.0947 - acc: 0.3662 - val_loss: 1.1001 - val_acc: 0.3421\n",
            "Epoch 65/100 - 0.11s - loss: 1.0945 - acc: 0.3662 - val_loss: 1.1000 - val_acc: 0.3441\n",
            "Epoch 66/100 - 0.10s - loss: 1.0944 - acc: 0.3668 - val_loss: 1.0999 - val_acc: 0.3462\n",
            "Epoch 67/100 - 0.11s - loss: 1.0943 - acc: 0.3666 - val_loss: 1.0998 - val_acc: 0.3462\n",
            "Epoch 68/100 - 0.11s - loss: 1.0942 - acc: 0.3682 - val_loss: 1.0997 - val_acc: 0.3462\n",
            "Epoch 69/100 - 0.12s - loss: 1.0941 - acc: 0.3684 - val_loss: 1.0996 - val_acc: 0.3462\n",
            "Epoch 70/100 - 0.11s - loss: 1.0939 - acc: 0.3691 - val_loss: 1.0995 - val_acc: 0.3441\n",
            "Epoch 71/100 - 0.11s - loss: 1.0938 - acc: 0.3704 - val_loss: 1.0994 - val_acc: 0.3462\n",
            "Epoch 72/100 - 0.12s - loss: 1.0937 - acc: 0.3711 - val_loss: 1.0992 - val_acc: 0.3441\n",
            "Epoch 73/100 - 0.11s - loss: 1.0936 - acc: 0.3716 - val_loss: 1.0991 - val_acc: 0.3462\n",
            "Epoch 74/100 - 0.11s - loss: 1.0935 - acc: 0.3727 - val_loss: 1.0990 - val_acc: 0.3482\n",
            "Epoch 75/100 - 0.12s - loss: 1.0933 - acc: 0.3727 - val_loss: 1.0989 - val_acc: 0.3522\n",
            "Epoch 76/100 - 0.11s - loss: 1.0932 - acc: 0.3736 - val_loss: 1.0988 - val_acc: 0.3543\n",
            "Epoch 77/100 - 0.14s - loss: 1.0931 - acc: 0.3745 - val_loss: 1.0987 - val_acc: 0.3543\n",
            "Epoch 78/100 - 0.12s - loss: 1.0930 - acc: 0.3745 - val_loss: 1.0986 - val_acc: 0.3543\n",
            "Epoch 79/100 - 0.11s - loss: 1.0929 - acc: 0.3749 - val_loss: 1.0985 - val_acc: 0.3543\n",
            "Epoch 80/100 - 0.11s - loss: 1.0928 - acc: 0.3756 - val_loss: 1.0984 - val_acc: 0.3543\n",
            "Epoch 81/100 - 0.11s - loss: 1.0927 - acc: 0.3761 - val_loss: 1.0983 - val_acc: 0.3522\n",
            "Epoch 82/100 - 0.11s - loss: 1.0925 - acc: 0.3765 - val_loss: 1.0982 - val_acc: 0.3543\n",
            "Epoch 83/100 - 0.12s - loss: 1.0924 - acc: 0.3774 - val_loss: 1.0981 - val_acc: 0.3522\n",
            "Epoch 84/100 - 0.10s - loss: 1.0923 - acc: 0.3783 - val_loss: 1.0980 - val_acc: 0.3543\n",
            "Epoch 85/100 - 0.11s - loss: 1.0922 - acc: 0.3785 - val_loss: 1.0979 - val_acc: 0.3543\n",
            "Epoch 86/100 - 0.11s - loss: 1.0921 - acc: 0.3788 - val_loss: 1.0978 - val_acc: 0.3543\n",
            "Epoch 87/100 - 0.12s - loss: 1.0920 - acc: 0.3799 - val_loss: 1.0977 - val_acc: 0.3543\n",
            "Epoch 88/100 - 0.11s - loss: 1.0919 - acc: 0.3801 - val_loss: 1.0976 - val_acc: 0.3543\n",
            "Epoch 89/100 - 0.12s - loss: 1.0917 - acc: 0.3806 - val_loss: 1.0975 - val_acc: 0.3543\n",
            "Epoch 90/100 - 0.11s - loss: 1.0916 - acc: 0.3819 - val_loss: 1.0974 - val_acc: 0.3563\n",
            "Epoch 91/100 - 0.12s - loss: 1.0915 - acc: 0.3817 - val_loss: 1.0973 - val_acc: 0.3563\n",
            "Epoch 92/100 - 0.12s - loss: 1.0914 - acc: 0.3821 - val_loss: 1.0972 - val_acc: 0.3583\n",
            "Epoch 93/100 - 0.11s - loss: 1.0913 - acc: 0.3828 - val_loss: 1.0971 - val_acc: 0.3583\n",
            "Epoch 94/100 - 0.10s - loss: 1.0912 - acc: 0.3839 - val_loss: 1.0970 - val_acc: 0.3623\n",
            "Epoch 95/100 - 0.13s - loss: 1.0911 - acc: 0.3826 - val_loss: 1.0969 - val_acc: 0.3623\n",
            "Epoch 96/100 - 0.11s - loss: 1.0910 - acc: 0.3828 - val_loss: 1.0968 - val_acc: 0.3644\n",
            "Epoch 97/100 - 0.11s - loss: 1.0909 - acc: 0.3837 - val_loss: 1.0967 - val_acc: 0.3644\n",
            "Epoch 98/100 - 0.10s - loss: 1.0907 - acc: 0.3844 - val_loss: 1.0966 - val_acc: 0.3684\n",
            "Epoch 99/100 - 0.11s - loss: 1.0906 - acc: 0.3848 - val_loss: 1.0965 - val_acc: 0.3684\n",
            "Epoch 100/100 - 0.10s - loss: 1.0905 - acc: 0.3855 - val_loss: 1.0964 - val_acc: 0.3704\n",
            "\n",
            "Combination 108/252:\n",
            "Hidden Layers: [128, 128], Activation: tanh, Learning Rate: 0.0001, Batch Size: 64, Epochs: 150\n",
            "Epoch 1/150 - 0.11s - loss: 1.1275 - acc: 0.3268 - val_loss: 1.1262 - val_acc: 0.3198\n",
            "Epoch 2/150 - 0.10s - loss: 1.1241 - acc: 0.3270 - val_loss: 1.1225 - val_acc: 0.3259\n",
            "Epoch 3/150 - 0.11s - loss: 1.1212 - acc: 0.3291 - val_loss: 1.1193 - val_acc: 0.3279\n",
            "Epoch 4/150 - 0.10s - loss: 1.1187 - acc: 0.3284 - val_loss: 1.1165 - val_acc: 0.3340\n",
            "Epoch 5/150 - 0.11s - loss: 1.1166 - acc: 0.3264 - val_loss: 1.1141 - val_acc: 0.3462\n",
            "Epoch 6/150 - 0.10s - loss: 1.1147 - acc: 0.3293 - val_loss: 1.1120 - val_acc: 0.3502\n",
            "Epoch 7/150 - 0.11s - loss: 1.1131 - acc: 0.3279 - val_loss: 1.1101 - val_acc: 0.3502\n",
            "Epoch 8/150 - 0.10s - loss: 1.1117 - acc: 0.3282 - val_loss: 1.1085 - val_acc: 0.3522\n",
            "Epoch 9/150 - 0.11s - loss: 1.1105 - acc: 0.3304 - val_loss: 1.1071 - val_acc: 0.3563\n",
            "Epoch 10/150 - 0.10s - loss: 1.1094 - acc: 0.3333 - val_loss: 1.1059 - val_acc: 0.3522\n",
            "Epoch 11/150 - 0.11s - loss: 1.1085 - acc: 0.3347 - val_loss: 1.1049 - val_acc: 0.3543\n",
            "Epoch 12/150 - 0.10s - loss: 1.1077 - acc: 0.3351 - val_loss: 1.1039 - val_acc: 0.3502\n",
            "Epoch 13/150 - 0.11s - loss: 1.1070 - acc: 0.3376 - val_loss: 1.1030 - val_acc: 0.3482\n",
            "Epoch 14/150 - 0.10s - loss: 1.1063 - acc: 0.3381 - val_loss: 1.1022 - val_acc: 0.3462\n",
            "Epoch 15/150 - 0.11s - loss: 1.1058 - acc: 0.3387 - val_loss: 1.1016 - val_acc: 0.3543\n",
            "Epoch 16/150 - 0.10s - loss: 1.1053 - acc: 0.3403 - val_loss: 1.1010 - val_acc: 0.3583\n",
            "Epoch 17/150 - 0.11s - loss: 1.1048 - acc: 0.3414 - val_loss: 1.1004 - val_acc: 0.3644\n",
            "Epoch 18/150 - 0.11s - loss: 1.1044 - acc: 0.3435 - val_loss: 1.0999 - val_acc: 0.3583\n",
            "Epoch 19/150 - 0.15s - loss: 1.1040 - acc: 0.3441 - val_loss: 1.0995 - val_acc: 0.3603\n",
            "Epoch 20/150 - 0.11s - loss: 1.1037 - acc: 0.3453 - val_loss: 1.0990 - val_acc: 0.3502\n",
            "Epoch 21/150 - 0.11s - loss: 1.1034 - acc: 0.3448 - val_loss: 1.0986 - val_acc: 0.3462\n",
            "Epoch 22/150 - 0.11s - loss: 1.1031 - acc: 0.3466 - val_loss: 1.0983 - val_acc: 0.3482\n",
            "Epoch 23/150 - 0.12s - loss: 1.1028 - acc: 0.3475 - val_loss: 1.0980 - val_acc: 0.3522\n",
            "Epoch 24/150 - 0.11s - loss: 1.1026 - acc: 0.3459 - val_loss: 1.0977 - val_acc: 0.3482\n",
            "Epoch 25/150 - 0.11s - loss: 1.1023 - acc: 0.3453 - val_loss: 1.0974 - val_acc: 0.3543\n",
            "Epoch 26/150 - 0.10s - loss: 1.1021 - acc: 0.3453 - val_loss: 1.0971 - val_acc: 0.3543\n",
            "Epoch 27/150 - 0.11s - loss: 1.1019 - acc: 0.3455 - val_loss: 1.0969 - val_acc: 0.3623\n",
            "Epoch 28/150 - 0.10s - loss: 1.1017 - acc: 0.3480 - val_loss: 1.0966 - val_acc: 0.3644\n",
            "Epoch 29/150 - 0.11s - loss: 1.1015 - acc: 0.3480 - val_loss: 1.0964 - val_acc: 0.3644\n",
            "Epoch 30/150 - 0.11s - loss: 1.1013 - acc: 0.3493 - val_loss: 1.0962 - val_acc: 0.3684\n",
            "Epoch 31/150 - 0.12s - loss: 1.1011 - acc: 0.3489 - val_loss: 1.0960 - val_acc: 0.3664\n",
            "Epoch 32/150 - 0.11s - loss: 1.1010 - acc: 0.3489 - val_loss: 1.0958 - val_acc: 0.3664\n",
            "Epoch 33/150 - 0.11s - loss: 1.1008 - acc: 0.3489 - val_loss: 1.0956 - val_acc: 0.3664\n",
            "Epoch 34/150 - 0.12s - loss: 1.1006 - acc: 0.3489 - val_loss: 1.0955 - val_acc: 0.3623\n",
            "Epoch 35/150 - 0.12s - loss: 1.1005 - acc: 0.3509 - val_loss: 1.0953 - val_acc: 0.3623\n",
            "Epoch 36/150 - 0.11s - loss: 1.1003 - acc: 0.3509 - val_loss: 1.0951 - val_acc: 0.3623\n",
            "Epoch 37/150 - 0.12s - loss: 1.1002 - acc: 0.3495 - val_loss: 1.0950 - val_acc: 0.3603\n",
            "Epoch 38/150 - 0.11s - loss: 1.1000 - acc: 0.3525 - val_loss: 1.0948 - val_acc: 0.3583\n",
            "Epoch 39/150 - 0.11s - loss: 1.0999 - acc: 0.3534 - val_loss: 1.0947 - val_acc: 0.3603\n",
            "Epoch 40/150 - 0.11s - loss: 1.0997 - acc: 0.3543 - val_loss: 1.0945 - val_acc: 0.3603\n",
            "Epoch 41/150 - 0.11s - loss: 1.0996 - acc: 0.3547 - val_loss: 1.0944 - val_acc: 0.3603\n",
            "Epoch 42/150 - 0.13s - loss: 1.0995 - acc: 0.3536 - val_loss: 1.0943 - val_acc: 0.3583\n",
            "Epoch 43/150 - 0.14s - loss: 1.0993 - acc: 0.3545 - val_loss: 1.0941 - val_acc: 0.3522\n",
            "Epoch 44/150 - 0.13s - loss: 1.0992 - acc: 0.3547 - val_loss: 1.0940 - val_acc: 0.3522\n",
            "Epoch 45/150 - 0.11s - loss: 1.0990 - acc: 0.3547 - val_loss: 1.0938 - val_acc: 0.3543\n",
            "Epoch 46/150 - 0.11s - loss: 1.0989 - acc: 0.3540 - val_loss: 1.0937 - val_acc: 0.3543\n",
            "Epoch 47/150 - 0.11s - loss: 1.0988 - acc: 0.3549 - val_loss: 1.0936 - val_acc: 0.3543\n",
            "Epoch 48/150 - 0.11s - loss: 1.0986 - acc: 0.3549 - val_loss: 1.0935 - val_acc: 0.3502\n",
            "Epoch 49/150 - 0.12s - loss: 1.0985 - acc: 0.3554 - val_loss: 1.0933 - val_acc: 0.3522\n",
            "Epoch 50/150 - 0.11s - loss: 1.0984 - acc: 0.3561 - val_loss: 1.0932 - val_acc: 0.3543\n",
            "Epoch 51/150 - 0.11s - loss: 1.0983 - acc: 0.3585 - val_loss: 1.0931 - val_acc: 0.3522\n",
            "Epoch 52/150 - 0.11s - loss: 1.0981 - acc: 0.3587 - val_loss: 1.0930 - val_acc: 0.3563\n",
            "Epoch 53/150 - 0.11s - loss: 1.0980 - acc: 0.3592 - val_loss: 1.0929 - val_acc: 0.3543\n",
            "Epoch 54/150 - 0.11s - loss: 1.0979 - acc: 0.3603 - val_loss: 1.0927 - val_acc: 0.3563\n",
            "Epoch 55/150 - 0.11s - loss: 1.0977 - acc: 0.3605 - val_loss: 1.0926 - val_acc: 0.3583\n",
            "Epoch 56/150 - 0.11s - loss: 1.0976 - acc: 0.3617 - val_loss: 1.0925 - val_acc: 0.3623\n",
            "Epoch 57/150 - 0.10s - loss: 1.0975 - acc: 0.3621 - val_loss: 1.0924 - val_acc: 0.3644\n",
            "Epoch 58/150 - 0.11s - loss: 1.0974 - acc: 0.3626 - val_loss: 1.0923 - val_acc: 0.3644\n",
            "Epoch 59/150 - 0.10s - loss: 1.0972 - acc: 0.3639 - val_loss: 1.0922 - val_acc: 0.3664\n",
            "Epoch 60/150 - 0.12s - loss: 1.0971 - acc: 0.3635 - val_loss: 1.0920 - val_acc: 0.3684\n",
            "Epoch 61/150 - 0.11s - loss: 1.0970 - acc: 0.3648 - val_loss: 1.0919 - val_acc: 0.3684\n",
            "Epoch 62/150 - 0.11s - loss: 1.0969 - acc: 0.3641 - val_loss: 1.0918 - val_acc: 0.3704\n",
            "Epoch 63/150 - 0.11s - loss: 1.0967 - acc: 0.3653 - val_loss: 1.0917 - val_acc: 0.3704\n",
            "Epoch 64/150 - 0.11s - loss: 1.0966 - acc: 0.3644 - val_loss: 1.0916 - val_acc: 0.3704\n",
            "Epoch 65/150 - 0.11s - loss: 1.0965 - acc: 0.3646 - val_loss: 1.0915 - val_acc: 0.3704\n",
            "Epoch 66/150 - 0.11s - loss: 1.0964 - acc: 0.3646 - val_loss: 1.0914 - val_acc: 0.3704\n",
            "Epoch 67/150 - 0.10s - loss: 1.0962 - acc: 0.3648 - val_loss: 1.0913 - val_acc: 0.3704\n",
            "Epoch 68/150 - 0.12s - loss: 1.0961 - acc: 0.3655 - val_loss: 1.0912 - val_acc: 0.3704\n",
            "Epoch 69/150 - 0.11s - loss: 1.0960 - acc: 0.3662 - val_loss: 1.0910 - val_acc: 0.3704\n",
            "Epoch 70/150 - 0.11s - loss: 1.0959 - acc: 0.3664 - val_loss: 1.0909 - val_acc: 0.3704\n",
            "Epoch 71/150 - 0.10s - loss: 1.0957 - acc: 0.3666 - val_loss: 1.0908 - val_acc: 0.3725\n",
            "Epoch 72/150 - 0.11s - loss: 1.0956 - acc: 0.3664 - val_loss: 1.0907 - val_acc: 0.3725\n",
            "Epoch 73/150 - 0.11s - loss: 1.0955 - acc: 0.3666 - val_loss: 1.0906 - val_acc: 0.3765\n",
            "Epoch 74/150 - 0.13s - loss: 1.0954 - acc: 0.3673 - val_loss: 1.0905 - val_acc: 0.3785\n",
            "Epoch 75/150 - 0.11s - loss: 1.0953 - acc: 0.3677 - val_loss: 1.0904 - val_acc: 0.3785\n",
            "Epoch 76/150 - 0.11s - loss: 1.0951 - acc: 0.3684 - val_loss: 1.0903 - val_acc: 0.3806\n",
            "Epoch 77/150 - 0.11s - loss: 1.0950 - acc: 0.3686 - val_loss: 1.0902 - val_acc: 0.3806\n",
            "Epoch 78/150 - 0.11s - loss: 1.0949 - acc: 0.3684 - val_loss: 1.0901 - val_acc: 0.3806\n",
            "Epoch 79/150 - 0.10s - loss: 1.0948 - acc: 0.3686 - val_loss: 1.0900 - val_acc: 0.3826\n",
            "Epoch 80/150 - 0.11s - loss: 1.0947 - acc: 0.3695 - val_loss: 1.0899 - val_acc: 0.3826\n",
            "Epoch 81/150 - 0.11s - loss: 1.0946 - acc: 0.3704 - val_loss: 1.0898 - val_acc: 0.3826\n",
            "Epoch 82/150 - 0.11s - loss: 1.0944 - acc: 0.3704 - val_loss: 1.0897 - val_acc: 0.3826\n",
            "Epoch 83/150 - 0.11s - loss: 1.0943 - acc: 0.3716 - val_loss: 1.0896 - val_acc: 0.3826\n",
            "Epoch 84/150 - 0.11s - loss: 1.0942 - acc: 0.3716 - val_loss: 1.0895 - val_acc: 0.3826\n",
            "Epoch 85/150 - 0.11s - loss: 1.0941 - acc: 0.3720 - val_loss: 1.0894 - val_acc: 0.3826\n",
            "Epoch 86/150 - 0.11s - loss: 1.0940 - acc: 0.3720 - val_loss: 1.0893 - val_acc: 0.3826\n",
            "Epoch 87/150 - 0.10s - loss: 1.0939 - acc: 0.3727 - val_loss: 1.0892 - val_acc: 0.3806\n",
            "Epoch 88/150 - 0.10s - loss: 1.0937 - acc: 0.3731 - val_loss: 1.0891 - val_acc: 0.3806\n",
            "Epoch 89/150 - 0.09s - loss: 1.0936 - acc: 0.3731 - val_loss: 1.0890 - val_acc: 0.3826\n",
            "Epoch 90/150 - 0.10s - loss: 1.0935 - acc: 0.3736 - val_loss: 1.0889 - val_acc: 0.3846\n",
            "Epoch 91/150 - 0.09s - loss: 1.0934 - acc: 0.3738 - val_loss: 1.0888 - val_acc: 0.3846\n",
            "Epoch 92/150 - 0.09s - loss: 1.0933 - acc: 0.3738 - val_loss: 1.0887 - val_acc: 0.3846\n",
            "Epoch 93/150 - 0.10s - loss: 1.0932 - acc: 0.3738 - val_loss: 1.0886 - val_acc: 0.3846\n",
            "Epoch 94/150 - 0.10s - loss: 1.0931 - acc: 0.3738 - val_loss: 1.0885 - val_acc: 0.3826\n",
            "Epoch 95/150 - 0.11s - loss: 1.0929 - acc: 0.3745 - val_loss: 1.0884 - val_acc: 0.3826\n",
            "Epoch 96/150 - 0.10s - loss: 1.0928 - acc: 0.3749 - val_loss: 1.0883 - val_acc: 0.3846\n",
            "Epoch 97/150 - 0.10s - loss: 1.0927 - acc: 0.3756 - val_loss: 1.0882 - val_acc: 0.3846\n",
            "Epoch 98/150 - 0.09s - loss: 1.0926 - acc: 0.3752 - val_loss: 1.0881 - val_acc: 0.3846\n",
            "Epoch 99/150 - 0.10s - loss: 1.0925 - acc: 0.3752 - val_loss: 1.0880 - val_acc: 0.3846\n",
            "Epoch 100/150 - 0.10s - loss: 1.0924 - acc: 0.3758 - val_loss: 1.0879 - val_acc: 0.3826\n",
            "Epoch 101/150 - 0.10s - loss: 1.0923 - acc: 0.3765 - val_loss: 1.0878 - val_acc: 0.3826\n",
            "Epoch 102/150 - 0.10s - loss: 1.0922 - acc: 0.3772 - val_loss: 1.0877 - val_acc: 0.3846\n",
            "Epoch 103/150 - 0.09s - loss: 1.0921 - acc: 0.3779 - val_loss: 1.0877 - val_acc: 0.3846\n",
            "Epoch 104/150 - 0.09s - loss: 1.0919 - acc: 0.3779 - val_loss: 1.0876 - val_acc: 0.3846\n",
            "Epoch 105/150 - 0.10s - loss: 1.0918 - acc: 0.3770 - val_loss: 1.0875 - val_acc: 0.3826\n",
            "Epoch 106/150 - 0.09s - loss: 1.0917 - acc: 0.3774 - val_loss: 1.0874 - val_acc: 0.3826\n",
            "Epoch 107/150 - 0.09s - loss: 1.0916 - acc: 0.3774 - val_loss: 1.0873 - val_acc: 0.3826\n",
            "Epoch 108/150 - 0.10s - loss: 1.0915 - acc: 0.3779 - val_loss: 1.0872 - val_acc: 0.3826\n",
            "Epoch 109/150 - 0.09s - loss: 1.0914 - acc: 0.3781 - val_loss: 1.0871 - val_acc: 0.3846\n",
            "Epoch 110/150 - 0.09s - loss: 1.0913 - acc: 0.3783 - val_loss: 1.0870 - val_acc: 0.3846\n",
            "Epoch 111/150 - 0.10s - loss: 1.0912 - acc: 0.3797 - val_loss: 1.0869 - val_acc: 0.3826\n",
            "Epoch 112/150 - 0.09s - loss: 1.0911 - acc: 0.3806 - val_loss: 1.0868 - val_acc: 0.3806\n",
            "Epoch 113/150 - 0.09s - loss: 1.0910 - acc: 0.3801 - val_loss: 1.0867 - val_acc: 0.3826\n",
            "Epoch 114/150 - 0.10s - loss: 1.0909 - acc: 0.3806 - val_loss: 1.0867 - val_acc: 0.3846\n",
            "Epoch 115/150 - 0.09s - loss: 1.0908 - acc: 0.3806 - val_loss: 1.0866 - val_acc: 0.3866\n",
            "Epoch 116/150 - 0.09s - loss: 1.0907 - acc: 0.3808 - val_loss: 1.0865 - val_acc: 0.3866\n",
            "Epoch 117/150 - 0.10s - loss: 1.0905 - acc: 0.3808 - val_loss: 1.0864 - val_acc: 0.3866\n",
            "Epoch 118/150 - 0.09s - loss: 1.0904 - acc: 0.3806 - val_loss: 1.0863 - val_acc: 0.3887\n",
            "Epoch 119/150 - 0.09s - loss: 1.0903 - acc: 0.3817 - val_loss: 1.0862 - val_acc: 0.3907\n",
            "Epoch 120/150 - 0.10s - loss: 1.0902 - acc: 0.3815 - val_loss: 1.0861 - val_acc: 0.3887\n",
            "Epoch 121/150 - 0.09s - loss: 1.0901 - acc: 0.3815 - val_loss: 1.0860 - val_acc: 0.3887\n",
            "Epoch 122/150 - 0.09s - loss: 1.0900 - acc: 0.3812 - val_loss: 1.0859 - val_acc: 0.3887\n",
            "Epoch 123/150 - 0.10s - loss: 1.0899 - acc: 0.3815 - val_loss: 1.0858 - val_acc: 0.3887\n",
            "Epoch 124/150 - 0.09s - loss: 1.0898 - acc: 0.3819 - val_loss: 1.0858 - val_acc: 0.3887\n",
            "Epoch 125/150 - 0.09s - loss: 1.0897 - acc: 0.3821 - val_loss: 1.0857 - val_acc: 0.3887\n",
            "Epoch 126/150 - 0.10s - loss: 1.0896 - acc: 0.3826 - val_loss: 1.0856 - val_acc: 0.3866\n",
            "Epoch 127/150 - 0.09s - loss: 1.0895 - acc: 0.3833 - val_loss: 1.0855 - val_acc: 0.3887\n",
            "Epoch 128/150 - 0.10s - loss: 1.0894 - acc: 0.3837 - val_loss: 1.0854 - val_acc: 0.3846\n",
            "Epoch 129/150 - 0.12s - loss: 1.0893 - acc: 0.3839 - val_loss: 1.0853 - val_acc: 0.3866\n",
            "Epoch 130/150 - 0.10s - loss: 1.0892 - acc: 0.3842 - val_loss: 1.0852 - val_acc: 0.3866\n",
            "Epoch 131/150 - 0.10s - loss: 1.0891 - acc: 0.3846 - val_loss: 1.0851 - val_acc: 0.3887\n",
            "Epoch 132/150 - 0.10s - loss: 1.0890 - acc: 0.3848 - val_loss: 1.0851 - val_acc: 0.3907\n",
            "Epoch 133/150 - 0.09s - loss: 1.0889 - acc: 0.3851 - val_loss: 1.0850 - val_acc: 0.3907\n",
            "Epoch 134/150 - 0.10s - loss: 1.0888 - acc: 0.3848 - val_loss: 1.0849 - val_acc: 0.3907\n",
            "Epoch 135/150 - 0.10s - loss: 1.0887 - acc: 0.3853 - val_loss: 1.0848 - val_acc: 0.3907\n",
            "Epoch 136/150 - 0.10s - loss: 1.0886 - acc: 0.3864 - val_loss: 1.0847 - val_acc: 0.3907\n",
            "Epoch 137/150 - 0.10s - loss: 1.0885 - acc: 0.3871 - val_loss: 1.0847 - val_acc: 0.3887\n",
            "Epoch 138/150 - 0.10s - loss: 1.0884 - acc: 0.3871 - val_loss: 1.0846 - val_acc: 0.3887\n",
            "Epoch 139/150 - 0.09s - loss: 1.0883 - acc: 0.3878 - val_loss: 1.0845 - val_acc: 0.3887\n",
            "Epoch 140/150 - 0.10s - loss: 1.0882 - acc: 0.3880 - val_loss: 1.0844 - val_acc: 0.3887\n",
            "Epoch 141/150 - 0.10s - loss: 1.0881 - acc: 0.3896 - val_loss: 1.0843 - val_acc: 0.3907\n",
            "Epoch 142/150 - 0.11s - loss: 1.0880 - acc: 0.3893 - val_loss: 1.0842 - val_acc: 0.3927\n",
            "Epoch 143/150 - 0.10s - loss: 1.0879 - acc: 0.3896 - val_loss: 1.0842 - val_acc: 0.3927\n",
            "Epoch 144/150 - 0.10s - loss: 1.0878 - acc: 0.3898 - val_loss: 1.0841 - val_acc: 0.3947\n",
            "Epoch 145/150 - 0.09s - loss: 1.0877 - acc: 0.3900 - val_loss: 1.0840 - val_acc: 0.3907\n",
            "Epoch 146/150 - 0.10s - loss: 1.0876 - acc: 0.3907 - val_loss: 1.0839 - val_acc: 0.3927\n",
            "Epoch 147/150 - 0.09s - loss: 1.0875 - acc: 0.3893 - val_loss: 1.0838 - val_acc: 0.3968\n",
            "Epoch 148/150 - 0.09s - loss: 1.0874 - acc: 0.3900 - val_loss: 1.0837 - val_acc: 0.3968\n",
            "Epoch 149/150 - 0.10s - loss: 1.0873 - acc: 0.3905 - val_loss: 1.0837 - val_acc: 0.3968\n",
            "Epoch 150/150 - 0.09s - loss: 1.0872 - acc: 0.3905 - val_loss: 1.0836 - val_acc: 0.3988\n",
            "\n",
            "Combination 109/252:\n",
            "Hidden Layers: [256, 128], Activation: relu, Learning Rate: 0.01, Batch Size: 32, Epochs: 50\n",
            "Epoch 1/50 - 0.12s - loss: 1.0831 - acc: 0.4073 - val_loss: 1.0890 - val_acc: 0.3745\n",
            "Epoch 2/50 - 0.15s - loss: 1.0699 - acc: 0.4399 - val_loss: 1.0797 - val_acc: 0.4069\n",
            "Epoch 3/50 - 0.13s - loss: 1.0589 - acc: 0.4584 - val_loss: 1.0725 - val_acc: 0.4150\n",
            "Epoch 4/50 - 0.13s - loss: 1.0497 - acc: 0.4613 - val_loss: 1.0664 - val_acc: 0.4332\n",
            "Epoch 5/50 - 0.15s - loss: 1.0418 - acc: 0.4728 - val_loss: 1.0620 - val_acc: 0.4372\n",
            "Epoch 6/50 - 0.12s - loss: 1.0342 - acc: 0.4809 - val_loss: 1.0569 - val_acc: 0.4636\n",
            "Epoch 7/50 - 0.13s - loss: 1.0271 - acc: 0.4897 - val_loss: 1.0521 - val_acc: 0.4676\n",
            "Epoch 8/50 - 0.15s - loss: 1.0205 - acc: 0.4888 - val_loss: 1.0480 - val_acc: 0.4676\n",
            "Epoch 9/50 - 0.13s - loss: 1.0173 - acc: 0.4912 - val_loss: 1.0455 - val_acc: 0.4777\n",
            "Epoch 10/50 - 0.12s - loss: 1.0093 - acc: 0.5040 - val_loss: 1.0409 - val_acc: 0.4899\n",
            "Epoch 11/50 - 0.15s - loss: 1.0017 - acc: 0.5061 - val_loss: 1.0336 - val_acc: 0.4879\n",
            "Epoch 12/50 - 0.12s - loss: 0.9958 - acc: 0.5133 - val_loss: 1.0299 - val_acc: 0.4879\n",
            "Epoch 13/50 - 0.12s - loss: 0.9901 - acc: 0.5148 - val_loss: 1.0256 - val_acc: 0.4919\n",
            "Epoch 14/50 - 0.14s - loss: 0.9940 - acc: 0.5052 - val_loss: 1.0278 - val_acc: 0.4939\n",
            "Epoch 15/50 - 0.14s - loss: 0.9798 - acc: 0.5261 - val_loss: 1.0175 - val_acc: 0.4980\n",
            "Epoch 16/50 - 0.13s - loss: 0.9750 - acc: 0.5236 - val_loss: 1.0150 - val_acc: 0.5000\n",
            "Epoch 17/50 - 0.16s - loss: 0.9714 - acc: 0.5328 - val_loss: 1.0120 - val_acc: 0.5162\n",
            "Epoch 18/50 - 0.13s - loss: 0.9674 - acc: 0.5340 - val_loss: 1.0078 - val_acc: 0.5040\n",
            "Epoch 19/50 - 0.13s - loss: 0.9605 - acc: 0.5405 - val_loss: 1.0033 - val_acc: 0.5202\n",
            "Epoch 20/50 - 0.15s - loss: 0.9541 - acc: 0.5400 - val_loss: 0.9992 - val_acc: 0.5263\n",
            "Epoch 21/50 - 0.14s - loss: 0.9487 - acc: 0.5425 - val_loss: 0.9947 - val_acc: 0.5243\n",
            "Epoch 22/50 - 0.13s - loss: 0.9443 - acc: 0.5459 - val_loss: 0.9907 - val_acc: 0.5283\n",
            "Epoch 23/50 - 0.19s - loss: 0.9525 - acc: 0.5493 - val_loss: 1.0001 - val_acc: 0.5526\n",
            "Epoch 24/50 - 0.15s - loss: 0.9383 - acc: 0.5603 - val_loss: 0.9907 - val_acc: 0.5445\n",
            "Epoch 25/50 - 0.15s - loss: 0.9332 - acc: 0.5657 - val_loss: 0.9860 - val_acc: 0.5486\n",
            "Epoch 26/50 - 0.16s - loss: 0.9278 - acc: 0.5646 - val_loss: 0.9818 - val_acc: 0.5486\n",
            "Epoch 27/50 - 0.14s - loss: 0.9280 - acc: 0.5630 - val_loss: 0.9802 - val_acc: 0.5466\n",
            "Epoch 28/50 - 0.13s - loss: 0.9256 - acc: 0.5616 - val_loss: 0.9828 - val_acc: 0.5283\n",
            "Epoch 29/50 - 0.16s - loss: 0.9204 - acc: 0.5621 - val_loss: 0.9798 - val_acc: 0.5243\n",
            "Epoch 30/50 - 0.12s - loss: 0.9218 - acc: 0.5711 - val_loss: 0.9795 - val_acc: 0.5547\n",
            "Epoch 31/50 - 0.13s - loss: 0.9126 - acc: 0.5769 - val_loss: 0.9763 - val_acc: 0.5628\n",
            "Epoch 32/50 - 0.15s - loss: 0.9056 - acc: 0.5760 - val_loss: 0.9685 - val_acc: 0.5526\n",
            "Epoch 33/50 - 0.14s - loss: 0.9201 - acc: 0.5709 - val_loss: 0.9817 - val_acc: 0.5567\n",
            "Epoch 34/50 - 0.15s - loss: 0.8975 - acc: 0.5816 - val_loss: 0.9648 - val_acc: 0.5567\n",
            "Epoch 35/50 - 0.16s - loss: 0.8956 - acc: 0.5877 - val_loss: 0.9661 - val_acc: 0.5668\n",
            "Epoch 36/50 - 0.13s - loss: 0.8910 - acc: 0.5866 - val_loss: 0.9625 - val_acc: 0.5547\n",
            "Epoch 37/50 - 0.14s - loss: 0.9015 - acc: 0.5749 - val_loss: 0.9711 - val_acc: 0.5628\n",
            "Epoch 38/50 - 0.15s - loss: 0.8838 - acc: 0.5906 - val_loss: 0.9621 - val_acc: 0.5607\n",
            "Epoch 39/50 - 0.14s - loss: 0.8850 - acc: 0.5949 - val_loss: 0.9635 - val_acc: 0.5729\n",
            "Epoch 40/50 - 0.13s - loss: 0.8781 - acc: 0.5933 - val_loss: 0.9602 - val_acc: 0.5607\n",
            "Epoch 41/50 - 0.18s - loss: 0.8745 - acc: 0.5985 - val_loss: 0.9596 - val_acc: 0.5709\n",
            "Epoch 42/50 - 0.13s - loss: 0.8761 - acc: 0.5972 - val_loss: 0.9672 - val_acc: 0.5466\n",
            "Epoch 43/50 - 0.13s - loss: 0.8696 - acc: 0.5985 - val_loss: 0.9567 - val_acc: 0.5668\n",
            "Epoch 44/50 - 0.15s - loss: 0.8647 - acc: 0.5978 - val_loss: 0.9547 - val_acc: 0.5547\n",
            "Epoch 45/50 - 0.14s - loss: 0.8619 - acc: 0.6039 - val_loss: 0.9561 - val_acc: 0.5628\n",
            "Epoch 46/50 - 0.12s - loss: 0.8625 - acc: 0.6118 - val_loss: 0.9583 - val_acc: 0.5668\n",
            "Epoch 47/50 - 0.16s - loss: 0.8579 - acc: 0.5996 - val_loss: 0.9537 - val_acc: 0.5587\n",
            "Epoch 48/50 - 0.13s - loss: 0.8599 - acc: 0.6010 - val_loss: 0.9585 - val_acc: 0.5364\n",
            "Epoch 49/50 - 0.13s - loss: 0.8563 - acc: 0.6012 - val_loss: 0.9597 - val_acc: 0.5425\n",
            "Epoch 50/50 - 0.15s - loss: 0.8501 - acc: 0.6113 - val_loss: 0.9596 - val_acc: 0.5506\n",
            "\n",
            "Combination 110/252:\n",
            "Hidden Layers: [256, 128], Activation: relu, Learning Rate: 0.01, Batch Size: 32, Epochs: 100\n",
            "Epoch 1/100 - 0.14s - loss: 1.0771 - acc: 0.4069 - val_loss: 1.0862 - val_acc: 0.4028\n",
            "Epoch 2/100 - 0.12s - loss: 1.0644 - acc: 0.4363 - val_loss: 1.0769 - val_acc: 0.4231\n",
            "Epoch 3/100 - 0.13s - loss: 1.0539 - acc: 0.4467 - val_loss: 1.0684 - val_acc: 0.4291\n",
            "Epoch 4/100 - 0.13s - loss: 1.0466 - acc: 0.4656 - val_loss: 1.0649 - val_acc: 0.4453\n",
            "Epoch 5/100 - 0.14s - loss: 1.0392 - acc: 0.4741 - val_loss: 1.0588 - val_acc: 0.4636\n",
            "Epoch 6/100 - 0.12s - loss: 1.0308 - acc: 0.4809 - val_loss: 1.0528 - val_acc: 0.4676\n",
            "Epoch 7/100 - 0.15s - loss: 1.0237 - acc: 0.4937 - val_loss: 1.0479 - val_acc: 0.4696\n",
            "Epoch 8/100 - 0.14s - loss: 1.0176 - acc: 0.4987 - val_loss: 1.0428 - val_acc: 0.4777\n",
            "Epoch 9/100 - 0.13s - loss: 1.0095 - acc: 0.4993 - val_loss: 1.0357 - val_acc: 0.4980\n",
            "Epoch 10/100 - 0.13s - loss: 1.0030 - acc: 0.5085 - val_loss: 1.0313 - val_acc: 0.4919\n",
            "Epoch 11/100 - 0.13s - loss: 0.9953 - acc: 0.5171 - val_loss: 1.0257 - val_acc: 0.5020\n",
            "Epoch 12/100 - 0.13s - loss: 0.9887 - acc: 0.5229 - val_loss: 1.0218 - val_acc: 0.5101\n",
            "Epoch 13/100 - 0.13s - loss: 0.9824 - acc: 0.5274 - val_loss: 1.0168 - val_acc: 0.5121\n",
            "Epoch 14/100 - 0.13s - loss: 0.9781 - acc: 0.5279 - val_loss: 1.0149 - val_acc: 0.5000\n",
            "Epoch 15/100 - 0.13s - loss: 0.9744 - acc: 0.5259 - val_loss: 1.0120 - val_acc: 0.5101\n",
            "Epoch 16/100 - 0.13s - loss: 0.9646 - acc: 0.5445 - val_loss: 1.0037 - val_acc: 0.5283\n",
            "Epoch 17/100 - 0.13s - loss: 0.9636 - acc: 0.5328 - val_loss: 1.0028 - val_acc: 0.5223\n",
            "Epoch 18/100 - 0.12s - loss: 0.9537 - acc: 0.5463 - val_loss: 0.9967 - val_acc: 0.5445\n",
            "Epoch 19/100 - 0.13s - loss: 0.9494 - acc: 0.5490 - val_loss: 0.9916 - val_acc: 0.5466\n",
            "Epoch 20/100 - 0.13s - loss: 0.9507 - acc: 0.5515 - val_loss: 0.9943 - val_acc: 0.5506\n",
            "Epoch 21/100 - 0.12s - loss: 0.9426 - acc: 0.5544 - val_loss: 0.9881 - val_acc: 0.5688\n",
            "Epoch 22/100 - 0.12s - loss: 0.9375 - acc: 0.5587 - val_loss: 0.9840 - val_acc: 0.5587\n",
            "Epoch 23/100 - 0.13s - loss: 0.9393 - acc: 0.5499 - val_loss: 0.9855 - val_acc: 0.5445\n",
            "Epoch 24/100 - 0.13s - loss: 0.9271 - acc: 0.5625 - val_loss: 0.9779 - val_acc: 0.5324\n",
            "Epoch 25/100 - 0.13s - loss: 0.9238 - acc: 0.5670 - val_loss: 0.9769 - val_acc: 0.5385\n",
            "Epoch 26/100 - 0.13s - loss: 0.9189 - acc: 0.5686 - val_loss: 0.9725 - val_acc: 0.5486\n",
            "Epoch 27/100 - 0.13s - loss: 0.9147 - acc: 0.5682 - val_loss: 0.9706 - val_acc: 0.5405\n",
            "Epoch 28/100 - 0.13s - loss: 0.9278 - acc: 0.5551 - val_loss: 0.9892 - val_acc: 0.5223\n",
            "Epoch 29/100 - 0.12s - loss: 0.9079 - acc: 0.5758 - val_loss: 0.9681 - val_acc: 0.5466\n",
            "Epoch 30/100 - 0.12s - loss: 0.9048 - acc: 0.5742 - val_loss: 0.9642 - val_acc: 0.5628\n",
            "Epoch 31/100 - 0.14s - loss: 0.9079 - acc: 0.5810 - val_loss: 0.9694 - val_acc: 0.5506\n",
            "Epoch 32/100 - 0.14s - loss: 0.8999 - acc: 0.5731 - val_loss: 0.9599 - val_acc: 0.5466\n",
            "Epoch 33/100 - 0.13s - loss: 0.9064 - acc: 0.5715 - val_loss: 0.9731 - val_acc: 0.5344\n",
            "Epoch 34/100 - 0.14s - loss: 0.9003 - acc: 0.5794 - val_loss: 0.9696 - val_acc: 0.5385\n",
            "Epoch 35/100 - 0.13s - loss: 0.8941 - acc: 0.5810 - val_loss: 0.9596 - val_acc: 0.5486\n",
            "Epoch 36/100 - 0.13s - loss: 0.8859 - acc: 0.5866 - val_loss: 0.9582 - val_acc: 0.5506\n",
            "Epoch 37/100 - 0.14s - loss: 0.8851 - acc: 0.5909 - val_loss: 0.9611 - val_acc: 0.5425\n",
            "Epoch 38/100 - 0.13s - loss: 0.8785 - acc: 0.5929 - val_loss: 0.9519 - val_acc: 0.5567\n",
            "Epoch 39/100 - 0.13s - loss: 0.8778 - acc: 0.5938 - val_loss: 0.9589 - val_acc: 0.5567\n",
            "Epoch 40/100 - 0.12s - loss: 0.8852 - acc: 0.5886 - val_loss: 0.9614 - val_acc: 0.5668\n",
            "Epoch 41/100 - 0.12s - loss: 0.8696 - acc: 0.6010 - val_loss: 0.9518 - val_acc: 0.5425\n",
            "Epoch 42/100 - 0.13s - loss: 0.8678 - acc: 0.5985 - val_loss: 0.9533 - val_acc: 0.5466\n",
            "Epoch 43/100 - 0.13s - loss: 0.8667 - acc: 0.5960 - val_loss: 0.9549 - val_acc: 0.5466\n",
            "Epoch 44/100 - 0.13s - loss: 0.8688 - acc: 0.5933 - val_loss: 0.9542 - val_acc: 0.5506\n",
            "Epoch 45/100 - 0.13s - loss: 0.8616 - acc: 0.5983 - val_loss: 0.9477 - val_acc: 0.5466\n",
            "Epoch 46/100 - 0.12s - loss: 0.8522 - acc: 0.6104 - val_loss: 0.9460 - val_acc: 0.5607\n",
            "Epoch 47/100 - 0.13s - loss: 0.8702 - acc: 0.6014 - val_loss: 0.9655 - val_acc: 0.5628\n",
            "Epoch 48/100 - 0.12s - loss: 0.8599 - acc: 0.6026 - val_loss: 0.9640 - val_acc: 0.5283\n",
            "Epoch 49/100 - 0.13s - loss: 0.8504 - acc: 0.6152 - val_loss: 0.9527 - val_acc: 0.5486\n",
            "Epoch 50/100 - 0.13s - loss: 0.8593 - acc: 0.6001 - val_loss: 0.9693 - val_acc: 0.5243\n",
            "Epoch 51/100 - 0.13s - loss: 0.8389 - acc: 0.6192 - val_loss: 0.9461 - val_acc: 0.5405\n",
            "Epoch 52/100 - 0.16s - loss: 0.8390 - acc: 0.6143 - val_loss: 0.9486 - val_acc: 0.5506\n",
            "Epoch 53/100 - 0.13s - loss: 0.8348 - acc: 0.6228 - val_loss: 0.9464 - val_acc: 0.5567\n",
            "Epoch 54/100 - 0.13s - loss: 0.8321 - acc: 0.6199 - val_loss: 0.9471 - val_acc: 0.5709\n",
            "Epoch 55/100 - 0.13s - loss: 0.8297 - acc: 0.6242 - val_loss: 0.9465 - val_acc: 0.5506\n",
            "Epoch 56/100 - 0.18s - loss: 0.8432 - acc: 0.6179 - val_loss: 0.9572 - val_acc: 0.5729\n",
            "Epoch 57/100 - 0.13s - loss: 0.8703 - acc: 0.5877 - val_loss: 0.9966 - val_acc: 0.5101\n",
            "Epoch 58/100 - 0.13s - loss: 0.8185 - acc: 0.6329 - val_loss: 0.9370 - val_acc: 0.5547\n",
            "Epoch 59/100 - 0.13s - loss: 0.8259 - acc: 0.6140 - val_loss: 0.9457 - val_acc: 0.5385\n",
            "Epoch 60/100 - 0.14s - loss: 0.8193 - acc: 0.6325 - val_loss: 0.9512 - val_acc: 0.5506\n",
            "Epoch 61/100 - 0.14s - loss: 0.8155 - acc: 0.6343 - val_loss: 0.9490 - val_acc: 0.5344\n",
            "Epoch 62/100 - 0.13s - loss: 0.8086 - acc: 0.6379 - val_loss: 0.9429 - val_acc: 0.5810\n",
            "Epoch 63/100 - 0.13s - loss: 0.8064 - acc: 0.6424 - val_loss: 0.9432 - val_acc: 0.5405\n",
            "Epoch 64/100 - 0.13s - loss: 0.8456 - acc: 0.6170 - val_loss: 0.9752 - val_acc: 0.5709\n",
            "Epoch 65/100 - 0.13s - loss: 0.8135 - acc: 0.6314 - val_loss: 0.9531 - val_acc: 0.5405\n",
            "Epoch 66/100 - 0.13s - loss: 0.8012 - acc: 0.6478 - val_loss: 0.9403 - val_acc: 0.5911\n",
            "Epoch 67/100 - 0.13s - loss: 0.8086 - acc: 0.6345 - val_loss: 0.9632 - val_acc: 0.5283\n",
            "Epoch 68/100 - 0.12s - loss: 0.8251 - acc: 0.6244 - val_loss: 0.9610 - val_acc: 0.5567\n",
            "Epoch 69/100 - 0.13s - loss: 0.7900 - acc: 0.6543 - val_loss: 0.9469 - val_acc: 0.5506\n",
            "Epoch 70/100 - 0.13s - loss: 0.8312 - acc: 0.6116 - val_loss: 0.9741 - val_acc: 0.5466\n",
            "Epoch 71/100 - 0.13s - loss: 0.7892 - acc: 0.6493 - val_loss: 0.9394 - val_acc: 0.5830\n",
            "Epoch 72/100 - 0.13s - loss: 0.8148 - acc: 0.6305 - val_loss: 0.9637 - val_acc: 0.5607\n",
            "Epoch 73/100 - 0.13s - loss: 0.8168 - acc: 0.6251 - val_loss: 0.9777 - val_acc: 0.5385\n",
            "Epoch 74/100 - 0.14s - loss: 0.7925 - acc: 0.6480 - val_loss: 0.9506 - val_acc: 0.5729\n",
            "Epoch 75/100 - 0.13s - loss: 0.7762 - acc: 0.6626 - val_loss: 0.9471 - val_acc: 0.5567\n",
            "Epoch 76/100 - 0.14s - loss: 0.7719 - acc: 0.6606 - val_loss: 0.9500 - val_acc: 0.5486\n",
            "Epoch 77/100 - 0.13s - loss: 0.7710 - acc: 0.6613 - val_loss: 0.9492 - val_acc: 0.5506\n",
            "Epoch 78/100 - 0.12s - loss: 0.8184 - acc: 0.6287 - val_loss: 0.9843 - val_acc: 0.5668\n",
            "Epoch 79/100 - 0.17s - loss: 0.7677 - acc: 0.6583 - val_loss: 0.9412 - val_acc: 0.5769\n",
            "Epoch 80/100 - 0.14s - loss: 0.7601 - acc: 0.6732 - val_loss: 0.9414 - val_acc: 0.5789\n",
            "Epoch 81/100 - 0.13s - loss: 0.7562 - acc: 0.6723 - val_loss: 0.9491 - val_acc: 0.5688\n",
            "Epoch 82/100 - 0.13s - loss: 0.7964 - acc: 0.6388 - val_loss: 0.9724 - val_acc: 0.5668\n",
            "Epoch 83/100 - 0.13s - loss: 0.7533 - acc: 0.6703 - val_loss: 0.9466 - val_acc: 0.5951\n",
            "Epoch 84/100 - 0.14s - loss: 0.7521 - acc: 0.6734 - val_loss: 0.9506 - val_acc: 0.5506\n",
            "Epoch 85/100 - 0.14s - loss: 0.7805 - acc: 0.6536 - val_loss: 0.9780 - val_acc: 0.5385\n",
            "Epoch 86/100 - 0.13s - loss: 0.7402 - acc: 0.6849 - val_loss: 0.9440 - val_acc: 0.5709\n",
            "Epoch 87/100 - 0.13s - loss: 0.7445 - acc: 0.6748 - val_loss: 0.9430 - val_acc: 0.5749\n",
            "Epoch 88/100 - 0.13s - loss: 0.7613 - acc: 0.6685 - val_loss: 0.9669 - val_acc: 0.5709\n",
            "Epoch 89/100 - 0.13s - loss: 0.7414 - acc: 0.6815 - val_loss: 0.9595 - val_acc: 0.5486\n",
            "Epoch 90/100 - 0.12s - loss: 0.7312 - acc: 0.6887 - val_loss: 0.9537 - val_acc: 0.5567\n",
            "Epoch 91/100 - 0.13s - loss: 0.7366 - acc: 0.6815 - val_loss: 0.9568 - val_acc: 0.5607\n",
            "Epoch 92/100 - 0.12s - loss: 0.7333 - acc: 0.6831 - val_loss: 0.9692 - val_acc: 0.5526\n",
            "Epoch 93/100 - 0.13s - loss: 0.7421 - acc: 0.6723 - val_loss: 0.9547 - val_acc: 0.5749\n",
            "Epoch 94/100 - 0.12s - loss: 0.7471 - acc: 0.6705 - val_loss: 0.9904 - val_acc: 0.5162\n",
            "Epoch 95/100 - 0.13s - loss: 0.7379 - acc: 0.6867 - val_loss: 0.9631 - val_acc: 0.5830\n",
            "Epoch 96/100 - 0.13s - loss: 0.7404 - acc: 0.6725 - val_loss: 0.9920 - val_acc: 0.5202\n",
            "Epoch 97/100 - 0.14s - loss: 0.7042 - acc: 0.7011 - val_loss: 0.9434 - val_acc: 0.5870\n",
            "Epoch 98/100 - 0.12s - loss: 0.7363 - acc: 0.6867 - val_loss: 0.9646 - val_acc: 0.5789\n",
            "Epoch 99/100 - 0.12s - loss: 0.7080 - acc: 0.6934 - val_loss: 0.9515 - val_acc: 0.5810\n",
            "Epoch 100/100 - 0.12s - loss: 0.7254 - acc: 0.6768 - val_loss: 0.9637 - val_acc: 0.5668\n",
            "\n",
            "Combination 111/252:\n",
            "Hidden Layers: [256, 128], Activation: relu, Learning Rate: 0.01, Batch Size: 32, Epochs: 150\n",
            "Epoch 1/150 - 0.13s - loss: 1.0772 - acc: 0.4161 - val_loss: 1.0868 - val_acc: 0.3644\n",
            "Epoch 2/150 - 0.13s - loss: 1.0664 - acc: 0.4420 - val_loss: 1.0789 - val_acc: 0.3907\n",
            "Epoch 3/150 - 0.15s - loss: 1.0566 - acc: 0.4579 - val_loss: 1.0720 - val_acc: 0.4312\n",
            "Epoch 4/150 - 0.16s - loss: 1.0489 - acc: 0.4658 - val_loss: 1.0679 - val_acc: 0.4332\n",
            "Epoch 5/150 - 0.14s - loss: 1.0418 - acc: 0.4705 - val_loss: 1.0645 - val_acc: 0.4291\n",
            "Epoch 6/150 - 0.13s - loss: 1.0334 - acc: 0.4732 - val_loss: 1.0563 - val_acc: 0.4757\n",
            "Epoch 7/150 - 0.13s - loss: 1.0259 - acc: 0.4910 - val_loss: 1.0535 - val_acc: 0.4514\n",
            "Epoch 8/150 - 0.12s - loss: 1.0179 - acc: 0.4984 - val_loss: 1.0466 - val_acc: 0.4696\n",
            "Epoch 9/150 - 0.13s - loss: 1.0108 - acc: 0.5000 - val_loss: 1.0411 - val_acc: 0.4879\n",
            "Epoch 10/150 - 0.13s - loss: 1.0042 - acc: 0.5047 - val_loss: 1.0375 - val_acc: 0.4777\n",
            "Epoch 11/150 - 0.14s - loss: 0.9986 - acc: 0.5074 - val_loss: 1.0342 - val_acc: 0.4818\n",
            "Epoch 12/150 - 0.13s - loss: 0.9995 - acc: 0.4966 - val_loss: 1.0390 - val_acc: 0.4615\n",
            "Epoch 13/150 - 0.13s - loss: 0.9837 - acc: 0.5281 - val_loss: 1.0221 - val_acc: 0.5040\n",
            "Epoch 14/150 - 0.12s - loss: 0.9793 - acc: 0.5283 - val_loss: 1.0186 - val_acc: 0.4980\n",
            "Epoch 15/150 - 0.15s - loss: 0.9759 - acc: 0.5340 - val_loss: 1.0144 - val_acc: 0.5162\n",
            "Epoch 16/150 - 0.13s - loss: 0.9677 - acc: 0.5333 - val_loss: 1.0095 - val_acc: 0.5202\n",
            "Epoch 17/150 - 0.13s - loss: 0.9621 - acc: 0.5364 - val_loss: 1.0066 - val_acc: 0.5081\n",
            "Epoch 18/150 - 0.12s - loss: 0.9547 - acc: 0.5481 - val_loss: 1.0002 - val_acc: 0.5142\n",
            "Epoch 19/150 - 0.13s - loss: 0.9507 - acc: 0.5475 - val_loss: 0.9969 - val_acc: 0.5182\n",
            "Epoch 20/150 - 0.12s - loss: 0.9459 - acc: 0.5558 - val_loss: 0.9946 - val_acc: 0.5142\n",
            "Epoch 21/150 - 0.13s - loss: 0.9401 - acc: 0.5580 - val_loss: 0.9891 - val_acc: 0.5425\n",
            "Epoch 22/150 - 0.13s - loss: 0.9392 - acc: 0.5542 - val_loss: 0.9887 - val_acc: 0.5466\n",
            "Epoch 23/150 - 0.13s - loss: 0.9346 - acc: 0.5596 - val_loss: 0.9898 - val_acc: 0.5263\n",
            "Epoch 24/150 - 0.13s - loss: 0.9302 - acc: 0.5596 - val_loss: 0.9850 - val_acc: 0.5243\n",
            "Epoch 25/150 - 0.13s - loss: 0.9275 - acc: 0.5643 - val_loss: 0.9810 - val_acc: 0.5486\n",
            "Epoch 26/150 - 0.12s - loss: 0.9233 - acc: 0.5673 - val_loss: 0.9845 - val_acc: 0.5243\n",
            "Epoch 27/150 - 0.12s - loss: 0.9145 - acc: 0.5722 - val_loss: 0.9746 - val_acc: 0.5283\n",
            "Epoch 28/150 - 0.13s - loss: 0.9109 - acc: 0.5733 - val_loss: 0.9714 - val_acc: 0.5466\n",
            "Epoch 29/150 - 0.14s - loss: 0.9104 - acc: 0.5738 - val_loss: 0.9774 - val_acc: 0.5182\n",
            "Epoch 30/150 - 0.12s - loss: 0.9059 - acc: 0.5778 - val_loss: 0.9686 - val_acc: 0.5425\n",
            "Epoch 31/150 - 0.12s - loss: 0.9081 - acc: 0.5735 - val_loss: 0.9813 - val_acc: 0.5243\n",
            "Epoch 32/150 - 0.13s - loss: 0.9006 - acc: 0.5816 - val_loss: 0.9732 - val_acc: 0.5506\n",
            "Epoch 33/150 - 0.13s - loss: 0.9070 - acc: 0.5731 - val_loss: 0.9772 - val_acc: 0.5324\n",
            "Epoch 34/150 - 0.12s - loss: 0.8934 - acc: 0.5801 - val_loss: 0.9636 - val_acc: 0.5364\n",
            "Epoch 35/150 - 0.12s - loss: 0.8868 - acc: 0.5875 - val_loss: 0.9634 - val_acc: 0.5344\n",
            "Epoch 36/150 - 0.12s - loss: 0.9111 - acc: 0.5753 - val_loss: 0.9834 - val_acc: 0.5243\n",
            "Epoch 37/150 - 0.12s - loss: 0.8806 - acc: 0.5940 - val_loss: 0.9632 - val_acc: 0.5344\n",
            "Epoch 38/150 - 0.13s - loss: 0.8829 - acc: 0.5886 - val_loss: 0.9671 - val_acc: 0.5223\n",
            "Epoch 39/150 - 0.13s - loss: 0.9172 - acc: 0.5740 - val_loss: 0.9920 - val_acc: 0.5405\n",
            "Epoch 40/150 - 0.12s - loss: 0.8786 - acc: 0.5933 - val_loss: 0.9681 - val_acc: 0.5283\n",
            "Epoch 41/150 - 0.12s - loss: 0.8670 - acc: 0.6008 - val_loss: 0.9565 - val_acc: 0.5405\n",
            "Epoch 42/150 - 0.12s - loss: 0.8657 - acc: 0.6012 - val_loss: 0.9581 - val_acc: 0.5344\n",
            "Epoch 43/150 - 0.12s - loss: 0.8645 - acc: 0.6003 - val_loss: 0.9550 - val_acc: 0.5445\n",
            "Epoch 44/150 - 0.12s - loss: 0.8695 - acc: 0.5949 - val_loss: 0.9669 - val_acc: 0.5121\n",
            "Epoch 45/150 - 0.13s - loss: 0.8859 - acc: 0.5911 - val_loss: 0.9795 - val_acc: 0.5283\n",
            "Epoch 46/150 - 0.12s - loss: 0.8522 - acc: 0.6107 - val_loss: 0.9543 - val_acc: 0.5445\n",
            "Epoch 47/150 - 0.12s - loss: 0.8751 - acc: 0.5850 - val_loss: 0.9818 - val_acc: 0.5142\n",
            "Epoch 48/150 - 0.12s - loss: 0.8862 - acc: 0.5859 - val_loss: 1.0032 - val_acc: 0.4980\n",
            "Epoch 49/150 - 0.12s - loss: 0.8585 - acc: 0.6077 - val_loss: 0.9603 - val_acc: 0.5547\n",
            "Epoch 50/150 - 0.12s - loss: 0.8485 - acc: 0.6127 - val_loss: 0.9671 - val_acc: 0.5304\n",
            "Epoch 51/150 - 0.13s - loss: 0.8385 - acc: 0.6174 - val_loss: 0.9559 - val_acc: 0.5324\n",
            "Epoch 52/150 - 0.14s - loss: 0.8346 - acc: 0.6154 - val_loss: 0.9557 - val_acc: 0.5445\n",
            "Epoch 53/150 - 0.12s - loss: 0.8340 - acc: 0.6194 - val_loss: 0.9514 - val_acc: 0.5526\n",
            "Epoch 54/150 - 0.12s - loss: 0.8265 - acc: 0.6219 - val_loss: 0.9489 - val_acc: 0.5628\n",
            "Epoch 55/150 - 0.12s - loss: 0.8267 - acc: 0.6203 - val_loss: 0.9517 - val_acc: 0.5547\n",
            "Epoch 56/150 - 0.12s - loss: 0.8211 - acc: 0.6224 - val_loss: 0.9521 - val_acc: 0.5344\n",
            "Epoch 57/150 - 0.12s - loss: 0.8209 - acc: 0.6318 - val_loss: 0.9512 - val_acc: 0.5486\n",
            "Epoch 58/150 - 0.13s - loss: 0.8161 - acc: 0.6282 - val_loss: 0.9492 - val_acc: 0.5547\n",
            "Epoch 59/150 - 0.15s - loss: 0.8160 - acc: 0.6284 - val_loss: 0.9499 - val_acc: 0.5607\n",
            "Epoch 60/150 - 0.12s - loss: 0.8337 - acc: 0.6188 - val_loss: 0.9637 - val_acc: 0.5526\n",
            "Epoch 61/150 - 0.13s - loss: 0.8075 - acc: 0.6365 - val_loss: 0.9494 - val_acc: 0.5567\n",
            "Epoch 62/150 - 0.12s - loss: 0.8094 - acc: 0.6354 - val_loss: 0.9472 - val_acc: 0.5567\n",
            "Epoch 63/150 - 0.13s - loss: 0.8019 - acc: 0.6415 - val_loss: 0.9496 - val_acc: 0.5506\n",
            "Epoch 64/150 - 0.13s - loss: 0.8056 - acc: 0.6311 - val_loss: 0.9607 - val_acc: 0.5263\n",
            "Epoch 65/150 - 0.13s - loss: 0.8261 - acc: 0.6282 - val_loss: 0.9736 - val_acc: 0.5466\n",
            "Epoch 66/150 - 0.13s - loss: 0.8117 - acc: 0.6395 - val_loss: 0.9663 - val_acc: 0.5445\n",
            "Epoch 67/150 - 0.13s - loss: 0.7882 - acc: 0.6493 - val_loss: 0.9550 - val_acc: 0.5648\n",
            "Epoch 68/150 - 0.13s - loss: 0.7933 - acc: 0.6489 - val_loss: 0.9687 - val_acc: 0.5364\n",
            "Epoch 69/150 - 0.13s - loss: 0.7812 - acc: 0.6595 - val_loss: 0.9518 - val_acc: 0.5466\n",
            "Epoch 70/150 - 0.13s - loss: 0.8054 - acc: 0.6381 - val_loss: 0.9686 - val_acc: 0.5466\n",
            "Epoch 71/150 - 0.13s - loss: 0.7826 - acc: 0.6619 - val_loss: 0.9633 - val_acc: 0.5364\n",
            "Epoch 72/150 - 0.12s - loss: 0.8386 - acc: 0.6120 - val_loss: 1.0336 - val_acc: 0.4818\n",
            "Epoch 73/150 - 0.13s - loss: 0.7762 - acc: 0.6523 - val_loss: 0.9501 - val_acc: 0.5668\n",
            "Epoch 74/150 - 0.13s - loss: 0.7658 - acc: 0.6583 - val_loss: 0.9513 - val_acc: 0.5587\n",
            "Epoch 75/150 - 0.15s - loss: 0.7873 - acc: 0.6437 - val_loss: 0.9683 - val_acc: 0.5587\n",
            "Epoch 76/150 - 0.14s - loss: 0.7697 - acc: 0.6565 - val_loss: 0.9506 - val_acc: 0.5709\n",
            "Epoch 77/150 - 0.13s - loss: 0.7604 - acc: 0.6671 - val_loss: 0.9469 - val_acc: 0.5688\n",
            "Epoch 78/150 - 0.12s - loss: 0.7563 - acc: 0.6642 - val_loss: 0.9526 - val_acc: 0.5486\n",
            "Epoch 79/150 - 0.12s - loss: 0.7609 - acc: 0.6610 - val_loss: 0.9588 - val_acc: 0.5648\n",
            "Epoch 80/150 - 0.12s - loss: 0.7538 - acc: 0.6698 - val_loss: 0.9576 - val_acc: 0.5648\n",
            "Epoch 81/150 - 0.13s - loss: 0.7946 - acc: 0.6428 - val_loss: 1.0005 - val_acc: 0.5385\n",
            "Epoch 82/150 - 0.12s - loss: 0.7677 - acc: 0.6592 - val_loss: 0.9648 - val_acc: 0.5628\n",
            "Epoch 83/150 - 0.12s - loss: 0.7544 - acc: 0.6689 - val_loss: 0.9602 - val_acc: 0.5567\n",
            "Epoch 84/150 - 0.12s - loss: 0.7505 - acc: 0.6669 - val_loss: 0.9731 - val_acc: 0.5526\n",
            "Epoch 85/150 - 0.14s - loss: 0.7422 - acc: 0.6817 - val_loss: 0.9711 - val_acc: 0.5587\n",
            "Epoch 86/150 - 0.15s - loss: 0.7317 - acc: 0.6883 - val_loss: 0.9478 - val_acc: 0.5810\n",
            "Epoch 87/150 - 0.15s - loss: 0.7441 - acc: 0.6707 - val_loss: 0.9590 - val_acc: 0.5628\n",
            "Epoch 88/150 - 0.14s - loss: 0.7311 - acc: 0.6817 - val_loss: 0.9714 - val_acc: 0.5486\n",
            "Epoch 89/150 - 0.13s - loss: 0.7526 - acc: 0.6736 - val_loss: 0.9876 - val_acc: 0.5486\n",
            "Epoch 90/150 - 0.14s - loss: 0.7271 - acc: 0.6831 - val_loss: 0.9629 - val_acc: 0.5709\n",
            "Epoch 91/150 - 0.13s - loss: 0.7111 - acc: 0.7072 - val_loss: 0.9606 - val_acc: 0.5405\n",
            "Epoch 92/150 - 0.13s - loss: 0.7291 - acc: 0.6892 - val_loss: 0.9748 - val_acc: 0.5526\n",
            "Epoch 93/150 - 0.13s - loss: 0.7136 - acc: 0.7024 - val_loss: 0.9655 - val_acc: 0.5405\n",
            "Epoch 94/150 - 0.12s - loss: 0.7094 - acc: 0.6966 - val_loss: 0.9572 - val_acc: 0.5688\n",
            "Epoch 95/150 - 0.12s - loss: 0.7117 - acc: 0.6966 - val_loss: 0.9632 - val_acc: 0.5810\n",
            "Epoch 96/150 - 0.12s - loss: 0.6958 - acc: 0.7119 - val_loss: 0.9644 - val_acc: 0.5506\n",
            "Epoch 97/150 - 0.12s - loss: 0.6917 - acc: 0.7112 - val_loss: 0.9625 - val_acc: 0.5607\n",
            "Epoch 98/150 - 0.12s - loss: 0.7340 - acc: 0.6853 - val_loss: 0.9879 - val_acc: 0.5587\n",
            "Epoch 99/150 - 0.12s - loss: 0.7121 - acc: 0.6930 - val_loss: 0.9966 - val_acc: 0.5364\n",
            "Epoch 100/150 - 0.14s - loss: 0.6822 - acc: 0.7186 - val_loss: 0.9737 - val_acc: 0.5506\n",
            "Epoch 101/150 - 0.13s - loss: 0.6959 - acc: 0.7029 - val_loss: 0.9669 - val_acc: 0.5729\n",
            "Epoch 102/150 - 0.13s - loss: 0.6694 - acc: 0.7251 - val_loss: 0.9533 - val_acc: 0.5648\n",
            "Epoch 103/150 - 0.13s - loss: 0.6917 - acc: 0.7002 - val_loss: 0.9620 - val_acc: 0.5810\n",
            "Epoch 104/150 - 0.13s - loss: 0.6653 - acc: 0.7227 - val_loss: 0.9518 - val_acc: 0.5769\n",
            "Epoch 105/150 - 0.13s - loss: 0.6693 - acc: 0.7218 - val_loss: 0.9760 - val_acc: 0.5486\n",
            "Epoch 106/150 - 0.12s - loss: 0.6656 - acc: 0.7346 - val_loss: 0.9786 - val_acc: 0.5587\n",
            "Epoch 107/150 - 0.12s - loss: 0.6776 - acc: 0.7143 - val_loss: 0.9733 - val_acc: 0.5709\n",
            "Epoch 108/150 - 0.12s - loss: 0.7568 - acc: 0.6676 - val_loss: 1.0516 - val_acc: 0.5486\n",
            "Epoch 109/150 - 0.12s - loss: 0.6566 - acc: 0.7328 - val_loss: 0.9661 - val_acc: 0.5587\n",
            "Epoch 110/150 - 0.12s - loss: 0.8435 - acc: 0.6012 - val_loss: 1.1860 - val_acc: 0.4717\n",
            "Epoch 111/150 - 0.13s - loss: 0.6514 - acc: 0.7287 - val_loss: 0.9726 - val_acc: 0.5688\n",
            "Epoch 112/150 - 0.13s - loss: 0.6923 - acc: 0.6988 - val_loss: 1.0354 - val_acc: 0.5182\n",
            "Epoch 113/150 - 0.13s - loss: 0.6808 - acc: 0.7072 - val_loss: 1.0130 - val_acc: 0.5405\n",
            "Epoch 114/150 - 0.12s - loss: 0.6577 - acc: 0.7195 - val_loss: 0.9934 - val_acc: 0.5688\n",
            "Epoch 115/150 - 0.12s - loss: 0.6234 - acc: 0.7521 - val_loss: 0.9612 - val_acc: 0.5789\n",
            "Epoch 116/150 - 0.12s - loss: 0.6307 - acc: 0.7391 - val_loss: 0.9741 - val_acc: 0.5709\n",
            "Epoch 117/150 - 0.13s - loss: 0.6407 - acc: 0.7312 - val_loss: 0.9809 - val_acc: 0.5648\n",
            "Epoch 118/150 - 0.13s - loss: 0.6515 - acc: 0.7186 - val_loss: 0.9842 - val_acc: 0.5587\n",
            "Epoch 119/150 - 0.12s - loss: 0.6823 - acc: 0.7054 - val_loss: 1.0341 - val_acc: 0.5385\n",
            "Epoch 120/150 - 0.12s - loss: 0.6075 - acc: 0.7656 - val_loss: 0.9725 - val_acc: 0.5587\n",
            "Epoch 121/150 - 0.12s - loss: 0.5993 - acc: 0.7686 - val_loss: 0.9646 - val_acc: 0.5709\n",
            "Epoch 122/150 - 0.12s - loss: 0.6219 - acc: 0.7506 - val_loss: 1.0013 - val_acc: 0.5364\n",
            "Epoch 123/150 - 0.13s - loss: 0.6346 - acc: 0.7434 - val_loss: 1.0271 - val_acc: 0.5405\n",
            "Epoch 124/150 - 0.12s - loss: 0.5887 - acc: 0.7800 - val_loss: 0.9678 - val_acc: 0.5709\n",
            "Epoch 125/150 - 0.14s - loss: 0.6002 - acc: 0.7652 - val_loss: 0.9953 - val_acc: 0.5466\n",
            "Epoch 126/150 - 0.12s - loss: 0.6499 - acc: 0.7224 - val_loss: 1.0569 - val_acc: 0.5243\n",
            "Epoch 127/150 - 0.12s - loss: 0.5910 - acc: 0.7587 - val_loss: 0.9763 - val_acc: 0.5709\n",
            "Epoch 128/150 - 0.12s - loss: 0.5738 - acc: 0.7780 - val_loss: 0.9787 - val_acc: 0.5688\n",
            "Epoch 129/150 - 0.13s - loss: 0.6539 - acc: 0.7099 - val_loss: 1.0515 - val_acc: 0.5364\n",
            "Epoch 130/150 - 0.12s - loss: 0.5848 - acc: 0.7733 - val_loss: 1.0021 - val_acc: 0.5607\n",
            "Epoch 131/150 - 0.12s - loss: 0.5741 - acc: 0.7735 - val_loss: 0.9803 - val_acc: 0.5870\n",
            "Epoch 132/150 - 0.12s - loss: 0.6401 - acc: 0.7164 - val_loss: 1.0833 - val_acc: 0.5081\n",
            "Epoch 133/150 - 0.12s - loss: 0.5696 - acc: 0.7787 - val_loss: 0.9933 - val_acc: 0.5830\n",
            "Epoch 134/150 - 0.12s - loss: 0.5776 - acc: 0.7578 - val_loss: 0.9854 - val_acc: 0.5911\n",
            "Epoch 135/150 - 0.12s - loss: 0.5574 - acc: 0.7865 - val_loss: 0.9894 - val_acc: 0.5729\n",
            "Epoch 136/150 - 0.13s - loss: 0.5665 - acc: 0.7726 - val_loss: 0.9939 - val_acc: 0.5789\n",
            "Epoch 137/150 - 0.12s - loss: 0.5501 - acc: 0.7883 - val_loss: 0.9914 - val_acc: 0.5810\n",
            "Epoch 138/150 - 0.12s - loss: 0.7499 - acc: 0.6230 - val_loss: 1.2073 - val_acc: 0.4838\n",
            "Epoch 139/150 - 0.13s - loss: 0.5421 - acc: 0.7915 - val_loss: 1.0095 - val_acc: 0.5688\n",
            "Epoch 140/150 - 0.13s - loss: 0.5333 - acc: 0.7998 - val_loss: 0.9929 - val_acc: 0.5891\n",
            "Epoch 141/150 - 0.13s - loss: 0.5999 - acc: 0.7443 - val_loss: 1.0443 - val_acc: 0.5810\n",
            "Epoch 142/150 - 0.12s - loss: 0.5342 - acc: 0.7908 - val_loss: 0.9982 - val_acc: 0.5648\n",
            "Epoch 143/150 - 0.12s - loss: 0.5038 - acc: 0.8162 - val_loss: 0.9882 - val_acc: 0.5749\n",
            "Epoch 144/150 - 0.12s - loss: 0.5014 - acc: 0.8288 - val_loss: 0.9885 - val_acc: 0.5769\n",
            "Epoch 145/150 - 0.12s - loss: 0.5529 - acc: 0.7778 - val_loss: 1.0398 - val_acc: 0.5709\n",
            "Epoch 146/150 - 0.12s - loss: 0.4907 - acc: 0.8237 - val_loss: 0.9905 - val_acc: 0.5830\n",
            "Epoch 147/150 - 0.12s - loss: 0.6870 - acc: 0.6685 - val_loss: 1.1403 - val_acc: 0.5344\n",
            "Epoch 148/150 - 0.12s - loss: 0.5401 - acc: 0.7854 - val_loss: 1.0720 - val_acc: 0.5324\n",
            "Epoch 149/150 - 0.14s - loss: 0.4977 - acc: 0.8189 - val_loss: 1.0047 - val_acc: 0.5830\n",
            "Epoch 150/150 - 0.12s - loss: 0.5155 - acc: 0.8072 - val_loss: 1.0369 - val_acc: 0.5547\n",
            "\n",
            "Combination 112/252:\n",
            "Hidden Layers: [256, 128], Activation: relu, Learning Rate: 0.01, Batch Size: 64, Epochs: 50\n",
            "Epoch 1/50 - 0.09s - loss: 1.0929 - acc: 0.3702 - val_loss: 1.0959 - val_acc: 0.3381\n",
            "Epoch 2/50 - 0.09s - loss: 1.0842 - acc: 0.4199 - val_loss: 1.0894 - val_acc: 0.3704\n",
            "Epoch 3/50 - 0.10s - loss: 1.0773 - acc: 0.4424 - val_loss: 1.0848 - val_acc: 0.3846\n",
            "Epoch 4/50 - 0.10s - loss: 1.0713 - acc: 0.4492 - val_loss: 1.0805 - val_acc: 0.4190\n",
            "Epoch 5/50 - 0.08s - loss: 1.0661 - acc: 0.4496 - val_loss: 1.0769 - val_acc: 0.4251\n",
            "Epoch 6/50 - 0.08s - loss: 1.0612 - acc: 0.4636 - val_loss: 1.0740 - val_acc: 0.4170\n",
            "Epoch 7/50 - 0.08s - loss: 1.0578 - acc: 0.4586 - val_loss: 1.0731 - val_acc: 0.4130\n",
            "Epoch 8/50 - 0.08s - loss: 1.0541 - acc: 0.4618 - val_loss: 1.0708 - val_acc: 0.4312\n",
            "Epoch 9/50 - 0.08s - loss: 1.0489 - acc: 0.4786 - val_loss: 1.0655 - val_acc: 0.4474\n",
            "Epoch 10/50 - 0.08s - loss: 1.0444 - acc: 0.4782 - val_loss: 1.0622 - val_acc: 0.4332\n",
            "Epoch 11/50 - 0.08s - loss: 1.0407 - acc: 0.4816 - val_loss: 1.0599 - val_acc: 0.4534\n",
            "Epoch 12/50 - 0.08s - loss: 1.0367 - acc: 0.4847 - val_loss: 1.0567 - val_acc: 0.4494\n",
            "Epoch 13/50 - 0.10s - loss: 1.0330 - acc: 0.4910 - val_loss: 1.0540 - val_acc: 0.4676\n",
            "Epoch 14/50 - 0.08s - loss: 1.0317 - acc: 0.4858 - val_loss: 1.0556 - val_acc: 0.4656\n",
            "Epoch 15/50 - 0.08s - loss: 1.0261 - acc: 0.4906 - val_loss: 1.0487 - val_acc: 0.4777\n",
            "Epoch 16/50 - 0.09s - loss: 1.0231 - acc: 0.4897 - val_loss: 1.0463 - val_acc: 0.4838\n",
            "Epoch 17/50 - 0.08s - loss: 1.0191 - acc: 0.4991 - val_loss: 1.0435 - val_acc: 0.4858\n",
            "Epoch 18/50 - 0.08s - loss: 1.0161 - acc: 0.5004 - val_loss: 1.0409 - val_acc: 0.4960\n",
            "Epoch 19/50 - 0.10s - loss: 1.0134 - acc: 0.4975 - val_loss: 1.0390 - val_acc: 0.4980\n",
            "Epoch 20/50 - 0.08s - loss: 1.0088 - acc: 0.5090 - val_loss: 1.0368 - val_acc: 0.4919\n",
            "Epoch 21/50 - 0.09s - loss: 1.0050 - acc: 0.5124 - val_loss: 1.0334 - val_acc: 0.4939\n",
            "Epoch 22/50 - 0.10s - loss: 1.0023 - acc: 0.5135 - val_loss: 1.0305 - val_acc: 0.4980\n",
            "Epoch 23/50 - 0.08s - loss: 0.9985 - acc: 0.5169 - val_loss: 1.0288 - val_acc: 0.5101\n",
            "Epoch 24/50 - 0.08s - loss: 0.9955 - acc: 0.5157 - val_loss: 1.0259 - val_acc: 0.5101\n",
            "Epoch 25/50 - 0.09s - loss: 0.9923 - acc: 0.5238 - val_loss: 1.0238 - val_acc: 0.5101\n",
            "Epoch 26/50 - 0.08s - loss: 0.9887 - acc: 0.5252 - val_loss: 1.0216 - val_acc: 0.5121\n",
            "Epoch 27/50 - 0.08s - loss: 0.9852 - acc: 0.5297 - val_loss: 1.0181 - val_acc: 0.5263\n",
            "Epoch 28/50 - 0.09s - loss: 0.9826 - acc: 0.5322 - val_loss: 1.0151 - val_acc: 0.5223\n",
            "Epoch 29/50 - 0.08s - loss: 0.9798 - acc: 0.5328 - val_loss: 1.0144 - val_acc: 0.5344\n",
            "Epoch 30/50 - 0.08s - loss: 0.9814 - acc: 0.5286 - val_loss: 1.0123 - val_acc: 0.5121\n",
            "Epoch 31/50 - 0.10s - loss: 0.9742 - acc: 0.5360 - val_loss: 1.0094 - val_acc: 0.5304\n",
            "Epoch 32/50 - 0.08s - loss: 0.9749 - acc: 0.5295 - val_loss: 1.0112 - val_acc: 0.5142\n",
            "Epoch 33/50 - 0.12s - loss: 0.9674 - acc: 0.5418 - val_loss: 1.0035 - val_acc: 0.5364\n",
            "Epoch 34/50 - 0.09s - loss: 0.9642 - acc: 0.5414 - val_loss: 1.0013 - val_acc: 0.5364\n",
            "Epoch 35/50 - 0.09s - loss: 0.9634 - acc: 0.5358 - val_loss: 1.0028 - val_acc: 0.5142\n",
            "Epoch 36/50 - 0.09s - loss: 0.9596 - acc: 0.5452 - val_loss: 0.9982 - val_acc: 0.5283\n",
            "Epoch 37/50 - 0.11s - loss: 0.9567 - acc: 0.5421 - val_loss: 0.9967 - val_acc: 0.5364\n",
            "Epoch 38/50 - 0.09s - loss: 0.9672 - acc: 0.5414 - val_loss: 1.0051 - val_acc: 0.5405\n",
            "Epoch 39/50 - 0.09s - loss: 0.9512 - acc: 0.5504 - val_loss: 0.9921 - val_acc: 0.5385\n",
            "Epoch 40/50 - 0.10s - loss: 0.9515 - acc: 0.5529 - val_loss: 0.9924 - val_acc: 0.5547\n",
            "Epoch 41/50 - 0.08s - loss: 0.9464 - acc: 0.5578 - val_loss: 0.9882 - val_acc: 0.5547\n",
            "Epoch 42/50 - 0.08s - loss: 0.9457 - acc: 0.5533 - val_loss: 0.9865 - val_acc: 0.5506\n",
            "Epoch 43/50 - 0.09s - loss: 0.9426 - acc: 0.5513 - val_loss: 0.9867 - val_acc: 0.5283\n",
            "Epoch 44/50 - 0.09s - loss: 0.9388 - acc: 0.5580 - val_loss: 0.9832 - val_acc: 0.5567\n",
            "Epoch 45/50 - 0.09s - loss: 0.9373 - acc: 0.5569 - val_loss: 0.9843 - val_acc: 0.5405\n",
            "Epoch 46/50 - 0.09s - loss: 0.9408 - acc: 0.5481 - val_loss: 0.9890 - val_acc: 0.5162\n",
            "Epoch 47/50 - 0.09s - loss: 0.9320 - acc: 0.5619 - val_loss: 0.9796 - val_acc: 0.5567\n",
            "Epoch 48/50 - 0.09s - loss: 0.9338 - acc: 0.5630 - val_loss: 0.9821 - val_acc: 0.5486\n",
            "Epoch 49/50 - 0.10s - loss: 0.9338 - acc: 0.5560 - val_loss: 0.9834 - val_acc: 0.5223\n",
            "Epoch 50/50 - 0.09s - loss: 0.9345 - acc: 0.5560 - val_loss: 0.9818 - val_acc: 0.5547\n",
            "\n",
            "Combination 113/252:\n",
            "Hidden Layers: [256, 128], Activation: relu, Learning Rate: 0.01, Batch Size: 64, Epochs: 100\n",
            "Epoch 1/100 - 0.09s - loss: 1.0897 - acc: 0.3765 - val_loss: 1.0905 - val_acc: 0.3887\n",
            "Epoch 2/100 - 0.09s - loss: 1.0801 - acc: 0.4121 - val_loss: 1.0818 - val_acc: 0.4190\n",
            "Epoch 3/100 - 0.09s - loss: 1.0727 - acc: 0.4370 - val_loss: 1.0758 - val_acc: 0.4474\n",
            "Epoch 4/100 - 0.09s - loss: 1.0672 - acc: 0.4420 - val_loss: 1.0711 - val_acc: 0.4372\n",
            "Epoch 5/100 - 0.09s - loss: 1.0617 - acc: 0.4469 - val_loss: 1.0680 - val_acc: 0.4514\n",
            "Epoch 6/100 - 0.09s - loss: 1.0574 - acc: 0.4528 - val_loss: 1.0648 - val_acc: 0.4595\n",
            "Epoch 7/100 - 0.09s - loss: 1.0536 - acc: 0.4566 - val_loss: 1.0631 - val_acc: 0.4636\n",
            "Epoch 8/100 - 0.10s - loss: 1.0513 - acc: 0.4539 - val_loss: 1.0607 - val_acc: 0.4453\n",
            "Epoch 9/100 - 0.09s - loss: 1.0469 - acc: 0.4649 - val_loss: 1.0581 - val_acc: 0.4696\n",
            "Epoch 10/100 - 0.09s - loss: 1.0437 - acc: 0.4674 - val_loss: 1.0558 - val_acc: 0.4696\n",
            "Epoch 11/100 - 0.10s - loss: 1.0427 - acc: 0.4582 - val_loss: 1.0545 - val_acc: 0.4555\n",
            "Epoch 12/100 - 0.09s - loss: 1.0383 - acc: 0.4762 - val_loss: 1.0536 - val_acc: 0.4858\n",
            "Epoch 13/100 - 0.09s - loss: 1.0351 - acc: 0.4748 - val_loss: 1.0500 - val_acc: 0.4737\n",
            "Epoch 14/100 - 0.09s - loss: 1.0321 - acc: 0.4836 - val_loss: 1.0496 - val_acc: 0.4777\n",
            "Epoch 15/100 - 0.11s - loss: 1.0311 - acc: 0.4735 - val_loss: 1.0473 - val_acc: 0.4676\n",
            "Epoch 16/100 - 0.09s - loss: 1.0263 - acc: 0.4921 - val_loss: 1.0457 - val_acc: 0.5000\n",
            "Epoch 17/100 - 0.10s - loss: 1.0242 - acc: 0.4960 - val_loss: 1.0438 - val_acc: 0.5020\n",
            "Epoch 18/100 - 0.09s - loss: 1.0201 - acc: 0.4987 - val_loss: 1.0411 - val_acc: 0.5061\n",
            "Epoch 19/100 - 0.09s - loss: 1.0180 - acc: 0.4982 - val_loss: 1.0414 - val_acc: 0.4919\n",
            "Epoch 20/100 - 0.09s - loss: 1.0148 - acc: 0.5000 - val_loss: 1.0374 - val_acc: 0.5040\n",
            "Epoch 21/100 - 0.09s - loss: 1.0114 - acc: 0.5065 - val_loss: 1.0366 - val_acc: 0.5040\n",
            "Epoch 22/100 - 0.09s - loss: 1.0086 - acc: 0.5036 - val_loss: 1.0335 - val_acc: 0.5162\n",
            "Epoch 23/100 - 0.09s - loss: 1.0054 - acc: 0.5121 - val_loss: 1.0327 - val_acc: 0.5020\n",
            "Epoch 24/100 - 0.09s - loss: 1.0018 - acc: 0.5144 - val_loss: 1.0293 - val_acc: 0.5263\n",
            "Epoch 25/100 - 0.09s - loss: 0.9989 - acc: 0.5130 - val_loss: 1.0272 - val_acc: 0.5223\n",
            "Epoch 26/100 - 0.10s - loss: 0.9959 - acc: 0.5232 - val_loss: 1.0259 - val_acc: 0.5081\n",
            "Epoch 27/100 - 0.09s - loss: 0.9926 - acc: 0.5196 - val_loss: 1.0226 - val_acc: 0.5283\n",
            "Epoch 28/100 - 0.09s - loss: 0.9957 - acc: 0.5175 - val_loss: 1.0298 - val_acc: 0.5020\n",
            "Epoch 29/100 - 0.09s - loss: 0.9871 - acc: 0.5241 - val_loss: 1.0186 - val_acc: 0.5283\n",
            "Epoch 30/100 - 0.09s - loss: 0.9842 - acc: 0.5324 - val_loss: 1.0187 - val_acc: 0.5142\n",
            "Epoch 31/100 - 0.09s - loss: 0.9813 - acc: 0.5349 - val_loss: 1.0166 - val_acc: 0.5202\n",
            "Epoch 32/100 - 0.09s - loss: 0.9784 - acc: 0.5317 - val_loss: 1.0129 - val_acc: 0.5121\n",
            "Epoch 33/100 - 0.09s - loss: 0.9751 - acc: 0.5333 - val_loss: 1.0097 - val_acc: 0.5263\n",
            "Epoch 34/100 - 0.09s - loss: 0.9730 - acc: 0.5398 - val_loss: 1.0110 - val_acc: 0.5243\n",
            "Epoch 35/100 - 0.10s - loss: 0.9764 - acc: 0.5250 - val_loss: 1.0161 - val_acc: 0.5000\n",
            "Epoch 36/100 - 0.09s - loss: 0.9655 - acc: 0.5421 - val_loss: 1.0034 - val_acc: 0.5283\n",
            "Epoch 37/100 - 0.09s - loss: 0.9631 - acc: 0.5430 - val_loss: 1.0022 - val_acc: 0.5243\n",
            "Epoch 38/100 - 0.09s - loss: 0.9702 - acc: 0.5299 - val_loss: 1.0123 - val_acc: 0.4858\n",
            "Epoch 39/100 - 0.09s - loss: 0.9604 - acc: 0.5403 - val_loss: 1.0021 - val_acc: 0.5283\n",
            "Epoch 40/100 - 0.09s - loss: 0.9550 - acc: 0.5416 - val_loss: 0.9945 - val_acc: 0.5223\n",
            "Epoch 41/100 - 0.10s - loss: 0.9528 - acc: 0.5486 - val_loss: 0.9935 - val_acc: 0.5405\n",
            "Epoch 42/100 - 0.09s - loss: 0.9502 - acc: 0.5495 - val_loss: 0.9914 - val_acc: 0.5385\n",
            "Epoch 43/100 - 0.09s - loss: 0.9514 - acc: 0.5499 - val_loss: 0.9929 - val_acc: 0.5445\n",
            "Epoch 44/100 - 0.10s - loss: 0.9451 - acc: 0.5529 - val_loss: 0.9876 - val_acc: 0.5405\n",
            "Epoch 45/100 - 0.09s - loss: 0.9413 - acc: 0.5571 - val_loss: 0.9854 - val_acc: 0.5445\n",
            "Epoch 46/100 - 0.09s - loss: 0.9438 - acc: 0.5502 - val_loss: 0.9859 - val_acc: 0.5506\n",
            "Epoch 47/100 - 0.10s - loss: 0.9396 - acc: 0.5529 - val_loss: 0.9871 - val_acc: 0.5385\n",
            "Epoch 48/100 - 0.10s - loss: 0.9359 - acc: 0.5607 - val_loss: 0.9819 - val_acc: 0.5506\n",
            "Epoch 49/100 - 0.08s - loss: 0.9349 - acc: 0.5544 - val_loss: 0.9801 - val_acc: 0.5668\n",
            "Epoch 50/100 - 0.09s - loss: 0.9313 - acc: 0.5598 - val_loss: 0.9811 - val_acc: 0.5526\n",
            "Epoch 51/100 - 0.10s - loss: 0.9310 - acc: 0.5603 - val_loss: 0.9777 - val_acc: 0.5749\n",
            "Epoch 52/100 - 0.10s - loss: 0.9306 - acc: 0.5587 - val_loss: 0.9825 - val_acc: 0.5344\n",
            "Epoch 53/100 - 0.10s - loss: 0.9292 - acc: 0.5513 - val_loss: 0.9759 - val_acc: 0.5547\n",
            "Epoch 54/100 - 0.09s - loss: 0.9245 - acc: 0.5646 - val_loss: 0.9787 - val_acc: 0.5587\n",
            "Epoch 55/100 - 0.09s - loss: 0.9198 - acc: 0.5682 - val_loss: 0.9729 - val_acc: 0.5709\n",
            "Epoch 56/100 - 0.10s - loss: 0.9178 - acc: 0.5641 - val_loss: 0.9699 - val_acc: 0.5486\n",
            "Epoch 57/100 - 0.09s - loss: 0.9325 - acc: 0.5664 - val_loss: 0.9822 - val_acc: 0.5587\n",
            "Epoch 58/100 - 0.10s - loss: 0.9146 - acc: 0.5664 - val_loss: 0.9708 - val_acc: 0.5547\n",
            "Epoch 59/100 - 0.10s - loss: 0.9095 - acc: 0.5709 - val_loss: 0.9654 - val_acc: 0.5628\n",
            "Epoch 60/100 - 0.10s - loss: 0.9093 - acc: 0.5664 - val_loss: 0.9636 - val_acc: 0.5567\n",
            "Epoch 61/100 - 0.09s - loss: 0.9060 - acc: 0.5677 - val_loss: 0.9624 - val_acc: 0.5607\n",
            "Epoch 62/100 - 0.11s - loss: 0.9044 - acc: 0.5729 - val_loss: 0.9641 - val_acc: 0.5688\n",
            "Epoch 63/100 - 0.10s - loss: 0.9238 - acc: 0.5668 - val_loss: 0.9766 - val_acc: 0.5547\n",
            "Epoch 64/100 - 0.09s - loss: 0.9027 - acc: 0.5738 - val_loss: 0.9601 - val_acc: 0.5648\n",
            "Epoch 65/100 - 0.09s - loss: 0.9027 - acc: 0.5785 - val_loss: 0.9633 - val_acc: 0.5810\n",
            "Epoch 66/100 - 0.09s - loss: 0.9005 - acc: 0.5753 - val_loss: 0.9645 - val_acc: 0.5547\n",
            "Epoch 67/100 - 0.09s - loss: 0.9039 - acc: 0.5722 - val_loss: 0.9709 - val_acc: 0.5344\n",
            "Epoch 68/100 - 0.10s - loss: 0.8943 - acc: 0.5760 - val_loss: 0.9585 - val_acc: 0.5607\n",
            "Epoch 69/100 - 0.09s - loss: 0.8906 - acc: 0.5846 - val_loss: 0.9559 - val_acc: 0.5709\n",
            "Epoch 70/100 - 0.09s - loss: 0.9015 - acc: 0.5753 - val_loss: 0.9738 - val_acc: 0.5263\n",
            "Epoch 71/100 - 0.10s - loss: 0.8868 - acc: 0.5857 - val_loss: 0.9547 - val_acc: 0.5789\n",
            "Epoch 72/100 - 0.09s - loss: 0.8868 - acc: 0.5857 - val_loss: 0.9566 - val_acc: 0.5607\n",
            "Epoch 73/100 - 0.09s - loss: 0.8999 - acc: 0.5688 - val_loss: 0.9714 - val_acc: 0.5223\n",
            "Epoch 74/100 - 0.09s - loss: 0.8837 - acc: 0.5877 - val_loss: 0.9560 - val_acc: 0.5587\n",
            "Epoch 75/100 - 0.09s - loss: 0.8865 - acc: 0.5864 - val_loss: 0.9619 - val_acc: 0.5526\n",
            "Epoch 76/100 - 0.09s - loss: 0.8839 - acc: 0.5873 - val_loss: 0.9605 - val_acc: 0.5506\n",
            "Epoch 77/100 - 0.10s - loss: 0.8870 - acc: 0.5807 - val_loss: 0.9561 - val_acc: 0.5567\n",
            "Epoch 78/100 - 0.09s - loss: 0.8726 - acc: 0.5945 - val_loss: 0.9475 - val_acc: 0.5587\n",
            "Epoch 79/100 - 0.09s - loss: 0.8771 - acc: 0.5875 - val_loss: 0.9490 - val_acc: 0.5607\n",
            "Epoch 80/100 - 0.11s - loss: 0.8797 - acc: 0.5918 - val_loss: 0.9573 - val_acc: 0.5587\n",
            "Epoch 81/100 - 0.10s - loss: 0.8698 - acc: 0.6001 - val_loss: 0.9507 - val_acc: 0.5567\n",
            "Epoch 82/100 - 0.09s - loss: 0.8746 - acc: 0.5803 - val_loss: 0.9531 - val_acc: 0.5648\n",
            "Epoch 83/100 - 0.09s - loss: 0.8644 - acc: 0.6017 - val_loss: 0.9435 - val_acc: 0.5628\n",
            "Epoch 84/100 - 0.09s - loss: 0.8717 - acc: 0.5967 - val_loss: 0.9481 - val_acc: 0.5729\n",
            "Epoch 85/100 - 0.09s - loss: 0.8668 - acc: 0.6005 - val_loss: 0.9462 - val_acc: 0.5789\n",
            "Epoch 86/100 - 0.10s - loss: 0.8755 - acc: 0.5974 - val_loss: 0.9537 - val_acc: 0.5769\n",
            "Epoch 87/100 - 0.10s - loss: 0.8653 - acc: 0.5947 - val_loss: 0.9475 - val_acc: 0.5688\n",
            "Epoch 88/100 - 0.10s - loss: 0.8617 - acc: 0.6028 - val_loss: 0.9522 - val_acc: 0.5506\n",
            "Epoch 89/100 - 0.10s - loss: 0.8536 - acc: 0.6098 - val_loss: 0.9416 - val_acc: 0.5628\n",
            "Epoch 90/100 - 0.09s - loss: 0.8515 - acc: 0.6098 - val_loss: 0.9407 - val_acc: 0.5709\n",
            "Epoch 91/100 - 0.09s - loss: 0.8779 - acc: 0.5904 - val_loss: 0.9775 - val_acc: 0.5121\n",
            "Epoch 92/100 - 0.11s - loss: 0.8649 - acc: 0.5938 - val_loss: 0.9488 - val_acc: 0.5891\n",
            "Epoch 93/100 - 0.09s - loss: 0.8475 - acc: 0.6154 - val_loss: 0.9413 - val_acc: 0.5648\n",
            "Epoch 94/100 - 0.09s - loss: 0.8470 - acc: 0.6120 - val_loss: 0.9434 - val_acc: 0.5587\n",
            "Epoch 95/100 - 0.09s - loss: 0.8492 - acc: 0.6095 - val_loss: 0.9502 - val_acc: 0.5506\n",
            "Epoch 96/100 - 0.09s - loss: 0.8636 - acc: 0.5981 - val_loss: 0.9683 - val_acc: 0.5405\n",
            "Epoch 97/100 - 0.09s - loss: 0.8447 - acc: 0.6026 - val_loss: 0.9414 - val_acc: 0.5709\n",
            "Epoch 98/100 - 0.10s - loss: 0.8452 - acc: 0.6131 - val_loss: 0.9452 - val_acc: 0.5547\n",
            "Epoch 99/100 - 0.09s - loss: 0.8368 - acc: 0.6188 - val_loss: 0.9395 - val_acc: 0.5688\n",
            "Epoch 100/100 - 0.10s - loss: 0.8350 - acc: 0.6224 - val_loss: 0.9378 - val_acc: 0.5709\n",
            "\n",
            "Combination 114/252:\n",
            "Hidden Layers: [256, 128], Activation: relu, Learning Rate: 0.01, Batch Size: 64, Epochs: 150\n",
            "Epoch 1/150 - 0.10s - loss: 1.0938 - acc: 0.3543 - val_loss: 1.0956 - val_acc: 0.3704\n",
            "Epoch 2/150 - 0.10s - loss: 1.0849 - acc: 0.3896 - val_loss: 1.0881 - val_acc: 0.3907\n",
            "Epoch 3/150 - 0.11s - loss: 1.0778 - acc: 0.4184 - val_loss: 1.0834 - val_acc: 0.4352\n",
            "Epoch 4/150 - 0.09s - loss: 1.0715 - acc: 0.4460 - val_loss: 1.0787 - val_acc: 0.4352\n",
            "Epoch 5/150 - 0.09s - loss: 1.0658 - acc: 0.4501 - val_loss: 1.0756 - val_acc: 0.4474\n",
            "Epoch 6/150 - 0.08s - loss: 1.0601 - acc: 0.4649 - val_loss: 1.0713 - val_acc: 0.4231\n",
            "Epoch 7/150 - 0.09s - loss: 1.0548 - acc: 0.4728 - val_loss: 1.0679 - val_acc: 0.4291\n",
            "Epoch 8/150 - 0.09s - loss: 1.0499 - acc: 0.4667 - val_loss: 1.0660 - val_acc: 0.4312\n",
            "Epoch 9/150 - 0.08s - loss: 1.0461 - acc: 0.4694 - val_loss: 1.0624 - val_acc: 0.4372\n",
            "Epoch 10/150 - 0.08s - loss: 1.0405 - acc: 0.4820 - val_loss: 1.0599 - val_acc: 0.4474\n",
            "Epoch 11/150 - 0.09s - loss: 1.0367 - acc: 0.4793 - val_loss: 1.0588 - val_acc: 0.4453\n",
            "Epoch 12/150 - 0.10s - loss: 1.0327 - acc: 0.4816 - val_loss: 1.0546 - val_acc: 0.4575\n",
            "Epoch 13/150 - 0.11s - loss: 1.0302 - acc: 0.4899 - val_loss: 1.0558 - val_acc: 0.4433\n",
            "Epoch 14/150 - 0.10s - loss: 1.0255 - acc: 0.4856 - val_loss: 1.0502 - val_acc: 0.4575\n",
            "Epoch 15/150 - 0.09s - loss: 1.0215 - acc: 0.5000 - val_loss: 1.0482 - val_acc: 0.4433\n",
            "Epoch 16/150 - 0.09s - loss: 1.0185 - acc: 0.4935 - val_loss: 1.0458 - val_acc: 0.4636\n",
            "Epoch 17/150 - 0.09s - loss: 1.0154 - acc: 0.4996 - val_loss: 1.0438 - val_acc: 0.4757\n",
            "Epoch 18/150 - 0.09s - loss: 1.0110 - acc: 0.5085 - val_loss: 1.0421 - val_acc: 0.4555\n",
            "Epoch 19/150 - 0.09s - loss: 1.0079 - acc: 0.5072 - val_loss: 1.0407 - val_acc: 0.4737\n",
            "Epoch 20/150 - 0.08s - loss: 1.0048 - acc: 0.5097 - val_loss: 1.0386 - val_acc: 0.4737\n",
            "Epoch 21/150 - 0.08s - loss: 1.0037 - acc: 0.5175 - val_loss: 1.0391 - val_acc: 0.4696\n",
            "Epoch 22/150 - 0.10s - loss: 0.9989 - acc: 0.5184 - val_loss: 1.0347 - val_acc: 0.4777\n",
            "Epoch 23/150 - 0.08s - loss: 0.9953 - acc: 0.5223 - val_loss: 1.0308 - val_acc: 0.4676\n",
            "Epoch 24/150 - 0.08s - loss: 0.9943 - acc: 0.5162 - val_loss: 1.0330 - val_acc: 0.4838\n",
            "Epoch 25/150 - 0.09s - loss: 0.9897 - acc: 0.5218 - val_loss: 1.0266 - val_acc: 0.4737\n",
            "Epoch 26/150 - 0.08s - loss: 0.9856 - acc: 0.5272 - val_loss: 1.0237 - val_acc: 0.4939\n",
            "Epoch 27/150 - 0.08s - loss: 0.9844 - acc: 0.5247 - val_loss: 1.0229 - val_acc: 0.4858\n",
            "Epoch 28/150 - 0.09s - loss: 0.9797 - acc: 0.5288 - val_loss: 1.0183 - val_acc: 0.5000\n",
            "Epoch 29/150 - 0.08s - loss: 0.9763 - acc: 0.5324 - val_loss: 1.0161 - val_acc: 0.5020\n",
            "Epoch 30/150 - 0.08s - loss: 0.9737 - acc: 0.5333 - val_loss: 1.0150 - val_acc: 0.5182\n",
            "Epoch 31/150 - 0.09s - loss: 0.9707 - acc: 0.5353 - val_loss: 1.0119 - val_acc: 0.5182\n",
            "Epoch 32/150 - 0.09s - loss: 0.9690 - acc: 0.5364 - val_loss: 1.0115 - val_acc: 0.5081\n",
            "Epoch 33/150 - 0.08s - loss: 0.9650 - acc: 0.5418 - val_loss: 1.0075 - val_acc: 0.5101\n",
            "Epoch 34/150 - 0.09s - loss: 0.9689 - acc: 0.5322 - val_loss: 1.0073 - val_acc: 0.5243\n",
            "Epoch 35/150 - 0.08s - loss: 0.9590 - acc: 0.5439 - val_loss: 1.0015 - val_acc: 0.5263\n",
            "Epoch 36/150 - 0.08s - loss: 0.9579 - acc: 0.5439 - val_loss: 1.0027 - val_acc: 0.5243\n",
            "Epoch 37/150 - 0.09s - loss: 0.9546 - acc: 0.5454 - val_loss: 0.9999 - val_acc: 0.5324\n",
            "Epoch 38/150 - 0.08s - loss: 0.9532 - acc: 0.5470 - val_loss: 0.9960 - val_acc: 0.5263\n",
            "Epoch 39/150 - 0.08s - loss: 0.9497 - acc: 0.5499 - val_loss: 0.9956 - val_acc: 0.5445\n",
            "Epoch 40/150 - 0.09s - loss: 0.9466 - acc: 0.5535 - val_loss: 0.9924 - val_acc: 0.5223\n",
            "Epoch 41/150 - 0.09s - loss: 0.9455 - acc: 0.5502 - val_loss: 0.9893 - val_acc: 0.5344\n",
            "Epoch 42/150 - 0.08s - loss: 0.9417 - acc: 0.5549 - val_loss: 0.9894 - val_acc: 0.5506\n",
            "Epoch 43/150 - 0.09s - loss: 0.9390 - acc: 0.5580 - val_loss: 0.9853 - val_acc: 0.5364\n",
            "Epoch 44/150 - 0.08s - loss: 0.9380 - acc: 0.5587 - val_loss: 0.9868 - val_acc: 0.5283\n",
            "Epoch 45/150 - 0.08s - loss: 0.9340 - acc: 0.5596 - val_loss: 0.9832 - val_acc: 0.5405\n",
            "Epoch 46/150 - 0.09s - loss: 0.9323 - acc: 0.5596 - val_loss: 0.9798 - val_acc: 0.5567\n",
            "Epoch 47/150 - 0.10s - loss: 0.9300 - acc: 0.5637 - val_loss: 0.9801 - val_acc: 0.5344\n",
            "Epoch 48/150 - 0.08s - loss: 0.9322 - acc: 0.5549 - val_loss: 0.9777 - val_acc: 0.5486\n",
            "Epoch 49/150 - 0.10s - loss: 0.9252 - acc: 0.5655 - val_loss: 0.9757 - val_acc: 0.5648\n",
            "Epoch 50/150 - 0.08s - loss: 0.9289 - acc: 0.5607 - val_loss: 0.9766 - val_acc: 0.5466\n",
            "Epoch 51/150 - 0.08s - loss: 0.9217 - acc: 0.5700 - val_loss: 0.9760 - val_acc: 0.5486\n",
            "Epoch 52/150 - 0.09s - loss: 0.9340 - acc: 0.5544 - val_loss: 0.9799 - val_acc: 0.5526\n",
            "Epoch 53/150 - 0.08s - loss: 0.9166 - acc: 0.5693 - val_loss: 0.9700 - val_acc: 0.5466\n",
            "Epoch 54/150 - 0.08s - loss: 0.9189 - acc: 0.5623 - val_loss: 0.9709 - val_acc: 0.5263\n",
            "Epoch 55/150 - 0.09s - loss: 0.9132 - acc: 0.5711 - val_loss: 0.9691 - val_acc: 0.5607\n",
            "Epoch 56/150 - 0.08s - loss: 0.9126 - acc: 0.5733 - val_loss: 0.9673 - val_acc: 0.5607\n",
            "Epoch 57/150 - 0.08s - loss: 0.9088 - acc: 0.5731 - val_loss: 0.9663 - val_acc: 0.5283\n",
            "Epoch 58/150 - 0.09s - loss: 0.9162 - acc: 0.5598 - val_loss: 0.9670 - val_acc: 0.5506\n",
            "Epoch 59/150 - 0.09s - loss: 0.9260 - acc: 0.5567 - val_loss: 0.9900 - val_acc: 0.4980\n",
            "Epoch 60/150 - 0.08s - loss: 0.9039 - acc: 0.5789 - val_loss: 0.9618 - val_acc: 0.5506\n",
            "Epoch 61/150 - 0.09s - loss: 0.9072 - acc: 0.5693 - val_loss: 0.9617 - val_acc: 0.5567\n",
            "Epoch 62/150 - 0.08s - loss: 0.9047 - acc: 0.5722 - val_loss: 0.9671 - val_acc: 0.5324\n",
            "Epoch 63/150 - 0.08s - loss: 0.9067 - acc: 0.5794 - val_loss: 0.9645 - val_acc: 0.5648\n",
            "Epoch 64/150 - 0.09s - loss: 0.9022 - acc: 0.5814 - val_loss: 0.9616 - val_acc: 0.5688\n",
            "Epoch 65/150 - 0.08s - loss: 0.9040 - acc: 0.5749 - val_loss: 0.9739 - val_acc: 0.5182\n",
            "Epoch 66/150 - 0.09s - loss: 0.8958 - acc: 0.5834 - val_loss: 0.9593 - val_acc: 0.5688\n",
            "Epoch 67/150 - 0.10s - loss: 0.8974 - acc: 0.5828 - val_loss: 0.9610 - val_acc: 0.5607\n",
            "Epoch 68/150 - 0.10s - loss: 0.9077 - acc: 0.5704 - val_loss: 0.9782 - val_acc: 0.5142\n",
            "Epoch 69/150 - 0.09s - loss: 0.8966 - acc: 0.5846 - val_loss: 0.9598 - val_acc: 0.5709\n",
            "Epoch 70/150 - 0.09s - loss: 0.8901 - acc: 0.5776 - val_loss: 0.9623 - val_acc: 0.5364\n",
            "Epoch 71/150 - 0.09s - loss: 0.8883 - acc: 0.5846 - val_loss: 0.9549 - val_acc: 0.5547\n",
            "Epoch 72/150 - 0.09s - loss: 0.8857 - acc: 0.5875 - val_loss: 0.9530 - val_acc: 0.5567\n",
            "Epoch 73/150 - 0.09s - loss: 0.8811 - acc: 0.5933 - val_loss: 0.9568 - val_acc: 0.5466\n",
            "Epoch 74/150 - 0.09s - loss: 0.8831 - acc: 0.5855 - val_loss: 0.9594 - val_acc: 0.5425\n",
            "Epoch 75/150 - 0.09s - loss: 0.8903 - acc: 0.5821 - val_loss: 0.9738 - val_acc: 0.5243\n",
            "Epoch 76/150 - 0.10s - loss: 0.8755 - acc: 0.5947 - val_loss: 0.9528 - val_acc: 0.5385\n",
            "Epoch 77/150 - 0.09s - loss: 0.8973 - acc: 0.5776 - val_loss: 0.9785 - val_acc: 0.5121\n",
            "Epoch 78/150 - 0.09s - loss: 0.8863 - acc: 0.5861 - val_loss: 0.9704 - val_acc: 0.5142\n",
            "Epoch 79/150 - 0.09s - loss: 0.8741 - acc: 0.5949 - val_loss: 0.9596 - val_acc: 0.5364\n",
            "Epoch 80/150 - 0.09s - loss: 0.8711 - acc: 0.5963 - val_loss: 0.9563 - val_acc: 0.5344\n",
            "Epoch 81/150 - 0.09s - loss: 0.8918 - acc: 0.5832 - val_loss: 0.9649 - val_acc: 0.5749\n",
            "Epoch 82/150 - 0.12s - loss: 0.8667 - acc: 0.5978 - val_loss: 0.9529 - val_acc: 0.5425\n",
            "Epoch 83/150 - 0.09s - loss: 0.8747 - acc: 0.5870 - val_loss: 0.9497 - val_acc: 0.5486\n",
            "Epoch 84/150 - 0.09s - loss: 0.8652 - acc: 0.5954 - val_loss: 0.9470 - val_acc: 0.5506\n",
            "Epoch 85/150 - 0.10s - loss: 0.8631 - acc: 0.6001 - val_loss: 0.9480 - val_acc: 0.5506\n",
            "Epoch 86/150 - 0.09s - loss: 0.8709 - acc: 0.5936 - val_loss: 0.9638 - val_acc: 0.5223\n",
            "Epoch 87/150 - 0.09s - loss: 0.8765 - acc: 0.5945 - val_loss: 0.9576 - val_acc: 0.5648\n",
            "Epoch 88/150 - 0.09s - loss: 0.8608 - acc: 0.5990 - val_loss: 0.9456 - val_acc: 0.5526\n",
            "Epoch 89/150 - 0.09s - loss: 0.8739 - acc: 0.6003 - val_loss: 0.9587 - val_acc: 0.5709\n",
            "Epoch 90/150 - 0.09s - loss: 0.8682 - acc: 0.5978 - val_loss: 0.9663 - val_acc: 0.5223\n",
            "Epoch 91/150 - 0.09s - loss: 0.8542 - acc: 0.6057 - val_loss: 0.9444 - val_acc: 0.5567\n",
            "Epoch 92/150 - 0.09s - loss: 0.8530 - acc: 0.6075 - val_loss: 0.9495 - val_acc: 0.5385\n",
            "Epoch 93/150 - 0.09s - loss: 0.8703 - acc: 0.5866 - val_loss: 0.9698 - val_acc: 0.5182\n",
            "Epoch 94/150 - 0.10s - loss: 0.8559 - acc: 0.6131 - val_loss: 0.9581 - val_acc: 0.5466\n",
            "Epoch 95/150 - 0.09s - loss: 0.8552 - acc: 0.6008 - val_loss: 0.9512 - val_acc: 0.5445\n",
            "Epoch 96/150 - 0.09s - loss: 0.8478 - acc: 0.6140 - val_loss: 0.9463 - val_acc: 0.5466\n",
            "Epoch 97/150 - 0.09s - loss: 0.8468 - acc: 0.6057 - val_loss: 0.9434 - val_acc: 0.5466\n",
            "Epoch 98/150 - 0.09s - loss: 0.8463 - acc: 0.6134 - val_loss: 0.9452 - val_acc: 0.5526\n",
            "Epoch 99/150 - 0.09s - loss: 0.8522 - acc: 0.6071 - val_loss: 0.9635 - val_acc: 0.5304\n",
            "Epoch 100/150 - 0.09s - loss: 0.8518 - acc: 0.6100 - val_loss: 0.9513 - val_acc: 0.5628\n",
            "Epoch 101/150 - 0.09s - loss: 0.8584 - acc: 0.5958 - val_loss: 0.9691 - val_acc: 0.5223\n",
            "Epoch 102/150 - 0.09s - loss: 0.8414 - acc: 0.6194 - val_loss: 0.9538 - val_acc: 0.5466\n",
            "Epoch 103/150 - 0.10s - loss: 0.8414 - acc: 0.6134 - val_loss: 0.9449 - val_acc: 0.5486\n",
            "Epoch 104/150 - 0.09s - loss: 0.8399 - acc: 0.6134 - val_loss: 0.9434 - val_acc: 0.5567\n",
            "Epoch 105/150 - 0.09s - loss: 0.8326 - acc: 0.6212 - val_loss: 0.9455 - val_acc: 0.5668\n",
            "Epoch 106/150 - 0.09s - loss: 0.8593 - acc: 0.6093 - val_loss: 0.9694 - val_acc: 0.5405\n",
            "Epoch 107/150 - 0.09s - loss: 0.8318 - acc: 0.6152 - val_loss: 0.9469 - val_acc: 0.5486\n",
            "Epoch 108/150 - 0.09s - loss: 0.8301 - acc: 0.6253 - val_loss: 0.9497 - val_acc: 0.5587\n",
            "Epoch 109/150 - 0.09s - loss: 0.8298 - acc: 0.6167 - val_loss: 0.9443 - val_acc: 0.5526\n",
            "Epoch 110/150 - 0.09s - loss: 0.8492 - acc: 0.6109 - val_loss: 0.9587 - val_acc: 0.5688\n",
            "Epoch 111/150 - 0.09s - loss: 0.8333 - acc: 0.6217 - val_loss: 0.9597 - val_acc: 0.5364\n",
            "Epoch 112/150 - 0.10s - loss: 0.8275 - acc: 0.6316 - val_loss: 0.9526 - val_acc: 0.5547\n",
            "Epoch 113/150 - 0.08s - loss: 0.8475 - acc: 0.6149 - val_loss: 0.9640 - val_acc: 0.5668\n",
            "Epoch 114/150 - 0.09s - loss: 0.8273 - acc: 0.6246 - val_loss: 0.9600 - val_acc: 0.5425\n",
            "Epoch 115/150 - 0.09s - loss: 0.8223 - acc: 0.6334 - val_loss: 0.9520 - val_acc: 0.5547\n",
            "Epoch 116/150 - 0.10s - loss: 0.8217 - acc: 0.6309 - val_loss: 0.9525 - val_acc: 0.5506\n",
            "Epoch 117/150 - 0.09s - loss: 0.8636 - acc: 0.6062 - val_loss: 0.9758 - val_acc: 0.5648\n",
            "Epoch 118/150 - 0.09s - loss: 0.8370 - acc: 0.6208 - val_loss: 0.9710 - val_acc: 0.5547\n",
            "Epoch 119/150 - 0.09s - loss: 0.8139 - acc: 0.6359 - val_loss: 0.9424 - val_acc: 0.5486\n",
            "Epoch 120/150 - 0.09s - loss: 0.8443 - acc: 0.6190 - val_loss: 0.9674 - val_acc: 0.5688\n",
            "Epoch 121/150 - 0.10s - loss: 0.8161 - acc: 0.6302 - val_loss: 0.9514 - val_acc: 0.5506\n",
            "Epoch 122/150 - 0.09s - loss: 0.8099 - acc: 0.6327 - val_loss: 0.9417 - val_acc: 0.5587\n",
            "Epoch 123/150 - 0.09s - loss: 0.8147 - acc: 0.6332 - val_loss: 0.9597 - val_acc: 0.5445\n",
            "Epoch 124/150 - 0.09s - loss: 0.8097 - acc: 0.6311 - val_loss: 0.9435 - val_acc: 0.5648\n",
            "Epoch 125/150 - 0.09s - loss: 0.8231 - acc: 0.6280 - val_loss: 0.9773 - val_acc: 0.5324\n",
            "Epoch 126/150 - 0.09s - loss: 0.8112 - acc: 0.6361 - val_loss: 0.9629 - val_acc: 0.5364\n",
            "Epoch 127/150 - 0.09s - loss: 0.8981 - acc: 0.5996 - val_loss: 1.0278 - val_acc: 0.5283\n",
            "Epoch 128/150 - 0.09s - loss: 0.8353 - acc: 0.6323 - val_loss: 0.9778 - val_acc: 0.5425\n",
            "Epoch 129/150 - 0.09s - loss: 0.8109 - acc: 0.6410 - val_loss: 0.9556 - val_acc: 0.5688\n",
            "Epoch 130/150 - 0.10s - loss: 0.8265 - acc: 0.6145 - val_loss: 0.9682 - val_acc: 0.5425\n",
            "Epoch 131/150 - 0.09s - loss: 0.8021 - acc: 0.6406 - val_loss: 0.9522 - val_acc: 0.5688\n",
            "Epoch 132/150 - 0.09s - loss: 0.7947 - acc: 0.6464 - val_loss: 0.9505 - val_acc: 0.5526\n",
            "Epoch 133/150 - 0.09s - loss: 0.8340 - acc: 0.6134 - val_loss: 0.9948 - val_acc: 0.5223\n",
            "Epoch 134/150 - 0.09s - loss: 0.8490 - acc: 0.6037 - val_loss: 1.0134 - val_acc: 0.5223\n",
            "Epoch 135/150 - 0.09s - loss: 0.8541 - acc: 0.5875 - val_loss: 0.9800 - val_acc: 0.5364\n",
            "Epoch 136/150 - 0.09s - loss: 0.9035 - acc: 0.5702 - val_loss: 1.0780 - val_acc: 0.5020\n",
            "Epoch 137/150 - 0.09s - loss: 0.7931 - acc: 0.6511 - val_loss: 0.9586 - val_acc: 0.5445\n",
            "Epoch 138/150 - 0.09s - loss: 0.7995 - acc: 0.6428 - val_loss: 0.9669 - val_acc: 0.5425\n",
            "Epoch 139/150 - 0.10s - loss: 0.7841 - acc: 0.6552 - val_loss: 0.9465 - val_acc: 0.5607\n",
            "Epoch 140/150 - 0.09s - loss: 0.7847 - acc: 0.6525 - val_loss: 0.9556 - val_acc: 0.5587\n",
            "Epoch 141/150 - 0.09s - loss: 0.8059 - acc: 0.6237 - val_loss: 0.9554 - val_acc: 0.5526\n",
            "Epoch 142/150 - 0.10s - loss: 0.8350 - acc: 0.6062 - val_loss: 1.0112 - val_acc: 0.5061\n",
            "Epoch 143/150 - 0.09s - loss: 0.8011 - acc: 0.6466 - val_loss: 0.9592 - val_acc: 0.5709\n",
            "Epoch 144/150 - 0.09s - loss: 0.7808 - acc: 0.6552 - val_loss: 0.9583 - val_acc: 0.5567\n",
            "Epoch 145/150 - 0.09s - loss: 0.8771 - acc: 0.5805 - val_loss: 1.0630 - val_acc: 0.5202\n",
            "Epoch 146/150 - 0.09s - loss: 0.9223 - acc: 0.5634 - val_loss: 1.1250 - val_acc: 0.4777\n",
            "Epoch 147/150 - 0.09s - loss: 0.7778 - acc: 0.6586 - val_loss: 0.9610 - val_acc: 0.5506\n",
            "Epoch 148/150 - 0.10s - loss: 0.7939 - acc: 0.6399 - val_loss: 0.9559 - val_acc: 0.5891\n",
            "Epoch 149/150 - 0.10s - loss: 0.7968 - acc: 0.6363 - val_loss: 0.9695 - val_acc: 0.5547\n",
            "Epoch 150/150 - 0.09s - loss: 0.7791 - acc: 0.6568 - val_loss: 0.9674 - val_acc: 0.5466\n",
            "\n",
            "Combination 115/252:\n",
            "Hidden Layers: [256, 128], Activation: relu, Learning Rate: 0.001, Batch Size: 32, Epochs: 50\n",
            "Epoch 1/50 - 0.13s - loss: 1.0997 - acc: 0.3493 - val_loss: 1.0975 - val_acc: 0.3462\n",
            "Epoch 2/50 - 0.12s - loss: 1.0954 - acc: 0.3637 - val_loss: 1.0948 - val_acc: 0.3543\n",
            "Epoch 3/50 - 0.12s - loss: 1.0925 - acc: 0.3671 - val_loss: 1.0926 - val_acc: 0.3603\n",
            "Epoch 4/50 - 0.12s - loss: 1.0899 - acc: 0.3770 - val_loss: 1.0904 - val_acc: 0.3623\n",
            "Epoch 5/50 - 0.12s - loss: 1.0875 - acc: 0.3817 - val_loss: 1.0881 - val_acc: 0.3583\n",
            "Epoch 6/50 - 0.12s - loss: 1.0853 - acc: 0.3857 - val_loss: 1.0863 - val_acc: 0.3725\n",
            "Epoch 7/50 - 0.12s - loss: 1.0832 - acc: 0.3938 - val_loss: 1.0845 - val_acc: 0.3785\n",
            "Epoch 8/50 - 0.12s - loss: 1.0811 - acc: 0.4024 - val_loss: 1.0825 - val_acc: 0.3988\n",
            "Epoch 9/50 - 0.11s - loss: 1.0791 - acc: 0.4082 - val_loss: 1.0809 - val_acc: 0.4089\n",
            "Epoch 10/50 - 0.12s - loss: 1.0773 - acc: 0.4154 - val_loss: 1.0792 - val_acc: 0.4130\n",
            "Epoch 11/50 - 0.12s - loss: 1.0755 - acc: 0.4184 - val_loss: 1.0776 - val_acc: 0.4271\n",
            "Epoch 12/50 - 0.12s - loss: 1.0738 - acc: 0.4244 - val_loss: 1.0761 - val_acc: 0.4271\n",
            "Epoch 13/50 - 0.11s - loss: 1.0722 - acc: 0.4271 - val_loss: 1.0748 - val_acc: 0.4393\n",
            "Epoch 14/50 - 0.12s - loss: 1.0706 - acc: 0.4260 - val_loss: 1.0734 - val_acc: 0.4312\n",
            "Epoch 15/50 - 0.12s - loss: 1.0691 - acc: 0.4300 - val_loss: 1.0722 - val_acc: 0.4332\n",
            "Epoch 16/50 - 0.12s - loss: 1.0677 - acc: 0.4336 - val_loss: 1.0711 - val_acc: 0.4474\n",
            "Epoch 17/50 - 0.12s - loss: 1.0662 - acc: 0.4363 - val_loss: 1.0698 - val_acc: 0.4453\n",
            "Epoch 18/50 - 0.12s - loss: 1.0648 - acc: 0.4381 - val_loss: 1.0687 - val_acc: 0.4413\n",
            "Epoch 19/50 - 0.11s - loss: 1.0635 - acc: 0.4404 - val_loss: 1.0678 - val_acc: 0.4352\n",
            "Epoch 20/50 - 0.12s - loss: 1.0623 - acc: 0.4429 - val_loss: 1.0666 - val_acc: 0.4453\n",
            "Epoch 21/50 - 0.12s - loss: 1.0610 - acc: 0.4456 - val_loss: 1.0657 - val_acc: 0.4555\n",
            "Epoch 22/50 - 0.14s - loss: 1.0598 - acc: 0.4469 - val_loss: 1.0648 - val_acc: 0.4595\n",
            "Epoch 23/50 - 0.12s - loss: 1.0587 - acc: 0.4489 - val_loss: 1.0638 - val_acc: 0.4555\n",
            "Epoch 24/50 - 0.12s - loss: 1.0576 - acc: 0.4516 - val_loss: 1.0627 - val_acc: 0.4514\n",
            "Epoch 25/50 - 0.12s - loss: 1.0565 - acc: 0.4541 - val_loss: 1.0619 - val_acc: 0.4575\n",
            "Epoch 26/50 - 0.12s - loss: 1.0555 - acc: 0.4546 - val_loss: 1.0612 - val_acc: 0.4696\n",
            "Epoch 27/50 - 0.12s - loss: 1.0545 - acc: 0.4577 - val_loss: 1.0602 - val_acc: 0.4514\n",
            "Epoch 28/50 - 0.13s - loss: 1.0534 - acc: 0.4568 - val_loss: 1.0596 - val_acc: 0.4555\n",
            "Epoch 29/50 - 0.14s - loss: 1.0524 - acc: 0.4546 - val_loss: 1.0590 - val_acc: 0.4615\n",
            "Epoch 30/50 - 0.13s - loss: 1.0515 - acc: 0.4579 - val_loss: 1.0583 - val_acc: 0.4636\n",
            "Epoch 31/50 - 0.12s - loss: 1.0505 - acc: 0.4564 - val_loss: 1.0577 - val_acc: 0.4615\n",
            "Epoch 32/50 - 0.12s - loss: 1.0495 - acc: 0.4595 - val_loss: 1.0568 - val_acc: 0.4595\n",
            "Epoch 33/50 - 0.12s - loss: 1.0486 - acc: 0.4620 - val_loss: 1.0559 - val_acc: 0.4595\n",
            "Epoch 34/50 - 0.12s - loss: 1.0477 - acc: 0.4663 - val_loss: 1.0551 - val_acc: 0.4534\n",
            "Epoch 35/50 - 0.12s - loss: 1.0469 - acc: 0.4622 - val_loss: 1.0549 - val_acc: 0.4636\n",
            "Epoch 36/50 - 0.12s - loss: 1.0460 - acc: 0.4651 - val_loss: 1.0540 - val_acc: 0.4595\n",
            "Epoch 37/50 - 0.12s - loss: 1.0451 - acc: 0.4665 - val_loss: 1.0534 - val_acc: 0.4615\n",
            "Epoch 38/50 - 0.12s - loss: 1.0443 - acc: 0.4692 - val_loss: 1.0525 - val_acc: 0.4595\n",
            "Epoch 39/50 - 0.12s - loss: 1.0436 - acc: 0.4703 - val_loss: 1.0517 - val_acc: 0.4656\n",
            "Epoch 40/50 - 0.12s - loss: 1.0427 - acc: 0.4712 - val_loss: 1.0513 - val_acc: 0.4656\n",
            "Epoch 41/50 - 0.12s - loss: 1.0419 - acc: 0.4717 - val_loss: 1.0508 - val_acc: 0.4696\n",
            "Epoch 42/50 - 0.13s - loss: 1.0411 - acc: 0.4699 - val_loss: 1.0504 - val_acc: 0.4696\n",
            "Epoch 43/50 - 0.12s - loss: 1.0403 - acc: 0.4696 - val_loss: 1.0500 - val_acc: 0.4636\n",
            "Epoch 44/50 - 0.14s - loss: 1.0395 - acc: 0.4694 - val_loss: 1.0494 - val_acc: 0.4656\n",
            "Epoch 45/50 - 0.12s - loss: 1.0388 - acc: 0.4717 - val_loss: 1.0487 - val_acc: 0.4696\n",
            "Epoch 46/50 - 0.12s - loss: 1.0380 - acc: 0.4755 - val_loss: 1.0479 - val_acc: 0.4696\n",
            "Epoch 47/50 - 0.12s - loss: 1.0372 - acc: 0.4735 - val_loss: 1.0476 - val_acc: 0.4737\n",
            "Epoch 48/50 - 0.12s - loss: 1.0365 - acc: 0.4762 - val_loss: 1.0468 - val_acc: 0.4757\n",
            "Epoch 49/50 - 0.12s - loss: 1.0357 - acc: 0.4732 - val_loss: 1.0465 - val_acc: 0.4757\n",
            "Epoch 50/50 - 0.12s - loss: 1.0350 - acc: 0.4735 - val_loss: 1.0460 - val_acc: 0.4737\n",
            "\n",
            "Combination 116/252:\n",
            "Hidden Layers: [256, 128], Activation: relu, Learning Rate: 0.001, Batch Size: 32, Epochs: 100\n",
            "Epoch 1/100 - 0.12s - loss: 1.1026 - acc: 0.3520 - val_loss: 1.1050 - val_acc: 0.3381\n",
            "Epoch 2/100 - 0.12s - loss: 1.0984 - acc: 0.3360 - val_loss: 1.1007 - val_acc: 0.3421\n",
            "Epoch 3/100 - 0.12s - loss: 1.0958 - acc: 0.3381 - val_loss: 1.0984 - val_acc: 0.3462\n",
            "Epoch 4/100 - 0.12s - loss: 1.0936 - acc: 0.3522 - val_loss: 1.0962 - val_acc: 0.3502\n",
            "Epoch 5/100 - 0.12s - loss: 1.0915 - acc: 0.3675 - val_loss: 1.0946 - val_acc: 0.3644\n",
            "Epoch 6/100 - 0.11s - loss: 1.0896 - acc: 0.3828 - val_loss: 1.0927 - val_acc: 0.3725\n",
            "Epoch 7/100 - 0.12s - loss: 1.0878 - acc: 0.3905 - val_loss: 1.0911 - val_acc: 0.3745\n",
            "Epoch 8/100 - 0.12s - loss: 1.0861 - acc: 0.3952 - val_loss: 1.0895 - val_acc: 0.3927\n",
            "Epoch 9/100 - 0.12s - loss: 1.0845 - acc: 0.4006 - val_loss: 1.0882 - val_acc: 0.4028\n",
            "Epoch 10/100 - 0.13s - loss: 1.0829 - acc: 0.4051 - val_loss: 1.0868 - val_acc: 0.4130\n",
            "Epoch 11/100 - 0.13s - loss: 1.0813 - acc: 0.4118 - val_loss: 1.0856 - val_acc: 0.4190\n",
            "Epoch 12/100 - 0.12s - loss: 1.0799 - acc: 0.4168 - val_loss: 1.0843 - val_acc: 0.4130\n",
            "Epoch 13/100 - 0.12s - loss: 1.0785 - acc: 0.4195 - val_loss: 1.0832 - val_acc: 0.4251\n",
            "Epoch 14/100 - 0.13s - loss: 1.0772 - acc: 0.4229 - val_loss: 1.0819 - val_acc: 0.4312\n",
            "Epoch 15/100 - 0.13s - loss: 1.0759 - acc: 0.4222 - val_loss: 1.0810 - val_acc: 0.4271\n",
            "Epoch 16/100 - 0.14s - loss: 1.0746 - acc: 0.4265 - val_loss: 1.0800 - val_acc: 0.4372\n",
            "Epoch 17/100 - 0.12s - loss: 1.0734 - acc: 0.4285 - val_loss: 1.0792 - val_acc: 0.4291\n",
            "Epoch 18/100 - 0.12s - loss: 1.0722 - acc: 0.4298 - val_loss: 1.0783 - val_acc: 0.4312\n",
            "Epoch 19/100 - 0.12s - loss: 1.0712 - acc: 0.4300 - val_loss: 1.0776 - val_acc: 0.4251\n",
            "Epoch 20/100 - 0.12s - loss: 1.0701 - acc: 0.4334 - val_loss: 1.0764 - val_acc: 0.4474\n",
            "Epoch 21/100 - 0.13s - loss: 1.0690 - acc: 0.4359 - val_loss: 1.0754 - val_acc: 0.4575\n",
            "Epoch 22/100 - 0.13s - loss: 1.0681 - acc: 0.4366 - val_loss: 1.0745 - val_acc: 0.4534\n",
            "Epoch 23/100 - 0.13s - loss: 1.0671 - acc: 0.4379 - val_loss: 1.0737 - val_acc: 0.4534\n",
            "Epoch 24/100 - 0.12s - loss: 1.0662 - acc: 0.4361 - val_loss: 1.0730 - val_acc: 0.4575\n",
            "Epoch 25/100 - 0.13s - loss: 1.0653 - acc: 0.4424 - val_loss: 1.0725 - val_acc: 0.4595\n",
            "Epoch 26/100 - 0.13s - loss: 1.0644 - acc: 0.4417 - val_loss: 1.0718 - val_acc: 0.4615\n",
            "Epoch 27/100 - 0.14s - loss: 1.0636 - acc: 0.4424 - val_loss: 1.0710 - val_acc: 0.4595\n",
            "Epoch 28/100 - 0.13s - loss: 1.0627 - acc: 0.4417 - val_loss: 1.0703 - val_acc: 0.4636\n",
            "Epoch 29/100 - 0.13s - loss: 1.0619 - acc: 0.4433 - val_loss: 1.0695 - val_acc: 0.4636\n",
            "Epoch 30/100 - 0.13s - loss: 1.0611 - acc: 0.4433 - val_loss: 1.0689 - val_acc: 0.4696\n",
            "Epoch 31/100 - 0.13s - loss: 1.0603 - acc: 0.4456 - val_loss: 1.0684 - val_acc: 0.4676\n",
            "Epoch 32/100 - 0.12s - loss: 1.0595 - acc: 0.4458 - val_loss: 1.0676 - val_acc: 0.4717\n",
            "Epoch 33/100 - 0.12s - loss: 1.0588 - acc: 0.4469 - val_loss: 1.0671 - val_acc: 0.4717\n",
            "Epoch 34/100 - 0.13s - loss: 1.0580 - acc: 0.4485 - val_loss: 1.0666 - val_acc: 0.4676\n",
            "Epoch 35/100 - 0.12s - loss: 1.0573 - acc: 0.4505 - val_loss: 1.0659 - val_acc: 0.4737\n",
            "Epoch 36/100 - 0.12s - loss: 1.0566 - acc: 0.4507 - val_loss: 1.0654 - val_acc: 0.4757\n",
            "Epoch 37/100 - 0.13s - loss: 1.0558 - acc: 0.4510 - val_loss: 1.0648 - val_acc: 0.4717\n",
            "Epoch 38/100 - 0.15s - loss: 1.0551 - acc: 0.4521 - val_loss: 1.0644 - val_acc: 0.4696\n",
            "Epoch 39/100 - 0.14s - loss: 1.0544 - acc: 0.4525 - val_loss: 1.0639 - val_acc: 0.4696\n",
            "Epoch 40/100 - 0.12s - loss: 1.0537 - acc: 0.4532 - val_loss: 1.0632 - val_acc: 0.4656\n",
            "Epoch 41/100 - 0.13s - loss: 1.0530 - acc: 0.4530 - val_loss: 1.0627 - val_acc: 0.4656\n",
            "Epoch 42/100 - 0.12s - loss: 1.0523 - acc: 0.4534 - val_loss: 1.0623 - val_acc: 0.4676\n",
            "Epoch 43/100 - 0.12s - loss: 1.0516 - acc: 0.4550 - val_loss: 1.0620 - val_acc: 0.4615\n",
            "Epoch 44/100 - 0.12s - loss: 1.0509 - acc: 0.4557 - val_loss: 1.0615 - val_acc: 0.4636\n",
            "Epoch 45/100 - 0.12s - loss: 1.0502 - acc: 0.4566 - val_loss: 1.0609 - val_acc: 0.4656\n",
            "Epoch 46/100 - 0.12s - loss: 1.0496 - acc: 0.4575 - val_loss: 1.0605 - val_acc: 0.4676\n",
            "Epoch 47/100 - 0.12s - loss: 1.0489 - acc: 0.4570 - val_loss: 1.0601 - val_acc: 0.4676\n",
            "Epoch 48/100 - 0.13s - loss: 1.0482 - acc: 0.4613 - val_loss: 1.0595 - val_acc: 0.4676\n",
            "Epoch 49/100 - 0.12s - loss: 1.0475 - acc: 0.4611 - val_loss: 1.0592 - val_acc: 0.4696\n",
            "Epoch 50/100 - 0.12s - loss: 1.0469 - acc: 0.4595 - val_loss: 1.0588 - val_acc: 0.4696\n",
            "Epoch 51/100 - 0.12s - loss: 1.0462 - acc: 0.4613 - val_loss: 1.0583 - val_acc: 0.4696\n",
            "Epoch 52/100 - 0.13s - loss: 1.0456 - acc: 0.4618 - val_loss: 1.0579 - val_acc: 0.4676\n",
            "Epoch 53/100 - 0.12s - loss: 1.0449 - acc: 0.4638 - val_loss: 1.0573 - val_acc: 0.4696\n",
            "Epoch 54/100 - 0.12s - loss: 1.0442 - acc: 0.4645 - val_loss: 1.0569 - val_acc: 0.4676\n",
            "Epoch 55/100 - 0.12s - loss: 1.0436 - acc: 0.4672 - val_loss: 1.0565 - val_acc: 0.4777\n",
            "Epoch 56/100 - 0.12s - loss: 1.0429 - acc: 0.4660 - val_loss: 1.0560 - val_acc: 0.4757\n",
            "Epoch 57/100 - 0.12s - loss: 1.0423 - acc: 0.4654 - val_loss: 1.0558 - val_acc: 0.4717\n",
            "Epoch 58/100 - 0.13s - loss: 1.0416 - acc: 0.4663 - val_loss: 1.0553 - val_acc: 0.4737\n",
            "Epoch 59/100 - 0.12s - loss: 1.0410 - acc: 0.4692 - val_loss: 1.0547 - val_acc: 0.4757\n",
            "Epoch 60/100 - 0.14s - loss: 1.0404 - acc: 0.4705 - val_loss: 1.0542 - val_acc: 0.4777\n",
            "Epoch 61/100 - 0.12s - loss: 1.0397 - acc: 0.4687 - val_loss: 1.0538 - val_acc: 0.4737\n",
            "Epoch 62/100 - 0.12s - loss: 1.0390 - acc: 0.4712 - val_loss: 1.0534 - val_acc: 0.4757\n",
            "Epoch 63/100 - 0.13s - loss: 1.0384 - acc: 0.4714 - val_loss: 1.0530 - val_acc: 0.4777\n",
            "Epoch 64/100 - 0.12s - loss: 1.0377 - acc: 0.4728 - val_loss: 1.0526 - val_acc: 0.4757\n",
            "Epoch 65/100 - 0.12s - loss: 1.0371 - acc: 0.4732 - val_loss: 1.0522 - val_acc: 0.4798\n",
            "Epoch 66/100 - 0.12s - loss: 1.0365 - acc: 0.4737 - val_loss: 1.0519 - val_acc: 0.4757\n",
            "Epoch 67/100 - 0.12s - loss: 1.0358 - acc: 0.4762 - val_loss: 1.0515 - val_acc: 0.4737\n",
            "Epoch 68/100 - 0.12s - loss: 1.0352 - acc: 0.4732 - val_loss: 1.0509 - val_acc: 0.4798\n",
            "Epoch 69/100 - 0.12s - loss: 1.0346 - acc: 0.4744 - val_loss: 1.0506 - val_acc: 0.4798\n",
            "Epoch 70/100 - 0.12s - loss: 1.0340 - acc: 0.4780 - val_loss: 1.0499 - val_acc: 0.4838\n",
            "Epoch 71/100 - 0.12s - loss: 1.0333 - acc: 0.4786 - val_loss: 1.0496 - val_acc: 0.4838\n",
            "Epoch 72/100 - 0.12s - loss: 1.0326 - acc: 0.4798 - val_loss: 1.0492 - val_acc: 0.4858\n",
            "Epoch 73/100 - 0.12s - loss: 1.0320 - acc: 0.4786 - val_loss: 1.0488 - val_acc: 0.4838\n",
            "Epoch 74/100 - 0.12s - loss: 1.0313 - acc: 0.4791 - val_loss: 1.0486 - val_acc: 0.4858\n",
            "Epoch 75/100 - 0.12s - loss: 1.0307 - acc: 0.4802 - val_loss: 1.0480 - val_acc: 0.4879\n",
            "Epoch 76/100 - 0.13s - loss: 1.0301 - acc: 0.4813 - val_loss: 1.0478 - val_acc: 0.4919\n",
            "Epoch 77/100 - 0.12s - loss: 1.0294 - acc: 0.4811 - val_loss: 1.0474 - val_acc: 0.4919\n",
            "Epoch 78/100 - 0.12s - loss: 1.0288 - acc: 0.4818 - val_loss: 1.0469 - val_acc: 0.4879\n",
            "Epoch 79/100 - 0.12s - loss: 1.0282 - acc: 0.4840 - val_loss: 1.0463 - val_acc: 0.4899\n",
            "Epoch 80/100 - 0.12s - loss: 1.0276 - acc: 0.4822 - val_loss: 1.0462 - val_acc: 0.4899\n",
            "Epoch 81/100 - 0.14s - loss: 1.0269 - acc: 0.4845 - val_loss: 1.0457 - val_acc: 0.4980\n",
            "Epoch 82/100 - 0.16s - loss: 1.0262 - acc: 0.4854 - val_loss: 1.0453 - val_acc: 0.4980\n",
            "Epoch 83/100 - 0.12s - loss: 1.0256 - acc: 0.4876 - val_loss: 1.0448 - val_acc: 0.4960\n",
            "Epoch 84/100 - 0.12s - loss: 1.0250 - acc: 0.4876 - val_loss: 1.0444 - val_acc: 0.4960\n",
            "Epoch 85/100 - 0.12s - loss: 1.0243 - acc: 0.4885 - val_loss: 1.0442 - val_acc: 0.5000\n",
            "Epoch 86/100 - 0.12s - loss: 1.0237 - acc: 0.4894 - val_loss: 1.0439 - val_acc: 0.5020\n",
            "Epoch 87/100 - 0.13s - loss: 1.0231 - acc: 0.4903 - val_loss: 1.0434 - val_acc: 0.5000\n",
            "Epoch 88/100 - 0.12s - loss: 1.0224 - acc: 0.4921 - val_loss: 1.0429 - val_acc: 0.4980\n",
            "Epoch 89/100 - 0.12s - loss: 1.0219 - acc: 0.4910 - val_loss: 1.0423 - val_acc: 0.5020\n",
            "Epoch 90/100 - 0.12s - loss: 1.0212 - acc: 0.4926 - val_loss: 1.0421 - val_acc: 0.5101\n",
            "Epoch 91/100 - 0.12s - loss: 1.0206 - acc: 0.4903 - val_loss: 1.0421 - val_acc: 0.5081\n",
            "Epoch 92/100 - 0.12s - loss: 1.0199 - acc: 0.4924 - val_loss: 1.0418 - val_acc: 0.5040\n",
            "Epoch 93/100 - 0.12s - loss: 1.0192 - acc: 0.4951 - val_loss: 1.0410 - val_acc: 0.5101\n",
            "Epoch 94/100 - 0.13s - loss: 1.0186 - acc: 0.4960 - val_loss: 1.0406 - val_acc: 0.5020\n",
            "Epoch 95/100 - 0.13s - loss: 1.0179 - acc: 0.4928 - val_loss: 1.0401 - val_acc: 0.5061\n",
            "Epoch 96/100 - 0.12s - loss: 1.0173 - acc: 0.4971 - val_loss: 1.0399 - val_acc: 0.5101\n",
            "Epoch 97/100 - 0.12s - loss: 1.0167 - acc: 0.4966 - val_loss: 1.0392 - val_acc: 0.5142\n",
            "Epoch 98/100 - 0.12s - loss: 1.0161 - acc: 0.4955 - val_loss: 1.0393 - val_acc: 0.5101\n",
            "Epoch 99/100 - 0.13s - loss: 1.0153 - acc: 0.4980 - val_loss: 1.0385 - val_acc: 0.5182\n",
            "Epoch 100/100 - 0.12s - loss: 1.0146 - acc: 0.4978 - val_loss: 1.0380 - val_acc: 0.5142\n",
            "\n",
            "Combination 117/252:\n",
            "Hidden Layers: [256, 128], Activation: relu, Learning Rate: 0.001, Batch Size: 32, Epochs: 150\n",
            "Epoch 1/150 - 0.12s - loss: 1.1056 - acc: 0.3504 - val_loss: 1.1003 - val_acc: 0.3704\n",
            "Epoch 2/150 - 0.12s - loss: 1.0976 - acc: 0.3637 - val_loss: 1.0948 - val_acc: 0.3806\n",
            "Epoch 3/150 - 0.12s - loss: 1.0946 - acc: 0.3767 - val_loss: 1.0931 - val_acc: 0.3988\n",
            "Epoch 4/150 - 0.12s - loss: 1.0924 - acc: 0.3844 - val_loss: 1.0917 - val_acc: 0.3785\n",
            "Epoch 5/150 - 0.15s - loss: 1.0904 - acc: 0.3900 - val_loss: 1.0902 - val_acc: 0.3907\n",
            "Epoch 6/150 - 0.12s - loss: 1.0885 - acc: 0.3961 - val_loss: 1.0887 - val_acc: 0.4028\n",
            "Epoch 7/150 - 0.12s - loss: 1.0866 - acc: 0.4042 - val_loss: 1.0871 - val_acc: 0.4190\n",
            "Epoch 8/150 - 0.12s - loss: 1.0849 - acc: 0.4062 - val_loss: 1.0853 - val_acc: 0.4211\n",
            "Epoch 9/150 - 0.13s - loss: 1.0832 - acc: 0.4098 - val_loss: 1.0838 - val_acc: 0.4190\n",
            "Epoch 10/150 - 0.13s - loss: 1.0816 - acc: 0.4148 - val_loss: 1.0825 - val_acc: 0.4291\n",
            "Epoch 11/150 - 0.14s - loss: 1.0800 - acc: 0.4184 - val_loss: 1.0812 - val_acc: 0.4352\n",
            "Epoch 12/150 - 0.12s - loss: 1.0785 - acc: 0.4233 - val_loss: 1.0799 - val_acc: 0.4332\n",
            "Epoch 13/150 - 0.12s - loss: 1.0771 - acc: 0.4291 - val_loss: 1.0786 - val_acc: 0.4413\n",
            "Epoch 14/150 - 0.12s - loss: 1.0757 - acc: 0.4321 - val_loss: 1.0775 - val_acc: 0.4494\n",
            "Epoch 15/150 - 0.13s - loss: 1.0744 - acc: 0.4327 - val_loss: 1.0767 - val_acc: 0.4494\n",
            "Epoch 16/150 - 0.13s - loss: 1.0731 - acc: 0.4336 - val_loss: 1.0757 - val_acc: 0.4453\n",
            "Epoch 17/150 - 0.13s - loss: 1.0719 - acc: 0.4402 - val_loss: 1.0745 - val_acc: 0.4433\n",
            "Epoch 18/150 - 0.12s - loss: 1.0707 - acc: 0.4424 - val_loss: 1.0736 - val_acc: 0.4494\n",
            "Epoch 19/150 - 0.12s - loss: 1.0696 - acc: 0.4426 - val_loss: 1.0728 - val_acc: 0.4514\n",
            "Epoch 20/150 - 0.12s - loss: 1.0684 - acc: 0.4451 - val_loss: 1.0720 - val_acc: 0.4534\n",
            "Epoch 21/150 - 0.12s - loss: 1.0673 - acc: 0.4462 - val_loss: 1.0711 - val_acc: 0.4514\n",
            "Epoch 22/150 - 0.12s - loss: 1.0663 - acc: 0.4519 - val_loss: 1.0703 - val_acc: 0.4575\n",
            "Epoch 23/150 - 0.12s - loss: 1.0652 - acc: 0.4543 - val_loss: 1.0696 - val_acc: 0.4534\n",
            "Epoch 24/150 - 0.13s - loss: 1.0642 - acc: 0.4570 - val_loss: 1.0687 - val_acc: 0.4494\n",
            "Epoch 25/150 - 0.12s - loss: 1.0632 - acc: 0.4579 - val_loss: 1.0679 - val_acc: 0.4433\n",
            "Epoch 26/150 - 0.14s - loss: 1.0622 - acc: 0.4615 - val_loss: 1.0671 - val_acc: 0.4453\n",
            "Epoch 27/150 - 0.12s - loss: 1.0612 - acc: 0.4604 - val_loss: 1.0668 - val_acc: 0.4595\n",
            "Epoch 28/150 - 0.12s - loss: 1.0603 - acc: 0.4615 - val_loss: 1.0659 - val_acc: 0.4514\n",
            "Epoch 29/150 - 0.12s - loss: 1.0594 - acc: 0.4638 - val_loss: 1.0653 - val_acc: 0.4555\n",
            "Epoch 30/150 - 0.13s - loss: 1.0584 - acc: 0.4654 - val_loss: 1.0647 - val_acc: 0.4534\n",
            "Epoch 31/150 - 0.12s - loss: 1.0576 - acc: 0.4667 - val_loss: 1.0640 - val_acc: 0.4534\n",
            "Epoch 32/150 - 0.12s - loss: 1.0567 - acc: 0.4681 - val_loss: 1.0634 - val_acc: 0.4534\n",
            "Epoch 33/150 - 0.12s - loss: 1.0559 - acc: 0.4726 - val_loss: 1.0631 - val_acc: 0.4555\n",
            "Epoch 34/150 - 0.12s - loss: 1.0550 - acc: 0.4712 - val_loss: 1.0626 - val_acc: 0.4575\n",
            "Epoch 35/150 - 0.12s - loss: 1.0541 - acc: 0.4672 - val_loss: 1.0615 - val_acc: 0.4575\n",
            "Epoch 36/150 - 0.12s - loss: 1.0533 - acc: 0.4699 - val_loss: 1.0611 - val_acc: 0.4615\n",
            "Epoch 37/150 - 0.12s - loss: 1.0525 - acc: 0.4705 - val_loss: 1.0608 - val_acc: 0.4656\n",
            "Epoch 38/150 - 0.12s - loss: 1.0517 - acc: 0.4676 - val_loss: 1.0601 - val_acc: 0.4656\n",
            "Epoch 39/150 - 0.12s - loss: 1.0509 - acc: 0.4735 - val_loss: 1.0595 - val_acc: 0.4595\n",
            "Epoch 40/150 - 0.12s - loss: 1.0501 - acc: 0.4735 - val_loss: 1.0590 - val_acc: 0.4555\n",
            "Epoch 41/150 - 0.12s - loss: 1.0493 - acc: 0.4746 - val_loss: 1.0586 - val_acc: 0.4575\n",
            "Epoch 42/150 - 0.13s - loss: 1.0486 - acc: 0.4750 - val_loss: 1.0582 - val_acc: 0.4615\n",
            "Epoch 43/150 - 0.12s - loss: 1.0478 - acc: 0.4712 - val_loss: 1.0577 - val_acc: 0.4656\n",
            "Epoch 44/150 - 0.13s - loss: 1.0471 - acc: 0.4712 - val_loss: 1.0571 - val_acc: 0.4615\n",
            "Epoch 45/150 - 0.13s - loss: 1.0463 - acc: 0.4726 - val_loss: 1.0565 - val_acc: 0.4676\n",
            "Epoch 46/150 - 0.13s - loss: 1.0456 - acc: 0.4710 - val_loss: 1.0562 - val_acc: 0.4636\n",
            "Epoch 47/150 - 0.14s - loss: 1.0449 - acc: 0.4784 - val_loss: 1.0557 - val_acc: 0.4636\n",
            "Epoch 48/150 - 0.14s - loss: 1.0442 - acc: 0.4759 - val_loss: 1.0551 - val_acc: 0.4696\n",
            "Epoch 49/150 - 0.12s - loss: 1.0435 - acc: 0.4755 - val_loss: 1.0549 - val_acc: 0.4676\n",
            "Epoch 50/150 - 0.13s - loss: 1.0428 - acc: 0.4775 - val_loss: 1.0544 - val_acc: 0.4636\n",
            "Epoch 51/150 - 0.12s - loss: 1.0421 - acc: 0.4771 - val_loss: 1.0543 - val_acc: 0.4636\n",
            "Epoch 52/150 - 0.12s - loss: 1.0414 - acc: 0.4789 - val_loss: 1.0537 - val_acc: 0.4656\n",
            "Epoch 53/150 - 0.12s - loss: 1.0407 - acc: 0.4784 - val_loss: 1.0532 - val_acc: 0.4676\n",
            "Epoch 54/150 - 0.13s - loss: 1.0400 - acc: 0.4782 - val_loss: 1.0528 - val_acc: 0.4676\n",
            "Epoch 55/150 - 0.12s - loss: 1.0393 - acc: 0.4791 - val_loss: 1.0525 - val_acc: 0.4656\n",
            "Epoch 56/150 - 0.12s - loss: 1.0387 - acc: 0.4798 - val_loss: 1.0520 - val_acc: 0.4656\n",
            "Epoch 57/150 - 0.12s - loss: 1.0380 - acc: 0.4811 - val_loss: 1.0515 - val_acc: 0.4777\n",
            "Epoch 58/150 - 0.12s - loss: 1.0373 - acc: 0.4793 - val_loss: 1.0511 - val_acc: 0.4717\n",
            "Epoch 59/150 - 0.12s - loss: 1.0367 - acc: 0.4829 - val_loss: 1.0508 - val_acc: 0.4757\n",
            "Epoch 60/150 - 0.12s - loss: 1.0361 - acc: 0.4786 - val_loss: 1.0503 - val_acc: 0.4696\n",
            "Epoch 61/150 - 0.12s - loss: 1.0354 - acc: 0.4804 - val_loss: 1.0499 - val_acc: 0.4737\n",
            "Epoch 62/150 - 0.12s - loss: 1.0348 - acc: 0.4852 - val_loss: 1.0501 - val_acc: 0.4757\n",
            "Epoch 63/150 - 0.12s - loss: 1.0341 - acc: 0.4840 - val_loss: 1.0497 - val_acc: 0.4696\n",
            "Epoch 64/150 - 0.12s - loss: 1.0334 - acc: 0.4845 - val_loss: 1.0489 - val_acc: 0.4818\n",
            "Epoch 65/150 - 0.12s - loss: 1.0327 - acc: 0.4845 - val_loss: 1.0483 - val_acc: 0.4798\n",
            "Epoch 66/150 - 0.12s - loss: 1.0321 - acc: 0.4847 - val_loss: 1.0482 - val_acc: 0.4858\n",
            "Epoch 67/150 - 0.12s - loss: 1.0314 - acc: 0.4852 - val_loss: 1.0478 - val_acc: 0.4858\n",
            "Epoch 68/150 - 0.12s - loss: 1.0309 - acc: 0.4874 - val_loss: 1.0470 - val_acc: 0.4818\n",
            "Epoch 69/150 - 0.13s - loss: 1.0301 - acc: 0.4838 - val_loss: 1.0469 - val_acc: 0.4798\n",
            "Epoch 70/150 - 0.15s - loss: 1.0294 - acc: 0.4852 - val_loss: 1.0466 - val_acc: 0.4838\n",
            "Epoch 71/150 - 0.13s - loss: 1.0288 - acc: 0.4840 - val_loss: 1.0461 - val_acc: 0.4798\n",
            "Epoch 72/150 - 0.12s - loss: 1.0281 - acc: 0.4845 - val_loss: 1.0457 - val_acc: 0.4818\n",
            "Epoch 73/150 - 0.12s - loss: 1.0275 - acc: 0.4849 - val_loss: 1.0452 - val_acc: 0.4818\n",
            "Epoch 74/150 - 0.12s - loss: 1.0268 - acc: 0.4863 - val_loss: 1.0450 - val_acc: 0.4919\n",
            "Epoch 75/150 - 0.12s - loss: 1.0262 - acc: 0.4870 - val_loss: 1.0443 - val_acc: 0.4838\n",
            "Epoch 76/150 - 0.12s - loss: 1.0255 - acc: 0.4872 - val_loss: 1.0440 - val_acc: 0.4879\n",
            "Epoch 77/150 - 0.12s - loss: 1.0249 - acc: 0.4892 - val_loss: 1.0440 - val_acc: 0.4899\n",
            "Epoch 78/150 - 0.12s - loss: 1.0242 - acc: 0.4888 - val_loss: 1.0431 - val_acc: 0.4879\n",
            "Epoch 79/150 - 0.12s - loss: 1.0236 - acc: 0.4906 - val_loss: 1.0426 - val_acc: 0.4899\n",
            "Epoch 80/150 - 0.12s - loss: 1.0230 - acc: 0.4924 - val_loss: 1.0428 - val_acc: 0.4919\n",
            "Epoch 81/150 - 0.12s - loss: 1.0223 - acc: 0.4903 - val_loss: 1.0421 - val_acc: 0.4919\n",
            "Epoch 82/150 - 0.12s - loss: 1.0216 - acc: 0.4888 - val_loss: 1.0415 - val_acc: 0.4919\n",
            "Epoch 83/150 - 0.13s - loss: 1.0210 - acc: 0.4933 - val_loss: 1.0414 - val_acc: 0.4980\n",
            "Epoch 84/150 - 0.13s - loss: 1.0204 - acc: 0.4912 - val_loss: 1.0405 - val_acc: 0.4960\n",
            "Epoch 85/150 - 0.12s - loss: 1.0197 - acc: 0.4928 - val_loss: 1.0405 - val_acc: 0.4879\n",
            "Epoch 86/150 - 0.12s - loss: 1.0190 - acc: 0.4937 - val_loss: 1.0400 - val_acc: 0.4939\n",
            "Epoch 87/150 - 0.12s - loss: 1.0184 - acc: 0.4942 - val_loss: 1.0395 - val_acc: 0.4899\n",
            "Epoch 88/150 - 0.12s - loss: 1.0178 - acc: 0.4919 - val_loss: 1.0390 - val_acc: 0.4939\n",
            "Epoch 89/150 - 0.12s - loss: 1.0171 - acc: 0.4946 - val_loss: 1.0386 - val_acc: 0.4960\n",
            "Epoch 90/150 - 0.12s - loss: 1.0164 - acc: 0.4971 - val_loss: 1.0382 - val_acc: 0.4939\n",
            "Epoch 91/150 - 0.12s - loss: 1.0158 - acc: 0.4964 - val_loss: 1.0377 - val_acc: 0.4980\n",
            "Epoch 92/150 - 0.14s - loss: 1.0151 - acc: 0.4987 - val_loss: 1.0375 - val_acc: 0.4939\n",
            "Epoch 93/150 - 0.12s - loss: 1.0145 - acc: 0.5002 - val_loss: 1.0371 - val_acc: 0.4919\n",
            "Epoch 94/150 - 0.12s - loss: 1.0139 - acc: 0.5004 - val_loss: 1.0366 - val_acc: 0.4960\n",
            "Epoch 95/150 - 0.13s - loss: 1.0134 - acc: 0.5029 - val_loss: 1.0368 - val_acc: 0.5020\n",
            "Epoch 96/150 - 0.13s - loss: 1.0126 - acc: 0.5045 - val_loss: 1.0358 - val_acc: 0.4980\n",
            "Epoch 97/150 - 0.12s - loss: 1.0120 - acc: 0.5058 - val_loss: 1.0358 - val_acc: 0.5020\n",
            "Epoch 98/150 - 0.12s - loss: 1.0112 - acc: 0.5036 - val_loss: 1.0347 - val_acc: 0.4980\n",
            "Epoch 99/150 - 0.12s - loss: 1.0106 - acc: 0.5007 - val_loss: 1.0342 - val_acc: 0.5000\n",
            "Epoch 100/150 - 0.12s - loss: 1.0100 - acc: 0.5011 - val_loss: 1.0337 - val_acc: 0.5020\n",
            "Epoch 101/150 - 0.12s - loss: 1.0093 - acc: 0.5018 - val_loss: 1.0332 - val_acc: 0.5020\n",
            "Epoch 102/150 - 0.12s - loss: 1.0086 - acc: 0.5074 - val_loss: 1.0329 - val_acc: 0.5040\n",
            "Epoch 103/150 - 0.12s - loss: 1.0080 - acc: 0.5103 - val_loss: 1.0327 - val_acc: 0.5020\n",
            "Epoch 104/150 - 0.12s - loss: 1.0073 - acc: 0.5079 - val_loss: 1.0320 - val_acc: 0.4980\n",
            "Epoch 105/150 - 0.12s - loss: 1.0067 - acc: 0.5079 - val_loss: 1.0318 - val_acc: 0.5020\n",
            "Epoch 106/150 - 0.12s - loss: 1.0060 - acc: 0.5108 - val_loss: 1.0310 - val_acc: 0.5061\n",
            "Epoch 107/150 - 0.13s - loss: 1.0053 - acc: 0.5106 - val_loss: 1.0307 - val_acc: 0.5020\n",
            "Epoch 108/150 - 0.12s - loss: 1.0047 - acc: 0.5115 - val_loss: 1.0301 - val_acc: 0.5040\n",
            "Epoch 109/150 - 0.12s - loss: 1.0040 - acc: 0.5135 - val_loss: 1.0300 - val_acc: 0.5061\n",
            "Epoch 110/150 - 0.12s - loss: 1.0034 - acc: 0.5124 - val_loss: 1.0292 - val_acc: 0.5081\n",
            "Epoch 111/150 - 0.12s - loss: 1.0026 - acc: 0.5160 - val_loss: 1.0289 - val_acc: 0.5081\n",
            "Epoch 112/150 - 0.12s - loss: 1.0020 - acc: 0.5144 - val_loss: 1.0285 - val_acc: 0.5101\n",
            "Epoch 113/150 - 0.12s - loss: 1.0014 - acc: 0.5164 - val_loss: 1.0279 - val_acc: 0.5182\n",
            "Epoch 114/150 - 0.14s - loss: 1.0008 - acc: 0.5180 - val_loss: 1.0273 - val_acc: 0.5182\n",
            "Epoch 115/150 - 0.12s - loss: 1.0000 - acc: 0.5144 - val_loss: 1.0272 - val_acc: 0.5121\n",
            "Epoch 116/150 - 0.12s - loss: 0.9993 - acc: 0.5205 - val_loss: 1.0265 - val_acc: 0.5182\n",
            "Epoch 117/150 - 0.12s - loss: 0.9986 - acc: 0.5184 - val_loss: 1.0262 - val_acc: 0.5182\n",
            "Epoch 118/150 - 0.13s - loss: 0.9980 - acc: 0.5198 - val_loss: 1.0256 - val_acc: 0.5162\n",
            "Epoch 119/150 - 0.13s - loss: 0.9977 - acc: 0.5227 - val_loss: 1.0255 - val_acc: 0.5202\n",
            "Epoch 120/150 - 0.13s - loss: 0.9966 - acc: 0.5238 - val_loss: 1.0245 - val_acc: 0.5202\n",
            "Epoch 121/150 - 0.12s - loss: 0.9960 - acc: 0.5229 - val_loss: 1.0239 - val_acc: 0.5202\n",
            "Epoch 122/150 - 0.12s - loss: 0.9953 - acc: 0.5209 - val_loss: 1.0239 - val_acc: 0.5182\n",
            "Epoch 123/150 - 0.12s - loss: 0.9947 - acc: 0.5229 - val_loss: 1.0229 - val_acc: 0.5223\n",
            "Epoch 124/150 - 0.12s - loss: 0.9940 - acc: 0.5234 - val_loss: 1.0226 - val_acc: 0.5202\n",
            "Epoch 125/150 - 0.12s - loss: 0.9933 - acc: 0.5234 - val_loss: 1.0222 - val_acc: 0.5202\n",
            "Epoch 126/150 - 0.12s - loss: 0.9926 - acc: 0.5252 - val_loss: 1.0217 - val_acc: 0.5202\n",
            "Epoch 127/150 - 0.12s - loss: 0.9920 - acc: 0.5229 - val_loss: 1.0213 - val_acc: 0.5162\n",
            "Epoch 128/150 - 0.12s - loss: 0.9913 - acc: 0.5256 - val_loss: 1.0206 - val_acc: 0.5202\n",
            "Epoch 129/150 - 0.12s - loss: 0.9906 - acc: 0.5263 - val_loss: 1.0201 - val_acc: 0.5223\n",
            "Epoch 130/150 - 0.12s - loss: 0.9900 - acc: 0.5277 - val_loss: 1.0198 - val_acc: 0.5162\n",
            "Epoch 131/150 - 0.13s - loss: 0.9893 - acc: 0.5274 - val_loss: 1.0192 - val_acc: 0.5202\n",
            "Epoch 132/150 - 0.13s - loss: 0.9886 - acc: 0.5263 - val_loss: 1.0189 - val_acc: 0.5263\n",
            "Epoch 133/150 - 0.13s - loss: 0.9881 - acc: 0.5256 - val_loss: 1.0180 - val_acc: 0.5304\n",
            "Epoch 134/150 - 0.12s - loss: 0.9873 - acc: 0.5261 - val_loss: 1.0180 - val_acc: 0.5283\n",
            "Epoch 135/150 - 0.12s - loss: 0.9867 - acc: 0.5261 - val_loss: 1.0176 - val_acc: 0.5263\n",
            "Epoch 136/150 - 0.14s - loss: 0.9860 - acc: 0.5304 - val_loss: 1.0171 - val_acc: 0.5223\n",
            "Epoch 137/150 - 0.13s - loss: 0.9854 - acc: 0.5297 - val_loss: 1.0167 - val_acc: 0.5202\n",
            "Epoch 138/150 - 0.12s - loss: 0.9847 - acc: 0.5301 - val_loss: 1.0162 - val_acc: 0.5202\n",
            "Epoch 139/150 - 0.12s - loss: 0.9840 - acc: 0.5301 - val_loss: 1.0151 - val_acc: 0.5243\n",
            "Epoch 140/150 - 0.12s - loss: 0.9837 - acc: 0.5263 - val_loss: 1.0146 - val_acc: 0.5385\n",
            "Epoch 141/150 - 0.12s - loss: 0.9827 - acc: 0.5295 - val_loss: 1.0147 - val_acc: 0.5283\n",
            "Epoch 142/150 - 0.12s - loss: 0.9821 - acc: 0.5306 - val_loss: 1.0142 - val_acc: 0.5243\n",
            "Epoch 143/150 - 0.12s - loss: 0.9817 - acc: 0.5292 - val_loss: 1.0142 - val_acc: 0.5304\n",
            "Epoch 144/150 - 0.12s - loss: 0.9808 - acc: 0.5306 - val_loss: 1.0132 - val_acc: 0.5324\n",
            "Epoch 145/150 - 0.12s - loss: 0.9800 - acc: 0.5319 - val_loss: 1.0125 - val_acc: 0.5304\n",
            "Epoch 146/150 - 0.12s - loss: 0.9794 - acc: 0.5319 - val_loss: 1.0119 - val_acc: 0.5263\n",
            "Epoch 147/150 - 0.12s - loss: 0.9788 - acc: 0.5342 - val_loss: 1.0110 - val_acc: 0.5263\n",
            "Epoch 148/150 - 0.12s - loss: 0.9783 - acc: 0.5326 - val_loss: 1.0116 - val_acc: 0.5304\n",
            "Epoch 149/150 - 0.13s - loss: 0.9774 - acc: 0.5335 - val_loss: 1.0101 - val_acc: 0.5304\n",
            "Epoch 150/150 - 0.13s - loss: 0.9768 - acc: 0.5355 - val_loss: 1.0099 - val_acc: 0.5283\n",
            "\n",
            "Combination 118/252:\n",
            "Hidden Layers: [256, 128], Activation: relu, Learning Rate: 0.001, Batch Size: 64, Epochs: 50\n",
            "Epoch 1/50 - 0.09s - loss: 1.1153 - acc: 0.2859 - val_loss: 1.1107 - val_acc: 0.2976\n",
            "Epoch 2/50 - 0.10s - loss: 1.1133 - acc: 0.2926 - val_loss: 1.1092 - val_acc: 0.3036\n",
            "Epoch 3/50 - 0.10s - loss: 1.1115 - acc: 0.2951 - val_loss: 1.1077 - val_acc: 0.3077\n",
            "Epoch 4/50 - 0.10s - loss: 1.1099 - acc: 0.2994 - val_loss: 1.1064 - val_acc: 0.3097\n",
            "Epoch 5/50 - 0.09s - loss: 1.1083 - acc: 0.3079 - val_loss: 1.1052 - val_acc: 0.3279\n",
            "Epoch 6/50 - 0.09s - loss: 1.1068 - acc: 0.3138 - val_loss: 1.1039 - val_acc: 0.3279\n",
            "Epoch 7/50 - 0.11s - loss: 1.1053 - acc: 0.3223 - val_loss: 1.1028 - val_acc: 0.3381\n",
            "Epoch 8/50 - 0.09s - loss: 1.1039 - acc: 0.3291 - val_loss: 1.1016 - val_acc: 0.3421\n",
            "Epoch 9/50 - 0.09s - loss: 1.1026 - acc: 0.3291 - val_loss: 1.1005 - val_acc: 0.3381\n",
            "Epoch 10/50 - 0.15s - loss: 1.1013 - acc: 0.3273 - val_loss: 1.0994 - val_acc: 0.3360\n",
            "Epoch 11/50 - 0.14s - loss: 1.1000 - acc: 0.3306 - val_loss: 1.0984 - val_acc: 0.3360\n",
            "Epoch 12/50 - 0.11s - loss: 1.0988 - acc: 0.3358 - val_loss: 1.0974 - val_acc: 0.3360\n",
            "Epoch 13/50 - 0.10s - loss: 1.0976 - acc: 0.3374 - val_loss: 1.0965 - val_acc: 0.3462\n",
            "Epoch 14/50 - 0.09s - loss: 1.0964 - acc: 0.3408 - val_loss: 1.0956 - val_acc: 0.3441\n",
            "Epoch 15/50 - 0.15s - loss: 1.0953 - acc: 0.3448 - val_loss: 1.0947 - val_acc: 0.3482\n",
            "Epoch 16/50 - 0.09s - loss: 1.0942 - acc: 0.3516 - val_loss: 1.0938 - val_acc: 0.3502\n",
            "Epoch 17/50 - 0.10s - loss: 1.0931 - acc: 0.3543 - val_loss: 1.0930 - val_acc: 0.3563\n",
            "Epoch 18/50 - 0.10s - loss: 1.0921 - acc: 0.3585 - val_loss: 1.0922 - val_acc: 0.3644\n",
            "Epoch 19/50 - 0.09s - loss: 1.0910 - acc: 0.3608 - val_loss: 1.0914 - val_acc: 0.3603\n",
            "Epoch 20/50 - 0.10s - loss: 1.0900 - acc: 0.3671 - val_loss: 1.0905 - val_acc: 0.3644\n",
            "Epoch 21/50 - 0.10s - loss: 1.0891 - acc: 0.3700 - val_loss: 1.0898 - val_acc: 0.3684\n",
            "Epoch 22/50 - 0.11s - loss: 1.0881 - acc: 0.3736 - val_loss: 1.0890 - val_acc: 0.3704\n",
            "Epoch 23/50 - 0.09s - loss: 1.0872 - acc: 0.3774 - val_loss: 1.0883 - val_acc: 0.3785\n",
            "Epoch 24/50 - 0.10s - loss: 1.0862 - acc: 0.3839 - val_loss: 1.0875 - val_acc: 0.3725\n",
            "Epoch 25/50 - 0.09s - loss: 1.0853 - acc: 0.3853 - val_loss: 1.0868 - val_acc: 0.3725\n",
            "Epoch 26/50 - 0.09s - loss: 1.0844 - acc: 0.3891 - val_loss: 1.0861 - val_acc: 0.3725\n",
            "Epoch 27/50 - 0.10s - loss: 1.0835 - acc: 0.3918 - val_loss: 1.0854 - val_acc: 0.3785\n",
            "Epoch 28/50 - 0.09s - loss: 1.0827 - acc: 0.3947 - val_loss: 1.0848 - val_acc: 0.3826\n",
            "Epoch 29/50 - 0.09s - loss: 1.0819 - acc: 0.3968 - val_loss: 1.0841 - val_acc: 0.3907\n",
            "Epoch 30/50 - 0.09s - loss: 1.0810 - acc: 0.4008 - val_loss: 1.0835 - val_acc: 0.3947\n",
            "Epoch 31/50 - 0.09s - loss: 1.0802 - acc: 0.4051 - val_loss: 1.0829 - val_acc: 0.3968\n",
            "Epoch 32/50 - 0.09s - loss: 1.0794 - acc: 0.4069 - val_loss: 1.0822 - val_acc: 0.4008\n",
            "Epoch 33/50 - 0.10s - loss: 1.0787 - acc: 0.4112 - val_loss: 1.0816 - val_acc: 0.4028\n",
            "Epoch 34/50 - 0.09s - loss: 1.0779 - acc: 0.4125 - val_loss: 1.0810 - val_acc: 0.4069\n",
            "Epoch 35/50 - 0.09s - loss: 1.0771 - acc: 0.4170 - val_loss: 1.0804 - val_acc: 0.4130\n",
            "Epoch 36/50 - 0.09s - loss: 1.0764 - acc: 0.4226 - val_loss: 1.0798 - val_acc: 0.4130\n",
            "Epoch 37/50 - 0.09s - loss: 1.0757 - acc: 0.4249 - val_loss: 1.0793 - val_acc: 0.4251\n",
            "Epoch 38/50 - 0.09s - loss: 1.0750 - acc: 0.4278 - val_loss: 1.0787 - val_acc: 0.4231\n",
            "Epoch 39/50 - 0.09s - loss: 1.0743 - acc: 0.4294 - val_loss: 1.0781 - val_acc: 0.4312\n",
            "Epoch 40/50 - 0.09s - loss: 1.0736 - acc: 0.4296 - val_loss: 1.0776 - val_acc: 0.4312\n",
            "Epoch 41/50 - 0.10s - loss: 1.0729 - acc: 0.4314 - val_loss: 1.0771 - val_acc: 0.4291\n",
            "Epoch 42/50 - 0.16s - loss: 1.0723 - acc: 0.4332 - val_loss: 1.0766 - val_acc: 0.4271\n",
            "Epoch 43/50 - 0.10s - loss: 1.0716 - acc: 0.4348 - val_loss: 1.0761 - val_acc: 0.4271\n",
            "Epoch 44/50 - 0.09s - loss: 1.0710 - acc: 0.4377 - val_loss: 1.0756 - val_acc: 0.4332\n",
            "Epoch 45/50 - 0.09s - loss: 1.0704 - acc: 0.4379 - val_loss: 1.0752 - val_acc: 0.4352\n",
            "Epoch 46/50 - 0.09s - loss: 1.0697 - acc: 0.4388 - val_loss: 1.0747 - val_acc: 0.4332\n",
            "Epoch 47/50 - 0.09s - loss: 1.0691 - acc: 0.4399 - val_loss: 1.0743 - val_acc: 0.4352\n",
            "Epoch 48/50 - 0.10s - loss: 1.0685 - acc: 0.4424 - val_loss: 1.0738 - val_acc: 0.4352\n",
            "Epoch 49/50 - 0.10s - loss: 1.0679 - acc: 0.4435 - val_loss: 1.0734 - val_acc: 0.4393\n",
            "Epoch 50/50 - 0.10s - loss: 1.0673 - acc: 0.4451 - val_loss: 1.0729 - val_acc: 0.4433\n",
            "\n",
            "Combination 119/252:\n",
            "Hidden Layers: [256, 128], Activation: relu, Learning Rate: 0.001, Batch Size: 64, Epochs: 100\n",
            "Epoch 1/100 - 0.12s - loss: 1.1009 - acc: 0.3309 - val_loss: 1.1018 - val_acc: 0.3219\n",
            "Epoch 2/100 - 0.10s - loss: 1.0981 - acc: 0.3342 - val_loss: 1.0988 - val_acc: 0.3198\n",
            "Epoch 3/100 - 0.09s - loss: 1.0962 - acc: 0.3365 - val_loss: 1.0969 - val_acc: 0.3259\n",
            "Epoch 4/100 - 0.09s - loss: 1.0947 - acc: 0.3450 - val_loss: 1.0954 - val_acc: 0.3360\n",
            "Epoch 5/100 - 0.09s - loss: 1.0933 - acc: 0.3534 - val_loss: 1.0942 - val_acc: 0.3502\n",
            "Epoch 6/100 - 0.10s - loss: 1.0920 - acc: 0.3662 - val_loss: 1.0932 - val_acc: 0.3664\n",
            "Epoch 7/100 - 0.11s - loss: 1.0908 - acc: 0.3720 - val_loss: 1.0923 - val_acc: 0.3785\n",
            "Epoch 8/100 - 0.10s - loss: 1.0896 - acc: 0.3772 - val_loss: 1.0915 - val_acc: 0.3806\n",
            "Epoch 9/100 - 0.10s - loss: 1.0885 - acc: 0.3833 - val_loss: 1.0908 - val_acc: 0.3745\n",
            "Epoch 10/100 - 0.11s - loss: 1.0874 - acc: 0.3907 - val_loss: 1.0900 - val_acc: 0.3765\n",
            "Epoch 11/100 - 0.09s - loss: 1.0863 - acc: 0.3938 - val_loss: 1.0893 - val_acc: 0.3907\n",
            "Epoch 12/100 - 0.10s - loss: 1.0853 - acc: 0.3977 - val_loss: 1.0886 - val_acc: 0.3968\n",
            "Epoch 13/100 - 0.10s - loss: 1.0844 - acc: 0.4017 - val_loss: 1.0880 - val_acc: 0.3988\n",
            "Epoch 14/100 - 0.09s - loss: 1.0834 - acc: 0.4053 - val_loss: 1.0874 - val_acc: 0.4008\n",
            "Epoch 15/100 - 0.10s - loss: 1.0825 - acc: 0.4064 - val_loss: 1.0868 - val_acc: 0.4008\n",
            "Epoch 16/100 - 0.10s - loss: 1.0816 - acc: 0.4141 - val_loss: 1.0862 - val_acc: 0.4109\n",
            "Epoch 17/100 - 0.09s - loss: 1.0807 - acc: 0.4172 - val_loss: 1.0856 - val_acc: 0.4049\n",
            "Epoch 18/100 - 0.10s - loss: 1.0798 - acc: 0.4184 - val_loss: 1.0851 - val_acc: 0.4049\n",
            "Epoch 19/100 - 0.15s - loss: 1.0790 - acc: 0.4222 - val_loss: 1.0845 - val_acc: 0.4089\n",
            "Epoch 20/100 - 0.12s - loss: 1.0782 - acc: 0.4269 - val_loss: 1.0839 - val_acc: 0.4170\n",
            "Epoch 21/100 - 0.11s - loss: 1.0774 - acc: 0.4283 - val_loss: 1.0833 - val_acc: 0.4190\n",
            "Epoch 22/100 - 0.11s - loss: 1.0766 - acc: 0.4314 - val_loss: 1.0828 - val_acc: 0.4150\n",
            "Epoch 23/100 - 0.10s - loss: 1.0759 - acc: 0.4307 - val_loss: 1.0823 - val_acc: 0.4170\n",
            "Epoch 24/100 - 0.14s - loss: 1.0751 - acc: 0.4330 - val_loss: 1.0819 - val_acc: 0.4231\n",
            "Epoch 25/100 - 0.09s - loss: 1.0744 - acc: 0.4343 - val_loss: 1.0813 - val_acc: 0.4170\n",
            "Epoch 26/100 - 0.10s - loss: 1.0737 - acc: 0.4330 - val_loss: 1.0809 - val_acc: 0.4130\n",
            "Epoch 27/100 - 0.09s - loss: 1.0730 - acc: 0.4336 - val_loss: 1.0804 - val_acc: 0.4170\n",
            "Epoch 28/100 - 0.09s - loss: 1.0723 - acc: 0.4354 - val_loss: 1.0799 - val_acc: 0.4190\n",
            "Epoch 29/100 - 0.09s - loss: 1.0717 - acc: 0.4368 - val_loss: 1.0796 - val_acc: 0.4231\n",
            "Epoch 30/100 - 0.09s - loss: 1.0710 - acc: 0.4386 - val_loss: 1.0791 - val_acc: 0.4170\n",
            "Epoch 31/100 - 0.10s - loss: 1.0703 - acc: 0.4417 - val_loss: 1.0788 - val_acc: 0.4231\n",
            "Epoch 32/100 - 0.09s - loss: 1.0697 - acc: 0.4406 - val_loss: 1.0785 - val_acc: 0.4251\n",
            "Epoch 33/100 - 0.09s - loss: 1.0691 - acc: 0.4413 - val_loss: 1.0781 - val_acc: 0.4211\n",
            "Epoch 34/100 - 0.10s - loss: 1.0685 - acc: 0.4429 - val_loss: 1.0777 - val_acc: 0.4231\n",
            "Epoch 35/100 - 0.09s - loss: 1.0679 - acc: 0.4435 - val_loss: 1.0773 - val_acc: 0.4251\n",
            "Epoch 36/100 - 0.09s - loss: 1.0673 - acc: 0.4426 - val_loss: 1.0769 - val_acc: 0.4211\n",
            "Epoch 37/100 - 0.10s - loss: 1.0667 - acc: 0.4453 - val_loss: 1.0765 - val_acc: 0.4231\n",
            "Epoch 38/100 - 0.09s - loss: 1.0661 - acc: 0.4458 - val_loss: 1.0762 - val_acc: 0.4211\n",
            "Epoch 39/100 - 0.09s - loss: 1.0655 - acc: 0.4478 - val_loss: 1.0758 - val_acc: 0.4190\n",
            "Epoch 40/100 - 0.10s - loss: 1.0649 - acc: 0.4523 - val_loss: 1.0754 - val_acc: 0.4231\n",
            "Epoch 41/100 - 0.10s - loss: 1.0643 - acc: 0.4510 - val_loss: 1.0750 - val_acc: 0.4312\n",
            "Epoch 42/100 - 0.10s - loss: 1.0638 - acc: 0.4510 - val_loss: 1.0746 - val_acc: 0.4312\n",
            "Epoch 43/100 - 0.10s - loss: 1.0632 - acc: 0.4543 - val_loss: 1.0744 - val_acc: 0.4312\n",
            "Epoch 44/100 - 0.09s - loss: 1.0627 - acc: 0.4541 - val_loss: 1.0741 - val_acc: 0.4332\n",
            "Epoch 45/100 - 0.09s - loss: 1.0621 - acc: 0.4559 - val_loss: 1.0737 - val_acc: 0.4332\n",
            "Epoch 46/100 - 0.09s - loss: 1.0616 - acc: 0.4559 - val_loss: 1.0734 - val_acc: 0.4291\n",
            "Epoch 47/100 - 0.10s - loss: 1.0610 - acc: 0.4579 - val_loss: 1.0731 - val_acc: 0.4312\n",
            "Epoch 48/100 - 0.09s - loss: 1.0605 - acc: 0.4570 - val_loss: 1.0727 - val_acc: 0.4291\n",
            "Epoch 49/100 - 0.11s - loss: 1.0600 - acc: 0.4584 - val_loss: 1.0724 - val_acc: 0.4352\n",
            "Epoch 50/100 - 0.09s - loss: 1.0594 - acc: 0.4593 - val_loss: 1.0721 - val_acc: 0.4352\n",
            "Epoch 51/100 - 0.09s - loss: 1.0589 - acc: 0.4602 - val_loss: 1.0718 - val_acc: 0.4332\n",
            "Epoch 52/100 - 0.10s - loss: 1.0584 - acc: 0.4597 - val_loss: 1.0715 - val_acc: 0.4332\n",
            "Epoch 53/100 - 0.09s - loss: 1.0579 - acc: 0.4620 - val_loss: 1.0712 - val_acc: 0.4393\n",
            "Epoch 54/100 - 0.09s - loss: 1.0574 - acc: 0.4624 - val_loss: 1.0709 - val_acc: 0.4332\n",
            "Epoch 55/100 - 0.20s - loss: 1.0569 - acc: 0.4627 - val_loss: 1.0706 - val_acc: 0.4393\n",
            "Epoch 56/100 - 0.11s - loss: 1.0564 - acc: 0.4622 - val_loss: 1.0703 - val_acc: 0.4393\n",
            "Epoch 57/100 - 0.10s - loss: 1.0559 - acc: 0.4611 - val_loss: 1.0700 - val_acc: 0.4413\n",
            "Epoch 58/100 - 0.10s - loss: 1.0554 - acc: 0.4615 - val_loss: 1.0697 - val_acc: 0.4352\n",
            "Epoch 59/100 - 0.10s - loss: 1.0549 - acc: 0.4613 - val_loss: 1.0695 - val_acc: 0.4332\n",
            "Epoch 60/100 - 0.10s - loss: 1.0544 - acc: 0.4631 - val_loss: 1.0692 - val_acc: 0.4332\n",
            "Epoch 61/100 - 0.11s - loss: 1.0540 - acc: 0.4629 - val_loss: 1.0689 - val_acc: 0.4372\n",
            "Epoch 62/100 - 0.09s - loss: 1.0535 - acc: 0.4651 - val_loss: 1.0686 - val_acc: 0.4372\n",
            "Epoch 63/100 - 0.09s - loss: 1.0530 - acc: 0.4665 - val_loss: 1.0683 - val_acc: 0.4393\n",
            "Epoch 64/100 - 0.10s - loss: 1.0525 - acc: 0.4651 - val_loss: 1.0681 - val_acc: 0.4393\n",
            "Epoch 65/100 - 0.11s - loss: 1.0521 - acc: 0.4651 - val_loss: 1.0678 - val_acc: 0.4393\n",
            "Epoch 66/100 - 0.10s - loss: 1.0516 - acc: 0.4665 - val_loss: 1.0674 - val_acc: 0.4332\n",
            "Epoch 67/100 - 0.10s - loss: 1.0512 - acc: 0.4674 - val_loss: 1.0671 - val_acc: 0.4352\n",
            "Epoch 68/100 - 0.10s - loss: 1.0507 - acc: 0.4663 - val_loss: 1.0669 - val_acc: 0.4372\n",
            "Epoch 69/100 - 0.10s - loss: 1.0502 - acc: 0.4656 - val_loss: 1.0666 - val_acc: 0.4352\n",
            "Epoch 70/100 - 0.09s - loss: 1.0498 - acc: 0.4669 - val_loss: 1.0664 - val_acc: 0.4352\n",
            "Epoch 71/100 - 0.09s - loss: 1.0493 - acc: 0.4665 - val_loss: 1.0662 - val_acc: 0.4372\n",
            "Epoch 72/100 - 0.09s - loss: 1.0489 - acc: 0.4681 - val_loss: 1.0659 - val_acc: 0.4312\n",
            "Epoch 73/100 - 0.09s - loss: 1.0484 - acc: 0.4681 - val_loss: 1.0656 - val_acc: 0.4352\n",
            "Epoch 74/100 - 0.09s - loss: 1.0480 - acc: 0.4678 - val_loss: 1.0654 - val_acc: 0.4352\n",
            "Epoch 75/100 - 0.10s - loss: 1.0475 - acc: 0.4685 - val_loss: 1.0651 - val_acc: 0.4332\n",
            "Epoch 76/100 - 0.10s - loss: 1.0471 - acc: 0.4694 - val_loss: 1.0649 - val_acc: 0.4352\n",
            "Epoch 77/100 - 0.10s - loss: 1.0466 - acc: 0.4717 - val_loss: 1.0646 - val_acc: 0.4352\n",
            "Epoch 78/100 - 0.11s - loss: 1.0462 - acc: 0.4723 - val_loss: 1.0644 - val_acc: 0.4352\n",
            "Epoch 79/100 - 0.09s - loss: 1.0458 - acc: 0.4728 - val_loss: 1.0641 - val_acc: 0.4393\n",
            "Epoch 80/100 - 0.09s - loss: 1.0453 - acc: 0.4728 - val_loss: 1.0639 - val_acc: 0.4393\n",
            "Epoch 81/100 - 0.11s - loss: 1.0449 - acc: 0.4732 - val_loss: 1.0637 - val_acc: 0.4393\n",
            "Epoch 82/100 - 0.11s - loss: 1.0444 - acc: 0.4741 - val_loss: 1.0634 - val_acc: 0.4413\n",
            "Epoch 83/100 - 0.10s - loss: 1.0440 - acc: 0.4748 - val_loss: 1.0632 - val_acc: 0.4413\n",
            "Epoch 84/100 - 0.12s - loss: 1.0436 - acc: 0.4744 - val_loss: 1.0628 - val_acc: 0.4413\n",
            "Epoch 85/100 - 0.12s - loss: 1.0431 - acc: 0.4755 - val_loss: 1.0626 - val_acc: 0.4413\n",
            "Epoch 86/100 - 0.14s - loss: 1.0427 - acc: 0.4753 - val_loss: 1.0625 - val_acc: 0.4453\n",
            "Epoch 87/100 - 0.09s - loss: 1.0423 - acc: 0.4755 - val_loss: 1.0622 - val_acc: 0.4413\n",
            "Epoch 88/100 - 0.10s - loss: 1.0418 - acc: 0.4757 - val_loss: 1.0620 - val_acc: 0.4453\n",
            "Epoch 89/100 - 0.09s - loss: 1.0414 - acc: 0.4764 - val_loss: 1.0618 - val_acc: 0.4433\n",
            "Epoch 90/100 - 0.09s - loss: 1.0410 - acc: 0.4773 - val_loss: 1.0615 - val_acc: 0.4433\n",
            "Epoch 91/100 - 0.09s - loss: 1.0405 - acc: 0.4780 - val_loss: 1.0612 - val_acc: 0.4433\n",
            "Epoch 92/100 - 0.09s - loss: 1.0401 - acc: 0.4784 - val_loss: 1.0609 - val_acc: 0.4413\n",
            "Epoch 93/100 - 0.11s - loss: 1.0397 - acc: 0.4780 - val_loss: 1.0607 - val_acc: 0.4453\n",
            "Epoch 94/100 - 0.10s - loss: 1.0392 - acc: 0.4782 - val_loss: 1.0605 - val_acc: 0.4413\n",
            "Epoch 95/100 - 0.10s - loss: 1.0388 - acc: 0.4786 - val_loss: 1.0603 - val_acc: 0.4453\n",
            "Epoch 96/100 - 0.13s - loss: 1.0384 - acc: 0.4798 - val_loss: 1.0601 - val_acc: 0.4474\n",
            "Epoch 97/100 - 0.10s - loss: 1.0380 - acc: 0.4798 - val_loss: 1.0599 - val_acc: 0.4453\n",
            "Epoch 98/100 - 0.10s - loss: 1.0376 - acc: 0.4804 - val_loss: 1.0595 - val_acc: 0.4433\n",
            "Epoch 99/100 - 0.10s - loss: 1.0371 - acc: 0.4811 - val_loss: 1.0594 - val_acc: 0.4453\n",
            "Epoch 100/100 - 0.10s - loss: 1.0367 - acc: 0.4831 - val_loss: 1.0592 - val_acc: 0.4494\n",
            "\n",
            "Combination 120/252:\n",
            "Hidden Layers: [256, 128], Activation: relu, Learning Rate: 0.001, Batch Size: 64, Epochs: 150\n",
            "Epoch 1/150 - 0.10s - loss: 1.1178 - acc: 0.2994 - val_loss: 1.1141 - val_acc: 0.3158\n",
            "Epoch 2/150 - 0.10s - loss: 1.1099 - acc: 0.3009 - val_loss: 1.1072 - val_acc: 0.3259\n",
            "Epoch 3/150 - 0.09s - loss: 1.1055 - acc: 0.3115 - val_loss: 1.1034 - val_acc: 0.3198\n",
            "Epoch 4/150 - 0.09s - loss: 1.1026 - acc: 0.3304 - val_loss: 1.1010 - val_acc: 0.3441\n",
            "Epoch 5/150 - 0.09s - loss: 1.1004 - acc: 0.3410 - val_loss: 1.0993 - val_acc: 0.3583\n",
            "Epoch 6/150 - 0.09s - loss: 1.0987 - acc: 0.3534 - val_loss: 1.0980 - val_acc: 0.3583\n",
            "Epoch 7/150 - 0.09s - loss: 1.0973 - acc: 0.3605 - val_loss: 1.0969 - val_acc: 0.3644\n",
            "Epoch 8/150 - 0.10s - loss: 1.0960 - acc: 0.3603 - val_loss: 1.0958 - val_acc: 0.3623\n",
            "Epoch 9/150 - 0.09s - loss: 1.0948 - acc: 0.3666 - val_loss: 1.0949 - val_acc: 0.3725\n",
            "Epoch 10/150 - 0.11s - loss: 1.0937 - acc: 0.3745 - val_loss: 1.0939 - val_acc: 0.3684\n",
            "Epoch 11/150 - 0.11s - loss: 1.0926 - acc: 0.3817 - val_loss: 1.0931 - val_acc: 0.3826\n",
            "Epoch 12/150 - 0.10s - loss: 1.0916 - acc: 0.3851 - val_loss: 1.0922 - val_acc: 0.3785\n",
            "Epoch 13/150 - 0.10s - loss: 1.0906 - acc: 0.3902 - val_loss: 1.0913 - val_acc: 0.3745\n",
            "Epoch 14/150 - 0.09s - loss: 1.0896 - acc: 0.3923 - val_loss: 1.0905 - val_acc: 0.3765\n",
            "Epoch 15/150 - 0.13s - loss: 1.0886 - acc: 0.3965 - val_loss: 1.0898 - val_acc: 0.3866\n",
            "Epoch 16/150 - 0.09s - loss: 1.0877 - acc: 0.4013 - val_loss: 1.0890 - val_acc: 0.3887\n",
            "Epoch 17/150 - 0.09s - loss: 1.0868 - acc: 0.4035 - val_loss: 1.0883 - val_acc: 0.3927\n",
            "Epoch 18/150 - 0.10s - loss: 1.0859 - acc: 0.4062 - val_loss: 1.0876 - val_acc: 0.3947\n",
            "Epoch 19/150 - 0.09s - loss: 1.0851 - acc: 0.4080 - val_loss: 1.0869 - val_acc: 0.3988\n",
            "Epoch 20/150 - 0.10s - loss: 1.0843 - acc: 0.4114 - val_loss: 1.0862 - val_acc: 0.4028\n",
            "Epoch 21/150 - 0.10s - loss: 1.0834 - acc: 0.4139 - val_loss: 1.0855 - val_acc: 0.4089\n",
            "Epoch 22/150 - 0.09s - loss: 1.0826 - acc: 0.4161 - val_loss: 1.0849 - val_acc: 0.4150\n",
            "Epoch 23/150 - 0.09s - loss: 1.0819 - acc: 0.4179 - val_loss: 1.0843 - val_acc: 0.4170\n",
            "Epoch 24/150 - 0.10s - loss: 1.0811 - acc: 0.4206 - val_loss: 1.0837 - val_acc: 0.4271\n",
            "Epoch 25/150 - 0.09s - loss: 1.0804 - acc: 0.4217 - val_loss: 1.0832 - val_acc: 0.4251\n",
            "Epoch 26/150 - 0.09s - loss: 1.0796 - acc: 0.4233 - val_loss: 1.0826 - val_acc: 0.4291\n",
            "Epoch 27/150 - 0.11s - loss: 1.0789 - acc: 0.4267 - val_loss: 1.0820 - val_acc: 0.4291\n",
            "Epoch 28/150 - 0.09s - loss: 1.0782 - acc: 0.4291 - val_loss: 1.0815 - val_acc: 0.4291\n",
            "Epoch 29/150 - 0.10s - loss: 1.0775 - acc: 0.4309 - val_loss: 1.0810 - val_acc: 0.4291\n",
            "Epoch 30/150 - 0.09s - loss: 1.0769 - acc: 0.4354 - val_loss: 1.0805 - val_acc: 0.4413\n",
            "Epoch 31/150 - 0.09s - loss: 1.0762 - acc: 0.4370 - val_loss: 1.0800 - val_acc: 0.4393\n",
            "Epoch 32/150 - 0.09s - loss: 1.0755 - acc: 0.4395 - val_loss: 1.0795 - val_acc: 0.4413\n",
            "Epoch 33/150 - 0.11s - loss: 1.0749 - acc: 0.4384 - val_loss: 1.0789 - val_acc: 0.4433\n",
            "Epoch 34/150 - 0.10s - loss: 1.0743 - acc: 0.4413 - val_loss: 1.0784 - val_acc: 0.4433\n",
            "Epoch 35/150 - 0.10s - loss: 1.0737 - acc: 0.4413 - val_loss: 1.0780 - val_acc: 0.4453\n",
            "Epoch 36/150 - 0.10s - loss: 1.0730 - acc: 0.4449 - val_loss: 1.0775 - val_acc: 0.4514\n",
            "Epoch 37/150 - 0.09s - loss: 1.0724 - acc: 0.4456 - val_loss: 1.0770 - val_acc: 0.4555\n",
            "Epoch 38/150 - 0.09s - loss: 1.0718 - acc: 0.4449 - val_loss: 1.0766 - val_acc: 0.4534\n",
            "Epoch 39/150 - 0.10s - loss: 1.0712 - acc: 0.4456 - val_loss: 1.0761 - val_acc: 0.4555\n",
            "Epoch 40/150 - 0.09s - loss: 1.0706 - acc: 0.4483 - val_loss: 1.0756 - val_acc: 0.4615\n",
            "Epoch 41/150 - 0.09s - loss: 1.0700 - acc: 0.4516 - val_loss: 1.0752 - val_acc: 0.4656\n",
            "Epoch 42/150 - 0.09s - loss: 1.0695 - acc: 0.4519 - val_loss: 1.0748 - val_acc: 0.4615\n",
            "Epoch 43/150 - 0.11s - loss: 1.0689 - acc: 0.4505 - val_loss: 1.0744 - val_acc: 0.4636\n",
            "Epoch 44/150 - 0.12s - loss: 1.0683 - acc: 0.4510 - val_loss: 1.0740 - val_acc: 0.4636\n",
            "Epoch 45/150 - 0.14s - loss: 1.0677 - acc: 0.4534 - val_loss: 1.0736 - val_acc: 0.4717\n",
            "Epoch 46/150 - 0.12s - loss: 1.0672 - acc: 0.4561 - val_loss: 1.0731 - val_acc: 0.4737\n",
            "Epoch 47/150 - 0.12s - loss: 1.0666 - acc: 0.4568 - val_loss: 1.0727 - val_acc: 0.4757\n",
            "Epoch 48/150 - 0.09s - loss: 1.0661 - acc: 0.4584 - val_loss: 1.0723 - val_acc: 0.4717\n",
            "Epoch 49/150 - 0.10s - loss: 1.0655 - acc: 0.4597 - val_loss: 1.0719 - val_acc: 0.4737\n",
            "Epoch 50/150 - 0.09s - loss: 1.0650 - acc: 0.4615 - val_loss: 1.0715 - val_acc: 0.4696\n",
            "Epoch 51/150 - 0.11s - loss: 1.0644 - acc: 0.4618 - val_loss: 1.0711 - val_acc: 0.4717\n",
            "Epoch 52/150 - 0.10s - loss: 1.0639 - acc: 0.4633 - val_loss: 1.0707 - val_acc: 0.4717\n",
            "Epoch 53/150 - 0.10s - loss: 1.0634 - acc: 0.4656 - val_loss: 1.0703 - val_acc: 0.4656\n",
            "Epoch 54/150 - 0.11s - loss: 1.0629 - acc: 0.4665 - val_loss: 1.0699 - val_acc: 0.4757\n",
            "Epoch 55/150 - 0.09s - loss: 1.0623 - acc: 0.4676 - val_loss: 1.0696 - val_acc: 0.4737\n",
            "Epoch 56/150 - 0.11s - loss: 1.0618 - acc: 0.4649 - val_loss: 1.0692 - val_acc: 0.4737\n",
            "Epoch 57/150 - 0.11s - loss: 1.0613 - acc: 0.4678 - val_loss: 1.0688 - val_acc: 0.4798\n",
            "Epoch 58/150 - 0.10s - loss: 1.0608 - acc: 0.4687 - val_loss: 1.0685 - val_acc: 0.4858\n",
            "Epoch 59/150 - 0.10s - loss: 1.0603 - acc: 0.4696 - val_loss: 1.0681 - val_acc: 0.4879\n",
            "Epoch 60/150 - 0.11s - loss: 1.0598 - acc: 0.4678 - val_loss: 1.0678 - val_acc: 0.4798\n",
            "Epoch 61/150 - 0.09s - loss: 1.0593 - acc: 0.4701 - val_loss: 1.0674 - val_acc: 0.4879\n",
            "Epoch 62/150 - 0.09s - loss: 1.0588 - acc: 0.4712 - val_loss: 1.0670 - val_acc: 0.4899\n",
            "Epoch 63/150 - 0.11s - loss: 1.0583 - acc: 0.4708 - val_loss: 1.0666 - val_acc: 0.4899\n",
            "Epoch 64/150 - 0.09s - loss: 1.0578 - acc: 0.4710 - val_loss: 1.0663 - val_acc: 0.4899\n",
            "Epoch 65/150 - 0.09s - loss: 1.0573 - acc: 0.4712 - val_loss: 1.0660 - val_acc: 0.4899\n",
            "Epoch 66/150 - 0.09s - loss: 1.0568 - acc: 0.4714 - val_loss: 1.0656 - val_acc: 0.4919\n",
            "Epoch 67/150 - 0.09s - loss: 1.0563 - acc: 0.4728 - val_loss: 1.0652 - val_acc: 0.4919\n",
            "Epoch 68/150 - 0.09s - loss: 1.0559 - acc: 0.4728 - val_loss: 1.0649 - val_acc: 0.4919\n",
            "Epoch 69/150 - 0.11s - loss: 1.0554 - acc: 0.4721 - val_loss: 1.0646 - val_acc: 0.4919\n",
            "Epoch 70/150 - 0.10s - loss: 1.0549 - acc: 0.4744 - val_loss: 1.0643 - val_acc: 0.4899\n",
            "Epoch 71/150 - 0.09s - loss: 1.0544 - acc: 0.4739 - val_loss: 1.0640 - val_acc: 0.4858\n",
            "Epoch 72/150 - 0.09s - loss: 1.0539 - acc: 0.4739 - val_loss: 1.0637 - val_acc: 0.4919\n",
            "Epoch 73/150 - 0.09s - loss: 1.0535 - acc: 0.4757 - val_loss: 1.0633 - val_acc: 0.4879\n",
            "Epoch 74/150 - 0.09s - loss: 1.0530 - acc: 0.4737 - val_loss: 1.0630 - val_acc: 0.4858\n",
            "Epoch 75/150 - 0.09s - loss: 1.0525 - acc: 0.4741 - val_loss: 1.0626 - val_acc: 0.4879\n",
            "Epoch 76/150 - 0.10s - loss: 1.0520 - acc: 0.4739 - val_loss: 1.0623 - val_acc: 0.4838\n",
            "Epoch 77/150 - 0.13s - loss: 1.0516 - acc: 0.4750 - val_loss: 1.0620 - val_acc: 0.4858\n",
            "Epoch 78/150 - 0.12s - loss: 1.0511 - acc: 0.4777 - val_loss: 1.0617 - val_acc: 0.4879\n",
            "Epoch 79/150 - 0.12s - loss: 1.0506 - acc: 0.4789 - val_loss: 1.0613 - val_acc: 0.4798\n",
            "Epoch 80/150 - 0.10s - loss: 1.0502 - acc: 0.4789 - val_loss: 1.0610 - val_acc: 0.4838\n",
            "Epoch 81/150 - 0.10s - loss: 1.0497 - acc: 0.4766 - val_loss: 1.0607 - val_acc: 0.4838\n",
            "Epoch 82/150 - 0.11s - loss: 1.0492 - acc: 0.4773 - val_loss: 1.0604 - val_acc: 0.4858\n",
            "Epoch 83/150 - 0.10s - loss: 1.0488 - acc: 0.4795 - val_loss: 1.0601 - val_acc: 0.4838\n",
            "Epoch 84/150 - 0.09s - loss: 1.0483 - acc: 0.4802 - val_loss: 1.0598 - val_acc: 0.4838\n",
            "Epoch 85/150 - 0.10s - loss: 1.0479 - acc: 0.4798 - val_loss: 1.0595 - val_acc: 0.4838\n",
            "Epoch 86/150 - 0.09s - loss: 1.0474 - acc: 0.4811 - val_loss: 1.0592 - val_acc: 0.4838\n",
            "Epoch 87/150 - 0.09s - loss: 1.0469 - acc: 0.4811 - val_loss: 1.0589 - val_acc: 0.4838\n",
            "Epoch 88/150 - 0.10s - loss: 1.0465 - acc: 0.4813 - val_loss: 1.0586 - val_acc: 0.4838\n",
            "Epoch 89/150 - 0.09s - loss: 1.0460 - acc: 0.4818 - val_loss: 1.0583 - val_acc: 0.4838\n",
            "Epoch 90/150 - 0.09s - loss: 1.0456 - acc: 0.4836 - val_loss: 1.0580 - val_acc: 0.4858\n",
            "Epoch 91/150 - 0.09s - loss: 1.0451 - acc: 0.4847 - val_loss: 1.0577 - val_acc: 0.4879\n",
            "Epoch 92/150 - 0.09s - loss: 1.0447 - acc: 0.4845 - val_loss: 1.0574 - val_acc: 0.4879\n",
            "Epoch 93/150 - 0.09s - loss: 1.0442 - acc: 0.4836 - val_loss: 1.0571 - val_acc: 0.4858\n",
            "Epoch 94/150 - 0.10s - loss: 1.0438 - acc: 0.4840 - val_loss: 1.0568 - val_acc: 0.4879\n",
            "Epoch 95/150 - 0.09s - loss: 1.0433 - acc: 0.4847 - val_loss: 1.0565 - val_acc: 0.4879\n",
            "Epoch 96/150 - 0.09s - loss: 1.0429 - acc: 0.4849 - val_loss: 1.0562 - val_acc: 0.4879\n",
            "Epoch 97/150 - 0.10s - loss: 1.0425 - acc: 0.4870 - val_loss: 1.0560 - val_acc: 0.4858\n",
            "Epoch 98/150 - 0.09s - loss: 1.0420 - acc: 0.4876 - val_loss: 1.0557 - val_acc: 0.4879\n",
            "Epoch 99/150 - 0.10s - loss: 1.0416 - acc: 0.4883 - val_loss: 1.0554 - val_acc: 0.4879\n",
            "Epoch 100/150 - 0.11s - loss: 1.0412 - acc: 0.4879 - val_loss: 1.0551 - val_acc: 0.4939\n",
            "Epoch 101/150 - 0.09s - loss: 1.0407 - acc: 0.4892 - val_loss: 1.0548 - val_acc: 0.4899\n",
            "Epoch 102/150 - 0.09s - loss: 1.0403 - acc: 0.4912 - val_loss: 1.0545 - val_acc: 0.4899\n",
            "Epoch 103/150 - 0.10s - loss: 1.0399 - acc: 0.4890 - val_loss: 1.0542 - val_acc: 0.4919\n",
            "Epoch 104/150 - 0.09s - loss: 1.0395 - acc: 0.4885 - val_loss: 1.0540 - val_acc: 0.4899\n",
            "Epoch 105/150 - 0.09s - loss: 1.0390 - acc: 0.4930 - val_loss: 1.0537 - val_acc: 0.4939\n",
            "Epoch 106/150 - 0.09s - loss: 1.0386 - acc: 0.4921 - val_loss: 1.0534 - val_acc: 0.4960\n",
            "Epoch 107/150 - 0.09s - loss: 1.0382 - acc: 0.4924 - val_loss: 1.0531 - val_acc: 0.4980\n",
            "Epoch 108/150 - 0.09s - loss: 1.0378 - acc: 0.4926 - val_loss: 1.0528 - val_acc: 0.5000\n",
            "Epoch 109/150 - 0.13s - loss: 1.0374 - acc: 0.4937 - val_loss: 1.0525 - val_acc: 0.4980\n",
            "Epoch 110/150 - 0.09s - loss: 1.0370 - acc: 0.4944 - val_loss: 1.0523 - val_acc: 0.5000\n",
            "Epoch 111/150 - 0.09s - loss: 1.0365 - acc: 0.4924 - val_loss: 1.0520 - val_acc: 0.5000\n",
            "Epoch 112/150 - 0.14s - loss: 1.0361 - acc: 0.4926 - val_loss: 1.0517 - val_acc: 0.5020\n",
            "Epoch 113/150 - 0.12s - loss: 1.0357 - acc: 0.4944 - val_loss: 1.0515 - val_acc: 0.5020\n",
            "Epoch 114/150 - 0.10s - loss: 1.0353 - acc: 0.4957 - val_loss: 1.0512 - val_acc: 0.5040\n",
            "Epoch 115/150 - 0.10s - loss: 1.0349 - acc: 0.4953 - val_loss: 1.0510 - val_acc: 0.5040\n",
            "Epoch 116/150 - 0.10s - loss: 1.0345 - acc: 0.4975 - val_loss: 1.0507 - val_acc: 0.4919\n",
            "Epoch 117/150 - 0.10s - loss: 1.0341 - acc: 0.4973 - val_loss: 1.0504 - val_acc: 0.4879\n",
            "Epoch 118/150 - 0.09s - loss: 1.0337 - acc: 0.4984 - val_loss: 1.0501 - val_acc: 0.4899\n",
            "Epoch 119/150 - 0.09s - loss: 1.0333 - acc: 0.4980 - val_loss: 1.0499 - val_acc: 0.4960\n",
            "Epoch 120/150 - 0.10s - loss: 1.0328 - acc: 0.4996 - val_loss: 1.0496 - val_acc: 0.4899\n",
            "Epoch 121/150 - 0.09s - loss: 1.0324 - acc: 0.5002 - val_loss: 1.0493 - val_acc: 0.4919\n",
            "Epoch 122/150 - 0.09s - loss: 1.0320 - acc: 0.5016 - val_loss: 1.0490 - val_acc: 0.4919\n",
            "Epoch 123/150 - 0.10s - loss: 1.0316 - acc: 0.4989 - val_loss: 1.0488 - val_acc: 0.4919\n",
            "Epoch 124/150 - 0.09s - loss: 1.0312 - acc: 0.4991 - val_loss: 1.0486 - val_acc: 0.4939\n",
            "Epoch 125/150 - 0.09s - loss: 1.0308 - acc: 0.5002 - val_loss: 1.0483 - val_acc: 0.4939\n",
            "Epoch 126/150 - 0.09s - loss: 1.0304 - acc: 0.5007 - val_loss: 1.0481 - val_acc: 0.4939\n",
            "Epoch 127/150 - 0.09s - loss: 1.0300 - acc: 0.4989 - val_loss: 1.0478 - val_acc: 0.4899\n",
            "Epoch 128/150 - 0.09s - loss: 1.0296 - acc: 0.5002 - val_loss: 1.0475 - val_acc: 0.4919\n",
            "Epoch 129/150 - 0.10s - loss: 1.0292 - acc: 0.5016 - val_loss: 1.0472 - val_acc: 0.4939\n",
            "Epoch 130/150 - 0.09s - loss: 1.0289 - acc: 0.4993 - val_loss: 1.0471 - val_acc: 0.4899\n",
            "Epoch 131/150 - 0.09s - loss: 1.0285 - acc: 0.5009 - val_loss: 1.0467 - val_acc: 0.4939\n",
            "Epoch 132/150 - 0.10s - loss: 1.0281 - acc: 0.4996 - val_loss: 1.0464 - val_acc: 0.4899\n",
            "Epoch 133/150 - 0.10s - loss: 1.0277 - acc: 0.5000 - val_loss: 1.0463 - val_acc: 0.4939\n",
            "Epoch 134/150 - 0.09s - loss: 1.0273 - acc: 0.5009 - val_loss: 1.0460 - val_acc: 0.4939\n",
            "Epoch 135/150 - 0.11s - loss: 1.0269 - acc: 0.5018 - val_loss: 1.0457 - val_acc: 0.4899\n",
            "Epoch 136/150 - 0.09s - loss: 1.0265 - acc: 0.5011 - val_loss: 1.0454 - val_acc: 0.4919\n",
            "Epoch 137/150 - 0.09s - loss: 1.0261 - acc: 0.5031 - val_loss: 1.0452 - val_acc: 0.4919\n",
            "Epoch 138/150 - 0.10s - loss: 1.0257 - acc: 0.5029 - val_loss: 1.0449 - val_acc: 0.4899\n",
            "Epoch 139/150 - 0.09s - loss: 1.0253 - acc: 0.5016 - val_loss: 1.0446 - val_acc: 0.4939\n",
            "Epoch 140/150 - 0.09s - loss: 1.0249 - acc: 0.5020 - val_loss: 1.0444 - val_acc: 0.4919\n",
            "Epoch 141/150 - 0.09s - loss: 1.0245 - acc: 0.5022 - val_loss: 1.0442 - val_acc: 0.4899\n",
            "Epoch 142/150 - 0.10s - loss: 1.0242 - acc: 0.5022 - val_loss: 1.0440 - val_acc: 0.4919\n",
            "Epoch 143/150 - 0.12s - loss: 1.0238 - acc: 0.5029 - val_loss: 1.0437 - val_acc: 0.4919\n",
            "Epoch 144/150 - 0.09s - loss: 1.0234 - acc: 0.5040 - val_loss: 1.0435 - val_acc: 0.4919\n",
            "Epoch 145/150 - 0.09s - loss: 1.0230 - acc: 0.5047 - val_loss: 1.0432 - val_acc: 0.4939\n",
            "Epoch 146/150 - 0.10s - loss: 1.0226 - acc: 0.5040 - val_loss: 1.0429 - val_acc: 0.4960\n",
            "Epoch 147/150 - 0.09s - loss: 1.0222 - acc: 0.5045 - val_loss: 1.0427 - val_acc: 0.4939\n",
            "Epoch 148/150 - 0.10s - loss: 1.0218 - acc: 0.5045 - val_loss: 1.0423 - val_acc: 0.4939\n",
            "Epoch 149/150 - 0.10s - loss: 1.0214 - acc: 0.5054 - val_loss: 1.0422 - val_acc: 0.4960\n",
            "Epoch 150/150 - 0.09s - loss: 1.0210 - acc: 0.5056 - val_loss: 1.0419 - val_acc: 0.5000\n",
            "\n",
            "Combination 121/252:\n",
            "Hidden Layers: [256, 128], Activation: relu, Learning Rate: 0.0001, Batch Size: 32, Epochs: 50\n",
            "Epoch 1/50 - 0.14s - loss: 1.1513 - acc: 0.3225 - val_loss: 1.1342 - val_acc: 0.3360\n",
            "Epoch 2/50 - 0.13s - loss: 1.1432 - acc: 0.3225 - val_loss: 1.1271 - val_acc: 0.3360\n",
            "Epoch 3/50 - 0.13s - loss: 1.1367 - acc: 0.3225 - val_loss: 1.1214 - val_acc: 0.3340\n",
            "Epoch 4/50 - 0.13s - loss: 1.1314 - acc: 0.3232 - val_loss: 1.1169 - val_acc: 0.3340\n",
            "Epoch 5/50 - 0.12s - loss: 1.1271 - acc: 0.3234 - val_loss: 1.1132 - val_acc: 0.3360\n",
            "Epoch 6/50 - 0.12s - loss: 1.1234 - acc: 0.3239 - val_loss: 1.1102 - val_acc: 0.3340\n",
            "Epoch 7/50 - 0.13s - loss: 1.1204 - acc: 0.3232 - val_loss: 1.1078 - val_acc: 0.3360\n",
            "Epoch 8/50 - 0.12s - loss: 1.1179 - acc: 0.3210 - val_loss: 1.1058 - val_acc: 0.3360\n",
            "Epoch 9/50 - 0.13s - loss: 1.1157 - acc: 0.3210 - val_loss: 1.1041 - val_acc: 0.3441\n",
            "Epoch 10/50 - 0.14s - loss: 1.1139 - acc: 0.3176 - val_loss: 1.1028 - val_acc: 0.3482\n",
            "Epoch 11/50 - 0.14s - loss: 1.1123 - acc: 0.3176 - val_loss: 1.1016 - val_acc: 0.3482\n",
            "Epoch 12/50 - 0.14s - loss: 1.1109 - acc: 0.3176 - val_loss: 1.1006 - val_acc: 0.3502\n",
            "Epoch 13/50 - 0.14s - loss: 1.1097 - acc: 0.3198 - val_loss: 1.0998 - val_acc: 0.3502\n",
            "Epoch 14/50 - 0.14s - loss: 1.1087 - acc: 0.3169 - val_loss: 1.0991 - val_acc: 0.3502\n",
            "Epoch 15/50 - 0.15s - loss: 1.1077 - acc: 0.3203 - val_loss: 1.0985 - val_acc: 0.3522\n",
            "Epoch 16/50 - 0.14s - loss: 1.1069 - acc: 0.3203 - val_loss: 1.0979 - val_acc: 0.3462\n",
            "Epoch 17/50 - 0.16s - loss: 1.1061 - acc: 0.3210 - val_loss: 1.0974 - val_acc: 0.3583\n",
            "Epoch 18/50 - 0.14s - loss: 1.1054 - acc: 0.3248 - val_loss: 1.0970 - val_acc: 0.3543\n",
            "Epoch 19/50 - 0.14s - loss: 1.1047 - acc: 0.3219 - val_loss: 1.0966 - val_acc: 0.3704\n",
            "Epoch 20/50 - 0.14s - loss: 1.1041 - acc: 0.3216 - val_loss: 1.0962 - val_acc: 0.3644\n",
            "Epoch 21/50 - 0.17s - loss: 1.1036 - acc: 0.3203 - val_loss: 1.0959 - val_acc: 0.3725\n",
            "Epoch 22/50 - 0.14s - loss: 1.1030 - acc: 0.3214 - val_loss: 1.0956 - val_acc: 0.3644\n",
            "Epoch 23/50 - 0.14s - loss: 1.1025 - acc: 0.3255 - val_loss: 1.0953 - val_acc: 0.3745\n",
            "Epoch 24/50 - 0.13s - loss: 1.1021 - acc: 0.3284 - val_loss: 1.0950 - val_acc: 0.3725\n",
            "Epoch 25/50 - 0.14s - loss: 1.1016 - acc: 0.3302 - val_loss: 1.0947 - val_acc: 0.3725\n",
            "Epoch 26/50 - 0.14s - loss: 1.1012 - acc: 0.3315 - val_loss: 1.0944 - val_acc: 0.3765\n",
            "Epoch 27/50 - 0.15s - loss: 1.1008 - acc: 0.3340 - val_loss: 1.0942 - val_acc: 0.3725\n",
            "Epoch 28/50 - 0.13s - loss: 1.1003 - acc: 0.3354 - val_loss: 1.0939 - val_acc: 0.3765\n",
            "Epoch 29/50 - 0.14s - loss: 1.1000 - acc: 0.3345 - val_loss: 1.0937 - val_acc: 0.3765\n",
            "Epoch 30/50 - 0.14s - loss: 1.0996 - acc: 0.3347 - val_loss: 1.0935 - val_acc: 0.3704\n",
            "Epoch 31/50 - 0.14s - loss: 1.0992 - acc: 0.3363 - val_loss: 1.0932 - val_acc: 0.3684\n",
            "Epoch 32/50 - 0.13s - loss: 1.0988 - acc: 0.3367 - val_loss: 1.0930 - val_acc: 0.3704\n",
            "Epoch 33/50 - 0.15s - loss: 1.0985 - acc: 0.3381 - val_loss: 1.0928 - val_acc: 0.3684\n",
            "Epoch 34/50 - 0.14s - loss: 1.0981 - acc: 0.3401 - val_loss: 1.0926 - val_acc: 0.3704\n",
            "Epoch 35/50 - 0.14s - loss: 1.0978 - acc: 0.3435 - val_loss: 1.0923 - val_acc: 0.3704\n",
            "Epoch 36/50 - 0.14s - loss: 1.0974 - acc: 0.3450 - val_loss: 1.0921 - val_acc: 0.3704\n",
            "Epoch 37/50 - 0.15s - loss: 1.0971 - acc: 0.3475 - val_loss: 1.0919 - val_acc: 0.3725\n",
            "Epoch 38/50 - 0.14s - loss: 1.0968 - acc: 0.3509 - val_loss: 1.0917 - val_acc: 0.3725\n",
            "Epoch 39/50 - 0.16s - loss: 1.0965 - acc: 0.3527 - val_loss: 1.0915 - val_acc: 0.3745\n",
            "Epoch 40/50 - 0.15s - loss: 1.0961 - acc: 0.3540 - val_loss: 1.0913 - val_acc: 0.3704\n",
            "Epoch 41/50 - 0.15s - loss: 1.0958 - acc: 0.3536 - val_loss: 1.0911 - val_acc: 0.3765\n",
            "Epoch 42/50 - 0.14s - loss: 1.0955 - acc: 0.3567 - val_loss: 1.0909 - val_acc: 0.3725\n",
            "Epoch 43/50 - 0.14s - loss: 1.0952 - acc: 0.3590 - val_loss: 1.0907 - val_acc: 0.3765\n",
            "Epoch 44/50 - 0.14s - loss: 1.0949 - acc: 0.3581 - val_loss: 1.0905 - val_acc: 0.3785\n",
            "Epoch 45/50 - 0.15s - loss: 1.0946 - acc: 0.3581 - val_loss: 1.0903 - val_acc: 0.3765\n",
            "Epoch 46/50 - 0.14s - loss: 1.0943 - acc: 0.3601 - val_loss: 1.0901 - val_acc: 0.3806\n",
            "Epoch 47/50 - 0.14s - loss: 1.0940 - acc: 0.3621 - val_loss: 1.0899 - val_acc: 0.3826\n",
            "Epoch 48/50 - 0.14s - loss: 1.0937 - acc: 0.3644 - val_loss: 1.0897 - val_acc: 0.3806\n",
            "Epoch 49/50 - 0.15s - loss: 1.0934 - acc: 0.3677 - val_loss: 1.0895 - val_acc: 0.3765\n",
            "Epoch 50/50 - 0.14s - loss: 1.0931 - acc: 0.3709 - val_loss: 1.0893 - val_acc: 0.3725\n",
            "\n",
            "Combination 122/252:\n",
            "Hidden Layers: [256, 128], Activation: relu, Learning Rate: 0.0001, Batch Size: 32, Epochs: 100\n",
            "Epoch 1/100 - 0.15s - loss: 1.1111 - acc: 0.3225 - val_loss: 1.0995 - val_acc: 0.3401\n",
            "Epoch 2/100 - 0.14s - loss: 1.1100 - acc: 0.3250 - val_loss: 1.0987 - val_acc: 0.3441\n",
            "Epoch 3/100 - 0.15s - loss: 1.1090 - acc: 0.3268 - val_loss: 1.0980 - val_acc: 0.3462\n",
            "Epoch 4/100 - 0.14s - loss: 1.1081 - acc: 0.3275 - val_loss: 1.0973 - val_acc: 0.3502\n",
            "Epoch 5/100 - 0.14s - loss: 1.1073 - acc: 0.3277 - val_loss: 1.0968 - val_acc: 0.3522\n",
            "Epoch 6/100 - 0.13s - loss: 1.1066 - acc: 0.3279 - val_loss: 1.0962 - val_acc: 0.3522\n",
            "Epoch 7/100 - 0.15s - loss: 1.1059 - acc: 0.3266 - val_loss: 1.0958 - val_acc: 0.3583\n",
            "Epoch 8/100 - 0.14s - loss: 1.1053 - acc: 0.3273 - val_loss: 1.0953 - val_acc: 0.3583\n",
            "Epoch 9/100 - 0.14s - loss: 1.1047 - acc: 0.3288 - val_loss: 1.0949 - val_acc: 0.3583\n",
            "Epoch 10/100 - 0.15s - loss: 1.1042 - acc: 0.3291 - val_loss: 1.0946 - val_acc: 0.3644\n",
            "Epoch 11/100 - 0.14s - loss: 1.1037 - acc: 0.3297 - val_loss: 1.0942 - val_acc: 0.3623\n",
            "Epoch 12/100 - 0.14s - loss: 1.1032 - acc: 0.3320 - val_loss: 1.0939 - val_acc: 0.3664\n",
            "Epoch 13/100 - 0.15s - loss: 1.1027 - acc: 0.3338 - val_loss: 1.0936 - val_acc: 0.3684\n",
            "Epoch 14/100 - 0.13s - loss: 1.1023 - acc: 0.3356 - val_loss: 1.0934 - val_acc: 0.3704\n",
            "Epoch 15/100 - 0.14s - loss: 1.1019 - acc: 0.3369 - val_loss: 1.0931 - val_acc: 0.3725\n",
            "Epoch 16/100 - 0.13s - loss: 1.1015 - acc: 0.3387 - val_loss: 1.0929 - val_acc: 0.3806\n",
            "Epoch 17/100 - 0.14s - loss: 1.1012 - acc: 0.3390 - val_loss: 1.0927 - val_acc: 0.3785\n",
            "Epoch 18/100 - 0.14s - loss: 1.1008 - acc: 0.3403 - val_loss: 1.0925 - val_acc: 0.3826\n",
            "Epoch 19/100 - 0.15s - loss: 1.1005 - acc: 0.3426 - val_loss: 1.0923 - val_acc: 0.3826\n",
            "Epoch 20/100 - 0.14s - loss: 1.1002 - acc: 0.3459 - val_loss: 1.0921 - val_acc: 0.3846\n",
            "Epoch 21/100 - 0.14s - loss: 1.0999 - acc: 0.3444 - val_loss: 1.0919 - val_acc: 0.3826\n",
            "Epoch 22/100 - 0.14s - loss: 1.0996 - acc: 0.3457 - val_loss: 1.0918 - val_acc: 0.3826\n",
            "Epoch 23/100 - 0.14s - loss: 1.0993 - acc: 0.3464 - val_loss: 1.0916 - val_acc: 0.3826\n",
            "Epoch 24/100 - 0.14s - loss: 1.0990 - acc: 0.3450 - val_loss: 1.0914 - val_acc: 0.3826\n",
            "Epoch 25/100 - 0.15s - loss: 1.0988 - acc: 0.3464 - val_loss: 1.0913 - val_acc: 0.3846\n",
            "Epoch 26/100 - 0.14s - loss: 1.0985 - acc: 0.3489 - val_loss: 1.0911 - val_acc: 0.3846\n",
            "Epoch 27/100 - 0.14s - loss: 1.0982 - acc: 0.3493 - val_loss: 1.0910 - val_acc: 0.3806\n",
            "Epoch 28/100 - 0.14s - loss: 1.0980 - acc: 0.3511 - val_loss: 1.0908 - val_acc: 0.3826\n",
            "Epoch 29/100 - 0.15s - loss: 1.0977 - acc: 0.3527 - val_loss: 1.0907 - val_acc: 0.3846\n",
            "Epoch 30/100 - 0.13s - loss: 1.0975 - acc: 0.3525 - val_loss: 1.0905 - val_acc: 0.3887\n",
            "Epoch 31/100 - 0.15s - loss: 1.0972 - acc: 0.3545 - val_loss: 1.0904 - val_acc: 0.3887\n",
            "Epoch 32/100 - 0.15s - loss: 1.0970 - acc: 0.3543 - val_loss: 1.0903 - val_acc: 0.3947\n",
            "Epoch 33/100 - 0.14s - loss: 1.0968 - acc: 0.3545 - val_loss: 1.0901 - val_acc: 0.3907\n",
            "Epoch 34/100 - 0.14s - loss: 1.0965 - acc: 0.3558 - val_loss: 1.0900 - val_acc: 0.3927\n",
            "Epoch 35/100 - 0.15s - loss: 1.0963 - acc: 0.3594 - val_loss: 1.0899 - val_acc: 0.3927\n",
            "Epoch 36/100 - 0.14s - loss: 1.0961 - acc: 0.3603 - val_loss: 1.0897 - val_acc: 0.3947\n",
            "Epoch 37/100 - 0.15s - loss: 1.0959 - acc: 0.3608 - val_loss: 1.0896 - val_acc: 0.3968\n",
            "Epoch 38/100 - 0.15s - loss: 1.0956 - acc: 0.3614 - val_loss: 1.0895 - val_acc: 0.4008\n",
            "Epoch 39/100 - 0.15s - loss: 1.0954 - acc: 0.3637 - val_loss: 1.0893 - val_acc: 0.4028\n",
            "Epoch 40/100 - 0.15s - loss: 1.0952 - acc: 0.3644 - val_loss: 1.0892 - val_acc: 0.4049\n",
            "Epoch 41/100 - 0.14s - loss: 1.0950 - acc: 0.3632 - val_loss: 1.0891 - val_acc: 0.4049\n",
            "Epoch 42/100 - 0.13s - loss: 1.0948 - acc: 0.3644 - val_loss: 1.0889 - val_acc: 0.4049\n",
            "Epoch 43/100 - 0.14s - loss: 1.0946 - acc: 0.3662 - val_loss: 1.0888 - val_acc: 0.4008\n",
            "Epoch 44/100 - 0.13s - loss: 1.0944 - acc: 0.3657 - val_loss: 1.0887 - val_acc: 0.3988\n",
            "Epoch 45/100 - 0.14s - loss: 1.0942 - acc: 0.3673 - val_loss: 1.0885 - val_acc: 0.3988\n",
            "Epoch 46/100 - 0.14s - loss: 1.0940 - acc: 0.3691 - val_loss: 1.0884 - val_acc: 0.3968\n",
            "Epoch 47/100 - 0.15s - loss: 1.0938 - acc: 0.3709 - val_loss: 1.0883 - val_acc: 0.3988\n",
            "Epoch 48/100 - 0.13s - loss: 1.0935 - acc: 0.3713 - val_loss: 1.0882 - val_acc: 0.4008\n",
            "Epoch 49/100 - 0.15s - loss: 1.0933 - acc: 0.3725 - val_loss: 1.0880 - val_acc: 0.4008\n",
            "Epoch 50/100 - 0.13s - loss: 1.0931 - acc: 0.3720 - val_loss: 1.0879 - val_acc: 0.4008\n",
            "Epoch 51/100 - 0.14s - loss: 1.0930 - acc: 0.3731 - val_loss: 1.0878 - val_acc: 0.4008\n",
            "Epoch 52/100 - 0.13s - loss: 1.0928 - acc: 0.3745 - val_loss: 1.0877 - val_acc: 0.4008\n",
            "Epoch 53/100 - 0.14s - loss: 1.0926 - acc: 0.3752 - val_loss: 1.0875 - val_acc: 0.4008\n",
            "Epoch 54/100 - 0.14s - loss: 1.0924 - acc: 0.3765 - val_loss: 1.0874 - val_acc: 0.4028\n",
            "Epoch 55/100 - 0.14s - loss: 1.0922 - acc: 0.3790 - val_loss: 1.0873 - val_acc: 0.4028\n",
            "Epoch 56/100 - 0.13s - loss: 1.0920 - acc: 0.3797 - val_loss: 1.0872 - val_acc: 0.4109\n",
            "Epoch 57/100 - 0.14s - loss: 1.0918 - acc: 0.3797 - val_loss: 1.0870 - val_acc: 0.4109\n",
            "Epoch 58/100 - 0.13s - loss: 1.0916 - acc: 0.3803 - val_loss: 1.0869 - val_acc: 0.4089\n",
            "Epoch 59/100 - 0.13s - loss: 1.0914 - acc: 0.3808 - val_loss: 1.0868 - val_acc: 0.4089\n",
            "Epoch 60/100 - 0.13s - loss: 1.0912 - acc: 0.3808 - val_loss: 1.0867 - val_acc: 0.4069\n",
            "Epoch 61/100 - 0.14s - loss: 1.0910 - acc: 0.3812 - val_loss: 1.0866 - val_acc: 0.4109\n",
            "Epoch 62/100 - 0.13s - loss: 1.0908 - acc: 0.3817 - val_loss: 1.0864 - val_acc: 0.4170\n",
            "Epoch 63/100 - 0.13s - loss: 1.0906 - acc: 0.3835 - val_loss: 1.0863 - val_acc: 0.4170\n",
            "Epoch 64/100 - 0.13s - loss: 1.0904 - acc: 0.3844 - val_loss: 1.0862 - val_acc: 0.4190\n",
            "Epoch 65/100 - 0.13s - loss: 1.0903 - acc: 0.3862 - val_loss: 1.0861 - val_acc: 0.4190\n",
            "Epoch 66/100 - 0.13s - loss: 1.0901 - acc: 0.3869 - val_loss: 1.0860 - val_acc: 0.4251\n",
            "Epoch 67/100 - 0.15s - loss: 1.0899 - acc: 0.3866 - val_loss: 1.0858 - val_acc: 0.4251\n",
            "Epoch 68/100 - 0.13s - loss: 1.0897 - acc: 0.3875 - val_loss: 1.0857 - val_acc: 0.4251\n",
            "Epoch 69/100 - 0.13s - loss: 1.0895 - acc: 0.3882 - val_loss: 1.0856 - val_acc: 0.4251\n",
            "Epoch 70/100 - 0.13s - loss: 1.0893 - acc: 0.3893 - val_loss: 1.0855 - val_acc: 0.4251\n",
            "Epoch 71/100 - 0.13s - loss: 1.0891 - acc: 0.3907 - val_loss: 1.0853 - val_acc: 0.4291\n",
            "Epoch 72/100 - 0.13s - loss: 1.0890 - acc: 0.3923 - val_loss: 1.0852 - val_acc: 0.4332\n",
            "Epoch 73/100 - 0.15s - loss: 1.0888 - acc: 0.3920 - val_loss: 1.0851 - val_acc: 0.4372\n",
            "Epoch 74/100 - 0.14s - loss: 1.0886 - acc: 0.3923 - val_loss: 1.0850 - val_acc: 0.4413\n",
            "Epoch 75/100 - 0.14s - loss: 1.0884 - acc: 0.3927 - val_loss: 1.0849 - val_acc: 0.4433\n",
            "Epoch 76/100 - 0.16s - loss: 1.0882 - acc: 0.3934 - val_loss: 1.0847 - val_acc: 0.4413\n",
            "Epoch 77/100 - 0.16s - loss: 1.0881 - acc: 0.3947 - val_loss: 1.0846 - val_acc: 0.4393\n",
            "Epoch 78/100 - 0.15s - loss: 1.0879 - acc: 0.3947 - val_loss: 1.0845 - val_acc: 0.4393\n",
            "Epoch 79/100 - 0.16s - loss: 1.0877 - acc: 0.3954 - val_loss: 1.0844 - val_acc: 0.4372\n",
            "Epoch 80/100 - 0.13s - loss: 1.0875 - acc: 0.3954 - val_loss: 1.0842 - val_acc: 0.4393\n",
            "Epoch 81/100 - 0.14s - loss: 1.0873 - acc: 0.3961 - val_loss: 1.0841 - val_acc: 0.4413\n",
            "Epoch 82/100 - 0.14s - loss: 1.0872 - acc: 0.3968 - val_loss: 1.0840 - val_acc: 0.4413\n",
            "Epoch 83/100 - 0.14s - loss: 1.0870 - acc: 0.3983 - val_loss: 1.0839 - val_acc: 0.4413\n",
            "Epoch 84/100 - 0.14s - loss: 1.0868 - acc: 0.3997 - val_loss: 1.0837 - val_acc: 0.4413\n",
            "Epoch 85/100 - 0.15s - loss: 1.0867 - acc: 0.3986 - val_loss: 1.0836 - val_acc: 0.4433\n",
            "Epoch 86/100 - 0.13s - loss: 1.0865 - acc: 0.3992 - val_loss: 1.0835 - val_acc: 0.4393\n",
            "Epoch 87/100 - 0.14s - loss: 1.0863 - acc: 0.3992 - val_loss: 1.0834 - val_acc: 0.4372\n",
            "Epoch 88/100 - 0.14s - loss: 1.0862 - acc: 0.3986 - val_loss: 1.0833 - val_acc: 0.4372\n",
            "Epoch 89/100 - 0.14s - loss: 1.0860 - acc: 0.3990 - val_loss: 1.0831 - val_acc: 0.4372\n",
            "Epoch 90/100 - 0.14s - loss: 1.0858 - acc: 0.3990 - val_loss: 1.0830 - val_acc: 0.4372\n",
            "Epoch 91/100 - 0.15s - loss: 1.0857 - acc: 0.3992 - val_loss: 1.0829 - val_acc: 0.4393\n",
            "Epoch 92/100 - 0.14s - loss: 1.0855 - acc: 0.4004 - val_loss: 1.0828 - val_acc: 0.4393\n",
            "Epoch 93/100 - 0.14s - loss: 1.0853 - acc: 0.4006 - val_loss: 1.0827 - val_acc: 0.4393\n",
            "Epoch 94/100 - 0.14s - loss: 1.0852 - acc: 0.4019 - val_loss: 1.0825 - val_acc: 0.4393\n",
            "Epoch 95/100 - 0.14s - loss: 1.0850 - acc: 0.4028 - val_loss: 1.0824 - val_acc: 0.4372\n",
            "Epoch 96/100 - 0.14s - loss: 1.0848 - acc: 0.4042 - val_loss: 1.0823 - val_acc: 0.4372\n",
            "Epoch 97/100 - 0.16s - loss: 1.0847 - acc: 0.4044 - val_loss: 1.0822 - val_acc: 0.4352\n",
            "Epoch 98/100 - 0.17s - loss: 1.0845 - acc: 0.4060 - val_loss: 1.0821 - val_acc: 0.4372\n",
            "Epoch 99/100 - 0.15s - loss: 1.0844 - acc: 0.4067 - val_loss: 1.0820 - val_acc: 0.4372\n",
            "Epoch 100/100 - 0.13s - loss: 1.0842 - acc: 0.4076 - val_loss: 1.0819 - val_acc: 0.4352\n",
            "\n",
            "Combination 123/252:\n",
            "Hidden Layers: [256, 128], Activation: relu, Learning Rate: 0.0001, Batch Size: 32, Epochs: 150\n",
            "Epoch 1/150 - 0.14s - loss: 1.1097 - acc: 0.2962 - val_loss: 1.1077 - val_acc: 0.3300\n",
            "Epoch 2/150 - 0.13s - loss: 1.1093 - acc: 0.2994 - val_loss: 1.1074 - val_acc: 0.3259\n",
            "Epoch 3/150 - 0.15s - loss: 1.1089 - acc: 0.3018 - val_loss: 1.1071 - val_acc: 0.3279\n",
            "Epoch 4/150 - 0.13s - loss: 1.1085 - acc: 0.3025 - val_loss: 1.1069 - val_acc: 0.3239\n",
            "Epoch 5/150 - 0.14s - loss: 1.1081 - acc: 0.3045 - val_loss: 1.1066 - val_acc: 0.3178\n",
            "Epoch 6/150 - 0.13s - loss: 1.1077 - acc: 0.3043 - val_loss: 1.1064 - val_acc: 0.3198\n",
            "Epoch 7/150 - 0.14s - loss: 1.1073 - acc: 0.3068 - val_loss: 1.1061 - val_acc: 0.3178\n",
            "Epoch 8/150 - 0.14s - loss: 1.1070 - acc: 0.3095 - val_loss: 1.1059 - val_acc: 0.3158\n",
            "Epoch 9/150 - 0.15s - loss: 1.1066 - acc: 0.3120 - val_loss: 1.1057 - val_acc: 0.3178\n",
            "Epoch 10/150 - 0.14s - loss: 1.1063 - acc: 0.3149 - val_loss: 1.1054 - val_acc: 0.3198\n",
            "Epoch 11/150 - 0.14s - loss: 1.1060 - acc: 0.3149 - val_loss: 1.1052 - val_acc: 0.3219\n",
            "Epoch 12/150 - 0.14s - loss: 1.1057 - acc: 0.3196 - val_loss: 1.1050 - val_acc: 0.3158\n",
            "Epoch 13/150 - 0.14s - loss: 1.1054 - acc: 0.3207 - val_loss: 1.1048 - val_acc: 0.3138\n",
            "Epoch 14/150 - 0.14s - loss: 1.1050 - acc: 0.3228 - val_loss: 1.1046 - val_acc: 0.3198\n",
            "Epoch 15/150 - 0.15s - loss: 1.1047 - acc: 0.3241 - val_loss: 1.1044 - val_acc: 0.3198\n",
            "Epoch 16/150 - 0.15s - loss: 1.1044 - acc: 0.3268 - val_loss: 1.1042 - val_acc: 0.3239\n",
            "Epoch 17/150 - 0.15s - loss: 1.1042 - acc: 0.3284 - val_loss: 1.1040 - val_acc: 0.3279\n",
            "Epoch 18/150 - 0.14s - loss: 1.1039 - acc: 0.3302 - val_loss: 1.1038 - val_acc: 0.3360\n",
            "Epoch 19/150 - 0.15s - loss: 1.1036 - acc: 0.3318 - val_loss: 1.1036 - val_acc: 0.3320\n",
            "Epoch 20/150 - 0.21s - loss: 1.1033 - acc: 0.3331 - val_loss: 1.1034 - val_acc: 0.3401\n",
            "Epoch 21/150 - 0.18s - loss: 1.1030 - acc: 0.3336 - val_loss: 1.1032 - val_acc: 0.3340\n",
            "Epoch 22/150 - 0.17s - loss: 1.1027 - acc: 0.3327 - val_loss: 1.1030 - val_acc: 0.3381\n",
            "Epoch 23/150 - 0.15s - loss: 1.1025 - acc: 0.3349 - val_loss: 1.1028 - val_acc: 0.3421\n",
            "Epoch 24/150 - 0.15s - loss: 1.1022 - acc: 0.3351 - val_loss: 1.1026 - val_acc: 0.3421\n",
            "Epoch 25/150 - 0.14s - loss: 1.1019 - acc: 0.3369 - val_loss: 1.1024 - val_acc: 0.3421\n",
            "Epoch 26/150 - 0.16s - loss: 1.1017 - acc: 0.3385 - val_loss: 1.1022 - val_acc: 0.3482\n",
            "Epoch 27/150 - 0.14s - loss: 1.1014 - acc: 0.3390 - val_loss: 1.1020 - val_acc: 0.3502\n",
            "Epoch 28/150 - 0.14s - loss: 1.1012 - acc: 0.3414 - val_loss: 1.1018 - val_acc: 0.3522\n",
            "Epoch 29/150 - 0.13s - loss: 1.1009 - acc: 0.3437 - val_loss: 1.1017 - val_acc: 0.3543\n",
            "Epoch 30/150 - 0.15s - loss: 1.1007 - acc: 0.3459 - val_loss: 1.1015 - val_acc: 0.3543\n",
            "Epoch 31/150 - 0.14s - loss: 1.1004 - acc: 0.3482 - val_loss: 1.1013 - val_acc: 0.3563\n",
            "Epoch 32/150 - 0.15s - loss: 1.1002 - acc: 0.3486 - val_loss: 1.1011 - val_acc: 0.3563\n",
            "Epoch 33/150 - 0.15s - loss: 1.0999 - acc: 0.3513 - val_loss: 1.1009 - val_acc: 0.3502\n",
            "Epoch 34/150 - 0.14s - loss: 1.0997 - acc: 0.3536 - val_loss: 1.1008 - val_acc: 0.3522\n",
            "Epoch 35/150 - 0.13s - loss: 1.0994 - acc: 0.3547 - val_loss: 1.1006 - val_acc: 0.3522\n",
            "Epoch 36/150 - 0.14s - loss: 1.0992 - acc: 0.3552 - val_loss: 1.1004 - val_acc: 0.3563\n",
            "Epoch 37/150 - 0.13s - loss: 1.0990 - acc: 0.3556 - val_loss: 1.1002 - val_acc: 0.3563\n",
            "Epoch 38/150 - 0.15s - loss: 1.0987 - acc: 0.3581 - val_loss: 1.1001 - val_acc: 0.3563\n",
            "Epoch 39/150 - 0.13s - loss: 1.0985 - acc: 0.3583 - val_loss: 1.0999 - val_acc: 0.3563\n",
            "Epoch 40/150 - 0.14s - loss: 1.0983 - acc: 0.3590 - val_loss: 1.0997 - val_acc: 0.3583\n",
            "Epoch 41/150 - 0.15s - loss: 1.0980 - acc: 0.3601 - val_loss: 1.0995 - val_acc: 0.3603\n",
            "Epoch 42/150 - 0.14s - loss: 1.0978 - acc: 0.3619 - val_loss: 1.0994 - val_acc: 0.3684\n",
            "Epoch 43/150 - 0.13s - loss: 1.0976 - acc: 0.3632 - val_loss: 1.0992 - val_acc: 0.3684\n",
            "Epoch 44/150 - 0.15s - loss: 1.0973 - acc: 0.3637 - val_loss: 1.0990 - val_acc: 0.3684\n",
            "Epoch 45/150 - 0.13s - loss: 1.0971 - acc: 0.3655 - val_loss: 1.0989 - val_acc: 0.3725\n",
            "Epoch 46/150 - 0.14s - loss: 1.0969 - acc: 0.3664 - val_loss: 1.0987 - val_acc: 0.3704\n",
            "Epoch 47/150 - 0.13s - loss: 1.0967 - acc: 0.3675 - val_loss: 1.0986 - val_acc: 0.3725\n",
            "Epoch 48/150 - 0.14s - loss: 1.0965 - acc: 0.3675 - val_loss: 1.0984 - val_acc: 0.3745\n",
            "Epoch 49/150 - 0.13s - loss: 1.0962 - acc: 0.3689 - val_loss: 1.0982 - val_acc: 0.3745\n",
            "Epoch 50/150 - 0.15s - loss: 1.0960 - acc: 0.3693 - val_loss: 1.0981 - val_acc: 0.3745\n",
            "Epoch 51/150 - 0.13s - loss: 1.0958 - acc: 0.3689 - val_loss: 1.0979 - val_acc: 0.3785\n",
            "Epoch 52/150 - 0.14s - loss: 1.0956 - acc: 0.3704 - val_loss: 1.0978 - val_acc: 0.3785\n",
            "Epoch 53/150 - 0.14s - loss: 1.0954 - acc: 0.3718 - val_loss: 1.0976 - val_acc: 0.3826\n",
            "Epoch 54/150 - 0.15s - loss: 1.0952 - acc: 0.3722 - val_loss: 1.0975 - val_acc: 0.3785\n",
            "Epoch 55/150 - 0.13s - loss: 1.0950 - acc: 0.3725 - val_loss: 1.0973 - val_acc: 0.3806\n",
            "Epoch 56/150 - 0.14s - loss: 1.0948 - acc: 0.3731 - val_loss: 1.0972 - val_acc: 0.3826\n",
            "Epoch 57/150 - 0.13s - loss: 1.0945 - acc: 0.3736 - val_loss: 1.0970 - val_acc: 0.3826\n",
            "Epoch 58/150 - 0.13s - loss: 1.0943 - acc: 0.3727 - val_loss: 1.0969 - val_acc: 0.3866\n",
            "Epoch 59/150 - 0.13s - loss: 1.0941 - acc: 0.3743 - val_loss: 1.0967 - val_acc: 0.3866\n",
            "Epoch 60/150 - 0.13s - loss: 1.0939 - acc: 0.3754 - val_loss: 1.0966 - val_acc: 0.3866\n",
            "Epoch 61/150 - 0.12s - loss: 1.0937 - acc: 0.3765 - val_loss: 1.0964 - val_acc: 0.3866\n",
            "Epoch 62/150 - 0.15s - loss: 1.0935 - acc: 0.3761 - val_loss: 1.0963 - val_acc: 0.3846\n",
            "Epoch 63/150 - 0.19s - loss: 1.0933 - acc: 0.3767 - val_loss: 1.0961 - val_acc: 0.3826\n",
            "Epoch 64/150 - 0.14s - loss: 1.0931 - acc: 0.3765 - val_loss: 1.0960 - val_acc: 0.3826\n",
            "Epoch 65/150 - 0.13s - loss: 1.0929 - acc: 0.3779 - val_loss: 1.0958 - val_acc: 0.3806\n",
            "Epoch 66/150 - 0.13s - loss: 1.0927 - acc: 0.3776 - val_loss: 1.0957 - val_acc: 0.3785\n",
            "Epoch 67/150 - 0.13s - loss: 1.0925 - acc: 0.3776 - val_loss: 1.0955 - val_acc: 0.3785\n",
            "Epoch 68/150 - 0.15s - loss: 1.0923 - acc: 0.3781 - val_loss: 1.0954 - val_acc: 0.3785\n",
            "Epoch 69/150 - 0.13s - loss: 1.0921 - acc: 0.3781 - val_loss: 1.0952 - val_acc: 0.3765\n",
            "Epoch 70/150 - 0.13s - loss: 1.0919 - acc: 0.3781 - val_loss: 1.0951 - val_acc: 0.3785\n",
            "Epoch 71/150 - 0.12s - loss: 1.0917 - acc: 0.3788 - val_loss: 1.0950 - val_acc: 0.3785\n",
            "Epoch 72/150 - 0.13s - loss: 1.0916 - acc: 0.3797 - val_loss: 1.0948 - val_acc: 0.3785\n",
            "Epoch 73/150 - 0.13s - loss: 1.0914 - acc: 0.3808 - val_loss: 1.0947 - val_acc: 0.3785\n",
            "Epoch 74/150 - 0.15s - loss: 1.0912 - acc: 0.3810 - val_loss: 1.0945 - val_acc: 0.3785\n",
            "Epoch 75/150 - 0.13s - loss: 1.0910 - acc: 0.3808 - val_loss: 1.0944 - val_acc: 0.3785\n",
            "Epoch 76/150 - 0.13s - loss: 1.0908 - acc: 0.3806 - val_loss: 1.0943 - val_acc: 0.3785\n",
            "Epoch 77/150 - 0.12s - loss: 1.0906 - acc: 0.3801 - val_loss: 1.0941 - val_acc: 0.3765\n",
            "Epoch 78/150 - 0.12s - loss: 1.0904 - acc: 0.3815 - val_loss: 1.0940 - val_acc: 0.3765\n",
            "Epoch 79/150 - 0.13s - loss: 1.0902 - acc: 0.3824 - val_loss: 1.0939 - val_acc: 0.3765\n",
            "Epoch 80/150 - 0.15s - loss: 1.0901 - acc: 0.3837 - val_loss: 1.0937 - val_acc: 0.3765\n",
            "Epoch 81/150 - 0.13s - loss: 1.0899 - acc: 0.3846 - val_loss: 1.0936 - val_acc: 0.3765\n",
            "Epoch 82/150 - 0.13s - loss: 1.0897 - acc: 0.3844 - val_loss: 1.0935 - val_acc: 0.3765\n",
            "Epoch 83/150 - 0.13s - loss: 1.0895 - acc: 0.3844 - val_loss: 1.0933 - val_acc: 0.3765\n",
            "Epoch 84/150 - 0.13s - loss: 1.0893 - acc: 0.3855 - val_loss: 1.0932 - val_acc: 0.3806\n",
            "Epoch 85/150 - 0.15s - loss: 1.0892 - acc: 0.3855 - val_loss: 1.0931 - val_acc: 0.3866\n",
            "Epoch 86/150 - 0.14s - loss: 1.0890 - acc: 0.3855 - val_loss: 1.0929 - val_acc: 0.3846\n",
            "Epoch 87/150 - 0.12s - loss: 1.0888 - acc: 0.3860 - val_loss: 1.0928 - val_acc: 0.3826\n",
            "Epoch 88/150 - 0.14s - loss: 1.0886 - acc: 0.3871 - val_loss: 1.0927 - val_acc: 0.3846\n",
            "Epoch 89/150 - 0.13s - loss: 1.0885 - acc: 0.3887 - val_loss: 1.0925 - val_acc: 0.3887\n",
            "Epoch 90/150 - 0.14s - loss: 1.0883 - acc: 0.3896 - val_loss: 1.0924 - val_acc: 0.3927\n",
            "Epoch 91/150 - 0.13s - loss: 1.0881 - acc: 0.3880 - val_loss: 1.0923 - val_acc: 0.3907\n",
            "Epoch 92/150 - 0.16s - loss: 1.0879 - acc: 0.3878 - val_loss: 1.0922 - val_acc: 0.3927\n",
            "Epoch 93/150 - 0.13s - loss: 1.0878 - acc: 0.3884 - val_loss: 1.0920 - val_acc: 0.3927\n",
            "Epoch 94/150 - 0.14s - loss: 1.0876 - acc: 0.3896 - val_loss: 1.0919 - val_acc: 0.3907\n",
            "Epoch 95/150 - 0.14s - loss: 1.0874 - acc: 0.3914 - val_loss: 1.0918 - val_acc: 0.3927\n",
            "Epoch 96/150 - 0.13s - loss: 1.0873 - acc: 0.3920 - val_loss: 1.0917 - val_acc: 0.3907\n",
            "Epoch 97/150 - 0.13s - loss: 1.0871 - acc: 0.3934 - val_loss: 1.0915 - val_acc: 0.3927\n",
            "Epoch 98/150 - 0.13s - loss: 1.0869 - acc: 0.3945 - val_loss: 1.0914 - val_acc: 0.3947\n",
            "Epoch 99/150 - 0.12s - loss: 1.0868 - acc: 0.3943 - val_loss: 1.0913 - val_acc: 0.3947\n",
            "Epoch 100/150 - 0.12s - loss: 1.0866 - acc: 0.3952 - val_loss: 1.0912 - val_acc: 0.3927\n",
            "Epoch 101/150 - 0.14s - loss: 1.0864 - acc: 0.3963 - val_loss: 1.0911 - val_acc: 0.3968\n",
            "Epoch 102/150 - 0.13s - loss: 1.0863 - acc: 0.3968 - val_loss: 1.0909 - val_acc: 0.3988\n",
            "Epoch 103/150 - 0.13s - loss: 1.0861 - acc: 0.3981 - val_loss: 1.0908 - val_acc: 0.3968\n",
            "Epoch 104/150 - 0.15s - loss: 1.0859 - acc: 0.3988 - val_loss: 1.0907 - val_acc: 0.3968\n",
            "Epoch 105/150 - 0.12s - loss: 1.0858 - acc: 0.3999 - val_loss: 1.0906 - val_acc: 0.3968\n",
            "Epoch 106/150 - 0.14s - loss: 1.0856 - acc: 0.4022 - val_loss: 1.0905 - val_acc: 0.3988\n",
            "Epoch 107/150 - 0.15s - loss: 1.0855 - acc: 0.4033 - val_loss: 1.0904 - val_acc: 0.3947\n",
            "Epoch 108/150 - 0.17s - loss: 1.0853 - acc: 0.4042 - val_loss: 1.0903 - val_acc: 0.3968\n",
            "Epoch 109/150 - 0.14s - loss: 1.0851 - acc: 0.4064 - val_loss: 1.0901 - val_acc: 0.3947\n",
            "Epoch 110/150 - 0.15s - loss: 1.0850 - acc: 0.4069 - val_loss: 1.0900 - val_acc: 0.3907\n",
            "Epoch 111/150 - 0.13s - loss: 1.0848 - acc: 0.4076 - val_loss: 1.0899 - val_acc: 0.3907\n",
            "Epoch 112/150 - 0.13s - loss: 1.0847 - acc: 0.4094 - val_loss: 1.0898 - val_acc: 0.3927\n",
            "Epoch 113/150 - 0.12s - loss: 1.0845 - acc: 0.4089 - val_loss: 1.0897 - val_acc: 0.3887\n",
            "Epoch 114/150 - 0.13s - loss: 1.0844 - acc: 0.4085 - val_loss: 1.0896 - val_acc: 0.3927\n",
            "Epoch 115/150 - 0.13s - loss: 1.0842 - acc: 0.4089 - val_loss: 1.0895 - val_acc: 0.3927\n",
            "Epoch 116/150 - 0.13s - loss: 1.0840 - acc: 0.4100 - val_loss: 1.0894 - val_acc: 0.3907\n",
            "Epoch 117/150 - 0.13s - loss: 1.0839 - acc: 0.4100 - val_loss: 1.0893 - val_acc: 0.3907\n",
            "Epoch 118/150 - 0.12s - loss: 1.0837 - acc: 0.4105 - val_loss: 1.0892 - val_acc: 0.3887\n",
            "Epoch 119/150 - 0.12s - loss: 1.0836 - acc: 0.4107 - val_loss: 1.0891 - val_acc: 0.3866\n",
            "Epoch 120/150 - 0.13s - loss: 1.0834 - acc: 0.4116 - val_loss: 1.0890 - val_acc: 0.3866\n",
            "Epoch 121/150 - 0.13s - loss: 1.0833 - acc: 0.4112 - val_loss: 1.0889 - val_acc: 0.3866\n",
            "Epoch 122/150 - 0.19s - loss: 1.0831 - acc: 0.4116 - val_loss: 1.0888 - val_acc: 0.3866\n",
            "Epoch 123/150 - 0.16s - loss: 1.0830 - acc: 0.4123 - val_loss: 1.0886 - val_acc: 0.3907\n",
            "Epoch 124/150 - 0.14s - loss: 1.0828 - acc: 0.4132 - val_loss: 1.0885 - val_acc: 0.3907\n",
            "Epoch 125/150 - 0.14s - loss: 1.0827 - acc: 0.4139 - val_loss: 1.0884 - val_acc: 0.3927\n",
            "Epoch 126/150 - 0.17s - loss: 1.0825 - acc: 0.4143 - val_loss: 1.0883 - val_acc: 0.3907\n",
            "Epoch 127/150 - 0.14s - loss: 1.0824 - acc: 0.4148 - val_loss: 1.0882 - val_acc: 0.3907\n",
            "Epoch 128/150 - 0.18s - loss: 1.0822 - acc: 0.4154 - val_loss: 1.0881 - val_acc: 0.3907\n",
            "Epoch 129/150 - 0.12s - loss: 1.0821 - acc: 0.4159 - val_loss: 1.0880 - val_acc: 0.3927\n",
            "Epoch 130/150 - 0.13s - loss: 1.0819 - acc: 0.4161 - val_loss: 1.0879 - val_acc: 0.3927\n",
            "Epoch 131/150 - 0.13s - loss: 1.0818 - acc: 0.4161 - val_loss: 1.0878 - val_acc: 0.3927\n",
            "Epoch 132/150 - 0.13s - loss: 1.0816 - acc: 0.4163 - val_loss: 1.0877 - val_acc: 0.3927\n",
            "Epoch 133/150 - 0.12s - loss: 1.0815 - acc: 0.4161 - val_loss: 1.0876 - val_acc: 0.3927\n",
            "Epoch 134/150 - 0.15s - loss: 1.0814 - acc: 0.4159 - val_loss: 1.0876 - val_acc: 0.3927\n",
            "Epoch 135/150 - 0.13s - loss: 1.0812 - acc: 0.4166 - val_loss: 1.0875 - val_acc: 0.3887\n",
            "Epoch 136/150 - 0.13s - loss: 1.0811 - acc: 0.4168 - val_loss: 1.0874 - val_acc: 0.3887\n",
            "Epoch 137/150 - 0.12s - loss: 1.0809 - acc: 0.4159 - val_loss: 1.0873 - val_acc: 0.3887\n",
            "Epoch 138/150 - 0.13s - loss: 1.0808 - acc: 0.4163 - val_loss: 1.0872 - val_acc: 0.3927\n",
            "Epoch 139/150 - 0.12s - loss: 1.0806 - acc: 0.4166 - val_loss: 1.0871 - val_acc: 0.3907\n",
            "Epoch 140/150 - 0.13s - loss: 1.0805 - acc: 0.4175 - val_loss: 1.0870 - val_acc: 0.3887\n",
            "Epoch 141/150 - 0.13s - loss: 1.0804 - acc: 0.4188 - val_loss: 1.0869 - val_acc: 0.3866\n",
            "Epoch 142/150 - 0.13s - loss: 1.0802 - acc: 0.4193 - val_loss: 1.0868 - val_acc: 0.3846\n",
            "Epoch 143/150 - 0.13s - loss: 1.0801 - acc: 0.4199 - val_loss: 1.0867 - val_acc: 0.3846\n",
            "Epoch 144/150 - 0.13s - loss: 1.0799 - acc: 0.4208 - val_loss: 1.0866 - val_acc: 0.3826\n",
            "Epoch 145/150 - 0.12s - loss: 1.0798 - acc: 0.4211 - val_loss: 1.0865 - val_acc: 0.3846\n",
            "Epoch 146/150 - 0.13s - loss: 1.0797 - acc: 0.4215 - val_loss: 1.0864 - val_acc: 0.3846\n",
            "Epoch 147/150 - 0.13s - loss: 1.0795 - acc: 0.4222 - val_loss: 1.0863 - val_acc: 0.3846\n",
            "Epoch 148/150 - 0.13s - loss: 1.0794 - acc: 0.4224 - val_loss: 1.0862 - val_acc: 0.3846\n",
            "Epoch 149/150 - 0.13s - loss: 1.0793 - acc: 0.4226 - val_loss: 1.0861 - val_acc: 0.3866\n",
            "Epoch 150/150 - 0.13s - loss: 1.0791 - acc: 0.4226 - val_loss: 1.0860 - val_acc: 0.3866\n",
            "\n",
            "Combination 124/252:\n",
            "Hidden Layers: [256, 128], Activation: relu, Learning Rate: 0.0001, Batch Size: 64, Epochs: 50\n",
            "Epoch 1/50 - 0.12s - loss: 1.1233 - acc: 0.3495 - val_loss: 1.1188 - val_acc: 0.3502\n",
            "Epoch 2/50 - 0.09s - loss: 1.1213 - acc: 0.3495 - val_loss: 1.1170 - val_acc: 0.3502\n",
            "Epoch 3/50 - 0.11s - loss: 1.1196 - acc: 0.3495 - val_loss: 1.1152 - val_acc: 0.3502\n",
            "Epoch 4/50 - 0.11s - loss: 1.1179 - acc: 0.3502 - val_loss: 1.1136 - val_acc: 0.3502\n",
            "Epoch 5/50 - 0.10s - loss: 1.1164 - acc: 0.3502 - val_loss: 1.1122 - val_acc: 0.3502\n",
            "Epoch 6/50 - 0.09s - loss: 1.1150 - acc: 0.3498 - val_loss: 1.1109 - val_acc: 0.3522\n",
            "Epoch 7/50 - 0.09s - loss: 1.1137 - acc: 0.3495 - val_loss: 1.1096 - val_acc: 0.3522\n",
            "Epoch 8/50 - 0.09s - loss: 1.1125 - acc: 0.3491 - val_loss: 1.1085 - val_acc: 0.3522\n",
            "Epoch 9/50 - 0.09s - loss: 1.1114 - acc: 0.3495 - val_loss: 1.1074 - val_acc: 0.3522\n",
            "Epoch 10/50 - 0.11s - loss: 1.1104 - acc: 0.3495 - val_loss: 1.1064 - val_acc: 0.3502\n",
            "Epoch 11/50 - 0.09s - loss: 1.1094 - acc: 0.3502 - val_loss: 1.1055 - val_acc: 0.3482\n",
            "Epoch 12/50 - 0.10s - loss: 1.1085 - acc: 0.3500 - val_loss: 1.1046 - val_acc: 0.3482\n",
            "Epoch 13/50 - 0.11s - loss: 1.1077 - acc: 0.3502 - val_loss: 1.1038 - val_acc: 0.3482\n",
            "Epoch 14/50 - 0.11s - loss: 1.1070 - acc: 0.3493 - val_loss: 1.1031 - val_acc: 0.3482\n",
            "Epoch 15/50 - 0.12s - loss: 1.1063 - acc: 0.3477 - val_loss: 1.1024 - val_acc: 0.3482\n",
            "Epoch 16/50 - 0.11s - loss: 1.1056 - acc: 0.3464 - val_loss: 1.1017 - val_acc: 0.3522\n",
            "Epoch 17/50 - 0.11s - loss: 1.1050 - acc: 0.3462 - val_loss: 1.1011 - val_acc: 0.3502\n",
            "Epoch 18/50 - 0.12s - loss: 1.1044 - acc: 0.3464 - val_loss: 1.1006 - val_acc: 0.3583\n",
            "Epoch 19/50 - 0.11s - loss: 1.1039 - acc: 0.3459 - val_loss: 1.1001 - val_acc: 0.3603\n",
            "Epoch 20/50 - 0.12s - loss: 1.1034 - acc: 0.3459 - val_loss: 1.0996 - val_acc: 0.3623\n",
            "Epoch 21/50 - 0.10s - loss: 1.1029 - acc: 0.3468 - val_loss: 1.0991 - val_acc: 0.3664\n",
            "Epoch 22/50 - 0.11s - loss: 1.1025 - acc: 0.3477 - val_loss: 1.0987 - val_acc: 0.3623\n",
            "Epoch 23/50 - 0.11s - loss: 1.1021 - acc: 0.3464 - val_loss: 1.0982 - val_acc: 0.3623\n",
            "Epoch 24/50 - 0.14s - loss: 1.1017 - acc: 0.3459 - val_loss: 1.0979 - val_acc: 0.3644\n",
            "Epoch 25/50 - 0.11s - loss: 1.1013 - acc: 0.3450 - val_loss: 1.0975 - val_acc: 0.3583\n",
            "Epoch 26/50 - 0.12s - loss: 1.1010 - acc: 0.3464 - val_loss: 1.0972 - val_acc: 0.3623\n",
            "Epoch 27/50 - 0.11s - loss: 1.1006 - acc: 0.3468 - val_loss: 1.0968 - val_acc: 0.3603\n",
            "Epoch 28/50 - 0.11s - loss: 1.1003 - acc: 0.3448 - val_loss: 1.0965 - val_acc: 0.3623\n",
            "Epoch 29/50 - 0.13s - loss: 1.1000 - acc: 0.3455 - val_loss: 1.0962 - val_acc: 0.3684\n",
            "Epoch 30/50 - 0.13s - loss: 1.0998 - acc: 0.3459 - val_loss: 1.0960 - val_acc: 0.3725\n",
            "Epoch 31/50 - 0.11s - loss: 1.0995 - acc: 0.3464 - val_loss: 1.0957 - val_acc: 0.3745\n",
            "Epoch 32/50 - 0.11s - loss: 1.0993 - acc: 0.3475 - val_loss: 1.0955 - val_acc: 0.3725\n",
            "Epoch 33/50 - 0.10s - loss: 1.0990 - acc: 0.3498 - val_loss: 1.0952 - val_acc: 0.3704\n",
            "Epoch 34/50 - 0.11s - loss: 1.0988 - acc: 0.3498 - val_loss: 1.0950 - val_acc: 0.3725\n",
            "Epoch 35/50 - 0.10s - loss: 1.0986 - acc: 0.3504 - val_loss: 1.0948 - val_acc: 0.3725\n",
            "Epoch 36/50 - 0.09s - loss: 1.0983 - acc: 0.3520 - val_loss: 1.0946 - val_acc: 0.3704\n",
            "Epoch 37/50 - 0.11s - loss: 1.0981 - acc: 0.3504 - val_loss: 1.0944 - val_acc: 0.3725\n",
            "Epoch 38/50 - 0.10s - loss: 1.0979 - acc: 0.3502 - val_loss: 1.0942 - val_acc: 0.3725\n",
            "Epoch 39/50 - 0.11s - loss: 1.0978 - acc: 0.3513 - val_loss: 1.0940 - val_acc: 0.3765\n",
            "Epoch 40/50 - 0.12s - loss: 1.0976 - acc: 0.3522 - val_loss: 1.0938 - val_acc: 0.3765\n",
            "Epoch 41/50 - 0.11s - loss: 1.0974 - acc: 0.3525 - val_loss: 1.0937 - val_acc: 0.3765\n",
            "Epoch 42/50 - 0.11s - loss: 1.0972 - acc: 0.3513 - val_loss: 1.0935 - val_acc: 0.3765\n",
            "Epoch 43/50 - 0.11s - loss: 1.0971 - acc: 0.3513 - val_loss: 1.0933 - val_acc: 0.3765\n",
            "Epoch 44/50 - 0.12s - loss: 1.0969 - acc: 0.3520 - val_loss: 1.0932 - val_acc: 0.3785\n",
            "Epoch 45/50 - 0.10s - loss: 1.0967 - acc: 0.3513 - val_loss: 1.0930 - val_acc: 0.3785\n",
            "Epoch 46/50 - 0.11s - loss: 1.0966 - acc: 0.3516 - val_loss: 1.0929 - val_acc: 0.3806\n",
            "Epoch 47/50 - 0.11s - loss: 1.0964 - acc: 0.3509 - val_loss: 1.0927 - val_acc: 0.3745\n",
            "Epoch 48/50 - 0.11s - loss: 1.0963 - acc: 0.3507 - val_loss: 1.0926 - val_acc: 0.3745\n",
            "Epoch 49/50 - 0.10s - loss: 1.0961 - acc: 0.3486 - val_loss: 1.0924 - val_acc: 0.3725\n",
            "Epoch 50/50 - 0.13s - loss: 1.0960 - acc: 0.3500 - val_loss: 1.0923 - val_acc: 0.3725\n",
            "\n",
            "Combination 125/252:\n",
            "Hidden Layers: [256, 128], Activation: relu, Learning Rate: 0.0001, Batch Size: 64, Epochs: 100\n",
            "Epoch 1/100 - 0.12s - loss: 1.1057 - acc: 0.3390 - val_loss: 1.1082 - val_acc: 0.3320\n",
            "Epoch 2/100 - 0.10s - loss: 1.1045 - acc: 0.3394 - val_loss: 1.1072 - val_acc: 0.3401\n",
            "Epoch 3/100 - 0.10s - loss: 1.1034 - acc: 0.3394 - val_loss: 1.1062 - val_acc: 0.3360\n",
            "Epoch 4/100 - 0.10s - loss: 1.1024 - acc: 0.3396 - val_loss: 1.1053 - val_acc: 0.3381\n",
            "Epoch 5/100 - 0.10s - loss: 1.1015 - acc: 0.3394 - val_loss: 1.1044 - val_acc: 0.3421\n",
            "Epoch 6/100 - 0.10s - loss: 1.1006 - acc: 0.3412 - val_loss: 1.1037 - val_acc: 0.3381\n",
            "Epoch 7/100 - 0.11s - loss: 1.0997 - acc: 0.3437 - val_loss: 1.1029 - val_acc: 0.3502\n",
            "Epoch 8/100 - 0.10s - loss: 1.0990 - acc: 0.3457 - val_loss: 1.1023 - val_acc: 0.3502\n",
            "Epoch 9/100 - 0.10s - loss: 1.0983 - acc: 0.3484 - val_loss: 1.1016 - val_acc: 0.3543\n",
            "Epoch 10/100 - 0.10s - loss: 1.0976 - acc: 0.3511 - val_loss: 1.1011 - val_acc: 0.3563\n",
            "Epoch 11/100 - 0.10s - loss: 1.0970 - acc: 0.3527 - val_loss: 1.1005 - val_acc: 0.3583\n",
            "Epoch 12/100 - 0.10s - loss: 1.0964 - acc: 0.3565 - val_loss: 1.1000 - val_acc: 0.3644\n",
            "Epoch 13/100 - 0.10s - loss: 1.0958 - acc: 0.3572 - val_loss: 1.0996 - val_acc: 0.3644\n",
            "Epoch 14/100 - 0.11s - loss: 1.0953 - acc: 0.3610 - val_loss: 1.0991 - val_acc: 0.3603\n",
            "Epoch 15/100 - 0.15s - loss: 1.0949 - acc: 0.3610 - val_loss: 1.0987 - val_acc: 0.3603\n",
            "Epoch 16/100 - 0.11s - loss: 1.0944 - acc: 0.3641 - val_loss: 1.0983 - val_acc: 0.3482\n",
            "Epoch 17/100 - 0.10s - loss: 1.0940 - acc: 0.3675 - val_loss: 1.0980 - val_acc: 0.3482\n",
            "Epoch 18/100 - 0.10s - loss: 1.0936 - acc: 0.3716 - val_loss: 1.0977 - val_acc: 0.3563\n",
            "Epoch 19/100 - 0.11s - loss: 1.0932 - acc: 0.3761 - val_loss: 1.0974 - val_acc: 0.3563\n",
            "Epoch 20/100 - 0.13s - loss: 1.0929 - acc: 0.3790 - val_loss: 1.0971 - val_acc: 0.3583\n",
            "Epoch 21/100 - 0.13s - loss: 1.0925 - acc: 0.3806 - val_loss: 1.0968 - val_acc: 0.3583\n",
            "Epoch 22/100 - 0.15s - loss: 1.0922 - acc: 0.3824 - val_loss: 1.0965 - val_acc: 0.3644\n",
            "Epoch 23/100 - 0.12s - loss: 1.0919 - acc: 0.3835 - val_loss: 1.0963 - val_acc: 0.3664\n",
            "Epoch 24/100 - 0.13s - loss: 1.0916 - acc: 0.3826 - val_loss: 1.0961 - val_acc: 0.3704\n",
            "Epoch 25/100 - 0.13s - loss: 1.0913 - acc: 0.3873 - val_loss: 1.0958 - val_acc: 0.3684\n",
            "Epoch 26/100 - 0.11s - loss: 1.0911 - acc: 0.3884 - val_loss: 1.0956 - val_acc: 0.3704\n",
            "Epoch 27/100 - 0.12s - loss: 1.0908 - acc: 0.3887 - val_loss: 1.0954 - val_acc: 0.3704\n",
            "Epoch 28/100 - 0.13s - loss: 1.0906 - acc: 0.3878 - val_loss: 1.0952 - val_acc: 0.3684\n",
            "Epoch 29/100 - 0.11s - loss: 1.0903 - acc: 0.3853 - val_loss: 1.0950 - val_acc: 0.3603\n",
            "Epoch 30/100 - 0.12s - loss: 1.0901 - acc: 0.3853 - val_loss: 1.0949 - val_acc: 0.3644\n",
            "Epoch 31/100 - 0.11s - loss: 1.0899 - acc: 0.3862 - val_loss: 1.0947 - val_acc: 0.3684\n",
            "Epoch 32/100 - 0.12s - loss: 1.0897 - acc: 0.3878 - val_loss: 1.0945 - val_acc: 0.3704\n",
            "Epoch 33/100 - 0.10s - loss: 1.0895 - acc: 0.3902 - val_loss: 1.0944 - val_acc: 0.3725\n",
            "Epoch 34/100 - 0.12s - loss: 1.0893 - acc: 0.3927 - val_loss: 1.0942 - val_acc: 0.3725\n",
            "Epoch 35/100 - 0.13s - loss: 1.0891 - acc: 0.3947 - val_loss: 1.0941 - val_acc: 0.3745\n",
            "Epoch 36/100 - 0.13s - loss: 1.0889 - acc: 0.3950 - val_loss: 1.0939 - val_acc: 0.3745\n",
            "Epoch 37/100 - 0.12s - loss: 1.0887 - acc: 0.3947 - val_loss: 1.0938 - val_acc: 0.3725\n",
            "Epoch 38/100 - 0.11s - loss: 1.0885 - acc: 0.3950 - val_loss: 1.0937 - val_acc: 0.3644\n",
            "Epoch 39/100 - 0.11s - loss: 1.0884 - acc: 0.3963 - val_loss: 1.0935 - val_acc: 0.3664\n",
            "Epoch 40/100 - 0.13s - loss: 1.0882 - acc: 0.3954 - val_loss: 1.0934 - val_acc: 0.3664\n",
            "Epoch 41/100 - 0.11s - loss: 1.0880 - acc: 0.3956 - val_loss: 1.0933 - val_acc: 0.3704\n",
            "Epoch 42/100 - 0.11s - loss: 1.0878 - acc: 0.3972 - val_loss: 1.0931 - val_acc: 0.3704\n",
            "Epoch 43/100 - 0.11s - loss: 1.0877 - acc: 0.3983 - val_loss: 1.0930 - val_acc: 0.3704\n",
            "Epoch 44/100 - 0.11s - loss: 1.0875 - acc: 0.3990 - val_loss: 1.0929 - val_acc: 0.3745\n",
            "Epoch 45/100 - 0.11s - loss: 1.0874 - acc: 0.3997 - val_loss: 1.0928 - val_acc: 0.3765\n",
            "Epoch 46/100 - 0.11s - loss: 1.0872 - acc: 0.3983 - val_loss: 1.0926 - val_acc: 0.3765\n",
            "Epoch 47/100 - 0.11s - loss: 1.0870 - acc: 0.3990 - val_loss: 1.0925 - val_acc: 0.3745\n",
            "Epoch 48/100 - 0.11s - loss: 1.0869 - acc: 0.3999 - val_loss: 1.0924 - val_acc: 0.3725\n",
            "Epoch 49/100 - 0.11s - loss: 1.0867 - acc: 0.4010 - val_loss: 1.0923 - val_acc: 0.3704\n",
            "Epoch 50/100 - 0.13s - loss: 1.0866 - acc: 0.4022 - val_loss: 1.0922 - val_acc: 0.3704\n",
            "Epoch 51/100 - 0.11s - loss: 1.0864 - acc: 0.4028 - val_loss: 1.0921 - val_acc: 0.3725\n",
            "Epoch 52/100 - 0.11s - loss: 1.0863 - acc: 0.4042 - val_loss: 1.0919 - val_acc: 0.3704\n",
            "Epoch 53/100 - 0.10s - loss: 1.0861 - acc: 0.4040 - val_loss: 1.0918 - val_acc: 0.3704\n",
            "Epoch 54/100 - 0.14s - loss: 1.0860 - acc: 0.4037 - val_loss: 1.0917 - val_acc: 0.3704\n",
            "Epoch 55/100 - 0.15s - loss: 1.0859 - acc: 0.4055 - val_loss: 1.0916 - val_acc: 0.3745\n",
            "Epoch 56/100 - 0.11s - loss: 1.0857 - acc: 0.4060 - val_loss: 1.0915 - val_acc: 0.3725\n",
            "Epoch 57/100 - 0.10s - loss: 1.0856 - acc: 0.4067 - val_loss: 1.0914 - val_acc: 0.3745\n",
            "Epoch 58/100 - 0.11s - loss: 1.0854 - acc: 0.4082 - val_loss: 1.0913 - val_acc: 0.3745\n",
            "Epoch 59/100 - 0.10s - loss: 1.0853 - acc: 0.4087 - val_loss: 1.0912 - val_acc: 0.3785\n",
            "Epoch 60/100 - 0.11s - loss: 1.0852 - acc: 0.4098 - val_loss: 1.0911 - val_acc: 0.3806\n",
            "Epoch 61/100 - 0.11s - loss: 1.0850 - acc: 0.4100 - val_loss: 1.0909 - val_acc: 0.3866\n",
            "Epoch 62/100 - 0.10s - loss: 1.0849 - acc: 0.4105 - val_loss: 1.0908 - val_acc: 0.3866\n",
            "Epoch 63/100 - 0.11s - loss: 1.0847 - acc: 0.4114 - val_loss: 1.0907 - val_acc: 0.3887\n",
            "Epoch 64/100 - 0.10s - loss: 1.0846 - acc: 0.4118 - val_loss: 1.0906 - val_acc: 0.3887\n",
            "Epoch 65/100 - 0.13s - loss: 1.0845 - acc: 0.4112 - val_loss: 1.0905 - val_acc: 0.3927\n",
            "Epoch 66/100 - 0.11s - loss: 1.0843 - acc: 0.4114 - val_loss: 1.0904 - val_acc: 0.3947\n",
            "Epoch 67/100 - 0.10s - loss: 1.0842 - acc: 0.4125 - val_loss: 1.0903 - val_acc: 0.3968\n",
            "Epoch 68/100 - 0.10s - loss: 1.0841 - acc: 0.4136 - val_loss: 1.0902 - val_acc: 0.3988\n",
            "Epoch 69/100 - 0.10s - loss: 1.0839 - acc: 0.4145 - val_loss: 1.0901 - val_acc: 0.3968\n",
            "Epoch 70/100 - 0.10s - loss: 1.0838 - acc: 0.4139 - val_loss: 1.0900 - val_acc: 0.3968\n",
            "Epoch 71/100 - 0.10s - loss: 1.0837 - acc: 0.4134 - val_loss: 1.0899 - val_acc: 0.3988\n",
            "Epoch 72/100 - 0.10s - loss: 1.0835 - acc: 0.4141 - val_loss: 1.0898 - val_acc: 0.3988\n",
            "Epoch 73/100 - 0.10s - loss: 1.0834 - acc: 0.4143 - val_loss: 1.0896 - val_acc: 0.3988\n",
            "Epoch 74/100 - 0.11s - loss: 1.0833 - acc: 0.4143 - val_loss: 1.0895 - val_acc: 0.4008\n",
            "Epoch 75/100 - 0.09s - loss: 1.0832 - acc: 0.4168 - val_loss: 1.0894 - val_acc: 0.4008\n",
            "Epoch 76/100 - 0.09s - loss: 1.0830 - acc: 0.4168 - val_loss: 1.0893 - val_acc: 0.4028\n",
            "Epoch 77/100 - 0.10s - loss: 1.0829 - acc: 0.4168 - val_loss: 1.0892 - val_acc: 0.4049\n",
            "Epoch 78/100 - 0.11s - loss: 1.0828 - acc: 0.4181 - val_loss: 1.0891 - val_acc: 0.4089\n",
            "Epoch 79/100 - 0.12s - loss: 1.0827 - acc: 0.4188 - val_loss: 1.0890 - val_acc: 0.4069\n",
            "Epoch 80/100 - 0.10s - loss: 1.0825 - acc: 0.4199 - val_loss: 1.0889 - val_acc: 0.4069\n",
            "Epoch 81/100 - 0.10s - loss: 1.0824 - acc: 0.4208 - val_loss: 1.0888 - val_acc: 0.4069\n",
            "Epoch 82/100 - 0.11s - loss: 1.0823 - acc: 0.4217 - val_loss: 1.0887 - val_acc: 0.4069\n",
            "Epoch 83/100 - 0.10s - loss: 1.0822 - acc: 0.4220 - val_loss: 1.0886 - val_acc: 0.4069\n",
            "Epoch 84/100 - 0.10s - loss: 1.0820 - acc: 0.4224 - val_loss: 1.0885 - val_acc: 0.4089\n",
            "Epoch 85/100 - 0.10s - loss: 1.0819 - acc: 0.4233 - val_loss: 1.0884 - val_acc: 0.4089\n",
            "Epoch 86/100 - 0.10s - loss: 1.0818 - acc: 0.4238 - val_loss: 1.0883 - val_acc: 0.4109\n",
            "Epoch 87/100 - 0.13s - loss: 1.0817 - acc: 0.4238 - val_loss: 1.0882 - val_acc: 0.4089\n",
            "Epoch 88/100 - 0.13s - loss: 1.0815 - acc: 0.4233 - val_loss: 1.0881 - val_acc: 0.4069\n",
            "Epoch 89/100 - 0.10s - loss: 1.0814 - acc: 0.4249 - val_loss: 1.0880 - val_acc: 0.4069\n",
            "Epoch 90/100 - 0.10s - loss: 1.0813 - acc: 0.4256 - val_loss: 1.0879 - val_acc: 0.4089\n",
            "Epoch 91/100 - 0.10s - loss: 1.0812 - acc: 0.4260 - val_loss: 1.0878 - val_acc: 0.4089\n",
            "Epoch 92/100 - 0.10s - loss: 1.0811 - acc: 0.4271 - val_loss: 1.0877 - val_acc: 0.4109\n",
            "Epoch 93/100 - 0.10s - loss: 1.0809 - acc: 0.4276 - val_loss: 1.0876 - val_acc: 0.4109\n",
            "Epoch 94/100 - 0.09s - loss: 1.0808 - acc: 0.4287 - val_loss: 1.0875 - val_acc: 0.4109\n",
            "Epoch 95/100 - 0.10s - loss: 1.0807 - acc: 0.4298 - val_loss: 1.0874 - val_acc: 0.4109\n",
            "Epoch 96/100 - 0.09s - loss: 1.0806 - acc: 0.4307 - val_loss: 1.0873 - val_acc: 0.4130\n",
            "Epoch 97/100 - 0.09s - loss: 1.0805 - acc: 0.4305 - val_loss: 1.0872 - val_acc: 0.4150\n",
            "Epoch 98/100 - 0.11s - loss: 1.0803 - acc: 0.4312 - val_loss: 1.0871 - val_acc: 0.4150\n",
            "Epoch 99/100 - 0.10s - loss: 1.0802 - acc: 0.4316 - val_loss: 1.0870 - val_acc: 0.4150\n",
            "Epoch 100/100 - 0.11s - loss: 1.0801 - acc: 0.4318 - val_loss: 1.0869 - val_acc: 0.4130\n",
            "\n",
            "Combination 126/252:\n",
            "Hidden Layers: [256, 128], Activation: relu, Learning Rate: 0.0001, Batch Size: 64, Epochs: 150\n",
            "Epoch 1/150 - 0.10s - loss: 1.1046 - acc: 0.3311 - val_loss: 1.0996 - val_acc: 0.3340\n",
            "Epoch 2/150 - 0.10s - loss: 1.1042 - acc: 0.3318 - val_loss: 1.0992 - val_acc: 0.3360\n",
            "Epoch 3/150 - 0.12s - loss: 1.1038 - acc: 0.3309 - val_loss: 1.0988 - val_acc: 0.3360\n",
            "Epoch 4/150 - 0.10s - loss: 1.1034 - acc: 0.3277 - val_loss: 1.0984 - val_acc: 0.3421\n",
            "Epoch 5/150 - 0.09s - loss: 1.1031 - acc: 0.3273 - val_loss: 1.0980 - val_acc: 0.3462\n",
            "Epoch 6/150 - 0.10s - loss: 1.1028 - acc: 0.3277 - val_loss: 1.0977 - val_acc: 0.3502\n",
            "Epoch 7/150 - 0.09s - loss: 1.1025 - acc: 0.3270 - val_loss: 1.0974 - val_acc: 0.3563\n",
            "Epoch 8/150 - 0.09s - loss: 1.1022 - acc: 0.3266 - val_loss: 1.0971 - val_acc: 0.3623\n",
            "Epoch 9/150 - 0.11s - loss: 1.1020 - acc: 0.3279 - val_loss: 1.0968 - val_acc: 0.3704\n",
            "Epoch 10/150 - 0.10s - loss: 1.1017 - acc: 0.3311 - val_loss: 1.0965 - val_acc: 0.3684\n",
            "Epoch 11/150 - 0.09s - loss: 1.1015 - acc: 0.3313 - val_loss: 1.0963 - val_acc: 0.3704\n",
            "Epoch 12/150 - 0.10s - loss: 1.1013 - acc: 0.3295 - val_loss: 1.0961 - val_acc: 0.3664\n",
            "Epoch 13/150 - 0.09s - loss: 1.1011 - acc: 0.3297 - val_loss: 1.0958 - val_acc: 0.3684\n",
            "Epoch 14/150 - 0.09s - loss: 1.1008 - acc: 0.3275 - val_loss: 1.0956 - val_acc: 0.3684\n",
            "Epoch 15/150 - 0.10s - loss: 1.1006 - acc: 0.3291 - val_loss: 1.0954 - val_acc: 0.3725\n",
            "Epoch 16/150 - 0.11s - loss: 1.1005 - acc: 0.3295 - val_loss: 1.0952 - val_acc: 0.3806\n",
            "Epoch 17/150 - 0.10s - loss: 1.1003 - acc: 0.3302 - val_loss: 1.0950 - val_acc: 0.3826\n",
            "Epoch 18/150 - 0.09s - loss: 1.1001 - acc: 0.3322 - val_loss: 1.0949 - val_acc: 0.3806\n",
            "Epoch 19/150 - 0.09s - loss: 1.0999 - acc: 0.3349 - val_loss: 1.0947 - val_acc: 0.3826\n",
            "Epoch 20/150 - 0.10s - loss: 1.0998 - acc: 0.3347 - val_loss: 1.0945 - val_acc: 0.3765\n",
            "Epoch 21/150 - 0.10s - loss: 1.0996 - acc: 0.3340 - val_loss: 1.0944 - val_acc: 0.3765\n",
            "Epoch 22/150 - 0.09s - loss: 1.0995 - acc: 0.3342 - val_loss: 1.0942 - val_acc: 0.3785\n",
            "Epoch 23/150 - 0.12s - loss: 1.0993 - acc: 0.3336 - val_loss: 1.0941 - val_acc: 0.3704\n",
            "Epoch 24/150 - 0.09s - loss: 1.0992 - acc: 0.3333 - val_loss: 1.0939 - val_acc: 0.3704\n",
            "Epoch 25/150 - 0.09s - loss: 1.0990 - acc: 0.3331 - val_loss: 1.0938 - val_acc: 0.3704\n",
            "Epoch 26/150 - 0.10s - loss: 1.0989 - acc: 0.3338 - val_loss: 1.0936 - val_acc: 0.3745\n",
            "Epoch 27/150 - 0.09s - loss: 1.0987 - acc: 0.3340 - val_loss: 1.0935 - val_acc: 0.3765\n",
            "Epoch 28/150 - 0.10s - loss: 1.0986 - acc: 0.3365 - val_loss: 1.0934 - val_acc: 0.3745\n",
            "Epoch 29/150 - 0.10s - loss: 1.0985 - acc: 0.3374 - val_loss: 1.0933 - val_acc: 0.3745\n",
            "Epoch 30/150 - 0.09s - loss: 1.0983 - acc: 0.3387 - val_loss: 1.0931 - val_acc: 0.3684\n",
            "Epoch 31/150 - 0.09s - loss: 1.0982 - acc: 0.3408 - val_loss: 1.0930 - val_acc: 0.3684\n",
            "Epoch 32/150 - 0.10s - loss: 1.0981 - acc: 0.3426 - val_loss: 1.0929 - val_acc: 0.3684\n",
            "Epoch 33/150 - 0.13s - loss: 1.0979 - acc: 0.3435 - val_loss: 1.0928 - val_acc: 0.3704\n",
            "Epoch 34/150 - 0.14s - loss: 1.0978 - acc: 0.3444 - val_loss: 1.0927 - val_acc: 0.3745\n",
            "Epoch 35/150 - 0.10s - loss: 1.0977 - acc: 0.3444 - val_loss: 1.0926 - val_acc: 0.3745\n",
            "Epoch 36/150 - 0.10s - loss: 1.0976 - acc: 0.3437 - val_loss: 1.0925 - val_acc: 0.3765\n",
            "Epoch 37/150 - 0.10s - loss: 1.0975 - acc: 0.3435 - val_loss: 1.0924 - val_acc: 0.3765\n",
            "Epoch 38/150 - 0.10s - loss: 1.0973 - acc: 0.3450 - val_loss: 1.0923 - val_acc: 0.3745\n",
            "Epoch 39/150 - 0.09s - loss: 1.0972 - acc: 0.3455 - val_loss: 1.0922 - val_acc: 0.3765\n",
            "Epoch 40/150 - 0.11s - loss: 1.0971 - acc: 0.3480 - val_loss: 1.0921 - val_acc: 0.3765\n",
            "Epoch 41/150 - 0.10s - loss: 1.0970 - acc: 0.3498 - val_loss: 1.0920 - val_acc: 0.3785\n",
            "Epoch 42/150 - 0.10s - loss: 1.0969 - acc: 0.3507 - val_loss: 1.0919 - val_acc: 0.3785\n",
            "Epoch 43/150 - 0.10s - loss: 1.0968 - acc: 0.3516 - val_loss: 1.0918 - val_acc: 0.3785\n",
            "Epoch 44/150 - 0.09s - loss: 1.0966 - acc: 0.3509 - val_loss: 1.0917 - val_acc: 0.3785\n",
            "Epoch 45/150 - 0.09s - loss: 1.0965 - acc: 0.3525 - val_loss: 1.0916 - val_acc: 0.3765\n",
            "Epoch 46/150 - 0.10s - loss: 1.0964 - acc: 0.3534 - val_loss: 1.0915 - val_acc: 0.3765\n",
            "Epoch 47/150 - 0.09s - loss: 1.0963 - acc: 0.3527 - val_loss: 1.0914 - val_acc: 0.3765\n",
            "Epoch 48/150 - 0.10s - loss: 1.0962 - acc: 0.3547 - val_loss: 1.0913 - val_acc: 0.3765\n",
            "Epoch 49/150 - 0.12s - loss: 1.0961 - acc: 0.3556 - val_loss: 1.0912 - val_acc: 0.3765\n",
            "Epoch 50/150 - 0.10s - loss: 1.0960 - acc: 0.3558 - val_loss: 1.0911 - val_acc: 0.3785\n",
            "Epoch 51/150 - 0.10s - loss: 1.0959 - acc: 0.3578 - val_loss: 1.0910 - val_acc: 0.3785\n",
            "Epoch 52/150 - 0.10s - loss: 1.0958 - acc: 0.3574 - val_loss: 1.0910 - val_acc: 0.3765\n",
            "Epoch 53/150 - 0.09s - loss: 1.0957 - acc: 0.3570 - val_loss: 1.0909 - val_acc: 0.3745\n",
            "Epoch 54/150 - 0.09s - loss: 1.0956 - acc: 0.3578 - val_loss: 1.0908 - val_acc: 0.3765\n",
            "Epoch 55/150 - 0.15s - loss: 1.0954 - acc: 0.3590 - val_loss: 1.0907 - val_acc: 0.3785\n",
            "Epoch 56/150 - 0.10s - loss: 1.0953 - acc: 0.3587 - val_loss: 1.0906 - val_acc: 0.3806\n",
            "Epoch 57/150 - 0.09s - loss: 1.0952 - acc: 0.3581 - val_loss: 1.0905 - val_acc: 0.3785\n",
            "Epoch 58/150 - 0.11s - loss: 1.0951 - acc: 0.3587 - val_loss: 1.0905 - val_acc: 0.3785\n",
            "Epoch 59/150 - 0.09s - loss: 1.0950 - acc: 0.3590 - val_loss: 1.0904 - val_acc: 0.3785\n",
            "Epoch 60/150 - 0.09s - loss: 1.0949 - acc: 0.3594 - val_loss: 1.0903 - val_acc: 0.3785\n",
            "Epoch 61/150 - 0.09s - loss: 1.0948 - acc: 0.3605 - val_loss: 1.0902 - val_acc: 0.3785\n",
            "Epoch 62/150 - 0.10s - loss: 1.0947 - acc: 0.3614 - val_loss: 1.0901 - val_acc: 0.3785\n",
            "Epoch 63/150 - 0.09s - loss: 1.0946 - acc: 0.3630 - val_loss: 1.0900 - val_acc: 0.3785\n",
            "Epoch 64/150 - 0.09s - loss: 1.0945 - acc: 0.3630 - val_loss: 1.0900 - val_acc: 0.3785\n",
            "Epoch 65/150 - 0.09s - loss: 1.0944 - acc: 0.3635 - val_loss: 1.0899 - val_acc: 0.3826\n",
            "Epoch 66/150 - 0.13s - loss: 1.0943 - acc: 0.3648 - val_loss: 1.0898 - val_acc: 0.3826\n",
            "Epoch 67/150 - 0.11s - loss: 1.0942 - acc: 0.3644 - val_loss: 1.0897 - val_acc: 0.3785\n",
            "Epoch 68/150 - 0.09s - loss: 1.0941 - acc: 0.3657 - val_loss: 1.0896 - val_acc: 0.3806\n",
            "Epoch 69/150 - 0.10s - loss: 1.0940 - acc: 0.3657 - val_loss: 1.0896 - val_acc: 0.3806\n",
            "Epoch 70/150 - 0.08s - loss: 1.0939 - acc: 0.3664 - val_loss: 1.0895 - val_acc: 0.3806\n",
            "Epoch 71/150 - 0.09s - loss: 1.0938 - acc: 0.3671 - val_loss: 1.0894 - val_acc: 0.3826\n",
            "Epoch 72/150 - 0.09s - loss: 1.0937 - acc: 0.3673 - val_loss: 1.0893 - val_acc: 0.3826\n",
            "Epoch 73/150 - 0.09s - loss: 1.0936 - acc: 0.3675 - val_loss: 1.0893 - val_acc: 0.3826\n",
            "Epoch 74/150 - 0.09s - loss: 1.0935 - acc: 0.3671 - val_loss: 1.0892 - val_acc: 0.3846\n",
            "Epoch 75/150 - 0.10s - loss: 1.0934 - acc: 0.3680 - val_loss: 1.0891 - val_acc: 0.3887\n",
            "Epoch 76/150 - 0.09s - loss: 1.0932 - acc: 0.3691 - val_loss: 1.0890 - val_acc: 0.3887\n",
            "Epoch 77/150 - 0.09s - loss: 1.0931 - acc: 0.3695 - val_loss: 1.0889 - val_acc: 0.3887\n",
            "Epoch 78/150 - 0.09s - loss: 1.0930 - acc: 0.3700 - val_loss: 1.0889 - val_acc: 0.3907\n",
            "Epoch 79/150 - 0.09s - loss: 1.0929 - acc: 0.3702 - val_loss: 1.0888 - val_acc: 0.3866\n",
            "Epoch 80/150 - 0.09s - loss: 1.0928 - acc: 0.3704 - val_loss: 1.0887 - val_acc: 0.3887\n",
            "Epoch 81/150 - 0.09s - loss: 1.0927 - acc: 0.3707 - val_loss: 1.0886 - val_acc: 0.3907\n",
            "Epoch 82/150 - 0.09s - loss: 1.0926 - acc: 0.3713 - val_loss: 1.0886 - val_acc: 0.3907\n",
            "Epoch 83/150 - 0.09s - loss: 1.0925 - acc: 0.3716 - val_loss: 1.0885 - val_acc: 0.3927\n",
            "Epoch 84/150 - 0.10s - loss: 1.0924 - acc: 0.3716 - val_loss: 1.0884 - val_acc: 0.3927\n",
            "Epoch 85/150 - 0.09s - loss: 1.0923 - acc: 0.3720 - val_loss: 1.0883 - val_acc: 0.3927\n",
            "Epoch 86/150 - 0.09s - loss: 1.0922 - acc: 0.3718 - val_loss: 1.0883 - val_acc: 0.3927\n",
            "Epoch 87/150 - 0.09s - loss: 1.0921 - acc: 0.3731 - val_loss: 1.0882 - val_acc: 0.3927\n",
            "Epoch 88/150 - 0.09s - loss: 1.0920 - acc: 0.3740 - val_loss: 1.0881 - val_acc: 0.3947\n",
            "Epoch 89/150 - 0.09s - loss: 1.0919 - acc: 0.3754 - val_loss: 1.0880 - val_acc: 0.3947\n",
            "Epoch 90/150 - 0.09s - loss: 1.0918 - acc: 0.3765 - val_loss: 1.0880 - val_acc: 0.3968\n",
            "Epoch 91/150 - 0.09s - loss: 1.0917 - acc: 0.3770 - val_loss: 1.0879 - val_acc: 0.3968\n",
            "Epoch 92/150 - 0.09s - loss: 1.0916 - acc: 0.3772 - val_loss: 1.0878 - val_acc: 0.3988\n",
            "Epoch 93/150 - 0.10s - loss: 1.0915 - acc: 0.3776 - val_loss: 1.0877 - val_acc: 0.3968\n",
            "Epoch 94/150 - 0.11s - loss: 1.0914 - acc: 0.3779 - val_loss: 1.0877 - val_acc: 0.3968\n",
            "Epoch 95/150 - 0.09s - loss: 1.0913 - acc: 0.3781 - val_loss: 1.0876 - val_acc: 0.3968\n",
            "Epoch 96/150 - 0.09s - loss: 1.0912 - acc: 0.3788 - val_loss: 1.0875 - val_acc: 0.3947\n",
            "Epoch 97/150 - 0.09s - loss: 1.0911 - acc: 0.3797 - val_loss: 1.0874 - val_acc: 0.3927\n",
            "Epoch 98/150 - 0.09s - loss: 1.0910 - acc: 0.3797 - val_loss: 1.0874 - val_acc: 0.3927\n",
            "Epoch 99/150 - 0.09s - loss: 1.0909 - acc: 0.3801 - val_loss: 1.0873 - val_acc: 0.3927\n",
            "Epoch 100/150 - 0.09s - loss: 1.0908 - acc: 0.3801 - val_loss: 1.0872 - val_acc: 0.3927\n",
            "Epoch 101/150 - 0.09s - loss: 1.0907 - acc: 0.3801 - val_loss: 1.0872 - val_acc: 0.3927\n",
            "Epoch 102/150 - 0.11s - loss: 1.0906 - acc: 0.3808 - val_loss: 1.0871 - val_acc: 0.3968\n",
            "Epoch 103/150 - 0.09s - loss: 1.0906 - acc: 0.3810 - val_loss: 1.0870 - val_acc: 0.3947\n",
            "Epoch 104/150 - 0.09s - loss: 1.0905 - acc: 0.3810 - val_loss: 1.0869 - val_acc: 0.3947\n",
            "Epoch 105/150 - 0.10s - loss: 1.0904 - acc: 0.3821 - val_loss: 1.0869 - val_acc: 0.3947\n",
            "Epoch 106/150 - 0.09s - loss: 1.0903 - acc: 0.3835 - val_loss: 1.0868 - val_acc: 0.3947\n",
            "Epoch 107/150 - 0.09s - loss: 1.0902 - acc: 0.3842 - val_loss: 1.0867 - val_acc: 0.3947\n",
            "Epoch 108/150 - 0.09s - loss: 1.0901 - acc: 0.3842 - val_loss: 1.0866 - val_acc: 0.3927\n",
            "Epoch 109/150 - 0.08s - loss: 1.0900 - acc: 0.3848 - val_loss: 1.0866 - val_acc: 0.3927\n",
            "Epoch 110/150 - 0.08s - loss: 1.0899 - acc: 0.3855 - val_loss: 1.0865 - val_acc: 0.3947\n",
            "Epoch 111/150 - 0.09s - loss: 1.0898 - acc: 0.3866 - val_loss: 1.0864 - val_acc: 0.3947\n",
            "Epoch 112/150 - 0.08s - loss: 1.0897 - acc: 0.3866 - val_loss: 1.0864 - val_acc: 0.3947\n",
            "Epoch 113/150 - 0.08s - loss: 1.0896 - acc: 0.3873 - val_loss: 1.0863 - val_acc: 0.3947\n",
            "Epoch 114/150 - 0.09s - loss: 1.0895 - acc: 0.3880 - val_loss: 1.0862 - val_acc: 0.3988\n",
            "Epoch 115/150 - 0.09s - loss: 1.0894 - acc: 0.3891 - val_loss: 1.0861 - val_acc: 0.4008\n",
            "Epoch 116/150 - 0.09s - loss: 1.0893 - acc: 0.3898 - val_loss: 1.0861 - val_acc: 0.4008\n",
            "Epoch 117/150 - 0.09s - loss: 1.0892 - acc: 0.3887 - val_loss: 1.0860 - val_acc: 0.4008\n",
            "Epoch 118/150 - 0.08s - loss: 1.0891 - acc: 0.3896 - val_loss: 1.0859 - val_acc: 0.4008\n",
            "Epoch 119/150 - 0.08s - loss: 1.0890 - acc: 0.3905 - val_loss: 1.0859 - val_acc: 0.4008\n",
            "Epoch 120/150 - 0.10s - loss: 1.0889 - acc: 0.3911 - val_loss: 1.0858 - val_acc: 0.4008\n",
            "Epoch 121/150 - 0.08s - loss: 1.0888 - acc: 0.3916 - val_loss: 1.0857 - val_acc: 0.4028\n",
            "Epoch 122/150 - 0.08s - loss: 1.0887 - acc: 0.3932 - val_loss: 1.0857 - val_acc: 0.4049\n",
            "Epoch 123/150 - 0.08s - loss: 1.0886 - acc: 0.3943 - val_loss: 1.0856 - val_acc: 0.4069\n",
            "Epoch 124/150 - 0.10s - loss: 1.0885 - acc: 0.3952 - val_loss: 1.0855 - val_acc: 0.4069\n",
            "Epoch 125/150 - 0.08s - loss: 1.0884 - acc: 0.3959 - val_loss: 1.0855 - val_acc: 0.4069\n",
            "Epoch 126/150 - 0.09s - loss: 1.0883 - acc: 0.3968 - val_loss: 1.0854 - val_acc: 0.4069\n",
            "Epoch 127/150 - 0.08s - loss: 1.0883 - acc: 0.3972 - val_loss: 1.0853 - val_acc: 0.4069\n",
            "Epoch 128/150 - 0.08s - loss: 1.0882 - acc: 0.3974 - val_loss: 1.0852 - val_acc: 0.4049\n",
            "Epoch 129/150 - 0.10s - loss: 1.0881 - acc: 0.3972 - val_loss: 1.0852 - val_acc: 0.4049\n",
            "Epoch 130/150 - 0.09s - loss: 1.0880 - acc: 0.3977 - val_loss: 1.0851 - val_acc: 0.4049\n",
            "Epoch 131/150 - 0.08s - loss: 1.0879 - acc: 0.3977 - val_loss: 1.0850 - val_acc: 0.4049\n",
            "Epoch 132/150 - 0.09s - loss: 1.0878 - acc: 0.3986 - val_loss: 1.0850 - val_acc: 0.4049\n",
            "Epoch 133/150 - 0.08s - loss: 1.0877 - acc: 0.3988 - val_loss: 1.0849 - val_acc: 0.4049\n",
            "Epoch 134/150 - 0.08s - loss: 1.0876 - acc: 0.3995 - val_loss: 1.0848 - val_acc: 0.4028\n",
            "Epoch 135/150 - 0.09s - loss: 1.0875 - acc: 0.3999 - val_loss: 1.0848 - val_acc: 0.4028\n",
            "Epoch 136/150 - 0.09s - loss: 1.0874 - acc: 0.4004 - val_loss: 1.0847 - val_acc: 0.4028\n",
            "Epoch 137/150 - 0.09s - loss: 1.0873 - acc: 0.4008 - val_loss: 1.0846 - val_acc: 0.4028\n",
            "Epoch 138/150 - 0.10s - loss: 1.0873 - acc: 0.4010 - val_loss: 1.0846 - val_acc: 0.4028\n",
            "Epoch 139/150 - 0.08s - loss: 1.0872 - acc: 0.4013 - val_loss: 1.0845 - val_acc: 0.4028\n",
            "Epoch 140/150 - 0.08s - loss: 1.0871 - acc: 0.4015 - val_loss: 1.0844 - val_acc: 0.4028\n",
            "Epoch 141/150 - 0.09s - loss: 1.0870 - acc: 0.4024 - val_loss: 1.0844 - val_acc: 0.4028\n",
            "Epoch 142/150 - 0.09s - loss: 1.0869 - acc: 0.4033 - val_loss: 1.0843 - val_acc: 0.4028\n",
            "Epoch 143/150 - 0.09s - loss: 1.0868 - acc: 0.4035 - val_loss: 1.0842 - val_acc: 0.4049\n",
            "Epoch 144/150 - 0.09s - loss: 1.0867 - acc: 0.4037 - val_loss: 1.0842 - val_acc: 0.4049\n",
            "Epoch 145/150 - 0.08s - loss: 1.0866 - acc: 0.4040 - val_loss: 1.0841 - val_acc: 0.4049\n",
            "Epoch 146/150 - 0.08s - loss: 1.0865 - acc: 0.4042 - val_loss: 1.0841 - val_acc: 0.4049\n",
            "Epoch 147/150 - 0.10s - loss: 1.0865 - acc: 0.4058 - val_loss: 1.0840 - val_acc: 0.4049\n",
            "Epoch 148/150 - 0.09s - loss: 1.0864 - acc: 0.4069 - val_loss: 1.0839 - val_acc: 0.4028\n",
            "Epoch 149/150 - 0.08s - loss: 1.0863 - acc: 0.4076 - val_loss: 1.0839 - val_acc: 0.4008\n",
            "Epoch 150/150 - 0.09s - loss: 1.0862 - acc: 0.4076 - val_loss: 1.0838 - val_acc: 0.4028\n",
            "\n",
            "Combination 127/252:\n",
            "Hidden Layers: [256, 128], Activation: tanh, Learning Rate: 0.01, Batch Size: 32, Epochs: 50\n",
            "Epoch 1/50 - 0.18s - loss: 1.0765 - acc: 0.4300 - val_loss: 1.0750 - val_acc: 0.4251\n",
            "Epoch 2/50 - 0.19s - loss: 1.0648 - acc: 0.4521 - val_loss: 1.0671 - val_acc: 0.4534\n",
            "Epoch 3/50 - 0.17s - loss: 1.0559 - acc: 0.4624 - val_loss: 1.0612 - val_acc: 0.4474\n",
            "Epoch 4/50 - 0.18s - loss: 1.0503 - acc: 0.4476 - val_loss: 1.0583 - val_acc: 0.4494\n",
            "Epoch 5/50 - 0.17s - loss: 1.0439 - acc: 0.4735 - val_loss: 1.0548 - val_acc: 0.4615\n",
            "Epoch 6/50 - 0.18s - loss: 1.0352 - acc: 0.4764 - val_loss: 1.0490 - val_acc: 0.4858\n",
            "Epoch 7/50 - 0.18s - loss: 1.0285 - acc: 0.4937 - val_loss: 1.0440 - val_acc: 0.4879\n",
            "Epoch 8/50 - 0.18s - loss: 1.0232 - acc: 0.4937 - val_loss: 1.0400 - val_acc: 0.4879\n",
            "Epoch 9/50 - 0.18s - loss: 1.0170 - acc: 0.5040 - val_loss: 1.0366 - val_acc: 0.4858\n",
            "Epoch 10/50 - 0.20s - loss: 1.0150 - acc: 0.4888 - val_loss: 1.0354 - val_acc: 0.4838\n",
            "Epoch 11/50 - 0.18s - loss: 1.0054 - acc: 0.5106 - val_loss: 1.0291 - val_acc: 0.4899\n",
            "Epoch 12/50 - 0.19s - loss: 0.9987 - acc: 0.5139 - val_loss: 1.0246 - val_acc: 0.5263\n",
            "Epoch 13/50 - 0.17s - loss: 0.9945 - acc: 0.5184 - val_loss: 1.0192 - val_acc: 0.5020\n",
            "Epoch 14/50 - 0.18s - loss: 0.9895 - acc: 0.5169 - val_loss: 1.0164 - val_acc: 0.5202\n",
            "Epoch 15/50 - 0.17s - loss: 0.9831 - acc: 0.5265 - val_loss: 1.0108 - val_acc: 0.5121\n",
            "Epoch 16/50 - 0.18s - loss: 0.9773 - acc: 0.5310 - val_loss: 1.0067 - val_acc: 0.5182\n",
            "Epoch 17/50 - 0.17s - loss: 0.9714 - acc: 0.5353 - val_loss: 1.0016 - val_acc: 0.5283\n",
            "Epoch 18/50 - 0.17s - loss: 0.9655 - acc: 0.5405 - val_loss: 0.9973 - val_acc: 0.5466\n",
            "Epoch 19/50 - 0.17s - loss: 0.9629 - acc: 0.5400 - val_loss: 0.9941 - val_acc: 0.5405\n",
            "Epoch 20/50 - 0.18s - loss: 0.9595 - acc: 0.5416 - val_loss: 0.9923 - val_acc: 0.5405\n",
            "Epoch 21/50 - 0.21s - loss: 0.9664 - acc: 0.5225 - val_loss: 1.0023 - val_acc: 0.5081\n",
            "Epoch 22/50 - 0.28s - loss: 0.9502 - acc: 0.5490 - val_loss: 0.9878 - val_acc: 0.5223\n",
            "Epoch 23/50 - 0.20s - loss: 0.9443 - acc: 0.5553 - val_loss: 0.9814 - val_acc: 0.5587\n",
            "Epoch 24/50 - 0.18s - loss: 0.9631 - acc: 0.5427 - val_loss: 0.9982 - val_acc: 0.5385\n",
            "Epoch 25/50 - 0.17s - loss: 0.9598 - acc: 0.5450 - val_loss: 0.9977 - val_acc: 0.5526\n",
            "Epoch 26/50 - 0.20s - loss: 0.9360 - acc: 0.5607 - val_loss: 0.9793 - val_acc: 0.5223\n",
            "Epoch 27/50 - 0.19s - loss: 0.9397 - acc: 0.5610 - val_loss: 0.9802 - val_acc: 0.5607\n",
            "Epoch 28/50 - 0.18s - loss: 0.9283 - acc: 0.5603 - val_loss: 0.9709 - val_acc: 0.5385\n",
            "Epoch 29/50 - 0.18s - loss: 0.9249 - acc: 0.5612 - val_loss: 0.9712 - val_acc: 0.5405\n",
            "Epoch 30/50 - 0.20s - loss: 0.9274 - acc: 0.5652 - val_loss: 0.9770 - val_acc: 0.5283\n",
            "Epoch 31/50 - 0.17s - loss: 0.9302 - acc: 0.5659 - val_loss: 0.9736 - val_acc: 0.5628\n",
            "Epoch 32/50 - 0.18s - loss: 0.9255 - acc: 0.5601 - val_loss: 0.9768 - val_acc: 0.5162\n",
            "Epoch 33/50 - 0.17s - loss: 0.9136 - acc: 0.5735 - val_loss: 0.9643 - val_acc: 0.5486\n",
            "Epoch 34/50 - 0.17s - loss: 0.9118 - acc: 0.5740 - val_loss: 0.9661 - val_acc: 0.5304\n",
            "Epoch 35/50 - 0.17s - loss: 0.9090 - acc: 0.5744 - val_loss: 0.9640 - val_acc: 0.5344\n",
            "Epoch 36/50 - 0.17s - loss: 0.9176 - acc: 0.5634 - val_loss: 0.9749 - val_acc: 0.5324\n",
            "Epoch 37/50 - 0.17s - loss: 0.9048 - acc: 0.5765 - val_loss: 0.9625 - val_acc: 0.5324\n",
            "Epoch 38/50 - 0.18s - loss: 0.9066 - acc: 0.5780 - val_loss: 0.9687 - val_acc: 0.5385\n",
            "Epoch 39/50 - 0.17s - loss: 0.9071 - acc: 0.5706 - val_loss: 0.9655 - val_acc: 0.5344\n",
            "Epoch 40/50 - 0.17s - loss: 0.9006 - acc: 0.5852 - val_loss: 0.9607 - val_acc: 0.5648\n",
            "Epoch 41/50 - 0.19s - loss: 0.9091 - acc: 0.5677 - val_loss: 0.9731 - val_acc: 0.5243\n",
            "Epoch 42/50 - 0.17s - loss: 0.9015 - acc: 0.5783 - val_loss: 0.9606 - val_acc: 0.5587\n",
            "Epoch 43/50 - 0.17s - loss: 0.8924 - acc: 0.5848 - val_loss: 0.9590 - val_acc: 0.5263\n",
            "Epoch 44/50 - 0.18s - loss: 0.9027 - acc: 0.5700 - val_loss: 0.9724 - val_acc: 0.5142\n",
            "Epoch 45/50 - 0.20s - loss: 0.9024 - acc: 0.5758 - val_loss: 0.9779 - val_acc: 0.5263\n",
            "Epoch 46/50 - 0.18s - loss: 0.8938 - acc: 0.5798 - val_loss: 0.9601 - val_acc: 0.5526\n",
            "Epoch 47/50 - 0.18s - loss: 0.8872 - acc: 0.5870 - val_loss: 0.9569 - val_acc: 0.5445\n",
            "Epoch 48/50 - 0.23s - loss: 0.8840 - acc: 0.5900 - val_loss: 0.9545 - val_acc: 0.5688\n",
            "Epoch 49/50 - 0.20s - loss: 0.8933 - acc: 0.5776 - val_loss: 0.9656 - val_acc: 0.5263\n",
            "Epoch 50/50 - 0.21s - loss: 0.8934 - acc: 0.5760 - val_loss: 0.9737 - val_acc: 0.5243\n",
            "\n",
            "Combination 128/252:\n",
            "Hidden Layers: [256, 128], Activation: tanh, Learning Rate: 0.01, Batch Size: 32, Epochs: 100\n",
            "Epoch 1/100 - 0.19s - loss: 1.0828 - acc: 0.4085 - val_loss: 1.0831 - val_acc: 0.4211\n",
            "Epoch 2/100 - 0.20s - loss: 1.0647 - acc: 0.4478 - val_loss: 1.0686 - val_acc: 0.4453\n",
            "Epoch 3/100 - 0.20s - loss: 1.0555 - acc: 0.4521 - val_loss: 1.0616 - val_acc: 0.4514\n",
            "Epoch 4/100 - 0.21s - loss: 1.0446 - acc: 0.4708 - val_loss: 1.0568 - val_acc: 0.4575\n",
            "Epoch 5/100 - 0.20s - loss: 1.0354 - acc: 0.4775 - val_loss: 1.0477 - val_acc: 0.4798\n",
            "Epoch 6/100 - 0.21s - loss: 1.0268 - acc: 0.4957 - val_loss: 1.0425 - val_acc: 0.4919\n",
            "Epoch 7/100 - 0.20s - loss: 1.0252 - acc: 0.4762 - val_loss: 1.0431 - val_acc: 0.5000\n",
            "Epoch 8/100 - 0.20s - loss: 1.0136 - acc: 0.4975 - val_loss: 1.0323 - val_acc: 0.5081\n",
            "Epoch 9/100 - 0.19s - loss: 1.0058 - acc: 0.5135 - val_loss: 1.0273 - val_acc: 0.5142\n",
            "Epoch 10/100 - 0.19s - loss: 1.0011 - acc: 0.5135 - val_loss: 1.0257 - val_acc: 0.5081\n",
            "Epoch 11/100 - 0.21s - loss: 0.9938 - acc: 0.5169 - val_loss: 1.0189 - val_acc: 0.5142\n",
            "Epoch 12/100 - 0.21s - loss: 0.9877 - acc: 0.5238 - val_loss: 1.0131 - val_acc: 0.5283\n",
            "Epoch 13/100 - 0.19s - loss: 0.9848 - acc: 0.5223 - val_loss: 1.0097 - val_acc: 0.5142\n",
            "Epoch 14/100 - 0.19s - loss: 0.9828 - acc: 0.5216 - val_loss: 1.0119 - val_acc: 0.5000\n",
            "Epoch 15/100 - 0.19s - loss: 0.9722 - acc: 0.5364 - val_loss: 1.0031 - val_acc: 0.5283\n",
            "Epoch 16/100 - 0.19s - loss: 0.9685 - acc: 0.5346 - val_loss: 1.0005 - val_acc: 0.5263\n",
            "Epoch 17/100 - 0.18s - loss: 0.9643 - acc: 0.5515 - val_loss: 0.9965 - val_acc: 0.5385\n",
            "Epoch 18/100 - 0.21s - loss: 0.9581 - acc: 0.5520 - val_loss: 0.9912 - val_acc: 0.5364\n",
            "Epoch 19/100 - 0.20s - loss: 0.9579 - acc: 0.5553 - val_loss: 0.9914 - val_acc: 0.5547\n",
            "Epoch 20/100 - 0.20s - loss: 0.9500 - acc: 0.5466 - val_loss: 0.9856 - val_acc: 0.5243\n",
            "Epoch 21/100 - 0.19s - loss: 0.9590 - acc: 0.5423 - val_loss: 0.9928 - val_acc: 0.5567\n",
            "Epoch 22/100 - 0.20s - loss: 0.9454 - acc: 0.5515 - val_loss: 0.9797 - val_acc: 0.5526\n",
            "Epoch 23/100 - 0.19s - loss: 0.9401 - acc: 0.5587 - val_loss: 0.9788 - val_acc: 0.5466\n",
            "Epoch 24/100 - 0.21s - loss: 0.9412 - acc: 0.5619 - val_loss: 0.9798 - val_acc: 0.5648\n",
            "Epoch 25/100 - 0.20s - loss: 0.9349 - acc: 0.5517 - val_loss: 0.9732 - val_acc: 0.5405\n",
            "Epoch 26/100 - 0.22s - loss: 0.9303 - acc: 0.5666 - val_loss: 0.9712 - val_acc: 0.5506\n",
            "Epoch 27/100 - 0.19s - loss: 0.9286 - acc: 0.5558 - val_loss: 0.9708 - val_acc: 0.5486\n",
            "Epoch 28/100 - 0.20s - loss: 0.9237 - acc: 0.5648 - val_loss: 0.9661 - val_acc: 0.5547\n",
            "Epoch 29/100 - 0.19s - loss: 0.9262 - acc: 0.5540 - val_loss: 0.9688 - val_acc: 0.5344\n",
            "Epoch 30/100 - 0.20s - loss: 0.9273 - acc: 0.5524 - val_loss: 0.9689 - val_acc: 0.5486\n",
            "Epoch 31/100 - 0.20s - loss: 0.9162 - acc: 0.5668 - val_loss: 0.9618 - val_acc: 0.5567\n",
            "Epoch 32/100 - 0.20s - loss: 0.9194 - acc: 0.5742 - val_loss: 0.9657 - val_acc: 0.5607\n",
            "Epoch 33/100 - 0.19s - loss: 0.9346 - acc: 0.5729 - val_loss: 0.9810 - val_acc: 0.5607\n",
            "Epoch 34/100 - 0.19s - loss: 0.9084 - acc: 0.5756 - val_loss: 0.9599 - val_acc: 0.5506\n",
            "Epoch 35/100 - 0.19s - loss: 0.9111 - acc: 0.5720 - val_loss: 0.9656 - val_acc: 0.5405\n",
            "Epoch 36/100 - 0.19s - loss: 0.9047 - acc: 0.5803 - val_loss: 0.9585 - val_acc: 0.5628\n",
            "Epoch 37/100 - 0.19s - loss: 0.9113 - acc: 0.5729 - val_loss: 0.9694 - val_acc: 0.5243\n",
            "Epoch 38/100 - 0.20s - loss: 0.9005 - acc: 0.5821 - val_loss: 0.9560 - val_acc: 0.5607\n",
            "Epoch 39/100 - 0.19s - loss: 0.9026 - acc: 0.5846 - val_loss: 0.9588 - val_acc: 0.5668\n",
            "Epoch 40/100 - 0.20s - loss: 0.9002 - acc: 0.5848 - val_loss: 0.9605 - val_acc: 0.5405\n",
            "Epoch 41/100 - 0.19s - loss: 0.8948 - acc: 0.5794 - val_loss: 0.9536 - val_acc: 0.5486\n",
            "Epoch 42/100 - 0.20s - loss: 0.8929 - acc: 0.5877 - val_loss: 0.9545 - val_acc: 0.5526\n",
            "Epoch 43/100 - 0.19s - loss: 0.9038 - acc: 0.5762 - val_loss: 0.9731 - val_acc: 0.5202\n",
            "Epoch 44/100 - 0.20s - loss: 0.8931 - acc: 0.5866 - val_loss: 0.9615 - val_acc: 0.5466\n",
            "Epoch 45/100 - 0.19s - loss: 0.8875 - acc: 0.5902 - val_loss: 0.9547 - val_acc: 0.5425\n",
            "Epoch 46/100 - 0.19s - loss: 0.8848 - acc: 0.5913 - val_loss: 0.9532 - val_acc: 0.5628\n",
            "Epoch 47/100 - 0.19s - loss: 0.8862 - acc: 0.5906 - val_loss: 0.9522 - val_acc: 0.5607\n",
            "Epoch 48/100 - 0.19s - loss: 0.9015 - acc: 0.5852 - val_loss: 0.9698 - val_acc: 0.5648\n",
            "Epoch 49/100 - 0.18s - loss: 0.8852 - acc: 0.5861 - val_loss: 0.9569 - val_acc: 0.5425\n",
            "Epoch 50/100 - 0.23s - loss: 0.9070 - acc: 0.5787 - val_loss: 0.9809 - val_acc: 0.5405\n",
            "Epoch 51/100 - 0.19s - loss: 0.9014 - acc: 0.5682 - val_loss: 0.9745 - val_acc: 0.5364\n",
            "Epoch 52/100 - 0.19s - loss: 0.8768 - acc: 0.5992 - val_loss: 0.9514 - val_acc: 0.5445\n",
            "Epoch 53/100 - 0.19s - loss: 0.8817 - acc: 0.5947 - val_loss: 0.9558 - val_acc: 0.5648\n",
            "Epoch 54/100 - 0.19s - loss: 0.8780 - acc: 0.5904 - val_loss: 0.9552 - val_acc: 0.5385\n",
            "Epoch 55/100 - 0.18s - loss: 0.8851 - acc: 0.5810 - val_loss: 0.9633 - val_acc: 0.5445\n",
            "Epoch 56/100 - 0.20s - loss: 0.8784 - acc: 0.5992 - val_loss: 0.9641 - val_acc: 0.5182\n",
            "Epoch 57/100 - 0.19s - loss: 0.8726 - acc: 0.5965 - val_loss: 0.9536 - val_acc: 0.5547\n",
            "Epoch 58/100 - 0.19s - loss: 0.8817 - acc: 0.5866 - val_loss: 0.9589 - val_acc: 0.5648\n",
            "Epoch 59/100 - 0.19s - loss: 0.8674 - acc: 0.6014 - val_loss: 0.9546 - val_acc: 0.5445\n",
            "Epoch 60/100 - 0.19s - loss: 0.8931 - acc: 0.5839 - val_loss: 0.9876 - val_acc: 0.5061\n",
            "Epoch 61/100 - 0.19s - loss: 0.8811 - acc: 0.5969 - val_loss: 0.9705 - val_acc: 0.5344\n",
            "Epoch 62/100 - 0.20s - loss: 0.8732 - acc: 0.5967 - val_loss: 0.9576 - val_acc: 0.5547\n",
            "Epoch 63/100 - 0.19s - loss: 0.8734 - acc: 0.6005 - val_loss: 0.9618 - val_acc: 0.5607\n",
            "Epoch 64/100 - 0.21s - loss: 0.8691 - acc: 0.5994 - val_loss: 0.9642 - val_acc: 0.5142\n",
            "Epoch 65/100 - 0.21s - loss: 0.8660 - acc: 0.6073 - val_loss: 0.9624 - val_acc: 0.5182\n",
            "Epoch 66/100 - 0.21s - loss: 0.8684 - acc: 0.5954 - val_loss: 0.9612 - val_acc: 0.5425\n",
            "Epoch 67/100 - 0.22s - loss: 0.8699 - acc: 0.5920 - val_loss: 0.9683 - val_acc: 0.5202\n",
            "Epoch 68/100 - 0.23s - loss: 0.8929 - acc: 0.5825 - val_loss: 0.9984 - val_acc: 0.4838\n",
            "Epoch 69/100 - 0.21s - loss: 0.8580 - acc: 0.6062 - val_loss: 0.9562 - val_acc: 0.5445\n",
            "Epoch 70/100 - 0.21s - loss: 0.8641 - acc: 0.6001 - val_loss: 0.9634 - val_acc: 0.5405\n",
            "Epoch 71/100 - 0.21s - loss: 0.8723 - acc: 0.5895 - val_loss: 0.9665 - val_acc: 0.5547\n",
            "Epoch 72/100 - 0.20s - loss: 0.8614 - acc: 0.6039 - val_loss: 0.9650 - val_acc: 0.5466\n",
            "Epoch 73/100 - 0.20s - loss: 0.8547 - acc: 0.6082 - val_loss: 0.9550 - val_acc: 0.5526\n",
            "Epoch 74/100 - 0.21s - loss: 0.8730 - acc: 0.5985 - val_loss: 0.9827 - val_acc: 0.5162\n",
            "Epoch 75/100 - 0.19s - loss: 0.8665 - acc: 0.5949 - val_loss: 0.9642 - val_acc: 0.5587\n",
            "Epoch 76/100 - 0.20s - loss: 0.8587 - acc: 0.6118 - val_loss: 0.9625 - val_acc: 0.5526\n",
            "Epoch 77/100 - 0.20s - loss: 0.8645 - acc: 0.6071 - val_loss: 0.9720 - val_acc: 0.5283\n",
            "Epoch 78/100 - 0.21s - loss: 0.8672 - acc: 0.5895 - val_loss: 0.9692 - val_acc: 0.5628\n",
            "Epoch 79/100 - 0.20s - loss: 0.8778 - acc: 0.5852 - val_loss: 0.9894 - val_acc: 0.5061\n",
            "Epoch 80/100 - 0.21s - loss: 0.8705 - acc: 0.5976 - val_loss: 0.9889 - val_acc: 0.5223\n",
            "Epoch 81/100 - 0.21s - loss: 0.8551 - acc: 0.6048 - val_loss: 0.9628 - val_acc: 0.5405\n",
            "Epoch 82/100 - 0.21s - loss: 0.8614 - acc: 0.5981 - val_loss: 0.9666 - val_acc: 0.5526\n",
            "Epoch 83/100 - 0.20s - loss: 0.8519 - acc: 0.6102 - val_loss: 0.9670 - val_acc: 0.5486\n",
            "Epoch 84/100 - 0.23s - loss: 0.8533 - acc: 0.6140 - val_loss: 0.9652 - val_acc: 0.5587\n",
            "Epoch 85/100 - 0.20s - loss: 0.8998 - acc: 0.5742 - val_loss: 0.9991 - val_acc: 0.5445\n",
            "Epoch 86/100 - 0.21s - loss: 0.8472 - acc: 0.6170 - val_loss: 0.9607 - val_acc: 0.5445\n",
            "Epoch 87/100 - 0.20s - loss: 0.8815 - acc: 0.5886 - val_loss: 1.0032 - val_acc: 0.5040\n",
            "Epoch 88/100 - 0.20s - loss: 0.8765 - acc: 0.5823 - val_loss: 0.9929 - val_acc: 0.5121\n",
            "Epoch 89/100 - 0.20s - loss: 0.8708 - acc: 0.5972 - val_loss: 0.9967 - val_acc: 0.5081\n",
            "Epoch 90/100 - 0.21s - loss: 0.8535 - acc: 0.6035 - val_loss: 0.9687 - val_acc: 0.5486\n",
            "Epoch 91/100 - 0.20s - loss: 0.8469 - acc: 0.6199 - val_loss: 0.9653 - val_acc: 0.5567\n",
            "Epoch 92/100 - 0.22s - loss: 0.8849 - acc: 0.5823 - val_loss: 1.0120 - val_acc: 0.4960\n",
            "Epoch 93/100 - 0.20s - loss: 0.8569 - acc: 0.6140 - val_loss: 0.9705 - val_acc: 0.5607\n",
            "Epoch 94/100 - 0.21s - loss: 0.8440 - acc: 0.6199 - val_loss: 0.9649 - val_acc: 0.5486\n",
            "Epoch 95/100 - 0.20s - loss: 0.8441 - acc: 0.6219 - val_loss: 0.9649 - val_acc: 0.5466\n",
            "Epoch 96/100 - 0.23s - loss: 0.8628 - acc: 0.6008 - val_loss: 0.9897 - val_acc: 0.5202\n",
            "Epoch 97/100 - 0.20s - loss: 0.8450 - acc: 0.6147 - val_loss: 0.9626 - val_acc: 0.5547\n",
            "Epoch 98/100 - 0.21s - loss: 0.8444 - acc: 0.6158 - val_loss: 0.9642 - val_acc: 0.5445\n",
            "Epoch 99/100 - 0.20s - loss: 0.8429 - acc: 0.6208 - val_loss: 0.9659 - val_acc: 0.5466\n",
            "Epoch 100/100 - 0.20s - loss: 0.8691 - acc: 0.5976 - val_loss: 1.0029 - val_acc: 0.5061\n",
            "\n",
            "Combination 129/252:\n",
            "Hidden Layers: [256, 128], Activation: tanh, Learning Rate: 0.01, Batch Size: 32, Epochs: 150\n",
            "Epoch 1/150 - 0.20s - loss: 1.0795 - acc: 0.3896 - val_loss: 1.0851 - val_acc: 0.3806\n",
            "Epoch 2/150 - 0.23s - loss: 1.0624 - acc: 0.4557 - val_loss: 1.0711 - val_acc: 0.4595\n",
            "Epoch 3/150 - 0.20s - loss: 1.0518 - acc: 0.4663 - val_loss: 1.0624 - val_acc: 0.4636\n",
            "Epoch 4/150 - 0.21s - loss: 1.0425 - acc: 0.4748 - val_loss: 1.0552 - val_acc: 0.4575\n",
            "Epoch 5/150 - 0.20s - loss: 1.0360 - acc: 0.4732 - val_loss: 1.0494 - val_acc: 0.4474\n",
            "Epoch 6/150 - 0.21s - loss: 1.0363 - acc: 0.4739 - val_loss: 1.0498 - val_acc: 0.4555\n",
            "Epoch 7/150 - 0.20s - loss: 1.0200 - acc: 0.4996 - val_loss: 1.0388 - val_acc: 0.4919\n",
            "Epoch 8/150 - 0.20s - loss: 1.0148 - acc: 0.4939 - val_loss: 1.0329 - val_acc: 0.4696\n",
            "Epoch 9/150 - 0.20s - loss: 1.0080 - acc: 0.5013 - val_loss: 1.0273 - val_acc: 0.5020\n",
            "Epoch 10/150 - 0.21s - loss: 1.0012 - acc: 0.5128 - val_loss: 1.0236 - val_acc: 0.5364\n",
            "Epoch 11/150 - 0.20s - loss: 0.9935 - acc: 0.5220 - val_loss: 1.0165 - val_acc: 0.5081\n",
            "Epoch 12/150 - 0.22s - loss: 0.9917 - acc: 0.5151 - val_loss: 1.0172 - val_acc: 0.4818\n",
            "Epoch 13/150 - 0.20s - loss: 0.9906 - acc: 0.5256 - val_loss: 1.0170 - val_acc: 0.5223\n",
            "Epoch 14/150 - 0.22s - loss: 0.9754 - acc: 0.5373 - val_loss: 1.0010 - val_acc: 0.5364\n",
            "Epoch 15/150 - 0.22s - loss: 0.9767 - acc: 0.5317 - val_loss: 1.0064 - val_acc: 0.5142\n",
            "Epoch 16/150 - 0.21s - loss: 0.9649 - acc: 0.5412 - val_loss: 0.9936 - val_acc: 0.5324\n",
            "Epoch 17/150 - 0.21s - loss: 0.9614 - acc: 0.5425 - val_loss: 0.9899 - val_acc: 0.5263\n",
            "Epoch 18/150 - 0.20s - loss: 0.9562 - acc: 0.5470 - val_loss: 0.9870 - val_acc: 0.5405\n",
            "Epoch 19/150 - 0.24s - loss: 0.9507 - acc: 0.5522 - val_loss: 0.9833 - val_acc: 0.5486\n",
            "Epoch 20/150 - 0.20s - loss: 0.9465 - acc: 0.5535 - val_loss: 0.9791 - val_acc: 0.5628\n",
            "Epoch 21/150 - 0.22s - loss: 0.9429 - acc: 0.5535 - val_loss: 0.9779 - val_acc: 0.5526\n",
            "Epoch 22/150 - 0.20s - loss: 0.9414 - acc: 0.5589 - val_loss: 0.9757 - val_acc: 0.5668\n",
            "Epoch 23/150 - 0.21s - loss: 0.9400 - acc: 0.5526 - val_loss: 0.9766 - val_acc: 0.5304\n",
            "Epoch 24/150 - 0.20s - loss: 0.9320 - acc: 0.5603 - val_loss: 0.9701 - val_acc: 0.5547\n",
            "Epoch 25/150 - 0.20s - loss: 0.9403 - acc: 0.5632 - val_loss: 0.9780 - val_acc: 0.5526\n",
            "Epoch 26/150 - 0.20s - loss: 0.9276 - acc: 0.5621 - val_loss: 0.9684 - val_acc: 0.5344\n",
            "Epoch 27/150 - 0.21s - loss: 0.9253 - acc: 0.5652 - val_loss: 0.9695 - val_acc: 0.5405\n",
            "Epoch 28/150 - 0.20s - loss: 0.9253 - acc: 0.5614 - val_loss: 0.9695 - val_acc: 0.5364\n",
            "Epoch 29/150 - 0.21s - loss: 0.9174 - acc: 0.5706 - val_loss: 0.9614 - val_acc: 0.5587\n",
            "Epoch 30/150 - 0.20s - loss: 0.9315 - acc: 0.5697 - val_loss: 0.9753 - val_acc: 0.5445\n",
            "Epoch 31/150 - 0.21s - loss: 0.9125 - acc: 0.5679 - val_loss: 0.9582 - val_acc: 0.5547\n",
            "Epoch 32/150 - 0.20s - loss: 0.9125 - acc: 0.5740 - val_loss: 0.9632 - val_acc: 0.5445\n",
            "Epoch 33/150 - 0.21s - loss: 0.9157 - acc: 0.5661 - val_loss: 0.9622 - val_acc: 0.5364\n",
            "Epoch 34/150 - 0.21s - loss: 0.9074 - acc: 0.5720 - val_loss: 0.9562 - val_acc: 0.5445\n",
            "Epoch 35/150 - 0.21s - loss: 0.9112 - acc: 0.5713 - val_loss: 0.9656 - val_acc: 0.5304\n",
            "Epoch 36/150 - 0.24s - loss: 0.9022 - acc: 0.5841 - val_loss: 0.9539 - val_acc: 0.5607\n",
            "Epoch 37/150 - 0.20s - loss: 0.9267 - acc: 0.5547 - val_loss: 0.9861 - val_acc: 0.5081\n",
            "Epoch 38/150 - 0.21s - loss: 0.9039 - acc: 0.5848 - val_loss: 0.9574 - val_acc: 0.5688\n",
            "Epoch 39/150 - 0.20s - loss: 0.9214 - acc: 0.5576 - val_loss: 0.9872 - val_acc: 0.5101\n",
            "Epoch 40/150 - 0.22s - loss: 0.8939 - acc: 0.5792 - val_loss: 0.9534 - val_acc: 0.5506\n",
            "Epoch 41/150 - 0.20s - loss: 0.8943 - acc: 0.5909 - val_loss: 0.9526 - val_acc: 0.5789\n",
            "Epoch 42/150 - 0.20s - loss: 0.8940 - acc: 0.5877 - val_loss: 0.9532 - val_acc: 0.5607\n",
            "Epoch 43/150 - 0.21s - loss: 0.8921 - acc: 0.5814 - val_loss: 0.9536 - val_acc: 0.5526\n",
            "Epoch 44/150 - 0.21s - loss: 0.8969 - acc: 0.5823 - val_loss: 0.9575 - val_acc: 0.5628\n",
            "Epoch 45/150 - 0.21s - loss: 0.8850 - acc: 0.5902 - val_loss: 0.9494 - val_acc: 0.5547\n",
            "Epoch 46/150 - 0.19s - loss: 0.9104 - acc: 0.5693 - val_loss: 0.9817 - val_acc: 0.5223\n",
            "Epoch 47/150 - 0.20s - loss: 0.8922 - acc: 0.5785 - val_loss: 0.9631 - val_acc: 0.5364\n",
            "Epoch 48/150 - 0.20s - loss: 0.9028 - acc: 0.5877 - val_loss: 0.9682 - val_acc: 0.5486\n",
            "Epoch 49/150 - 0.20s - loss: 0.8796 - acc: 0.5960 - val_loss: 0.9493 - val_acc: 0.5506\n",
            "Epoch 50/150 - 0.19s - loss: 0.8939 - acc: 0.5765 - val_loss: 0.9713 - val_acc: 0.5182\n",
            "Epoch 51/150 - 0.21s - loss: 0.8794 - acc: 0.5902 - val_loss: 0.9540 - val_acc: 0.5567\n",
            "Epoch 52/150 - 0.19s - loss: 0.8772 - acc: 0.6012 - val_loss: 0.9526 - val_acc: 0.5749\n",
            "Epoch 53/150 - 0.20s - loss: 0.8866 - acc: 0.5866 - val_loss: 0.9706 - val_acc: 0.5304\n",
            "Epoch 54/150 - 0.19s - loss: 0.8754 - acc: 0.6010 - val_loss: 0.9515 - val_acc: 0.5648\n",
            "Epoch 55/150 - 0.21s - loss: 0.8770 - acc: 0.5956 - val_loss: 0.9629 - val_acc: 0.5324\n",
            "Epoch 56/150 - 0.20s - loss: 0.8841 - acc: 0.5985 - val_loss: 0.9646 - val_acc: 0.5628\n",
            "Epoch 57/150 - 0.22s - loss: 0.8791 - acc: 0.5978 - val_loss: 0.9582 - val_acc: 0.5648\n",
            "Epoch 58/150 - 0.21s - loss: 0.9065 - acc: 0.5702 - val_loss: 0.9998 - val_acc: 0.4939\n",
            "Epoch 59/150 - 0.20s - loss: 0.8726 - acc: 0.5940 - val_loss: 0.9539 - val_acc: 0.5668\n",
            "Epoch 60/150 - 0.21s - loss: 0.8765 - acc: 0.5846 - val_loss: 0.9594 - val_acc: 0.5466\n",
            "Epoch 61/150 - 0.19s - loss: 0.8696 - acc: 0.5965 - val_loss: 0.9596 - val_acc: 0.5425\n",
            "Epoch 62/150 - 0.21s - loss: 0.8740 - acc: 0.5981 - val_loss: 0.9705 - val_acc: 0.5425\n",
            "Epoch 63/150 - 0.21s - loss: 0.8742 - acc: 0.5974 - val_loss: 0.9695 - val_acc: 0.5283\n",
            "Epoch 64/150 - 0.20s - loss: 0.8862 - acc: 0.5891 - val_loss: 0.9882 - val_acc: 0.5101\n",
            "Epoch 65/150 - 0.19s - loss: 0.8701 - acc: 0.5900 - val_loss: 0.9583 - val_acc: 0.5607\n",
            "Epoch 66/150 - 0.19s - loss: 0.8605 - acc: 0.6044 - val_loss: 0.9553 - val_acc: 0.5445\n",
            "Epoch 67/150 - 0.19s - loss: 0.8669 - acc: 0.5940 - val_loss: 0.9647 - val_acc: 0.5364\n",
            "Epoch 68/150 - 0.21s - loss: 0.8617 - acc: 0.6068 - val_loss: 0.9562 - val_acc: 0.5628\n",
            "Epoch 69/150 - 0.20s - loss: 0.8700 - acc: 0.5924 - val_loss: 0.9667 - val_acc: 0.5445\n",
            "Epoch 70/150 - 0.20s - loss: 0.8797 - acc: 0.5909 - val_loss: 0.9807 - val_acc: 0.5506\n",
            "Epoch 71/150 - 0.19s - loss: 0.8948 - acc: 0.5832 - val_loss: 0.9839 - val_acc: 0.5628\n",
            "Epoch 72/150 - 0.19s - loss: 0.8664 - acc: 0.6035 - val_loss: 0.9633 - val_acc: 0.5607\n",
            "Epoch 73/150 - 0.19s - loss: 0.8627 - acc: 0.6134 - val_loss: 0.9674 - val_acc: 0.5425\n",
            "Epoch 74/150 - 0.20s - loss: 0.8801 - acc: 0.5823 - val_loss: 0.9835 - val_acc: 0.5304\n",
            "Epoch 75/150 - 0.18s - loss: 0.8734 - acc: 0.5969 - val_loss: 0.9811 - val_acc: 0.5364\n",
            "Epoch 76/150 - 0.21s - loss: 0.8656 - acc: 0.6089 - val_loss: 0.9711 - val_acc: 0.5364\n",
            "Epoch 77/150 - 0.20s - loss: 0.8581 - acc: 0.6116 - val_loss: 0.9634 - val_acc: 0.5486\n",
            "Epoch 78/150 - 0.22s - loss: 0.8684 - acc: 0.5994 - val_loss: 0.9686 - val_acc: 0.5547\n",
            "Epoch 79/150 - 0.19s - loss: 0.8874 - acc: 0.5803 - val_loss: 0.9835 - val_acc: 0.5506\n",
            "Epoch 80/150 - 0.20s - loss: 0.8653 - acc: 0.6082 - val_loss: 0.9736 - val_acc: 0.5547\n",
            "Epoch 81/150 - 0.19s - loss: 0.8551 - acc: 0.5992 - val_loss: 0.9659 - val_acc: 0.5445\n",
            "Epoch 82/150 - 0.21s - loss: 0.8628 - acc: 0.6066 - val_loss: 0.9654 - val_acc: 0.5547\n",
            "Epoch 83/150 - 0.20s - loss: 0.8552 - acc: 0.6071 - val_loss: 0.9689 - val_acc: 0.5486\n",
            "Epoch 84/150 - 0.20s - loss: 0.8587 - acc: 0.6032 - val_loss: 0.9659 - val_acc: 0.5628\n",
            "Epoch 85/150 - 0.21s - loss: 0.8692 - acc: 0.5949 - val_loss: 0.9881 - val_acc: 0.5223\n",
            "Epoch 86/150 - 0.19s - loss: 0.8516 - acc: 0.6068 - val_loss: 0.9628 - val_acc: 0.5425\n",
            "Epoch 87/150 - 0.19s - loss: 0.8501 - acc: 0.6118 - val_loss: 0.9670 - val_acc: 0.5425\n",
            "Epoch 88/150 - 0.23s - loss: 0.8757 - acc: 0.5875 - val_loss: 0.9837 - val_acc: 0.5405\n",
            "Epoch 89/150 - 0.19s - loss: 0.8537 - acc: 0.6091 - val_loss: 0.9749 - val_acc: 0.5405\n",
            "Epoch 90/150 - 0.19s - loss: 0.8539 - acc: 0.6118 - val_loss: 0.9757 - val_acc: 0.5344\n",
            "Epoch 91/150 - 0.20s - loss: 0.8658 - acc: 0.5933 - val_loss: 0.9709 - val_acc: 0.5648\n",
            "Epoch 92/150 - 0.19s - loss: 0.8528 - acc: 0.6111 - val_loss: 0.9730 - val_acc: 0.5445\n",
            "Epoch 93/150 - 0.18s - loss: 0.8530 - acc: 0.6084 - val_loss: 0.9752 - val_acc: 0.5486\n",
            "Epoch 94/150 - 0.19s - loss: 0.8643 - acc: 0.5963 - val_loss: 0.9828 - val_acc: 0.5243\n",
            "Epoch 95/150 - 0.18s - loss: 0.8499 - acc: 0.6131 - val_loss: 0.9727 - val_acc: 0.5304\n",
            "Epoch 96/150 - 0.19s - loss: 0.8680 - acc: 0.5931 - val_loss: 0.9781 - val_acc: 0.5587\n",
            "Epoch 97/150 - 0.18s - loss: 0.8527 - acc: 0.6129 - val_loss: 0.9666 - val_acc: 0.5466\n",
            "Epoch 98/150 - 0.20s - loss: 0.9158 - acc: 0.5628 - val_loss: 1.0475 - val_acc: 0.4818\n",
            "Epoch 99/150 - 0.18s - loss: 0.8587 - acc: 0.6131 - val_loss: 0.9835 - val_acc: 0.5486\n",
            "Epoch 100/150 - 0.19s - loss: 0.8449 - acc: 0.6107 - val_loss: 0.9697 - val_acc: 0.5526\n",
            "Epoch 101/150 - 0.18s - loss: 0.8439 - acc: 0.6122 - val_loss: 0.9657 - val_acc: 0.5567\n",
            "Epoch 102/150 - 0.19s - loss: 0.8415 - acc: 0.6140 - val_loss: 0.9662 - val_acc: 0.5567\n",
            "Epoch 103/150 - 0.19s - loss: 0.8497 - acc: 0.6125 - val_loss: 0.9814 - val_acc: 0.5344\n",
            "Epoch 104/150 - 0.20s - loss: 0.8441 - acc: 0.6149 - val_loss: 0.9731 - val_acc: 0.5364\n",
            "Epoch 105/150 - 0.18s - loss: 0.8736 - acc: 0.5882 - val_loss: 0.9908 - val_acc: 0.5385\n",
            "Epoch 106/150 - 0.19s - loss: 0.8508 - acc: 0.6179 - val_loss: 0.9740 - val_acc: 0.5526\n",
            "Epoch 107/150 - 0.18s - loss: 0.8535 - acc: 0.6019 - val_loss: 0.9857 - val_acc: 0.5202\n",
            "Epoch 108/150 - 0.21s - loss: 0.8882 - acc: 0.5857 - val_loss: 1.0259 - val_acc: 0.5020\n",
            "Epoch 109/150 - 0.18s - loss: 0.8538 - acc: 0.6221 - val_loss: 0.9793 - val_acc: 0.5567\n",
            "Epoch 110/150 - 0.19s - loss: 0.8389 - acc: 0.6167 - val_loss: 0.9645 - val_acc: 0.5547\n",
            "Epoch 111/150 - 0.19s - loss: 0.8501 - acc: 0.6066 - val_loss: 0.9692 - val_acc: 0.5526\n",
            "Epoch 112/150 - 0.19s - loss: 0.8433 - acc: 0.6203 - val_loss: 0.9679 - val_acc: 0.5607\n",
            "Epoch 113/150 - 0.19s - loss: 0.8500 - acc: 0.6075 - val_loss: 0.9762 - val_acc: 0.5405\n",
            "Epoch 114/150 - 0.20s - loss: 0.8415 - acc: 0.6129 - val_loss: 0.9715 - val_acc: 0.5547\n",
            "Epoch 115/150 - 0.19s - loss: 0.8611 - acc: 0.6138 - val_loss: 0.9930 - val_acc: 0.5445\n",
            "Epoch 116/150 - 0.19s - loss: 0.8435 - acc: 0.6109 - val_loss: 0.9677 - val_acc: 0.5506\n",
            "Epoch 117/150 - 0.19s - loss: 0.8608 - acc: 0.6026 - val_loss: 0.9989 - val_acc: 0.5142\n",
            "Epoch 118/150 - 0.19s - loss: 0.8521 - acc: 0.6203 - val_loss: 0.9790 - val_acc: 0.5607\n",
            "Epoch 119/150 - 0.19s - loss: 0.8743 - acc: 0.5864 - val_loss: 1.0099 - val_acc: 0.5040\n",
            "Epoch 120/150 - 0.19s - loss: 0.8418 - acc: 0.6269 - val_loss: 0.9719 - val_acc: 0.5709\n",
            "Epoch 121/150 - 0.18s - loss: 0.8474 - acc: 0.6125 - val_loss: 0.9747 - val_acc: 0.5486\n",
            "Epoch 122/150 - 0.19s - loss: 0.8454 - acc: 0.6113 - val_loss: 0.9739 - val_acc: 0.5486\n",
            "Epoch 123/150 - 0.18s - loss: 0.8466 - acc: 0.6244 - val_loss: 0.9767 - val_acc: 0.5547\n",
            "Epoch 124/150 - 0.20s - loss: 0.8393 - acc: 0.6269 - val_loss: 0.9708 - val_acc: 0.5567\n",
            "Epoch 125/150 - 0.18s - loss: 0.8614 - acc: 0.5954 - val_loss: 0.9820 - val_acc: 0.5628\n",
            "Epoch 126/150 - 0.19s - loss: 0.8445 - acc: 0.6181 - val_loss: 0.9809 - val_acc: 0.5344\n",
            "Epoch 127/150 - 0.19s - loss: 0.9261 - acc: 0.5526 - val_loss: 1.0645 - val_acc: 0.5000\n",
            "Epoch 128/150 - 0.22s - loss: 0.8413 - acc: 0.6138 - val_loss: 0.9788 - val_acc: 0.5405\n",
            "Epoch 129/150 - 0.18s - loss: 0.8359 - acc: 0.6192 - val_loss: 0.9726 - val_acc: 0.5425\n",
            "Epoch 130/150 - 0.19s - loss: 0.8368 - acc: 0.6199 - val_loss: 0.9678 - val_acc: 0.5688\n",
            "Epoch 131/150 - 0.18s - loss: 0.8418 - acc: 0.6206 - val_loss: 0.9720 - val_acc: 0.5486\n",
            "Epoch 132/150 - 0.18s - loss: 0.8461 - acc: 0.6095 - val_loss: 0.9838 - val_acc: 0.5304\n",
            "Epoch 133/150 - 0.18s - loss: 0.8902 - acc: 0.5846 - val_loss: 1.0432 - val_acc: 0.4838\n",
            "Epoch 134/150 - 0.19s - loss: 0.8382 - acc: 0.6197 - val_loss: 0.9692 - val_acc: 0.5567\n",
            "Epoch 135/150 - 0.18s - loss: 0.8388 - acc: 0.6194 - val_loss: 0.9783 - val_acc: 0.5466\n",
            "Epoch 136/150 - 0.19s - loss: 0.8394 - acc: 0.6253 - val_loss: 0.9730 - val_acc: 0.5567\n",
            "Epoch 137/150 - 0.18s - loss: 0.8349 - acc: 0.6190 - val_loss: 0.9664 - val_acc: 0.5486\n",
            "Epoch 138/150 - 0.19s - loss: 0.8680 - acc: 0.5996 - val_loss: 0.9927 - val_acc: 0.5506\n",
            "Epoch 139/150 - 0.18s - loss: 0.8485 - acc: 0.6082 - val_loss: 0.9921 - val_acc: 0.5202\n",
            "Epoch 140/150 - 0.19s - loss: 0.8706 - acc: 0.5875 - val_loss: 1.0148 - val_acc: 0.5142\n",
            "Epoch 141/150 - 0.18s - loss: 0.8600 - acc: 0.6037 - val_loss: 1.0077 - val_acc: 0.5162\n",
            "Epoch 142/150 - 0.20s - loss: 0.8324 - acc: 0.6219 - val_loss: 0.9739 - val_acc: 0.5567\n",
            "Epoch 143/150 - 0.19s - loss: 0.8427 - acc: 0.6260 - val_loss: 0.9841 - val_acc: 0.5506\n",
            "Epoch 144/150 - 0.20s - loss: 0.8549 - acc: 0.6035 - val_loss: 0.9864 - val_acc: 0.5587\n",
            "Epoch 145/150 - 0.20s - loss: 0.8344 - acc: 0.6235 - val_loss: 0.9709 - val_acc: 0.5425\n",
            "Epoch 146/150 - 0.19s - loss: 0.8307 - acc: 0.6251 - val_loss: 0.9658 - val_acc: 0.5607\n",
            "Epoch 147/150 - 0.22s - loss: 0.8527 - acc: 0.6091 - val_loss: 1.0021 - val_acc: 0.5182\n",
            "Epoch 148/150 - 0.19s - loss: 0.8281 - acc: 0.6246 - val_loss: 0.9682 - val_acc: 0.5607\n",
            "Epoch 149/150 - 0.19s - loss: 0.8383 - acc: 0.6179 - val_loss: 0.9723 - val_acc: 0.5506\n",
            "Epoch 150/150 - 0.18s - loss: 0.8291 - acc: 0.6246 - val_loss: 0.9666 - val_acc: 0.5709\n",
            "\n",
            "Combination 130/252:\n",
            "Hidden Layers: [256, 128], Activation: tanh, Learning Rate: 0.01, Batch Size: 64, Epochs: 50\n",
            "Epoch 1/50 - 0.16s - loss: 1.0927 - acc: 0.3668 - val_loss: 1.0943 - val_acc: 0.3644\n",
            "Epoch 2/50 - 0.15s - loss: 1.0835 - acc: 0.4044 - val_loss: 1.0868 - val_acc: 0.3866\n",
            "Epoch 3/50 - 0.16s - loss: 1.0796 - acc: 0.3893 - val_loss: 1.0871 - val_acc: 0.3725\n",
            "Epoch 4/50 - 0.15s - loss: 1.0701 - acc: 0.4260 - val_loss: 1.0773 - val_acc: 0.3887\n",
            "Epoch 5/50 - 0.16s - loss: 1.0642 - acc: 0.4395 - val_loss: 1.0723 - val_acc: 0.4312\n",
            "Epoch 6/50 - 0.17s - loss: 1.0607 - acc: 0.4444 - val_loss: 1.0691 - val_acc: 0.4150\n",
            "Epoch 7/50 - 0.18s - loss: 1.0547 - acc: 0.4521 - val_loss: 1.0654 - val_acc: 0.4494\n",
            "Epoch 8/50 - 0.15s - loss: 1.0503 - acc: 0.4604 - val_loss: 1.0620 - val_acc: 0.4372\n",
            "Epoch 9/50 - 0.16s - loss: 1.0464 - acc: 0.4606 - val_loss: 1.0602 - val_acc: 0.4352\n",
            "Epoch 10/50 - 0.15s - loss: 1.0425 - acc: 0.4658 - val_loss: 1.0564 - val_acc: 0.4656\n",
            "Epoch 11/50 - 0.15s - loss: 1.0391 - acc: 0.4676 - val_loss: 1.0541 - val_acc: 0.4494\n",
            "Epoch 12/50 - 0.15s - loss: 1.0351 - acc: 0.4721 - val_loss: 1.0508 - val_acc: 0.4575\n",
            "Epoch 13/50 - 0.16s - loss: 1.0319 - acc: 0.4789 - val_loss: 1.0500 - val_acc: 0.4676\n",
            "Epoch 14/50 - 0.15s - loss: 1.0284 - acc: 0.4784 - val_loss: 1.0471 - val_acc: 0.4737\n",
            "Epoch 15/50 - 0.16s - loss: 1.0254 - acc: 0.4870 - val_loss: 1.0437 - val_acc: 0.4757\n",
            "Epoch 16/50 - 0.15s - loss: 1.0228 - acc: 0.4948 - val_loss: 1.0436 - val_acc: 0.4798\n",
            "Epoch 17/50 - 0.17s - loss: 1.0188 - acc: 0.4964 - val_loss: 1.0392 - val_acc: 0.4757\n",
            "Epoch 18/50 - 0.15s - loss: 1.0151 - acc: 0.4921 - val_loss: 1.0372 - val_acc: 0.4879\n",
            "Epoch 19/50 - 0.15s - loss: 1.0114 - acc: 0.4966 - val_loss: 1.0340 - val_acc: 0.4960\n",
            "Epoch 20/50 - 0.15s - loss: 1.0080 - acc: 0.5029 - val_loss: 1.0309 - val_acc: 0.4980\n",
            "Epoch 21/50 - 0.16s - loss: 1.0049 - acc: 0.5038 - val_loss: 1.0284 - val_acc: 0.5000\n",
            "Epoch 22/50 - 0.15s - loss: 1.0028 - acc: 0.5133 - val_loss: 1.0274 - val_acc: 0.4980\n",
            "Epoch 23/50 - 0.15s - loss: 0.9992 - acc: 0.5099 - val_loss: 1.0249 - val_acc: 0.5101\n",
            "Epoch 24/50 - 0.15s - loss: 0.9957 - acc: 0.5112 - val_loss: 1.0218 - val_acc: 0.5162\n",
            "Epoch 25/50 - 0.16s - loss: 0.9927 - acc: 0.5139 - val_loss: 1.0193 - val_acc: 0.5243\n",
            "Epoch 26/50 - 0.16s - loss: 0.9898 - acc: 0.5173 - val_loss: 1.0163 - val_acc: 0.5101\n",
            "Epoch 27/50 - 0.17s - loss: 0.9881 - acc: 0.5202 - val_loss: 1.0161 - val_acc: 0.5223\n",
            "Epoch 28/50 - 0.16s - loss: 0.9871 - acc: 0.5218 - val_loss: 1.0163 - val_acc: 0.4939\n",
            "Epoch 29/50 - 0.16s - loss: 0.9810 - acc: 0.5256 - val_loss: 1.0090 - val_acc: 0.5243\n",
            "Epoch 30/50 - 0.15s - loss: 0.9792 - acc: 0.5265 - val_loss: 1.0087 - val_acc: 0.5304\n",
            "Epoch 31/50 - 0.16s - loss: 0.9763 - acc: 0.5283 - val_loss: 1.0060 - val_acc: 0.5344\n",
            "Epoch 32/50 - 0.15s - loss: 0.9756 - acc: 0.5315 - val_loss: 1.0058 - val_acc: 0.5182\n",
            "Epoch 33/50 - 0.16s - loss: 0.9760 - acc: 0.5295 - val_loss: 1.0081 - val_acc: 0.5202\n",
            "Epoch 34/50 - 0.15s - loss: 0.9677 - acc: 0.5340 - val_loss: 0.9983 - val_acc: 0.5405\n",
            "Epoch 35/50 - 0.16s - loss: 0.9664 - acc: 0.5342 - val_loss: 0.9973 - val_acc: 0.5466\n",
            "Epoch 36/50 - 0.15s - loss: 0.9786 - acc: 0.5139 - val_loss: 1.0101 - val_acc: 0.4858\n",
            "Epoch 37/50 - 0.18s - loss: 0.9619 - acc: 0.5412 - val_loss: 0.9930 - val_acc: 0.5466\n",
            "Epoch 38/50 - 0.15s - loss: 0.9583 - acc: 0.5412 - val_loss: 0.9912 - val_acc: 0.5466\n",
            "Epoch 39/50 - 0.16s - loss: 0.9565 - acc: 0.5443 - val_loss: 0.9890 - val_acc: 0.5526\n",
            "Epoch 40/50 - 0.14s - loss: 0.9568 - acc: 0.5416 - val_loss: 0.9915 - val_acc: 0.5425\n",
            "Epoch 41/50 - 0.15s - loss: 0.9526 - acc: 0.5403 - val_loss: 0.9871 - val_acc: 0.5506\n",
            "Epoch 42/50 - 0.15s - loss: 0.9543 - acc: 0.5409 - val_loss: 0.9879 - val_acc: 0.5466\n",
            "Epoch 43/50 - 0.16s - loss: 0.9597 - acc: 0.5335 - val_loss: 0.9965 - val_acc: 0.5081\n",
            "Epoch 44/50 - 0.15s - loss: 0.9473 - acc: 0.5477 - val_loss: 0.9806 - val_acc: 0.5526\n",
            "Epoch 45/50 - 0.16s - loss: 0.9571 - acc: 0.5335 - val_loss: 0.9937 - val_acc: 0.5081\n",
            "Epoch 46/50 - 0.15s - loss: 0.9413 - acc: 0.5504 - val_loss: 0.9777 - val_acc: 0.5628\n",
            "Epoch 47/50 - 0.15s - loss: 0.9462 - acc: 0.5448 - val_loss: 0.9807 - val_acc: 0.5526\n",
            "Epoch 48/50 - 0.15s - loss: 0.9381 - acc: 0.5562 - val_loss: 0.9746 - val_acc: 0.5769\n",
            "Epoch 49/50 - 0.16s - loss: 0.9393 - acc: 0.5517 - val_loss: 0.9766 - val_acc: 0.5567\n",
            "Epoch 50/50 - 0.15s - loss: 0.9376 - acc: 0.5522 - val_loss: 0.9757 - val_acc: 0.5526\n",
            "\n",
            "Combination 131/252:\n",
            "Hidden Layers: [256, 128], Activation: tanh, Learning Rate: 0.01, Batch Size: 64, Epochs: 100\n",
            "Epoch 1/100 - 0.16s - loss: 1.0887 - acc: 0.4127 - val_loss: 1.0862 - val_acc: 0.3826\n",
            "Epoch 2/100 - 0.17s - loss: 1.0798 - acc: 0.4071 - val_loss: 1.0791 - val_acc: 0.4089\n",
            "Epoch 3/100 - 0.16s - loss: 1.0720 - acc: 0.4269 - val_loss: 1.0732 - val_acc: 0.4089\n",
            "Epoch 4/100 - 0.15s - loss: 1.0660 - acc: 0.4471 - val_loss: 1.0693 - val_acc: 0.4352\n",
            "Epoch 5/100 - 0.16s - loss: 1.0603 - acc: 0.4552 - val_loss: 1.0640 - val_acc: 0.4393\n",
            "Epoch 6/100 - 0.15s - loss: 1.0552 - acc: 0.4584 - val_loss: 1.0610 - val_acc: 0.4372\n",
            "Epoch 7/100 - 0.18s - loss: 1.0500 - acc: 0.4692 - val_loss: 1.0571 - val_acc: 0.4413\n",
            "Epoch 8/100 - 0.15s - loss: 1.0452 - acc: 0.4694 - val_loss: 1.0540 - val_acc: 0.4636\n",
            "Epoch 9/100 - 0.15s - loss: 1.0410 - acc: 0.4714 - val_loss: 1.0514 - val_acc: 0.4636\n",
            "Epoch 10/100 - 0.15s - loss: 1.0402 - acc: 0.4658 - val_loss: 1.0503 - val_acc: 0.4676\n",
            "Epoch 11/100 - 0.16s - loss: 1.0327 - acc: 0.4852 - val_loss: 1.0452 - val_acc: 0.4615\n",
            "Epoch 12/100 - 0.15s - loss: 1.0310 - acc: 0.4892 - val_loss: 1.0431 - val_acc: 0.4717\n",
            "Epoch 13/100 - 0.16s - loss: 1.0268 - acc: 0.4811 - val_loss: 1.0428 - val_acc: 0.4757\n",
            "Epoch 14/100 - 0.15s - loss: 1.0209 - acc: 0.4960 - val_loss: 1.0373 - val_acc: 0.4939\n",
            "Epoch 15/100 - 0.16s - loss: 1.0174 - acc: 0.4960 - val_loss: 1.0347 - val_acc: 0.4939\n",
            "Epoch 16/100 - 0.15s - loss: 1.0141 - acc: 0.5009 - val_loss: 1.0327 - val_acc: 0.4980\n",
            "Epoch 17/100 - 0.17s - loss: 1.0117 - acc: 0.5029 - val_loss: 1.0314 - val_acc: 0.4818\n",
            "Epoch 18/100 - 0.15s - loss: 1.0083 - acc: 0.5013 - val_loss: 1.0294 - val_acc: 0.5182\n",
            "Epoch 19/100 - 0.16s - loss: 1.0045 - acc: 0.5061 - val_loss: 1.0254 - val_acc: 0.4919\n",
            "Epoch 20/100 - 0.15s - loss: 1.0011 - acc: 0.5083 - val_loss: 1.0239 - val_acc: 0.5101\n",
            "Epoch 21/100 - 0.15s - loss: 0.9978 - acc: 0.5101 - val_loss: 1.0214 - val_acc: 0.5223\n",
            "Epoch 22/100 - 0.15s - loss: 0.9950 - acc: 0.5128 - val_loss: 1.0193 - val_acc: 0.5081\n",
            "Epoch 23/100 - 0.16s - loss: 0.9931 - acc: 0.5214 - val_loss: 1.0161 - val_acc: 0.5304\n",
            "Epoch 24/100 - 0.15s - loss: 0.9897 - acc: 0.5148 - val_loss: 1.0146 - val_acc: 0.5040\n",
            "Epoch 25/100 - 0.16s - loss: 0.9863 - acc: 0.5220 - val_loss: 1.0121 - val_acc: 0.5202\n",
            "Epoch 26/100 - 0.15s - loss: 0.9832 - acc: 0.5270 - val_loss: 1.0081 - val_acc: 0.5405\n",
            "Epoch 27/100 - 0.16s - loss: 0.9807 - acc: 0.5272 - val_loss: 1.0074 - val_acc: 0.5182\n",
            "Epoch 28/100 - 0.17s - loss: 0.9794 - acc: 0.5272 - val_loss: 1.0069 - val_acc: 0.5182\n",
            "Epoch 29/100 - 0.16s - loss: 0.9772 - acc: 0.5342 - val_loss: 1.0041 - val_acc: 0.5526\n",
            "Epoch 30/100 - 0.15s - loss: 0.9802 - acc: 0.5250 - val_loss: 1.0090 - val_acc: 0.4899\n",
            "Epoch 31/100 - 0.16s - loss: 0.9709 - acc: 0.5367 - val_loss: 0.9993 - val_acc: 0.5587\n",
            "Epoch 32/100 - 0.15s - loss: 0.9683 - acc: 0.5358 - val_loss: 0.9980 - val_acc: 0.5405\n",
            "Epoch 33/100 - 0.16s - loss: 0.9660 - acc: 0.5378 - val_loss: 0.9963 - val_acc: 0.5324\n",
            "Epoch 34/100 - 0.15s - loss: 0.9642 - acc: 0.5380 - val_loss: 0.9953 - val_acc: 0.5324\n",
            "Epoch 35/100 - 0.16s - loss: 0.9649 - acc: 0.5310 - val_loss: 0.9975 - val_acc: 0.5081\n",
            "Epoch 36/100 - 0.15s - loss: 0.9587 - acc: 0.5470 - val_loss: 0.9897 - val_acc: 0.5506\n",
            "Epoch 37/100 - 0.16s - loss: 0.9642 - acc: 0.5387 - val_loss: 0.9952 - val_acc: 0.5486\n",
            "Epoch 38/100 - 0.15s - loss: 0.9589 - acc: 0.5436 - val_loss: 0.9915 - val_acc: 0.5223\n",
            "Epoch 39/100 - 0.15s - loss: 0.9521 - acc: 0.5515 - val_loss: 0.9846 - val_acc: 0.5567\n",
            "Epoch 40/100 - 0.15s - loss: 0.9530 - acc: 0.5522 - val_loss: 0.9856 - val_acc: 0.5688\n",
            "Epoch 41/100 - 0.16s - loss: 0.9495 - acc: 0.5493 - val_loss: 0.9823 - val_acc: 0.5648\n",
            "Epoch 42/100 - 0.15s - loss: 0.9476 - acc: 0.5506 - val_loss: 0.9815 - val_acc: 0.5304\n",
            "Epoch 43/100 - 0.16s - loss: 0.9446 - acc: 0.5560 - val_loss: 0.9791 - val_acc: 0.5466\n",
            "Epoch 44/100 - 0.15s - loss: 0.9466 - acc: 0.5524 - val_loss: 0.9814 - val_acc: 0.5344\n",
            "Epoch 45/100 - 0.16s - loss: 0.9500 - acc: 0.5454 - val_loss: 0.9871 - val_acc: 0.5182\n",
            "Epoch 46/100 - 0.15s - loss: 0.9419 - acc: 0.5553 - val_loss: 0.9758 - val_acc: 0.5607\n",
            "Epoch 47/100 - 0.19s - loss: 0.9373 - acc: 0.5601 - val_loss: 0.9750 - val_acc: 0.5445\n",
            "Epoch 48/100 - 0.15s - loss: 0.9557 - acc: 0.5362 - val_loss: 0.9952 - val_acc: 0.4960\n",
            "Epoch 49/100 - 0.16s - loss: 0.9362 - acc: 0.5542 - val_loss: 0.9742 - val_acc: 0.5628\n",
            "Epoch 50/100 - 0.15s - loss: 0.9359 - acc: 0.5524 - val_loss: 0.9715 - val_acc: 0.5547\n",
            "Epoch 51/100 - 0.16s - loss: 0.9307 - acc: 0.5623 - val_loss: 0.9688 - val_acc: 0.5607\n",
            "Epoch 52/100 - 0.15s - loss: 0.9345 - acc: 0.5587 - val_loss: 0.9717 - val_acc: 0.5668\n",
            "Epoch 53/100 - 0.16s - loss: 0.9341 - acc: 0.5574 - val_loss: 0.9754 - val_acc: 0.5304\n",
            "Epoch 54/100 - 0.15s - loss: 0.9276 - acc: 0.5639 - val_loss: 0.9660 - val_acc: 0.5628\n",
            "Epoch 55/100 - 0.16s - loss: 0.9241 - acc: 0.5655 - val_loss: 0.9656 - val_acc: 0.5445\n",
            "Epoch 56/100 - 0.15s - loss: 0.9234 - acc: 0.5673 - val_loss: 0.9660 - val_acc: 0.5425\n",
            "Epoch 57/100 - 0.16s - loss: 0.9259 - acc: 0.5578 - val_loss: 0.9681 - val_acc: 0.5324\n",
            "Epoch 58/100 - 0.15s - loss: 0.9201 - acc: 0.5717 - val_loss: 0.9623 - val_acc: 0.5648\n",
            "Epoch 59/100 - 0.16s - loss: 0.9225 - acc: 0.5634 - val_loss: 0.9693 - val_acc: 0.5324\n",
            "Epoch 60/100 - 0.15s - loss: 0.9229 - acc: 0.5715 - val_loss: 0.9664 - val_acc: 0.5587\n",
            "Epoch 61/100 - 0.16s - loss: 0.9153 - acc: 0.5700 - val_loss: 0.9589 - val_acc: 0.5628\n",
            "Epoch 62/100 - 0.15s - loss: 0.9202 - acc: 0.5684 - val_loss: 0.9672 - val_acc: 0.5385\n",
            "Epoch 63/100 - 0.15s - loss: 0.9372 - acc: 0.5502 - val_loss: 0.9863 - val_acc: 0.5182\n",
            "Epoch 64/100 - 0.15s - loss: 0.9254 - acc: 0.5684 - val_loss: 0.9686 - val_acc: 0.5789\n",
            "Epoch 65/100 - 0.16s - loss: 0.9133 - acc: 0.5758 - val_loss: 0.9595 - val_acc: 0.5607\n",
            "Epoch 66/100 - 0.15s - loss: 0.9115 - acc: 0.5702 - val_loss: 0.9611 - val_acc: 0.5223\n",
            "Epoch 67/100 - 0.18s - loss: 0.9249 - acc: 0.5571 - val_loss: 0.9783 - val_acc: 0.5101\n",
            "Epoch 68/100 - 0.15s - loss: 0.9071 - acc: 0.5810 - val_loss: 0.9558 - val_acc: 0.5628\n",
            "Epoch 69/100 - 0.16s - loss: 0.9044 - acc: 0.5789 - val_loss: 0.9548 - val_acc: 0.5567\n",
            "Epoch 70/100 - 0.15s - loss: 0.9059 - acc: 0.5814 - val_loss: 0.9552 - val_acc: 0.5648\n",
            "Epoch 71/100 - 0.16s - loss: 0.9037 - acc: 0.5738 - val_loss: 0.9570 - val_acc: 0.5263\n",
            "Epoch 72/100 - 0.15s - loss: 0.9007 - acc: 0.5814 - val_loss: 0.9532 - val_acc: 0.5547\n",
            "Epoch 73/100 - 0.16s - loss: 0.9036 - acc: 0.5709 - val_loss: 0.9577 - val_acc: 0.5243\n",
            "Epoch 74/100 - 0.15s - loss: 0.9089 - acc: 0.5792 - val_loss: 0.9597 - val_acc: 0.5648\n",
            "Epoch 75/100 - 0.16s - loss: 0.9004 - acc: 0.5720 - val_loss: 0.9554 - val_acc: 0.5324\n",
            "Epoch 76/100 - 0.17s - loss: 0.8982 - acc: 0.5747 - val_loss: 0.9557 - val_acc: 0.5385\n",
            "Epoch 77/100 - 0.18s - loss: 0.9143 - acc: 0.5605 - val_loss: 0.9767 - val_acc: 0.5040\n",
            "Epoch 78/100 - 0.16s - loss: 0.8998 - acc: 0.5816 - val_loss: 0.9535 - val_acc: 0.5709\n",
            "Epoch 79/100 - 0.18s - loss: 0.8948 - acc: 0.5834 - val_loss: 0.9510 - val_acc: 0.5648\n",
            "Epoch 80/100 - 0.16s - loss: 0.8981 - acc: 0.5807 - val_loss: 0.9532 - val_acc: 0.5688\n",
            "Epoch 81/100 - 0.18s - loss: 0.8930 - acc: 0.5780 - val_loss: 0.9566 - val_acc: 0.5324\n",
            "Epoch 82/100 - 0.16s - loss: 0.8908 - acc: 0.5830 - val_loss: 0.9523 - val_acc: 0.5364\n",
            "Epoch 83/100 - 0.17s - loss: 0.8944 - acc: 0.5742 - val_loss: 0.9584 - val_acc: 0.5263\n",
            "Epoch 84/100 - 0.16s - loss: 0.8939 - acc: 0.5760 - val_loss: 0.9609 - val_acc: 0.5223\n",
            "Epoch 85/100 - 0.17s - loss: 0.8980 - acc: 0.5848 - val_loss: 0.9613 - val_acc: 0.5567\n",
            "Epoch 86/100 - 0.16s - loss: 0.8870 - acc: 0.5884 - val_loss: 0.9496 - val_acc: 0.5688\n",
            "Epoch 87/100 - 0.18s - loss: 0.8945 - acc: 0.5778 - val_loss: 0.9637 - val_acc: 0.5304\n",
            "Epoch 88/100 - 0.16s - loss: 0.8862 - acc: 0.5855 - val_loss: 0.9515 - val_acc: 0.5466\n",
            "Epoch 89/100 - 0.16s - loss: 0.8980 - acc: 0.5688 - val_loss: 0.9661 - val_acc: 0.5243\n",
            "Epoch 90/100 - 0.15s - loss: 0.8835 - acc: 0.5886 - val_loss: 0.9507 - val_acc: 0.5466\n",
            "Epoch 91/100 - 0.16s - loss: 0.8826 - acc: 0.5861 - val_loss: 0.9538 - val_acc: 0.5445\n",
            "Epoch 92/100 - 0.15s - loss: 0.8809 - acc: 0.5954 - val_loss: 0.9492 - val_acc: 0.5526\n",
            "Epoch 93/100 - 0.16s - loss: 0.8837 - acc: 0.5945 - val_loss: 0.9510 - val_acc: 0.5567\n",
            "Epoch 94/100 - 0.15s - loss: 0.8804 - acc: 0.5888 - val_loss: 0.9508 - val_acc: 0.5364\n",
            "Epoch 95/100 - 0.16s - loss: 0.8831 - acc: 0.5812 - val_loss: 0.9575 - val_acc: 0.5304\n",
            "Epoch 96/100 - 0.15s - loss: 0.8791 - acc: 0.5913 - val_loss: 0.9502 - val_acc: 0.5607\n",
            "Epoch 97/100 - 0.17s - loss: 0.8848 - acc: 0.5823 - val_loss: 0.9606 - val_acc: 0.5324\n",
            "Epoch 98/100 - 0.15s - loss: 0.8805 - acc: 0.5913 - val_loss: 0.9579 - val_acc: 0.5385\n",
            "Epoch 99/100 - 0.16s - loss: 0.8763 - acc: 0.5884 - val_loss: 0.9510 - val_acc: 0.5364\n",
            "Epoch 100/100 - 0.15s - loss: 0.8821 - acc: 0.5864 - val_loss: 0.9610 - val_acc: 0.5304\n",
            "\n",
            "Combination 132/252:\n",
            "Hidden Layers: [256, 128], Activation: tanh, Learning Rate: 0.01, Batch Size: 64, Epochs: 150\n",
            "Epoch 1/150 - 0.15s - loss: 1.0873 - acc: 0.4067 - val_loss: 1.0892 - val_acc: 0.4028\n",
            "Epoch 2/150 - 0.15s - loss: 1.0777 - acc: 0.4087 - val_loss: 1.0830 - val_acc: 0.3806\n",
            "Epoch 3/150 - 0.16s - loss: 1.0699 - acc: 0.4411 - val_loss: 1.0758 - val_acc: 0.4352\n",
            "Epoch 4/150 - 0.15s - loss: 1.0638 - acc: 0.4456 - val_loss: 1.0724 - val_acc: 0.4069\n",
            "Epoch 5/150 - 0.16s - loss: 1.0579 - acc: 0.4573 - val_loss: 1.0673 - val_acc: 0.4271\n",
            "Epoch 6/150 - 0.15s - loss: 1.0528 - acc: 0.4602 - val_loss: 1.0623 - val_acc: 0.4595\n",
            "Epoch 7/150 - 0.22s - loss: 1.0471 - acc: 0.4714 - val_loss: 1.0586 - val_acc: 0.4474\n",
            "Epoch 8/150 - 0.16s - loss: 1.0436 - acc: 0.4703 - val_loss: 1.0553 - val_acc: 0.4696\n",
            "Epoch 9/150 - 0.18s - loss: 1.0383 - acc: 0.4800 - val_loss: 1.0520 - val_acc: 0.4717\n",
            "Epoch 10/150 - 0.17s - loss: 1.0345 - acc: 0.4888 - val_loss: 1.0499 - val_acc: 0.4696\n",
            "Epoch 11/150 - 0.17s - loss: 1.0310 - acc: 0.4804 - val_loss: 1.0462 - val_acc: 0.4798\n",
            "Epoch 12/150 - 0.15s - loss: 1.0286 - acc: 0.4867 - val_loss: 1.0441 - val_acc: 0.4737\n",
            "Epoch 13/150 - 0.16s - loss: 1.0240 - acc: 0.4908 - val_loss: 1.0414 - val_acc: 0.4858\n",
            "Epoch 14/150 - 0.15s - loss: 1.0206 - acc: 0.4971 - val_loss: 1.0390 - val_acc: 0.4838\n",
            "Epoch 15/150 - 0.16s - loss: 1.0161 - acc: 0.5000 - val_loss: 1.0347 - val_acc: 0.5061\n",
            "Epoch 16/150 - 0.15s - loss: 1.0128 - acc: 0.5040 - val_loss: 1.0323 - val_acc: 0.5040\n",
            "Epoch 17/150 - 0.16s - loss: 1.0100 - acc: 0.5151 - val_loss: 1.0312 - val_acc: 0.5040\n",
            "Epoch 18/150 - 0.15s - loss: 1.0056 - acc: 0.5117 - val_loss: 1.0264 - val_acc: 0.5081\n",
            "Epoch 19/150 - 0.16s - loss: 1.0047 - acc: 0.5103 - val_loss: 1.0251 - val_acc: 0.5040\n",
            "Epoch 20/150 - 0.16s - loss: 1.0001 - acc: 0.5180 - val_loss: 1.0227 - val_acc: 0.5142\n",
            "Epoch 21/150 - 0.17s - loss: 0.9966 - acc: 0.5189 - val_loss: 1.0185 - val_acc: 0.5162\n",
            "Epoch 22/150 - 0.15s - loss: 0.9940 - acc: 0.5187 - val_loss: 1.0175 - val_acc: 0.5182\n",
            "Epoch 23/150 - 0.15s - loss: 0.9899 - acc: 0.5247 - val_loss: 1.0126 - val_acc: 0.5142\n",
            "Epoch 24/150 - 0.15s - loss: 0.9891 - acc: 0.5207 - val_loss: 1.0119 - val_acc: 0.5162\n",
            "Epoch 25/150 - 0.16s - loss: 0.9844 - acc: 0.5243 - val_loss: 1.0079 - val_acc: 0.5223\n",
            "Epoch 26/150 - 0.18s - loss: 0.9867 - acc: 0.5232 - val_loss: 1.0106 - val_acc: 0.5202\n",
            "Epoch 27/150 - 0.25s - loss: 0.9789 - acc: 0.5322 - val_loss: 1.0039 - val_acc: 0.5263\n",
            "Epoch 28/150 - 0.16s - loss: 0.9786 - acc: 0.5295 - val_loss: 1.0022 - val_acc: 0.5283\n",
            "Epoch 29/150 - 0.17s - loss: 0.9778 - acc: 0.5353 - val_loss: 1.0015 - val_acc: 0.5283\n",
            "Epoch 30/150 - 0.16s - loss: 0.9711 - acc: 0.5301 - val_loss: 0.9969 - val_acc: 0.5324\n",
            "Epoch 31/150 - 0.17s - loss: 0.9688 - acc: 0.5333 - val_loss: 0.9935 - val_acc: 0.5263\n",
            "Epoch 32/150 - 0.17s - loss: 0.9729 - acc: 0.5277 - val_loss: 0.9996 - val_acc: 0.5020\n",
            "Epoch 33/150 - 0.18s - loss: 0.9688 - acc: 0.5337 - val_loss: 0.9962 - val_acc: 0.5101\n",
            "Epoch 34/150 - 0.16s - loss: 0.9645 - acc: 0.5362 - val_loss: 0.9914 - val_acc: 0.5202\n",
            "Epoch 35/150 - 0.17s - loss: 0.9578 - acc: 0.5450 - val_loss: 0.9841 - val_acc: 0.5385\n",
            "Epoch 36/150 - 0.22s - loss: 0.9582 - acc: 0.5398 - val_loss: 0.9864 - val_acc: 0.5243\n",
            "Epoch 37/150 - 0.17s - loss: 0.9553 - acc: 0.5448 - val_loss: 0.9810 - val_acc: 0.5466\n",
            "Epoch 38/150 - 0.17s - loss: 0.9524 - acc: 0.5488 - val_loss: 0.9789 - val_acc: 0.5425\n",
            "Epoch 39/150 - 0.17s - loss: 0.9507 - acc: 0.5463 - val_loss: 0.9800 - val_acc: 0.5344\n",
            "Epoch 40/150 - 0.17s - loss: 0.9471 - acc: 0.5517 - val_loss: 0.9754 - val_acc: 0.5445\n",
            "Epoch 41/150 - 0.16s - loss: 0.9460 - acc: 0.5522 - val_loss: 0.9742 - val_acc: 0.5466\n",
            "Epoch 42/150 - 0.16s - loss: 0.9461 - acc: 0.5506 - val_loss: 0.9757 - val_acc: 0.5526\n",
            "Epoch 43/150 - 0.16s - loss: 0.9411 - acc: 0.5504 - val_loss: 0.9716 - val_acc: 0.5385\n",
            "Epoch 44/150 - 0.19s - loss: 0.9400 - acc: 0.5567 - val_loss: 0.9689 - val_acc: 0.5587\n",
            "Epoch 45/150 - 0.16s - loss: 0.9522 - acc: 0.5364 - val_loss: 0.9853 - val_acc: 0.5162\n",
            "Epoch 46/150 - 0.18s - loss: 0.9358 - acc: 0.5594 - val_loss: 0.9661 - val_acc: 0.5567\n",
            "Epoch 47/150 - 0.19s - loss: 0.9362 - acc: 0.5549 - val_loss: 0.9692 - val_acc: 0.5324\n",
            "Epoch 48/150 - 0.18s - loss: 0.9351 - acc: 0.5574 - val_loss: 0.9660 - val_acc: 0.5445\n",
            "Epoch 49/150 - 0.16s - loss: 0.9299 - acc: 0.5625 - val_loss: 0.9626 - val_acc: 0.5547\n",
            "Epoch 50/150 - 0.17s - loss: 0.9336 - acc: 0.5598 - val_loss: 0.9650 - val_acc: 0.5587\n",
            "Epoch 51/150 - 0.16s - loss: 0.9290 - acc: 0.5650 - val_loss: 0.9628 - val_acc: 0.5526\n",
            "Epoch 52/150 - 0.16s - loss: 0.9254 - acc: 0.5675 - val_loss: 0.9605 - val_acc: 0.5445\n",
            "Epoch 53/150 - 0.15s - loss: 0.9230 - acc: 0.5621 - val_loss: 0.9578 - val_acc: 0.5547\n",
            "Epoch 54/150 - 0.18s - loss: 0.9213 - acc: 0.5655 - val_loss: 0.9570 - val_acc: 0.5445\n",
            "Epoch 55/150 - 0.17s - loss: 0.9271 - acc: 0.5574 - val_loss: 0.9652 - val_acc: 0.5304\n",
            "Epoch 56/150 - 0.16s - loss: 0.9192 - acc: 0.5697 - val_loss: 0.9554 - val_acc: 0.5628\n",
            "Epoch 57/150 - 0.14s - loss: 0.9175 - acc: 0.5657 - val_loss: 0.9565 - val_acc: 0.5385\n",
            "Epoch 58/150 - 0.15s - loss: 0.9185 - acc: 0.5717 - val_loss: 0.9552 - val_acc: 0.5567\n",
            "Epoch 59/150 - 0.14s - loss: 0.9137 - acc: 0.5700 - val_loss: 0.9530 - val_acc: 0.5526\n",
            "Epoch 60/150 - 0.15s - loss: 0.9170 - acc: 0.5657 - val_loss: 0.9586 - val_acc: 0.5344\n",
            "Epoch 61/150 - 0.15s - loss: 0.9192 - acc: 0.5632 - val_loss: 0.9605 - val_acc: 0.5405\n",
            "Epoch 62/150 - 0.16s - loss: 0.9136 - acc: 0.5749 - val_loss: 0.9545 - val_acc: 0.5526\n",
            "Epoch 63/150 - 0.15s - loss: 0.9187 - acc: 0.5578 - val_loss: 0.9628 - val_acc: 0.5364\n",
            "Epoch 64/150 - 0.16s - loss: 0.9152 - acc: 0.5641 - val_loss: 0.9604 - val_acc: 0.5445\n",
            "Epoch 65/150 - 0.15s - loss: 0.9090 - acc: 0.5697 - val_loss: 0.9527 - val_acc: 0.5445\n",
            "Epoch 66/150 - 0.16s - loss: 0.9093 - acc: 0.5688 - val_loss: 0.9549 - val_acc: 0.5486\n",
            "Epoch 67/150 - 0.14s - loss: 0.9100 - acc: 0.5686 - val_loss: 0.9548 - val_acc: 0.5486\n",
            "Epoch 68/150 - 0.15s - loss: 0.9024 - acc: 0.5807 - val_loss: 0.9492 - val_acc: 0.5425\n",
            "Epoch 69/150 - 0.15s - loss: 0.9417 - acc: 0.5425 - val_loss: 0.9934 - val_acc: 0.4919\n",
            "Epoch 70/150 - 0.15s - loss: 0.9010 - acc: 0.5765 - val_loss: 0.9499 - val_acc: 0.5405\n",
            "Epoch 71/150 - 0.15s - loss: 0.9180 - acc: 0.5596 - val_loss: 0.9648 - val_acc: 0.5425\n",
            "Epoch 72/150 - 0.15s - loss: 0.8978 - acc: 0.5828 - val_loss: 0.9483 - val_acc: 0.5425\n",
            "Epoch 73/150 - 0.16s - loss: 0.9331 - acc: 0.5454 - val_loss: 0.9873 - val_acc: 0.5121\n",
            "Epoch 74/150 - 0.16s - loss: 0.8958 - acc: 0.5828 - val_loss: 0.9453 - val_acc: 0.5607\n",
            "Epoch 75/150 - 0.15s - loss: 0.8979 - acc: 0.5846 - val_loss: 0.9464 - val_acc: 0.5648\n",
            "Epoch 76/150 - 0.15s - loss: 0.8933 - acc: 0.5859 - val_loss: 0.9444 - val_acc: 0.5587\n",
            "Epoch 77/150 - 0.14s - loss: 0.9118 - acc: 0.5632 - val_loss: 0.9675 - val_acc: 0.5324\n",
            "Epoch 78/150 - 0.14s - loss: 0.9027 - acc: 0.5762 - val_loss: 0.9539 - val_acc: 0.5749\n",
            "Epoch 79/150 - 0.14s - loss: 0.8916 - acc: 0.5816 - val_loss: 0.9455 - val_acc: 0.5567\n",
            "Epoch 80/150 - 0.15s - loss: 0.8946 - acc: 0.5801 - val_loss: 0.9535 - val_acc: 0.5304\n",
            "Epoch 81/150 - 0.14s - loss: 0.8934 - acc: 0.5789 - val_loss: 0.9527 - val_acc: 0.5405\n",
            "Epoch 82/150 - 0.14s - loss: 0.8972 - acc: 0.5843 - val_loss: 0.9508 - val_acc: 0.5628\n",
            "Epoch 83/150 - 0.15s - loss: 0.8998 - acc: 0.5735 - val_loss: 0.9608 - val_acc: 0.5243\n",
            "Epoch 84/150 - 0.14s - loss: 0.8933 - acc: 0.5864 - val_loss: 0.9516 - val_acc: 0.5547\n",
            "Epoch 85/150 - 0.15s - loss: 0.8854 - acc: 0.5884 - val_loss: 0.9473 - val_acc: 0.5506\n",
            "Epoch 86/150 - 0.16s - loss: 0.8892 - acc: 0.5927 - val_loss: 0.9504 - val_acc: 0.5405\n",
            "Epoch 87/150 - 0.19s - loss: 0.9004 - acc: 0.5850 - val_loss: 0.9569 - val_acc: 0.5668\n",
            "Epoch 88/150 - 0.16s - loss: 0.8822 - acc: 0.5877 - val_loss: 0.9447 - val_acc: 0.5526\n",
            "Epoch 89/150 - 0.15s - loss: 0.8863 - acc: 0.5864 - val_loss: 0.9461 - val_acc: 0.5607\n",
            "Epoch 90/150 - 0.15s - loss: 0.8990 - acc: 0.5837 - val_loss: 0.9584 - val_acc: 0.5648\n",
            "Epoch 91/150 - 0.16s - loss: 0.8859 - acc: 0.5902 - val_loss: 0.9545 - val_acc: 0.5283\n",
            "Epoch 92/150 - 0.15s - loss: 0.8800 - acc: 0.5929 - val_loss: 0.9431 - val_acc: 0.5688\n",
            "Epoch 93/150 - 0.15s - loss: 0.8771 - acc: 0.5965 - val_loss: 0.9431 - val_acc: 0.5668\n",
            "Epoch 94/150 - 0.15s - loss: 0.8922 - acc: 0.5778 - val_loss: 0.9625 - val_acc: 0.5223\n",
            "Epoch 95/150 - 0.15s - loss: 0.8848 - acc: 0.5819 - val_loss: 0.9577 - val_acc: 0.5324\n",
            "Epoch 96/150 - 0.16s - loss: 0.8812 - acc: 0.5870 - val_loss: 0.9540 - val_acc: 0.5344\n",
            "Epoch 97/150 - 0.14s - loss: 0.8749 - acc: 0.5947 - val_loss: 0.9443 - val_acc: 0.5729\n",
            "Epoch 98/150 - 0.15s - loss: 0.8750 - acc: 0.5958 - val_loss: 0.9458 - val_acc: 0.5425\n",
            "Epoch 99/150 - 0.15s - loss: 0.8864 - acc: 0.5922 - val_loss: 0.9589 - val_acc: 0.5385\n",
            "Epoch 100/150 - 0.15s - loss: 0.8987 - acc: 0.5722 - val_loss: 0.9777 - val_acc: 0.4939\n",
            "Epoch 101/150 - 0.15s - loss: 0.8987 - acc: 0.5794 - val_loss: 0.9813 - val_acc: 0.5081\n",
            "Epoch 102/150 - 0.15s - loss: 0.8860 - acc: 0.5888 - val_loss: 0.9570 - val_acc: 0.5769\n",
            "Epoch 103/150 - 0.15s - loss: 0.8854 - acc: 0.5884 - val_loss: 0.9665 - val_acc: 0.5182\n",
            "Epoch 104/150 - 0.15s - loss: 0.8700 - acc: 0.5972 - val_loss: 0.9466 - val_acc: 0.5526\n",
            "Epoch 105/150 - 0.15s - loss: 0.8791 - acc: 0.5875 - val_loss: 0.9592 - val_acc: 0.5344\n",
            "Epoch 106/150 - 0.18s - loss: 0.8689 - acc: 0.5996 - val_loss: 0.9487 - val_acc: 0.5466\n",
            "Epoch 107/150 - 0.15s - loss: 0.9003 - acc: 0.5702 - val_loss: 0.9827 - val_acc: 0.5121\n",
            "Epoch 108/150 - 0.14s - loss: 0.8666 - acc: 0.5987 - val_loss: 0.9459 - val_acc: 0.5648\n",
            "Epoch 109/150 - 0.15s - loss: 0.8755 - acc: 0.5981 - val_loss: 0.9543 - val_acc: 0.5749\n",
            "Epoch 110/150 - 0.15s - loss: 0.8764 - acc: 0.5965 - val_loss: 0.9547 - val_acc: 0.5668\n",
            "Epoch 111/150 - 0.15s - loss: 0.8832 - acc: 0.5839 - val_loss: 0.9700 - val_acc: 0.5121\n",
            "Epoch 112/150 - 0.14s - loss: 0.8654 - acc: 0.6003 - val_loss: 0.9493 - val_acc: 0.5547\n",
            "Epoch 113/150 - 0.15s - loss: 0.8676 - acc: 0.5976 - val_loss: 0.9540 - val_acc: 0.5425\n",
            "Epoch 114/150 - 0.15s - loss: 0.8727 - acc: 0.5927 - val_loss: 0.9593 - val_acc: 0.5405\n",
            "Epoch 115/150 - 0.14s - loss: 0.8889 - acc: 0.5798 - val_loss: 0.9783 - val_acc: 0.5405\n",
            "Epoch 116/150 - 0.16s - loss: 0.8718 - acc: 0.5936 - val_loss: 0.9647 - val_acc: 0.5223\n",
            "Epoch 117/150 - 0.16s - loss: 0.8904 - acc: 0.5774 - val_loss: 0.9815 - val_acc: 0.5061\n",
            "Epoch 118/150 - 0.15s - loss: 0.8690 - acc: 0.5976 - val_loss: 0.9595 - val_acc: 0.5364\n",
            "Epoch 119/150 - 0.15s - loss: 0.8635 - acc: 0.6055 - val_loss: 0.9544 - val_acc: 0.5263\n",
            "Epoch 120/150 - 0.15s - loss: 0.8996 - acc: 0.5855 - val_loss: 0.9823 - val_acc: 0.5668\n",
            "Epoch 121/150 - 0.14s - loss: 0.8630 - acc: 0.6023 - val_loss: 0.9574 - val_acc: 0.5223\n",
            "Epoch 122/150 - 0.16s - loss: 0.8667 - acc: 0.5927 - val_loss: 0.9547 - val_acc: 0.5607\n",
            "Epoch 123/150 - 0.14s - loss: 0.8952 - acc: 0.5859 - val_loss: 0.9806 - val_acc: 0.5628\n",
            "Epoch 124/150 - 0.16s - loss: 0.8609 - acc: 0.6023 - val_loss: 0.9511 - val_acc: 0.5628\n",
            "Epoch 125/150 - 0.14s - loss: 0.8799 - acc: 0.5888 - val_loss: 0.9803 - val_acc: 0.5182\n",
            "Epoch 126/150 - 0.15s - loss: 0.8788 - acc: 0.5816 - val_loss: 0.9765 - val_acc: 0.5182\n",
            "Epoch 127/150 - 0.16s - loss: 0.8626 - acc: 0.6062 - val_loss: 0.9589 - val_acc: 0.5425\n",
            "Epoch 128/150 - 0.15s - loss: 0.8642 - acc: 0.6035 - val_loss: 0.9568 - val_acc: 0.5628\n",
            "Epoch 129/150 - 0.14s - loss: 0.8690 - acc: 0.5972 - val_loss: 0.9704 - val_acc: 0.5243\n",
            "Epoch 130/150 - 0.14s - loss: 0.8581 - acc: 0.6062 - val_loss: 0.9579 - val_acc: 0.5405\n",
            "Epoch 131/150 - 0.14s - loss: 0.8786 - acc: 0.5969 - val_loss: 0.9778 - val_acc: 0.5405\n",
            "Epoch 132/150 - 0.14s - loss: 0.8566 - acc: 0.6030 - val_loss: 0.9545 - val_acc: 0.5506\n",
            "Epoch 133/150 - 0.15s - loss: 0.8759 - acc: 0.5857 - val_loss: 0.9673 - val_acc: 0.5547\n",
            "Epoch 134/150 - 0.15s - loss: 0.8732 - acc: 0.5893 - val_loss: 0.9675 - val_acc: 0.5385\n",
            "Epoch 135/150 - 0.19s - loss: 0.8564 - acc: 0.6044 - val_loss: 0.9597 - val_acc: 0.5344\n",
            "Epoch 136/150 - 0.14s - loss: 0.8523 - acc: 0.6127 - val_loss: 0.9535 - val_acc: 0.5445\n",
            "Epoch 137/150 - 0.14s - loss: 0.9162 - acc: 0.5643 - val_loss: 1.0279 - val_acc: 0.5081\n",
            "Epoch 138/150 - 0.15s - loss: 0.9205 - acc: 0.5603 - val_loss: 1.0347 - val_acc: 0.4757\n",
            "Epoch 139/150 - 0.14s - loss: 0.9008 - acc: 0.5729 - val_loss: 1.0078 - val_acc: 0.5061\n",
            "Epoch 140/150 - 0.16s - loss: 0.8527 - acc: 0.6073 - val_loss: 0.9571 - val_acc: 0.5445\n",
            "Epoch 141/150 - 0.15s - loss: 0.8576 - acc: 0.6059 - val_loss: 0.9630 - val_acc: 0.5445\n",
            "Epoch 142/150 - 0.16s - loss: 0.9053 - acc: 0.5630 - val_loss: 0.9991 - val_acc: 0.5304\n",
            "Epoch 143/150 - 0.14s - loss: 0.8628 - acc: 0.6073 - val_loss: 0.9676 - val_acc: 0.5486\n",
            "Epoch 144/150 - 0.16s - loss: 0.8521 - acc: 0.6095 - val_loss: 0.9589 - val_acc: 0.5547\n",
            "Epoch 145/150 - 0.14s - loss: 0.8662 - acc: 0.5974 - val_loss: 0.9774 - val_acc: 0.5142\n",
            "Epoch 146/150 - 0.14s - loss: 0.8616 - acc: 0.6057 - val_loss: 0.9752 - val_acc: 0.5304\n",
            "Epoch 147/150 - 0.18s - loss: 0.8934 - acc: 0.5933 - val_loss: 0.9936 - val_acc: 0.5587\n",
            "Epoch 148/150 - 0.15s - loss: 0.8578 - acc: 0.6037 - val_loss: 0.9644 - val_acc: 0.5405\n",
            "Epoch 149/150 - 0.15s - loss: 0.8639 - acc: 0.6055 - val_loss: 0.9767 - val_acc: 0.5364\n",
            "Epoch 150/150 - 0.15s - loss: 0.8474 - acc: 0.6120 - val_loss: 0.9584 - val_acc: 0.5486\n",
            "\n",
            "Combination 133/252:\n",
            "Hidden Layers: [256, 128], Activation: tanh, Learning Rate: 0.001, Batch Size: 32, Epochs: 50\n",
            "Epoch 1/50 - 0.18s - loss: 1.0990 - acc: 0.3684 - val_loss: 1.0917 - val_acc: 0.3785\n",
            "Epoch 2/50 - 0.18s - loss: 1.0952 - acc: 0.3785 - val_loss: 1.0879 - val_acc: 0.3765\n",
            "Epoch 3/50 - 0.18s - loss: 1.0921 - acc: 0.3810 - val_loss: 1.0852 - val_acc: 0.3968\n",
            "Epoch 4/50 - 0.20s - loss: 1.0894 - acc: 0.3932 - val_loss: 1.0831 - val_acc: 0.4049\n",
            "Epoch 5/50 - 0.17s - loss: 1.0868 - acc: 0.4026 - val_loss: 1.0810 - val_acc: 0.4109\n",
            "Epoch 6/50 - 0.19s - loss: 1.0844 - acc: 0.4082 - val_loss: 1.0791 - val_acc: 0.4271\n",
            "Epoch 7/50 - 0.18s - loss: 1.0821 - acc: 0.4154 - val_loss: 1.0774 - val_acc: 0.4291\n",
            "Epoch 8/50 - 0.19s - loss: 1.0799 - acc: 0.4215 - val_loss: 1.0757 - val_acc: 0.4352\n",
            "Epoch 9/50 - 0.18s - loss: 1.0779 - acc: 0.4278 - val_loss: 1.0741 - val_acc: 0.4474\n",
            "Epoch 10/50 - 0.18s - loss: 1.0760 - acc: 0.4339 - val_loss: 1.0728 - val_acc: 0.4534\n",
            "Epoch 11/50 - 0.18s - loss: 1.0742 - acc: 0.4399 - val_loss: 1.0713 - val_acc: 0.4474\n",
            "Epoch 12/50 - 0.18s - loss: 1.0724 - acc: 0.4420 - val_loss: 1.0701 - val_acc: 0.4595\n",
            "Epoch 13/50 - 0.17s - loss: 1.0707 - acc: 0.4449 - val_loss: 1.0688 - val_acc: 0.4575\n",
            "Epoch 14/50 - 0.18s - loss: 1.0692 - acc: 0.4487 - val_loss: 1.0678 - val_acc: 0.4575\n",
            "Epoch 15/50 - 0.18s - loss: 1.0676 - acc: 0.4512 - val_loss: 1.0668 - val_acc: 0.4555\n",
            "Epoch 16/50 - 0.21s - loss: 1.0661 - acc: 0.4510 - val_loss: 1.0656 - val_acc: 0.4575\n",
            "Epoch 17/50 - 0.18s - loss: 1.0647 - acc: 0.4534 - val_loss: 1.0646 - val_acc: 0.4575\n",
            "Epoch 18/50 - 0.17s - loss: 1.0633 - acc: 0.4546 - val_loss: 1.0636 - val_acc: 0.4636\n",
            "Epoch 19/50 - 0.18s - loss: 1.0618 - acc: 0.4595 - val_loss: 1.0623 - val_acc: 0.4555\n",
            "Epoch 20/50 - 0.24s - loss: 1.0605 - acc: 0.4611 - val_loss: 1.0614 - val_acc: 0.4555\n",
            "Epoch 21/50 - 0.18s - loss: 1.0592 - acc: 0.4636 - val_loss: 1.0605 - val_acc: 0.4494\n",
            "Epoch 22/50 - 0.17s - loss: 1.0579 - acc: 0.4672 - val_loss: 1.0594 - val_acc: 0.4595\n",
            "Epoch 23/50 - 0.18s - loss: 1.0567 - acc: 0.4681 - val_loss: 1.0587 - val_acc: 0.4555\n",
            "Epoch 24/50 - 0.19s - loss: 1.0555 - acc: 0.4712 - val_loss: 1.0579 - val_acc: 0.4595\n",
            "Epoch 25/50 - 0.20s - loss: 1.0543 - acc: 0.4696 - val_loss: 1.0571 - val_acc: 0.4514\n",
            "Epoch 26/50 - 0.20s - loss: 1.0531 - acc: 0.4696 - val_loss: 1.0563 - val_acc: 0.4534\n",
            "Epoch 27/50 - 0.17s - loss: 1.0520 - acc: 0.4723 - val_loss: 1.0554 - val_acc: 0.4656\n",
            "Epoch 28/50 - 0.18s - loss: 1.0509 - acc: 0.4735 - val_loss: 1.0545 - val_acc: 0.4595\n",
            "Epoch 29/50 - 0.17s - loss: 1.0498 - acc: 0.4757 - val_loss: 1.0537 - val_acc: 0.4636\n",
            "Epoch 30/50 - 0.19s - loss: 1.0487 - acc: 0.4780 - val_loss: 1.0530 - val_acc: 0.4656\n",
            "Epoch 31/50 - 0.18s - loss: 1.0476 - acc: 0.4777 - val_loss: 1.0523 - val_acc: 0.4595\n",
            "Epoch 32/50 - 0.18s - loss: 1.0466 - acc: 0.4798 - val_loss: 1.0515 - val_acc: 0.4656\n",
            "Epoch 33/50 - 0.22s - loss: 1.0456 - acc: 0.4780 - val_loss: 1.0510 - val_acc: 0.4575\n",
            "Epoch 34/50 - 0.19s - loss: 1.0445 - acc: 0.4793 - val_loss: 1.0502 - val_acc: 0.4737\n",
            "Epoch 35/50 - 0.22s - loss: 1.0435 - acc: 0.4786 - val_loss: 1.0495 - val_acc: 0.4676\n",
            "Epoch 36/50 - 0.17s - loss: 1.0426 - acc: 0.4816 - val_loss: 1.0487 - val_acc: 0.4838\n",
            "Epoch 37/50 - 0.19s - loss: 1.0416 - acc: 0.4818 - val_loss: 1.0479 - val_acc: 0.4858\n",
            "Epoch 38/50 - 0.17s - loss: 1.0406 - acc: 0.4800 - val_loss: 1.0474 - val_acc: 0.4858\n",
            "Epoch 39/50 - 0.19s - loss: 1.0397 - acc: 0.4811 - val_loss: 1.0467 - val_acc: 0.4899\n",
            "Epoch 40/50 - 0.18s - loss: 1.0389 - acc: 0.4816 - val_loss: 1.0461 - val_acc: 0.4919\n",
            "Epoch 41/50 - 0.18s - loss: 1.0378 - acc: 0.4818 - val_loss: 1.0455 - val_acc: 0.4879\n",
            "Epoch 42/50 - 0.18s - loss: 1.0369 - acc: 0.4829 - val_loss: 1.0449 - val_acc: 0.4858\n",
            "Epoch 43/50 - 0.17s - loss: 1.0360 - acc: 0.4831 - val_loss: 1.0445 - val_acc: 0.4757\n",
            "Epoch 44/50 - 0.18s - loss: 1.0351 - acc: 0.4834 - val_loss: 1.0436 - val_acc: 0.4899\n",
            "Epoch 45/50 - 0.19s - loss: 1.0342 - acc: 0.4861 - val_loss: 1.0431 - val_acc: 0.4960\n",
            "Epoch 46/50 - 0.17s - loss: 1.0334 - acc: 0.4861 - val_loss: 1.0425 - val_acc: 0.4939\n",
            "Epoch 47/50 - 0.18s - loss: 1.0325 - acc: 0.4854 - val_loss: 1.0419 - val_acc: 0.4919\n",
            "Epoch 48/50 - 0.18s - loss: 1.0316 - acc: 0.4861 - val_loss: 1.0413 - val_acc: 0.4939\n",
            "Epoch 49/50 - 0.20s - loss: 1.0308 - acc: 0.4867 - val_loss: 1.0409 - val_acc: 0.4939\n",
            "Epoch 50/50 - 0.18s - loss: 1.0300 - acc: 0.4899 - val_loss: 1.0401 - val_acc: 0.4919\n",
            "\n",
            "Combination 134/252:\n",
            "Hidden Layers: [256, 128], Activation: tanh, Learning Rate: 0.001, Batch Size: 32, Epochs: 100\n",
            "Epoch 1/100 - 0.17s - loss: 1.1009 - acc: 0.3320 - val_loss: 1.1029 - val_acc: 0.3077\n",
            "Epoch 2/100 - 0.18s - loss: 1.0963 - acc: 0.3534 - val_loss: 1.0979 - val_acc: 0.3401\n",
            "Epoch 3/100 - 0.19s - loss: 1.0930 - acc: 0.3803 - val_loss: 1.0950 - val_acc: 0.3704\n",
            "Epoch 4/100 - 0.18s - loss: 1.0900 - acc: 0.3920 - val_loss: 1.0928 - val_acc: 0.3745\n",
            "Epoch 5/100 - 0.20s - loss: 1.0873 - acc: 0.4040 - val_loss: 1.0906 - val_acc: 0.3907\n",
            "Epoch 6/100 - 0.18s - loss: 1.0847 - acc: 0.4139 - val_loss: 1.0886 - val_acc: 0.3947\n",
            "Epoch 7/100 - 0.18s - loss: 1.0824 - acc: 0.4229 - val_loss: 1.0870 - val_acc: 0.4089\n",
            "Epoch 8/100 - 0.20s - loss: 1.0802 - acc: 0.4220 - val_loss: 1.0850 - val_acc: 0.3968\n",
            "Epoch 9/100 - 0.19s - loss: 1.0782 - acc: 0.4296 - val_loss: 1.0834 - val_acc: 0.4069\n",
            "Epoch 10/100 - 0.18s - loss: 1.0762 - acc: 0.4381 - val_loss: 1.0822 - val_acc: 0.4089\n",
            "Epoch 11/100 - 0.18s - loss: 1.0745 - acc: 0.4449 - val_loss: 1.0810 - val_acc: 0.4150\n",
            "Epoch 12/100 - 0.18s - loss: 1.0727 - acc: 0.4476 - val_loss: 1.0795 - val_acc: 0.4231\n",
            "Epoch 13/100 - 0.19s - loss: 1.0711 - acc: 0.4519 - val_loss: 1.0783 - val_acc: 0.4211\n",
            "Epoch 14/100 - 0.17s - loss: 1.0696 - acc: 0.4528 - val_loss: 1.0774 - val_acc: 0.4190\n",
            "Epoch 15/100 - 0.19s - loss: 1.0680 - acc: 0.4568 - val_loss: 1.0760 - val_acc: 0.4312\n",
            "Epoch 16/100 - 0.22s - loss: 1.0666 - acc: 0.4566 - val_loss: 1.0749 - val_acc: 0.4372\n",
            "Epoch 17/100 - 0.21s - loss: 1.0652 - acc: 0.4575 - val_loss: 1.0740 - val_acc: 0.4352\n",
            "Epoch 18/100 - 0.21s - loss: 1.0639 - acc: 0.4593 - val_loss: 1.0729 - val_acc: 0.4352\n",
            "Epoch 19/100 - 0.19s - loss: 1.0626 - acc: 0.4638 - val_loss: 1.0722 - val_acc: 0.4372\n",
            "Epoch 20/100 - 0.19s - loss: 1.0614 - acc: 0.4627 - val_loss: 1.0712 - val_acc: 0.4372\n",
            "Epoch 21/100 - 0.18s - loss: 1.0602 - acc: 0.4649 - val_loss: 1.0700 - val_acc: 0.4433\n",
            "Epoch 22/100 - 0.18s - loss: 1.0590 - acc: 0.4669 - val_loss: 1.0692 - val_acc: 0.4413\n",
            "Epoch 23/100 - 0.21s - loss: 1.0578 - acc: 0.4624 - val_loss: 1.0684 - val_acc: 0.4474\n",
            "Epoch 24/100 - 0.18s - loss: 1.0567 - acc: 0.4667 - val_loss: 1.0676 - val_acc: 0.4453\n",
            "Epoch 25/100 - 0.18s - loss: 1.0556 - acc: 0.4690 - val_loss: 1.0669 - val_acc: 0.4514\n",
            "Epoch 26/100 - 0.18s - loss: 1.0545 - acc: 0.4683 - val_loss: 1.0659 - val_acc: 0.4575\n",
            "Epoch 27/100 - 0.20s - loss: 1.0535 - acc: 0.4694 - val_loss: 1.0651 - val_acc: 0.4595\n",
            "Epoch 28/100 - 0.17s - loss: 1.0525 - acc: 0.4726 - val_loss: 1.0646 - val_acc: 0.4636\n",
            "Epoch 29/100 - 0.18s - loss: 1.0514 - acc: 0.4735 - val_loss: 1.0636 - val_acc: 0.4636\n",
            "Epoch 30/100 - 0.17s - loss: 1.0504 - acc: 0.4748 - val_loss: 1.0631 - val_acc: 0.4696\n",
            "Epoch 31/100 - 0.18s - loss: 1.0495 - acc: 0.4773 - val_loss: 1.0620 - val_acc: 0.4636\n",
            "Epoch 32/100 - 0.18s - loss: 1.0485 - acc: 0.4762 - val_loss: 1.0614 - val_acc: 0.4737\n",
            "Epoch 33/100 - 0.18s - loss: 1.0476 - acc: 0.4750 - val_loss: 1.0607 - val_acc: 0.4595\n",
            "Epoch 34/100 - 0.17s - loss: 1.0466 - acc: 0.4786 - val_loss: 1.0600 - val_acc: 0.4636\n",
            "Epoch 35/100 - 0.19s - loss: 1.0457 - acc: 0.4793 - val_loss: 1.0596 - val_acc: 0.4737\n",
            "Epoch 36/100 - 0.18s - loss: 1.0447 - acc: 0.4804 - val_loss: 1.0587 - val_acc: 0.4737\n",
            "Epoch 37/100 - 0.18s - loss: 1.0438 - acc: 0.4811 - val_loss: 1.0580 - val_acc: 0.4757\n",
            "Epoch 38/100 - 0.17s - loss: 1.0430 - acc: 0.4845 - val_loss: 1.0573 - val_acc: 0.4696\n",
            "Epoch 39/100 - 0.18s - loss: 1.0421 - acc: 0.4836 - val_loss: 1.0568 - val_acc: 0.4737\n",
            "Epoch 40/100 - 0.17s - loss: 1.0412 - acc: 0.4825 - val_loss: 1.0558 - val_acc: 0.4717\n",
            "Epoch 41/100 - 0.18s - loss: 1.0403 - acc: 0.4843 - val_loss: 1.0552 - val_acc: 0.4757\n",
            "Epoch 42/100 - 0.17s - loss: 1.0394 - acc: 0.4870 - val_loss: 1.0548 - val_acc: 0.4737\n",
            "Epoch 43/100 - 0.21s - loss: 1.0386 - acc: 0.4872 - val_loss: 1.0541 - val_acc: 0.4757\n",
            "Epoch 44/100 - 0.19s - loss: 1.0377 - acc: 0.4867 - val_loss: 1.0532 - val_acc: 0.4777\n",
            "Epoch 45/100 - 0.20s - loss: 1.0369 - acc: 0.4852 - val_loss: 1.0526 - val_acc: 0.4798\n",
            "Epoch 46/100 - 0.19s - loss: 1.0361 - acc: 0.4867 - val_loss: 1.0518 - val_acc: 0.4818\n",
            "Epoch 47/100 - 0.19s - loss: 1.0352 - acc: 0.4836 - val_loss: 1.0514 - val_acc: 0.4838\n",
            "Epoch 48/100 - 0.19s - loss: 1.0345 - acc: 0.4852 - val_loss: 1.0506 - val_acc: 0.4818\n",
            "Epoch 49/100 - 0.20s - loss: 1.0336 - acc: 0.4854 - val_loss: 1.0502 - val_acc: 0.4899\n",
            "Epoch 50/100 - 0.19s - loss: 1.0328 - acc: 0.4858 - val_loss: 1.0493 - val_acc: 0.4879\n",
            "Epoch 51/100 - 0.20s - loss: 1.0320 - acc: 0.4955 - val_loss: 1.0490 - val_acc: 0.4939\n",
            "Epoch 52/100 - 0.21s - loss: 1.0311 - acc: 0.4910 - val_loss: 1.0484 - val_acc: 0.4939\n",
            "Epoch 53/100 - 0.20s - loss: 1.0303 - acc: 0.4935 - val_loss: 1.0476 - val_acc: 0.4939\n",
            "Epoch 54/100 - 0.19s - loss: 1.0296 - acc: 0.4948 - val_loss: 1.0474 - val_acc: 0.4919\n",
            "Epoch 55/100 - 0.21s - loss: 1.0288 - acc: 0.4930 - val_loss: 1.0466 - val_acc: 0.4939\n",
            "Epoch 56/100 - 0.19s - loss: 1.0280 - acc: 0.4962 - val_loss: 1.0462 - val_acc: 0.4960\n",
            "Epoch 57/100 - 0.23s - loss: 1.0272 - acc: 0.4944 - val_loss: 1.0453 - val_acc: 0.4960\n",
            "Epoch 58/100 - 0.22s - loss: 1.0264 - acc: 0.4996 - val_loss: 1.0448 - val_acc: 0.4980\n",
            "Epoch 59/100 - 0.20s - loss: 1.0256 - acc: 0.4998 - val_loss: 1.0443 - val_acc: 0.4939\n",
            "Epoch 60/100 - 0.20s - loss: 1.0248 - acc: 0.5020 - val_loss: 1.0434 - val_acc: 0.5020\n",
            "Epoch 61/100 - 0.19s - loss: 1.0240 - acc: 0.5029 - val_loss: 1.0430 - val_acc: 0.5040\n",
            "Epoch 62/100 - 0.21s - loss: 1.0235 - acc: 0.5034 - val_loss: 1.0430 - val_acc: 0.4879\n",
            "Epoch 63/100 - 0.20s - loss: 1.0225 - acc: 0.5029 - val_loss: 1.0418 - val_acc: 0.5040\n",
            "Epoch 64/100 - 0.20s - loss: 1.0218 - acc: 0.5056 - val_loss: 1.0414 - val_acc: 0.5020\n",
            "Epoch 65/100 - 0.19s - loss: 1.0210 - acc: 0.5058 - val_loss: 1.0406 - val_acc: 0.5061\n",
            "Epoch 66/100 - 0.20s - loss: 1.0203 - acc: 0.5061 - val_loss: 1.0402 - val_acc: 0.5061\n",
            "Epoch 67/100 - 0.19s - loss: 1.0195 - acc: 0.5065 - val_loss: 1.0394 - val_acc: 0.5101\n",
            "Epoch 68/100 - 0.20s - loss: 1.0188 - acc: 0.5054 - val_loss: 1.0387 - val_acc: 0.5081\n",
            "Epoch 69/100 - 0.20s - loss: 1.0180 - acc: 0.5072 - val_loss: 1.0382 - val_acc: 0.5081\n",
            "Epoch 70/100 - 0.22s - loss: 1.0172 - acc: 0.5090 - val_loss: 1.0376 - val_acc: 0.5101\n",
            "Epoch 71/100 - 0.19s - loss: 1.0165 - acc: 0.5074 - val_loss: 1.0373 - val_acc: 0.5061\n",
            "Epoch 72/100 - 0.20s - loss: 1.0159 - acc: 0.5070 - val_loss: 1.0367 - val_acc: 0.5020\n",
            "Epoch 73/100 - 0.19s - loss: 1.0152 - acc: 0.5067 - val_loss: 1.0363 - val_acc: 0.5142\n",
            "Epoch 74/100 - 0.20s - loss: 1.0142 - acc: 0.5076 - val_loss: 1.0353 - val_acc: 0.5121\n",
            "Epoch 75/100 - 0.19s - loss: 1.0135 - acc: 0.5101 - val_loss: 1.0350 - val_acc: 0.5040\n",
            "Epoch 76/100 - 0.20s - loss: 1.0128 - acc: 0.5103 - val_loss: 1.0341 - val_acc: 0.5081\n",
            "Epoch 77/100 - 0.19s - loss: 1.0121 - acc: 0.5117 - val_loss: 1.0334 - val_acc: 0.5162\n",
            "Epoch 78/100 - 0.20s - loss: 1.0114 - acc: 0.5112 - val_loss: 1.0328 - val_acc: 0.5182\n",
            "Epoch 79/100 - 0.19s - loss: 1.0107 - acc: 0.5119 - val_loss: 1.0322 - val_acc: 0.5202\n",
            "Epoch 80/100 - 0.20s - loss: 1.0098 - acc: 0.5124 - val_loss: 1.0319 - val_acc: 0.5101\n",
            "Epoch 81/100 - 0.20s - loss: 1.0093 - acc: 0.5119 - val_loss: 1.0313 - val_acc: 0.5182\n",
            "Epoch 82/100 - 0.25s - loss: 1.0084 - acc: 0.5142 - val_loss: 1.0308 - val_acc: 0.5121\n",
            "Epoch 83/100 - 0.21s - loss: 1.0077 - acc: 0.5144 - val_loss: 1.0304 - val_acc: 0.5223\n",
            "Epoch 84/100 - 0.19s - loss: 1.0070 - acc: 0.5139 - val_loss: 1.0298 - val_acc: 0.5223\n",
            "Epoch 85/100 - 0.20s - loss: 1.0064 - acc: 0.5128 - val_loss: 1.0293 - val_acc: 0.5182\n",
            "Epoch 86/100 - 0.21s - loss: 1.0056 - acc: 0.5164 - val_loss: 1.0286 - val_acc: 0.5182\n",
            "Epoch 87/100 - 0.20s - loss: 1.0048 - acc: 0.5171 - val_loss: 1.0279 - val_acc: 0.5243\n",
            "Epoch 88/100 - 0.20s - loss: 1.0042 - acc: 0.5155 - val_loss: 1.0278 - val_acc: 0.5223\n",
            "Epoch 89/100 - 0.19s - loss: 1.0034 - acc: 0.5155 - val_loss: 1.0266 - val_acc: 0.5202\n",
            "Epoch 90/100 - 0.20s - loss: 1.0027 - acc: 0.5189 - val_loss: 1.0261 - val_acc: 0.5243\n",
            "Epoch 91/100 - 0.19s - loss: 1.0021 - acc: 0.5184 - val_loss: 1.0260 - val_acc: 0.5162\n",
            "Epoch 92/100 - 0.20s - loss: 1.0013 - acc: 0.5182 - val_loss: 1.0250 - val_acc: 0.5304\n",
            "Epoch 93/100 - 0.19s - loss: 1.0006 - acc: 0.5205 - val_loss: 1.0248 - val_acc: 0.5283\n",
            "Epoch 94/100 - 0.20s - loss: 0.9999 - acc: 0.5200 - val_loss: 1.0241 - val_acc: 0.5263\n",
            "Epoch 95/100 - 0.19s - loss: 0.9992 - acc: 0.5196 - val_loss: 1.0232 - val_acc: 0.5263\n",
            "Epoch 96/100 - 0.20s - loss: 0.9986 - acc: 0.5184 - val_loss: 1.0225 - val_acc: 0.5162\n",
            "Epoch 97/100 - 0.19s - loss: 0.9978 - acc: 0.5216 - val_loss: 1.0221 - val_acc: 0.5263\n",
            "Epoch 98/100 - 0.20s - loss: 0.9972 - acc: 0.5198 - val_loss: 1.0213 - val_acc: 0.5202\n",
            "Epoch 99/100 - 0.19s - loss: 0.9964 - acc: 0.5223 - val_loss: 1.0212 - val_acc: 0.5263\n",
            "Epoch 100/100 - 0.21s - loss: 0.9958 - acc: 0.5214 - val_loss: 1.0204 - val_acc: 0.5304\n",
            "\n",
            "Combination 135/252:\n",
            "Hidden Layers: [256, 128], Activation: tanh, Learning Rate: 0.001, Batch Size: 32, Epochs: 150\n",
            "Epoch 1/150 - 0.19s - loss: 1.1002 - acc: 0.3581 - val_loss: 1.1043 - val_acc: 0.3462\n",
            "Epoch 2/150 - 0.23s - loss: 1.0960 - acc: 0.3554 - val_loss: 1.1014 - val_acc: 0.3198\n",
            "Epoch 3/150 - 0.19s - loss: 1.0927 - acc: 0.3605 - val_loss: 1.0989 - val_acc: 0.3401\n",
            "Epoch 4/150 - 0.21s - loss: 1.0898 - acc: 0.3657 - val_loss: 1.0968 - val_acc: 0.3543\n",
            "Epoch 5/150 - 0.19s - loss: 1.0870 - acc: 0.3810 - val_loss: 1.0943 - val_acc: 0.3725\n",
            "Epoch 6/150 - 0.19s - loss: 1.0845 - acc: 0.3947 - val_loss: 1.0920 - val_acc: 0.3785\n",
            "Epoch 7/150 - 0.19s - loss: 1.0821 - acc: 0.4026 - val_loss: 1.0903 - val_acc: 0.3725\n",
            "Epoch 8/150 - 0.20s - loss: 1.0798 - acc: 0.4127 - val_loss: 1.0883 - val_acc: 0.3947\n",
            "Epoch 9/150 - 0.20s - loss: 1.0777 - acc: 0.4226 - val_loss: 1.0863 - val_acc: 0.3988\n",
            "Epoch 10/150 - 0.22s - loss: 1.0756 - acc: 0.4240 - val_loss: 1.0848 - val_acc: 0.4089\n",
            "Epoch 11/150 - 0.21s - loss: 1.0737 - acc: 0.4341 - val_loss: 1.0830 - val_acc: 0.4170\n",
            "Epoch 12/150 - 0.20s - loss: 1.0719 - acc: 0.4321 - val_loss: 1.0818 - val_acc: 0.4109\n",
            "Epoch 13/150 - 0.20s - loss: 1.0701 - acc: 0.4415 - val_loss: 1.0804 - val_acc: 0.4170\n",
            "Epoch 14/150 - 0.21s - loss: 1.0685 - acc: 0.4480 - val_loss: 1.0789 - val_acc: 0.4312\n",
            "Epoch 15/150 - 0.19s - loss: 1.0669 - acc: 0.4480 - val_loss: 1.0779 - val_acc: 0.4332\n",
            "Epoch 16/150 - 0.21s - loss: 1.0653 - acc: 0.4539 - val_loss: 1.0766 - val_acc: 0.4332\n",
            "Epoch 17/150 - 0.19s - loss: 1.0639 - acc: 0.4557 - val_loss: 1.0752 - val_acc: 0.4312\n",
            "Epoch 18/150 - 0.20s - loss: 1.0624 - acc: 0.4595 - val_loss: 1.0743 - val_acc: 0.4372\n",
            "Epoch 19/150 - 0.20s - loss: 1.0611 - acc: 0.4586 - val_loss: 1.0730 - val_acc: 0.4251\n",
            "Epoch 20/150 - 0.23s - loss: 1.0598 - acc: 0.4613 - val_loss: 1.0724 - val_acc: 0.4393\n",
            "Epoch 21/150 - 0.20s - loss: 1.0586 - acc: 0.4631 - val_loss: 1.0709 - val_acc: 0.4291\n",
            "Epoch 22/150 - 0.22s - loss: 1.0573 - acc: 0.4642 - val_loss: 1.0704 - val_acc: 0.4393\n",
            "Epoch 23/150 - 0.19s - loss: 1.0561 - acc: 0.4683 - val_loss: 1.0692 - val_acc: 0.4433\n",
            "Epoch 24/150 - 0.21s - loss: 1.0550 - acc: 0.4681 - val_loss: 1.0683 - val_acc: 0.4453\n",
            "Epoch 25/150 - 0.19s - loss: 1.0538 - acc: 0.4692 - val_loss: 1.0677 - val_acc: 0.4453\n",
            "Epoch 26/150 - 0.20s - loss: 1.0528 - acc: 0.4721 - val_loss: 1.0668 - val_acc: 0.4534\n",
            "Epoch 27/150 - 0.21s - loss: 1.0517 - acc: 0.4723 - val_loss: 1.0660 - val_acc: 0.4494\n",
            "Epoch 28/150 - 0.21s - loss: 1.0507 - acc: 0.4714 - val_loss: 1.0652 - val_acc: 0.4514\n",
            "Epoch 29/150 - 0.21s - loss: 1.0497 - acc: 0.4708 - val_loss: 1.0645 - val_acc: 0.4514\n",
            "Epoch 30/150 - 0.22s - loss: 1.0487 - acc: 0.4730 - val_loss: 1.0638 - val_acc: 0.4534\n",
            "Epoch 31/150 - 0.21s - loss: 1.0477 - acc: 0.4746 - val_loss: 1.0629 - val_acc: 0.4615\n",
            "Epoch 32/150 - 0.20s - loss: 1.0468 - acc: 0.4748 - val_loss: 1.0624 - val_acc: 0.4595\n",
            "Epoch 33/150 - 0.21s - loss: 1.0459 - acc: 0.4750 - val_loss: 1.0615 - val_acc: 0.4636\n",
            "Epoch 34/150 - 0.19s - loss: 1.0450 - acc: 0.4759 - val_loss: 1.0609 - val_acc: 0.4737\n",
            "Epoch 35/150 - 0.20s - loss: 1.0442 - acc: 0.4768 - val_loss: 1.0603 - val_acc: 0.4777\n",
            "Epoch 36/150 - 0.19s - loss: 1.0433 - acc: 0.4764 - val_loss: 1.0595 - val_acc: 0.4737\n",
            "Epoch 37/150 - 0.19s - loss: 1.0424 - acc: 0.4780 - val_loss: 1.0590 - val_acc: 0.4737\n",
            "Epoch 38/150 - 0.19s - loss: 1.0416 - acc: 0.4811 - val_loss: 1.0585 - val_acc: 0.4737\n",
            "Epoch 39/150 - 0.22s - loss: 1.0408 - acc: 0.4809 - val_loss: 1.0579 - val_acc: 0.4757\n",
            "Epoch 40/150 - 0.19s - loss: 1.0400 - acc: 0.4811 - val_loss: 1.0573 - val_acc: 0.4777\n",
            "Epoch 41/150 - 0.19s - loss: 1.0392 - acc: 0.4789 - val_loss: 1.0566 - val_acc: 0.4798\n",
            "Epoch 42/150 - 0.20s - loss: 1.0384 - acc: 0.4800 - val_loss: 1.0561 - val_acc: 0.4818\n",
            "Epoch 43/150 - 0.20s - loss: 1.0376 - acc: 0.4838 - val_loss: 1.0556 - val_acc: 0.4818\n",
            "Epoch 44/150 - 0.19s - loss: 1.0369 - acc: 0.4849 - val_loss: 1.0551 - val_acc: 0.4818\n",
            "Epoch 45/150 - 0.20s - loss: 1.0362 - acc: 0.4861 - val_loss: 1.0547 - val_acc: 0.4818\n",
            "Epoch 46/150 - 0.19s - loss: 1.0354 - acc: 0.4865 - val_loss: 1.0541 - val_acc: 0.4818\n",
            "Epoch 47/150 - 0.20s - loss: 1.0346 - acc: 0.4867 - val_loss: 1.0533 - val_acc: 0.4818\n",
            "Epoch 48/150 - 0.19s - loss: 1.0339 - acc: 0.4870 - val_loss: 1.0528 - val_acc: 0.4798\n",
            "Epoch 49/150 - 0.20s - loss: 1.0333 - acc: 0.4883 - val_loss: 1.0525 - val_acc: 0.4838\n",
            "Epoch 50/150 - 0.20s - loss: 1.0325 - acc: 0.4899 - val_loss: 1.0517 - val_acc: 0.4838\n",
            "Epoch 51/150 - 0.20s - loss: 1.0318 - acc: 0.4899 - val_loss: 1.0512 - val_acc: 0.4798\n",
            "Epoch 52/150 - 0.19s - loss: 1.0311 - acc: 0.4894 - val_loss: 1.0508 - val_acc: 0.4858\n",
            "Epoch 53/150 - 0.20s - loss: 1.0304 - acc: 0.4917 - val_loss: 1.0502 - val_acc: 0.4798\n",
            "Epoch 54/150 - 0.19s - loss: 1.0297 - acc: 0.4892 - val_loss: 1.0497 - val_acc: 0.4858\n",
            "Epoch 55/150 - 0.20s - loss: 1.0290 - acc: 0.4942 - val_loss: 1.0491 - val_acc: 0.4818\n",
            "Epoch 56/150 - 0.19s - loss: 1.0283 - acc: 0.4919 - val_loss: 1.0488 - val_acc: 0.4798\n",
            "Epoch 57/150 - 0.21s - loss: 1.0276 - acc: 0.4933 - val_loss: 1.0482 - val_acc: 0.4818\n",
            "Epoch 58/150 - 0.19s - loss: 1.0270 - acc: 0.4957 - val_loss: 1.0479 - val_acc: 0.4858\n",
            "Epoch 59/150 - 0.20s - loss: 1.0263 - acc: 0.4944 - val_loss: 1.0473 - val_acc: 0.4838\n",
            "Epoch 60/150 - 0.21s - loss: 1.0256 - acc: 0.4951 - val_loss: 1.0468 - val_acc: 0.4858\n",
            "Epoch 61/150 - 0.19s - loss: 1.0250 - acc: 0.4948 - val_loss: 1.0464 - val_acc: 0.4899\n",
            "Epoch 62/150 - 0.19s - loss: 1.0243 - acc: 0.4991 - val_loss: 1.0460 - val_acc: 0.4879\n",
            "Epoch 63/150 - 0.20s - loss: 1.0236 - acc: 0.5002 - val_loss: 1.0454 - val_acc: 0.4879\n",
            "Epoch 64/150 - 0.19s - loss: 1.0230 - acc: 0.5000 - val_loss: 1.0450 - val_acc: 0.4919\n",
            "Epoch 65/150 - 0.20s - loss: 1.0224 - acc: 0.5009 - val_loss: 1.0444 - val_acc: 0.4879\n",
            "Epoch 66/150 - 0.19s - loss: 1.0217 - acc: 0.4993 - val_loss: 1.0439 - val_acc: 0.4879\n",
            "Epoch 67/150 - 0.20s - loss: 1.0210 - acc: 0.5013 - val_loss: 1.0434 - val_acc: 0.4939\n",
            "Epoch 68/150 - 0.20s - loss: 1.0204 - acc: 0.5025 - val_loss: 1.0431 - val_acc: 0.4960\n",
            "Epoch 69/150 - 0.20s - loss: 1.0198 - acc: 0.5040 - val_loss: 1.0426 - val_acc: 0.4960\n",
            "Epoch 70/150 - 0.19s - loss: 1.0192 - acc: 0.5043 - val_loss: 1.0424 - val_acc: 0.4980\n",
            "Epoch 71/150 - 0.20s - loss: 1.0185 - acc: 0.5036 - val_loss: 1.0416 - val_acc: 0.4960\n",
            "Epoch 72/150 - 0.19s - loss: 1.0179 - acc: 0.5052 - val_loss: 1.0414 - val_acc: 0.5040\n",
            "Epoch 73/150 - 0.21s - loss: 1.0173 - acc: 0.5049 - val_loss: 1.0408 - val_acc: 0.5020\n",
            "Epoch 74/150 - 0.19s - loss: 1.0166 - acc: 0.5085 - val_loss: 1.0403 - val_acc: 0.5061\n",
            "Epoch 75/150 - 0.21s - loss: 1.0160 - acc: 0.5088 - val_loss: 1.0397 - val_acc: 0.5040\n",
            "Epoch 76/150 - 0.19s - loss: 1.0153 - acc: 0.5083 - val_loss: 1.0393 - val_acc: 0.5061\n",
            "Epoch 77/150 - 0.21s - loss: 1.0147 - acc: 0.5085 - val_loss: 1.0387 - val_acc: 0.5040\n",
            "Epoch 78/150 - 0.19s - loss: 1.0141 - acc: 0.5067 - val_loss: 1.0381 - val_acc: 0.5000\n",
            "Epoch 79/150 - 0.25s - loss: 1.0135 - acc: 0.5092 - val_loss: 1.0379 - val_acc: 0.5061\n",
            "Epoch 80/150 - 0.20s - loss: 1.0128 - acc: 0.5094 - val_loss: 1.0372 - val_acc: 0.5061\n",
            "Epoch 81/150 - 0.20s - loss: 1.0122 - acc: 0.5108 - val_loss: 1.0367 - val_acc: 0.5061\n",
            "Epoch 82/150 - 0.20s - loss: 1.0117 - acc: 0.5065 - val_loss: 1.0361 - val_acc: 0.5061\n",
            "Epoch 83/150 - 0.22s - loss: 1.0110 - acc: 0.5106 - val_loss: 1.0359 - val_acc: 0.5040\n",
            "Epoch 84/150 - 0.20s - loss: 1.0103 - acc: 0.5117 - val_loss: 1.0353 - val_acc: 0.5040\n",
            "Epoch 85/150 - 0.24s - loss: 1.0097 - acc: 0.5121 - val_loss: 1.0348 - val_acc: 0.5040\n",
            "Epoch 86/150 - 0.23s - loss: 1.0092 - acc: 0.5130 - val_loss: 1.0346 - val_acc: 0.5061\n",
            "Epoch 87/150 - 0.22s - loss: 1.0085 - acc: 0.5137 - val_loss: 1.0340 - val_acc: 0.5081\n",
            "Epoch 88/150 - 0.23s - loss: 1.0080 - acc: 0.5119 - val_loss: 1.0333 - val_acc: 0.5061\n",
            "Epoch 89/150 - 0.19s - loss: 1.0075 - acc: 0.5142 - val_loss: 1.0334 - val_acc: 0.5081\n",
            "Epoch 90/150 - 0.20s - loss: 1.0068 - acc: 0.5162 - val_loss: 1.0328 - val_acc: 0.5020\n",
            "Epoch 91/150 - 0.22s - loss: 1.0062 - acc: 0.5160 - val_loss: 1.0325 - val_acc: 0.5121\n",
            "Epoch 92/150 - 0.22s - loss: 1.0057 - acc: 0.5155 - val_loss: 1.0322 - val_acc: 0.5162\n",
            "Epoch 93/150 - 0.21s - loss: 1.0049 - acc: 0.5175 - val_loss: 1.0314 - val_acc: 0.5142\n",
            "Epoch 94/150 - 0.23s - loss: 1.0042 - acc: 0.5164 - val_loss: 1.0304 - val_acc: 0.5061\n",
            "Epoch 95/150 - 0.21s - loss: 1.0037 - acc: 0.5189 - val_loss: 1.0304 - val_acc: 0.5162\n",
            "Epoch 96/150 - 0.20s - loss: 1.0030 - acc: 0.5189 - val_loss: 1.0298 - val_acc: 0.5101\n",
            "Epoch 97/150 - 0.20s - loss: 1.0024 - acc: 0.5189 - val_loss: 1.0291 - val_acc: 0.5040\n",
            "Epoch 98/150 - 0.19s - loss: 1.0019 - acc: 0.5184 - val_loss: 1.0286 - val_acc: 0.5081\n",
            "Epoch 99/150 - 0.21s - loss: 1.0012 - acc: 0.5193 - val_loss: 1.0283 - val_acc: 0.5121\n",
            "Epoch 100/150 - 0.19s - loss: 1.0006 - acc: 0.5193 - val_loss: 1.0276 - val_acc: 0.5081\n",
            "Epoch 101/150 - 0.23s - loss: 1.0000 - acc: 0.5196 - val_loss: 1.0272 - val_acc: 0.5121\n",
            "Epoch 102/150 - 0.19s - loss: 0.9995 - acc: 0.5218 - val_loss: 1.0269 - val_acc: 0.5182\n",
            "Epoch 103/150 - 0.21s - loss: 0.9990 - acc: 0.5207 - val_loss: 1.0270 - val_acc: 0.5182\n",
            "Epoch 104/150 - 0.20s - loss: 0.9982 - acc: 0.5220 - val_loss: 1.0260 - val_acc: 0.5202\n",
            "Epoch 105/150 - 0.20s - loss: 0.9976 - acc: 0.5214 - val_loss: 1.0254 - val_acc: 0.5142\n",
            "Epoch 106/150 - 0.19s - loss: 0.9971 - acc: 0.5202 - val_loss: 1.0247 - val_acc: 0.5142\n",
            "Epoch 107/150 - 0.20s - loss: 0.9964 - acc: 0.5241 - val_loss: 1.0245 - val_acc: 0.5202\n",
            "Epoch 108/150 - 0.19s - loss: 0.9959 - acc: 0.5254 - val_loss: 1.0242 - val_acc: 0.5202\n",
            "Epoch 109/150 - 0.21s - loss: 0.9953 - acc: 0.5232 - val_loss: 1.0233 - val_acc: 0.5162\n",
            "Epoch 110/150 - 0.19s - loss: 0.9947 - acc: 0.5216 - val_loss: 1.0228 - val_acc: 0.5202\n",
            "Epoch 111/150 - 0.22s - loss: 0.9942 - acc: 0.5259 - val_loss: 1.0229 - val_acc: 0.5243\n",
            "Epoch 112/150 - 0.19s - loss: 0.9936 - acc: 0.5272 - val_loss: 1.0224 - val_acc: 0.5162\n",
            "Epoch 113/150 - 0.19s - loss: 0.9929 - acc: 0.5270 - val_loss: 1.0215 - val_acc: 0.5202\n",
            "Epoch 114/150 - 0.19s - loss: 0.9923 - acc: 0.5261 - val_loss: 1.0209 - val_acc: 0.5202\n",
            "Epoch 115/150 - 0.20s - loss: 0.9917 - acc: 0.5268 - val_loss: 1.0205 - val_acc: 0.5223\n",
            "Epoch 116/150 - 0.19s - loss: 0.9912 - acc: 0.5270 - val_loss: 1.0204 - val_acc: 0.5283\n",
            "Epoch 117/150 - 0.20s - loss: 0.9906 - acc: 0.5283 - val_loss: 1.0197 - val_acc: 0.5223\n",
            "Epoch 118/150 - 0.19s - loss: 0.9900 - acc: 0.5263 - val_loss: 1.0190 - val_acc: 0.5283\n",
            "Epoch 119/150 - 0.20s - loss: 0.9894 - acc: 0.5288 - val_loss: 1.0189 - val_acc: 0.5243\n",
            "Epoch 120/150 - 0.19s - loss: 0.9890 - acc: 0.5238 - val_loss: 1.0180 - val_acc: 0.5304\n",
            "Epoch 121/150 - 0.20s - loss: 0.9883 - acc: 0.5272 - val_loss: 1.0180 - val_acc: 0.5344\n",
            "Epoch 122/150 - 0.19s - loss: 0.9879 - acc: 0.5299 - val_loss: 1.0173 - val_acc: 0.5405\n",
            "Epoch 123/150 - 0.19s - loss: 0.9872 - acc: 0.5308 - val_loss: 1.0168 - val_acc: 0.5364\n",
            "Epoch 124/150 - 0.19s - loss: 0.9866 - acc: 0.5313 - val_loss: 1.0164 - val_acc: 0.5364\n",
            "Epoch 125/150 - 0.19s - loss: 0.9865 - acc: 0.5281 - val_loss: 1.0158 - val_acc: 0.5364\n",
            "Epoch 126/150 - 0.19s - loss: 0.9856 - acc: 0.5319 - val_loss: 1.0157 - val_acc: 0.5202\n",
            "Epoch 127/150 - 0.20s - loss: 0.9849 - acc: 0.5319 - val_loss: 1.0152 - val_acc: 0.5263\n",
            "Epoch 128/150 - 0.19s - loss: 0.9843 - acc: 0.5324 - val_loss: 1.0144 - val_acc: 0.5364\n",
            "Epoch 129/150 - 0.20s - loss: 0.9837 - acc: 0.5326 - val_loss: 1.0141 - val_acc: 0.5324\n",
            "Epoch 130/150 - 0.20s - loss: 0.9832 - acc: 0.5326 - val_loss: 1.0135 - val_acc: 0.5283\n",
            "Epoch 131/150 - 0.23s - loss: 0.9827 - acc: 0.5337 - val_loss: 1.0134 - val_acc: 0.5304\n",
            "Epoch 132/150 - 0.19s - loss: 0.9820 - acc: 0.5319 - val_loss: 1.0126 - val_acc: 0.5324\n",
            "Epoch 133/150 - 0.22s - loss: 0.9816 - acc: 0.5331 - val_loss: 1.0126 - val_acc: 0.5304\n",
            "Epoch 134/150 - 0.20s - loss: 0.9809 - acc: 0.5349 - val_loss: 1.0118 - val_acc: 0.5344\n",
            "Epoch 135/150 - 0.21s - loss: 0.9806 - acc: 0.5340 - val_loss: 1.0111 - val_acc: 0.5344\n",
            "Epoch 136/150 - 0.19s - loss: 0.9798 - acc: 0.5353 - val_loss: 1.0108 - val_acc: 0.5344\n",
            "Epoch 137/150 - 0.20s - loss: 0.9794 - acc: 0.5344 - val_loss: 1.0109 - val_acc: 0.5304\n",
            "Epoch 138/150 - 0.19s - loss: 0.9788 - acc: 0.5346 - val_loss: 1.0097 - val_acc: 0.5324\n",
            "Epoch 139/150 - 0.21s - loss: 0.9782 - acc: 0.5349 - val_loss: 1.0093 - val_acc: 0.5344\n",
            "Epoch 140/150 - 0.19s - loss: 0.9778 - acc: 0.5371 - val_loss: 1.0096 - val_acc: 0.5304\n",
            "Epoch 141/150 - 0.21s - loss: 0.9772 - acc: 0.5382 - val_loss: 1.0089 - val_acc: 0.5364\n",
            "Epoch 142/150 - 0.19s - loss: 0.9767 - acc: 0.5378 - val_loss: 1.0083 - val_acc: 0.5405\n",
            "Epoch 143/150 - 0.20s - loss: 0.9761 - acc: 0.5387 - val_loss: 1.0076 - val_acc: 0.5364\n",
            "Epoch 144/150 - 0.20s - loss: 0.9758 - acc: 0.5358 - val_loss: 1.0082 - val_acc: 0.5324\n",
            "Epoch 145/150 - 0.19s - loss: 0.9750 - acc: 0.5376 - val_loss: 1.0067 - val_acc: 0.5364\n",
            "Epoch 146/150 - 0.19s - loss: 0.9745 - acc: 0.5396 - val_loss: 1.0066 - val_acc: 0.5364\n",
            "Epoch 147/150 - 0.20s - loss: 0.9741 - acc: 0.5385 - val_loss: 1.0064 - val_acc: 0.5364\n",
            "Epoch 148/150 - 0.19s - loss: 0.9736 - acc: 0.5385 - val_loss: 1.0060 - val_acc: 0.5344\n",
            "Epoch 149/150 - 0.19s - loss: 0.9729 - acc: 0.5407 - val_loss: 1.0051 - val_acc: 0.5364\n",
            "Epoch 150/150 - 0.19s - loss: 0.9725 - acc: 0.5403 - val_loss: 1.0053 - val_acc: 0.5304\n",
            "\n",
            "Combination 136/252:\n",
            "Hidden Layers: [256, 128], Activation: tanh, Learning Rate: 0.001, Batch Size: 64, Epochs: 50\n",
            "Epoch 1/50 - 0.19s - loss: 1.1020 - acc: 0.3549 - val_loss: 1.1048 - val_acc: 0.3623\n",
            "Epoch 2/50 - 0.16s - loss: 1.0960 - acc: 0.3673 - val_loss: 1.0988 - val_acc: 0.3785\n",
            "Epoch 3/50 - 0.16s - loss: 1.0934 - acc: 0.3716 - val_loss: 1.0962 - val_acc: 0.3806\n",
            "Epoch 4/50 - 0.16s - loss: 1.0915 - acc: 0.3781 - val_loss: 1.0947 - val_acc: 0.3644\n",
            "Epoch 5/50 - 0.17s - loss: 1.0900 - acc: 0.3837 - val_loss: 1.0934 - val_acc: 0.3745\n",
            "Epoch 6/50 - 0.16s - loss: 1.0886 - acc: 0.3896 - val_loss: 1.0922 - val_acc: 0.3806\n",
            "Epoch 7/50 - 0.17s - loss: 1.0873 - acc: 0.3954 - val_loss: 1.0910 - val_acc: 0.3785\n",
            "Epoch 8/50 - 0.16s - loss: 1.0860 - acc: 0.4022 - val_loss: 1.0900 - val_acc: 0.3887\n",
            "Epoch 9/50 - 0.16s - loss: 1.0847 - acc: 0.4037 - val_loss: 1.0891 - val_acc: 0.3968\n",
            "Epoch 10/50 - 0.16s - loss: 1.0835 - acc: 0.4069 - val_loss: 1.0881 - val_acc: 0.4008\n",
            "Epoch 11/50 - 0.18s - loss: 1.0823 - acc: 0.4121 - val_loss: 1.0872 - val_acc: 0.3988\n",
            "Epoch 12/50 - 0.16s - loss: 1.0811 - acc: 0.4134 - val_loss: 1.0863 - val_acc: 0.4049\n",
            "Epoch 13/50 - 0.17s - loss: 1.0800 - acc: 0.4181 - val_loss: 1.0854 - val_acc: 0.4109\n",
            "Epoch 14/50 - 0.16s - loss: 1.0789 - acc: 0.4213 - val_loss: 1.0846 - val_acc: 0.4049\n",
            "Epoch 15/50 - 0.17s - loss: 1.0779 - acc: 0.4240 - val_loss: 1.0838 - val_acc: 0.4109\n",
            "Epoch 16/50 - 0.16s - loss: 1.0768 - acc: 0.4287 - val_loss: 1.0830 - val_acc: 0.4049\n",
            "Epoch 17/50 - 0.18s - loss: 1.0758 - acc: 0.4303 - val_loss: 1.0822 - val_acc: 0.4211\n",
            "Epoch 18/50 - 0.16s - loss: 1.0748 - acc: 0.4339 - val_loss: 1.0813 - val_acc: 0.4291\n",
            "Epoch 19/50 - 0.18s - loss: 1.0738 - acc: 0.4348 - val_loss: 1.0806 - val_acc: 0.4332\n",
            "Epoch 20/50 - 0.16s - loss: 1.0729 - acc: 0.4339 - val_loss: 1.0800 - val_acc: 0.4271\n",
            "Epoch 21/50 - 0.20s - loss: 1.0720 - acc: 0.4361 - val_loss: 1.0794 - val_acc: 0.4231\n",
            "Epoch 22/50 - 0.16s - loss: 1.0711 - acc: 0.4422 - val_loss: 1.0788 - val_acc: 0.4231\n",
            "Epoch 23/50 - 0.16s - loss: 1.0701 - acc: 0.4399 - val_loss: 1.0781 - val_acc: 0.4271\n",
            "Epoch 24/50 - 0.16s - loss: 1.0693 - acc: 0.4413 - val_loss: 1.0773 - val_acc: 0.4413\n",
            "Epoch 25/50 - 0.16s - loss: 1.0684 - acc: 0.4447 - val_loss: 1.0767 - val_acc: 0.4474\n",
            "Epoch 26/50 - 0.16s - loss: 1.0676 - acc: 0.4485 - val_loss: 1.0761 - val_acc: 0.4474\n",
            "Epoch 27/50 - 0.17s - loss: 1.0668 - acc: 0.4512 - val_loss: 1.0755 - val_acc: 0.4494\n",
            "Epoch 28/50 - 0.16s - loss: 1.0659 - acc: 0.4541 - val_loss: 1.0749 - val_acc: 0.4514\n",
            "Epoch 29/50 - 0.17s - loss: 1.0652 - acc: 0.4543 - val_loss: 1.0744 - val_acc: 0.4514\n",
            "Epoch 30/50 - 0.16s - loss: 1.0644 - acc: 0.4559 - val_loss: 1.0739 - val_acc: 0.4555\n",
            "Epoch 31/50 - 0.17s - loss: 1.0636 - acc: 0.4593 - val_loss: 1.0732 - val_acc: 0.4595\n",
            "Epoch 32/50 - 0.16s - loss: 1.0628 - acc: 0.4627 - val_loss: 1.0726 - val_acc: 0.4534\n",
            "Epoch 33/50 - 0.18s - loss: 1.0621 - acc: 0.4638 - val_loss: 1.0721 - val_acc: 0.4555\n",
            "Epoch 34/50 - 0.17s - loss: 1.0614 - acc: 0.4654 - val_loss: 1.0715 - val_acc: 0.4514\n",
            "Epoch 35/50 - 0.18s - loss: 1.0606 - acc: 0.4658 - val_loss: 1.0711 - val_acc: 0.4494\n",
            "Epoch 36/50 - 0.16s - loss: 1.0599 - acc: 0.4674 - val_loss: 1.0706 - val_acc: 0.4494\n",
            "Epoch 37/50 - 0.18s - loss: 1.0592 - acc: 0.4676 - val_loss: 1.0701 - val_acc: 0.4534\n",
            "Epoch 38/50 - 0.16s - loss: 1.0585 - acc: 0.4712 - val_loss: 1.0696 - val_acc: 0.4494\n",
            "Epoch 39/50 - 0.17s - loss: 1.0579 - acc: 0.4728 - val_loss: 1.0691 - val_acc: 0.4514\n",
            "Epoch 40/50 - 0.16s - loss: 1.0572 - acc: 0.4710 - val_loss: 1.0686 - val_acc: 0.4615\n",
            "Epoch 41/50 - 0.19s - loss: 1.0565 - acc: 0.4699 - val_loss: 1.0681 - val_acc: 0.4575\n",
            "Epoch 42/50 - 0.17s - loss: 1.0559 - acc: 0.4705 - val_loss: 1.0677 - val_acc: 0.4615\n",
            "Epoch 43/50 - 0.17s - loss: 1.0553 - acc: 0.4712 - val_loss: 1.0674 - val_acc: 0.4575\n",
            "Epoch 44/50 - 0.16s - loss: 1.0546 - acc: 0.4719 - val_loss: 1.0668 - val_acc: 0.4636\n",
            "Epoch 45/50 - 0.18s - loss: 1.0540 - acc: 0.4721 - val_loss: 1.0664 - val_acc: 0.4656\n",
            "Epoch 46/50 - 0.16s - loss: 1.0534 - acc: 0.4753 - val_loss: 1.0660 - val_acc: 0.4575\n",
            "Epoch 47/50 - 0.18s - loss: 1.0528 - acc: 0.4739 - val_loss: 1.0655 - val_acc: 0.4656\n",
            "Epoch 48/50 - 0.16s - loss: 1.0522 - acc: 0.4744 - val_loss: 1.0651 - val_acc: 0.4656\n",
            "Epoch 49/50 - 0.19s - loss: 1.0516 - acc: 0.4746 - val_loss: 1.0648 - val_acc: 0.4615\n",
            "Epoch 50/50 - 0.16s - loss: 1.0510 - acc: 0.4735 - val_loss: 1.0643 - val_acc: 0.4636\n",
            "\n",
            "Combination 137/252:\n",
            "Hidden Layers: [256, 128], Activation: tanh, Learning Rate: 0.001, Batch Size: 64, Epochs: 100\n",
            "Epoch 1/100 - 0.17s - loss: 1.0941 - acc: 0.3857 - val_loss: 1.0906 - val_acc: 0.3968\n",
            "Epoch 2/100 - 0.17s - loss: 1.0894 - acc: 0.3950 - val_loss: 1.0874 - val_acc: 0.4150\n",
            "Epoch 3/100 - 0.17s - loss: 1.0873 - acc: 0.4031 - val_loss: 1.0861 - val_acc: 0.4069\n",
            "Epoch 4/100 - 0.16s - loss: 1.0858 - acc: 0.4080 - val_loss: 1.0852 - val_acc: 0.4008\n",
            "Epoch 5/100 - 0.18s - loss: 1.0846 - acc: 0.4134 - val_loss: 1.0843 - val_acc: 0.3988\n",
            "Epoch 6/100 - 0.16s - loss: 1.0834 - acc: 0.4184 - val_loss: 1.0835 - val_acc: 0.4231\n",
            "Epoch 7/100 - 0.17s - loss: 1.0823 - acc: 0.4195 - val_loss: 1.0827 - val_acc: 0.4291\n",
            "Epoch 8/100 - 0.17s - loss: 1.0813 - acc: 0.4217 - val_loss: 1.0819 - val_acc: 0.4251\n",
            "Epoch 9/100 - 0.18s - loss: 1.0803 - acc: 0.4238 - val_loss: 1.0812 - val_acc: 0.4231\n",
            "Epoch 10/100 - 0.17s - loss: 1.0793 - acc: 0.4269 - val_loss: 1.0803 - val_acc: 0.4251\n",
            "Epoch 11/100 - 0.20s - loss: 1.0783 - acc: 0.4363 - val_loss: 1.0795 - val_acc: 0.4312\n",
            "Epoch 12/100 - 0.21s - loss: 1.0774 - acc: 0.4393 - val_loss: 1.0789 - val_acc: 0.4291\n",
            "Epoch 13/100 - 0.19s - loss: 1.0764 - acc: 0.4399 - val_loss: 1.0782 - val_acc: 0.4312\n",
            "Epoch 14/100 - 0.16s - loss: 1.0756 - acc: 0.4447 - val_loss: 1.0775 - val_acc: 0.4352\n",
            "Epoch 15/100 - 0.17s - loss: 1.0747 - acc: 0.4467 - val_loss: 1.0768 - val_acc: 0.4372\n",
            "Epoch 16/100 - 0.18s - loss: 1.0738 - acc: 0.4471 - val_loss: 1.0762 - val_acc: 0.4393\n",
            "Epoch 17/100 - 0.17s - loss: 1.0730 - acc: 0.4501 - val_loss: 1.0755 - val_acc: 0.4372\n",
            "Epoch 18/100 - 0.17s - loss: 1.0722 - acc: 0.4534 - val_loss: 1.0748 - val_acc: 0.4413\n",
            "Epoch 19/100 - 0.17s - loss: 1.0714 - acc: 0.4559 - val_loss: 1.0743 - val_acc: 0.4453\n",
            "Epoch 20/100 - 0.17s - loss: 1.0706 - acc: 0.4566 - val_loss: 1.0737 - val_acc: 0.4474\n",
            "Epoch 21/100 - 0.16s - loss: 1.0699 - acc: 0.4546 - val_loss: 1.0732 - val_acc: 0.4494\n",
            "Epoch 22/100 - 0.20s - loss: 1.0691 - acc: 0.4577 - val_loss: 1.0726 - val_acc: 0.4575\n",
            "Epoch 23/100 - 0.18s - loss: 1.0684 - acc: 0.4577 - val_loss: 1.0720 - val_acc: 0.4514\n",
            "Epoch 24/100 - 0.17s - loss: 1.0676 - acc: 0.4582 - val_loss: 1.0715 - val_acc: 0.4534\n",
            "Epoch 25/100 - 0.18s - loss: 1.0669 - acc: 0.4586 - val_loss: 1.0711 - val_acc: 0.4474\n",
            "Epoch 26/100 - 0.18s - loss: 1.0663 - acc: 0.4595 - val_loss: 1.0706 - val_acc: 0.4534\n",
            "Epoch 27/100 - 0.17s - loss: 1.0656 - acc: 0.4595 - val_loss: 1.0701 - val_acc: 0.4575\n",
            "Epoch 28/100 - 0.19s - loss: 1.0649 - acc: 0.4604 - val_loss: 1.0695 - val_acc: 0.4615\n",
            "Epoch 29/100 - 0.18s - loss: 1.0642 - acc: 0.4620 - val_loss: 1.0690 - val_acc: 0.4676\n",
            "Epoch 30/100 - 0.19s - loss: 1.0636 - acc: 0.4631 - val_loss: 1.0685 - val_acc: 0.4696\n",
            "Epoch 31/100 - 0.16s - loss: 1.0629 - acc: 0.4624 - val_loss: 1.0680 - val_acc: 0.4615\n",
            "Epoch 32/100 - 0.18s - loss: 1.0623 - acc: 0.4618 - val_loss: 1.0676 - val_acc: 0.4676\n",
            "Epoch 33/100 - 0.18s - loss: 1.0617 - acc: 0.4649 - val_loss: 1.0671 - val_acc: 0.4676\n",
            "Epoch 34/100 - 0.17s - loss: 1.0610 - acc: 0.4667 - val_loss: 1.0666 - val_acc: 0.4676\n",
            "Epoch 35/100 - 0.17s - loss: 1.0604 - acc: 0.4672 - val_loss: 1.0662 - val_acc: 0.4696\n",
            "Epoch 36/100 - 0.18s - loss: 1.0598 - acc: 0.4667 - val_loss: 1.0658 - val_acc: 0.4737\n",
            "Epoch 37/100 - 0.16s - loss: 1.0592 - acc: 0.4674 - val_loss: 1.0654 - val_acc: 0.4737\n",
            "Epoch 38/100 - 0.18s - loss: 1.0586 - acc: 0.4665 - val_loss: 1.0650 - val_acc: 0.4777\n",
            "Epoch 39/100 - 0.15s - loss: 1.0581 - acc: 0.4676 - val_loss: 1.0646 - val_acc: 0.4717\n",
            "Epoch 40/100 - 0.15s - loss: 1.0575 - acc: 0.4696 - val_loss: 1.0641 - val_acc: 0.4717\n",
            "Epoch 41/100 - 0.15s - loss: 1.0569 - acc: 0.4701 - val_loss: 1.0637 - val_acc: 0.4676\n",
            "Epoch 42/100 - 0.16s - loss: 1.0563 - acc: 0.4726 - val_loss: 1.0632 - val_acc: 0.4737\n",
            "Epoch 43/100 - 0.15s - loss: 1.0558 - acc: 0.4744 - val_loss: 1.0629 - val_acc: 0.4737\n",
            "Epoch 44/100 - 0.15s - loss: 1.0552 - acc: 0.4728 - val_loss: 1.0625 - val_acc: 0.4717\n",
            "Epoch 45/100 - 0.15s - loss: 1.0547 - acc: 0.4723 - val_loss: 1.0621 - val_acc: 0.4717\n",
            "Epoch 46/100 - 0.15s - loss: 1.0541 - acc: 0.4768 - val_loss: 1.0616 - val_acc: 0.4696\n",
            "Epoch 47/100 - 0.15s - loss: 1.0536 - acc: 0.4764 - val_loss: 1.0613 - val_acc: 0.4717\n",
            "Epoch 48/100 - 0.15s - loss: 1.0531 - acc: 0.4762 - val_loss: 1.0609 - val_acc: 0.4696\n",
            "Epoch 49/100 - 0.15s - loss: 1.0525 - acc: 0.4775 - val_loss: 1.0606 - val_acc: 0.4757\n",
            "Epoch 50/100 - 0.20s - loss: 1.0520 - acc: 0.4791 - val_loss: 1.0602 - val_acc: 0.4777\n",
            "Epoch 51/100 - 0.15s - loss: 1.0515 - acc: 0.4791 - val_loss: 1.0598 - val_acc: 0.4737\n",
            "Epoch 52/100 - 0.15s - loss: 1.0510 - acc: 0.4784 - val_loss: 1.0594 - val_acc: 0.4696\n",
            "Epoch 53/100 - 0.15s - loss: 1.0505 - acc: 0.4780 - val_loss: 1.0591 - val_acc: 0.4696\n",
            "Epoch 54/100 - 0.15s - loss: 1.0500 - acc: 0.4789 - val_loss: 1.0587 - val_acc: 0.4676\n",
            "Epoch 55/100 - 0.15s - loss: 1.0495 - acc: 0.4789 - val_loss: 1.0585 - val_acc: 0.4737\n",
            "Epoch 56/100 - 0.16s - loss: 1.0490 - acc: 0.4793 - val_loss: 1.0581 - val_acc: 0.4696\n",
            "Epoch 57/100 - 0.15s - loss: 1.0485 - acc: 0.4793 - val_loss: 1.0577 - val_acc: 0.4656\n",
            "Epoch 58/100 - 0.15s - loss: 1.0480 - acc: 0.4809 - val_loss: 1.0573 - val_acc: 0.4676\n",
            "Epoch 59/100 - 0.15s - loss: 1.0475 - acc: 0.4836 - val_loss: 1.0570 - val_acc: 0.4737\n",
            "Epoch 60/100 - 0.15s - loss: 1.0470 - acc: 0.4831 - val_loss: 1.0567 - val_acc: 0.4737\n",
            "Epoch 61/100 - 0.16s - loss: 1.0465 - acc: 0.4802 - val_loss: 1.0564 - val_acc: 0.4676\n",
            "Epoch 62/100 - 0.15s - loss: 1.0461 - acc: 0.4834 - val_loss: 1.0560 - val_acc: 0.4737\n",
            "Epoch 63/100 - 0.16s - loss: 1.0456 - acc: 0.4831 - val_loss: 1.0557 - val_acc: 0.4737\n",
            "Epoch 64/100 - 0.16s - loss: 1.0451 - acc: 0.4822 - val_loss: 1.0554 - val_acc: 0.4717\n",
            "Epoch 65/100 - 0.16s - loss: 1.0447 - acc: 0.4822 - val_loss: 1.0551 - val_acc: 0.4737\n",
            "Epoch 66/100 - 0.15s - loss: 1.0442 - acc: 0.4822 - val_loss: 1.0547 - val_acc: 0.4717\n",
            "Epoch 67/100 - 0.15s - loss: 1.0437 - acc: 0.4820 - val_loss: 1.0545 - val_acc: 0.4737\n",
            "Epoch 68/100 - 0.16s - loss: 1.0433 - acc: 0.4816 - val_loss: 1.0541 - val_acc: 0.4717\n",
            "Epoch 69/100 - 0.14s - loss: 1.0429 - acc: 0.4843 - val_loss: 1.0540 - val_acc: 0.4798\n",
            "Epoch 70/100 - 0.17s - loss: 1.0424 - acc: 0.4834 - val_loss: 1.0536 - val_acc: 0.4757\n",
            "Epoch 71/100 - 0.15s - loss: 1.0419 - acc: 0.4827 - val_loss: 1.0531 - val_acc: 0.4717\n",
            "Epoch 72/100 - 0.15s - loss: 1.0415 - acc: 0.4840 - val_loss: 1.0527 - val_acc: 0.4737\n",
            "Epoch 73/100 - 0.15s - loss: 1.0410 - acc: 0.4847 - val_loss: 1.0525 - val_acc: 0.4636\n",
            "Epoch 74/100 - 0.16s - loss: 1.0406 - acc: 0.4845 - val_loss: 1.0523 - val_acc: 0.4737\n",
            "Epoch 75/100 - 0.15s - loss: 1.0402 - acc: 0.4847 - val_loss: 1.0519 - val_acc: 0.4717\n",
            "Epoch 76/100 - 0.14s - loss: 1.0397 - acc: 0.4849 - val_loss: 1.0515 - val_acc: 0.4737\n",
            "Epoch 77/100 - 0.16s - loss: 1.0393 - acc: 0.4834 - val_loss: 1.0513 - val_acc: 0.4777\n",
            "Epoch 78/100 - 0.15s - loss: 1.0388 - acc: 0.4845 - val_loss: 1.0509 - val_acc: 0.4737\n",
            "Epoch 79/100 - 0.15s - loss: 1.0384 - acc: 0.4872 - val_loss: 1.0506 - val_acc: 0.4858\n",
            "Epoch 80/100 - 0.15s - loss: 1.0380 - acc: 0.4858 - val_loss: 1.0503 - val_acc: 0.4838\n",
            "Epoch 81/100 - 0.15s - loss: 1.0376 - acc: 0.4863 - val_loss: 1.0500 - val_acc: 0.4858\n",
            "Epoch 82/100 - 0.18s - loss: 1.0371 - acc: 0.4852 - val_loss: 1.0498 - val_acc: 0.4858\n",
            "Epoch 83/100 - 0.15s - loss: 1.0367 - acc: 0.4865 - val_loss: 1.0494 - val_acc: 0.4858\n",
            "Epoch 84/100 - 0.16s - loss: 1.0363 - acc: 0.4874 - val_loss: 1.0491 - val_acc: 0.4818\n",
            "Epoch 85/100 - 0.14s - loss: 1.0359 - acc: 0.4863 - val_loss: 1.0489 - val_acc: 0.4858\n",
            "Epoch 86/100 - 0.15s - loss: 1.0355 - acc: 0.4874 - val_loss: 1.0486 - val_acc: 0.4798\n",
            "Epoch 87/100 - 0.14s - loss: 1.0350 - acc: 0.4870 - val_loss: 1.0484 - val_acc: 0.4838\n",
            "Epoch 88/100 - 0.15s - loss: 1.0346 - acc: 0.4867 - val_loss: 1.0481 - val_acc: 0.4798\n",
            "Epoch 89/100 - 0.15s - loss: 1.0342 - acc: 0.4885 - val_loss: 1.0477 - val_acc: 0.4777\n",
            "Epoch 90/100 - 0.16s - loss: 1.0338 - acc: 0.4879 - val_loss: 1.0474 - val_acc: 0.4798\n",
            "Epoch 91/100 - 0.15s - loss: 1.0334 - acc: 0.4874 - val_loss: 1.0472 - val_acc: 0.4798\n",
            "Epoch 92/100 - 0.15s - loss: 1.0330 - acc: 0.4870 - val_loss: 1.0469 - val_acc: 0.4838\n",
            "Epoch 93/100 - 0.15s - loss: 1.0326 - acc: 0.4883 - val_loss: 1.0466 - val_acc: 0.4879\n",
            "Epoch 94/100 - 0.15s - loss: 1.0322 - acc: 0.4892 - val_loss: 1.0463 - val_acc: 0.4858\n",
            "Epoch 95/100 - 0.14s - loss: 1.0318 - acc: 0.4865 - val_loss: 1.0462 - val_acc: 0.4879\n",
            "Epoch 96/100 - 0.15s - loss: 1.0314 - acc: 0.4874 - val_loss: 1.0459 - val_acc: 0.4858\n",
            "Epoch 97/100 - 0.14s - loss: 1.0310 - acc: 0.4894 - val_loss: 1.0454 - val_acc: 0.4899\n",
            "Epoch 98/100 - 0.15s - loss: 1.0306 - acc: 0.4903 - val_loss: 1.0451 - val_acc: 0.4838\n",
            "Epoch 99/100 - 0.14s - loss: 1.0302 - acc: 0.4894 - val_loss: 1.0449 - val_acc: 0.4879\n",
            "Epoch 100/100 - 0.15s - loss: 1.0298 - acc: 0.4899 - val_loss: 1.0447 - val_acc: 0.4838\n",
            "\n",
            "Combination 138/252:\n",
            "Hidden Layers: [256, 128], Activation: tanh, Learning Rate: 0.001, Batch Size: 64, Epochs: 150\n",
            "Epoch 1/150 - 0.14s - loss: 1.0979 - acc: 0.3621 - val_loss: 1.0993 - val_acc: 0.3725\n",
            "Epoch 2/150 - 0.15s - loss: 1.0911 - acc: 0.3932 - val_loss: 1.0946 - val_acc: 0.3887\n",
            "Epoch 3/150 - 0.14s - loss: 1.0880 - acc: 0.4179 - val_loss: 1.0927 - val_acc: 0.3745\n",
            "Epoch 4/150 - 0.15s - loss: 1.0861 - acc: 0.4163 - val_loss: 1.0916 - val_acc: 0.3684\n",
            "Epoch 5/150 - 0.14s - loss: 1.0848 - acc: 0.4202 - val_loss: 1.0908 - val_acc: 0.3583\n",
            "Epoch 6/150 - 0.16s - loss: 1.0836 - acc: 0.4112 - val_loss: 1.0901 - val_acc: 0.3684\n",
            "Epoch 7/150 - 0.14s - loss: 1.0825 - acc: 0.4159 - val_loss: 1.0894 - val_acc: 0.3725\n",
            "Epoch 8/150 - 0.14s - loss: 1.0815 - acc: 0.4125 - val_loss: 1.0886 - val_acc: 0.3765\n",
            "Epoch 9/150 - 0.14s - loss: 1.0805 - acc: 0.4116 - val_loss: 1.0879 - val_acc: 0.3806\n",
            "Epoch 10/150 - 0.16s - loss: 1.0795 - acc: 0.4130 - val_loss: 1.0872 - val_acc: 0.3785\n",
            "Epoch 11/150 - 0.14s - loss: 1.0786 - acc: 0.4217 - val_loss: 1.0864 - val_acc: 0.3704\n",
            "Epoch 12/150 - 0.15s - loss: 1.0777 - acc: 0.4242 - val_loss: 1.0858 - val_acc: 0.3826\n",
            "Epoch 13/150 - 0.14s - loss: 1.0768 - acc: 0.4260 - val_loss: 1.0851 - val_acc: 0.3826\n",
            "Epoch 14/150 - 0.15s - loss: 1.0760 - acc: 0.4276 - val_loss: 1.0844 - val_acc: 0.3846\n",
            "Epoch 15/150 - 0.14s - loss: 1.0751 - acc: 0.4330 - val_loss: 1.0839 - val_acc: 0.3947\n",
            "Epoch 16/150 - 0.15s - loss: 1.0743 - acc: 0.4334 - val_loss: 1.0832 - val_acc: 0.3968\n",
            "Epoch 17/150 - 0.14s - loss: 1.0736 - acc: 0.4339 - val_loss: 1.0827 - val_acc: 0.4069\n",
            "Epoch 18/150 - 0.15s - loss: 1.0727 - acc: 0.4352 - val_loss: 1.0819 - val_acc: 0.4028\n",
            "Epoch 19/150 - 0.14s - loss: 1.0720 - acc: 0.4352 - val_loss: 1.0813 - val_acc: 0.3968\n",
            "Epoch 20/150 - 0.14s - loss: 1.0713 - acc: 0.4361 - val_loss: 1.0810 - val_acc: 0.4028\n",
            "Epoch 21/150 - 0.14s - loss: 1.0705 - acc: 0.4359 - val_loss: 1.0804 - val_acc: 0.4069\n",
            "Epoch 22/150 - 0.15s - loss: 1.0698 - acc: 0.4408 - val_loss: 1.0798 - val_acc: 0.4190\n",
            "Epoch 23/150 - 0.14s - loss: 1.0691 - acc: 0.4408 - val_loss: 1.0793 - val_acc: 0.4109\n",
            "Epoch 24/150 - 0.14s - loss: 1.0684 - acc: 0.4442 - val_loss: 1.0788 - val_acc: 0.4190\n",
            "Epoch 25/150 - 0.14s - loss: 1.0678 - acc: 0.4487 - val_loss: 1.0782 - val_acc: 0.4211\n",
            "Epoch 26/150 - 0.15s - loss: 1.0671 - acc: 0.4460 - val_loss: 1.0777 - val_acc: 0.4251\n",
            "Epoch 27/150 - 0.14s - loss: 1.0665 - acc: 0.4467 - val_loss: 1.0772 - val_acc: 0.4291\n",
            "Epoch 28/150 - 0.15s - loss: 1.0658 - acc: 0.4485 - val_loss: 1.0768 - val_acc: 0.4312\n",
            "Epoch 29/150 - 0.14s - loss: 1.0652 - acc: 0.4521 - val_loss: 1.0764 - val_acc: 0.4332\n",
            "Epoch 30/150 - 0.15s - loss: 1.0646 - acc: 0.4537 - val_loss: 1.0759 - val_acc: 0.4352\n",
            "Epoch 31/150 - 0.16s - loss: 1.0639 - acc: 0.4541 - val_loss: 1.0754 - val_acc: 0.4372\n",
            "Epoch 32/150 - 0.14s - loss: 1.0633 - acc: 0.4514 - val_loss: 1.0749 - val_acc: 0.4312\n",
            "Epoch 33/150 - 0.14s - loss: 1.0627 - acc: 0.4591 - val_loss: 1.0746 - val_acc: 0.4372\n",
            "Epoch 34/150 - 0.15s - loss: 1.0621 - acc: 0.4568 - val_loss: 1.0740 - val_acc: 0.4352\n",
            "Epoch 35/150 - 0.14s - loss: 1.0616 - acc: 0.4627 - val_loss: 1.0737 - val_acc: 0.4393\n",
            "Epoch 36/150 - 0.15s - loss: 1.0610 - acc: 0.4582 - val_loss: 1.0731 - val_acc: 0.4393\n",
            "Epoch 37/150 - 0.14s - loss: 1.0604 - acc: 0.4606 - val_loss: 1.0727 - val_acc: 0.4393\n",
            "Epoch 38/150 - 0.15s - loss: 1.0599 - acc: 0.4672 - val_loss: 1.0723 - val_acc: 0.4433\n",
            "Epoch 39/150 - 0.15s - loss: 1.0593 - acc: 0.4624 - val_loss: 1.0719 - val_acc: 0.4453\n",
            "Epoch 40/150 - 0.21s - loss: 1.0587 - acc: 0.4615 - val_loss: 1.0716 - val_acc: 0.4453\n",
            "Epoch 41/150 - 0.15s - loss: 1.0582 - acc: 0.4656 - val_loss: 1.0711 - val_acc: 0.4453\n",
            "Epoch 42/150 - 0.17s - loss: 1.0576 - acc: 0.4672 - val_loss: 1.0707 - val_acc: 0.4413\n",
            "Epoch 43/150 - 0.15s - loss: 1.0571 - acc: 0.4678 - val_loss: 1.0703 - val_acc: 0.4413\n",
            "Epoch 44/150 - 0.15s - loss: 1.0566 - acc: 0.4669 - val_loss: 1.0699 - val_acc: 0.4433\n",
            "Epoch 45/150 - 0.16s - loss: 1.0561 - acc: 0.4683 - val_loss: 1.0696 - val_acc: 0.4474\n",
            "Epoch 46/150 - 0.15s - loss: 1.0555 - acc: 0.4681 - val_loss: 1.0692 - val_acc: 0.4474\n",
            "Epoch 47/150 - 0.16s - loss: 1.0550 - acc: 0.4710 - val_loss: 1.0688 - val_acc: 0.4474\n",
            "Epoch 48/150 - 0.15s - loss: 1.0545 - acc: 0.4714 - val_loss: 1.0686 - val_acc: 0.4494\n",
            "Epoch 49/150 - 0.15s - loss: 1.0540 - acc: 0.4721 - val_loss: 1.0682 - val_acc: 0.4494\n",
            "Epoch 50/150 - 0.18s - loss: 1.0535 - acc: 0.4708 - val_loss: 1.0677 - val_acc: 0.4514\n",
            "Epoch 51/150 - 0.15s - loss: 1.0530 - acc: 0.4705 - val_loss: 1.0674 - val_acc: 0.4453\n",
            "Epoch 52/150 - 0.14s - loss: 1.0525 - acc: 0.4694 - val_loss: 1.0670 - val_acc: 0.4534\n",
            "Epoch 53/150 - 0.15s - loss: 1.0520 - acc: 0.4710 - val_loss: 1.0667 - val_acc: 0.4453\n",
            "Epoch 54/150 - 0.16s - loss: 1.0515 - acc: 0.4714 - val_loss: 1.0662 - val_acc: 0.4534\n",
            "Epoch 55/150 - 0.14s - loss: 1.0510 - acc: 0.4728 - val_loss: 1.0659 - val_acc: 0.4575\n",
            "Epoch 56/150 - 0.16s - loss: 1.0505 - acc: 0.4744 - val_loss: 1.0657 - val_acc: 0.4474\n",
            "Epoch 57/150 - 0.14s - loss: 1.0501 - acc: 0.4746 - val_loss: 1.0653 - val_acc: 0.4494\n",
            "Epoch 58/150 - 0.16s - loss: 1.0496 - acc: 0.4750 - val_loss: 1.0650 - val_acc: 0.4534\n",
            "Epoch 59/150 - 0.15s - loss: 1.0491 - acc: 0.4750 - val_loss: 1.0646 - val_acc: 0.4534\n",
            "Epoch 60/150 - 0.15s - loss: 1.0486 - acc: 0.4759 - val_loss: 1.0642 - val_acc: 0.4555\n",
            "Epoch 61/150 - 0.15s - loss: 1.0482 - acc: 0.4762 - val_loss: 1.0639 - val_acc: 0.4534\n",
            "Epoch 62/150 - 0.15s - loss: 1.0477 - acc: 0.4755 - val_loss: 1.0636 - val_acc: 0.4595\n",
            "Epoch 63/150 - 0.15s - loss: 1.0472 - acc: 0.4773 - val_loss: 1.0633 - val_acc: 0.4534\n",
            "Epoch 64/150 - 0.15s - loss: 1.0468 - acc: 0.4771 - val_loss: 1.0629 - val_acc: 0.4575\n",
            "Epoch 65/150 - 0.14s - loss: 1.0463 - acc: 0.4780 - val_loss: 1.0625 - val_acc: 0.4575\n",
            "Epoch 66/150 - 0.16s - loss: 1.0459 - acc: 0.4798 - val_loss: 1.0623 - val_acc: 0.4575\n",
            "Epoch 67/150 - 0.14s - loss: 1.0454 - acc: 0.4795 - val_loss: 1.0619 - val_acc: 0.4575\n",
            "Epoch 68/150 - 0.15s - loss: 1.0450 - acc: 0.4784 - val_loss: 1.0617 - val_acc: 0.4514\n",
            "Epoch 69/150 - 0.19s - loss: 1.0445 - acc: 0.4795 - val_loss: 1.0613 - val_acc: 0.4534\n",
            "Epoch 70/150 - 0.15s - loss: 1.0441 - acc: 0.4800 - val_loss: 1.0609 - val_acc: 0.4615\n",
            "Epoch 71/150 - 0.15s - loss: 1.0436 - acc: 0.4800 - val_loss: 1.0606 - val_acc: 0.4595\n",
            "Epoch 72/150 - 0.16s - loss: 1.0432 - acc: 0.4807 - val_loss: 1.0603 - val_acc: 0.4595\n",
            "Epoch 73/150 - 0.14s - loss: 1.0428 - acc: 0.4807 - val_loss: 1.0599 - val_acc: 0.4656\n",
            "Epoch 74/150 - 0.16s - loss: 1.0423 - acc: 0.4838 - val_loss: 1.0596 - val_acc: 0.4636\n",
            "Epoch 75/150 - 0.14s - loss: 1.0419 - acc: 0.4852 - val_loss: 1.0594 - val_acc: 0.4615\n",
            "Epoch 76/150 - 0.15s - loss: 1.0415 - acc: 0.4836 - val_loss: 1.0591 - val_acc: 0.4615\n",
            "Epoch 77/150 - 0.15s - loss: 1.0410 - acc: 0.4849 - val_loss: 1.0588 - val_acc: 0.4636\n",
            "Epoch 78/150 - 0.16s - loss: 1.0406 - acc: 0.4845 - val_loss: 1.0584 - val_acc: 0.4615\n",
            "Epoch 79/150 - 0.15s - loss: 1.0402 - acc: 0.4854 - val_loss: 1.0583 - val_acc: 0.4555\n",
            "Epoch 80/150 - 0.16s - loss: 1.0397 - acc: 0.4863 - val_loss: 1.0580 - val_acc: 0.4595\n",
            "Epoch 81/150 - 0.15s - loss: 1.0393 - acc: 0.4854 - val_loss: 1.0575 - val_acc: 0.4595\n",
            "Epoch 82/150 - 0.16s - loss: 1.0389 - acc: 0.4838 - val_loss: 1.0572 - val_acc: 0.4595\n",
            "Epoch 83/150 - 0.15s - loss: 1.0385 - acc: 0.4849 - val_loss: 1.0569 - val_acc: 0.4615\n",
            "Epoch 84/150 - 0.15s - loss: 1.0381 - acc: 0.4852 - val_loss: 1.0566 - val_acc: 0.4615\n",
            "Epoch 85/150 - 0.15s - loss: 1.0376 - acc: 0.4843 - val_loss: 1.0563 - val_acc: 0.4615\n",
            "Epoch 86/150 - 0.15s - loss: 1.0372 - acc: 0.4831 - val_loss: 1.0560 - val_acc: 0.4636\n",
            "Epoch 87/150 - 0.14s - loss: 1.0368 - acc: 0.4843 - val_loss: 1.0557 - val_acc: 0.4636\n",
            "Epoch 88/150 - 0.14s - loss: 1.0364 - acc: 0.4847 - val_loss: 1.0554 - val_acc: 0.4636\n",
            "Epoch 89/150 - 0.18s - loss: 1.0360 - acc: 0.4843 - val_loss: 1.0551 - val_acc: 0.4636\n",
            "Epoch 90/150 - 0.15s - loss: 1.0356 - acc: 0.4847 - val_loss: 1.0548 - val_acc: 0.4636\n",
            "Epoch 91/150 - 0.15s - loss: 1.0352 - acc: 0.4865 - val_loss: 1.0546 - val_acc: 0.4656\n",
            "Epoch 92/150 - 0.15s - loss: 1.0348 - acc: 0.4865 - val_loss: 1.0543 - val_acc: 0.4676\n",
            "Epoch 93/150 - 0.17s - loss: 1.0344 - acc: 0.4867 - val_loss: 1.0540 - val_acc: 0.4656\n",
            "Epoch 94/150 - 0.20s - loss: 1.0340 - acc: 0.4870 - val_loss: 1.0536 - val_acc: 0.4636\n",
            "Epoch 95/150 - 0.16s - loss: 1.0336 - acc: 0.4894 - val_loss: 1.0533 - val_acc: 0.4636\n",
            "Epoch 96/150 - 0.17s - loss: 1.0332 - acc: 0.4856 - val_loss: 1.0531 - val_acc: 0.4636\n",
            "Epoch 97/150 - 0.18s - loss: 1.0328 - acc: 0.4872 - val_loss: 1.0528 - val_acc: 0.4676\n",
            "Epoch 98/150 - 0.16s - loss: 1.0324 - acc: 0.4863 - val_loss: 1.0524 - val_acc: 0.4676\n",
            "Epoch 99/150 - 0.15s - loss: 1.0320 - acc: 0.4870 - val_loss: 1.0522 - val_acc: 0.4636\n",
            "Epoch 100/150 - 0.15s - loss: 1.0316 - acc: 0.4899 - val_loss: 1.0520 - val_acc: 0.4737\n",
            "Epoch 101/150 - 0.15s - loss: 1.0312 - acc: 0.4899 - val_loss: 1.0516 - val_acc: 0.4676\n",
            "Epoch 102/150 - 0.15s - loss: 1.0308 - acc: 0.4899 - val_loss: 1.0513 - val_acc: 0.4737\n",
            "Epoch 103/150 - 0.14s - loss: 1.0304 - acc: 0.4894 - val_loss: 1.0510 - val_acc: 0.4717\n",
            "Epoch 104/150 - 0.15s - loss: 1.0300 - acc: 0.4928 - val_loss: 1.0509 - val_acc: 0.4717\n",
            "Epoch 105/150 - 0.15s - loss: 1.0296 - acc: 0.4917 - val_loss: 1.0505 - val_acc: 0.4737\n",
            "Epoch 106/150 - 0.20s - loss: 1.0292 - acc: 0.4915 - val_loss: 1.0502 - val_acc: 0.4737\n",
            "Epoch 107/150 - 0.15s - loss: 1.0288 - acc: 0.4919 - val_loss: 1.0499 - val_acc: 0.4737\n",
            "Epoch 108/150 - 0.14s - loss: 1.0285 - acc: 0.4926 - val_loss: 1.0496 - val_acc: 0.4696\n",
            "Epoch 109/150 - 0.15s - loss: 1.0281 - acc: 0.4921 - val_loss: 1.0493 - val_acc: 0.4737\n",
            "Epoch 110/150 - 0.15s - loss: 1.0277 - acc: 0.4926 - val_loss: 1.0489 - val_acc: 0.4757\n",
            "Epoch 111/150 - 0.15s - loss: 1.0273 - acc: 0.4935 - val_loss: 1.0487 - val_acc: 0.4777\n",
            "Epoch 112/150 - 0.15s - loss: 1.0269 - acc: 0.4971 - val_loss: 1.0486 - val_acc: 0.4757\n",
            "Epoch 113/150 - 0.14s - loss: 1.0266 - acc: 0.4971 - val_loss: 1.0484 - val_acc: 0.4757\n",
            "Epoch 114/150 - 0.17s - loss: 1.0262 - acc: 0.4955 - val_loss: 1.0479 - val_acc: 0.4798\n",
            "Epoch 115/150 - 0.15s - loss: 1.0258 - acc: 0.4962 - val_loss: 1.0477 - val_acc: 0.4798\n",
            "Epoch 116/150 - 0.16s - loss: 1.0254 - acc: 0.4971 - val_loss: 1.0475 - val_acc: 0.4858\n",
            "Epoch 117/150 - 0.15s - loss: 1.0251 - acc: 0.4944 - val_loss: 1.0472 - val_acc: 0.4818\n",
            "Epoch 118/150 - 0.15s - loss: 1.0247 - acc: 0.4951 - val_loss: 1.0468 - val_acc: 0.4838\n",
            "Epoch 119/150 - 0.14s - loss: 1.0243 - acc: 0.4978 - val_loss: 1.0465 - val_acc: 0.4838\n",
            "Epoch 120/150 - 0.15s - loss: 1.0239 - acc: 0.4973 - val_loss: 1.0462 - val_acc: 0.4777\n",
            "Epoch 121/150 - 0.14s - loss: 1.0235 - acc: 0.4973 - val_loss: 1.0460 - val_acc: 0.4858\n",
            "Epoch 122/150 - 0.16s - loss: 1.0232 - acc: 0.4993 - val_loss: 1.0458 - val_acc: 0.4818\n",
            "Epoch 123/150 - 0.14s - loss: 1.0228 - acc: 0.4991 - val_loss: 1.0455 - val_acc: 0.4838\n",
            "Epoch 124/150 - 0.16s - loss: 1.0224 - acc: 0.4971 - val_loss: 1.0451 - val_acc: 0.4858\n",
            "Epoch 125/150 - 0.16s - loss: 1.0221 - acc: 0.4973 - val_loss: 1.0448 - val_acc: 0.4879\n",
            "Epoch 126/150 - 0.21s - loss: 1.0217 - acc: 0.4982 - val_loss: 1.0445 - val_acc: 0.4879\n",
            "Epoch 127/150 - 0.16s - loss: 1.0213 - acc: 0.5002 - val_loss: 1.0443 - val_acc: 0.4798\n",
            "Epoch 128/150 - 0.16s - loss: 1.0209 - acc: 0.5034 - val_loss: 1.0442 - val_acc: 0.4858\n",
            "Epoch 129/150 - 0.16s - loss: 1.0206 - acc: 0.5016 - val_loss: 1.0438 - val_acc: 0.4818\n",
            "Epoch 130/150 - 0.18s - loss: 1.0202 - acc: 0.4993 - val_loss: 1.0434 - val_acc: 0.4818\n",
            "Epoch 131/150 - 0.16s - loss: 1.0198 - acc: 0.5027 - val_loss: 1.0432 - val_acc: 0.4798\n",
            "Epoch 132/150 - 0.16s - loss: 1.0195 - acc: 0.5022 - val_loss: 1.0429 - val_acc: 0.4798\n",
            "Epoch 133/150 - 0.15s - loss: 1.0191 - acc: 0.5016 - val_loss: 1.0426 - val_acc: 0.4818\n",
            "Epoch 134/150 - 0.17s - loss: 1.0187 - acc: 0.5022 - val_loss: 1.0424 - val_acc: 0.4838\n",
            "Epoch 135/150 - 0.16s - loss: 1.0184 - acc: 0.5049 - val_loss: 1.0422 - val_acc: 0.4838\n",
            "Epoch 136/150 - 0.16s - loss: 1.0180 - acc: 0.5040 - val_loss: 1.0419 - val_acc: 0.4838\n",
            "Epoch 137/150 - 0.17s - loss: 1.0177 - acc: 0.5038 - val_loss: 1.0416 - val_acc: 0.4818\n",
            "Epoch 138/150 - 0.18s - loss: 1.0173 - acc: 0.5054 - val_loss: 1.0414 - val_acc: 0.4879\n",
            "Epoch 139/150 - 0.16s - loss: 1.0169 - acc: 0.5049 - val_loss: 1.0411 - val_acc: 0.4879\n",
            "Epoch 140/150 - 0.17s - loss: 1.0165 - acc: 0.5045 - val_loss: 1.0407 - val_acc: 0.4838\n",
            "Epoch 141/150 - 0.17s - loss: 1.0162 - acc: 0.5036 - val_loss: 1.0404 - val_acc: 0.4858\n",
            "Epoch 142/150 - 0.17s - loss: 1.0158 - acc: 0.5049 - val_loss: 1.0401 - val_acc: 0.4858\n",
            "Epoch 143/150 - 0.18s - loss: 1.0154 - acc: 0.5034 - val_loss: 1.0399 - val_acc: 0.4879\n",
            "Epoch 144/150 - 0.17s - loss: 1.0151 - acc: 0.5034 - val_loss: 1.0396 - val_acc: 0.4899\n",
            "Epoch 145/150 - 0.18s - loss: 1.0147 - acc: 0.5029 - val_loss: 1.0393 - val_acc: 0.4879\n",
            "Epoch 146/150 - 0.17s - loss: 1.0144 - acc: 0.5049 - val_loss: 1.0390 - val_acc: 0.4939\n",
            "Epoch 147/150 - 0.16s - loss: 1.0140 - acc: 0.5049 - val_loss: 1.0388 - val_acc: 0.4899\n",
            "Epoch 148/150 - 0.16s - loss: 1.0136 - acc: 0.5049 - val_loss: 1.0385 - val_acc: 0.4919\n",
            "Epoch 149/150 - 0.16s - loss: 1.0133 - acc: 0.5049 - val_loss: 1.0383 - val_acc: 0.4960\n",
            "Epoch 150/150 - 0.17s - loss: 1.0129 - acc: 0.5058 - val_loss: 1.0380 - val_acc: 0.4939\n",
            "\n",
            "Combination 139/252:\n",
            "Hidden Layers: [256, 128], Activation: tanh, Learning Rate: 0.0001, Batch Size: 32, Epochs: 50\n",
            "Epoch 1/50 - 0.19s - loss: 1.0987 - acc: 0.3423 - val_loss: 1.1003 - val_acc: 0.3239\n",
            "Epoch 2/50 - 0.21s - loss: 1.0982 - acc: 0.3441 - val_loss: 1.0998 - val_acc: 0.3381\n",
            "Epoch 3/50 - 0.19s - loss: 1.0977 - acc: 0.3439 - val_loss: 1.0993 - val_acc: 0.3441\n",
            "Epoch 4/50 - 0.20s - loss: 1.0973 - acc: 0.3446 - val_loss: 1.0989 - val_acc: 0.3482\n",
            "Epoch 5/50 - 0.20s - loss: 1.0969 - acc: 0.3462 - val_loss: 1.0985 - val_acc: 0.3522\n",
            "Epoch 6/50 - 0.21s - loss: 1.0965 - acc: 0.3464 - val_loss: 1.0981 - val_acc: 0.3462\n",
            "Epoch 7/50 - 0.19s - loss: 1.0962 - acc: 0.3475 - val_loss: 1.0978 - val_acc: 0.3563\n",
            "Epoch 8/50 - 0.21s - loss: 1.0959 - acc: 0.3498 - val_loss: 1.0974 - val_acc: 0.3583\n",
            "Epoch 9/50 - 0.19s - loss: 1.0955 - acc: 0.3536 - val_loss: 1.0971 - val_acc: 0.3623\n",
            "Epoch 10/50 - 0.20s - loss: 1.0952 - acc: 0.3570 - val_loss: 1.0968 - val_acc: 0.3563\n",
            "Epoch 11/50 - 0.19s - loss: 1.0949 - acc: 0.3581 - val_loss: 1.0965 - val_acc: 0.3603\n",
            "Epoch 12/50 - 0.20s - loss: 1.0946 - acc: 0.3574 - val_loss: 1.0963 - val_acc: 0.3603\n",
            "Epoch 13/50 - 0.19s - loss: 1.0943 - acc: 0.3574 - val_loss: 1.0960 - val_acc: 0.3644\n",
            "Epoch 14/50 - 0.22s - loss: 1.0940 - acc: 0.3578 - val_loss: 1.0957 - val_acc: 0.3623\n",
            "Epoch 15/50 - 0.19s - loss: 1.0937 - acc: 0.3592 - val_loss: 1.0955 - val_acc: 0.3623\n",
            "Epoch 16/50 - 0.22s - loss: 1.0935 - acc: 0.3594 - val_loss: 1.0952 - val_acc: 0.3644\n",
            "Epoch 17/50 - 0.22s - loss: 1.0932 - acc: 0.3605 - val_loss: 1.0950 - val_acc: 0.3684\n",
            "Epoch 18/50 - 0.22s - loss: 1.0929 - acc: 0.3612 - val_loss: 1.0947 - val_acc: 0.3684\n",
            "Epoch 19/50 - 0.20s - loss: 1.0926 - acc: 0.3617 - val_loss: 1.0945 - val_acc: 0.3664\n",
            "Epoch 20/50 - 0.19s - loss: 1.0924 - acc: 0.3637 - val_loss: 1.0943 - val_acc: 0.3725\n",
            "Epoch 21/50 - 0.18s - loss: 1.0921 - acc: 0.3657 - val_loss: 1.0940 - val_acc: 0.3725\n",
            "Epoch 22/50 - 0.19s - loss: 1.0918 - acc: 0.3691 - val_loss: 1.0938 - val_acc: 0.3765\n",
            "Epoch 23/50 - 0.18s - loss: 1.0916 - acc: 0.3682 - val_loss: 1.0936 - val_acc: 0.3745\n",
            "Epoch 24/50 - 0.19s - loss: 1.0913 - acc: 0.3709 - val_loss: 1.0934 - val_acc: 0.3765\n",
            "Epoch 25/50 - 0.18s - loss: 1.0910 - acc: 0.3718 - val_loss: 1.0931 - val_acc: 0.3806\n",
            "Epoch 26/50 - 0.19s - loss: 1.0908 - acc: 0.3740 - val_loss: 1.0929 - val_acc: 0.3846\n",
            "Epoch 27/50 - 0.18s - loss: 1.0905 - acc: 0.3758 - val_loss: 1.0927 - val_acc: 0.3866\n",
            "Epoch 28/50 - 0.20s - loss: 1.0903 - acc: 0.3788 - val_loss: 1.0925 - val_acc: 0.3927\n",
            "Epoch 29/50 - 0.18s - loss: 1.0900 - acc: 0.3812 - val_loss: 1.0923 - val_acc: 0.3927\n",
            "Epoch 30/50 - 0.19s - loss: 1.0898 - acc: 0.3815 - val_loss: 1.0921 - val_acc: 0.3887\n",
            "Epoch 31/50 - 0.18s - loss: 1.0895 - acc: 0.3839 - val_loss: 1.0919 - val_acc: 0.3887\n",
            "Epoch 32/50 - 0.20s - loss: 1.0893 - acc: 0.3848 - val_loss: 1.0917 - val_acc: 0.3866\n",
            "Epoch 33/50 - 0.18s - loss: 1.0891 - acc: 0.3860 - val_loss: 1.0915 - val_acc: 0.3866\n",
            "Epoch 34/50 - 0.19s - loss: 1.0888 - acc: 0.3882 - val_loss: 1.0913 - val_acc: 0.3866\n",
            "Epoch 35/50 - 0.18s - loss: 1.0886 - acc: 0.3891 - val_loss: 1.0911 - val_acc: 0.3907\n",
            "Epoch 36/50 - 0.19s - loss: 1.0883 - acc: 0.3900 - val_loss: 1.0909 - val_acc: 0.3907\n",
            "Epoch 37/50 - 0.18s - loss: 1.0881 - acc: 0.3916 - val_loss: 1.0907 - val_acc: 0.3866\n",
            "Epoch 38/50 - 0.19s - loss: 1.0879 - acc: 0.3934 - val_loss: 1.0905 - val_acc: 0.3866\n",
            "Epoch 39/50 - 0.19s - loss: 1.0876 - acc: 0.3947 - val_loss: 1.0903 - val_acc: 0.3846\n",
            "Epoch 40/50 - 0.20s - loss: 1.0874 - acc: 0.3947 - val_loss: 1.0901 - val_acc: 0.3907\n",
            "Epoch 41/50 - 0.18s - loss: 1.0872 - acc: 0.3959 - val_loss: 1.0900 - val_acc: 0.3887\n",
            "Epoch 42/50 - 0.19s - loss: 1.0870 - acc: 0.3970 - val_loss: 1.0898 - val_acc: 0.3887\n",
            "Epoch 43/50 - 0.18s - loss: 1.0867 - acc: 0.3979 - val_loss: 1.0896 - val_acc: 0.3866\n",
            "Epoch 44/50 - 0.19s - loss: 1.0865 - acc: 0.3983 - val_loss: 1.0894 - val_acc: 0.3887\n",
            "Epoch 45/50 - 0.18s - loss: 1.0863 - acc: 0.3990 - val_loss: 1.0892 - val_acc: 0.3927\n",
            "Epoch 46/50 - 0.19s - loss: 1.0861 - acc: 0.4013 - val_loss: 1.0891 - val_acc: 0.3947\n",
            "Epoch 47/50 - 0.18s - loss: 1.0858 - acc: 0.4010 - val_loss: 1.0889 - val_acc: 0.3947\n",
            "Epoch 48/50 - 0.20s - loss: 1.0856 - acc: 0.4008 - val_loss: 1.0887 - val_acc: 0.3968\n",
            "Epoch 49/50 - 0.19s - loss: 1.0854 - acc: 0.4001 - val_loss: 1.0885 - val_acc: 0.3927\n",
            "Epoch 50/50 - 0.20s - loss: 1.0852 - acc: 0.4010 - val_loss: 1.0884 - val_acc: 0.3887\n",
            "\n",
            "Combination 140/252:\n",
            "Hidden Layers: [256, 128], Activation: tanh, Learning Rate: 0.0001, Batch Size: 32, Epochs: 100\n",
            "Epoch 1/100 - 0.18s - loss: 1.1005 - acc: 0.3464 - val_loss: 1.1010 - val_acc: 0.3178\n",
            "Epoch 2/100 - 0.21s - loss: 1.0998 - acc: 0.3468 - val_loss: 1.1002 - val_acc: 0.3198\n",
            "Epoch 3/100 - 0.18s - loss: 1.0992 - acc: 0.3518 - val_loss: 1.0995 - val_acc: 0.3198\n",
            "Epoch 4/100 - 0.19s - loss: 1.0986 - acc: 0.3522 - val_loss: 1.0988 - val_acc: 0.3219\n",
            "Epoch 5/100 - 0.18s - loss: 1.0982 - acc: 0.3552 - val_loss: 1.0983 - val_acc: 0.3300\n",
            "Epoch 6/100 - 0.20s - loss: 1.0977 - acc: 0.3574 - val_loss: 1.0978 - val_acc: 0.3340\n",
            "Epoch 7/100 - 0.18s - loss: 1.0973 - acc: 0.3578 - val_loss: 1.0974 - val_acc: 0.3340\n",
            "Epoch 8/100 - 0.19s - loss: 1.0969 - acc: 0.3583 - val_loss: 1.0970 - val_acc: 0.3300\n",
            "Epoch 9/100 - 0.18s - loss: 1.0966 - acc: 0.3574 - val_loss: 1.0966 - val_acc: 0.3300\n",
            "Epoch 10/100 - 0.19s - loss: 1.0962 - acc: 0.3590 - val_loss: 1.0963 - val_acc: 0.3320\n",
            "Epoch 11/100 - 0.18s - loss: 1.0959 - acc: 0.3596 - val_loss: 1.0960 - val_acc: 0.3320\n",
            "Epoch 12/100 - 0.19s - loss: 1.0955 - acc: 0.3623 - val_loss: 1.0956 - val_acc: 0.3381\n",
            "Epoch 13/100 - 0.19s - loss: 1.0952 - acc: 0.3646 - val_loss: 1.0953 - val_acc: 0.3381\n",
            "Epoch 14/100 - 0.19s - loss: 1.0949 - acc: 0.3648 - val_loss: 1.0951 - val_acc: 0.3401\n",
            "Epoch 15/100 - 0.18s - loss: 1.0946 - acc: 0.3648 - val_loss: 1.0948 - val_acc: 0.3441\n",
            "Epoch 16/100 - 0.20s - loss: 1.0943 - acc: 0.3655 - val_loss: 1.0945 - val_acc: 0.3462\n",
            "Epoch 17/100 - 0.18s - loss: 1.0940 - acc: 0.3668 - val_loss: 1.0942 - val_acc: 0.3502\n",
            "Epoch 18/100 - 0.19s - loss: 1.0937 - acc: 0.3695 - val_loss: 1.0940 - val_acc: 0.3482\n",
            "Epoch 19/100 - 0.18s - loss: 1.0934 - acc: 0.3686 - val_loss: 1.0937 - val_acc: 0.3502\n",
            "Epoch 20/100 - 0.19s - loss: 1.0931 - acc: 0.3709 - val_loss: 1.0935 - val_acc: 0.3543\n",
            "Epoch 21/100 - 0.20s - loss: 1.0928 - acc: 0.3729 - val_loss: 1.0932 - val_acc: 0.3563\n",
            "Epoch 22/100 - 0.19s - loss: 1.0925 - acc: 0.3752 - val_loss: 1.0930 - val_acc: 0.3563\n",
            "Epoch 23/100 - 0.18s - loss: 1.0922 - acc: 0.3756 - val_loss: 1.0927 - val_acc: 0.3583\n",
            "Epoch 24/100 - 0.19s - loss: 1.0919 - acc: 0.3776 - val_loss: 1.0925 - val_acc: 0.3603\n",
            "Epoch 25/100 - 0.18s - loss: 1.0916 - acc: 0.3803 - val_loss: 1.0922 - val_acc: 0.3644\n",
            "Epoch 26/100 - 0.19s - loss: 1.0913 - acc: 0.3790 - val_loss: 1.0920 - val_acc: 0.3684\n",
            "Epoch 27/100 - 0.18s - loss: 1.0910 - acc: 0.3792 - val_loss: 1.0918 - val_acc: 0.3684\n",
            "Epoch 28/100 - 0.19s - loss: 1.0908 - acc: 0.3806 - val_loss: 1.0915 - val_acc: 0.3725\n",
            "Epoch 29/100 - 0.18s - loss: 1.0905 - acc: 0.3824 - val_loss: 1.0913 - val_acc: 0.3745\n",
            "Epoch 30/100 - 0.19s - loss: 1.0902 - acc: 0.3833 - val_loss: 1.0911 - val_acc: 0.3806\n",
            "Epoch 31/100 - 0.18s - loss: 1.0899 - acc: 0.3830 - val_loss: 1.0909 - val_acc: 0.3806\n",
            "Epoch 32/100 - 0.20s - loss: 1.0897 - acc: 0.3833 - val_loss: 1.0907 - val_acc: 0.3826\n",
            "Epoch 33/100 - 0.20s - loss: 1.0894 - acc: 0.3842 - val_loss: 1.0904 - val_acc: 0.3866\n",
            "Epoch 34/100 - 0.21s - loss: 1.0891 - acc: 0.3844 - val_loss: 1.0902 - val_acc: 0.3907\n",
            "Epoch 35/100 - 0.18s - loss: 1.0889 - acc: 0.3853 - val_loss: 1.0900 - val_acc: 0.3907\n",
            "Epoch 36/100 - 0.19s - loss: 1.0886 - acc: 0.3864 - val_loss: 1.0898 - val_acc: 0.3866\n",
            "Epoch 37/100 - 0.18s - loss: 1.0883 - acc: 0.3862 - val_loss: 1.0896 - val_acc: 0.3846\n",
            "Epoch 38/100 - 0.19s - loss: 1.0881 - acc: 0.3880 - val_loss: 1.0894 - val_acc: 0.3927\n",
            "Epoch 39/100 - 0.18s - loss: 1.0878 - acc: 0.3893 - val_loss: 1.0892 - val_acc: 0.3947\n",
            "Epoch 40/100 - 0.20s - loss: 1.0876 - acc: 0.3898 - val_loss: 1.0890 - val_acc: 0.3947\n",
            "Epoch 41/100 - 0.20s - loss: 1.0873 - acc: 0.3907 - val_loss: 1.0888 - val_acc: 0.3988\n",
            "Epoch 42/100 - 0.19s - loss: 1.0871 - acc: 0.3920 - val_loss: 1.0886 - val_acc: 0.4008\n",
            "Epoch 43/100 - 0.18s - loss: 1.0868 - acc: 0.3914 - val_loss: 1.0884 - val_acc: 0.3988\n",
            "Epoch 44/100 - 0.19s - loss: 1.0866 - acc: 0.3927 - val_loss: 1.0882 - val_acc: 0.3988\n",
            "Epoch 45/100 - 0.19s - loss: 1.0863 - acc: 0.3950 - val_loss: 1.0880 - val_acc: 0.4008\n",
            "Epoch 46/100 - 0.20s - loss: 1.0861 - acc: 0.3963 - val_loss: 1.0878 - val_acc: 0.3988\n",
            "Epoch 47/100 - 0.18s - loss: 1.0858 - acc: 0.3963 - val_loss: 1.0876 - val_acc: 0.4008\n",
            "Epoch 48/100 - 0.19s - loss: 1.0856 - acc: 0.3963 - val_loss: 1.0874 - val_acc: 0.4089\n",
            "Epoch 49/100 - 0.18s - loss: 1.0854 - acc: 0.3968 - val_loss: 1.0872 - val_acc: 0.4049\n",
            "Epoch 50/100 - 0.19s - loss: 1.0851 - acc: 0.3977 - val_loss: 1.0870 - val_acc: 0.4069\n",
            "Epoch 51/100 - 0.18s - loss: 1.0849 - acc: 0.4001 - val_loss: 1.0868 - val_acc: 0.4049\n",
            "Epoch 52/100 - 0.19s - loss: 1.0846 - acc: 0.4015 - val_loss: 1.0867 - val_acc: 0.4109\n",
            "Epoch 53/100 - 0.18s - loss: 1.0844 - acc: 0.4028 - val_loss: 1.0865 - val_acc: 0.4089\n",
            "Epoch 54/100 - 0.19s - loss: 1.0842 - acc: 0.4044 - val_loss: 1.0863 - val_acc: 0.4069\n",
            "Epoch 55/100 - 0.18s - loss: 1.0839 - acc: 0.4055 - val_loss: 1.0861 - val_acc: 0.4069\n",
            "Epoch 56/100 - 0.19s - loss: 1.0837 - acc: 0.4067 - val_loss: 1.0859 - val_acc: 0.4049\n",
            "Epoch 57/100 - 0.19s - loss: 1.0835 - acc: 0.4073 - val_loss: 1.0857 - val_acc: 0.4069\n",
            "Epoch 58/100 - 0.20s - loss: 1.0833 - acc: 0.4085 - val_loss: 1.0856 - val_acc: 0.4089\n",
            "Epoch 59/100 - 0.18s - loss: 1.0830 - acc: 0.4087 - val_loss: 1.0854 - val_acc: 0.4069\n",
            "Epoch 60/100 - 0.21s - loss: 1.0828 - acc: 0.4094 - val_loss: 1.0852 - val_acc: 0.4089\n",
            "Epoch 61/100 - 0.18s - loss: 1.0826 - acc: 0.4107 - val_loss: 1.0850 - val_acc: 0.4150\n",
            "Epoch 62/100 - 0.20s - loss: 1.0824 - acc: 0.4107 - val_loss: 1.0849 - val_acc: 0.4170\n",
            "Epoch 63/100 - 0.18s - loss: 1.0822 - acc: 0.4116 - val_loss: 1.0847 - val_acc: 0.4190\n",
            "Epoch 64/100 - 0.20s - loss: 1.0819 - acc: 0.4125 - val_loss: 1.0845 - val_acc: 0.4190\n",
            "Epoch 65/100 - 0.18s - loss: 1.0817 - acc: 0.4123 - val_loss: 1.0844 - val_acc: 0.4211\n",
            "Epoch 66/100 - 0.19s - loss: 1.0815 - acc: 0.4130 - val_loss: 1.0842 - val_acc: 0.4190\n",
            "Epoch 67/100 - 0.19s - loss: 1.0813 - acc: 0.4141 - val_loss: 1.0840 - val_acc: 0.4211\n",
            "Epoch 68/100 - 0.20s - loss: 1.0811 - acc: 0.4152 - val_loss: 1.0839 - val_acc: 0.4211\n",
            "Epoch 69/100 - 0.19s - loss: 1.0809 - acc: 0.4170 - val_loss: 1.0837 - val_acc: 0.4211\n",
            "Epoch 70/100 - 0.19s - loss: 1.0807 - acc: 0.4159 - val_loss: 1.0835 - val_acc: 0.4231\n",
            "Epoch 71/100 - 0.18s - loss: 1.0804 - acc: 0.4168 - val_loss: 1.0834 - val_acc: 0.4231\n",
            "Epoch 72/100 - 0.20s - loss: 1.0802 - acc: 0.4168 - val_loss: 1.0832 - val_acc: 0.4251\n",
            "Epoch 73/100 - 0.18s - loss: 1.0800 - acc: 0.4170 - val_loss: 1.0830 - val_acc: 0.4251\n",
            "Epoch 74/100 - 0.19s - loss: 1.0798 - acc: 0.4181 - val_loss: 1.0829 - val_acc: 0.4271\n",
            "Epoch 75/100 - 0.19s - loss: 1.0796 - acc: 0.4184 - val_loss: 1.0827 - val_acc: 0.4271\n",
            "Epoch 76/100 - 0.20s - loss: 1.0794 - acc: 0.4179 - val_loss: 1.0826 - val_acc: 0.4291\n",
            "Epoch 77/100 - 0.19s - loss: 1.0792 - acc: 0.4193 - val_loss: 1.0824 - val_acc: 0.4271\n",
            "Epoch 78/100 - 0.20s - loss: 1.0790 - acc: 0.4190 - val_loss: 1.0823 - val_acc: 0.4271\n",
            "Epoch 79/100 - 0.20s - loss: 1.0788 - acc: 0.4184 - val_loss: 1.0821 - val_acc: 0.4271\n",
            "Epoch 80/100 - 0.22s - loss: 1.0786 - acc: 0.4202 - val_loss: 1.0820 - val_acc: 0.4291\n",
            "Epoch 81/100 - 0.20s - loss: 1.0784 - acc: 0.4199 - val_loss: 1.0818 - val_acc: 0.4291\n",
            "Epoch 82/100 - 0.19s - loss: 1.0782 - acc: 0.4202 - val_loss: 1.0817 - val_acc: 0.4291\n",
            "Epoch 83/100 - 0.18s - loss: 1.0780 - acc: 0.4215 - val_loss: 1.0815 - val_acc: 0.4291\n",
            "Epoch 84/100 - 0.19s - loss: 1.0778 - acc: 0.4213 - val_loss: 1.0814 - val_acc: 0.4291\n",
            "Epoch 85/100 - 0.20s - loss: 1.0777 - acc: 0.4213 - val_loss: 1.0812 - val_acc: 0.4271\n",
            "Epoch 86/100 - 0.21s - loss: 1.0775 - acc: 0.4224 - val_loss: 1.0811 - val_acc: 0.4271\n",
            "Epoch 87/100 - 0.19s - loss: 1.0773 - acc: 0.4226 - val_loss: 1.0809 - val_acc: 0.4271\n",
            "Epoch 88/100 - 0.21s - loss: 1.0771 - acc: 0.4224 - val_loss: 1.0808 - val_acc: 0.4271\n",
            "Epoch 89/100 - 0.18s - loss: 1.0769 - acc: 0.4235 - val_loss: 1.0806 - val_acc: 0.4291\n",
            "Epoch 90/100 - 0.19s - loss: 1.0767 - acc: 0.4235 - val_loss: 1.0805 - val_acc: 0.4291\n",
            "Epoch 91/100 - 0.19s - loss: 1.0765 - acc: 0.4247 - val_loss: 1.0803 - val_acc: 0.4291\n",
            "Epoch 92/100 - 0.19s - loss: 1.0763 - acc: 0.4251 - val_loss: 1.0802 - val_acc: 0.4332\n",
            "Epoch 93/100 - 0.18s - loss: 1.0762 - acc: 0.4269 - val_loss: 1.0801 - val_acc: 0.4332\n",
            "Epoch 94/100 - 0.20s - loss: 1.0760 - acc: 0.4271 - val_loss: 1.0799 - val_acc: 0.4271\n",
            "Epoch 95/100 - 0.20s - loss: 1.0758 - acc: 0.4280 - val_loss: 1.0798 - val_acc: 0.4251\n",
            "Epoch 96/100 - 0.20s - loss: 1.0756 - acc: 0.4287 - val_loss: 1.0796 - val_acc: 0.4231\n",
            "Epoch 97/100 - 0.18s - loss: 1.0754 - acc: 0.4289 - val_loss: 1.0795 - val_acc: 0.4251\n",
            "Epoch 98/100 - 0.22s - loss: 1.0752 - acc: 0.4303 - val_loss: 1.0794 - val_acc: 0.4251\n",
            "Epoch 99/100 - 0.19s - loss: 1.0751 - acc: 0.4309 - val_loss: 1.0792 - val_acc: 0.4271\n",
            "Epoch 100/100 - 0.19s - loss: 1.0749 - acc: 0.4312 - val_loss: 1.0791 - val_acc: 0.4291\n",
            "\n",
            "Combination 141/252:\n",
            "Hidden Layers: [256, 128], Activation: tanh, Learning Rate: 0.0001, Batch Size: 32, Epochs: 150\n",
            "Epoch 1/150 - 0.19s - loss: 1.1116 - acc: 0.3369 - val_loss: 1.1067 - val_acc: 0.3401\n",
            "Epoch 2/150 - 0.20s - loss: 1.1082 - acc: 0.3423 - val_loss: 1.1040 - val_acc: 0.3401\n",
            "Epoch 3/150 - 0.18s - loss: 1.1056 - acc: 0.3486 - val_loss: 1.1020 - val_acc: 0.3522\n",
            "Epoch 4/150 - 0.19s - loss: 1.1036 - acc: 0.3502 - val_loss: 1.1005 - val_acc: 0.3563\n",
            "Epoch 5/150 - 0.19s - loss: 1.1020 - acc: 0.3466 - val_loss: 1.0993 - val_acc: 0.3623\n",
            "Epoch 6/150 - 0.20s - loss: 1.1007 - acc: 0.3473 - val_loss: 1.0984 - val_acc: 0.3623\n",
            "Epoch 7/150 - 0.18s - loss: 1.0996 - acc: 0.3475 - val_loss: 1.0977 - val_acc: 0.3522\n",
            "Epoch 8/150 - 0.19s - loss: 1.0988 - acc: 0.3527 - val_loss: 1.0971 - val_acc: 0.3543\n",
            "Epoch 9/150 - 0.19s - loss: 1.0980 - acc: 0.3534 - val_loss: 1.0966 - val_acc: 0.3502\n",
            "Epoch 10/150 - 0.22s - loss: 1.0974 - acc: 0.3534 - val_loss: 1.0962 - val_acc: 0.3502\n",
            "Epoch 11/150 - 0.19s - loss: 1.0968 - acc: 0.3534 - val_loss: 1.0958 - val_acc: 0.3502\n",
            "Epoch 12/150 - 0.20s - loss: 1.0963 - acc: 0.3552 - val_loss: 1.0955 - val_acc: 0.3563\n",
            "Epoch 13/150 - 0.19s - loss: 1.0959 - acc: 0.3605 - val_loss: 1.0952 - val_acc: 0.3522\n",
            "Epoch 14/150 - 0.21s - loss: 1.0955 - acc: 0.3599 - val_loss: 1.0949 - val_acc: 0.3522\n",
            "Epoch 15/150 - 0.19s - loss: 1.0951 - acc: 0.3596 - val_loss: 1.0946 - val_acc: 0.3583\n",
            "Epoch 16/150 - 0.24s - loss: 1.0947 - acc: 0.3596 - val_loss: 1.0944 - val_acc: 0.3543\n",
            "Epoch 17/150 - 0.19s - loss: 1.0944 - acc: 0.3605 - val_loss: 1.0941 - val_acc: 0.3502\n",
            "Epoch 18/150 - 0.21s - loss: 1.0940 - acc: 0.3639 - val_loss: 1.0939 - val_acc: 0.3522\n",
            "Epoch 19/150 - 0.20s - loss: 1.0937 - acc: 0.3650 - val_loss: 1.0937 - val_acc: 0.3502\n",
            "Epoch 20/150 - 0.20s - loss: 1.0934 - acc: 0.3657 - val_loss: 1.0934 - val_acc: 0.3543\n",
            "Epoch 21/150 - 0.18s - loss: 1.0931 - acc: 0.3675 - val_loss: 1.0932 - val_acc: 0.3543\n",
            "Epoch 22/150 - 0.20s - loss: 1.0928 - acc: 0.3698 - val_loss: 1.0929 - val_acc: 0.3543\n",
            "Epoch 23/150 - 0.19s - loss: 1.0925 - acc: 0.3729 - val_loss: 1.0927 - val_acc: 0.3543\n",
            "Epoch 24/150 - 0.19s - loss: 1.0922 - acc: 0.3740 - val_loss: 1.0925 - val_acc: 0.3522\n",
            "Epoch 25/150 - 0.18s - loss: 1.0919 - acc: 0.3752 - val_loss: 1.0922 - val_acc: 0.3502\n",
            "Epoch 26/150 - 0.19s - loss: 1.0916 - acc: 0.3743 - val_loss: 1.0920 - val_acc: 0.3502\n",
            "Epoch 27/150 - 0.18s - loss: 1.0913 - acc: 0.3731 - val_loss: 1.0918 - val_acc: 0.3502\n",
            "Epoch 28/150 - 0.19s - loss: 1.0911 - acc: 0.3725 - val_loss: 1.0916 - val_acc: 0.3522\n",
            "Epoch 29/150 - 0.19s - loss: 1.0908 - acc: 0.3743 - val_loss: 1.0913 - val_acc: 0.3502\n",
            "Epoch 30/150 - 0.20s - loss: 1.0905 - acc: 0.3758 - val_loss: 1.0911 - val_acc: 0.3522\n",
            "Epoch 31/150 - 0.18s - loss: 1.0903 - acc: 0.3747 - val_loss: 1.0909 - val_acc: 0.3502\n",
            "Epoch 32/150 - 0.20s - loss: 1.0900 - acc: 0.3743 - val_loss: 1.0907 - val_acc: 0.3502\n",
            "Epoch 33/150 - 0.18s - loss: 1.0897 - acc: 0.3763 - val_loss: 1.0904 - val_acc: 0.3522\n",
            "Epoch 34/150 - 0.21s - loss: 1.0895 - acc: 0.3776 - val_loss: 1.0902 - val_acc: 0.3502\n",
            "Epoch 35/150 - 0.19s - loss: 1.0892 - acc: 0.3794 - val_loss: 1.0900 - val_acc: 0.3502\n",
            "Epoch 36/150 - 0.20s - loss: 1.0890 - acc: 0.3790 - val_loss: 1.0898 - val_acc: 0.3522\n",
            "Epoch 37/150 - 0.18s - loss: 1.0887 - acc: 0.3794 - val_loss: 1.0895 - val_acc: 0.3502\n",
            "Epoch 38/150 - 0.20s - loss: 1.0884 - acc: 0.3803 - val_loss: 1.0893 - val_acc: 0.3522\n",
            "Epoch 39/150 - 0.19s - loss: 1.0882 - acc: 0.3815 - val_loss: 1.0891 - val_acc: 0.3522\n",
            "Epoch 40/150 - 0.19s - loss: 1.0879 - acc: 0.3819 - val_loss: 1.0889 - val_acc: 0.3502\n",
            "Epoch 41/150 - 0.19s - loss: 1.0877 - acc: 0.3819 - val_loss: 1.0887 - val_acc: 0.3522\n",
            "Epoch 42/150 - 0.21s - loss: 1.0875 - acc: 0.3828 - val_loss: 1.0885 - val_acc: 0.3543\n",
            "Epoch 43/150 - 0.19s - loss: 1.0872 - acc: 0.3835 - val_loss: 1.0883 - val_acc: 0.3522\n",
            "Epoch 44/150 - 0.21s - loss: 1.0870 - acc: 0.3855 - val_loss: 1.0881 - val_acc: 0.3543\n",
            "Epoch 45/150 - 0.19s - loss: 1.0867 - acc: 0.3864 - val_loss: 1.0879 - val_acc: 0.3543\n",
            "Epoch 46/150 - 0.20s - loss: 1.0865 - acc: 0.3882 - val_loss: 1.0877 - val_acc: 0.3563\n",
            "Epoch 47/150 - 0.18s - loss: 1.0863 - acc: 0.3887 - val_loss: 1.0875 - val_acc: 0.3583\n",
            "Epoch 48/150 - 0.19s - loss: 1.0860 - acc: 0.3891 - val_loss: 1.0873 - val_acc: 0.3543\n",
            "Epoch 49/150 - 0.19s - loss: 1.0858 - acc: 0.3909 - val_loss: 1.0871 - val_acc: 0.3583\n",
            "Epoch 50/150 - 0.21s - loss: 1.0856 - acc: 0.3929 - val_loss: 1.0869 - val_acc: 0.3583\n",
            "Epoch 51/150 - 0.21s - loss: 1.0853 - acc: 0.3943 - val_loss: 1.0867 - val_acc: 0.3623\n",
            "Epoch 52/150 - 0.21s - loss: 1.0851 - acc: 0.3945 - val_loss: 1.0865 - val_acc: 0.3583\n",
            "Epoch 53/150 - 0.18s - loss: 1.0849 - acc: 0.3929 - val_loss: 1.0863 - val_acc: 0.3583\n",
            "Epoch 54/150 - 0.19s - loss: 1.0847 - acc: 0.3934 - val_loss: 1.0861 - val_acc: 0.3603\n",
            "Epoch 55/150 - 0.18s - loss: 1.0844 - acc: 0.3950 - val_loss: 1.0859 - val_acc: 0.3623\n",
            "Epoch 56/150 - 0.20s - loss: 1.0842 - acc: 0.3954 - val_loss: 1.0857 - val_acc: 0.3623\n",
            "Epoch 57/150 - 0.19s - loss: 1.0840 - acc: 0.3970 - val_loss: 1.0855 - val_acc: 0.3664\n",
            "Epoch 58/150 - 0.21s - loss: 1.0838 - acc: 0.3963 - val_loss: 1.0853 - val_acc: 0.3664\n",
            "Epoch 59/150 - 0.18s - loss: 1.0836 - acc: 0.3986 - val_loss: 1.0851 - val_acc: 0.3725\n",
            "Epoch 60/150 - 0.20s - loss: 1.0834 - acc: 0.3999 - val_loss: 1.0850 - val_acc: 0.3725\n",
            "Epoch 61/150 - 0.19s - loss: 1.0831 - acc: 0.4004 - val_loss: 1.0848 - val_acc: 0.3725\n",
            "Epoch 62/150 - 0.21s - loss: 1.0829 - acc: 0.4019 - val_loss: 1.0846 - val_acc: 0.3725\n",
            "Epoch 63/150 - 0.20s - loss: 1.0827 - acc: 0.4026 - val_loss: 1.0844 - val_acc: 0.3725\n",
            "Epoch 64/150 - 0.20s - loss: 1.0825 - acc: 0.4024 - val_loss: 1.0843 - val_acc: 0.3725\n",
            "Epoch 65/150 - 0.20s - loss: 1.0823 - acc: 0.4031 - val_loss: 1.0841 - val_acc: 0.3725\n",
            "Epoch 66/150 - 0.19s - loss: 1.0821 - acc: 0.4031 - val_loss: 1.0839 - val_acc: 0.3664\n",
            "Epoch 67/150 - 0.19s - loss: 1.0819 - acc: 0.4049 - val_loss: 1.0837 - val_acc: 0.3684\n",
            "Epoch 68/150 - 0.22s - loss: 1.0817 - acc: 0.4062 - val_loss: 1.0836 - val_acc: 0.3704\n",
            "Epoch 69/150 - 0.19s - loss: 1.0815 - acc: 0.4076 - val_loss: 1.0834 - val_acc: 0.3725\n",
            "Epoch 70/150 - 0.21s - loss: 1.0813 - acc: 0.4076 - val_loss: 1.0832 - val_acc: 0.3725\n",
            "Epoch 71/150 - 0.18s - loss: 1.0811 - acc: 0.4069 - val_loss: 1.0831 - val_acc: 0.3725\n",
            "Epoch 72/150 - 0.20s - loss: 1.0809 - acc: 0.4078 - val_loss: 1.0829 - val_acc: 0.3704\n",
            "Epoch 73/150 - 0.19s - loss: 1.0807 - acc: 0.4082 - val_loss: 1.0827 - val_acc: 0.3664\n",
            "Epoch 74/150 - 0.19s - loss: 1.0805 - acc: 0.4076 - val_loss: 1.0826 - val_acc: 0.3684\n",
            "Epoch 75/150 - 0.18s - loss: 1.0803 - acc: 0.4082 - val_loss: 1.0824 - val_acc: 0.3664\n",
            "Epoch 76/150 - 0.20s - loss: 1.0801 - acc: 0.4094 - val_loss: 1.0822 - val_acc: 0.3684\n",
            "Epoch 77/150 - 0.18s - loss: 1.0799 - acc: 0.4109 - val_loss: 1.0821 - val_acc: 0.3725\n",
            "Epoch 78/150 - 0.19s - loss: 1.0797 - acc: 0.4123 - val_loss: 1.0819 - val_acc: 0.3725\n",
            "Epoch 79/150 - 0.18s - loss: 1.0795 - acc: 0.4130 - val_loss: 1.0817 - val_acc: 0.3745\n",
            "Epoch 80/150 - 0.20s - loss: 1.0794 - acc: 0.4150 - val_loss: 1.0816 - val_acc: 0.3745\n",
            "Epoch 81/150 - 0.19s - loss: 1.0792 - acc: 0.4157 - val_loss: 1.0814 - val_acc: 0.3745\n",
            "Epoch 82/150 - 0.19s - loss: 1.0790 - acc: 0.4159 - val_loss: 1.0813 - val_acc: 0.3745\n",
            "Epoch 83/150 - 0.19s - loss: 1.0788 - acc: 0.4175 - val_loss: 1.0811 - val_acc: 0.3765\n",
            "Epoch 84/150 - 0.20s - loss: 1.0786 - acc: 0.4175 - val_loss: 1.0810 - val_acc: 0.3745\n",
            "Epoch 85/150 - 0.18s - loss: 1.0784 - acc: 0.4186 - val_loss: 1.0808 - val_acc: 0.3745\n",
            "Epoch 86/150 - 0.21s - loss: 1.0783 - acc: 0.4199 - val_loss: 1.0806 - val_acc: 0.3745\n",
            "Epoch 87/150 - 0.18s - loss: 1.0781 - acc: 0.4208 - val_loss: 1.0805 - val_acc: 0.3745\n",
            "Epoch 88/150 - 0.20s - loss: 1.0779 - acc: 0.4204 - val_loss: 1.0803 - val_acc: 0.3745\n",
            "Epoch 89/150 - 0.19s - loss: 1.0777 - acc: 0.4211 - val_loss: 1.0802 - val_acc: 0.3725\n",
            "Epoch 90/150 - 0.20s - loss: 1.0775 - acc: 0.4215 - val_loss: 1.0801 - val_acc: 0.3725\n",
            "Epoch 91/150 - 0.19s - loss: 1.0774 - acc: 0.4224 - val_loss: 1.0799 - val_acc: 0.3725\n",
            "Epoch 92/150 - 0.21s - loss: 1.0772 - acc: 0.4224 - val_loss: 1.0798 - val_acc: 0.3704\n",
            "Epoch 93/150 - 0.19s - loss: 1.0770 - acc: 0.4226 - val_loss: 1.0796 - val_acc: 0.3725\n",
            "Epoch 94/150 - 0.19s - loss: 1.0768 - acc: 0.4226 - val_loss: 1.0795 - val_acc: 0.3725\n",
            "Epoch 95/150 - 0.19s - loss: 1.0767 - acc: 0.4238 - val_loss: 1.0793 - val_acc: 0.3765\n",
            "Epoch 96/150 - 0.20s - loss: 1.0765 - acc: 0.4247 - val_loss: 1.0792 - val_acc: 0.3765\n",
            "Epoch 97/150 - 0.20s - loss: 1.0763 - acc: 0.4251 - val_loss: 1.0790 - val_acc: 0.3765\n",
            "Epoch 98/150 - 0.22s - loss: 1.0761 - acc: 0.4262 - val_loss: 1.0789 - val_acc: 0.3765\n",
            "Epoch 99/150 - 0.19s - loss: 1.0760 - acc: 0.4274 - val_loss: 1.0787 - val_acc: 0.3785\n",
            "Epoch 100/150 - 0.20s - loss: 1.0758 - acc: 0.4280 - val_loss: 1.0786 - val_acc: 0.3806\n",
            "Epoch 101/150 - 0.20s - loss: 1.0756 - acc: 0.4285 - val_loss: 1.0785 - val_acc: 0.3826\n",
            "Epoch 102/150 - 0.19s - loss: 1.0755 - acc: 0.4287 - val_loss: 1.0783 - val_acc: 0.3846\n",
            "Epoch 103/150 - 0.18s - loss: 1.0753 - acc: 0.4287 - val_loss: 1.0782 - val_acc: 0.3846\n",
            "Epoch 104/150 - 0.20s - loss: 1.0751 - acc: 0.4296 - val_loss: 1.0781 - val_acc: 0.3866\n",
            "Epoch 105/150 - 0.20s - loss: 1.0750 - acc: 0.4307 - val_loss: 1.0779 - val_acc: 0.3866\n",
            "Epoch 106/150 - 0.19s - loss: 1.0748 - acc: 0.4314 - val_loss: 1.0778 - val_acc: 0.3907\n",
            "Epoch 107/150 - 0.19s - loss: 1.0747 - acc: 0.4314 - val_loss: 1.0777 - val_acc: 0.3927\n",
            "Epoch 108/150 - 0.18s - loss: 1.0745 - acc: 0.4300 - val_loss: 1.0775 - val_acc: 0.3907\n",
            "Epoch 109/150 - 0.19s - loss: 1.0743 - acc: 0.4300 - val_loss: 1.0774 - val_acc: 0.3907\n",
            "Epoch 110/150 - 0.18s - loss: 1.0742 - acc: 0.4303 - val_loss: 1.0773 - val_acc: 0.3907\n",
            "Epoch 111/150 - 0.19s - loss: 1.0740 - acc: 0.4312 - val_loss: 1.0771 - val_acc: 0.3927\n",
            "Epoch 112/150 - 0.18s - loss: 1.0739 - acc: 0.4312 - val_loss: 1.0770 - val_acc: 0.3907\n",
            "Epoch 113/150 - 0.19s - loss: 1.0737 - acc: 0.4318 - val_loss: 1.0769 - val_acc: 0.3887\n",
            "Epoch 114/150 - 0.18s - loss: 1.0735 - acc: 0.4316 - val_loss: 1.0767 - val_acc: 0.3866\n",
            "Epoch 115/150 - 0.20s - loss: 1.0734 - acc: 0.4332 - val_loss: 1.0766 - val_acc: 0.3866\n",
            "Epoch 116/150 - 0.18s - loss: 1.0732 - acc: 0.4341 - val_loss: 1.0765 - val_acc: 0.3866\n",
            "Epoch 117/150 - 0.19s - loss: 1.0731 - acc: 0.4348 - val_loss: 1.0764 - val_acc: 0.3866\n",
            "Epoch 118/150 - 0.18s - loss: 1.0729 - acc: 0.4345 - val_loss: 1.0762 - val_acc: 0.3866\n",
            "Epoch 119/150 - 0.20s - loss: 1.0728 - acc: 0.4350 - val_loss: 1.0761 - val_acc: 0.3866\n",
            "Epoch 120/150 - 0.20s - loss: 1.0726 - acc: 0.4357 - val_loss: 1.0760 - val_acc: 0.3846\n",
            "Epoch 121/150 - 0.21s - loss: 1.0725 - acc: 0.4361 - val_loss: 1.0759 - val_acc: 0.3866\n",
            "Epoch 122/150 - 0.18s - loss: 1.0723 - acc: 0.4377 - val_loss: 1.0757 - val_acc: 0.3866\n",
            "Epoch 123/150 - 0.21s - loss: 1.0722 - acc: 0.4384 - val_loss: 1.0756 - val_acc: 0.3866\n",
            "Epoch 124/150 - 0.19s - loss: 1.0720 - acc: 0.4388 - val_loss: 1.0755 - val_acc: 0.3887\n",
            "Epoch 125/150 - 0.20s - loss: 1.0719 - acc: 0.4393 - val_loss: 1.0754 - val_acc: 0.3887\n",
            "Epoch 126/150 - 0.19s - loss: 1.0717 - acc: 0.4399 - val_loss: 1.0752 - val_acc: 0.3846\n",
            "Epoch 127/150 - 0.20s - loss: 1.0716 - acc: 0.4402 - val_loss: 1.0751 - val_acc: 0.3866\n",
            "Epoch 128/150 - 0.19s - loss: 1.0714 - acc: 0.4404 - val_loss: 1.0750 - val_acc: 0.3907\n",
            "Epoch 129/150 - 0.19s - loss: 1.0713 - acc: 0.4406 - val_loss: 1.0749 - val_acc: 0.3907\n",
            "Epoch 130/150 - 0.18s - loss: 1.0711 - acc: 0.4415 - val_loss: 1.0748 - val_acc: 0.3907\n",
            "Epoch 131/150 - 0.20s - loss: 1.0710 - acc: 0.4420 - val_loss: 1.0746 - val_acc: 0.3887\n",
            "Epoch 132/150 - 0.18s - loss: 1.0708 - acc: 0.4429 - val_loss: 1.0745 - val_acc: 0.3927\n",
            "Epoch 133/150 - 0.20s - loss: 1.0707 - acc: 0.4433 - val_loss: 1.0744 - val_acc: 0.3927\n",
            "Epoch 134/150 - 0.19s - loss: 1.0705 - acc: 0.4440 - val_loss: 1.0743 - val_acc: 0.3907\n",
            "Epoch 135/150 - 0.20s - loss: 1.0704 - acc: 0.4440 - val_loss: 1.0742 - val_acc: 0.3927\n",
            "Epoch 136/150 - 0.19s - loss: 1.0703 - acc: 0.4433 - val_loss: 1.0741 - val_acc: 0.3927\n",
            "Epoch 137/150 - 0.19s - loss: 1.0701 - acc: 0.4440 - val_loss: 1.0739 - val_acc: 0.3947\n",
            "Epoch 138/150 - 0.19s - loss: 1.0700 - acc: 0.4440 - val_loss: 1.0738 - val_acc: 0.3947\n",
            "Epoch 139/150 - 0.21s - loss: 1.0698 - acc: 0.4438 - val_loss: 1.0737 - val_acc: 0.3947\n",
            "Epoch 140/150 - 0.20s - loss: 1.0697 - acc: 0.4444 - val_loss: 1.0736 - val_acc: 0.3947\n",
            "Epoch 141/150 - 0.19s - loss: 1.0695 - acc: 0.4442 - val_loss: 1.0735 - val_acc: 0.3947\n",
            "Epoch 142/150 - 0.19s - loss: 1.0694 - acc: 0.4442 - val_loss: 1.0734 - val_acc: 0.3947\n",
            "Epoch 143/150 - 0.20s - loss: 1.0693 - acc: 0.4449 - val_loss: 1.0733 - val_acc: 0.3968\n",
            "Epoch 144/150 - 0.19s - loss: 1.0691 - acc: 0.4456 - val_loss: 1.0732 - val_acc: 0.4049\n",
            "Epoch 145/150 - 0.19s - loss: 1.0690 - acc: 0.4460 - val_loss: 1.0730 - val_acc: 0.4049\n",
            "Epoch 146/150 - 0.18s - loss: 1.0689 - acc: 0.4469 - val_loss: 1.0729 - val_acc: 0.4049\n",
            "Epoch 147/150 - 0.20s - loss: 1.0687 - acc: 0.4471 - val_loss: 1.0728 - val_acc: 0.4049\n",
            "Epoch 148/150 - 0.19s - loss: 1.0686 - acc: 0.4474 - val_loss: 1.0727 - val_acc: 0.4049\n",
            "Epoch 149/150 - 0.19s - loss: 1.0684 - acc: 0.4471 - val_loss: 1.0726 - val_acc: 0.4049\n",
            "Epoch 150/150 - 0.19s - loss: 1.0683 - acc: 0.4474 - val_loss: 1.0725 - val_acc: 0.4028\n",
            "\n",
            "Combination 142/252:\n",
            "Hidden Layers: [256, 128], Activation: tanh, Learning Rate: 0.0001, Batch Size: 64, Epochs: 50\n",
            "Epoch 1/50 - 0.17s - loss: 1.0901 - acc: 0.3848 - val_loss: 1.0918 - val_acc: 0.3704\n",
            "Epoch 2/50 - 0.15s - loss: 1.0899 - acc: 0.3851 - val_loss: 1.0916 - val_acc: 0.3765\n",
            "Epoch 3/50 - 0.17s - loss: 1.0897 - acc: 0.3873 - val_loss: 1.0914 - val_acc: 0.3745\n",
            "Epoch 4/50 - 0.16s - loss: 1.0895 - acc: 0.3869 - val_loss: 1.0913 - val_acc: 0.3765\n",
            "Epoch 5/50 - 0.16s - loss: 1.0894 - acc: 0.3871 - val_loss: 1.0911 - val_acc: 0.3704\n",
            "Epoch 6/50 - 0.15s - loss: 1.0892 - acc: 0.3900 - val_loss: 1.0910 - val_acc: 0.3704\n",
            "Epoch 7/50 - 0.16s - loss: 1.0890 - acc: 0.3909 - val_loss: 1.0908 - val_acc: 0.3785\n",
            "Epoch 8/50 - 0.18s - loss: 1.0888 - acc: 0.3936 - val_loss: 1.0907 - val_acc: 0.3846\n",
            "Epoch 9/50 - 0.18s - loss: 1.0887 - acc: 0.3934 - val_loss: 1.0905 - val_acc: 0.3846\n",
            "Epoch 10/50 - 0.17s - loss: 1.0885 - acc: 0.3932 - val_loss: 1.0904 - val_acc: 0.3887\n",
            "Epoch 11/50 - 0.16s - loss: 1.0884 - acc: 0.3932 - val_loss: 1.0902 - val_acc: 0.3927\n",
            "Epoch 12/50 - 0.16s - loss: 1.0882 - acc: 0.3941 - val_loss: 1.0901 - val_acc: 0.3887\n",
            "Epoch 13/50 - 0.17s - loss: 1.0881 - acc: 0.3950 - val_loss: 1.0900 - val_acc: 0.3907\n",
            "Epoch 14/50 - 0.16s - loss: 1.0879 - acc: 0.3963 - val_loss: 1.0899 - val_acc: 0.3927\n",
            "Epoch 15/50 - 0.16s - loss: 1.0877 - acc: 0.3968 - val_loss: 1.0897 - val_acc: 0.3947\n",
            "Epoch 16/50 - 0.15s - loss: 1.0876 - acc: 0.3974 - val_loss: 1.0896 - val_acc: 0.3968\n",
            "Epoch 17/50 - 0.16s - loss: 1.0875 - acc: 0.3986 - val_loss: 1.0895 - val_acc: 0.3988\n",
            "Epoch 18/50 - 0.15s - loss: 1.0873 - acc: 0.3995 - val_loss: 1.0893 - val_acc: 0.4028\n",
            "Epoch 19/50 - 0.16s - loss: 1.0872 - acc: 0.4004 - val_loss: 1.0892 - val_acc: 0.4008\n",
            "Epoch 20/50 - 0.15s - loss: 1.0870 - acc: 0.4015 - val_loss: 1.0891 - val_acc: 0.4028\n",
            "Epoch 21/50 - 0.16s - loss: 1.0869 - acc: 0.4019 - val_loss: 1.0890 - val_acc: 0.4069\n",
            "Epoch 22/50 - 0.15s - loss: 1.0867 - acc: 0.4017 - val_loss: 1.0889 - val_acc: 0.4049\n",
            "Epoch 23/50 - 0.16s - loss: 1.0866 - acc: 0.4013 - val_loss: 1.0887 - val_acc: 0.4049\n",
            "Epoch 24/50 - 0.16s - loss: 1.0864 - acc: 0.4010 - val_loss: 1.0886 - val_acc: 0.4069\n",
            "Epoch 25/50 - 0.21s - loss: 1.0863 - acc: 0.4013 - val_loss: 1.0885 - val_acc: 0.4049\n",
            "Epoch 26/50 - 0.16s - loss: 1.0862 - acc: 0.4024 - val_loss: 1.0884 - val_acc: 0.4028\n",
            "Epoch 27/50 - 0.16s - loss: 1.0860 - acc: 0.4037 - val_loss: 1.0883 - val_acc: 0.4028\n",
            "Epoch 28/50 - 0.16s - loss: 1.0859 - acc: 0.4046 - val_loss: 1.0882 - val_acc: 0.4028\n",
            "Epoch 29/50 - 0.17s - loss: 1.0857 - acc: 0.4058 - val_loss: 1.0881 - val_acc: 0.4028\n",
            "Epoch 30/50 - 0.16s - loss: 1.0856 - acc: 0.4058 - val_loss: 1.0879 - val_acc: 0.4049\n",
            "Epoch 31/50 - 0.18s - loss: 1.0855 - acc: 0.4062 - val_loss: 1.0878 - val_acc: 0.4049\n",
            "Epoch 32/50 - 0.15s - loss: 1.0853 - acc: 0.4060 - val_loss: 1.0877 - val_acc: 0.4069\n",
            "Epoch 33/50 - 0.16s - loss: 1.0852 - acc: 0.4071 - val_loss: 1.0876 - val_acc: 0.4069\n",
            "Epoch 34/50 - 0.15s - loss: 1.0851 - acc: 0.4067 - val_loss: 1.0875 - val_acc: 0.4089\n",
            "Epoch 35/50 - 0.16s - loss: 1.0849 - acc: 0.4069 - val_loss: 1.0874 - val_acc: 0.4069\n",
            "Epoch 36/50 - 0.16s - loss: 1.0848 - acc: 0.4071 - val_loss: 1.0873 - val_acc: 0.4089\n",
            "Epoch 37/50 - 0.17s - loss: 1.0847 - acc: 0.4082 - val_loss: 1.0872 - val_acc: 0.4069\n",
            "Epoch 38/50 - 0.15s - loss: 1.0845 - acc: 0.4094 - val_loss: 1.0871 - val_acc: 0.4069\n",
            "Epoch 39/50 - 0.17s - loss: 1.0844 - acc: 0.4103 - val_loss: 1.0869 - val_acc: 0.4069\n",
            "Epoch 40/50 - 0.15s - loss: 1.0843 - acc: 0.4103 - val_loss: 1.0868 - val_acc: 0.4089\n",
            "Epoch 41/50 - 0.17s - loss: 1.0841 - acc: 0.4116 - val_loss: 1.0867 - val_acc: 0.4069\n",
            "Epoch 42/50 - 0.15s - loss: 1.0840 - acc: 0.4125 - val_loss: 1.0866 - val_acc: 0.4069\n",
            "Epoch 43/50 - 0.16s - loss: 1.0839 - acc: 0.4130 - val_loss: 1.0865 - val_acc: 0.4089\n",
            "Epoch 44/50 - 0.17s - loss: 1.0838 - acc: 0.4125 - val_loss: 1.0864 - val_acc: 0.4109\n",
            "Epoch 45/50 - 0.16s - loss: 1.0836 - acc: 0.4130 - val_loss: 1.0863 - val_acc: 0.4089\n",
            "Epoch 46/50 - 0.16s - loss: 1.0835 - acc: 0.4127 - val_loss: 1.0862 - val_acc: 0.4089\n",
            "Epoch 47/50 - 0.16s - loss: 1.0834 - acc: 0.4139 - val_loss: 1.0861 - val_acc: 0.4089\n",
            "Epoch 48/50 - 0.15s - loss: 1.0832 - acc: 0.4145 - val_loss: 1.0860 - val_acc: 0.4089\n",
            "Epoch 49/50 - 0.18s - loss: 1.0831 - acc: 0.4145 - val_loss: 1.0859 - val_acc: 0.4089\n",
            "Epoch 50/50 - 0.16s - loss: 1.0830 - acc: 0.4157 - val_loss: 1.0858 - val_acc: 0.4089\n",
            "\n",
            "Combination 143/252:\n",
            "Hidden Layers: [256, 128], Activation: tanh, Learning Rate: 0.0001, Batch Size: 64, Epochs: 100\n",
            "Epoch 1/100 - 0.17s - loss: 1.1211 - acc: 0.3302 - val_loss: 1.1216 - val_acc: 0.3401\n",
            "Epoch 2/100 - 0.16s - loss: 1.1180 - acc: 0.3279 - val_loss: 1.1188 - val_acc: 0.3360\n",
            "Epoch 3/100 - 0.17s - loss: 1.1153 - acc: 0.3270 - val_loss: 1.1164 - val_acc: 0.3421\n",
            "Epoch 4/100 - 0.16s - loss: 1.1130 - acc: 0.3246 - val_loss: 1.1143 - val_acc: 0.3441\n",
            "Epoch 5/100 - 0.16s - loss: 1.1110 - acc: 0.3228 - val_loss: 1.1125 - val_acc: 0.3441\n",
            "Epoch 6/100 - 0.16s - loss: 1.1093 - acc: 0.3212 - val_loss: 1.1110 - val_acc: 0.3421\n",
            "Epoch 7/100 - 0.17s - loss: 1.1078 - acc: 0.3216 - val_loss: 1.1097 - val_acc: 0.3401\n",
            "Epoch 8/100 - 0.16s - loss: 1.1065 - acc: 0.3205 - val_loss: 1.1086 - val_acc: 0.3421\n",
            "Epoch 9/100 - 0.18s - loss: 1.1054 - acc: 0.3185 - val_loss: 1.1076 - val_acc: 0.3401\n",
            "Epoch 10/100 - 0.16s - loss: 1.1044 - acc: 0.3198 - val_loss: 1.1067 - val_acc: 0.3441\n",
            "Epoch 11/100 - 0.19s - loss: 1.1035 - acc: 0.3178 - val_loss: 1.1060 - val_acc: 0.3421\n",
            "Epoch 12/100 - 0.15s - loss: 1.1028 - acc: 0.3187 - val_loss: 1.1054 - val_acc: 0.3401\n",
            "Epoch 13/100 - 0.16s - loss: 1.1021 - acc: 0.3210 - val_loss: 1.1048 - val_acc: 0.3441\n",
            "Epoch 14/100 - 0.16s - loss: 1.1015 - acc: 0.3203 - val_loss: 1.1043 - val_acc: 0.3482\n",
            "Epoch 15/100 - 0.17s - loss: 1.1010 - acc: 0.3225 - val_loss: 1.1038 - val_acc: 0.3502\n",
            "Epoch 16/100 - 0.15s - loss: 1.1005 - acc: 0.3214 - val_loss: 1.1034 - val_acc: 0.3522\n",
            "Epoch 17/100 - 0.16s - loss: 1.1001 - acc: 0.3219 - val_loss: 1.1031 - val_acc: 0.3543\n",
            "Epoch 18/100 - 0.16s - loss: 1.0997 - acc: 0.3219 - val_loss: 1.1027 - val_acc: 0.3543\n",
            "Epoch 19/100 - 0.17s - loss: 1.0993 - acc: 0.3230 - val_loss: 1.1024 - val_acc: 0.3603\n",
            "Epoch 20/100 - 0.16s - loss: 1.0990 - acc: 0.3225 - val_loss: 1.1022 - val_acc: 0.3623\n",
            "Epoch 21/100 - 0.16s - loss: 1.0987 - acc: 0.3234 - val_loss: 1.1019 - val_acc: 0.3583\n",
            "Epoch 22/100 - 0.16s - loss: 1.0984 - acc: 0.3241 - val_loss: 1.1017 - val_acc: 0.3522\n",
            "Epoch 23/100 - 0.17s - loss: 1.0981 - acc: 0.3232 - val_loss: 1.1014 - val_acc: 0.3401\n",
            "Epoch 24/100 - 0.16s - loss: 1.0978 - acc: 0.3239 - val_loss: 1.1012 - val_acc: 0.3381\n",
            "Epoch 25/100 - 0.17s - loss: 1.0976 - acc: 0.3259 - val_loss: 1.1010 - val_acc: 0.3340\n",
            "Epoch 26/100 - 0.17s - loss: 1.0974 - acc: 0.3291 - val_loss: 1.1008 - val_acc: 0.3340\n",
            "Epoch 27/100 - 0.19s - loss: 1.0971 - acc: 0.3306 - val_loss: 1.1007 - val_acc: 0.3340\n",
            "Epoch 28/100 - 0.16s - loss: 1.0969 - acc: 0.3347 - val_loss: 1.1005 - val_acc: 0.3360\n",
            "Epoch 29/100 - 0.20s - loss: 1.0967 - acc: 0.3356 - val_loss: 1.1003 - val_acc: 0.3401\n",
            "Epoch 30/100 - 0.16s - loss: 1.0965 - acc: 0.3358 - val_loss: 1.1001 - val_acc: 0.3381\n",
            "Epoch 31/100 - 0.17s - loss: 1.0963 - acc: 0.3374 - val_loss: 1.1000 - val_acc: 0.3381\n",
            "Epoch 32/100 - 0.15s - loss: 1.0961 - acc: 0.3372 - val_loss: 1.0998 - val_acc: 0.3381\n",
            "Epoch 33/100 - 0.17s - loss: 1.0960 - acc: 0.3378 - val_loss: 1.0997 - val_acc: 0.3360\n",
            "Epoch 34/100 - 0.16s - loss: 1.0958 - acc: 0.3378 - val_loss: 1.0995 - val_acc: 0.3401\n",
            "Epoch 35/100 - 0.17s - loss: 1.0956 - acc: 0.3412 - val_loss: 1.0994 - val_acc: 0.3381\n",
            "Epoch 36/100 - 0.16s - loss: 1.0954 - acc: 0.3414 - val_loss: 1.0992 - val_acc: 0.3381\n",
            "Epoch 37/100 - 0.17s - loss: 1.0952 - acc: 0.3430 - val_loss: 1.0991 - val_acc: 0.3401\n",
            "Epoch 38/100 - 0.16s - loss: 1.0951 - acc: 0.3432 - val_loss: 1.0989 - val_acc: 0.3421\n",
            "Epoch 39/100 - 0.18s - loss: 1.0949 - acc: 0.3435 - val_loss: 1.0988 - val_acc: 0.3441\n",
            "Epoch 40/100 - 0.17s - loss: 1.0947 - acc: 0.3426 - val_loss: 1.0987 - val_acc: 0.3401\n",
            "Epoch 41/100 - 0.16s - loss: 1.0946 - acc: 0.3430 - val_loss: 1.0985 - val_acc: 0.3401\n",
            "Epoch 42/100 - 0.15s - loss: 1.0944 - acc: 0.3430 - val_loss: 1.0984 - val_acc: 0.3381\n",
            "Epoch 43/100 - 0.17s - loss: 1.0943 - acc: 0.3453 - val_loss: 1.0983 - val_acc: 0.3381\n",
            "Epoch 44/100 - 0.16s - loss: 1.0941 - acc: 0.3457 - val_loss: 1.0981 - val_acc: 0.3360\n",
            "Epoch 45/100 - 0.17s - loss: 1.0940 - acc: 0.3446 - val_loss: 1.0980 - val_acc: 0.3381\n",
            "Epoch 46/100 - 0.16s - loss: 1.0938 - acc: 0.3466 - val_loss: 1.0979 - val_acc: 0.3401\n",
            "Epoch 47/100 - 0.18s - loss: 1.0936 - acc: 0.3480 - val_loss: 1.0977 - val_acc: 0.3421\n",
            "Epoch 48/100 - 0.17s - loss: 1.0935 - acc: 0.3502 - val_loss: 1.0976 - val_acc: 0.3421\n",
            "Epoch 49/100 - 0.16s - loss: 1.0933 - acc: 0.3502 - val_loss: 1.0975 - val_acc: 0.3441\n",
            "Epoch 50/100 - 0.16s - loss: 1.0932 - acc: 0.3527 - val_loss: 1.0973 - val_acc: 0.3441\n",
            "Epoch 51/100 - 0.17s - loss: 1.0930 - acc: 0.3538 - val_loss: 1.0972 - val_acc: 0.3522\n",
            "Epoch 52/100 - 0.15s - loss: 1.0929 - acc: 0.3547 - val_loss: 1.0971 - val_acc: 0.3543\n",
            "Epoch 53/100 - 0.16s - loss: 1.0927 - acc: 0.3547 - val_loss: 1.0970 - val_acc: 0.3502\n",
            "Epoch 54/100 - 0.16s - loss: 1.0926 - acc: 0.3549 - val_loss: 1.0968 - val_acc: 0.3502\n",
            "Epoch 55/100 - 0.17s - loss: 1.0924 - acc: 0.3565 - val_loss: 1.0967 - val_acc: 0.3462\n",
            "Epoch 56/100 - 0.16s - loss: 1.0923 - acc: 0.3583 - val_loss: 1.0966 - val_acc: 0.3462\n",
            "Epoch 57/100 - 0.17s - loss: 1.0921 - acc: 0.3596 - val_loss: 1.0965 - val_acc: 0.3462\n",
            "Epoch 58/100 - 0.16s - loss: 1.0920 - acc: 0.3601 - val_loss: 1.0963 - val_acc: 0.3441\n",
            "Epoch 59/100 - 0.17s - loss: 1.0919 - acc: 0.3619 - val_loss: 1.0962 - val_acc: 0.3421\n",
            "Epoch 60/100 - 0.16s - loss: 1.0917 - acc: 0.3626 - val_loss: 1.0961 - val_acc: 0.3441\n",
            "Epoch 61/100 - 0.16s - loss: 1.0916 - acc: 0.3644 - val_loss: 1.0960 - val_acc: 0.3421\n",
            "Epoch 62/100 - 0.16s - loss: 1.0914 - acc: 0.3646 - val_loss: 1.0959 - val_acc: 0.3482\n",
            "Epoch 63/100 - 0.17s - loss: 1.0913 - acc: 0.3657 - val_loss: 1.0957 - val_acc: 0.3502\n",
            "Epoch 64/100 - 0.16s - loss: 1.0911 - acc: 0.3659 - val_loss: 1.0956 - val_acc: 0.3502\n",
            "Epoch 65/100 - 0.20s - loss: 1.0910 - acc: 0.3662 - val_loss: 1.0955 - val_acc: 0.3502\n",
            "Epoch 66/100 - 0.15s - loss: 1.0909 - acc: 0.3675 - val_loss: 1.0954 - val_acc: 0.3522\n",
            "Epoch 67/100 - 0.17s - loss: 1.0907 - acc: 0.3677 - val_loss: 1.0953 - val_acc: 0.3543\n",
            "Epoch 68/100 - 0.16s - loss: 1.0906 - acc: 0.3680 - val_loss: 1.0952 - val_acc: 0.3563\n",
            "Epoch 69/100 - 0.17s - loss: 1.0904 - acc: 0.3702 - val_loss: 1.0950 - val_acc: 0.3543\n",
            "Epoch 70/100 - 0.15s - loss: 1.0903 - acc: 0.3709 - val_loss: 1.0949 - val_acc: 0.3543\n",
            "Epoch 71/100 - 0.17s - loss: 1.0902 - acc: 0.3720 - val_loss: 1.0948 - val_acc: 0.3543\n",
            "Epoch 72/100 - 0.16s - loss: 1.0900 - acc: 0.3720 - val_loss: 1.0947 - val_acc: 0.3543\n",
            "Epoch 73/100 - 0.17s - loss: 1.0899 - acc: 0.3727 - val_loss: 1.0946 - val_acc: 0.3543\n",
            "Epoch 74/100 - 0.16s - loss: 1.0898 - acc: 0.3731 - val_loss: 1.0945 - val_acc: 0.3543\n",
            "Epoch 75/100 - 0.17s - loss: 1.0896 - acc: 0.3734 - val_loss: 1.0944 - val_acc: 0.3563\n",
            "Epoch 76/100 - 0.16s - loss: 1.0895 - acc: 0.3736 - val_loss: 1.0943 - val_acc: 0.3563\n",
            "Epoch 77/100 - 0.16s - loss: 1.0894 - acc: 0.3743 - val_loss: 1.0941 - val_acc: 0.3583\n",
            "Epoch 78/100 - 0.15s - loss: 1.0892 - acc: 0.3749 - val_loss: 1.0940 - val_acc: 0.3583\n",
            "Epoch 79/100 - 0.17s - loss: 1.0891 - acc: 0.3763 - val_loss: 1.0939 - val_acc: 0.3603\n",
            "Epoch 80/100 - 0.16s - loss: 1.0890 - acc: 0.3767 - val_loss: 1.0938 - val_acc: 0.3603\n",
            "Epoch 81/100 - 0.17s - loss: 1.0888 - acc: 0.3772 - val_loss: 1.0937 - val_acc: 0.3603\n",
            "Epoch 82/100 - 0.16s - loss: 1.0887 - acc: 0.3772 - val_loss: 1.0936 - val_acc: 0.3623\n",
            "Epoch 83/100 - 0.17s - loss: 1.0886 - acc: 0.3779 - val_loss: 1.0935 - val_acc: 0.3684\n",
            "Epoch 84/100 - 0.17s - loss: 1.0884 - acc: 0.3788 - val_loss: 1.0934 - val_acc: 0.3684\n",
            "Epoch 85/100 - 0.16s - loss: 1.0883 - acc: 0.3799 - val_loss: 1.0933 - val_acc: 0.3684\n",
            "Epoch 86/100 - 0.15s - loss: 1.0882 - acc: 0.3801 - val_loss: 1.0932 - val_acc: 0.3664\n",
            "Epoch 87/100 - 0.16s - loss: 1.0881 - acc: 0.3806 - val_loss: 1.0931 - val_acc: 0.3684\n",
            "Epoch 88/100 - 0.15s - loss: 1.0879 - acc: 0.3806 - val_loss: 1.0930 - val_acc: 0.3664\n",
            "Epoch 89/100 - 0.16s - loss: 1.0878 - acc: 0.3806 - val_loss: 1.0929 - val_acc: 0.3644\n",
            "Epoch 90/100 - 0.15s - loss: 1.0877 - acc: 0.3817 - val_loss: 1.0928 - val_acc: 0.3644\n",
            "Epoch 91/100 - 0.17s - loss: 1.0876 - acc: 0.3833 - val_loss: 1.0927 - val_acc: 0.3644\n",
            "Epoch 92/100 - 0.15s - loss: 1.0874 - acc: 0.3830 - val_loss: 1.0926 - val_acc: 0.3644\n",
            "Epoch 93/100 - 0.17s - loss: 1.0873 - acc: 0.3837 - val_loss: 1.0925 - val_acc: 0.3644\n",
            "Epoch 94/100 - 0.15s - loss: 1.0872 - acc: 0.3837 - val_loss: 1.0924 - val_acc: 0.3644\n",
            "Epoch 95/100 - 0.16s - loss: 1.0871 - acc: 0.3853 - val_loss: 1.0923 - val_acc: 0.3623\n",
            "Epoch 96/100 - 0.15s - loss: 1.0869 - acc: 0.3871 - val_loss: 1.0922 - val_acc: 0.3623\n",
            "Epoch 97/100 - 0.16s - loss: 1.0868 - acc: 0.3873 - val_loss: 1.0921 - val_acc: 0.3623\n",
            "Epoch 98/100 - 0.15s - loss: 1.0867 - acc: 0.3878 - val_loss: 1.0920 - val_acc: 0.3603\n",
            "Epoch 99/100 - 0.17s - loss: 1.0866 - acc: 0.3884 - val_loss: 1.0919 - val_acc: 0.3603\n",
            "Epoch 100/100 - 0.16s - loss: 1.0865 - acc: 0.3900 - val_loss: 1.0918 - val_acc: 0.3603\n",
            "\n",
            "Combination 144/252:\n",
            "Hidden Layers: [256, 128], Activation: tanh, Learning Rate: 0.0001, Batch Size: 64, Epochs: 150\n",
            "Epoch 1/150 - 0.16s - loss: 1.1026 - acc: 0.3405 - val_loss: 1.1008 - val_acc: 0.3543\n",
            "Epoch 2/150 - 0.17s - loss: 1.1019 - acc: 0.3372 - val_loss: 1.1003 - val_acc: 0.3583\n",
            "Epoch 3/150 - 0.17s - loss: 1.1012 - acc: 0.3405 - val_loss: 1.0999 - val_acc: 0.3543\n",
            "Epoch 4/150 - 0.15s - loss: 1.1007 - acc: 0.3387 - val_loss: 1.0995 - val_acc: 0.3522\n",
            "Epoch 5/150 - 0.16s - loss: 1.1001 - acc: 0.3421 - val_loss: 1.0991 - val_acc: 0.3502\n",
            "Epoch 6/150 - 0.15s - loss: 1.0996 - acc: 0.3412 - val_loss: 1.0988 - val_acc: 0.3462\n",
            "Epoch 7/150 - 0.16s - loss: 1.0992 - acc: 0.3448 - val_loss: 1.0985 - val_acc: 0.3482\n",
            "Epoch 8/150 - 0.15s - loss: 1.0987 - acc: 0.3502 - val_loss: 1.0982 - val_acc: 0.3482\n",
            "Epoch 9/150 - 0.16s - loss: 1.0984 - acc: 0.3511 - val_loss: 1.0980 - val_acc: 0.3502\n",
            "Epoch 10/150 - 0.15s - loss: 1.0980 - acc: 0.3531 - val_loss: 1.0978 - val_acc: 0.3462\n",
            "Epoch 11/150 - 0.17s - loss: 1.0977 - acc: 0.3574 - val_loss: 1.0976 - val_acc: 0.3502\n",
            "Epoch 12/150 - 0.15s - loss: 1.0974 - acc: 0.3576 - val_loss: 1.0974 - val_acc: 0.3522\n",
            "Epoch 13/150 - 0.16s - loss: 1.0971 - acc: 0.3587 - val_loss: 1.0973 - val_acc: 0.3543\n",
            "Epoch 14/150 - 0.15s - loss: 1.0968 - acc: 0.3587 - val_loss: 1.0971 - val_acc: 0.3563\n",
            "Epoch 15/150 - 0.16s - loss: 1.0966 - acc: 0.3596 - val_loss: 1.0970 - val_acc: 0.3543\n",
            "Epoch 16/150 - 0.15s - loss: 1.0963 - acc: 0.3608 - val_loss: 1.0968 - val_acc: 0.3563\n",
            "Epoch 17/150 - 0.16s - loss: 1.0961 - acc: 0.3628 - val_loss: 1.0967 - val_acc: 0.3563\n",
            "Epoch 18/150 - 0.15s - loss: 1.0959 - acc: 0.3653 - val_loss: 1.0966 - val_acc: 0.3583\n",
            "Epoch 19/150 - 0.18s - loss: 1.0957 - acc: 0.3644 - val_loss: 1.0965 - val_acc: 0.3623\n",
            "Epoch 20/150 - 0.16s - loss: 1.0956 - acc: 0.3632 - val_loss: 1.0964 - val_acc: 0.3623\n",
            "Epoch 21/150 - 0.18s - loss: 1.0954 - acc: 0.3641 - val_loss: 1.0963 - val_acc: 0.3664\n",
            "Epoch 22/150 - 0.16s - loss: 1.0952 - acc: 0.3650 - val_loss: 1.0962 - val_acc: 0.3603\n",
            "Epoch 23/150 - 0.17s - loss: 1.0950 - acc: 0.3664 - val_loss: 1.0961 - val_acc: 0.3644\n",
            "Epoch 24/150 - 0.16s - loss: 1.0949 - acc: 0.3673 - val_loss: 1.0960 - val_acc: 0.3684\n",
            "Epoch 25/150 - 0.17s - loss: 1.0947 - acc: 0.3700 - val_loss: 1.0959 - val_acc: 0.3644\n",
            "Epoch 26/150 - 0.16s - loss: 1.0946 - acc: 0.3704 - val_loss: 1.0958 - val_acc: 0.3684\n",
            "Epoch 27/150 - 0.17s - loss: 1.0944 - acc: 0.3722 - val_loss: 1.0958 - val_acc: 0.3664\n",
            "Epoch 28/150 - 0.16s - loss: 1.0943 - acc: 0.3736 - val_loss: 1.0957 - val_acc: 0.3664\n",
            "Epoch 29/150 - 0.18s - loss: 1.0942 - acc: 0.3736 - val_loss: 1.0956 - val_acc: 0.3664\n",
            "Epoch 30/150 - 0.17s - loss: 1.0940 - acc: 0.3745 - val_loss: 1.0955 - val_acc: 0.3704\n",
            "Epoch 31/150 - 0.18s - loss: 1.0939 - acc: 0.3747 - val_loss: 1.0954 - val_acc: 0.3664\n",
            "Epoch 32/150 - 0.16s - loss: 1.0938 - acc: 0.3758 - val_loss: 1.0954 - val_acc: 0.3664\n",
            "Epoch 33/150 - 0.17s - loss: 1.0936 - acc: 0.3763 - val_loss: 1.0953 - val_acc: 0.3664\n",
            "Epoch 34/150 - 0.16s - loss: 1.0935 - acc: 0.3767 - val_loss: 1.0952 - val_acc: 0.3664\n",
            "Epoch 35/150 - 0.17s - loss: 1.0934 - acc: 0.3770 - val_loss: 1.0951 - val_acc: 0.3664\n",
            "Epoch 36/150 - 0.16s - loss: 1.0933 - acc: 0.3758 - val_loss: 1.0950 - val_acc: 0.3704\n",
            "Epoch 37/150 - 0.18s - loss: 1.0932 - acc: 0.3747 - val_loss: 1.0950 - val_acc: 0.3704\n",
            "Epoch 38/150 - 0.16s - loss: 1.0930 - acc: 0.3736 - val_loss: 1.0949 - val_acc: 0.3684\n",
            "Epoch 39/150 - 0.17s - loss: 1.0929 - acc: 0.3734 - val_loss: 1.0948 - val_acc: 0.3684\n",
            "Epoch 40/150 - 0.15s - loss: 1.0928 - acc: 0.3745 - val_loss: 1.0947 - val_acc: 0.3704\n",
            "Epoch 41/150 - 0.16s - loss: 1.0927 - acc: 0.3767 - val_loss: 1.0947 - val_acc: 0.3745\n",
            "Epoch 42/150 - 0.16s - loss: 1.0926 - acc: 0.3779 - val_loss: 1.0946 - val_acc: 0.3745\n",
            "Epoch 43/150 - 0.17s - loss: 1.0925 - acc: 0.3790 - val_loss: 1.0945 - val_acc: 0.3765\n",
            "Epoch 44/150 - 0.16s - loss: 1.0924 - acc: 0.3797 - val_loss: 1.0944 - val_acc: 0.3765\n",
            "Epoch 45/150 - 0.16s - loss: 1.0923 - acc: 0.3803 - val_loss: 1.0943 - val_acc: 0.3785\n",
            "Epoch 46/150 - 0.15s - loss: 1.0921 - acc: 0.3801 - val_loss: 1.0943 - val_acc: 0.3826\n",
            "Epoch 47/150 - 0.17s - loss: 1.0920 - acc: 0.3797 - val_loss: 1.0942 - val_acc: 0.3806\n",
            "Epoch 48/150 - 0.16s - loss: 1.0919 - acc: 0.3792 - val_loss: 1.0941 - val_acc: 0.3806\n",
            "Epoch 49/150 - 0.17s - loss: 1.0918 - acc: 0.3785 - val_loss: 1.0940 - val_acc: 0.3826\n",
            "Epoch 50/150 - 0.16s - loss: 1.0917 - acc: 0.3776 - val_loss: 1.0940 - val_acc: 0.3826\n",
            "Epoch 51/150 - 0.17s - loss: 1.0916 - acc: 0.3779 - val_loss: 1.0939 - val_acc: 0.3826\n",
            "Epoch 52/150 - 0.16s - loss: 1.0915 - acc: 0.3785 - val_loss: 1.0938 - val_acc: 0.3846\n",
            "Epoch 53/150 - 0.16s - loss: 1.0914 - acc: 0.3803 - val_loss: 1.0937 - val_acc: 0.3866\n",
            "Epoch 54/150 - 0.16s - loss: 1.0913 - acc: 0.3815 - val_loss: 1.0936 - val_acc: 0.3866\n",
            "Epoch 55/150 - 0.18s - loss: 1.0912 - acc: 0.3817 - val_loss: 1.0936 - val_acc: 0.3887\n",
            "Epoch 56/150 - 0.18s - loss: 1.0911 - acc: 0.3815 - val_loss: 1.0935 - val_acc: 0.3887\n",
            "Epoch 57/150 - 0.16s - loss: 1.0910 - acc: 0.3812 - val_loss: 1.0934 - val_acc: 0.3927\n",
            "Epoch 58/150 - 0.16s - loss: 1.0909 - acc: 0.3810 - val_loss: 1.0933 - val_acc: 0.3907\n",
            "Epoch 59/150 - 0.17s - loss: 1.0908 - acc: 0.3815 - val_loss: 1.0932 - val_acc: 0.3947\n",
            "Epoch 60/150 - 0.16s - loss: 1.0907 - acc: 0.3819 - val_loss: 1.0932 - val_acc: 0.3947\n",
            "Epoch 61/150 - 0.16s - loss: 1.0906 - acc: 0.3821 - val_loss: 1.0931 - val_acc: 0.3947\n",
            "Epoch 62/150 - 0.16s - loss: 1.0905 - acc: 0.3826 - val_loss: 1.0930 - val_acc: 0.3947\n",
            "Epoch 63/150 - 0.17s - loss: 1.0904 - acc: 0.3837 - val_loss: 1.0929 - val_acc: 0.3947\n",
            "Epoch 64/150 - 0.16s - loss: 1.0903 - acc: 0.3842 - val_loss: 1.0928 - val_acc: 0.3947\n",
            "Epoch 65/150 - 0.16s - loss: 1.0902 - acc: 0.3837 - val_loss: 1.0928 - val_acc: 0.3947\n",
            "Epoch 66/150 - 0.16s - loss: 1.0901 - acc: 0.3842 - val_loss: 1.0927 - val_acc: 0.3947\n",
            "Epoch 67/150 - 0.17s - loss: 1.0900 - acc: 0.3846 - val_loss: 1.0926 - val_acc: 0.3947\n",
            "Epoch 68/150 - 0.16s - loss: 1.0899 - acc: 0.3848 - val_loss: 1.0925 - val_acc: 0.3968\n",
            "Epoch 69/150 - 0.16s - loss: 1.0898 - acc: 0.3853 - val_loss: 1.0924 - val_acc: 0.3968\n",
            "Epoch 70/150 - 0.15s - loss: 1.0897 - acc: 0.3855 - val_loss: 1.0923 - val_acc: 0.3968\n",
            "Epoch 71/150 - 0.17s - loss: 1.0896 - acc: 0.3855 - val_loss: 1.0923 - val_acc: 0.3968\n",
            "Epoch 72/150 - 0.15s - loss: 1.0895 - acc: 0.3851 - val_loss: 1.0922 - val_acc: 0.3968\n",
            "Epoch 73/150 - 0.18s - loss: 1.0894 - acc: 0.3851 - val_loss: 1.0921 - val_acc: 0.3968\n",
            "Epoch 74/150 - 0.16s - loss: 1.0893 - acc: 0.3853 - val_loss: 1.0920 - val_acc: 0.3968\n",
            "Epoch 75/150 - 0.18s - loss: 1.0892 - acc: 0.3853 - val_loss: 1.0919 - val_acc: 0.3947\n",
            "Epoch 76/150 - 0.16s - loss: 1.0891 - acc: 0.3855 - val_loss: 1.0919 - val_acc: 0.3947\n",
            "Epoch 77/150 - 0.19s - loss: 1.0890 - acc: 0.3853 - val_loss: 1.0918 - val_acc: 0.3968\n",
            "Epoch 78/150 - 0.17s - loss: 1.0889 - acc: 0.3851 - val_loss: 1.0917 - val_acc: 0.3947\n",
            "Epoch 79/150 - 0.17s - loss: 1.0888 - acc: 0.3862 - val_loss: 1.0916 - val_acc: 0.3947\n",
            "Epoch 80/150 - 0.16s - loss: 1.0887 - acc: 0.3866 - val_loss: 1.0916 - val_acc: 0.3968\n",
            "Epoch 81/150 - 0.17s - loss: 1.0886 - acc: 0.3880 - val_loss: 1.0915 - val_acc: 0.3968\n",
            "Epoch 82/150 - 0.16s - loss: 1.0885 - acc: 0.3882 - val_loss: 1.0914 - val_acc: 0.3968\n",
            "Epoch 83/150 - 0.17s - loss: 1.0884 - acc: 0.3887 - val_loss: 1.0913 - val_acc: 0.3988\n",
            "Epoch 84/150 - 0.16s - loss: 1.0883 - acc: 0.3889 - val_loss: 1.0912 - val_acc: 0.3968\n",
            "Epoch 85/150 - 0.16s - loss: 1.0882 - acc: 0.3887 - val_loss: 1.0912 - val_acc: 0.3968\n",
            "Epoch 86/150 - 0.15s - loss: 1.0881 - acc: 0.3891 - val_loss: 1.0911 - val_acc: 0.3947\n",
            "Epoch 87/150 - 0.18s - loss: 1.0880 - acc: 0.3891 - val_loss: 1.0910 - val_acc: 0.3968\n",
            "Epoch 88/150 - 0.16s - loss: 1.0879 - acc: 0.3896 - val_loss: 1.0909 - val_acc: 0.3968\n",
            "Epoch 89/150 - 0.17s - loss: 1.0878 - acc: 0.3893 - val_loss: 1.0909 - val_acc: 0.3968\n",
            "Epoch 90/150 - 0.15s - loss: 1.0877 - acc: 0.3891 - val_loss: 1.0908 - val_acc: 0.3947\n",
            "Epoch 91/150 - 0.18s - loss: 1.0876 - acc: 0.3900 - val_loss: 1.0907 - val_acc: 0.3927\n",
            "Epoch 92/150 - 0.16s - loss: 1.0875 - acc: 0.3900 - val_loss: 1.0906 - val_acc: 0.3927\n",
            "Epoch 93/150 - 0.16s - loss: 1.0874 - acc: 0.3900 - val_loss: 1.0906 - val_acc: 0.3907\n",
            "Epoch 94/150 - 0.16s - loss: 1.0873 - acc: 0.3905 - val_loss: 1.0905 - val_acc: 0.3907\n",
            "Epoch 95/150 - 0.17s - loss: 1.0873 - acc: 0.3905 - val_loss: 1.0904 - val_acc: 0.3907\n",
            "Epoch 96/150 - 0.15s - loss: 1.0872 - acc: 0.3902 - val_loss: 1.0903 - val_acc: 0.3907\n",
            "Epoch 97/150 - 0.16s - loss: 1.0871 - acc: 0.3907 - val_loss: 1.0902 - val_acc: 0.3887\n",
            "Epoch 98/150 - 0.16s - loss: 1.0870 - acc: 0.3902 - val_loss: 1.0902 - val_acc: 0.3887\n",
            "Epoch 99/150 - 0.18s - loss: 1.0869 - acc: 0.3905 - val_loss: 1.0901 - val_acc: 0.3887\n",
            "Epoch 100/150 - 0.17s - loss: 1.0868 - acc: 0.3907 - val_loss: 1.0900 - val_acc: 0.3887\n",
            "Epoch 101/150 - 0.18s - loss: 1.0867 - acc: 0.3914 - val_loss: 1.0899 - val_acc: 0.3907\n",
            "Epoch 102/150 - 0.17s - loss: 1.0866 - acc: 0.3916 - val_loss: 1.0899 - val_acc: 0.3907\n",
            "Epoch 103/150 - 0.19s - loss: 1.0865 - acc: 0.3920 - val_loss: 1.0898 - val_acc: 0.3907\n",
            "Epoch 104/150 - 0.16s - loss: 1.0864 - acc: 0.3920 - val_loss: 1.0897 - val_acc: 0.3907\n",
            "Epoch 105/150 - 0.16s - loss: 1.0863 - acc: 0.3918 - val_loss: 1.0896 - val_acc: 0.3907\n",
            "Epoch 106/150 - 0.16s - loss: 1.0862 - acc: 0.3918 - val_loss: 1.0896 - val_acc: 0.3907\n",
            "Epoch 107/150 - 0.17s - loss: 1.0862 - acc: 0.3920 - val_loss: 1.0895 - val_acc: 0.3887\n",
            "Epoch 108/150 - 0.16s - loss: 1.0861 - acc: 0.3918 - val_loss: 1.0894 - val_acc: 0.3887\n",
            "Epoch 109/150 - 0.16s - loss: 1.0860 - acc: 0.3918 - val_loss: 1.0893 - val_acc: 0.3887\n",
            "Epoch 110/150 - 0.18s - loss: 1.0859 - acc: 0.3923 - val_loss: 1.0893 - val_acc: 0.3887\n",
            "Epoch 111/150 - 0.18s - loss: 1.0858 - acc: 0.3925 - val_loss: 1.0892 - val_acc: 0.3887\n",
            "Epoch 112/150 - 0.16s - loss: 1.0857 - acc: 0.3932 - val_loss: 1.0891 - val_acc: 0.3866\n",
            "Epoch 113/150 - 0.17s - loss: 1.0856 - acc: 0.3934 - val_loss: 1.0890 - val_acc: 0.3826\n",
            "Epoch 114/150 - 0.16s - loss: 1.0855 - acc: 0.3943 - val_loss: 1.0890 - val_acc: 0.3826\n",
            "Epoch 115/150 - 0.17s - loss: 1.0854 - acc: 0.3947 - val_loss: 1.0889 - val_acc: 0.3826\n",
            "Epoch 116/150 - 0.15s - loss: 1.0853 - acc: 0.3941 - val_loss: 1.0888 - val_acc: 0.3826\n",
            "Epoch 117/150 - 0.16s - loss: 1.0853 - acc: 0.3947 - val_loss: 1.0887 - val_acc: 0.3826\n",
            "Epoch 118/150 - 0.16s - loss: 1.0852 - acc: 0.3945 - val_loss: 1.0887 - val_acc: 0.3785\n",
            "Epoch 119/150 - 0.17s - loss: 1.0851 - acc: 0.3956 - val_loss: 1.0886 - val_acc: 0.3785\n",
            "Epoch 120/150 - 0.16s - loss: 1.0850 - acc: 0.3961 - val_loss: 1.0885 - val_acc: 0.3826\n",
            "Epoch 121/150 - 0.17s - loss: 1.0849 - acc: 0.3961 - val_loss: 1.0884 - val_acc: 0.3826\n",
            "Epoch 122/150 - 0.16s - loss: 1.0848 - acc: 0.3961 - val_loss: 1.0884 - val_acc: 0.3826\n",
            "Epoch 123/150 - 0.18s - loss: 1.0847 - acc: 0.3963 - val_loss: 1.0883 - val_acc: 0.3826\n",
            "Epoch 124/150 - 0.16s - loss: 1.0846 - acc: 0.3956 - val_loss: 1.0882 - val_acc: 0.3826\n",
            "Epoch 125/150 - 0.17s - loss: 1.0846 - acc: 0.3970 - val_loss: 1.0882 - val_acc: 0.3826\n",
            "Epoch 126/150 - 0.16s - loss: 1.0845 - acc: 0.3970 - val_loss: 1.0881 - val_acc: 0.3826\n",
            "Epoch 127/150 - 0.20s - loss: 1.0844 - acc: 0.3972 - val_loss: 1.0880 - val_acc: 0.3806\n",
            "Epoch 128/150 - 0.16s - loss: 1.0843 - acc: 0.3972 - val_loss: 1.0879 - val_acc: 0.3806\n",
            "Epoch 129/150 - 0.18s - loss: 1.0842 - acc: 0.3968 - val_loss: 1.0879 - val_acc: 0.3806\n",
            "Epoch 130/150 - 0.16s - loss: 1.0841 - acc: 0.3990 - val_loss: 1.0878 - val_acc: 0.3806\n",
            "Epoch 131/150 - 0.18s - loss: 1.0840 - acc: 0.3997 - val_loss: 1.0877 - val_acc: 0.3806\n",
            "Epoch 132/150 - 0.16s - loss: 1.0840 - acc: 0.3999 - val_loss: 1.0877 - val_acc: 0.3806\n",
            "Epoch 133/150 - 0.17s - loss: 1.0839 - acc: 0.4001 - val_loss: 1.0876 - val_acc: 0.3806\n",
            "Epoch 134/150 - 0.16s - loss: 1.0838 - acc: 0.4001 - val_loss: 1.0875 - val_acc: 0.3806\n",
            "Epoch 135/150 - 0.18s - loss: 1.0837 - acc: 0.4001 - val_loss: 1.0874 - val_acc: 0.3806\n",
            "Epoch 136/150 - 0.17s - loss: 1.0836 - acc: 0.3999 - val_loss: 1.0874 - val_acc: 0.3806\n",
            "Epoch 137/150 - 0.17s - loss: 1.0835 - acc: 0.4004 - val_loss: 1.0873 - val_acc: 0.3806\n",
            "Epoch 138/150 - 0.16s - loss: 1.0834 - acc: 0.4010 - val_loss: 1.0872 - val_acc: 0.3806\n",
            "Epoch 139/150 - 0.17s - loss: 1.0834 - acc: 0.4015 - val_loss: 1.0872 - val_acc: 0.3806\n",
            "Epoch 140/150 - 0.16s - loss: 1.0833 - acc: 0.4015 - val_loss: 1.0871 - val_acc: 0.3806\n",
            "Epoch 141/150 - 0.17s - loss: 1.0832 - acc: 0.4019 - val_loss: 1.0870 - val_acc: 0.3806\n",
            "Epoch 142/150 - 0.16s - loss: 1.0831 - acc: 0.4022 - val_loss: 1.0869 - val_acc: 0.3806\n",
            "Epoch 143/150 - 0.17s - loss: 1.0830 - acc: 0.4022 - val_loss: 1.0869 - val_acc: 0.3826\n",
            "Epoch 144/150 - 0.17s - loss: 1.0829 - acc: 0.4026 - val_loss: 1.0868 - val_acc: 0.3846\n",
            "Epoch 145/150 - 0.20s - loss: 1.0829 - acc: 0.4026 - val_loss: 1.0867 - val_acc: 0.3846\n",
            "Epoch 146/150 - 0.17s - loss: 1.0828 - acc: 0.4026 - val_loss: 1.0867 - val_acc: 0.3846\n",
            "Epoch 147/150 - 0.17s - loss: 1.0827 - acc: 0.4028 - val_loss: 1.0866 - val_acc: 0.3846\n",
            "Epoch 148/150 - 0.17s - loss: 1.0826 - acc: 0.4035 - val_loss: 1.0865 - val_acc: 0.3846\n",
            "Epoch 149/150 - 0.17s - loss: 1.0825 - acc: 0.4040 - val_loss: 1.0865 - val_acc: 0.3866\n",
            "Epoch 150/150 - 0.17s - loss: 1.0824 - acc: 0.4044 - val_loss: 1.0864 - val_acc: 0.3866\n",
            "\n",
            "Combination 145/252:\n",
            "Hidden Layers: [128, 64, 32], Activation: relu, Learning Rate: 0.01, Batch Size: 32, Epochs: 50\n",
            "Epoch 1/50 - 0.10s - loss: 1.0825 - acc: 0.4325 - val_loss: 1.0817 - val_acc: 0.4109\n",
            "Epoch 2/50 - 0.08s - loss: 1.0693 - acc: 0.4521 - val_loss: 1.0710 - val_acc: 0.4453\n",
            "Epoch 3/50 - 0.08s - loss: 1.0573 - acc: 0.4638 - val_loss: 1.0621 - val_acc: 0.4555\n",
            "Epoch 4/50 - 0.09s - loss: 1.0454 - acc: 0.4730 - val_loss: 1.0526 - val_acc: 0.4818\n",
            "Epoch 5/50 - 0.08s - loss: 1.0361 - acc: 0.4854 - val_loss: 1.0470 - val_acc: 0.4757\n",
            "Epoch 6/50 - 0.08s - loss: 1.0258 - acc: 0.4847 - val_loss: 1.0381 - val_acc: 0.4919\n",
            "Epoch 7/50 - 0.08s - loss: 1.0175 - acc: 0.4980 - val_loss: 1.0350 - val_acc: 0.4838\n",
            "Epoch 8/50 - 0.09s - loss: 1.0065 - acc: 0.5092 - val_loss: 1.0242 - val_acc: 0.4899\n",
            "Epoch 9/50 - 0.08s - loss: 0.9978 - acc: 0.5151 - val_loss: 1.0179 - val_acc: 0.5000\n",
            "Epoch 10/50 - 0.09s - loss: 0.9879 - acc: 0.5200 - val_loss: 1.0111 - val_acc: 0.5081\n",
            "Epoch 11/50 - 0.08s - loss: 0.9850 - acc: 0.5218 - val_loss: 1.0083 - val_acc: 0.5223\n",
            "Epoch 12/50 - 0.08s - loss: 0.9720 - acc: 0.5268 - val_loss: 0.9981 - val_acc: 0.5202\n",
            "Epoch 13/50 - 0.09s - loss: 0.9666 - acc: 0.5326 - val_loss: 0.9962 - val_acc: 0.5162\n",
            "Epoch 14/50 - 0.10s - loss: 0.9573 - acc: 0.5380 - val_loss: 0.9865 - val_acc: 0.5344\n",
            "Epoch 15/50 - 0.08s - loss: 0.9530 - acc: 0.5380 - val_loss: 0.9833 - val_acc: 0.5344\n",
            "Epoch 16/50 - 0.09s - loss: 0.9442 - acc: 0.5513 - val_loss: 0.9750 - val_acc: 0.5486\n",
            "Epoch 17/50 - 0.08s - loss: 0.9388 - acc: 0.5520 - val_loss: 0.9719 - val_acc: 0.5506\n",
            "Epoch 18/50 - 0.08s - loss: 0.9353 - acc: 0.5598 - val_loss: 0.9744 - val_acc: 0.5526\n",
            "Epoch 19/50 - 0.09s - loss: 0.9280 - acc: 0.5576 - val_loss: 0.9635 - val_acc: 0.5547\n",
            "Epoch 20/50 - 0.12s - loss: 0.9214 - acc: 0.5655 - val_loss: 0.9642 - val_acc: 0.5547\n",
            "Epoch 21/50 - 0.09s - loss: 0.9214 - acc: 0.5652 - val_loss: 0.9672 - val_acc: 0.5526\n",
            "Epoch 22/50 - 0.10s - loss: 0.9114 - acc: 0.5702 - val_loss: 0.9600 - val_acc: 0.5587\n",
            "Epoch 23/50 - 0.08s - loss: 0.9166 - acc: 0.5619 - val_loss: 0.9598 - val_acc: 0.5587\n",
            "Epoch 24/50 - 0.08s - loss: 0.9271 - acc: 0.5607 - val_loss: 0.9827 - val_acc: 0.5020\n",
            "Epoch 25/50 - 0.10s - loss: 0.9096 - acc: 0.5706 - val_loss: 0.9557 - val_acc: 0.5587\n",
            "Epoch 26/50 - 0.08s - loss: 0.8939 - acc: 0.5814 - val_loss: 0.9529 - val_acc: 0.5547\n",
            "Epoch 27/50 - 0.08s - loss: 0.8954 - acc: 0.5735 - val_loss: 0.9543 - val_acc: 0.5526\n",
            "Epoch 28/50 - 0.08s - loss: 0.9167 - acc: 0.5641 - val_loss: 0.9892 - val_acc: 0.5101\n",
            "Epoch 29/50 - 0.08s - loss: 0.8821 - acc: 0.5956 - val_loss: 0.9492 - val_acc: 0.5425\n",
            "Epoch 30/50 - 0.08s - loss: 0.8792 - acc: 0.5900 - val_loss: 0.9500 - val_acc: 0.5506\n",
            "Epoch 31/50 - 0.09s - loss: 0.8699 - acc: 0.5940 - val_loss: 0.9435 - val_acc: 0.5526\n",
            "Epoch 32/50 - 0.09s - loss: 0.8691 - acc: 0.5936 - val_loss: 0.9470 - val_acc: 0.5506\n",
            "Epoch 33/50 - 0.10s - loss: 0.9154 - acc: 0.5717 - val_loss: 0.9801 - val_acc: 0.5526\n",
            "Epoch 34/50 - 0.10s - loss: 0.8595 - acc: 0.6048 - val_loss: 0.9471 - val_acc: 0.5466\n",
            "Epoch 35/50 - 0.08s - loss: 0.8662 - acc: 0.5969 - val_loss: 0.9615 - val_acc: 0.5304\n",
            "Epoch 36/50 - 0.08s - loss: 0.9095 - acc: 0.5697 - val_loss: 1.0145 - val_acc: 0.4919\n",
            "Epoch 37/50 - 0.09s - loss: 0.8569 - acc: 0.6093 - val_loss: 0.9465 - val_acc: 0.5607\n",
            "Epoch 38/50 - 0.09s - loss: 0.8420 - acc: 0.6140 - val_loss: 0.9454 - val_acc: 0.5506\n",
            "Epoch 39/50 - 0.08s - loss: 0.8582 - acc: 0.6012 - val_loss: 0.9532 - val_acc: 0.5506\n",
            "Epoch 40/50 - 0.09s - loss: 0.8427 - acc: 0.6077 - val_loss: 0.9487 - val_acc: 0.5587\n",
            "Epoch 41/50 - 0.08s - loss: 0.8339 - acc: 0.6154 - val_loss: 0.9429 - val_acc: 0.5648\n",
            "Epoch 42/50 - 0.08s - loss: 0.9112 - acc: 0.5652 - val_loss: 1.0067 - val_acc: 0.5486\n",
            "Epoch 43/50 - 0.09s - loss: 0.8432 - acc: 0.6109 - val_loss: 0.9697 - val_acc: 0.5344\n",
            "Epoch 44/50 - 0.10s - loss: 0.8210 - acc: 0.6282 - val_loss: 0.9425 - val_acc: 0.5526\n",
            "Epoch 45/50 - 0.09s - loss: 0.8200 - acc: 0.6228 - val_loss: 0.9458 - val_acc: 0.5486\n",
            "Epoch 46/50 - 0.10s - loss: 0.8377 - acc: 0.6233 - val_loss: 0.9822 - val_acc: 0.5182\n",
            "Epoch 47/50 - 0.09s - loss: 0.8317 - acc: 0.6219 - val_loss: 0.9789 - val_acc: 0.5263\n",
            "Epoch 48/50 - 0.08s - loss: 0.8036 - acc: 0.6415 - val_loss: 0.9493 - val_acc: 0.5526\n",
            "Epoch 49/50 - 0.10s - loss: 0.7983 - acc: 0.6406 - val_loss: 0.9427 - val_acc: 0.5628\n",
            "Epoch 50/50 - 0.09s - loss: 0.8440 - acc: 0.6138 - val_loss: 0.9806 - val_acc: 0.5466\n",
            "\n",
            "Combination 146/252:\n",
            "Hidden Layers: [128, 64, 32], Activation: relu, Learning Rate: 0.01, Batch Size: 32, Epochs: 100\n",
            "Epoch 1/100 - 0.09s - loss: 1.0845 - acc: 0.3929 - val_loss: 1.0878 - val_acc: 0.3664\n",
            "Epoch 2/100 - 0.09s - loss: 1.0748 - acc: 0.4204 - val_loss: 1.0804 - val_acc: 0.3866\n",
            "Epoch 3/100 - 0.08s - loss: 1.0659 - acc: 0.4431 - val_loss: 1.0750 - val_acc: 0.4109\n",
            "Epoch 4/100 - 0.08s - loss: 1.0588 - acc: 0.4537 - val_loss: 1.0691 - val_acc: 0.4170\n",
            "Epoch 5/100 - 0.08s - loss: 1.0522 - acc: 0.4584 - val_loss: 1.0645 - val_acc: 0.4352\n",
            "Epoch 6/100 - 0.10s - loss: 1.0450 - acc: 0.4649 - val_loss: 1.0618 - val_acc: 0.4271\n",
            "Epoch 7/100 - 0.08s - loss: 1.0388 - acc: 0.4633 - val_loss: 1.0580 - val_acc: 0.4332\n",
            "Epoch 8/100 - 0.09s - loss: 1.0326 - acc: 0.4699 - val_loss: 1.0546 - val_acc: 0.4474\n",
            "Epoch 9/100 - 0.08s - loss: 1.0267 - acc: 0.4901 - val_loss: 1.0514 - val_acc: 0.4595\n",
            "Epoch 10/100 - 0.08s - loss: 1.0211 - acc: 0.4901 - val_loss: 1.0506 - val_acc: 0.4656\n",
            "Epoch 11/100 - 0.09s - loss: 1.0132 - acc: 0.4942 - val_loss: 1.0426 - val_acc: 0.4777\n",
            "Epoch 12/100 - 0.08s - loss: 1.0088 - acc: 0.5063 - val_loss: 1.0405 - val_acc: 0.4656\n",
            "Epoch 13/100 - 0.08s - loss: 1.0012 - acc: 0.5130 - val_loss: 1.0361 - val_acc: 0.4696\n",
            "Epoch 14/100 - 0.08s - loss: 0.9928 - acc: 0.5189 - val_loss: 1.0324 - val_acc: 0.4818\n",
            "Epoch 15/100 - 0.08s - loss: 0.9883 - acc: 0.5133 - val_loss: 1.0293 - val_acc: 0.5061\n",
            "Epoch 16/100 - 0.08s - loss: 0.9771 - acc: 0.5324 - val_loss: 1.0167 - val_acc: 0.4858\n",
            "Epoch 17/100 - 0.09s - loss: 0.9725 - acc: 0.5281 - val_loss: 1.0158 - val_acc: 0.4818\n",
            "Epoch 18/100 - 0.09s - loss: 0.9594 - acc: 0.5486 - val_loss: 1.0060 - val_acc: 0.5304\n",
            "Epoch 19/100 - 0.09s - loss: 0.9562 - acc: 0.5367 - val_loss: 1.0048 - val_acc: 0.4899\n",
            "Epoch 20/100 - 0.09s - loss: 0.9457 - acc: 0.5571 - val_loss: 0.9930 - val_acc: 0.5385\n",
            "Epoch 21/100 - 0.08s - loss: 0.9385 - acc: 0.5556 - val_loss: 0.9917 - val_acc: 0.5223\n",
            "Epoch 22/100 - 0.08s - loss: 0.9320 - acc: 0.5650 - val_loss: 0.9856 - val_acc: 0.5304\n",
            "Epoch 23/100 - 0.10s - loss: 0.9308 - acc: 0.5684 - val_loss: 0.9895 - val_acc: 0.5304\n",
            "Epoch 24/100 - 0.12s - loss: 0.9380 - acc: 0.5607 - val_loss: 0.9905 - val_acc: 0.5425\n",
            "Epoch 25/100 - 0.08s - loss: 0.9149 - acc: 0.5762 - val_loss: 0.9751 - val_acc: 0.5344\n",
            "Epoch 26/100 - 0.09s - loss: 0.9108 - acc: 0.5747 - val_loss: 0.9739 - val_acc: 0.5223\n",
            "Epoch 27/100 - 0.08s - loss: 0.9141 - acc: 0.5648 - val_loss: 0.9867 - val_acc: 0.5243\n",
            "Epoch 28/100 - 0.08s - loss: 0.9135 - acc: 0.5751 - val_loss: 0.9811 - val_acc: 0.5202\n",
            "Epoch 29/100 - 0.08s - loss: 0.8979 - acc: 0.5774 - val_loss: 0.9683 - val_acc: 0.5243\n",
            "Epoch 30/100 - 0.09s - loss: 0.8962 - acc: 0.5859 - val_loss: 0.9709 - val_acc: 0.5283\n",
            "Epoch 31/100 - 0.09s - loss: 0.8871 - acc: 0.5868 - val_loss: 0.9626 - val_acc: 0.5506\n",
            "Epoch 32/100 - 0.10s - loss: 0.9535 - acc: 0.5308 - val_loss: 1.0305 - val_acc: 0.4595\n",
            "Epoch 33/100 - 0.09s - loss: 0.8973 - acc: 0.5776 - val_loss: 0.9868 - val_acc: 0.5121\n",
            "Epoch 34/100 - 0.08s - loss: 0.9048 - acc: 0.5866 - val_loss: 0.9808 - val_acc: 0.5304\n",
            "Epoch 35/100 - 0.09s - loss: 0.8667 - acc: 0.5981 - val_loss: 0.9539 - val_acc: 0.5385\n",
            "Epoch 36/100 - 0.08s - loss: 0.8630 - acc: 0.6039 - val_loss: 0.9527 - val_acc: 0.5587\n",
            "Epoch 37/100 - 0.08s - loss: 0.8662 - acc: 0.5974 - val_loss: 0.9652 - val_acc: 0.5304\n",
            "Epoch 38/100 - 0.08s - loss: 0.8694 - acc: 0.5954 - val_loss: 0.9628 - val_acc: 0.5385\n",
            "Epoch 39/100 - 0.08s - loss: 0.8648 - acc: 0.6032 - val_loss: 0.9543 - val_acc: 0.5486\n",
            "Epoch 40/100 - 0.08s - loss: 0.8513 - acc: 0.6156 - val_loss: 0.9557 - val_acc: 0.5324\n",
            "Epoch 41/100 - 0.08s - loss: 0.8476 - acc: 0.6089 - val_loss: 0.9456 - val_acc: 0.5445\n",
            "Epoch 42/100 - 0.09s - loss: 0.8390 - acc: 0.6174 - val_loss: 0.9483 - val_acc: 0.5486\n",
            "Epoch 43/100 - 0.08s - loss: 0.8739 - acc: 0.6048 - val_loss: 0.9736 - val_acc: 0.5486\n",
            "Epoch 44/100 - 0.09s - loss: 0.8579 - acc: 0.6023 - val_loss: 0.9610 - val_acc: 0.5344\n",
            "Epoch 45/100 - 0.08s - loss: 0.8305 - acc: 0.6226 - val_loss: 0.9551 - val_acc: 0.5445\n",
            "Epoch 46/100 - 0.08s - loss: 0.8285 - acc: 0.6345 - val_loss: 0.9486 - val_acc: 0.5385\n",
            "Epoch 47/100 - 0.08s - loss: 0.8327 - acc: 0.6183 - val_loss: 0.9452 - val_acc: 0.5425\n",
            "Epoch 48/100 - 0.10s - loss: 0.8228 - acc: 0.6311 - val_loss: 0.9438 - val_acc: 0.5607\n",
            "Epoch 49/100 - 0.08s - loss: 0.8266 - acc: 0.6210 - val_loss: 0.9691 - val_acc: 0.5304\n",
            "Epoch 50/100 - 0.10s - loss: 0.8491 - acc: 0.6082 - val_loss: 0.9855 - val_acc: 0.5263\n",
            "Epoch 51/100 - 0.08s - loss: 0.8083 - acc: 0.6368 - val_loss: 0.9435 - val_acc: 0.5526\n",
            "Epoch 52/100 - 0.08s - loss: 0.8241 - acc: 0.6255 - val_loss: 0.9688 - val_acc: 0.5385\n",
            "Epoch 53/100 - 0.08s - loss: 0.8009 - acc: 0.6379 - val_loss: 0.9456 - val_acc: 0.5567\n",
            "Epoch 54/100 - 0.09s - loss: 0.8001 - acc: 0.6417 - val_loss: 0.9517 - val_acc: 0.5526\n",
            "Epoch 55/100 - 0.08s - loss: 0.7967 - acc: 0.6455 - val_loss: 0.9588 - val_acc: 0.5526\n",
            "Epoch 56/100 - 0.09s - loss: 0.7874 - acc: 0.6500 - val_loss: 0.9407 - val_acc: 0.5648\n",
            "Epoch 57/100 - 0.08s - loss: 0.8070 - acc: 0.6392 - val_loss: 0.9748 - val_acc: 0.5506\n",
            "Epoch 58/100 - 0.08s - loss: 0.7828 - acc: 0.6525 - val_loss: 0.9593 - val_acc: 0.5607\n",
            "Epoch 59/100 - 0.08s - loss: 0.7858 - acc: 0.6426 - val_loss: 0.9586 - val_acc: 0.5466\n",
            "Epoch 60/100 - 0.09s - loss: 0.8028 - acc: 0.6350 - val_loss: 0.9991 - val_acc: 0.5081\n",
            "Epoch 61/100 - 0.08s - loss: 0.7904 - acc: 0.6428 - val_loss: 0.9577 - val_acc: 0.5405\n",
            "Epoch 62/100 - 0.09s - loss: 0.7814 - acc: 0.6471 - val_loss: 0.9551 - val_acc: 0.5668\n",
            "Epoch 63/100 - 0.08s - loss: 0.7766 - acc: 0.6487 - val_loss: 0.9811 - val_acc: 0.5263\n",
            "Epoch 64/100 - 0.08s - loss: 0.8037 - acc: 0.6498 - val_loss: 0.9812 - val_acc: 0.5587\n",
            "Epoch 65/100 - 0.08s - loss: 0.7595 - acc: 0.6736 - val_loss: 0.9445 - val_acc: 0.5709\n",
            "Epoch 66/100 - 0.09s - loss: 0.7579 - acc: 0.6586 - val_loss: 0.9542 - val_acc: 0.5607\n",
            "Epoch 67/100 - 0.08s - loss: 0.7505 - acc: 0.6732 - val_loss: 0.9706 - val_acc: 0.5506\n",
            "Epoch 68/100 - 0.09s - loss: 0.7906 - acc: 0.6336 - val_loss: 1.0133 - val_acc: 0.5202\n",
            "Epoch 69/100 - 0.08s - loss: 0.7659 - acc: 0.6667 - val_loss: 0.9805 - val_acc: 0.5567\n",
            "Epoch 70/100 - 0.08s - loss: 0.7564 - acc: 0.6698 - val_loss: 0.9625 - val_acc: 0.5668\n",
            "Epoch 71/100 - 0.08s - loss: 0.7501 - acc: 0.6624 - val_loss: 0.9760 - val_acc: 0.5587\n",
            "Epoch 72/100 - 0.09s - loss: 0.7716 - acc: 0.6538 - val_loss: 0.9789 - val_acc: 0.5547\n",
            "Epoch 73/100 - 0.08s - loss: 0.7496 - acc: 0.6628 - val_loss: 0.9677 - val_acc: 0.5547\n",
            "Epoch 74/100 - 0.08s - loss: 0.7244 - acc: 0.6928 - val_loss: 0.9787 - val_acc: 0.5445\n",
            "Epoch 75/100 - 0.08s - loss: 0.7138 - acc: 0.7058 - val_loss: 0.9610 - val_acc: 0.5668\n",
            "Epoch 76/100 - 0.08s - loss: 0.7602 - acc: 0.6547 - val_loss: 1.0069 - val_acc: 0.5405\n",
            "Epoch 77/100 - 0.09s - loss: 0.7135 - acc: 0.7042 - val_loss: 0.9619 - val_acc: 0.5789\n",
            "Epoch 78/100 - 0.12s - loss: 0.8277 - acc: 0.5990 - val_loss: 1.1095 - val_acc: 0.4919\n",
            "Epoch 79/100 - 0.09s - loss: 0.7270 - acc: 0.6826 - val_loss: 1.0078 - val_acc: 0.5344\n",
            "Epoch 80/100 - 0.09s - loss: 0.8862 - acc: 0.5864 - val_loss: 1.1707 - val_acc: 0.4858\n",
            "Epoch 81/100 - 0.08s - loss: 0.7323 - acc: 0.6757 - val_loss: 1.0285 - val_acc: 0.5466\n",
            "Epoch 82/100 - 0.09s - loss: 0.7404 - acc: 0.6570 - val_loss: 1.0313 - val_acc: 0.5385\n",
            "Epoch 83/100 - 0.08s - loss: 0.6806 - acc: 0.7092 - val_loss: 0.9532 - val_acc: 0.5769\n",
            "Epoch 84/100 - 0.08s - loss: 0.7084 - acc: 0.6970 - val_loss: 0.9907 - val_acc: 0.5850\n",
            "Epoch 85/100 - 0.08s - loss: 0.6729 - acc: 0.7278 - val_loss: 0.9830 - val_acc: 0.5648\n",
            "Epoch 86/100 - 0.08s - loss: 0.6558 - acc: 0.7346 - val_loss: 0.9696 - val_acc: 0.5688\n",
            "Epoch 87/100 - 0.08s - loss: 0.6786 - acc: 0.7076 - val_loss: 0.9757 - val_acc: 0.5850\n",
            "Epoch 88/100 - 0.09s - loss: 0.6792 - acc: 0.7141 - val_loss: 0.9979 - val_acc: 0.5587\n",
            "Epoch 89/100 - 0.10s - loss: 0.6465 - acc: 0.7382 - val_loss: 0.9686 - val_acc: 0.5789\n",
            "Epoch 90/100 - 0.08s - loss: 0.7122 - acc: 0.6788 - val_loss: 1.0645 - val_acc: 0.5304\n",
            "Epoch 91/100 - 0.09s - loss: 0.6834 - acc: 0.7164 - val_loss: 1.0104 - val_acc: 0.5709\n",
            "Epoch 92/100 - 0.08s - loss: 0.6216 - acc: 0.7472 - val_loss: 0.9560 - val_acc: 0.5870\n",
            "Epoch 93/100 - 0.08s - loss: 0.6769 - acc: 0.7029 - val_loss: 1.0196 - val_acc: 0.5425\n",
            "Epoch 94/100 - 0.08s - loss: 0.6094 - acc: 0.7623 - val_loss: 0.9548 - val_acc: 0.5850\n",
            "Epoch 95/100 - 0.09s - loss: 0.6297 - acc: 0.7440 - val_loss: 0.9898 - val_acc: 0.5567\n",
            "Epoch 96/100 - 0.08s - loss: 0.6711 - acc: 0.7076 - val_loss: 1.0445 - val_acc: 0.5283\n",
            "Epoch 97/100 - 0.09s - loss: 0.7142 - acc: 0.6777 - val_loss: 1.0511 - val_acc: 0.5506\n",
            "Epoch 98/100 - 0.08s - loss: 0.6437 - acc: 0.7265 - val_loss: 1.0102 - val_acc: 0.5749\n",
            "Epoch 99/100 - 0.09s - loss: 0.7479 - acc: 0.6345 - val_loss: 1.1375 - val_acc: 0.4960\n",
            "Epoch 100/100 - 0.10s - loss: 0.6778 - acc: 0.7029 - val_loss: 1.0732 - val_acc: 0.5425\n",
            "\n",
            "Combination 147/252:\n",
            "Hidden Layers: [128, 64, 32], Activation: relu, Learning Rate: 0.01, Batch Size: 32, Epochs: 150\n",
            "Epoch 1/150 - 0.08s - loss: 1.0855 - acc: 0.3923 - val_loss: 1.0890 - val_acc: 0.4028\n",
            "Epoch 2/150 - 0.08s - loss: 1.0766 - acc: 0.4213 - val_loss: 1.0837 - val_acc: 0.4089\n",
            "Epoch 3/150 - 0.08s - loss: 1.0685 - acc: 0.4422 - val_loss: 1.0772 - val_acc: 0.4251\n",
            "Epoch 4/150 - 0.08s - loss: 1.0601 - acc: 0.4532 - val_loss: 1.0721 - val_acc: 0.4312\n",
            "Epoch 5/150 - 0.09s - loss: 1.0509 - acc: 0.4665 - val_loss: 1.0659 - val_acc: 0.4433\n",
            "Epoch 6/150 - 0.09s - loss: 1.0410 - acc: 0.4705 - val_loss: 1.0578 - val_acc: 0.4656\n",
            "Epoch 7/150 - 0.08s - loss: 1.0319 - acc: 0.4847 - val_loss: 1.0523 - val_acc: 0.4595\n",
            "Epoch 8/150 - 0.08s - loss: 1.0202 - acc: 0.4888 - val_loss: 1.0453 - val_acc: 0.4696\n",
            "Epoch 9/150 - 0.08s - loss: 1.0097 - acc: 0.5045 - val_loss: 1.0403 - val_acc: 0.4757\n",
            "Epoch 10/150 - 0.08s - loss: 0.9988 - acc: 0.5070 - val_loss: 1.0301 - val_acc: 0.4879\n",
            "Epoch 11/150 - 0.08s - loss: 0.9917 - acc: 0.5103 - val_loss: 1.0267 - val_acc: 0.4939\n",
            "Epoch 12/150 - 0.08s - loss: 0.9793 - acc: 0.5254 - val_loss: 1.0140 - val_acc: 0.4980\n",
            "Epoch 13/150 - 0.09s - loss: 0.9699 - acc: 0.5335 - val_loss: 1.0105 - val_acc: 0.5121\n",
            "Epoch 14/150 - 0.08s - loss: 0.9664 - acc: 0.5306 - val_loss: 1.0099 - val_acc: 0.5020\n",
            "Epoch 15/150 - 0.09s - loss: 0.9616 - acc: 0.5328 - val_loss: 1.0085 - val_acc: 0.5020\n",
            "Epoch 16/150 - 0.08s - loss: 0.9538 - acc: 0.5405 - val_loss: 0.9947 - val_acc: 0.5101\n",
            "Epoch 17/150 - 0.08s - loss: 0.9557 - acc: 0.5445 - val_loss: 0.9999 - val_acc: 0.5324\n",
            "Epoch 18/150 - 0.09s - loss: 0.9348 - acc: 0.5560 - val_loss: 0.9847 - val_acc: 0.5405\n",
            "Epoch 19/150 - 0.09s - loss: 0.9351 - acc: 0.5529 - val_loss: 0.9913 - val_acc: 0.5142\n",
            "Epoch 20/150 - 0.08s - loss: 0.9314 - acc: 0.5535 - val_loss: 0.9901 - val_acc: 0.5061\n",
            "Epoch 21/150 - 0.08s - loss: 0.9230 - acc: 0.5650 - val_loss: 0.9770 - val_acc: 0.5425\n",
            "Epoch 22/150 - 0.08s - loss: 0.9160 - acc: 0.5673 - val_loss: 0.9708 - val_acc: 0.5385\n",
            "Epoch 23/150 - 0.08s - loss: 0.9270 - acc: 0.5540 - val_loss: 0.9908 - val_acc: 0.5081\n",
            "Epoch 24/150 - 0.08s - loss: 0.9307 - acc: 0.5585 - val_loss: 0.9812 - val_acc: 0.5526\n",
            "Epoch 25/150 - 0.09s - loss: 0.9136 - acc: 0.5700 - val_loss: 0.9692 - val_acc: 0.5405\n",
            "Epoch 26/150 - 0.08s - loss: 0.8969 - acc: 0.5807 - val_loss: 0.9631 - val_acc: 0.5364\n",
            "Epoch 27/150 - 0.08s - loss: 0.8955 - acc: 0.5807 - val_loss: 0.9591 - val_acc: 0.5506\n",
            "Epoch 28/150 - 0.09s - loss: 0.8931 - acc: 0.5839 - val_loss: 0.9618 - val_acc: 0.5567\n",
            "Epoch 29/150 - 0.08s - loss: 0.8895 - acc: 0.5893 - val_loss: 0.9613 - val_acc: 0.5668\n",
            "Epoch 30/150 - 0.10s - loss: 0.8814 - acc: 0.5902 - val_loss: 0.9591 - val_acc: 0.5506\n",
            "Epoch 31/150 - 0.09s - loss: 0.9165 - acc: 0.5670 - val_loss: 0.9832 - val_acc: 0.5425\n",
            "Epoch 32/150 - 0.08s - loss: 0.8734 - acc: 0.5922 - val_loss: 0.9553 - val_acc: 0.5445\n",
            "Epoch 33/150 - 0.09s - loss: 0.8744 - acc: 0.5976 - val_loss: 0.9540 - val_acc: 0.5688\n",
            "Epoch 34/150 - 0.08s - loss: 0.8885 - acc: 0.5841 - val_loss: 0.9657 - val_acc: 0.5466\n",
            "Epoch 35/150 - 0.08s - loss: 0.9089 - acc: 0.5740 - val_loss: 0.9810 - val_acc: 0.5607\n",
            "Epoch 36/150 - 0.09s - loss: 0.8845 - acc: 0.5900 - val_loss: 0.9606 - val_acc: 0.5769\n",
            "Epoch 37/150 - 0.09s - loss: 0.9187 - acc: 0.5594 - val_loss: 1.0244 - val_acc: 0.4798\n",
            "Epoch 38/150 - 0.08s - loss: 0.8515 - acc: 0.6035 - val_loss: 0.9531 - val_acc: 0.5364\n",
            "Epoch 39/150 - 0.09s - loss: 0.8583 - acc: 0.6023 - val_loss: 0.9499 - val_acc: 0.5709\n",
            "Epoch 40/150 - 0.09s - loss: 0.8454 - acc: 0.6125 - val_loss: 0.9409 - val_acc: 0.5729\n",
            "Epoch 41/150 - 0.08s - loss: 0.8929 - acc: 0.5738 - val_loss: 1.0143 - val_acc: 0.4960\n",
            "Epoch 42/150 - 0.10s - loss: 0.8604 - acc: 0.6026 - val_loss: 0.9579 - val_acc: 0.5364\n",
            "Epoch 43/150 - 0.08s - loss: 0.8643 - acc: 0.5969 - val_loss: 0.9891 - val_acc: 0.5020\n",
            "Epoch 44/150 - 0.08s - loss: 0.8329 - acc: 0.6165 - val_loss: 0.9503 - val_acc: 0.5567\n",
            "Epoch 45/150 - 0.09s - loss: 0.8235 - acc: 0.6269 - val_loss: 0.9462 - val_acc: 0.5607\n",
            "Epoch 46/150 - 0.08s - loss: 0.8385 - acc: 0.6134 - val_loss: 0.9686 - val_acc: 0.5223\n",
            "Epoch 47/150 - 0.08s - loss: 0.8545 - acc: 0.6055 - val_loss: 0.9822 - val_acc: 0.5405\n",
            "Epoch 48/150 - 0.09s - loss: 0.8201 - acc: 0.6251 - val_loss: 0.9626 - val_acc: 0.5182\n",
            "Epoch 49/150 - 0.09s - loss: 0.8200 - acc: 0.6293 - val_loss: 0.9631 - val_acc: 0.5263\n",
            "Epoch 50/150 - 0.08s - loss: 0.8064 - acc: 0.6372 - val_loss: 0.9415 - val_acc: 0.5688\n",
            "Epoch 51/150 - 0.09s - loss: 0.8667 - acc: 0.5965 - val_loss: 1.0232 - val_acc: 0.5081\n",
            "Epoch 52/150 - 0.08s - loss: 0.8127 - acc: 0.6334 - val_loss: 0.9618 - val_acc: 0.5162\n",
            "Epoch 53/150 - 0.08s - loss: 0.8172 - acc: 0.6278 - val_loss: 0.9523 - val_acc: 0.5486\n",
            "Epoch 54/150 - 0.08s - loss: 0.8060 - acc: 0.6383 - val_loss: 0.9441 - val_acc: 0.5810\n",
            "Epoch 55/150 - 0.09s - loss: 0.8335 - acc: 0.6156 - val_loss: 0.9755 - val_acc: 0.5263\n",
            "Epoch 56/150 - 0.08s - loss: 0.7858 - acc: 0.6502 - val_loss: 0.9480 - val_acc: 0.5607\n",
            "Epoch 57/150 - 0.08s - loss: 0.8091 - acc: 0.6334 - val_loss: 0.9853 - val_acc: 0.5223\n",
            "Epoch 58/150 - 0.09s - loss: 0.8036 - acc: 0.6334 - val_loss: 0.9749 - val_acc: 0.5182\n",
            "Epoch 59/150 - 0.09s - loss: 0.7857 - acc: 0.6496 - val_loss: 0.9460 - val_acc: 0.5567\n",
            "Epoch 60/150 - 0.09s - loss: 0.7760 - acc: 0.6633 - val_loss: 0.9443 - val_acc: 0.5547\n",
            "Epoch 61/150 - 0.08s - loss: 0.7718 - acc: 0.6619 - val_loss: 0.9545 - val_acc: 0.5344\n",
            "Epoch 62/150 - 0.08s - loss: 0.8236 - acc: 0.6152 - val_loss: 0.9717 - val_acc: 0.5729\n",
            "Epoch 63/150 - 0.08s - loss: 0.8246 - acc: 0.6264 - val_loss: 1.0405 - val_acc: 0.5121\n",
            "Epoch 64/150 - 0.08s - loss: 0.8370 - acc: 0.6098 - val_loss: 0.9886 - val_acc: 0.5628\n",
            "Epoch 65/150 - 0.08s - loss: 0.8588 - acc: 0.6039 - val_loss: 1.0919 - val_acc: 0.4960\n",
            "Epoch 66/150 - 0.08s - loss: 0.7997 - acc: 0.6318 - val_loss: 1.0102 - val_acc: 0.5061\n",
            "Epoch 67/150 - 0.09s - loss: 0.7508 - acc: 0.6790 - val_loss: 0.9447 - val_acc: 0.5587\n",
            "Epoch 68/150 - 0.08s - loss: 0.7970 - acc: 0.6442 - val_loss: 0.9788 - val_acc: 0.5587\n",
            "Epoch 69/150 - 0.09s - loss: 0.8958 - acc: 0.5859 - val_loss: 1.1069 - val_acc: 0.5000\n",
            "Epoch 70/150 - 0.08s - loss: 0.8193 - acc: 0.6264 - val_loss: 1.0068 - val_acc: 0.5304\n",
            "Epoch 71/150 - 0.08s - loss: 0.7636 - acc: 0.6617 - val_loss: 1.0064 - val_acc: 0.5142\n",
            "Epoch 72/150 - 0.09s - loss: 0.7308 - acc: 0.6822 - val_loss: 0.9546 - val_acc: 0.5385\n",
            "Epoch 73/150 - 0.10s - loss: 0.8367 - acc: 0.6127 - val_loss: 1.0963 - val_acc: 0.4879\n",
            "Epoch 74/150 - 0.08s - loss: 0.8377 - acc: 0.6084 - val_loss: 1.0320 - val_acc: 0.5445\n",
            "Epoch 75/150 - 0.09s - loss: 0.7255 - acc: 0.6856 - val_loss: 0.9651 - val_acc: 0.5506\n",
            "Epoch 76/150 - 0.09s - loss: 0.8276 - acc: 0.5976 - val_loss: 1.0090 - val_acc: 0.5344\n",
            "Epoch 77/150 - 0.10s - loss: 0.7174 - acc: 0.6919 - val_loss: 0.9587 - val_acc: 0.5587\n",
            "Epoch 78/150 - 0.10s - loss: 0.9513 - acc: 0.5297 - val_loss: 1.1298 - val_acc: 0.4960\n",
            "Epoch 79/150 - 0.08s - loss: 0.7615 - acc: 0.6529 - val_loss: 1.0010 - val_acc: 0.5526\n",
            "Epoch 80/150 - 0.08s - loss: 0.7309 - acc: 0.6813 - val_loss: 1.0008 - val_acc: 0.5405\n",
            "Epoch 81/150 - 0.08s - loss: 0.6967 - acc: 0.7114 - val_loss: 0.9349 - val_acc: 0.5891\n",
            "Epoch 82/150 - 0.08s - loss: 0.7297 - acc: 0.6862 - val_loss: 0.9718 - val_acc: 0.5547\n",
            "Epoch 83/150 - 0.08s - loss: 0.6941 - acc: 0.7074 - val_loss: 0.9523 - val_acc: 0.5830\n",
            "Epoch 84/150 - 0.09s - loss: 0.7160 - acc: 0.6914 - val_loss: 0.9549 - val_acc: 0.5830\n",
            "Epoch 85/150 - 0.09s - loss: 0.6932 - acc: 0.7119 - val_loss: 0.9518 - val_acc: 0.5789\n",
            "Epoch 86/150 - 0.09s - loss: 0.6914 - acc: 0.7036 - val_loss: 0.9945 - val_acc: 0.5466\n",
            "Epoch 87/150 - 0.09s - loss: 0.7365 - acc: 0.6545 - val_loss: 1.0144 - val_acc: 0.5344\n",
            "Epoch 88/150 - 0.08s - loss: 0.6861 - acc: 0.7036 - val_loss: 0.9831 - val_acc: 0.5466\n",
            "Epoch 89/150 - 0.08s - loss: 0.7155 - acc: 0.6887 - val_loss: 1.0162 - val_acc: 0.5364\n",
            "Epoch 90/150 - 0.09s - loss: 0.6854 - acc: 0.7090 - val_loss: 0.9562 - val_acc: 0.5729\n",
            "Epoch 91/150 - 0.08s - loss: 0.6888 - acc: 0.7121 - val_loss: 0.9995 - val_acc: 0.5567\n",
            "Epoch 92/150 - 0.08s - loss: 0.7318 - acc: 0.6712 - val_loss: 1.0763 - val_acc: 0.5324\n",
            "Epoch 93/150 - 0.08s - loss: 0.6504 - acc: 0.7265 - val_loss: 0.9891 - val_acc: 0.5466\n",
            "Epoch 94/150 - 0.08s - loss: 0.6539 - acc: 0.7323 - val_loss: 0.9601 - val_acc: 0.5628\n",
            "Epoch 95/150 - 0.08s - loss: 0.6431 - acc: 0.7391 - val_loss: 0.9654 - val_acc: 0.5830\n",
            "Epoch 96/150 - 0.09s - loss: 0.8126 - acc: 0.6289 - val_loss: 1.1951 - val_acc: 0.4960\n",
            "Epoch 97/150 - 0.08s - loss: 0.6205 - acc: 0.7537 - val_loss: 0.9655 - val_acc: 0.5506\n",
            "Epoch 98/150 - 0.08s - loss: 0.6225 - acc: 0.7474 - val_loss: 0.9777 - val_acc: 0.5607\n",
            "Epoch 99/150 - 0.09s - loss: 0.6589 - acc: 0.7224 - val_loss: 1.0129 - val_acc: 0.5607\n",
            "Epoch 100/150 - 0.08s - loss: 0.6322 - acc: 0.7328 - val_loss: 1.0108 - val_acc: 0.5385\n",
            "Epoch 101/150 - 0.08s - loss: 0.7047 - acc: 0.6946 - val_loss: 1.0510 - val_acc: 0.5587\n",
            "Epoch 102/150 - 0.09s - loss: 0.6856 - acc: 0.7114 - val_loss: 1.0238 - val_acc: 0.5709\n",
            "Epoch 103/150 - 0.10s - loss: 0.6553 - acc: 0.7114 - val_loss: 1.0520 - val_acc: 0.5364\n",
            "Epoch 104/150 - 0.10s - loss: 0.6530 - acc: 0.7045 - val_loss: 1.0288 - val_acc: 0.5486\n",
            "Epoch 105/150 - 0.09s - loss: 0.5848 - acc: 0.7679 - val_loss: 0.9777 - val_acc: 0.5709\n",
            "Epoch 106/150 - 0.08s - loss: 0.5854 - acc: 0.7578 - val_loss: 0.9829 - val_acc: 0.5648\n",
            "Epoch 107/150 - 0.08s - loss: 0.7174 - acc: 0.6658 - val_loss: 1.0597 - val_acc: 0.5729\n",
            "Epoch 108/150 - 0.09s - loss: 0.5718 - acc: 0.7773 - val_loss: 0.9532 - val_acc: 0.5749\n",
            "Epoch 109/150 - 0.10s - loss: 0.6007 - acc: 0.7557 - val_loss: 0.9923 - val_acc: 0.5769\n",
            "Epoch 110/150 - 0.08s - loss: 0.5604 - acc: 0.7834 - val_loss: 0.9726 - val_acc: 0.5769\n",
            "Epoch 111/150 - 0.09s - loss: 0.5903 - acc: 0.7652 - val_loss: 0.9851 - val_acc: 0.5789\n",
            "Epoch 112/150 - 0.09s - loss: 0.7008 - acc: 0.6833 - val_loss: 1.0846 - val_acc: 0.5506\n",
            "Epoch 113/150 - 0.08s - loss: 0.5406 - acc: 0.7906 - val_loss: 0.9953 - val_acc: 0.5749\n",
            "Epoch 114/150 - 0.09s - loss: 0.5417 - acc: 0.7919 - val_loss: 0.9852 - val_acc: 0.5466\n",
            "Epoch 115/150 - 0.08s - loss: 0.5636 - acc: 0.7659 - val_loss: 1.0318 - val_acc: 0.5486\n",
            "Epoch 116/150 - 0.08s - loss: 0.6877 - acc: 0.7042 - val_loss: 1.0756 - val_acc: 0.5810\n",
            "Epoch 117/150 - 0.09s - loss: 0.5649 - acc: 0.7728 - val_loss: 1.0619 - val_acc: 0.5385\n",
            "Epoch 118/150 - 0.08s - loss: 0.5165 - acc: 0.8099 - val_loss: 0.9709 - val_acc: 0.5789\n",
            "Epoch 119/150 - 0.08s - loss: 0.5255 - acc: 0.8063 - val_loss: 0.9914 - val_acc: 0.5688\n",
            "Epoch 120/150 - 0.08s - loss: 0.5295 - acc: 0.7931 - val_loss: 1.0223 - val_acc: 0.5688\n",
            "Epoch 121/150 - 0.08s - loss: 0.5264 - acc: 0.8039 - val_loss: 0.9795 - val_acc: 0.5830\n",
            "Epoch 122/150 - 0.08s - loss: 0.6187 - acc: 0.7290 - val_loss: 1.0802 - val_acc: 0.5648\n",
            "Epoch 123/150 - 0.09s - loss: 0.5231 - acc: 0.7917 - val_loss: 1.0642 - val_acc: 0.5385\n",
            "Epoch 124/150 - 0.08s - loss: 0.4796 - acc: 0.8250 - val_loss: 0.9794 - val_acc: 0.5729\n",
            "Epoch 125/150 - 0.08s - loss: 0.4782 - acc: 0.8302 - val_loss: 0.9924 - val_acc: 0.5688\n",
            "Epoch 126/150 - 0.09s - loss: 0.5309 - acc: 0.7785 - val_loss: 1.0811 - val_acc: 0.5466\n",
            "Epoch 127/150 - 0.08s - loss: 0.4719 - acc: 0.8174 - val_loss: 1.0468 - val_acc: 0.5830\n",
            "Epoch 128/150 - 0.08s - loss: 0.4999 - acc: 0.7971 - val_loss: 1.0748 - val_acc: 0.5385\n",
            "Epoch 129/150 - 0.09s - loss: 0.4570 - acc: 0.8304 - val_loss: 1.0374 - val_acc: 0.5567\n",
            "Epoch 130/150 - 0.08s - loss: 0.4798 - acc: 0.8225 - val_loss: 1.0213 - val_acc: 0.5789\n",
            "Epoch 131/150 - 0.08s - loss: 0.4671 - acc: 0.8302 - val_loss: 1.0580 - val_acc: 0.5243\n",
            "Epoch 132/150 - 0.09s - loss: 0.4628 - acc: 0.8264 - val_loss: 1.0963 - val_acc: 0.5445\n",
            "Epoch 133/150 - 0.08s - loss: 0.4303 - acc: 0.8520 - val_loss: 1.0321 - val_acc: 0.5668\n",
            "Epoch 134/150 - 0.08s - loss: 0.4495 - acc: 0.8302 - val_loss: 1.0436 - val_acc: 0.5688\n",
            "Epoch 135/150 - 0.08s - loss: 0.6135 - acc: 0.7170 - val_loss: 1.1752 - val_acc: 0.5486\n",
            "Epoch 136/150 - 0.08s - loss: 0.5341 - acc: 0.7850 - val_loss: 1.0640 - val_acc: 0.5567\n",
            "Epoch 137/150 - 0.08s - loss: 0.4398 - acc: 0.8351 - val_loss: 1.0500 - val_acc: 0.5850\n",
            "Epoch 138/150 - 0.08s - loss: 0.4557 - acc: 0.8232 - val_loss: 1.0758 - val_acc: 0.5547\n",
            "Epoch 139/150 - 0.10s - loss: 0.4773 - acc: 0.8068 - val_loss: 1.1823 - val_acc: 0.5526\n",
            "Epoch 140/150 - 0.08s - loss: 0.4029 - acc: 0.8677 - val_loss: 1.0121 - val_acc: 0.5749\n",
            "Epoch 141/150 - 0.09s - loss: 0.4842 - acc: 0.8068 - val_loss: 1.1346 - val_acc: 0.5668\n",
            "Epoch 142/150 - 0.08s - loss: 0.4858 - acc: 0.8050 - val_loss: 1.2056 - val_acc: 0.5324\n",
            "Epoch 143/150 - 0.08s - loss: 0.3970 - acc: 0.8644 - val_loss: 1.0347 - val_acc: 0.5688\n",
            "Epoch 144/150 - 0.08s - loss: 0.4327 - acc: 0.8300 - val_loss: 1.0973 - val_acc: 0.5951\n",
            "Epoch 145/150 - 0.08s - loss: 0.3624 - acc: 0.8842 - val_loss: 1.0555 - val_acc: 0.5587\n",
            "Epoch 146/150 - 0.08s - loss: 0.3656 - acc: 0.8790 - val_loss: 1.0588 - val_acc: 0.5810\n",
            "Epoch 147/150 - 0.08s - loss: 0.7136 - acc: 0.6766 - val_loss: 1.5210 - val_acc: 0.4879\n",
            "Epoch 148/150 - 0.09s - loss: 0.3423 - acc: 0.8862 - val_loss: 1.0903 - val_acc: 0.5709\n",
            "Epoch 149/150 - 0.08s - loss: 0.4270 - acc: 0.8198 - val_loss: 1.1128 - val_acc: 0.5992\n",
            "Epoch 150/150 - 0.09s - loss: 0.3931 - acc: 0.8552 - val_loss: 1.1606 - val_acc: 0.5486\n",
            "\n",
            "Combination 148/252:\n",
            "Hidden Layers: [128, 64, 32], Activation: relu, Learning Rate: 0.01, Batch Size: 64, Epochs: 50\n",
            "Epoch 1/50 - 0.07s - loss: 1.0938 - acc: 0.3871 - val_loss: 1.0929 - val_acc: 0.3623\n",
            "Epoch 2/50 - 0.07s - loss: 1.0866 - acc: 0.4055 - val_loss: 1.0863 - val_acc: 0.3887\n",
            "Epoch 3/50 - 0.07s - loss: 1.0817 - acc: 0.4213 - val_loss: 1.0826 - val_acc: 0.3846\n",
            "Epoch 4/50 - 0.07s - loss: 1.0772 - acc: 0.4247 - val_loss: 1.0780 - val_acc: 0.3846\n",
            "Epoch 5/50 - 0.07s - loss: 1.0736 - acc: 0.4370 - val_loss: 1.0758 - val_acc: 0.4150\n",
            "Epoch 6/50 - 0.06s - loss: 1.0697 - acc: 0.4492 - val_loss: 1.0723 - val_acc: 0.4231\n",
            "Epoch 7/50 - 0.07s - loss: 1.0662 - acc: 0.4485 - val_loss: 1.0691 - val_acc: 0.4271\n",
            "Epoch 8/50 - 0.08s - loss: 1.0630 - acc: 0.4568 - val_loss: 1.0675 - val_acc: 0.4251\n",
            "Epoch 9/50 - 0.07s - loss: 1.0593 - acc: 0.4627 - val_loss: 1.0642 - val_acc: 0.4372\n",
            "Epoch 10/50 - 0.07s - loss: 1.0558 - acc: 0.4654 - val_loss: 1.0622 - val_acc: 0.4393\n",
            "Epoch 11/50 - 0.07s - loss: 1.0522 - acc: 0.4708 - val_loss: 1.0599 - val_acc: 0.4474\n",
            "Epoch 12/50 - 0.07s - loss: 1.0485 - acc: 0.4757 - val_loss: 1.0574 - val_acc: 0.4575\n",
            "Epoch 13/50 - 0.07s - loss: 1.0456 - acc: 0.4726 - val_loss: 1.0560 - val_acc: 0.4494\n",
            "Epoch 14/50 - 0.07s - loss: 1.0416 - acc: 0.4717 - val_loss: 1.0524 - val_acc: 0.4474\n",
            "Epoch 15/50 - 0.06s - loss: 1.0377 - acc: 0.4755 - val_loss: 1.0495 - val_acc: 0.4636\n",
            "Epoch 16/50 - 0.08s - loss: 1.0334 - acc: 0.4854 - val_loss: 1.0477 - val_acc: 0.4555\n",
            "Epoch 17/50 - 0.07s - loss: 1.0325 - acc: 0.4825 - val_loss: 1.0472 - val_acc: 0.4555\n",
            "Epoch 18/50 - 0.07s - loss: 1.0252 - acc: 0.4890 - val_loss: 1.0433 - val_acc: 0.4676\n",
            "Epoch 19/50 - 0.07s - loss: 1.0216 - acc: 0.4939 - val_loss: 1.0410 - val_acc: 0.4636\n",
            "Epoch 20/50 - 0.07s - loss: 1.0188 - acc: 0.4951 - val_loss: 1.0404 - val_acc: 0.4656\n",
            "Epoch 21/50 - 0.06s - loss: 1.0118 - acc: 0.4978 - val_loss: 1.0335 - val_acc: 0.4737\n",
            "Epoch 22/50 - 0.08s - loss: 1.0078 - acc: 0.5038 - val_loss: 1.0303 - val_acc: 0.4858\n",
            "Epoch 23/50 - 0.07s - loss: 1.0039 - acc: 0.5061 - val_loss: 1.0284 - val_acc: 0.4980\n",
            "Epoch 24/50 - 0.07s - loss: 0.9983 - acc: 0.5148 - val_loss: 1.0231 - val_acc: 0.4777\n",
            "Epoch 25/50 - 0.06s - loss: 0.9935 - acc: 0.5196 - val_loss: 1.0210 - val_acc: 0.4980\n",
            "Epoch 26/50 - 0.06s - loss: 0.9892 - acc: 0.5146 - val_loss: 1.0174 - val_acc: 0.4980\n",
            "Epoch 27/50 - 0.07s - loss: 0.9864 - acc: 0.5155 - val_loss: 1.0142 - val_acc: 0.5040\n",
            "Epoch 28/50 - 0.07s - loss: 0.9869 - acc: 0.5182 - val_loss: 1.0153 - val_acc: 0.5101\n",
            "Epoch 29/50 - 0.06s - loss: 0.9753 - acc: 0.5306 - val_loss: 1.0054 - val_acc: 0.5101\n",
            "Epoch 30/50 - 0.07s - loss: 0.9722 - acc: 0.5292 - val_loss: 1.0017 - val_acc: 0.5121\n",
            "Epoch 31/50 - 0.08s - loss: 0.9666 - acc: 0.5362 - val_loss: 0.9989 - val_acc: 0.5304\n",
            "Epoch 32/50 - 0.07s - loss: 0.9645 - acc: 0.5391 - val_loss: 0.9950 - val_acc: 0.5142\n",
            "Epoch 33/50 - 0.07s - loss: 0.9650 - acc: 0.5335 - val_loss: 0.9969 - val_acc: 0.5324\n",
            "Epoch 34/50 - 0.07s - loss: 0.9550 - acc: 0.5439 - val_loss: 0.9892 - val_acc: 0.5283\n",
            "Epoch 35/50 - 0.07s - loss: 0.9554 - acc: 0.5378 - val_loss: 0.9913 - val_acc: 0.5101\n",
            "Epoch 36/50 - 0.06s - loss: 0.9522 - acc: 0.5452 - val_loss: 0.9872 - val_acc: 0.5405\n",
            "Epoch 37/50 - 0.07s - loss: 0.9454 - acc: 0.5511 - val_loss: 0.9826 - val_acc: 0.5304\n",
            "Epoch 38/50 - 0.07s - loss: 0.9589 - acc: 0.5418 - val_loss: 0.9956 - val_acc: 0.5202\n",
            "Epoch 39/50 - 0.07s - loss: 0.9416 - acc: 0.5511 - val_loss: 0.9786 - val_acc: 0.5445\n",
            "Epoch 40/50 - 0.07s - loss: 0.9419 - acc: 0.5468 - val_loss: 0.9834 - val_acc: 0.5263\n",
            "Epoch 41/50 - 0.07s - loss: 0.9411 - acc: 0.5481 - val_loss: 0.9824 - val_acc: 0.5081\n",
            "Epoch 42/50 - 0.07s - loss: 0.9310 - acc: 0.5576 - val_loss: 0.9745 - val_acc: 0.5364\n",
            "Epoch 43/50 - 0.07s - loss: 0.9377 - acc: 0.5450 - val_loss: 0.9837 - val_acc: 0.5182\n",
            "Epoch 44/50 - 0.07s - loss: 0.9376 - acc: 0.5432 - val_loss: 0.9863 - val_acc: 0.5142\n",
            "Epoch 45/50 - 0.06s - loss: 0.9418 - acc: 0.5400 - val_loss: 0.9908 - val_acc: 0.5040\n",
            "Epoch 46/50 - 0.07s - loss: 0.9220 - acc: 0.5605 - val_loss: 0.9689 - val_acc: 0.5425\n",
            "Epoch 47/50 - 0.08s - loss: 0.9281 - acc: 0.5524 - val_loss: 0.9811 - val_acc: 0.5121\n",
            "Epoch 48/50 - 0.07s - loss: 0.9375 - acc: 0.5475 - val_loss: 0.9879 - val_acc: 0.5283\n",
            "Epoch 49/50 - 0.06s - loss: 0.9231 - acc: 0.5643 - val_loss: 0.9719 - val_acc: 0.5425\n",
            "Epoch 50/50 - 0.06s - loss: 0.9154 - acc: 0.5702 - val_loss: 0.9657 - val_acc: 0.5607\n",
            "\n",
            "Combination 149/252:\n",
            "Hidden Layers: [128, 64, 32], Activation: relu, Learning Rate: 0.01, Batch Size: 64, Epochs: 100\n",
            "Epoch 1/100 - 0.07s - loss: 1.0930 - acc: 0.3734 - val_loss: 1.0924 - val_acc: 0.3765\n",
            "Epoch 2/100 - 0.06s - loss: 1.0893 - acc: 0.3835 - val_loss: 1.0892 - val_acc: 0.3968\n",
            "Epoch 3/100 - 0.07s - loss: 1.0858 - acc: 0.3952 - val_loss: 1.0864 - val_acc: 0.4008\n",
            "Epoch 4/100 - 0.08s - loss: 1.0820 - acc: 0.4031 - val_loss: 1.0839 - val_acc: 0.3947\n",
            "Epoch 5/100 - 0.06s - loss: 1.0782 - acc: 0.4145 - val_loss: 1.0808 - val_acc: 0.4211\n",
            "Epoch 6/100 - 0.08s - loss: 1.0756 - acc: 0.4238 - val_loss: 1.0788 - val_acc: 0.4251\n",
            "Epoch 7/100 - 0.07s - loss: 1.0705 - acc: 0.4363 - val_loss: 1.0747 - val_acc: 0.4352\n",
            "Epoch 8/100 - 0.07s - loss: 1.0670 - acc: 0.4435 - val_loss: 1.0718 - val_acc: 0.4514\n",
            "Epoch 9/100 - 0.07s - loss: 1.0637 - acc: 0.4523 - val_loss: 1.0691 - val_acc: 0.4636\n",
            "Epoch 10/100 - 0.07s - loss: 1.0599 - acc: 0.4525 - val_loss: 1.0667 - val_acc: 0.4494\n",
            "Epoch 11/100 - 0.08s - loss: 1.0570 - acc: 0.4501 - val_loss: 1.0647 - val_acc: 0.4615\n",
            "Epoch 12/100 - 0.06s - loss: 1.0532 - acc: 0.4579 - val_loss: 1.0619 - val_acc: 0.4636\n",
            "Epoch 13/100 - 0.06s - loss: 1.0482 - acc: 0.4685 - val_loss: 1.0580 - val_acc: 0.4696\n",
            "Epoch 14/100 - 0.07s - loss: 1.0449 - acc: 0.4694 - val_loss: 1.0551 - val_acc: 0.4636\n",
            "Epoch 15/100 - 0.07s - loss: 1.0398 - acc: 0.4780 - val_loss: 1.0523 - val_acc: 0.4696\n",
            "Epoch 16/100 - 0.07s - loss: 1.0355 - acc: 0.4768 - val_loss: 1.0488 - val_acc: 0.4696\n",
            "Epoch 17/100 - 0.07s - loss: 1.0314 - acc: 0.4840 - val_loss: 1.0475 - val_acc: 0.4737\n",
            "Epoch 18/100 - 0.08s - loss: 1.0267 - acc: 0.4852 - val_loss: 1.0433 - val_acc: 0.4899\n",
            "Epoch 19/100 - 0.07s - loss: 1.0213 - acc: 0.4928 - val_loss: 1.0395 - val_acc: 0.4858\n",
            "Epoch 20/100 - 0.06s - loss: 1.0173 - acc: 0.4964 - val_loss: 1.0373 - val_acc: 0.4879\n",
            "Epoch 21/100 - 0.07s - loss: 1.0191 - acc: 0.4816 - val_loss: 1.0371 - val_acc: 0.4939\n",
            "Epoch 22/100 - 0.07s - loss: 1.0073 - acc: 0.5011 - val_loss: 1.0278 - val_acc: 0.4960\n",
            "Epoch 23/100 - 0.06s - loss: 1.0028 - acc: 0.5038 - val_loss: 1.0261 - val_acc: 0.5040\n",
            "Epoch 24/100 - 0.07s - loss: 0.9975 - acc: 0.5056 - val_loss: 1.0210 - val_acc: 0.5101\n",
            "Epoch 25/100 - 0.07s - loss: 0.9929 - acc: 0.5119 - val_loss: 1.0172 - val_acc: 0.5182\n",
            "Epoch 26/100 - 0.07s - loss: 0.9891 - acc: 0.5101 - val_loss: 1.0137 - val_acc: 0.5061\n",
            "Epoch 27/100 - 0.07s - loss: 0.9853 - acc: 0.5175 - val_loss: 1.0102 - val_acc: 0.5061\n",
            "Epoch 28/100 - 0.06s - loss: 0.9836 - acc: 0.5144 - val_loss: 1.0107 - val_acc: 0.5040\n",
            "Epoch 29/100 - 0.06s - loss: 0.9832 - acc: 0.5196 - val_loss: 1.0067 - val_acc: 0.5263\n",
            "Epoch 30/100 - 0.07s - loss: 0.9732 - acc: 0.5261 - val_loss: 1.0009 - val_acc: 0.5243\n",
            "Epoch 31/100 - 0.07s - loss: 0.9682 - acc: 0.5306 - val_loss: 0.9950 - val_acc: 0.5344\n",
            "Epoch 32/100 - 0.07s - loss: 0.9668 - acc: 0.5328 - val_loss: 0.9958 - val_acc: 0.5223\n",
            "Epoch 33/100 - 0.07s - loss: 0.9608 - acc: 0.5324 - val_loss: 0.9883 - val_acc: 0.5344\n",
            "Epoch 34/100 - 0.07s - loss: 0.9622 - acc: 0.5364 - val_loss: 0.9882 - val_acc: 0.5486\n",
            "Epoch 35/100 - 0.06s - loss: 0.9581 - acc: 0.5389 - val_loss: 0.9842 - val_acc: 0.5506\n",
            "Epoch 36/100 - 0.07s - loss: 0.9538 - acc: 0.5427 - val_loss: 0.9838 - val_acc: 0.5344\n",
            "Epoch 37/100 - 0.06s - loss: 0.9763 - acc: 0.5184 - val_loss: 1.0086 - val_acc: 0.4960\n",
            "Epoch 38/100 - 0.07s - loss: 0.9612 - acc: 0.5360 - val_loss: 0.9853 - val_acc: 0.5405\n",
            "Epoch 39/100 - 0.07s - loss: 0.9437 - acc: 0.5463 - val_loss: 0.9761 - val_acc: 0.5344\n",
            "Epoch 40/100 - 0.08s - loss: 0.9386 - acc: 0.5479 - val_loss: 0.9687 - val_acc: 0.5526\n",
            "Epoch 41/100 - 0.07s - loss: 0.9361 - acc: 0.5538 - val_loss: 0.9680 - val_acc: 0.5486\n",
            "Epoch 42/100 - 0.07s - loss: 0.9418 - acc: 0.5531 - val_loss: 0.9687 - val_acc: 0.5688\n",
            "Epoch 43/100 - 0.06s - loss: 0.9318 - acc: 0.5560 - val_loss: 0.9650 - val_acc: 0.5526\n",
            "Epoch 44/100 - 0.06s - loss: 0.9299 - acc: 0.5580 - val_loss: 0.9654 - val_acc: 0.5445\n",
            "Epoch 45/100 - 0.08s - loss: 0.9332 - acc: 0.5526 - val_loss: 0.9709 - val_acc: 0.5405\n",
            "Epoch 46/100 - 0.07s - loss: 0.9226 - acc: 0.5623 - val_loss: 0.9550 - val_acc: 0.5709\n",
            "Epoch 47/100 - 0.07s - loss: 0.9253 - acc: 0.5630 - val_loss: 0.9578 - val_acc: 0.5587\n",
            "Epoch 48/100 - 0.07s - loss: 0.9178 - acc: 0.5686 - val_loss: 0.9510 - val_acc: 0.5810\n",
            "Epoch 49/100 - 0.07s - loss: 0.9173 - acc: 0.5675 - val_loss: 0.9565 - val_acc: 0.5506\n",
            "Epoch 50/100 - 0.07s - loss: 0.9116 - acc: 0.5664 - val_loss: 0.9482 - val_acc: 0.5749\n",
            "Epoch 51/100 - 0.07s - loss: 0.9140 - acc: 0.5652 - val_loss: 0.9482 - val_acc: 0.5688\n",
            "Epoch 52/100 - 0.07s - loss: 0.9186 - acc: 0.5646 - val_loss: 0.9525 - val_acc: 0.5628\n",
            "Epoch 53/100 - 0.07s - loss: 0.9057 - acc: 0.5747 - val_loss: 0.9430 - val_acc: 0.5769\n",
            "Epoch 54/100 - 0.07s - loss: 0.9054 - acc: 0.5765 - val_loss: 0.9451 - val_acc: 0.5709\n",
            "Epoch 55/100 - 0.06s - loss: 0.9019 - acc: 0.5742 - val_loss: 0.9487 - val_acc: 0.5567\n",
            "Epoch 56/100 - 0.07s - loss: 0.9013 - acc: 0.5792 - val_loss: 0.9431 - val_acc: 0.5688\n",
            "Epoch 57/100 - 0.07s - loss: 0.9076 - acc: 0.5774 - val_loss: 0.9471 - val_acc: 0.5688\n",
            "Epoch 58/100 - 0.06s - loss: 0.9010 - acc: 0.5684 - val_loss: 0.9414 - val_acc: 0.5628\n",
            "Epoch 59/100 - 0.07s - loss: 0.8894 - acc: 0.5850 - val_loss: 0.9364 - val_acc: 0.5668\n",
            "Epoch 60/100 - 0.07s - loss: 0.9097 - acc: 0.5771 - val_loss: 0.9531 - val_acc: 0.5688\n",
            "Epoch 61/100 - 0.07s - loss: 0.9410 - acc: 0.5443 - val_loss: 1.0030 - val_acc: 0.5263\n",
            "Epoch 62/100 - 0.06s - loss: 0.8842 - acc: 0.5882 - val_loss: 0.9350 - val_acc: 0.5688\n",
            "Epoch 63/100 - 0.06s - loss: 0.8886 - acc: 0.5850 - val_loss: 0.9453 - val_acc: 0.5567\n",
            "Epoch 64/100 - 0.07s - loss: 0.8894 - acc: 0.5828 - val_loss: 0.9487 - val_acc: 0.5567\n",
            "Epoch 65/100 - 0.07s - loss: 0.8782 - acc: 0.5870 - val_loss: 0.9307 - val_acc: 0.5688\n",
            "Epoch 66/100 - 0.06s - loss: 0.8754 - acc: 0.5920 - val_loss: 0.9285 - val_acc: 0.5668\n",
            "Epoch 67/100 - 0.07s - loss: 0.8758 - acc: 0.5963 - val_loss: 0.9306 - val_acc: 0.5668\n",
            "Epoch 68/100 - 0.07s - loss: 0.9008 - acc: 0.5816 - val_loss: 0.9514 - val_acc: 0.5769\n",
            "Epoch 69/100 - 0.07s - loss: 0.9030 - acc: 0.5697 - val_loss: 0.9715 - val_acc: 0.5202\n",
            "Epoch 70/100 - 0.07s - loss: 0.8693 - acc: 0.6003 - val_loss: 0.9362 - val_acc: 0.5688\n",
            "Epoch 71/100 - 0.07s - loss: 0.8638 - acc: 0.6028 - val_loss: 0.9308 - val_acc: 0.5587\n",
            "Epoch 72/100 - 0.07s - loss: 0.8617 - acc: 0.6010 - val_loss: 0.9317 - val_acc: 0.5648\n",
            "Epoch 73/100 - 0.07s - loss: 0.8727 - acc: 0.5947 - val_loss: 0.9464 - val_acc: 0.5466\n",
            "Epoch 74/100 - 0.07s - loss: 0.8977 - acc: 0.5760 - val_loss: 0.9558 - val_acc: 0.5749\n",
            "Epoch 75/100 - 0.07s - loss: 0.8868 - acc: 0.5951 - val_loss: 0.9469 - val_acc: 0.5749\n",
            "Epoch 76/100 - 0.07s - loss: 0.8527 - acc: 0.6068 - val_loss: 0.9232 - val_acc: 0.5830\n",
            "Epoch 77/100 - 0.07s - loss: 0.9240 - acc: 0.5740 - val_loss: 0.9803 - val_acc: 0.5648\n",
            "Epoch 78/100 - 0.07s - loss: 0.8758 - acc: 0.5987 - val_loss: 0.9432 - val_acc: 0.5769\n",
            "Epoch 79/100 - 0.07s - loss: 1.1120 - acc: 0.4694 - val_loss: 1.2137 - val_acc: 0.4332\n",
            "Epoch 80/100 - 0.07s - loss: 0.8438 - acc: 0.6066 - val_loss: 0.9210 - val_acc: 0.5749\n",
            "Epoch 81/100 - 0.07s - loss: 0.8871 - acc: 0.5765 - val_loss: 0.9792 - val_acc: 0.5304\n",
            "Epoch 82/100 - 0.07s - loss: 0.8480 - acc: 0.6053 - val_loss: 0.9300 - val_acc: 0.5607\n",
            "Epoch 83/100 - 0.07s - loss: 0.8446 - acc: 0.6201 - val_loss: 0.9243 - val_acc: 0.5648\n",
            "Epoch 84/100 - 0.06s - loss: 0.8995 - acc: 0.5688 - val_loss: 0.9989 - val_acc: 0.5223\n",
            "Epoch 85/100 - 0.06s - loss: 0.8337 - acc: 0.6185 - val_loss: 0.9278 - val_acc: 0.5587\n",
            "Epoch 86/100 - 0.07s - loss: 0.8420 - acc: 0.6107 - val_loss: 0.9393 - val_acc: 0.5607\n",
            "Epoch 87/100 - 0.07s - loss: 0.8381 - acc: 0.6073 - val_loss: 0.9246 - val_acc: 0.5587\n",
            "Epoch 88/100 - 0.06s - loss: 0.8804 - acc: 0.5936 - val_loss: 0.9584 - val_acc: 0.5810\n",
            "Epoch 89/100 - 0.07s - loss: 0.8271 - acc: 0.6298 - val_loss: 0.9195 - val_acc: 0.5891\n",
            "Epoch 90/100 - 0.06s - loss: 0.8739 - acc: 0.5834 - val_loss: 0.9818 - val_acc: 0.5486\n",
            "Epoch 91/100 - 0.07s - loss: 0.8911 - acc: 0.5774 - val_loss: 0.9998 - val_acc: 0.5466\n",
            "Epoch 92/100 - 0.06s - loss: 0.8400 - acc: 0.6163 - val_loss: 0.9527 - val_acc: 0.5587\n",
            "Epoch 93/100 - 0.07s - loss: 0.9300 - acc: 0.5576 - val_loss: 1.0530 - val_acc: 0.5182\n",
            "Epoch 94/100 - 0.06s - loss: 0.8336 - acc: 0.6273 - val_loss: 0.9331 - val_acc: 0.5911\n",
            "Epoch 95/100 - 0.08s - loss: 0.8191 - acc: 0.6233 - val_loss: 0.9205 - val_acc: 0.5749\n",
            "Epoch 96/100 - 0.07s - loss: 0.9092 - acc: 0.5648 - val_loss: 1.0419 - val_acc: 0.4980\n",
            "Epoch 97/100 - 0.07s - loss: 0.8077 - acc: 0.6439 - val_loss: 0.9180 - val_acc: 0.5891\n",
            "Epoch 98/100 - 0.07s - loss: 0.8038 - acc: 0.6359 - val_loss: 0.9189 - val_acc: 0.5810\n",
            "Epoch 99/100 - 0.07s - loss: 0.8030 - acc: 0.6426 - val_loss: 0.9129 - val_acc: 0.5891\n",
            "Epoch 100/100 - 0.06s - loss: 0.8173 - acc: 0.6390 - val_loss: 0.9296 - val_acc: 0.5870\n",
            "Model saved to models/best_model.npy\n",
            "New best model found! Validation accuracy: 0.5870\n",
            "\n",
            "Combination 150/252:\n",
            "Hidden Layers: [128, 64, 32], Activation: relu, Learning Rate: 0.01, Batch Size: 64, Epochs: 150\n",
            "Epoch 1/150 - 0.06s - loss: 1.0957 - acc: 0.3740 - val_loss: 1.0970 - val_acc: 0.3421\n",
            "Epoch 2/150 - 0.07s - loss: 1.0901 - acc: 0.4062 - val_loss: 1.0933 - val_acc: 0.3684\n",
            "Epoch 3/150 - 0.06s - loss: 1.0856 - acc: 0.4161 - val_loss: 1.0904 - val_acc: 0.3725\n",
            "Epoch 4/150 - 0.07s - loss: 1.0816 - acc: 0.4249 - val_loss: 1.0878 - val_acc: 0.3927\n",
            "Epoch 5/150 - 0.08s - loss: 1.0780 - acc: 0.4361 - val_loss: 1.0856 - val_acc: 0.3988\n",
            "Epoch 6/150 - 0.07s - loss: 1.0745 - acc: 0.4357 - val_loss: 1.0833 - val_acc: 0.3968\n",
            "Epoch 7/150 - 0.07s - loss: 1.0710 - acc: 0.4525 - val_loss: 1.0804 - val_acc: 0.4109\n",
            "Epoch 8/150 - 0.07s - loss: 1.0672 - acc: 0.4561 - val_loss: 1.0779 - val_acc: 0.4170\n",
            "Epoch 9/150 - 0.08s - loss: 1.0633 - acc: 0.4588 - val_loss: 1.0754 - val_acc: 0.4211\n",
            "Epoch 10/150 - 0.06s - loss: 1.0595 - acc: 0.4640 - val_loss: 1.0727 - val_acc: 0.4332\n",
            "Epoch 11/150 - 0.07s - loss: 1.0559 - acc: 0.4591 - val_loss: 1.0714 - val_acc: 0.4312\n",
            "Epoch 12/150 - 0.06s - loss: 1.0512 - acc: 0.4714 - val_loss: 1.0671 - val_acc: 0.4514\n",
            "Epoch 13/150 - 0.07s - loss: 1.0484 - acc: 0.4804 - val_loss: 1.0647 - val_acc: 0.4494\n",
            "Epoch 14/150 - 0.06s - loss: 1.0424 - acc: 0.4818 - val_loss: 1.0616 - val_acc: 0.4474\n",
            "Epoch 15/150 - 0.07s - loss: 1.0382 - acc: 0.4845 - val_loss: 1.0594 - val_acc: 0.4534\n",
            "Epoch 16/150 - 0.07s - loss: 1.0344 - acc: 0.4843 - val_loss: 1.0579 - val_acc: 0.4696\n",
            "Epoch 17/150 - 0.07s - loss: 1.0303 - acc: 0.4843 - val_loss: 1.0561 - val_acc: 0.4534\n",
            "Epoch 18/150 - 0.06s - loss: 1.0271 - acc: 0.4811 - val_loss: 1.0530 - val_acc: 0.4636\n",
            "Epoch 19/150 - 0.07s - loss: 1.0209 - acc: 0.4942 - val_loss: 1.0494 - val_acc: 0.4676\n",
            "Epoch 20/150 - 0.06s - loss: 1.0167 - acc: 0.4953 - val_loss: 1.0476 - val_acc: 0.4838\n",
            "Epoch 21/150 - 0.07s - loss: 1.0127 - acc: 0.4996 - val_loss: 1.0437 - val_acc: 0.4960\n",
            "Epoch 22/150 - 0.07s - loss: 1.0083 - acc: 0.5047 - val_loss: 1.0421 - val_acc: 0.4939\n",
            "Epoch 23/150 - 0.07s - loss: 1.0055 - acc: 0.5031 - val_loss: 1.0414 - val_acc: 0.4919\n",
            "Epoch 24/150 - 0.07s - loss: 1.0036 - acc: 0.5025 - val_loss: 1.0407 - val_acc: 0.4717\n",
            "Epoch 25/150 - 0.07s - loss: 1.0002 - acc: 0.5067 - val_loss: 1.0401 - val_acc: 0.4879\n",
            "Epoch 26/150 - 0.07s - loss: 0.9945 - acc: 0.5081 - val_loss: 1.0339 - val_acc: 0.4879\n",
            "Epoch 27/150 - 0.07s - loss: 0.9896 - acc: 0.5112 - val_loss: 1.0278 - val_acc: 0.5142\n",
            "Epoch 28/150 - 0.07s - loss: 0.9908 - acc: 0.5067 - val_loss: 1.0316 - val_acc: 0.4696\n",
            "Epoch 29/150 - 0.07s - loss: 0.9806 - acc: 0.5182 - val_loss: 1.0222 - val_acc: 0.5243\n",
            "Epoch 30/150 - 0.06s - loss: 0.9817 - acc: 0.5315 - val_loss: 1.0253 - val_acc: 0.5243\n",
            "Epoch 31/150 - 0.07s - loss: 0.9730 - acc: 0.5265 - val_loss: 1.0158 - val_acc: 0.5223\n",
            "Epoch 32/150 - 0.06s - loss: 0.9705 - acc: 0.5308 - val_loss: 1.0135 - val_acc: 0.5344\n",
            "Epoch 33/150 - 0.08s - loss: 0.9750 - acc: 0.5225 - val_loss: 1.0205 - val_acc: 0.4717\n",
            "Epoch 34/150 - 0.07s - loss: 0.9636 - acc: 0.5367 - val_loss: 1.0094 - val_acc: 0.5344\n",
            "Epoch 35/150 - 0.07s - loss: 0.9591 - acc: 0.5421 - val_loss: 1.0049 - val_acc: 0.5385\n",
            "Epoch 36/150 - 0.08s - loss: 0.9605 - acc: 0.5430 - val_loss: 1.0062 - val_acc: 0.5425\n",
            "Epoch 37/150 - 0.07s - loss: 0.9755 - acc: 0.5130 - val_loss: 1.0243 - val_acc: 0.4372\n",
            "Epoch 38/150 - 0.07s - loss: 0.9505 - acc: 0.5396 - val_loss: 1.0001 - val_acc: 0.5304\n",
            "Epoch 39/150 - 0.07s - loss: 0.9494 - acc: 0.5378 - val_loss: 0.9992 - val_acc: 0.5182\n",
            "Epoch 40/150 - 0.08s - loss: 0.9536 - acc: 0.5439 - val_loss: 1.0016 - val_acc: 0.5344\n",
            "Epoch 41/150 - 0.08s - loss: 0.9444 - acc: 0.5457 - val_loss: 0.9987 - val_acc: 0.5223\n",
            "Epoch 42/150 - 0.07s - loss: 0.9375 - acc: 0.5493 - val_loss: 0.9907 - val_acc: 0.5364\n",
            "Epoch 43/150 - 0.08s - loss: 0.9357 - acc: 0.5553 - val_loss: 0.9880 - val_acc: 0.5445\n",
            "Epoch 44/150 - 0.06s - loss: 0.9377 - acc: 0.5562 - val_loss: 0.9928 - val_acc: 0.5466\n",
            "Epoch 45/150 - 0.07s - loss: 0.9334 - acc: 0.5481 - val_loss: 0.9879 - val_acc: 0.5162\n",
            "Epoch 46/150 - 0.07s - loss: 0.9307 - acc: 0.5506 - val_loss: 0.9835 - val_acc: 0.5466\n",
            "Epoch 47/150 - 0.07s - loss: 0.9255 - acc: 0.5632 - val_loss: 0.9851 - val_acc: 0.5344\n",
            "Epoch 48/150 - 0.07s - loss: 0.9288 - acc: 0.5632 - val_loss: 0.9846 - val_acc: 0.5425\n",
            "Epoch 49/150 - 0.07s - loss: 0.9214 - acc: 0.5535 - val_loss: 0.9804 - val_acc: 0.5304\n",
            "Epoch 50/150 - 0.07s - loss: 0.9331 - acc: 0.5625 - val_loss: 0.9901 - val_acc: 0.5526\n",
            "Epoch 51/150 - 0.07s - loss: 0.9337 - acc: 0.5511 - val_loss: 0.9988 - val_acc: 0.5020\n",
            "Epoch 52/150 - 0.07s - loss: 0.9245 - acc: 0.5630 - val_loss: 0.9820 - val_acc: 0.5425\n",
            "Epoch 53/150 - 0.07s - loss: 0.9177 - acc: 0.5634 - val_loss: 0.9766 - val_acc: 0.5466\n",
            "Epoch 54/150 - 0.06s - loss: 0.9074 - acc: 0.5706 - val_loss: 0.9727 - val_acc: 0.5445\n",
            "Epoch 55/150 - 0.07s - loss: 0.9071 - acc: 0.5673 - val_loss: 0.9751 - val_acc: 0.5263\n",
            "Epoch 56/150 - 0.07s - loss: 0.9038 - acc: 0.5776 - val_loss: 0.9706 - val_acc: 0.5466\n",
            "Epoch 57/150 - 0.07s - loss: 0.9032 - acc: 0.5747 - val_loss: 0.9742 - val_acc: 0.5466\n",
            "Epoch 58/150 - 0.07s - loss: 0.9102 - acc: 0.5762 - val_loss: 0.9731 - val_acc: 0.5486\n",
            "Epoch 59/150 - 0.07s - loss: 0.8965 - acc: 0.5812 - val_loss: 0.9672 - val_acc: 0.5486\n",
            "Epoch 60/150 - 0.07s - loss: 0.8994 - acc: 0.5758 - val_loss: 0.9680 - val_acc: 0.5466\n",
            "Epoch 61/150 - 0.06s - loss: 0.8962 - acc: 0.5801 - val_loss: 0.9676 - val_acc: 0.5567\n",
            "Epoch 62/150 - 0.07s - loss: 0.8889 - acc: 0.5821 - val_loss: 0.9659 - val_acc: 0.5445\n",
            "Epoch 63/150 - 0.07s - loss: 0.8924 - acc: 0.5810 - val_loss: 0.9645 - val_acc: 0.5486\n",
            "Epoch 64/150 - 0.07s - loss: 0.8888 - acc: 0.5902 - val_loss: 0.9649 - val_acc: 0.5567\n",
            "Epoch 65/150 - 0.07s - loss: 0.8952 - acc: 0.5864 - val_loss: 0.9704 - val_acc: 0.5526\n",
            "Epoch 66/150 - 0.07s - loss: 0.8996 - acc: 0.5729 - val_loss: 0.9713 - val_acc: 0.5304\n",
            "Epoch 67/150 - 0.08s - loss: 0.8803 - acc: 0.5882 - val_loss: 0.9585 - val_acc: 0.5486\n",
            "Epoch 68/150 - 0.07s - loss: 0.8992 - acc: 0.5765 - val_loss: 0.9919 - val_acc: 0.5162\n",
            "Epoch 69/150 - 0.07s - loss: 0.9318 - acc: 0.5490 - val_loss: 1.0282 - val_acc: 0.4858\n",
            "Epoch 70/150 - 0.07s - loss: 0.9224 - acc: 0.5603 - val_loss: 1.0212 - val_acc: 0.5020\n",
            "Epoch 71/150 - 0.09s - loss: 0.8733 - acc: 0.5933 - val_loss: 0.9546 - val_acc: 0.5688\n",
            "Epoch 72/150 - 0.07s - loss: 0.8672 - acc: 0.5965 - val_loss: 0.9570 - val_acc: 0.5648\n",
            "Epoch 73/150 - 0.07s - loss: 0.9294 - acc: 0.5486 - val_loss: 1.0323 - val_acc: 0.4717\n",
            "Epoch 74/150 - 0.07s - loss: 0.8884 - acc: 0.5911 - val_loss: 0.9731 - val_acc: 0.5526\n",
            "Epoch 75/150 - 0.07s - loss: 0.8619 - acc: 0.6037 - val_loss: 0.9597 - val_acc: 0.5506\n",
            "Epoch 76/150 - 0.07s - loss: 0.8573 - acc: 0.6041 - val_loss: 0.9544 - val_acc: 0.5648\n",
            "Epoch 77/150 - 0.07s - loss: 0.8805 - acc: 0.5922 - val_loss: 0.9882 - val_acc: 0.5162\n",
            "Epoch 78/150 - 0.06s - loss: 0.8673 - acc: 0.5996 - val_loss: 0.9720 - val_acc: 0.5385\n",
            "Epoch 79/150 - 0.07s - loss: 0.8527 - acc: 0.6118 - val_loss: 0.9524 - val_acc: 0.5668\n",
            "Epoch 80/150 - 0.07s - loss: 0.8492 - acc: 0.6113 - val_loss: 0.9531 - val_acc: 0.5587\n",
            "Epoch 81/150 - 0.08s - loss: 0.8763 - acc: 0.5897 - val_loss: 0.9942 - val_acc: 0.5283\n",
            "Epoch 82/150 - 0.07s - loss: 0.8523 - acc: 0.6107 - val_loss: 0.9619 - val_acc: 0.5526\n",
            "Epoch 83/150 - 0.07s - loss: 0.9283 - acc: 0.5493 - val_loss: 1.0487 - val_acc: 0.4818\n",
            "Epoch 84/150 - 0.07s - loss: 0.8525 - acc: 0.6077 - val_loss: 0.9722 - val_acc: 0.5324\n",
            "Epoch 85/150 - 0.07s - loss: 0.9598 - acc: 0.5263 - val_loss: 1.0873 - val_acc: 0.4453\n",
            "Epoch 86/150 - 0.07s - loss: 0.8916 - acc: 0.5724 - val_loss: 1.0177 - val_acc: 0.4858\n",
            "Epoch 87/150 - 0.06s - loss: 0.8413 - acc: 0.6143 - val_loss: 0.9660 - val_acc: 0.5425\n",
            "Epoch 88/150 - 0.07s - loss: 0.8477 - acc: 0.6158 - val_loss: 0.9589 - val_acc: 0.5648\n",
            "Epoch 89/150 - 0.08s - loss: 0.8430 - acc: 0.6109 - val_loss: 0.9590 - val_acc: 0.5405\n",
            "Epoch 90/150 - 0.07s - loss: 0.8392 - acc: 0.6188 - val_loss: 0.9698 - val_acc: 0.5445\n",
            "Epoch 91/150 - 0.06s - loss: 0.8676 - acc: 0.5906 - val_loss: 1.0048 - val_acc: 0.4960\n",
            "Epoch 92/150 - 0.07s - loss: 0.8465 - acc: 0.6158 - val_loss: 0.9616 - val_acc: 0.5607\n",
            "Epoch 93/150 - 0.07s - loss: 0.8398 - acc: 0.6158 - val_loss: 0.9665 - val_acc: 0.5283\n",
            "Epoch 94/150 - 0.06s - loss: 0.8273 - acc: 0.6278 - val_loss: 0.9574 - val_acc: 0.5445\n",
            "Epoch 95/150 - 0.06s - loss: 0.8265 - acc: 0.6275 - val_loss: 0.9547 - val_acc: 0.5607\n",
            "Epoch 96/150 - 0.07s - loss: 0.9053 - acc: 0.5801 - val_loss: 1.0120 - val_acc: 0.5385\n",
            "Epoch 97/150 - 0.06s - loss: 0.8243 - acc: 0.6314 - val_loss: 0.9703 - val_acc: 0.5324\n",
            "Epoch 98/150 - 0.07s - loss: 0.8157 - acc: 0.6287 - val_loss: 0.9490 - val_acc: 0.5607\n",
            "Epoch 99/150 - 0.07s - loss: 0.8124 - acc: 0.6356 - val_loss: 0.9548 - val_acc: 0.5709\n",
            "Epoch 100/150 - 0.07s - loss: 0.8057 - acc: 0.6444 - val_loss: 0.9501 - val_acc: 0.5769\n",
            "Epoch 101/150 - 0.07s - loss: 0.8037 - acc: 0.6460 - val_loss: 0.9501 - val_acc: 0.5587\n",
            "Epoch 102/150 - 0.07s - loss: 0.8942 - acc: 0.5740 - val_loss: 1.0666 - val_acc: 0.4676\n",
            "Epoch 103/150 - 0.07s - loss: 0.9174 - acc: 0.5529 - val_loss: 1.0858 - val_acc: 0.4858\n",
            "Epoch 104/150 - 0.08s - loss: 0.8541 - acc: 0.5981 - val_loss: 1.0241 - val_acc: 0.5101\n",
            "Epoch 105/150 - 0.08s - loss: 0.7963 - acc: 0.6484 - val_loss: 0.9505 - val_acc: 0.5648\n",
            "Epoch 106/150 - 0.07s - loss: 0.8572 - acc: 0.5947 - val_loss: 1.0209 - val_acc: 0.4939\n",
            "Epoch 107/150 - 0.07s - loss: 0.8832 - acc: 0.5780 - val_loss: 1.0185 - val_acc: 0.5223\n",
            "Epoch 108/150 - 0.07s - loss: 0.7943 - acc: 0.6496 - val_loss: 0.9665 - val_acc: 0.5364\n",
            "Epoch 109/150 - 0.08s - loss: 0.8112 - acc: 0.6320 - val_loss: 0.9889 - val_acc: 0.5202\n",
            "Epoch 110/150 - 0.07s - loss: 0.9723 - acc: 0.5324 - val_loss: 1.1596 - val_acc: 0.4615\n",
            "Epoch 111/150 - 0.07s - loss: 0.8110 - acc: 0.6251 - val_loss: 0.9857 - val_acc: 0.5364\n",
            "Epoch 112/150 - 0.07s - loss: 0.8017 - acc: 0.6363 - val_loss: 0.9915 - val_acc: 0.5223\n",
            "Epoch 113/150 - 0.07s - loss: 0.7986 - acc: 0.6383 - val_loss: 0.9880 - val_acc: 0.5283\n",
            "Epoch 114/150 - 0.07s - loss: 0.8544 - acc: 0.6012 - val_loss: 1.0457 - val_acc: 0.5101\n",
            "Epoch 115/150 - 0.07s - loss: 0.7950 - acc: 0.6415 - val_loss: 0.9895 - val_acc: 0.5283\n",
            "Epoch 116/150 - 0.07s - loss: 0.7945 - acc: 0.6397 - val_loss: 0.9947 - val_acc: 0.5243\n",
            "Epoch 117/150 - 0.08s - loss: 0.7705 - acc: 0.6662 - val_loss: 0.9651 - val_acc: 0.5506\n",
            "Epoch 118/150 - 0.07s - loss: 0.8025 - acc: 0.6428 - val_loss: 0.9724 - val_acc: 0.5526\n",
            "Epoch 119/150 - 0.07s - loss: 0.7714 - acc: 0.6597 - val_loss: 0.9566 - val_acc: 0.5668\n",
            "Epoch 120/150 - 0.07s - loss: 0.7701 - acc: 0.6613 - val_loss: 0.9530 - val_acc: 0.5567\n",
            "Epoch 121/150 - 0.07s - loss: 0.7807 - acc: 0.6527 - val_loss: 0.9756 - val_acc: 0.5547\n",
            "Epoch 122/150 - 0.07s - loss: 0.7799 - acc: 0.6511 - val_loss: 0.9689 - val_acc: 0.5445\n",
            "Epoch 123/150 - 0.08s - loss: 0.7679 - acc: 0.6624 - val_loss: 0.9803 - val_acc: 0.5385\n",
            "Epoch 124/150 - 0.08s - loss: 0.7621 - acc: 0.6685 - val_loss: 0.9733 - val_acc: 0.5304\n",
            "Epoch 125/150 - 0.07s - loss: 0.7680 - acc: 0.6617 - val_loss: 0.9759 - val_acc: 0.5385\n",
            "Epoch 126/150 - 0.07s - loss: 0.8485 - acc: 0.5949 - val_loss: 1.0854 - val_acc: 0.4777\n",
            "Epoch 127/150 - 0.07s - loss: 0.7534 - acc: 0.6759 - val_loss: 0.9680 - val_acc: 0.5567\n",
            "Epoch 128/150 - 0.07s - loss: 0.7684 - acc: 0.6586 - val_loss: 0.9957 - val_acc: 0.5101\n",
            "Epoch 129/150 - 0.07s - loss: 0.7419 - acc: 0.6815 - val_loss: 0.9583 - val_acc: 0.5648\n",
            "Epoch 130/150 - 0.09s - loss: 0.7378 - acc: 0.6885 - val_loss: 0.9633 - val_acc: 0.5587\n",
            "Epoch 131/150 - 0.07s - loss: 0.7671 - acc: 0.6622 - val_loss: 0.9788 - val_acc: 0.5688\n",
            "Epoch 132/150 - 0.07s - loss: 0.7425 - acc: 0.6811 - val_loss: 0.9611 - val_acc: 0.5607\n",
            "Epoch 133/150 - 0.11s - loss: 0.8002 - acc: 0.6242 - val_loss: 1.0305 - val_acc: 0.5223\n",
            "Epoch 134/150 - 0.07s - loss: 0.7684 - acc: 0.6635 - val_loss: 0.9842 - val_acc: 0.5587\n",
            "Epoch 135/150 - 0.08s - loss: 0.7408 - acc: 0.6842 - val_loss: 0.9823 - val_acc: 0.5486\n",
            "Epoch 136/150 - 0.07s - loss: 0.7884 - acc: 0.6428 - val_loss: 0.9965 - val_acc: 0.5506\n",
            "Epoch 137/150 - 0.07s - loss: 0.7564 - acc: 0.6658 - val_loss: 1.0156 - val_acc: 0.5142\n",
            "Epoch 138/150 - 0.07s - loss: 0.7884 - acc: 0.6534 - val_loss: 1.0135 - val_acc: 0.5486\n",
            "Epoch 139/150 - 0.07s - loss: 0.7283 - acc: 0.6898 - val_loss: 0.9681 - val_acc: 0.5688\n",
            "Epoch 140/150 - 0.07s - loss: 0.7476 - acc: 0.6718 - val_loss: 0.9916 - val_acc: 0.5547\n",
            "Epoch 141/150 - 0.07s - loss: 0.7268 - acc: 0.6907 - val_loss: 0.9623 - val_acc: 0.5607\n",
            "Epoch 142/150 - 0.08s - loss: 0.7118 - acc: 0.6993 - val_loss: 0.9593 - val_acc: 0.5709\n",
            "Epoch 143/150 - 0.07s - loss: 0.7866 - acc: 0.6532 - val_loss: 1.0212 - val_acc: 0.5607\n",
            "Epoch 144/150 - 0.07s - loss: 0.7347 - acc: 0.6786 - val_loss: 0.9969 - val_acc: 0.5364\n",
            "Epoch 145/150 - 0.07s - loss: 0.7445 - acc: 0.6680 - val_loss: 1.0215 - val_acc: 0.5101\n",
            "Epoch 146/150 - 0.08s - loss: 0.7122 - acc: 0.6970 - val_loss: 0.9734 - val_acc: 0.5648\n",
            "Epoch 147/150 - 0.07s - loss: 0.7283 - acc: 0.6815 - val_loss: 1.0151 - val_acc: 0.5101\n",
            "Epoch 148/150 - 0.07s - loss: 0.9454 - acc: 0.5369 - val_loss: 1.2374 - val_acc: 0.4433\n",
            "Epoch 149/150 - 0.07s - loss: 0.6922 - acc: 0.7087 - val_loss: 0.9754 - val_acc: 0.5567\n",
            "Epoch 150/150 - 0.07s - loss: 0.6932 - acc: 0.7112 - val_loss: 0.9731 - val_acc: 0.5628\n",
            "\n",
            "Combination 151/252:\n",
            "Hidden Layers: [128, 64, 32], Activation: relu, Learning Rate: 0.001, Batch Size: 32, Epochs: 50\n",
            "Epoch 1/50 - 0.08s - loss: 1.1112 - acc: 0.3048 - val_loss: 1.1149 - val_acc: 0.3036\n",
            "Epoch 2/50 - 0.08s - loss: 1.1039 - acc: 0.3077 - val_loss: 1.1091 - val_acc: 0.3158\n",
            "Epoch 3/50 - 0.08s - loss: 1.1014 - acc: 0.3174 - val_loss: 1.1072 - val_acc: 0.3016\n",
            "Epoch 4/50 - 0.08s - loss: 1.0997 - acc: 0.3248 - val_loss: 1.1060 - val_acc: 0.3057\n",
            "Epoch 5/50 - 0.08s - loss: 1.0984 - acc: 0.3331 - val_loss: 1.1049 - val_acc: 0.3178\n",
            "Epoch 6/50 - 0.08s - loss: 1.0972 - acc: 0.3408 - val_loss: 1.1039 - val_acc: 0.3198\n",
            "Epoch 7/50 - 0.09s - loss: 1.0961 - acc: 0.3489 - val_loss: 1.1029 - val_acc: 0.3401\n",
            "Epoch 8/50 - 0.08s - loss: 1.0950 - acc: 0.3574 - val_loss: 1.1020 - val_acc: 0.3360\n",
            "Epoch 9/50 - 0.09s - loss: 1.0939 - acc: 0.3664 - val_loss: 1.1011 - val_acc: 0.3381\n",
            "Epoch 10/50 - 0.08s - loss: 1.0929 - acc: 0.3734 - val_loss: 1.1002 - val_acc: 0.3482\n",
            "Epoch 11/50 - 0.08s - loss: 1.0919 - acc: 0.3803 - val_loss: 1.0995 - val_acc: 0.3441\n",
            "Epoch 12/50 - 0.08s - loss: 1.0909 - acc: 0.3887 - val_loss: 1.0987 - val_acc: 0.3482\n",
            "Epoch 13/50 - 0.10s - loss: 1.0900 - acc: 0.3914 - val_loss: 1.0979 - val_acc: 0.3482\n",
            "Epoch 14/50 - 0.08s - loss: 1.0891 - acc: 0.3923 - val_loss: 1.0971 - val_acc: 0.3563\n",
            "Epoch 15/50 - 0.09s - loss: 1.0882 - acc: 0.3929 - val_loss: 1.0965 - val_acc: 0.3684\n",
            "Epoch 16/50 - 0.08s - loss: 1.0873 - acc: 0.3943 - val_loss: 1.0957 - val_acc: 0.3644\n",
            "Epoch 17/50 - 0.08s - loss: 1.0864 - acc: 0.3970 - val_loss: 1.0950 - val_acc: 0.3704\n",
            "Epoch 18/50 - 0.09s - loss: 1.0856 - acc: 0.3986 - val_loss: 1.0943 - val_acc: 0.3704\n",
            "Epoch 19/50 - 0.08s - loss: 1.0848 - acc: 0.4042 - val_loss: 1.0936 - val_acc: 0.3684\n",
            "Epoch 20/50 - 0.08s - loss: 1.0840 - acc: 0.4040 - val_loss: 1.0930 - val_acc: 0.3725\n",
            "Epoch 21/50 - 0.08s - loss: 1.0832 - acc: 0.4078 - val_loss: 1.0923 - val_acc: 0.3704\n",
            "Epoch 22/50 - 0.08s - loss: 1.0824 - acc: 0.4103 - val_loss: 1.0916 - val_acc: 0.3684\n",
            "Epoch 23/50 - 0.08s - loss: 1.0817 - acc: 0.4134 - val_loss: 1.0911 - val_acc: 0.3785\n",
            "Epoch 24/50 - 0.09s - loss: 1.0809 - acc: 0.4148 - val_loss: 1.0905 - val_acc: 0.3826\n",
            "Epoch 25/50 - 0.09s - loss: 1.0802 - acc: 0.4148 - val_loss: 1.0899 - val_acc: 0.3826\n",
            "Epoch 26/50 - 0.08s - loss: 1.0795 - acc: 0.4159 - val_loss: 1.0893 - val_acc: 0.3887\n",
            "Epoch 27/50 - 0.08s - loss: 1.0788 - acc: 0.4170 - val_loss: 1.0888 - val_acc: 0.3947\n",
            "Epoch 28/50 - 0.08s - loss: 1.0781 - acc: 0.4179 - val_loss: 1.0883 - val_acc: 0.3927\n",
            "Epoch 29/50 - 0.08s - loss: 1.0775 - acc: 0.4199 - val_loss: 1.0877 - val_acc: 0.3927\n",
            "Epoch 30/50 - 0.08s - loss: 1.0768 - acc: 0.4267 - val_loss: 1.0871 - val_acc: 0.3968\n",
            "Epoch 31/50 - 0.08s - loss: 1.0761 - acc: 0.4260 - val_loss: 1.0866 - val_acc: 0.3866\n",
            "Epoch 32/50 - 0.08s - loss: 1.0755 - acc: 0.4233 - val_loss: 1.0861 - val_acc: 0.3887\n",
            "Epoch 33/50 - 0.08s - loss: 1.0748 - acc: 0.4283 - val_loss: 1.0856 - val_acc: 0.3866\n",
            "Epoch 34/50 - 0.08s - loss: 1.0742 - acc: 0.4332 - val_loss: 1.0850 - val_acc: 0.3826\n",
            "Epoch 35/50 - 0.08s - loss: 1.0735 - acc: 0.4354 - val_loss: 1.0845 - val_acc: 0.3927\n",
            "Epoch 36/50 - 0.08s - loss: 1.0729 - acc: 0.4368 - val_loss: 1.0841 - val_acc: 0.3846\n",
            "Epoch 37/50 - 0.08s - loss: 1.0722 - acc: 0.4343 - val_loss: 1.0835 - val_acc: 0.3947\n",
            "Epoch 38/50 - 0.08s - loss: 1.0716 - acc: 0.4354 - val_loss: 1.0830 - val_acc: 0.3927\n",
            "Epoch 39/50 - 0.08s - loss: 1.0709 - acc: 0.4348 - val_loss: 1.0826 - val_acc: 0.3866\n",
            "Epoch 40/50 - 0.08s - loss: 1.0703 - acc: 0.4372 - val_loss: 1.0821 - val_acc: 0.3968\n",
            "Epoch 41/50 - 0.10s - loss: 1.0697 - acc: 0.4404 - val_loss: 1.0816 - val_acc: 0.4028\n",
            "Epoch 42/50 - 0.09s - loss: 1.0690 - acc: 0.4415 - val_loss: 1.0813 - val_acc: 0.3947\n",
            "Epoch 43/50 - 0.08s - loss: 1.0684 - acc: 0.4424 - val_loss: 1.0807 - val_acc: 0.3968\n",
            "Epoch 44/50 - 0.09s - loss: 1.0677 - acc: 0.4456 - val_loss: 1.0802 - val_acc: 0.4028\n",
            "Epoch 45/50 - 0.09s - loss: 1.0671 - acc: 0.4465 - val_loss: 1.0797 - val_acc: 0.4130\n",
            "Epoch 46/50 - 0.08s - loss: 1.0664 - acc: 0.4487 - val_loss: 1.0793 - val_acc: 0.4109\n",
            "Epoch 47/50 - 0.08s - loss: 1.0658 - acc: 0.4521 - val_loss: 1.0788 - val_acc: 0.4109\n",
            "Epoch 48/50 - 0.08s - loss: 1.0651 - acc: 0.4498 - val_loss: 1.0784 - val_acc: 0.4170\n",
            "Epoch 49/50 - 0.09s - loss: 1.0645 - acc: 0.4521 - val_loss: 1.0779 - val_acc: 0.4130\n",
            "Epoch 50/50 - 0.09s - loss: 1.0638 - acc: 0.4555 - val_loss: 1.0774 - val_acc: 0.4069\n",
            "\n",
            "Combination 152/252:\n",
            "Hidden Layers: [128, 64, 32], Activation: relu, Learning Rate: 0.001, Batch Size: 32, Epochs: 100\n",
            "Epoch 1/100 - 0.09s - loss: 1.1013 - acc: 0.3453 - val_loss: 1.1003 - val_acc: 0.3522\n",
            "Epoch 2/100 - 0.09s - loss: 1.0960 - acc: 0.3608 - val_loss: 1.0968 - val_acc: 0.3543\n",
            "Epoch 3/100 - 0.08s - loss: 1.0930 - acc: 0.3738 - val_loss: 1.0949 - val_acc: 0.3684\n",
            "Epoch 4/100 - 0.08s - loss: 1.0907 - acc: 0.3803 - val_loss: 1.0933 - val_acc: 0.3846\n",
            "Epoch 5/100 - 0.09s - loss: 1.0887 - acc: 0.3844 - val_loss: 1.0918 - val_acc: 0.4008\n",
            "Epoch 6/100 - 0.08s - loss: 1.0869 - acc: 0.3914 - val_loss: 1.0904 - val_acc: 0.4089\n",
            "Epoch 7/100 - 0.08s - loss: 1.0853 - acc: 0.3977 - val_loss: 1.0892 - val_acc: 0.4049\n",
            "Epoch 8/100 - 0.08s - loss: 1.0837 - acc: 0.4049 - val_loss: 1.0880 - val_acc: 0.4069\n",
            "Epoch 9/100 - 0.08s - loss: 1.0822 - acc: 0.4069 - val_loss: 1.0868 - val_acc: 0.4049\n",
            "Epoch 10/100 - 0.08s - loss: 1.0808 - acc: 0.4087 - val_loss: 1.0857 - val_acc: 0.4008\n",
            "Epoch 11/100 - 0.09s - loss: 1.0795 - acc: 0.4159 - val_loss: 1.0846 - val_acc: 0.4069\n",
            "Epoch 12/100 - 0.09s - loss: 1.0782 - acc: 0.4186 - val_loss: 1.0836 - val_acc: 0.4089\n",
            "Epoch 13/100 - 0.09s - loss: 1.0769 - acc: 0.4229 - val_loss: 1.0826 - val_acc: 0.4109\n",
            "Epoch 14/100 - 0.10s - loss: 1.0755 - acc: 0.4238 - val_loss: 1.0816 - val_acc: 0.4190\n",
            "Epoch 15/100 - 0.08s - loss: 1.0742 - acc: 0.4285 - val_loss: 1.0806 - val_acc: 0.4170\n",
            "Epoch 16/100 - 0.09s - loss: 1.0729 - acc: 0.4323 - val_loss: 1.0795 - val_acc: 0.4190\n",
            "Epoch 17/100 - 0.09s - loss: 1.0717 - acc: 0.4366 - val_loss: 1.0785 - val_acc: 0.4170\n",
            "Epoch 18/100 - 0.08s - loss: 1.0704 - acc: 0.4384 - val_loss: 1.0775 - val_acc: 0.4231\n",
            "Epoch 19/100 - 0.08s - loss: 1.0691 - acc: 0.4417 - val_loss: 1.0765 - val_acc: 0.4271\n",
            "Epoch 20/100 - 0.09s - loss: 1.0679 - acc: 0.4426 - val_loss: 1.0755 - val_acc: 0.4312\n",
            "Epoch 21/100 - 0.08s - loss: 1.0667 - acc: 0.4447 - val_loss: 1.0746 - val_acc: 0.4291\n",
            "Epoch 22/100 - 0.09s - loss: 1.0654 - acc: 0.4438 - val_loss: 1.0737 - val_acc: 0.4372\n",
            "Epoch 23/100 - 0.08s - loss: 1.0643 - acc: 0.4453 - val_loss: 1.0727 - val_acc: 0.4372\n",
            "Epoch 24/100 - 0.08s - loss: 1.0631 - acc: 0.4485 - val_loss: 1.0720 - val_acc: 0.4372\n",
            "Epoch 25/100 - 0.09s - loss: 1.0620 - acc: 0.4498 - val_loss: 1.0711 - val_acc: 0.4393\n",
            "Epoch 26/100 - 0.08s - loss: 1.0608 - acc: 0.4525 - val_loss: 1.0704 - val_acc: 0.4453\n",
            "Epoch 27/100 - 0.08s - loss: 1.0597 - acc: 0.4516 - val_loss: 1.0694 - val_acc: 0.4433\n",
            "Epoch 28/100 - 0.10s - loss: 1.0585 - acc: 0.4534 - val_loss: 1.0686 - val_acc: 0.4453\n",
            "Epoch 29/100 - 0.08s - loss: 1.0575 - acc: 0.4557 - val_loss: 1.0677 - val_acc: 0.4372\n",
            "Epoch 30/100 - 0.08s - loss: 1.0563 - acc: 0.4566 - val_loss: 1.0670 - val_acc: 0.4372\n",
            "Epoch 31/100 - 0.08s - loss: 1.0553 - acc: 0.4584 - val_loss: 1.0665 - val_acc: 0.4474\n",
            "Epoch 32/100 - 0.08s - loss: 1.0542 - acc: 0.4588 - val_loss: 1.0655 - val_acc: 0.4433\n",
            "Epoch 33/100 - 0.08s - loss: 1.0531 - acc: 0.4602 - val_loss: 1.0644 - val_acc: 0.4453\n",
            "Epoch 34/100 - 0.08s - loss: 1.0520 - acc: 0.4618 - val_loss: 1.0637 - val_acc: 0.4433\n",
            "Epoch 35/100 - 0.09s - loss: 1.0510 - acc: 0.4651 - val_loss: 1.0630 - val_acc: 0.4474\n",
            "Epoch 36/100 - 0.08s - loss: 1.0499 - acc: 0.4642 - val_loss: 1.0621 - val_acc: 0.4433\n",
            "Epoch 37/100 - 0.09s - loss: 1.0489 - acc: 0.4636 - val_loss: 1.0613 - val_acc: 0.4453\n",
            "Epoch 38/100 - 0.08s - loss: 1.0478 - acc: 0.4667 - val_loss: 1.0608 - val_acc: 0.4453\n",
            "Epoch 39/100 - 0.08s - loss: 1.0467 - acc: 0.4685 - val_loss: 1.0597 - val_acc: 0.4413\n",
            "Epoch 40/100 - 0.09s - loss: 1.0457 - acc: 0.4685 - val_loss: 1.0589 - val_acc: 0.4474\n",
            "Epoch 41/100 - 0.08s - loss: 1.0446 - acc: 0.4710 - val_loss: 1.0584 - val_acc: 0.4575\n",
            "Epoch 42/100 - 0.08s - loss: 1.0436 - acc: 0.4728 - val_loss: 1.0578 - val_acc: 0.4636\n",
            "Epoch 43/100 - 0.09s - loss: 1.0425 - acc: 0.4723 - val_loss: 1.0567 - val_acc: 0.4413\n",
            "Epoch 44/100 - 0.10s - loss: 1.0415 - acc: 0.4730 - val_loss: 1.0561 - val_acc: 0.4534\n",
            "Epoch 45/100 - 0.08s - loss: 1.0405 - acc: 0.4746 - val_loss: 1.0557 - val_acc: 0.4595\n",
            "Epoch 46/100 - 0.10s - loss: 1.0394 - acc: 0.4755 - val_loss: 1.0549 - val_acc: 0.4636\n",
            "Epoch 47/100 - 0.08s - loss: 1.0384 - acc: 0.4789 - val_loss: 1.0538 - val_acc: 0.4453\n",
            "Epoch 48/100 - 0.08s - loss: 1.0373 - acc: 0.4791 - val_loss: 1.0533 - val_acc: 0.4474\n",
            "Epoch 49/100 - 0.08s - loss: 1.0363 - acc: 0.4804 - val_loss: 1.0528 - val_acc: 0.4575\n",
            "Epoch 50/100 - 0.08s - loss: 1.0353 - acc: 0.4777 - val_loss: 1.0520 - val_acc: 0.4514\n",
            "Epoch 51/100 - 0.08s - loss: 1.0342 - acc: 0.4822 - val_loss: 1.0515 - val_acc: 0.4615\n",
            "Epoch 52/100 - 0.08s - loss: 1.0332 - acc: 0.4816 - val_loss: 1.0506 - val_acc: 0.4696\n",
            "Epoch 53/100 - 0.10s - loss: 1.0321 - acc: 0.4831 - val_loss: 1.0500 - val_acc: 0.4575\n",
            "Epoch 54/100 - 0.08s - loss: 1.0311 - acc: 0.4852 - val_loss: 1.0494 - val_acc: 0.4595\n",
            "Epoch 55/100 - 0.09s - loss: 1.0301 - acc: 0.4845 - val_loss: 1.0491 - val_acc: 0.4656\n",
            "Epoch 56/100 - 0.08s - loss: 1.0290 - acc: 0.4858 - val_loss: 1.0483 - val_acc: 0.4676\n",
            "Epoch 57/100 - 0.08s - loss: 1.0280 - acc: 0.4876 - val_loss: 1.0477 - val_acc: 0.4636\n",
            "Epoch 58/100 - 0.09s - loss: 1.0271 - acc: 0.4856 - val_loss: 1.0473 - val_acc: 0.4595\n",
            "Epoch 59/100 - 0.08s - loss: 1.0260 - acc: 0.4867 - val_loss: 1.0464 - val_acc: 0.4676\n",
            "Epoch 60/100 - 0.08s - loss: 1.0250 - acc: 0.4910 - val_loss: 1.0457 - val_acc: 0.4696\n",
            "Epoch 61/100 - 0.08s - loss: 1.0239 - acc: 0.4921 - val_loss: 1.0450 - val_acc: 0.4717\n",
            "Epoch 62/100 - 0.08s - loss: 1.0229 - acc: 0.4924 - val_loss: 1.0443 - val_acc: 0.4676\n",
            "Epoch 63/100 - 0.07s - loss: 1.0219 - acc: 0.4910 - val_loss: 1.0438 - val_acc: 0.4656\n",
            "Epoch 64/100 - 0.08s - loss: 1.0209 - acc: 0.4939 - val_loss: 1.0432 - val_acc: 0.4656\n",
            "Epoch 65/100 - 0.09s - loss: 1.0199 - acc: 0.4930 - val_loss: 1.0426 - val_acc: 0.4676\n",
            "Epoch 66/100 - 0.07s - loss: 1.0189 - acc: 0.4937 - val_loss: 1.0417 - val_acc: 0.4595\n",
            "Epoch 67/100 - 0.08s - loss: 1.0179 - acc: 0.4939 - val_loss: 1.0410 - val_acc: 0.4757\n",
            "Epoch 68/100 - 0.08s - loss: 1.0169 - acc: 0.4944 - val_loss: 1.0405 - val_acc: 0.4636\n",
            "Epoch 69/100 - 0.07s - loss: 1.0160 - acc: 0.4948 - val_loss: 1.0398 - val_acc: 0.4636\n",
            "Epoch 70/100 - 0.08s - loss: 1.0150 - acc: 0.4942 - val_loss: 1.0392 - val_acc: 0.4676\n",
            "Epoch 71/100 - 0.09s - loss: 1.0140 - acc: 0.4955 - val_loss: 1.0385 - val_acc: 0.4676\n",
            "Epoch 72/100 - 0.07s - loss: 1.0134 - acc: 0.4946 - val_loss: 1.0385 - val_acc: 0.4717\n",
            "Epoch 73/100 - 0.09s - loss: 1.0122 - acc: 0.4982 - val_loss: 1.0371 - val_acc: 0.4757\n",
            "Epoch 74/100 - 0.08s - loss: 1.0113 - acc: 0.4989 - val_loss: 1.0363 - val_acc: 0.4757\n",
            "Epoch 75/100 - 0.08s - loss: 1.0102 - acc: 0.4980 - val_loss: 1.0357 - val_acc: 0.4717\n",
            "Epoch 76/100 - 0.09s - loss: 1.0097 - acc: 0.5027 - val_loss: 1.0350 - val_acc: 0.4717\n",
            "Epoch 77/100 - 0.08s - loss: 1.0083 - acc: 0.5000 - val_loss: 1.0344 - val_acc: 0.4798\n",
            "Epoch 78/100 - 0.08s - loss: 1.0073 - acc: 0.4991 - val_loss: 1.0335 - val_acc: 0.4737\n",
            "Epoch 79/100 - 0.08s - loss: 1.0065 - acc: 0.5020 - val_loss: 1.0330 - val_acc: 0.4757\n",
            "Epoch 80/100 - 0.08s - loss: 1.0054 - acc: 0.5016 - val_loss: 1.0321 - val_acc: 0.4838\n",
            "Epoch 81/100 - 0.08s - loss: 1.0045 - acc: 0.4982 - val_loss: 1.0319 - val_acc: 0.4818\n",
            "Epoch 82/100 - 0.09s - loss: 1.0034 - acc: 0.5038 - val_loss: 1.0308 - val_acc: 0.4777\n",
            "Epoch 83/100 - 0.08s - loss: 1.0024 - acc: 0.5027 - val_loss: 1.0300 - val_acc: 0.4838\n",
            "Epoch 84/100 - 0.08s - loss: 1.0014 - acc: 0.5045 - val_loss: 1.0293 - val_acc: 0.4838\n",
            "Epoch 85/100 - 0.09s - loss: 1.0004 - acc: 0.5038 - val_loss: 1.0290 - val_acc: 0.4838\n",
            "Epoch 86/100 - 0.08s - loss: 0.9996 - acc: 0.5027 - val_loss: 1.0287 - val_acc: 0.4818\n",
            "Epoch 87/100 - 0.08s - loss: 0.9986 - acc: 0.5027 - val_loss: 1.0280 - val_acc: 0.4798\n",
            "Epoch 88/100 - 0.09s - loss: 0.9975 - acc: 0.5090 - val_loss: 1.0264 - val_acc: 0.4879\n",
            "Epoch 89/100 - 0.08s - loss: 0.9965 - acc: 0.5049 - val_loss: 1.0263 - val_acc: 0.4899\n",
            "Epoch 90/100 - 0.08s - loss: 0.9955 - acc: 0.5054 - val_loss: 1.0253 - val_acc: 0.4899\n",
            "Epoch 91/100 - 0.08s - loss: 0.9944 - acc: 0.5094 - val_loss: 1.0241 - val_acc: 0.4858\n",
            "Epoch 92/100 - 0.10s - loss: 0.9935 - acc: 0.5139 - val_loss: 1.0237 - val_acc: 0.4879\n",
            "Epoch 93/100 - 0.08s - loss: 0.9928 - acc: 0.5106 - val_loss: 1.0230 - val_acc: 0.4939\n",
            "Epoch 94/100 - 0.10s - loss: 0.9916 - acc: 0.5108 - val_loss: 1.0232 - val_acc: 0.4899\n",
            "Epoch 95/100 - 0.08s - loss: 0.9906 - acc: 0.5106 - val_loss: 1.0225 - val_acc: 0.4858\n",
            "Epoch 96/100 - 0.09s - loss: 0.9896 - acc: 0.5135 - val_loss: 1.0217 - val_acc: 0.4919\n",
            "Epoch 97/100 - 0.10s - loss: 0.9886 - acc: 0.5133 - val_loss: 1.0208 - val_acc: 0.4899\n",
            "Epoch 98/100 - 0.09s - loss: 0.9876 - acc: 0.5151 - val_loss: 1.0200 - val_acc: 0.4919\n",
            "Epoch 99/100 - 0.08s - loss: 0.9867 - acc: 0.5164 - val_loss: 1.0192 - val_acc: 0.4919\n",
            "Epoch 100/100 - 0.10s - loss: 0.9860 - acc: 0.5153 - val_loss: 1.0178 - val_acc: 0.4939\n",
            "\n",
            "Combination 153/252:\n",
            "Hidden Layers: [128, 64, 32], Activation: relu, Learning Rate: 0.001, Batch Size: 32, Epochs: 150\n",
            "Epoch 1/150 - 0.08s - loss: 1.1093 - acc: 0.3270 - val_loss: 1.1111 - val_acc: 0.3138\n",
            "Epoch 2/150 - 0.08s - loss: 1.1001 - acc: 0.3302 - val_loss: 1.1011 - val_acc: 0.3158\n",
            "Epoch 3/150 - 0.09s - loss: 1.0954 - acc: 0.3437 - val_loss: 1.0960 - val_acc: 0.3279\n",
            "Epoch 4/150 - 0.09s - loss: 1.0927 - acc: 0.3722 - val_loss: 1.0931 - val_acc: 0.3502\n",
            "Epoch 5/150 - 0.08s - loss: 1.0907 - acc: 0.3837 - val_loss: 1.0910 - val_acc: 0.3684\n",
            "Epoch 6/150 - 0.09s - loss: 1.0893 - acc: 0.3920 - val_loss: 1.0896 - val_acc: 0.3785\n",
            "Epoch 7/150 - 0.09s - loss: 1.0881 - acc: 0.3943 - val_loss: 1.0884 - val_acc: 0.3927\n",
            "Epoch 8/150 - 0.08s - loss: 1.0870 - acc: 0.3954 - val_loss: 1.0874 - val_acc: 0.3927\n",
            "Epoch 9/150 - 0.09s - loss: 1.0860 - acc: 0.3963 - val_loss: 1.0864 - val_acc: 0.4049\n",
            "Epoch 10/150 - 0.08s - loss: 1.0851 - acc: 0.3999 - val_loss: 1.0856 - val_acc: 0.4008\n",
            "Epoch 11/150 - 0.08s - loss: 1.0842 - acc: 0.4015 - val_loss: 1.0848 - val_acc: 0.4049\n",
            "Epoch 12/150 - 0.10s - loss: 1.0833 - acc: 0.4058 - val_loss: 1.0840 - val_acc: 0.4049\n",
            "Epoch 13/150 - 0.09s - loss: 1.0825 - acc: 0.4062 - val_loss: 1.0833 - val_acc: 0.4008\n",
            "Epoch 14/150 - 0.08s - loss: 1.0817 - acc: 0.4103 - val_loss: 1.0826 - val_acc: 0.4028\n",
            "Epoch 15/150 - 0.09s - loss: 1.0809 - acc: 0.4127 - val_loss: 1.0818 - val_acc: 0.4069\n",
            "Epoch 16/150 - 0.08s - loss: 1.0801 - acc: 0.4127 - val_loss: 1.0812 - val_acc: 0.4089\n",
            "Epoch 17/150 - 0.08s - loss: 1.0793 - acc: 0.4157 - val_loss: 1.0805 - val_acc: 0.4150\n",
            "Epoch 18/150 - 0.09s - loss: 1.0784 - acc: 0.4193 - val_loss: 1.0798 - val_acc: 0.4190\n",
            "Epoch 19/150 - 0.09s - loss: 1.0776 - acc: 0.4204 - val_loss: 1.0790 - val_acc: 0.4251\n",
            "Epoch 20/150 - 0.09s - loss: 1.0768 - acc: 0.4208 - val_loss: 1.0783 - val_acc: 0.4372\n",
            "Epoch 21/150 - 0.09s - loss: 1.0759 - acc: 0.4251 - val_loss: 1.0777 - val_acc: 0.4393\n",
            "Epoch 22/150 - 0.08s - loss: 1.0750 - acc: 0.4280 - val_loss: 1.0769 - val_acc: 0.4393\n",
            "Epoch 23/150 - 0.08s - loss: 1.0742 - acc: 0.4289 - val_loss: 1.0762 - val_acc: 0.4372\n",
            "Epoch 24/150 - 0.08s - loss: 1.0733 - acc: 0.4323 - val_loss: 1.0754 - val_acc: 0.4312\n",
            "Epoch 25/150 - 0.10s - loss: 1.0725 - acc: 0.4325 - val_loss: 1.0748 - val_acc: 0.4352\n",
            "Epoch 26/150 - 0.08s - loss: 1.0717 - acc: 0.4341 - val_loss: 1.0741 - val_acc: 0.4332\n",
            "Epoch 27/150 - 0.09s - loss: 1.0709 - acc: 0.4357 - val_loss: 1.0733 - val_acc: 0.4352\n",
            "Epoch 28/150 - 0.08s - loss: 1.0700 - acc: 0.4366 - val_loss: 1.0726 - val_acc: 0.4372\n",
            "Epoch 29/150 - 0.08s - loss: 1.0692 - acc: 0.4375 - val_loss: 1.0718 - val_acc: 0.4413\n",
            "Epoch 30/150 - 0.09s - loss: 1.0683 - acc: 0.4381 - val_loss: 1.0711 - val_acc: 0.4413\n",
            "Epoch 31/150 - 0.09s - loss: 1.0674 - acc: 0.4399 - val_loss: 1.0704 - val_acc: 0.4413\n",
            "Epoch 32/150 - 0.08s - loss: 1.0664 - acc: 0.4420 - val_loss: 1.0698 - val_acc: 0.4413\n",
            "Epoch 33/150 - 0.08s - loss: 1.0654 - acc: 0.4422 - val_loss: 1.0690 - val_acc: 0.4474\n",
            "Epoch 34/150 - 0.08s - loss: 1.0644 - acc: 0.4438 - val_loss: 1.0685 - val_acc: 0.4453\n",
            "Epoch 35/150 - 0.08s - loss: 1.0634 - acc: 0.4422 - val_loss: 1.0679 - val_acc: 0.4433\n",
            "Epoch 36/150 - 0.09s - loss: 1.0625 - acc: 0.4435 - val_loss: 1.0672 - val_acc: 0.4393\n",
            "Epoch 37/150 - 0.08s - loss: 1.0615 - acc: 0.4417 - val_loss: 1.0665 - val_acc: 0.4393\n",
            "Epoch 38/150 - 0.08s - loss: 1.0606 - acc: 0.4422 - val_loss: 1.0659 - val_acc: 0.4433\n",
            "Epoch 39/150 - 0.08s - loss: 1.0597 - acc: 0.4444 - val_loss: 1.0654 - val_acc: 0.4433\n",
            "Epoch 40/150 - 0.08s - loss: 1.0589 - acc: 0.4458 - val_loss: 1.0648 - val_acc: 0.4474\n",
            "Epoch 41/150 - 0.08s - loss: 1.0580 - acc: 0.4480 - val_loss: 1.0642 - val_acc: 0.4474\n",
            "Epoch 42/150 - 0.08s - loss: 1.0572 - acc: 0.4501 - val_loss: 1.0637 - val_acc: 0.4514\n",
            "Epoch 43/150 - 0.08s - loss: 1.0563 - acc: 0.4519 - val_loss: 1.0632 - val_acc: 0.4494\n",
            "Epoch 44/150 - 0.08s - loss: 1.0555 - acc: 0.4523 - val_loss: 1.0626 - val_acc: 0.4514\n",
            "Epoch 45/150 - 0.09s - loss: 1.0546 - acc: 0.4530 - val_loss: 1.0622 - val_acc: 0.4494\n",
            "Epoch 46/150 - 0.08s - loss: 1.0538 - acc: 0.4555 - val_loss: 1.0619 - val_acc: 0.4474\n",
            "Epoch 47/150 - 0.08s - loss: 1.0530 - acc: 0.4541 - val_loss: 1.0611 - val_acc: 0.4413\n",
            "Epoch 48/150 - 0.10s - loss: 1.0521 - acc: 0.4582 - val_loss: 1.0608 - val_acc: 0.4474\n",
            "Epoch 49/150 - 0.08s - loss: 1.0512 - acc: 0.4584 - val_loss: 1.0603 - val_acc: 0.4514\n",
            "Epoch 50/150 - 0.08s - loss: 1.0504 - acc: 0.4573 - val_loss: 1.0597 - val_acc: 0.4494\n",
            "Epoch 51/150 - 0.09s - loss: 1.0496 - acc: 0.4584 - val_loss: 1.0593 - val_acc: 0.4474\n",
            "Epoch 52/150 - 0.09s - loss: 1.0488 - acc: 0.4582 - val_loss: 1.0588 - val_acc: 0.4494\n",
            "Epoch 53/150 - 0.09s - loss: 1.0479 - acc: 0.4602 - val_loss: 1.0584 - val_acc: 0.4514\n",
            "Epoch 54/150 - 0.10s - loss: 1.0471 - acc: 0.4606 - val_loss: 1.0581 - val_acc: 0.4514\n",
            "Epoch 55/150 - 0.08s - loss: 1.0463 - acc: 0.4609 - val_loss: 1.0576 - val_acc: 0.4514\n",
            "Epoch 56/150 - 0.08s - loss: 1.0455 - acc: 0.4613 - val_loss: 1.0571 - val_acc: 0.4494\n",
            "Epoch 57/150 - 0.08s - loss: 1.0447 - acc: 0.4627 - val_loss: 1.0567 - val_acc: 0.4534\n",
            "Epoch 58/150 - 0.08s - loss: 1.0439 - acc: 0.4631 - val_loss: 1.0561 - val_acc: 0.4514\n",
            "Epoch 59/150 - 0.08s - loss: 1.0431 - acc: 0.4651 - val_loss: 1.0557 - val_acc: 0.4534\n",
            "Epoch 60/150 - 0.08s - loss: 1.0423 - acc: 0.4651 - val_loss: 1.0557 - val_acc: 0.4636\n",
            "Epoch 61/150 - 0.08s - loss: 1.0415 - acc: 0.4660 - val_loss: 1.0547 - val_acc: 0.4534\n",
            "Epoch 62/150 - 0.08s - loss: 1.0407 - acc: 0.4683 - val_loss: 1.0548 - val_acc: 0.4615\n",
            "Epoch 63/150 - 0.09s - loss: 1.0399 - acc: 0.4683 - val_loss: 1.0540 - val_acc: 0.4615\n",
            "Epoch 64/150 - 0.08s - loss: 1.0391 - acc: 0.4685 - val_loss: 1.0533 - val_acc: 0.4595\n",
            "Epoch 65/150 - 0.08s - loss: 1.0384 - acc: 0.4705 - val_loss: 1.0527 - val_acc: 0.4575\n",
            "Epoch 66/150 - 0.09s - loss: 1.0376 - acc: 0.4717 - val_loss: 1.0523 - val_acc: 0.4534\n",
            "Epoch 67/150 - 0.08s - loss: 1.0367 - acc: 0.4730 - val_loss: 1.0521 - val_acc: 0.4636\n",
            "Epoch 68/150 - 0.08s - loss: 1.0360 - acc: 0.4732 - val_loss: 1.0516 - val_acc: 0.4636\n",
            "Epoch 69/150 - 0.08s - loss: 1.0352 - acc: 0.4762 - val_loss: 1.0512 - val_acc: 0.4656\n",
            "Epoch 70/150 - 0.09s - loss: 1.0344 - acc: 0.4748 - val_loss: 1.0505 - val_acc: 0.4656\n",
            "Epoch 71/150 - 0.08s - loss: 1.0336 - acc: 0.4793 - val_loss: 1.0503 - val_acc: 0.4656\n",
            "Epoch 72/150 - 0.09s - loss: 1.0329 - acc: 0.4764 - val_loss: 1.0496 - val_acc: 0.4656\n",
            "Epoch 73/150 - 0.08s - loss: 1.0321 - acc: 0.4791 - val_loss: 1.0494 - val_acc: 0.4636\n",
            "Epoch 74/150 - 0.08s - loss: 1.0313 - acc: 0.4798 - val_loss: 1.0488 - val_acc: 0.4656\n",
            "Epoch 75/150 - 0.09s - loss: 1.0306 - acc: 0.4798 - val_loss: 1.0480 - val_acc: 0.4737\n",
            "Epoch 76/150 - 0.08s - loss: 1.0298 - acc: 0.4816 - val_loss: 1.0475 - val_acc: 0.4737\n",
            "Epoch 77/150 - 0.08s - loss: 1.0291 - acc: 0.4840 - val_loss: 1.0476 - val_acc: 0.4615\n",
            "Epoch 78/150 - 0.09s - loss: 1.0282 - acc: 0.4827 - val_loss: 1.0468 - val_acc: 0.4615\n",
            "Epoch 79/150 - 0.09s - loss: 1.0275 - acc: 0.4834 - val_loss: 1.0461 - val_acc: 0.4777\n",
            "Epoch 80/150 - 0.09s - loss: 1.0267 - acc: 0.4849 - val_loss: 1.0457 - val_acc: 0.4757\n",
            "Epoch 81/150 - 0.09s - loss: 1.0260 - acc: 0.4847 - val_loss: 1.0452 - val_acc: 0.4757\n",
            "Epoch 82/150 - 0.08s - loss: 1.0252 - acc: 0.4854 - val_loss: 1.0446 - val_acc: 0.4777\n",
            "Epoch 83/150 - 0.08s - loss: 1.0245 - acc: 0.4854 - val_loss: 1.0441 - val_acc: 0.4777\n",
            "Epoch 84/150 - 0.09s - loss: 1.0238 - acc: 0.4858 - val_loss: 1.0436 - val_acc: 0.4798\n",
            "Epoch 85/150 - 0.08s - loss: 1.0230 - acc: 0.4865 - val_loss: 1.0431 - val_acc: 0.4838\n",
            "Epoch 86/150 - 0.08s - loss: 1.0222 - acc: 0.4874 - val_loss: 1.0429 - val_acc: 0.4757\n",
            "Epoch 87/150 - 0.09s - loss: 1.0214 - acc: 0.4874 - val_loss: 1.0422 - val_acc: 0.4858\n",
            "Epoch 88/150 - 0.08s - loss: 1.0207 - acc: 0.4892 - val_loss: 1.0417 - val_acc: 0.4838\n",
            "Epoch 89/150 - 0.08s - loss: 1.0199 - acc: 0.4883 - val_loss: 1.0410 - val_acc: 0.4858\n",
            "Epoch 90/150 - 0.09s - loss: 1.0192 - acc: 0.4885 - val_loss: 1.0405 - val_acc: 0.4858\n",
            "Epoch 91/150 - 0.08s - loss: 1.0184 - acc: 0.4937 - val_loss: 1.0404 - val_acc: 0.4798\n",
            "Epoch 92/150 - 0.08s - loss: 1.0176 - acc: 0.4935 - val_loss: 1.0399 - val_acc: 0.4798\n",
            "Epoch 93/150 - 0.08s - loss: 1.0170 - acc: 0.4919 - val_loss: 1.0392 - val_acc: 0.4858\n",
            "Epoch 94/150 - 0.08s - loss: 1.0161 - acc: 0.4955 - val_loss: 1.0389 - val_acc: 0.4798\n",
            "Epoch 95/150 - 0.08s - loss: 1.0154 - acc: 0.4966 - val_loss: 1.0387 - val_acc: 0.4777\n",
            "Epoch 96/150 - 0.09s - loss: 1.0147 - acc: 0.4924 - val_loss: 1.0374 - val_acc: 0.5000\n",
            "Epoch 97/150 - 0.08s - loss: 1.0139 - acc: 0.4991 - val_loss: 1.0377 - val_acc: 0.4777\n",
            "Epoch 98/150 - 0.08s - loss: 1.0131 - acc: 0.5004 - val_loss: 1.0370 - val_acc: 0.4798\n",
            "Epoch 99/150 - 0.08s - loss: 1.0123 - acc: 0.4978 - val_loss: 1.0361 - val_acc: 0.4838\n",
            "Epoch 100/150 - 0.08s - loss: 1.0115 - acc: 0.4966 - val_loss: 1.0355 - val_acc: 0.4919\n",
            "Epoch 101/150 - 0.08s - loss: 1.0108 - acc: 0.5013 - val_loss: 1.0356 - val_acc: 0.4757\n",
            "Epoch 102/150 - 0.10s - loss: 1.0099 - acc: 0.5004 - val_loss: 1.0345 - val_acc: 0.4838\n",
            "Epoch 103/150 - 0.08s - loss: 1.0092 - acc: 0.4998 - val_loss: 1.0337 - val_acc: 0.4919\n",
            "Epoch 104/150 - 0.08s - loss: 1.0085 - acc: 0.5029 - val_loss: 1.0339 - val_acc: 0.4818\n",
            "Epoch 105/150 - 0.09s - loss: 1.0079 - acc: 0.4998 - val_loss: 1.0325 - val_acc: 0.4980\n",
            "Epoch 106/150 - 0.10s - loss: 1.0069 - acc: 0.5045 - val_loss: 1.0327 - val_acc: 0.4838\n",
            "Epoch 107/150 - 0.09s - loss: 1.0064 - acc: 0.5018 - val_loss: 1.0327 - val_acc: 0.4838\n",
            "Epoch 108/150 - 0.10s - loss: 1.0053 - acc: 0.5040 - val_loss: 1.0309 - val_acc: 0.4899\n",
            "Epoch 109/150 - 0.09s - loss: 1.0045 - acc: 0.5036 - val_loss: 1.0305 - val_acc: 0.4980\n",
            "Epoch 110/150 - 0.08s - loss: 1.0038 - acc: 0.5076 - val_loss: 1.0305 - val_acc: 0.4919\n",
            "Epoch 111/150 - 0.09s - loss: 1.0030 - acc: 0.5049 - val_loss: 1.0291 - val_acc: 0.4939\n",
            "Epoch 112/150 - 0.08s - loss: 1.0026 - acc: 0.5076 - val_loss: 1.0299 - val_acc: 0.4960\n",
            "Epoch 113/150 - 0.08s - loss: 1.0014 - acc: 0.5074 - val_loss: 1.0279 - val_acc: 0.4960\n",
            "Epoch 114/150 - 0.08s - loss: 1.0007 - acc: 0.5135 - val_loss: 1.0279 - val_acc: 0.4879\n",
            "Epoch 115/150 - 0.09s - loss: 1.0000 - acc: 0.5106 - val_loss: 1.0274 - val_acc: 0.4919\n",
            "Epoch 116/150 - 0.08s - loss: 0.9992 - acc: 0.5130 - val_loss: 1.0268 - val_acc: 0.4939\n",
            "Epoch 117/150 - 0.08s - loss: 0.9984 - acc: 0.5128 - val_loss: 1.0261 - val_acc: 0.4919\n",
            "Epoch 118/150 - 0.09s - loss: 0.9977 - acc: 0.5139 - val_loss: 1.0258 - val_acc: 0.4919\n",
            "Epoch 119/150 - 0.09s - loss: 0.9967 - acc: 0.5130 - val_loss: 1.0244 - val_acc: 0.5121\n",
            "Epoch 120/150 - 0.11s - loss: 0.9960 - acc: 0.5153 - val_loss: 1.0240 - val_acc: 0.5000\n",
            "Epoch 121/150 - 0.08s - loss: 0.9953 - acc: 0.5142 - val_loss: 1.0237 - val_acc: 0.5020\n",
            "Epoch 122/150 - 0.08s - loss: 0.9945 - acc: 0.5144 - val_loss: 1.0222 - val_acc: 0.5142\n",
            "Epoch 123/150 - 0.09s - loss: 0.9936 - acc: 0.5180 - val_loss: 1.0222 - val_acc: 0.5101\n",
            "Epoch 124/150 - 0.08s - loss: 0.9928 - acc: 0.5171 - val_loss: 1.0212 - val_acc: 0.5142\n",
            "Epoch 125/150 - 0.09s - loss: 0.9922 - acc: 0.5171 - val_loss: 1.0205 - val_acc: 0.5202\n",
            "Epoch 126/150 - 0.09s - loss: 0.9912 - acc: 0.5198 - val_loss: 1.0200 - val_acc: 0.5182\n",
            "Epoch 127/150 - 0.08s - loss: 0.9907 - acc: 0.5126 - val_loss: 1.0200 - val_acc: 0.5061\n",
            "Epoch 128/150 - 0.08s - loss: 0.9897 - acc: 0.5187 - val_loss: 1.0187 - val_acc: 0.5223\n",
            "Epoch 129/150 - 0.08s - loss: 0.9890 - acc: 0.5169 - val_loss: 1.0185 - val_acc: 0.5182\n",
            "Epoch 130/150 - 0.08s - loss: 0.9882 - acc: 0.5175 - val_loss: 1.0178 - val_acc: 0.5202\n",
            "Epoch 131/150 - 0.08s - loss: 0.9874 - acc: 0.5227 - val_loss: 1.0168 - val_acc: 0.5324\n",
            "Epoch 132/150 - 0.10s - loss: 0.9866 - acc: 0.5218 - val_loss: 1.0163 - val_acc: 0.5364\n",
            "Epoch 133/150 - 0.10s - loss: 0.9859 - acc: 0.5196 - val_loss: 1.0157 - val_acc: 0.5223\n",
            "Epoch 134/150 - 0.10s - loss: 0.9859 - acc: 0.5155 - val_loss: 1.0166 - val_acc: 0.5000\n",
            "Epoch 135/150 - 0.11s - loss: 0.9843 - acc: 0.5216 - val_loss: 1.0145 - val_acc: 0.5324\n",
            "Epoch 136/150 - 0.08s - loss: 0.9835 - acc: 0.5214 - val_loss: 1.0136 - val_acc: 0.5304\n",
            "Epoch 137/150 - 0.08s - loss: 0.9836 - acc: 0.5182 - val_loss: 1.0148 - val_acc: 0.5061\n",
            "Epoch 138/150 - 0.09s - loss: 0.9822 - acc: 0.5218 - val_loss: 1.0121 - val_acc: 0.5425\n",
            "Epoch 139/150 - 0.08s - loss: 0.9814 - acc: 0.5220 - val_loss: 1.0124 - val_acc: 0.5283\n",
            "Epoch 140/150 - 0.08s - loss: 0.9805 - acc: 0.5225 - val_loss: 1.0112 - val_acc: 0.5385\n",
            "Epoch 141/150 - 0.09s - loss: 0.9799 - acc: 0.5220 - val_loss: 1.0111 - val_acc: 0.5283\n",
            "Epoch 142/150 - 0.08s - loss: 0.9791 - acc: 0.5241 - val_loss: 1.0103 - val_acc: 0.5243\n",
            "Epoch 143/150 - 0.08s - loss: 0.9782 - acc: 0.5250 - val_loss: 1.0093 - val_acc: 0.5344\n",
            "Epoch 144/150 - 0.09s - loss: 0.9776 - acc: 0.5241 - val_loss: 1.0084 - val_acc: 0.5425\n",
            "Epoch 145/150 - 0.09s - loss: 0.9769 - acc: 0.5241 - val_loss: 1.0077 - val_acc: 0.5425\n",
            "Epoch 146/150 - 0.08s - loss: 0.9764 - acc: 0.5252 - val_loss: 1.0071 - val_acc: 0.5486\n",
            "Epoch 147/150 - 0.09s - loss: 0.9753 - acc: 0.5261 - val_loss: 1.0067 - val_acc: 0.5425\n",
            "Epoch 148/150 - 0.11s - loss: 0.9750 - acc: 0.5263 - val_loss: 1.0060 - val_acc: 0.5466\n",
            "Epoch 149/150 - 0.09s - loss: 0.9737 - acc: 0.5295 - val_loss: 1.0054 - val_acc: 0.5385\n",
            "Epoch 150/150 - 0.13s - loss: 0.9741 - acc: 0.5270 - val_loss: 1.0070 - val_acc: 0.5162\n",
            "\n",
            "Combination 154/252:\n",
            "Hidden Layers: [128, 64, 32], Activation: relu, Learning Rate: 0.001, Batch Size: 64, Epochs: 50\n",
            "Epoch 1/50 - 0.08s - loss: 1.1124 - acc: 0.3430 - val_loss: 1.1097 - val_acc: 0.3441\n",
            "Epoch 2/50 - 0.08s - loss: 1.1069 - acc: 0.3527 - val_loss: 1.1050 - val_acc: 0.3583\n",
            "Epoch 3/50 - 0.08s - loss: 1.1032 - acc: 0.3581 - val_loss: 1.1020 - val_acc: 0.3603\n",
            "Epoch 4/50 - 0.08s - loss: 1.1004 - acc: 0.3603 - val_loss: 1.1000 - val_acc: 0.3583\n",
            "Epoch 5/50 - 0.07s - loss: 1.0984 - acc: 0.3639 - val_loss: 1.0986 - val_acc: 0.3664\n",
            "Epoch 6/50 - 0.07s - loss: 1.0968 - acc: 0.3731 - val_loss: 1.0974 - val_acc: 0.3684\n",
            "Epoch 7/50 - 0.08s - loss: 1.0954 - acc: 0.3716 - val_loss: 1.0965 - val_acc: 0.3704\n",
            "Epoch 8/50 - 0.07s - loss: 1.0943 - acc: 0.3700 - val_loss: 1.0956 - val_acc: 0.3704\n",
            "Epoch 9/50 - 0.08s - loss: 1.0933 - acc: 0.3722 - val_loss: 1.0949 - val_acc: 0.3745\n",
            "Epoch 10/50 - 0.10s - loss: 1.0925 - acc: 0.3785 - val_loss: 1.0942 - val_acc: 0.3684\n",
            "Epoch 11/50 - 0.07s - loss: 1.0918 - acc: 0.3833 - val_loss: 1.0936 - val_acc: 0.3866\n",
            "Epoch 12/50 - 0.08s - loss: 1.0911 - acc: 0.3828 - val_loss: 1.0929 - val_acc: 0.3866\n",
            "Epoch 13/50 - 0.07s - loss: 1.0904 - acc: 0.3896 - val_loss: 1.0923 - val_acc: 0.3866\n",
            "Epoch 14/50 - 0.07s - loss: 1.0898 - acc: 0.3918 - val_loss: 1.0918 - val_acc: 0.4028\n",
            "Epoch 15/50 - 0.07s - loss: 1.0892 - acc: 0.3925 - val_loss: 1.0913 - val_acc: 0.3887\n",
            "Epoch 16/50 - 0.07s - loss: 1.0886 - acc: 0.3965 - val_loss: 1.0907 - val_acc: 0.4008\n",
            "Epoch 17/50 - 0.07s - loss: 1.0881 - acc: 0.3990 - val_loss: 1.0903 - val_acc: 0.3947\n",
            "Epoch 18/50 - 0.07s - loss: 1.0875 - acc: 0.4053 - val_loss: 1.0898 - val_acc: 0.3947\n",
            "Epoch 19/50 - 0.08s - loss: 1.0869 - acc: 0.4080 - val_loss: 1.0893 - val_acc: 0.3907\n",
            "Epoch 20/50 - 0.07s - loss: 1.0864 - acc: 0.4121 - val_loss: 1.0888 - val_acc: 0.4008\n",
            "Epoch 21/50 - 0.07s - loss: 1.0859 - acc: 0.4152 - val_loss: 1.0883 - val_acc: 0.4109\n",
            "Epoch 22/50 - 0.07s - loss: 1.0854 - acc: 0.4161 - val_loss: 1.0879 - val_acc: 0.4109\n",
            "Epoch 23/50 - 0.07s - loss: 1.0849 - acc: 0.4181 - val_loss: 1.0874 - val_acc: 0.4069\n",
            "Epoch 24/50 - 0.06s - loss: 1.0844 - acc: 0.4211 - val_loss: 1.0870 - val_acc: 0.4028\n",
            "Epoch 25/50 - 0.07s - loss: 1.0839 - acc: 0.4202 - val_loss: 1.0865 - val_acc: 0.4089\n",
            "Epoch 26/50 - 0.07s - loss: 1.0834 - acc: 0.4217 - val_loss: 1.0861 - val_acc: 0.4109\n",
            "Epoch 27/50 - 0.08s - loss: 1.0829 - acc: 0.4186 - val_loss: 1.0857 - val_acc: 0.4089\n",
            "Epoch 28/50 - 0.07s - loss: 1.0825 - acc: 0.4202 - val_loss: 1.0852 - val_acc: 0.4109\n",
            "Epoch 29/50 - 0.08s - loss: 1.0820 - acc: 0.4213 - val_loss: 1.0848 - val_acc: 0.4109\n",
            "Epoch 30/50 - 0.08s - loss: 1.0815 - acc: 0.4231 - val_loss: 1.0845 - val_acc: 0.4069\n",
            "Epoch 31/50 - 0.08s - loss: 1.0810 - acc: 0.4278 - val_loss: 1.0841 - val_acc: 0.4049\n",
            "Epoch 32/50 - 0.07s - loss: 1.0805 - acc: 0.4278 - val_loss: 1.0837 - val_acc: 0.4109\n",
            "Epoch 33/50 - 0.08s - loss: 1.0801 - acc: 0.4294 - val_loss: 1.0833 - val_acc: 0.4089\n",
            "Epoch 34/50 - 0.08s - loss: 1.0796 - acc: 0.4314 - val_loss: 1.0829 - val_acc: 0.4130\n",
            "Epoch 35/50 - 0.07s - loss: 1.0791 - acc: 0.4330 - val_loss: 1.0825 - val_acc: 0.4069\n",
            "Epoch 36/50 - 0.07s - loss: 1.0786 - acc: 0.4336 - val_loss: 1.0822 - val_acc: 0.4109\n",
            "Epoch 37/50 - 0.07s - loss: 1.0781 - acc: 0.4366 - val_loss: 1.0817 - val_acc: 0.4008\n",
            "Epoch 38/50 - 0.07s - loss: 1.0776 - acc: 0.4381 - val_loss: 1.0814 - val_acc: 0.4028\n",
            "Epoch 39/50 - 0.07s - loss: 1.0771 - acc: 0.4399 - val_loss: 1.0810 - val_acc: 0.4008\n",
            "Epoch 40/50 - 0.09s - loss: 1.0766 - acc: 0.4390 - val_loss: 1.0806 - val_acc: 0.4049\n",
            "Epoch 41/50 - 0.08s - loss: 1.0761 - acc: 0.4408 - val_loss: 1.0801 - val_acc: 0.4109\n",
            "Epoch 42/50 - 0.10s - loss: 1.0756 - acc: 0.4426 - val_loss: 1.0797 - val_acc: 0.4069\n",
            "Epoch 43/50 - 0.07s - loss: 1.0751 - acc: 0.4431 - val_loss: 1.0793 - val_acc: 0.4049\n",
            "Epoch 44/50 - 0.07s - loss: 1.0746 - acc: 0.4435 - val_loss: 1.0789 - val_acc: 0.4049\n",
            "Epoch 45/50 - 0.07s - loss: 1.0741 - acc: 0.4449 - val_loss: 1.0785 - val_acc: 0.4069\n",
            "Epoch 46/50 - 0.08s - loss: 1.0736 - acc: 0.4478 - val_loss: 1.0781 - val_acc: 0.4049\n",
            "Epoch 47/50 - 0.08s - loss: 1.0731 - acc: 0.4494 - val_loss: 1.0777 - val_acc: 0.4069\n",
            "Epoch 48/50 - 0.07s - loss: 1.0725 - acc: 0.4505 - val_loss: 1.0773 - val_acc: 0.4069\n",
            "Epoch 49/50 - 0.07s - loss: 1.0720 - acc: 0.4519 - val_loss: 1.0770 - val_acc: 0.4049\n",
            "Epoch 50/50 - 0.07s - loss: 1.0715 - acc: 0.4552 - val_loss: 1.0765 - val_acc: 0.4069\n",
            "\n",
            "Combination 155/252:\n",
            "Hidden Layers: [128, 64, 32], Activation: relu, Learning Rate: 0.001, Batch Size: 64, Epochs: 100\n",
            "Epoch 1/100 - 0.07s - loss: 1.1132 - acc: 0.3531 - val_loss: 1.1160 - val_acc: 0.3279\n",
            "Epoch 2/100 - 0.08s - loss: 1.1105 - acc: 0.3556 - val_loss: 1.1131 - val_acc: 0.3340\n",
            "Epoch 3/100 - 0.08s - loss: 1.1082 - acc: 0.3578 - val_loss: 1.1108 - val_acc: 0.3462\n",
            "Epoch 4/100 - 0.08s - loss: 1.1064 - acc: 0.3614 - val_loss: 1.1089 - val_acc: 0.3502\n",
            "Epoch 5/100 - 0.07s - loss: 1.1048 - acc: 0.3662 - val_loss: 1.1072 - val_acc: 0.3462\n",
            "Epoch 6/100 - 0.07s - loss: 1.1034 - acc: 0.3693 - val_loss: 1.1059 - val_acc: 0.3441\n",
            "Epoch 7/100 - 0.08s - loss: 1.1021 - acc: 0.3754 - val_loss: 1.1047 - val_acc: 0.3543\n",
            "Epoch 8/100 - 0.08s - loss: 1.1010 - acc: 0.3761 - val_loss: 1.1036 - val_acc: 0.3644\n",
            "Epoch 9/100 - 0.07s - loss: 1.1000 - acc: 0.3767 - val_loss: 1.1027 - val_acc: 0.3563\n",
            "Epoch 10/100 - 0.07s - loss: 1.0991 - acc: 0.3758 - val_loss: 1.1019 - val_acc: 0.3563\n",
            "Epoch 11/100 - 0.07s - loss: 1.0982 - acc: 0.3758 - val_loss: 1.1011 - val_acc: 0.3603\n",
            "Epoch 12/100 - 0.07s - loss: 1.0973 - acc: 0.3779 - val_loss: 1.1004 - val_acc: 0.3603\n",
            "Epoch 13/100 - 0.06s - loss: 1.0965 - acc: 0.3794 - val_loss: 1.0997 - val_acc: 0.3603\n",
            "Epoch 14/100 - 0.08s - loss: 1.0957 - acc: 0.3803 - val_loss: 1.0991 - val_acc: 0.3684\n",
            "Epoch 15/100 - 0.07s - loss: 1.0950 - acc: 0.3806 - val_loss: 1.0984 - val_acc: 0.3684\n",
            "Epoch 16/100 - 0.07s - loss: 1.0942 - acc: 0.3812 - val_loss: 1.0978 - val_acc: 0.3603\n",
            "Epoch 17/100 - 0.08s - loss: 1.0935 - acc: 0.3839 - val_loss: 1.0973 - val_acc: 0.3623\n",
            "Epoch 18/100 - 0.10s - loss: 1.0928 - acc: 0.3860 - val_loss: 1.0967 - val_acc: 0.3603\n",
            "Epoch 19/100 - 0.07s - loss: 1.0922 - acc: 0.3882 - val_loss: 1.0962 - val_acc: 0.3603\n",
            "Epoch 20/100 - 0.06s - loss: 1.0915 - acc: 0.3900 - val_loss: 1.0957 - val_acc: 0.3543\n",
            "Epoch 21/100 - 0.07s - loss: 1.0909 - acc: 0.3900 - val_loss: 1.0952 - val_acc: 0.3522\n",
            "Epoch 22/100 - 0.06s - loss: 1.0903 - acc: 0.3934 - val_loss: 1.0947 - val_acc: 0.3583\n",
            "Epoch 23/100 - 0.06s - loss: 1.0897 - acc: 0.3947 - val_loss: 1.0942 - val_acc: 0.3583\n",
            "Epoch 24/100 - 0.06s - loss: 1.0891 - acc: 0.3992 - val_loss: 1.0937 - val_acc: 0.3583\n",
            "Epoch 25/100 - 0.07s - loss: 1.0885 - acc: 0.4001 - val_loss: 1.0932 - val_acc: 0.3603\n",
            "Epoch 26/100 - 0.06s - loss: 1.0880 - acc: 0.4022 - val_loss: 1.0927 - val_acc: 0.3583\n",
            "Epoch 27/100 - 0.06s - loss: 1.0875 - acc: 0.4049 - val_loss: 1.0923 - val_acc: 0.3563\n",
            "Epoch 28/100 - 0.06s - loss: 1.0869 - acc: 0.4049 - val_loss: 1.0918 - val_acc: 0.3522\n",
            "Epoch 29/100 - 0.06s - loss: 1.0864 - acc: 0.4060 - val_loss: 1.0914 - val_acc: 0.3543\n",
            "Epoch 30/100 - 0.06s - loss: 1.0859 - acc: 0.4078 - val_loss: 1.0910 - val_acc: 0.3543\n",
            "Epoch 31/100 - 0.06s - loss: 1.0854 - acc: 0.4080 - val_loss: 1.0906 - val_acc: 0.3543\n",
            "Epoch 32/100 - 0.06s - loss: 1.0849 - acc: 0.4107 - val_loss: 1.0902 - val_acc: 0.3563\n",
            "Epoch 33/100 - 0.06s - loss: 1.0845 - acc: 0.4130 - val_loss: 1.0898 - val_acc: 0.3664\n",
            "Epoch 34/100 - 0.07s - loss: 1.0840 - acc: 0.4127 - val_loss: 1.0894 - val_acc: 0.3725\n",
            "Epoch 35/100 - 0.07s - loss: 1.0835 - acc: 0.4154 - val_loss: 1.0891 - val_acc: 0.3704\n",
            "Epoch 36/100 - 0.06s - loss: 1.0831 - acc: 0.4170 - val_loss: 1.0887 - val_acc: 0.3664\n",
            "Epoch 37/100 - 0.06s - loss: 1.0826 - acc: 0.4202 - val_loss: 1.0883 - val_acc: 0.3704\n",
            "Epoch 38/100 - 0.06s - loss: 1.0821 - acc: 0.4188 - val_loss: 1.0880 - val_acc: 0.3745\n",
            "Epoch 39/100 - 0.07s - loss: 1.0817 - acc: 0.4181 - val_loss: 1.0877 - val_acc: 0.3745\n",
            "Epoch 40/100 - 0.06s - loss: 1.0812 - acc: 0.4213 - val_loss: 1.0874 - val_acc: 0.3725\n",
            "Epoch 41/100 - 0.06s - loss: 1.0807 - acc: 0.4240 - val_loss: 1.0871 - val_acc: 0.3684\n",
            "Epoch 42/100 - 0.06s - loss: 1.0803 - acc: 0.4240 - val_loss: 1.0868 - val_acc: 0.3725\n",
            "Epoch 43/100 - 0.07s - loss: 1.0798 - acc: 0.4262 - val_loss: 1.0865 - val_acc: 0.3704\n",
            "Epoch 44/100 - 0.06s - loss: 1.0794 - acc: 0.4276 - val_loss: 1.0863 - val_acc: 0.3725\n",
            "Epoch 45/100 - 0.06s - loss: 1.0790 - acc: 0.4309 - val_loss: 1.0860 - val_acc: 0.3704\n",
            "Epoch 46/100 - 0.06s - loss: 1.0785 - acc: 0.4325 - val_loss: 1.0857 - val_acc: 0.3684\n",
            "Epoch 47/100 - 0.06s - loss: 1.0781 - acc: 0.4330 - val_loss: 1.0854 - val_acc: 0.3725\n",
            "Epoch 48/100 - 0.06s - loss: 1.0777 - acc: 0.4343 - val_loss: 1.0851 - val_acc: 0.3725\n",
            "Epoch 49/100 - 0.06s - loss: 1.0773 - acc: 0.4343 - val_loss: 1.0849 - val_acc: 0.3745\n",
            "Epoch 50/100 - 0.06s - loss: 1.0769 - acc: 0.4343 - val_loss: 1.0846 - val_acc: 0.3745\n",
            "Epoch 51/100 - 0.07s - loss: 1.0765 - acc: 0.4354 - val_loss: 1.0844 - val_acc: 0.3765\n",
            "Epoch 52/100 - 0.09s - loss: 1.0761 - acc: 0.4354 - val_loss: 1.0841 - val_acc: 0.3887\n",
            "Epoch 53/100 - 0.06s - loss: 1.0757 - acc: 0.4370 - val_loss: 1.0839 - val_acc: 0.3887\n",
            "Epoch 54/100 - 0.06s - loss: 1.0753 - acc: 0.4384 - val_loss: 1.0836 - val_acc: 0.3866\n",
            "Epoch 55/100 - 0.06s - loss: 1.0749 - acc: 0.4413 - val_loss: 1.0834 - val_acc: 0.3826\n",
            "Epoch 56/100 - 0.07s - loss: 1.0745 - acc: 0.4447 - val_loss: 1.0832 - val_acc: 0.3866\n",
            "Epoch 57/100 - 0.07s - loss: 1.0741 - acc: 0.4460 - val_loss: 1.0829 - val_acc: 0.3887\n",
            "Epoch 58/100 - 0.06s - loss: 1.0737 - acc: 0.4474 - val_loss: 1.0827 - val_acc: 0.3927\n",
            "Epoch 59/100 - 0.07s - loss: 1.0733 - acc: 0.4489 - val_loss: 1.0825 - val_acc: 0.3927\n",
            "Epoch 60/100 - 0.06s - loss: 1.0729 - acc: 0.4487 - val_loss: 1.0822 - val_acc: 0.3907\n",
            "Epoch 61/100 - 0.06s - loss: 1.0725 - acc: 0.4496 - val_loss: 1.0820 - val_acc: 0.3968\n",
            "Epoch 62/100 - 0.06s - loss: 1.0721 - acc: 0.4510 - val_loss: 1.0817 - val_acc: 0.3988\n",
            "Epoch 63/100 - 0.06s - loss: 1.0718 - acc: 0.4512 - val_loss: 1.0815 - val_acc: 0.3927\n",
            "Epoch 64/100 - 0.06s - loss: 1.0714 - acc: 0.4519 - val_loss: 1.0812 - val_acc: 0.3947\n",
            "Epoch 65/100 - 0.06s - loss: 1.0710 - acc: 0.4525 - val_loss: 1.0810 - val_acc: 0.3988\n",
            "Epoch 66/100 - 0.06s - loss: 1.0706 - acc: 0.4523 - val_loss: 1.0808 - val_acc: 0.3988\n",
            "Epoch 67/100 - 0.06s - loss: 1.0702 - acc: 0.4541 - val_loss: 1.0806 - val_acc: 0.4028\n",
            "Epoch 68/100 - 0.07s - loss: 1.0698 - acc: 0.4546 - val_loss: 1.0803 - val_acc: 0.4008\n",
            "Epoch 69/100 - 0.06s - loss: 1.0694 - acc: 0.4557 - val_loss: 1.0801 - val_acc: 0.4008\n",
            "Epoch 70/100 - 0.06s - loss: 1.0691 - acc: 0.4575 - val_loss: 1.0798 - val_acc: 0.4008\n",
            "Epoch 71/100 - 0.06s - loss: 1.0687 - acc: 0.4591 - val_loss: 1.0796 - val_acc: 0.4028\n",
            "Epoch 72/100 - 0.06s - loss: 1.0683 - acc: 0.4602 - val_loss: 1.0794 - val_acc: 0.4008\n",
            "Epoch 73/100 - 0.06s - loss: 1.0679 - acc: 0.4624 - val_loss: 1.0791 - val_acc: 0.4028\n",
            "Epoch 74/100 - 0.06s - loss: 1.0675 - acc: 0.4624 - val_loss: 1.0788 - val_acc: 0.4028\n",
            "Epoch 75/100 - 0.06s - loss: 1.0671 - acc: 0.4615 - val_loss: 1.0786 - val_acc: 0.4028\n",
            "Epoch 76/100 - 0.06s - loss: 1.0668 - acc: 0.4622 - val_loss: 1.0784 - val_acc: 0.4049\n",
            "Epoch 77/100 - 0.06s - loss: 1.0664 - acc: 0.4649 - val_loss: 1.0781 - val_acc: 0.4049\n",
            "Epoch 78/100 - 0.06s - loss: 1.0660 - acc: 0.4633 - val_loss: 1.0779 - val_acc: 0.4069\n",
            "Epoch 79/100 - 0.06s - loss: 1.0656 - acc: 0.4647 - val_loss: 1.0777 - val_acc: 0.4109\n",
            "Epoch 80/100 - 0.06s - loss: 1.0652 - acc: 0.4672 - val_loss: 1.0774 - val_acc: 0.4089\n",
            "Epoch 81/100 - 0.06s - loss: 1.0648 - acc: 0.4676 - val_loss: 1.0771 - val_acc: 0.4069\n",
            "Epoch 82/100 - 0.06s - loss: 1.0644 - acc: 0.4681 - val_loss: 1.0769 - val_acc: 0.4089\n",
            "Epoch 83/100 - 0.07s - loss: 1.0640 - acc: 0.4685 - val_loss: 1.0766 - val_acc: 0.4089\n",
            "Epoch 84/100 - 0.07s - loss: 1.0636 - acc: 0.4701 - val_loss: 1.0764 - val_acc: 0.4069\n",
            "Epoch 85/100 - 0.06s - loss: 1.0632 - acc: 0.4701 - val_loss: 1.0762 - val_acc: 0.4069\n",
            "Epoch 86/100 - 0.06s - loss: 1.0628 - acc: 0.4705 - val_loss: 1.0759 - val_acc: 0.4130\n",
            "Epoch 87/100 - 0.08s - loss: 1.0624 - acc: 0.4710 - val_loss: 1.0756 - val_acc: 0.4130\n",
            "Epoch 88/100 - 0.06s - loss: 1.0620 - acc: 0.4728 - val_loss: 1.0754 - val_acc: 0.4150\n",
            "Epoch 89/100 - 0.06s - loss: 1.0616 - acc: 0.4723 - val_loss: 1.0752 - val_acc: 0.4190\n",
            "Epoch 90/100 - 0.06s - loss: 1.0612 - acc: 0.4726 - val_loss: 1.0749 - val_acc: 0.4271\n",
            "Epoch 91/100 - 0.07s - loss: 1.0608 - acc: 0.4732 - val_loss: 1.0747 - val_acc: 0.4271\n",
            "Epoch 92/100 - 0.06s - loss: 1.0604 - acc: 0.4732 - val_loss: 1.0744 - val_acc: 0.4312\n",
            "Epoch 93/100 - 0.06s - loss: 1.0600 - acc: 0.4726 - val_loss: 1.0742 - val_acc: 0.4332\n",
            "Epoch 94/100 - 0.06s - loss: 1.0595 - acc: 0.4726 - val_loss: 1.0739 - val_acc: 0.4332\n",
            "Epoch 95/100 - 0.06s - loss: 1.0591 - acc: 0.4737 - val_loss: 1.0736 - val_acc: 0.4332\n",
            "Epoch 96/100 - 0.06s - loss: 1.0587 - acc: 0.4739 - val_loss: 1.0733 - val_acc: 0.4312\n",
            "Epoch 97/100 - 0.06s - loss: 1.0583 - acc: 0.4746 - val_loss: 1.0730 - val_acc: 0.4312\n",
            "Epoch 98/100 - 0.06s - loss: 1.0579 - acc: 0.4728 - val_loss: 1.0728 - val_acc: 0.4271\n",
            "Epoch 99/100 - 0.07s - loss: 1.0575 - acc: 0.4753 - val_loss: 1.0725 - val_acc: 0.4271\n",
            "Epoch 100/100 - 0.06s - loss: 1.0571 - acc: 0.4753 - val_loss: 1.0723 - val_acc: 0.4312\n",
            "\n",
            "Combination 156/252:\n",
            "Hidden Layers: [128, 64, 32], Activation: relu, Learning Rate: 0.001, Batch Size: 64, Epochs: 150\n",
            "Epoch 1/150 - 0.06s - loss: 1.0995 - acc: 0.3297 - val_loss: 1.1001 - val_acc: 0.3583\n",
            "Epoch 2/150 - 0.06s - loss: 1.0987 - acc: 0.3342 - val_loss: 1.0993 - val_acc: 0.3623\n",
            "Epoch 3/150 - 0.07s - loss: 1.0979 - acc: 0.3394 - val_loss: 1.0986 - val_acc: 0.3664\n",
            "Epoch 4/150 - 0.06s - loss: 1.0971 - acc: 0.3448 - val_loss: 1.0979 - val_acc: 0.3704\n",
            "Epoch 5/150 - 0.06s - loss: 1.0964 - acc: 0.3498 - val_loss: 1.0973 - val_acc: 0.3704\n",
            "Epoch 6/150 - 0.06s - loss: 1.0957 - acc: 0.3527 - val_loss: 1.0967 - val_acc: 0.3785\n",
            "Epoch 7/150 - 0.07s - loss: 1.0951 - acc: 0.3610 - val_loss: 1.0962 - val_acc: 0.3785\n",
            "Epoch 8/150 - 0.06s - loss: 1.0945 - acc: 0.3653 - val_loss: 1.0957 - val_acc: 0.3826\n",
            "Epoch 9/150 - 0.06s - loss: 1.0938 - acc: 0.3716 - val_loss: 1.0952 - val_acc: 0.3745\n",
            "Epoch 10/150 - 0.06s - loss: 1.0932 - acc: 0.3797 - val_loss: 1.0947 - val_acc: 0.3785\n",
            "Epoch 11/150 - 0.07s - loss: 1.0927 - acc: 0.3842 - val_loss: 1.0943 - val_acc: 0.3745\n",
            "Epoch 12/150 - 0.06s - loss: 1.0921 - acc: 0.3878 - val_loss: 1.0939 - val_acc: 0.3846\n",
            "Epoch 13/150 - 0.06s - loss: 1.0915 - acc: 0.3945 - val_loss: 1.0934 - val_acc: 0.3785\n",
            "Epoch 14/150 - 0.06s - loss: 1.0909 - acc: 0.3965 - val_loss: 1.0929 - val_acc: 0.3806\n",
            "Epoch 15/150 - 0.07s - loss: 1.0904 - acc: 0.4001 - val_loss: 1.0925 - val_acc: 0.3846\n",
            "Epoch 16/150 - 0.06s - loss: 1.0898 - acc: 0.4019 - val_loss: 1.0921 - val_acc: 0.3785\n",
            "Epoch 17/150 - 0.06s - loss: 1.0893 - acc: 0.4033 - val_loss: 1.0917 - val_acc: 0.3826\n",
            "Epoch 18/150 - 0.06s - loss: 1.0888 - acc: 0.4051 - val_loss: 1.0913 - val_acc: 0.3826\n",
            "Epoch 19/150 - 0.07s - loss: 1.0882 - acc: 0.4082 - val_loss: 1.0910 - val_acc: 0.3745\n",
            "Epoch 20/150 - 0.06s - loss: 1.0877 - acc: 0.4089 - val_loss: 1.0906 - val_acc: 0.3846\n",
            "Epoch 21/150 - 0.06s - loss: 1.0872 - acc: 0.4091 - val_loss: 1.0902 - val_acc: 0.3846\n",
            "Epoch 22/150 - 0.06s - loss: 1.0867 - acc: 0.4096 - val_loss: 1.0899 - val_acc: 0.3826\n",
            "Epoch 23/150 - 0.08s - loss: 1.0861 - acc: 0.4114 - val_loss: 1.0895 - val_acc: 0.3846\n",
            "Epoch 24/150 - 0.09s - loss: 1.0856 - acc: 0.4166 - val_loss: 1.0891 - val_acc: 0.3927\n",
            "Epoch 25/150 - 0.06s - loss: 1.0851 - acc: 0.4175 - val_loss: 1.0887 - val_acc: 0.3968\n",
            "Epoch 26/150 - 0.06s - loss: 1.0846 - acc: 0.4186 - val_loss: 1.0884 - val_acc: 0.3968\n",
            "Epoch 27/150 - 0.07s - loss: 1.0841 - acc: 0.4202 - val_loss: 1.0880 - val_acc: 0.3968\n",
            "Epoch 28/150 - 0.06s - loss: 1.0836 - acc: 0.4213 - val_loss: 1.0876 - val_acc: 0.4008\n",
            "Epoch 29/150 - 0.06s - loss: 1.0831 - acc: 0.4222 - val_loss: 1.0872 - val_acc: 0.4049\n",
            "Epoch 30/150 - 0.07s - loss: 1.0825 - acc: 0.4238 - val_loss: 1.0868 - val_acc: 0.4049\n",
            "Epoch 31/150 - 0.06s - loss: 1.0820 - acc: 0.4258 - val_loss: 1.0864 - val_acc: 0.4130\n",
            "Epoch 32/150 - 0.06s - loss: 1.0815 - acc: 0.4258 - val_loss: 1.0860 - val_acc: 0.4150\n",
            "Epoch 33/150 - 0.06s - loss: 1.0810 - acc: 0.4256 - val_loss: 1.0856 - val_acc: 0.4130\n",
            "Epoch 34/150 - 0.06s - loss: 1.0805 - acc: 0.4271 - val_loss: 1.0852 - val_acc: 0.4190\n",
            "Epoch 35/150 - 0.07s - loss: 1.0800 - acc: 0.4280 - val_loss: 1.0849 - val_acc: 0.4231\n",
            "Epoch 36/150 - 0.06s - loss: 1.0795 - acc: 0.4287 - val_loss: 1.0846 - val_acc: 0.4211\n",
            "Epoch 37/150 - 0.07s - loss: 1.0790 - acc: 0.4303 - val_loss: 1.0842 - val_acc: 0.4251\n",
            "Epoch 38/150 - 0.07s - loss: 1.0785 - acc: 0.4309 - val_loss: 1.0839 - val_acc: 0.4251\n",
            "Epoch 39/150 - 0.06s - loss: 1.0780 - acc: 0.4312 - val_loss: 1.0836 - val_acc: 0.4271\n",
            "Epoch 40/150 - 0.06s - loss: 1.0774 - acc: 0.4323 - val_loss: 1.0832 - val_acc: 0.4251\n",
            "Epoch 41/150 - 0.06s - loss: 1.0769 - acc: 0.4354 - val_loss: 1.0829 - val_acc: 0.4271\n",
            "Epoch 42/150 - 0.07s - loss: 1.0764 - acc: 0.4366 - val_loss: 1.0825 - val_acc: 0.4231\n",
            "Epoch 43/150 - 0.06s - loss: 1.0759 - acc: 0.4381 - val_loss: 1.0822 - val_acc: 0.4251\n",
            "Epoch 44/150 - 0.06s - loss: 1.0754 - acc: 0.4390 - val_loss: 1.0818 - val_acc: 0.4251\n",
            "Epoch 45/150 - 0.06s - loss: 1.0749 - acc: 0.4413 - val_loss: 1.0815 - val_acc: 0.4271\n",
            "Epoch 46/150 - 0.07s - loss: 1.0743 - acc: 0.4426 - val_loss: 1.0812 - val_acc: 0.4271\n",
            "Epoch 47/150 - 0.06s - loss: 1.0738 - acc: 0.4402 - val_loss: 1.0808 - val_acc: 0.4291\n",
            "Epoch 48/150 - 0.06s - loss: 1.0733 - acc: 0.4404 - val_loss: 1.0804 - val_acc: 0.4271\n",
            "Epoch 49/150 - 0.06s - loss: 1.0728 - acc: 0.4424 - val_loss: 1.0801 - val_acc: 0.4251\n",
            "Epoch 50/150 - 0.06s - loss: 1.0723 - acc: 0.4426 - val_loss: 1.0797 - val_acc: 0.4251\n",
            "Epoch 51/150 - 0.06s - loss: 1.0718 - acc: 0.4440 - val_loss: 1.0793 - val_acc: 0.4231\n",
            "Epoch 52/150 - 0.06s - loss: 1.0713 - acc: 0.4456 - val_loss: 1.0790 - val_acc: 0.4211\n",
            "Epoch 53/150 - 0.06s - loss: 1.0708 - acc: 0.4458 - val_loss: 1.0787 - val_acc: 0.4190\n",
            "Epoch 54/150 - 0.07s - loss: 1.0703 - acc: 0.4462 - val_loss: 1.0783 - val_acc: 0.4251\n",
            "Epoch 55/150 - 0.06s - loss: 1.0698 - acc: 0.4456 - val_loss: 1.0780 - val_acc: 0.4271\n",
            "Epoch 56/150 - 0.06s - loss: 1.0692 - acc: 0.4460 - val_loss: 1.0777 - val_acc: 0.4231\n",
            "Epoch 57/150 - 0.06s - loss: 1.0687 - acc: 0.4469 - val_loss: 1.0774 - val_acc: 0.4231\n",
            "Epoch 58/150 - 0.06s - loss: 1.0682 - acc: 0.4492 - val_loss: 1.0771 - val_acc: 0.4211\n",
            "Epoch 59/150 - 0.06s - loss: 1.0677 - acc: 0.4487 - val_loss: 1.0768 - val_acc: 0.4231\n",
            "Epoch 60/150 - 0.06s - loss: 1.0672 - acc: 0.4496 - val_loss: 1.0765 - val_acc: 0.4190\n",
            "Epoch 61/150 - 0.07s - loss: 1.0667 - acc: 0.4507 - val_loss: 1.0762 - val_acc: 0.4231\n",
            "Epoch 62/150 - 0.07s - loss: 1.0662 - acc: 0.4510 - val_loss: 1.0759 - val_acc: 0.4190\n",
            "Epoch 63/150 - 0.06s - loss: 1.0657 - acc: 0.4512 - val_loss: 1.0756 - val_acc: 0.4211\n",
            "Epoch 64/150 - 0.06s - loss: 1.0652 - acc: 0.4514 - val_loss: 1.0753 - val_acc: 0.4211\n",
            "Epoch 65/150 - 0.06s - loss: 1.0648 - acc: 0.4516 - val_loss: 1.0751 - val_acc: 0.4231\n",
            "Epoch 66/150 - 0.06s - loss: 1.0643 - acc: 0.4514 - val_loss: 1.0747 - val_acc: 0.4251\n",
            "Epoch 67/150 - 0.06s - loss: 1.0638 - acc: 0.4512 - val_loss: 1.0744 - val_acc: 0.4251\n",
            "Epoch 68/150 - 0.06s - loss: 1.0633 - acc: 0.4521 - val_loss: 1.0741 - val_acc: 0.4271\n",
            "Epoch 69/150 - 0.06s - loss: 1.0628 - acc: 0.4534 - val_loss: 1.0739 - val_acc: 0.4251\n",
            "Epoch 70/150 - 0.07s - loss: 1.0624 - acc: 0.4548 - val_loss: 1.0736 - val_acc: 0.4251\n",
            "Epoch 71/150 - 0.06s - loss: 1.0619 - acc: 0.4573 - val_loss: 1.0734 - val_acc: 0.4251\n",
            "Epoch 72/150 - 0.06s - loss: 1.0614 - acc: 0.4577 - val_loss: 1.0730 - val_acc: 0.4251\n",
            "Epoch 73/150 - 0.06s - loss: 1.0610 - acc: 0.4577 - val_loss: 1.0727 - val_acc: 0.4190\n",
            "Epoch 74/150 - 0.06s - loss: 1.0605 - acc: 0.4573 - val_loss: 1.0724 - val_acc: 0.4190\n",
            "Epoch 75/150 - 0.06s - loss: 1.0601 - acc: 0.4573 - val_loss: 1.0721 - val_acc: 0.4312\n",
            "Epoch 76/150 - 0.06s - loss: 1.0596 - acc: 0.4586 - val_loss: 1.0718 - val_acc: 0.4251\n",
            "Epoch 77/150 - 0.06s - loss: 1.0592 - acc: 0.4582 - val_loss: 1.0715 - val_acc: 0.4251\n",
            "Epoch 78/150 - 0.06s - loss: 1.0587 - acc: 0.4586 - val_loss: 1.0713 - val_acc: 0.4251\n",
            "Epoch 79/150 - 0.06s - loss: 1.0583 - acc: 0.4595 - val_loss: 1.0710 - val_acc: 0.4291\n",
            "Epoch 80/150 - 0.06s - loss: 1.0578 - acc: 0.4613 - val_loss: 1.0707 - val_acc: 0.4271\n",
            "Epoch 81/150 - 0.06s - loss: 1.0574 - acc: 0.4622 - val_loss: 1.0704 - val_acc: 0.4251\n",
            "Epoch 82/150 - 0.07s - loss: 1.0570 - acc: 0.4613 - val_loss: 1.0701 - val_acc: 0.4291\n",
            "Epoch 83/150 - 0.06s - loss: 1.0565 - acc: 0.4618 - val_loss: 1.0699 - val_acc: 0.4251\n",
            "Epoch 84/150 - 0.06s - loss: 1.0561 - acc: 0.4624 - val_loss: 1.0696 - val_acc: 0.4251\n",
            "Epoch 85/150 - 0.07s - loss: 1.0556 - acc: 0.4645 - val_loss: 1.0694 - val_acc: 0.4291\n",
            "Epoch 86/150 - 0.09s - loss: 1.0552 - acc: 0.4640 - val_loss: 1.0692 - val_acc: 0.4291\n",
            "Epoch 87/150 - 0.09s - loss: 1.0548 - acc: 0.4636 - val_loss: 1.0689 - val_acc: 0.4291\n",
            "Epoch 88/150 - 0.06s - loss: 1.0544 - acc: 0.4638 - val_loss: 1.0686 - val_acc: 0.4291\n",
            "Epoch 89/150 - 0.06s - loss: 1.0539 - acc: 0.4629 - val_loss: 1.0684 - val_acc: 0.4312\n",
            "Epoch 90/150 - 0.07s - loss: 1.0535 - acc: 0.4642 - val_loss: 1.0682 - val_acc: 0.4271\n",
            "Epoch 91/150 - 0.06s - loss: 1.0531 - acc: 0.4642 - val_loss: 1.0679 - val_acc: 0.4312\n",
            "Epoch 92/150 - 0.06s - loss: 1.0527 - acc: 0.4640 - val_loss: 1.0677 - val_acc: 0.4312\n",
            "Epoch 93/150 - 0.07s - loss: 1.0523 - acc: 0.4649 - val_loss: 1.0674 - val_acc: 0.4332\n",
            "Epoch 94/150 - 0.08s - loss: 1.0519 - acc: 0.4660 - val_loss: 1.0672 - val_acc: 0.4332\n",
            "Epoch 95/150 - 0.06s - loss: 1.0515 - acc: 0.4676 - val_loss: 1.0670 - val_acc: 0.4393\n",
            "Epoch 96/150 - 0.06s - loss: 1.0512 - acc: 0.4672 - val_loss: 1.0668 - val_acc: 0.4393\n",
            "Epoch 97/150 - 0.06s - loss: 1.0508 - acc: 0.4678 - val_loss: 1.0665 - val_acc: 0.4393\n",
            "Epoch 98/150 - 0.06s - loss: 1.0504 - acc: 0.4676 - val_loss: 1.0663 - val_acc: 0.4372\n",
            "Epoch 99/150 - 0.06s - loss: 1.0500 - acc: 0.4678 - val_loss: 1.0661 - val_acc: 0.4393\n",
            "Epoch 100/150 - 0.07s - loss: 1.0496 - acc: 0.4681 - val_loss: 1.0659 - val_acc: 0.4393\n",
            "Epoch 101/150 - 0.08s - loss: 1.0493 - acc: 0.4690 - val_loss: 1.0657 - val_acc: 0.4413\n",
            "Epoch 102/150 - 0.06s - loss: 1.0489 - acc: 0.4696 - val_loss: 1.0654 - val_acc: 0.4393\n",
            "Epoch 103/150 - 0.06s - loss: 1.0486 - acc: 0.4699 - val_loss: 1.0651 - val_acc: 0.4312\n",
            "Epoch 104/150 - 0.06s - loss: 1.0482 - acc: 0.4712 - val_loss: 1.0650 - val_acc: 0.4372\n",
            "Epoch 105/150 - 0.06s - loss: 1.0478 - acc: 0.4714 - val_loss: 1.0647 - val_acc: 0.4332\n",
            "Epoch 106/150 - 0.06s - loss: 1.0474 - acc: 0.4717 - val_loss: 1.0645 - val_acc: 0.4372\n",
            "Epoch 107/150 - 0.06s - loss: 1.0471 - acc: 0.4726 - val_loss: 1.0643 - val_acc: 0.4372\n",
            "Epoch 108/150 - 0.06s - loss: 1.0467 - acc: 0.4708 - val_loss: 1.0642 - val_acc: 0.4413\n",
            "Epoch 109/150 - 0.07s - loss: 1.0464 - acc: 0.4732 - val_loss: 1.0639 - val_acc: 0.4372\n",
            "Epoch 110/150 - 0.06s - loss: 1.0460 - acc: 0.4732 - val_loss: 1.0637 - val_acc: 0.4372\n",
            "Epoch 111/150 - 0.06s - loss: 1.0457 - acc: 0.4732 - val_loss: 1.0634 - val_acc: 0.4352\n",
            "Epoch 112/150 - 0.06s - loss: 1.0453 - acc: 0.4735 - val_loss: 1.0633 - val_acc: 0.4413\n",
            "Epoch 113/150 - 0.06s - loss: 1.0450 - acc: 0.4739 - val_loss: 1.0631 - val_acc: 0.4372\n",
            "Epoch 114/150 - 0.06s - loss: 1.0447 - acc: 0.4748 - val_loss: 1.0629 - val_acc: 0.4352\n",
            "Epoch 115/150 - 0.06s - loss: 1.0443 - acc: 0.4753 - val_loss: 1.0627 - val_acc: 0.4372\n",
            "Epoch 116/150 - 0.06s - loss: 1.0440 - acc: 0.4748 - val_loss: 1.0624 - val_acc: 0.4393\n",
            "Epoch 117/150 - 0.07s - loss: 1.0436 - acc: 0.4757 - val_loss: 1.0622 - val_acc: 0.4372\n",
            "Epoch 118/150 - 0.07s - loss: 1.0433 - acc: 0.4744 - val_loss: 1.0619 - val_acc: 0.4372\n",
            "Epoch 119/150 - 0.06s - loss: 1.0430 - acc: 0.4753 - val_loss: 1.0617 - val_acc: 0.4352\n",
            "Epoch 120/150 - 0.06s - loss: 1.0426 - acc: 0.4757 - val_loss: 1.0616 - val_acc: 0.4352\n",
            "Epoch 121/150 - 0.06s - loss: 1.0423 - acc: 0.4768 - val_loss: 1.0614 - val_acc: 0.4352\n",
            "Epoch 122/150 - 0.06s - loss: 1.0420 - acc: 0.4782 - val_loss: 1.0612 - val_acc: 0.4372\n",
            "Epoch 123/150 - 0.06s - loss: 1.0416 - acc: 0.4777 - val_loss: 1.0611 - val_acc: 0.4372\n",
            "Epoch 124/150 - 0.06s - loss: 1.0413 - acc: 0.4768 - val_loss: 1.0607 - val_acc: 0.4372\n",
            "Epoch 125/150 - 0.07s - loss: 1.0410 - acc: 0.4780 - val_loss: 1.0606 - val_acc: 0.4393\n",
            "Epoch 126/150 - 0.06s - loss: 1.0406 - acc: 0.4780 - val_loss: 1.0604 - val_acc: 0.4393\n",
            "Epoch 127/150 - 0.06s - loss: 1.0403 - acc: 0.4775 - val_loss: 1.0601 - val_acc: 0.4393\n",
            "Epoch 128/150 - 0.06s - loss: 1.0399 - acc: 0.4780 - val_loss: 1.0600 - val_acc: 0.4413\n",
            "Epoch 129/150 - 0.06s - loss: 1.0396 - acc: 0.4780 - val_loss: 1.0597 - val_acc: 0.4393\n",
            "Epoch 130/150 - 0.06s - loss: 1.0393 - acc: 0.4773 - val_loss: 1.0596 - val_acc: 0.4393\n",
            "Epoch 131/150 - 0.06s - loss: 1.0390 - acc: 0.4793 - val_loss: 1.0595 - val_acc: 0.4413\n",
            "Epoch 132/150 - 0.07s - loss: 1.0386 - acc: 0.4798 - val_loss: 1.0593 - val_acc: 0.4413\n",
            "Epoch 133/150 - 0.07s - loss: 1.0383 - acc: 0.4780 - val_loss: 1.0590 - val_acc: 0.4372\n",
            "Epoch 134/150 - 0.06s - loss: 1.0380 - acc: 0.4789 - val_loss: 1.0588 - val_acc: 0.4332\n",
            "Epoch 135/150 - 0.06s - loss: 1.0377 - acc: 0.4798 - val_loss: 1.0585 - val_acc: 0.4352\n",
            "Epoch 136/150 - 0.06s - loss: 1.0373 - acc: 0.4789 - val_loss: 1.0584 - val_acc: 0.4352\n",
            "Epoch 137/150 - 0.06s - loss: 1.0370 - acc: 0.4795 - val_loss: 1.0582 - val_acc: 0.4352\n",
            "Epoch 138/150 - 0.07s - loss: 1.0367 - acc: 0.4804 - val_loss: 1.0580 - val_acc: 0.4352\n",
            "Epoch 139/150 - 0.06s - loss: 1.0363 - acc: 0.4809 - val_loss: 1.0578 - val_acc: 0.4372\n",
            "Epoch 140/150 - 0.06s - loss: 1.0360 - acc: 0.4809 - val_loss: 1.0576 - val_acc: 0.4372\n",
            "Epoch 141/150 - 0.06s - loss: 1.0357 - acc: 0.4813 - val_loss: 1.0575 - val_acc: 0.4372\n",
            "Epoch 142/150 - 0.06s - loss: 1.0354 - acc: 0.4813 - val_loss: 1.0573 - val_acc: 0.4372\n",
            "Epoch 143/150 - 0.06s - loss: 1.0350 - acc: 0.4818 - val_loss: 1.0571 - val_acc: 0.4393\n",
            "Epoch 144/150 - 0.06s - loss: 1.0347 - acc: 0.4836 - val_loss: 1.0569 - val_acc: 0.4393\n",
            "Epoch 145/150 - 0.06s - loss: 1.0344 - acc: 0.4838 - val_loss: 1.0568 - val_acc: 0.4372\n",
            "Epoch 146/150 - 0.06s - loss: 1.0341 - acc: 0.4822 - val_loss: 1.0565 - val_acc: 0.4372\n",
            "Epoch 147/150 - 0.05s - loss: 1.0337 - acc: 0.4836 - val_loss: 1.0563 - val_acc: 0.4393\n",
            "Epoch 148/150 - 0.06s - loss: 1.0334 - acc: 0.4845 - val_loss: 1.0561 - val_acc: 0.4393\n",
            "Epoch 149/150 - 0.06s - loss: 1.0331 - acc: 0.4829 - val_loss: 1.0560 - val_acc: 0.4372\n",
            "Epoch 150/150 - 0.06s - loss: 1.0328 - acc: 0.4872 - val_loss: 1.0559 - val_acc: 0.4393\n",
            "\n",
            "Combination 157/252:\n",
            "Hidden Layers: [128, 64, 32], Activation: relu, Learning Rate: 0.0001, Batch Size: 32, Epochs: 50\n",
            "Epoch 1/50 - 0.07s - loss: 1.1056 - acc: 0.3507 - val_loss: 1.1058 - val_acc: 0.3603\n",
            "Epoch 2/50 - 0.07s - loss: 1.1051 - acc: 0.3527 - val_loss: 1.1052 - val_acc: 0.3543\n",
            "Epoch 3/50 - 0.07s - loss: 1.1046 - acc: 0.3527 - val_loss: 1.1046 - val_acc: 0.3543\n",
            "Epoch 4/50 - 0.07s - loss: 1.1042 - acc: 0.3525 - val_loss: 1.1041 - val_acc: 0.3583\n",
            "Epoch 5/50 - 0.10s - loss: 1.1037 - acc: 0.3531 - val_loss: 1.1036 - val_acc: 0.3583\n",
            "Epoch 6/50 - 0.08s - loss: 1.1033 - acc: 0.3538 - val_loss: 1.1031 - val_acc: 0.3583\n",
            "Epoch 7/50 - 0.07s - loss: 1.1030 - acc: 0.3552 - val_loss: 1.1027 - val_acc: 0.3623\n",
            "Epoch 8/50 - 0.07s - loss: 1.1026 - acc: 0.3561 - val_loss: 1.1022 - val_acc: 0.3623\n",
            "Epoch 9/50 - 0.07s - loss: 1.1023 - acc: 0.3567 - val_loss: 1.1018 - val_acc: 0.3664\n",
            "Epoch 10/50 - 0.08s - loss: 1.1020 - acc: 0.3581 - val_loss: 1.1014 - val_acc: 0.3644\n",
            "Epoch 11/50 - 0.07s - loss: 1.1017 - acc: 0.3599 - val_loss: 1.1011 - val_acc: 0.3603\n",
            "Epoch 12/50 - 0.10s - loss: 1.1014 - acc: 0.3590 - val_loss: 1.1007 - val_acc: 0.3603\n",
            "Epoch 13/50 - 0.07s - loss: 1.1011 - acc: 0.3601 - val_loss: 1.1004 - val_acc: 0.3623\n",
            "Epoch 14/50 - 0.08s - loss: 1.1009 - acc: 0.3583 - val_loss: 1.1001 - val_acc: 0.3644\n",
            "Epoch 15/50 - 0.07s - loss: 1.1006 - acc: 0.3596 - val_loss: 1.0998 - val_acc: 0.3684\n",
            "Epoch 16/50 - 0.07s - loss: 1.1004 - acc: 0.3590 - val_loss: 1.0995 - val_acc: 0.3644\n",
            "Epoch 17/50 - 0.08s - loss: 1.1002 - acc: 0.3583 - val_loss: 1.0992 - val_acc: 0.3623\n",
            "Epoch 18/50 - 0.08s - loss: 1.1000 - acc: 0.3578 - val_loss: 1.0989 - val_acc: 0.3623\n",
            "Epoch 19/50 - 0.07s - loss: 1.0998 - acc: 0.3578 - val_loss: 1.0987 - val_acc: 0.3623\n",
            "Epoch 20/50 - 0.08s - loss: 1.0996 - acc: 0.3574 - val_loss: 1.0984 - val_acc: 0.3704\n",
            "Epoch 21/50 - 0.08s - loss: 1.0994 - acc: 0.3590 - val_loss: 1.0982 - val_acc: 0.3725\n",
            "Epoch 22/50 - 0.07s - loss: 1.0992 - acc: 0.3599 - val_loss: 1.0979 - val_acc: 0.3725\n",
            "Epoch 23/50 - 0.07s - loss: 1.0990 - acc: 0.3592 - val_loss: 1.0977 - val_acc: 0.3725\n",
            "Epoch 24/50 - 0.07s - loss: 1.0988 - acc: 0.3599 - val_loss: 1.0975 - val_acc: 0.3725\n",
            "Epoch 25/50 - 0.07s - loss: 1.0986 - acc: 0.3603 - val_loss: 1.0973 - val_acc: 0.3785\n",
            "Epoch 26/50 - 0.08s - loss: 1.0985 - acc: 0.3587 - val_loss: 1.0971 - val_acc: 0.3806\n",
            "Epoch 27/50 - 0.09s - loss: 1.0983 - acc: 0.3585 - val_loss: 1.0969 - val_acc: 0.3826\n",
            "Epoch 28/50 - 0.09s - loss: 1.0981 - acc: 0.3574 - val_loss: 1.0967 - val_acc: 0.3745\n",
            "Epoch 29/50 - 0.10s - loss: 1.0980 - acc: 0.3572 - val_loss: 1.0965 - val_acc: 0.3725\n",
            "Epoch 30/50 - 0.08s - loss: 1.0978 - acc: 0.3561 - val_loss: 1.0963 - val_acc: 0.3745\n",
            "Epoch 31/50 - 0.07s - loss: 1.0977 - acc: 0.3570 - val_loss: 1.0961 - val_acc: 0.3725\n",
            "Epoch 32/50 - 0.08s - loss: 1.0975 - acc: 0.3572 - val_loss: 1.0960 - val_acc: 0.3745\n",
            "Epoch 33/50 - 0.07s - loss: 1.0974 - acc: 0.3578 - val_loss: 1.0958 - val_acc: 0.3745\n",
            "Epoch 34/50 - 0.07s - loss: 1.0972 - acc: 0.3570 - val_loss: 1.0956 - val_acc: 0.3745\n",
            "Epoch 35/50 - 0.08s - loss: 1.0971 - acc: 0.3578 - val_loss: 1.0955 - val_acc: 0.3765\n",
            "Epoch 36/50 - 0.09s - loss: 1.0970 - acc: 0.3578 - val_loss: 1.0953 - val_acc: 0.3765\n",
            "Epoch 37/50 - 0.07s - loss: 1.0968 - acc: 0.3592 - val_loss: 1.0952 - val_acc: 0.3765\n",
            "Epoch 38/50 - 0.09s - loss: 1.0967 - acc: 0.3608 - val_loss: 1.0950 - val_acc: 0.3785\n",
            "Epoch 39/50 - 0.08s - loss: 1.0966 - acc: 0.3610 - val_loss: 1.0949 - val_acc: 0.3806\n",
            "Epoch 40/50 - 0.07s - loss: 1.0965 - acc: 0.3608 - val_loss: 1.0947 - val_acc: 0.3826\n",
            "Epoch 41/50 - 0.09s - loss: 1.0963 - acc: 0.3608 - val_loss: 1.0946 - val_acc: 0.3846\n",
            "Epoch 42/50 - 0.08s - loss: 1.0962 - acc: 0.3612 - val_loss: 1.0945 - val_acc: 0.3846\n",
            "Epoch 43/50 - 0.07s - loss: 1.0961 - acc: 0.3621 - val_loss: 1.0943 - val_acc: 0.3866\n",
            "Epoch 44/50 - 0.07s - loss: 1.0960 - acc: 0.3619 - val_loss: 1.0942 - val_acc: 0.3866\n",
            "Epoch 45/50 - 0.08s - loss: 1.0959 - acc: 0.3623 - val_loss: 1.0941 - val_acc: 0.3866\n",
            "Epoch 46/50 - 0.07s - loss: 1.0957 - acc: 0.3628 - val_loss: 1.0939 - val_acc: 0.3846\n",
            "Epoch 47/50 - 0.08s - loss: 1.0956 - acc: 0.3623 - val_loss: 1.0938 - val_acc: 0.3846\n",
            "Epoch 48/50 - 0.08s - loss: 1.0955 - acc: 0.3626 - val_loss: 1.0937 - val_acc: 0.3846\n",
            "Epoch 49/50 - 0.07s - loss: 1.0954 - acc: 0.3621 - val_loss: 1.0936 - val_acc: 0.3826\n",
            "Epoch 50/50 - 0.08s - loss: 1.0953 - acc: 0.3619 - val_loss: 1.0935 - val_acc: 0.3826\n",
            "\n",
            "Combination 158/252:\n",
            "Hidden Layers: [128, 64, 32], Activation: relu, Learning Rate: 0.0001, Batch Size: 32, Epochs: 100\n",
            "Epoch 1/100 - 0.08s - loss: 1.1297 - acc: 0.3556 - val_loss: 1.1270 - val_acc: 0.3502\n",
            "Epoch 2/100 - 0.07s - loss: 1.1254 - acc: 0.3545 - val_loss: 1.1234 - val_acc: 0.3543\n",
            "Epoch 3/100 - 0.08s - loss: 1.1219 - acc: 0.3545 - val_loss: 1.1204 - val_acc: 0.3502\n",
            "Epoch 4/100 - 0.08s - loss: 1.1188 - acc: 0.3554 - val_loss: 1.1179 - val_acc: 0.3502\n",
            "Epoch 5/100 - 0.08s - loss: 1.1163 - acc: 0.3583 - val_loss: 1.1157 - val_acc: 0.3482\n",
            "Epoch 6/100 - 0.08s - loss: 1.1141 - acc: 0.3608 - val_loss: 1.1140 - val_acc: 0.3462\n",
            "Epoch 7/100 - 0.08s - loss: 1.1122 - acc: 0.3612 - val_loss: 1.1124 - val_acc: 0.3300\n",
            "Epoch 8/100 - 0.08s - loss: 1.1105 - acc: 0.3603 - val_loss: 1.1112 - val_acc: 0.3300\n",
            "Epoch 9/100 - 0.08s - loss: 1.1091 - acc: 0.3610 - val_loss: 1.1101 - val_acc: 0.3340\n",
            "Epoch 10/100 - 0.08s - loss: 1.1079 - acc: 0.3608 - val_loss: 1.1091 - val_acc: 0.3360\n",
            "Epoch 11/100 - 0.07s - loss: 1.1069 - acc: 0.3605 - val_loss: 1.1083 - val_acc: 0.3381\n",
            "Epoch 12/100 - 0.08s - loss: 1.1059 - acc: 0.3612 - val_loss: 1.1076 - val_acc: 0.3381\n",
            "Epoch 13/100 - 0.09s - loss: 1.1051 - acc: 0.3599 - val_loss: 1.1070 - val_acc: 0.3360\n",
            "Epoch 14/100 - 0.08s - loss: 1.1044 - acc: 0.3587 - val_loss: 1.1064 - val_acc: 0.3340\n",
            "Epoch 15/100 - 0.08s - loss: 1.1037 - acc: 0.3565 - val_loss: 1.1059 - val_acc: 0.3340\n",
            "Epoch 16/100 - 0.07s - loss: 1.1031 - acc: 0.3563 - val_loss: 1.1055 - val_acc: 0.3300\n",
            "Epoch 17/100 - 0.08s - loss: 1.1026 - acc: 0.3565 - val_loss: 1.1051 - val_acc: 0.3300\n",
            "Epoch 18/100 - 0.08s - loss: 1.1021 - acc: 0.3587 - val_loss: 1.1047 - val_acc: 0.3340\n",
            "Epoch 19/100 - 0.09s - loss: 1.1016 - acc: 0.3585 - val_loss: 1.1043 - val_acc: 0.3401\n",
            "Epoch 20/100 - 0.07s - loss: 1.1012 - acc: 0.3583 - val_loss: 1.1040 - val_acc: 0.3462\n",
            "Epoch 21/100 - 0.07s - loss: 1.1008 - acc: 0.3599 - val_loss: 1.1037 - val_acc: 0.3462\n",
            "Epoch 22/100 - 0.09s - loss: 1.1005 - acc: 0.3565 - val_loss: 1.1033 - val_acc: 0.3482\n",
            "Epoch 23/100 - 0.08s - loss: 1.1001 - acc: 0.3594 - val_loss: 1.1030 - val_acc: 0.3482\n",
            "Epoch 24/100 - 0.08s - loss: 1.0998 - acc: 0.3601 - val_loss: 1.1027 - val_acc: 0.3502\n",
            "Epoch 25/100 - 0.07s - loss: 1.0994 - acc: 0.3603 - val_loss: 1.1025 - val_acc: 0.3522\n",
            "Epoch 26/100 - 0.07s - loss: 1.0991 - acc: 0.3599 - val_loss: 1.1022 - val_acc: 0.3482\n",
            "Epoch 27/100 - 0.08s - loss: 1.0988 - acc: 0.3608 - val_loss: 1.1019 - val_acc: 0.3543\n",
            "Epoch 28/100 - 0.09s - loss: 1.0985 - acc: 0.3605 - val_loss: 1.1017 - val_acc: 0.3543\n",
            "Epoch 29/100 - 0.08s - loss: 1.0982 - acc: 0.3599 - val_loss: 1.1014 - val_acc: 0.3522\n",
            "Epoch 30/100 - 0.08s - loss: 1.0980 - acc: 0.3603 - val_loss: 1.1012 - val_acc: 0.3522\n",
            "Epoch 31/100 - 0.07s - loss: 1.0977 - acc: 0.3610 - val_loss: 1.1009 - val_acc: 0.3522\n",
            "Epoch 32/100 - 0.07s - loss: 1.0974 - acc: 0.3628 - val_loss: 1.1007 - val_acc: 0.3543\n",
            "Epoch 33/100 - 0.07s - loss: 1.0972 - acc: 0.3626 - val_loss: 1.1005 - val_acc: 0.3563\n",
            "Epoch 34/100 - 0.08s - loss: 1.0969 - acc: 0.3630 - val_loss: 1.1002 - val_acc: 0.3563\n",
            "Epoch 35/100 - 0.07s - loss: 1.0967 - acc: 0.3632 - val_loss: 1.1000 - val_acc: 0.3583\n",
            "Epoch 36/100 - 0.07s - loss: 1.0964 - acc: 0.3626 - val_loss: 1.0998 - val_acc: 0.3603\n",
            "Epoch 37/100 - 0.08s - loss: 1.0962 - acc: 0.3655 - val_loss: 1.0995 - val_acc: 0.3603\n",
            "Epoch 38/100 - 0.07s - loss: 1.0959 - acc: 0.3662 - val_loss: 1.0993 - val_acc: 0.3583\n",
            "Epoch 39/100 - 0.08s - loss: 1.0957 - acc: 0.3659 - val_loss: 1.0991 - val_acc: 0.3583\n",
            "Epoch 40/100 - 0.08s - loss: 1.0955 - acc: 0.3664 - val_loss: 1.0988 - val_acc: 0.3563\n",
            "Epoch 41/100 - 0.07s - loss: 1.0952 - acc: 0.3673 - val_loss: 1.0986 - val_acc: 0.3563\n",
            "Epoch 42/100 - 0.09s - loss: 1.0950 - acc: 0.3673 - val_loss: 1.0984 - val_acc: 0.3522\n",
            "Epoch 43/100 - 0.07s - loss: 1.0948 - acc: 0.3686 - val_loss: 1.0982 - val_acc: 0.3502\n",
            "Epoch 44/100 - 0.07s - loss: 1.0945 - acc: 0.3702 - val_loss: 1.0980 - val_acc: 0.3482\n",
            "Epoch 45/100 - 0.07s - loss: 1.0943 - acc: 0.3711 - val_loss: 1.0978 - val_acc: 0.3482\n",
            "Epoch 46/100 - 0.08s - loss: 1.0941 - acc: 0.3720 - val_loss: 1.0976 - val_acc: 0.3502\n",
            "Epoch 47/100 - 0.07s - loss: 1.0939 - acc: 0.3729 - val_loss: 1.0973 - val_acc: 0.3482\n",
            "Epoch 48/100 - 0.07s - loss: 1.0937 - acc: 0.3736 - val_loss: 1.0971 - val_acc: 0.3502\n",
            "Epoch 49/100 - 0.07s - loss: 1.0934 - acc: 0.3743 - val_loss: 1.0969 - val_acc: 0.3502\n",
            "Epoch 50/100 - 0.07s - loss: 1.0932 - acc: 0.3749 - val_loss: 1.0967 - val_acc: 0.3543\n",
            "Epoch 51/100 - 0.07s - loss: 1.0930 - acc: 0.3758 - val_loss: 1.0965 - val_acc: 0.3522\n",
            "Epoch 52/100 - 0.08s - loss: 1.0928 - acc: 0.3767 - val_loss: 1.0963 - val_acc: 0.3563\n",
            "Epoch 53/100 - 0.07s - loss: 1.0926 - acc: 0.3783 - val_loss: 1.0960 - val_acc: 0.3583\n",
            "Epoch 54/100 - 0.07s - loss: 1.0923 - acc: 0.3794 - val_loss: 1.0958 - val_acc: 0.3603\n",
            "Epoch 55/100 - 0.07s - loss: 1.0921 - acc: 0.3788 - val_loss: 1.0956 - val_acc: 0.3603\n",
            "Epoch 56/100 - 0.07s - loss: 1.0919 - acc: 0.3806 - val_loss: 1.0954 - val_acc: 0.3664\n",
            "Epoch 57/100 - 0.07s - loss: 1.0917 - acc: 0.3810 - val_loss: 1.0952 - val_acc: 0.3644\n",
            "Epoch 58/100 - 0.09s - loss: 1.0915 - acc: 0.3812 - val_loss: 1.0950 - val_acc: 0.3704\n",
            "Epoch 59/100 - 0.07s - loss: 1.0913 - acc: 0.3815 - val_loss: 1.0948 - val_acc: 0.3725\n",
            "Epoch 60/100 - 0.08s - loss: 1.0911 - acc: 0.3837 - val_loss: 1.0946 - val_acc: 0.3725\n",
            "Epoch 61/100 - 0.07s - loss: 1.0909 - acc: 0.3846 - val_loss: 1.0944 - val_acc: 0.3704\n",
            "Epoch 62/100 - 0.07s - loss: 1.0907 - acc: 0.3844 - val_loss: 1.0942 - val_acc: 0.3745\n",
            "Epoch 63/100 - 0.07s - loss: 1.0905 - acc: 0.3853 - val_loss: 1.0940 - val_acc: 0.3765\n",
            "Epoch 64/100 - 0.08s - loss: 1.0903 - acc: 0.3862 - val_loss: 1.0938 - val_acc: 0.3704\n",
            "Epoch 65/100 - 0.07s - loss: 1.0901 - acc: 0.3882 - val_loss: 1.0936 - val_acc: 0.3745\n",
            "Epoch 66/100 - 0.09s - loss: 1.0899 - acc: 0.3900 - val_loss: 1.0934 - val_acc: 0.3785\n",
            "Epoch 67/100 - 0.08s - loss: 1.0897 - acc: 0.3920 - val_loss: 1.0932 - val_acc: 0.3765\n",
            "Epoch 68/100 - 0.07s - loss: 1.0895 - acc: 0.3932 - val_loss: 1.0930 - val_acc: 0.3765\n",
            "Epoch 69/100 - 0.08s - loss: 1.0893 - acc: 0.3943 - val_loss: 1.0928 - val_acc: 0.3765\n",
            "Epoch 70/100 - 0.08s - loss: 1.0891 - acc: 0.3952 - val_loss: 1.0926 - val_acc: 0.3765\n",
            "Epoch 71/100 - 0.07s - loss: 1.0889 - acc: 0.3941 - val_loss: 1.0924 - val_acc: 0.3765\n",
            "Epoch 72/100 - 0.07s - loss: 1.0887 - acc: 0.3954 - val_loss: 1.0922 - val_acc: 0.3806\n",
            "Epoch 73/100 - 0.07s - loss: 1.0885 - acc: 0.3950 - val_loss: 1.0921 - val_acc: 0.3806\n",
            "Epoch 74/100 - 0.07s - loss: 1.0883 - acc: 0.3956 - val_loss: 1.0919 - val_acc: 0.3806\n",
            "Epoch 75/100 - 0.07s - loss: 1.0881 - acc: 0.3950 - val_loss: 1.0917 - val_acc: 0.3826\n",
            "Epoch 76/100 - 0.08s - loss: 1.0879 - acc: 0.3959 - val_loss: 1.0915 - val_acc: 0.3826\n",
            "Epoch 77/100 - 0.07s - loss: 1.0878 - acc: 0.3965 - val_loss: 1.0913 - val_acc: 0.3826\n",
            "Epoch 78/100 - 0.07s - loss: 1.0876 - acc: 0.3979 - val_loss: 1.0912 - val_acc: 0.3826\n",
            "Epoch 79/100 - 0.07s - loss: 1.0874 - acc: 0.3983 - val_loss: 1.0910 - val_acc: 0.3826\n",
            "Epoch 80/100 - 0.07s - loss: 1.0872 - acc: 0.3992 - val_loss: 1.0908 - val_acc: 0.3826\n",
            "Epoch 81/100 - 0.07s - loss: 1.0870 - acc: 0.4010 - val_loss: 1.0906 - val_acc: 0.3806\n",
            "Epoch 82/100 - 0.08s - loss: 1.0868 - acc: 0.4015 - val_loss: 1.0905 - val_acc: 0.3826\n",
            "Epoch 83/100 - 0.07s - loss: 1.0866 - acc: 0.4019 - val_loss: 1.0903 - val_acc: 0.3866\n",
            "Epoch 84/100 - 0.07s - loss: 1.0864 - acc: 0.4022 - val_loss: 1.0901 - val_acc: 0.3866\n",
            "Epoch 85/100 - 0.08s - loss: 1.0862 - acc: 0.4033 - val_loss: 1.0900 - val_acc: 0.3887\n",
            "Epoch 86/100 - 0.07s - loss: 1.0860 - acc: 0.4024 - val_loss: 1.0898 - val_acc: 0.3907\n",
            "Epoch 87/100 - 0.07s - loss: 1.0859 - acc: 0.4022 - val_loss: 1.0896 - val_acc: 0.3927\n",
            "Epoch 88/100 - 0.08s - loss: 1.0857 - acc: 0.4035 - val_loss: 1.0894 - val_acc: 0.3927\n",
            "Epoch 89/100 - 0.08s - loss: 1.0855 - acc: 0.4046 - val_loss: 1.0893 - val_acc: 0.3947\n",
            "Epoch 90/100 - 0.08s - loss: 1.0853 - acc: 0.4044 - val_loss: 1.0891 - val_acc: 0.3968\n",
            "Epoch 91/100 - 0.09s - loss: 1.0851 - acc: 0.4044 - val_loss: 1.0890 - val_acc: 0.3968\n",
            "Epoch 92/100 - 0.11s - loss: 1.0849 - acc: 0.4058 - val_loss: 1.0888 - val_acc: 0.3968\n",
            "Epoch 93/100 - 0.09s - loss: 1.0847 - acc: 0.4069 - val_loss: 1.0886 - val_acc: 0.3968\n",
            "Epoch 94/100 - 0.08s - loss: 1.0846 - acc: 0.4076 - val_loss: 1.0885 - val_acc: 0.4028\n",
            "Epoch 95/100 - 0.08s - loss: 1.0844 - acc: 0.4087 - val_loss: 1.0883 - val_acc: 0.4028\n",
            "Epoch 96/100 - 0.08s - loss: 1.0842 - acc: 0.4078 - val_loss: 1.0882 - val_acc: 0.4008\n",
            "Epoch 97/100 - 0.07s - loss: 1.0840 - acc: 0.4080 - val_loss: 1.0880 - val_acc: 0.4028\n",
            "Epoch 98/100 - 0.08s - loss: 1.0838 - acc: 0.4082 - val_loss: 1.0878 - val_acc: 0.4008\n",
            "Epoch 99/100 - 0.08s - loss: 1.0837 - acc: 0.4082 - val_loss: 1.0877 - val_acc: 0.3988\n",
            "Epoch 100/100 - 0.07s - loss: 1.0835 - acc: 0.4098 - val_loss: 1.0875 - val_acc: 0.3988\n",
            "\n",
            "Combination 159/252:\n",
            "Hidden Layers: [128, 64, 32], Activation: relu, Learning Rate: 0.0001, Batch Size: 32, Epochs: 150\n",
            "Epoch 1/150 - 0.07s - loss: 1.0970 - acc: 0.3444 - val_loss: 1.0987 - val_acc: 0.3340\n",
            "Epoch 2/150 - 0.08s - loss: 1.0968 - acc: 0.3457 - val_loss: 1.0986 - val_acc: 0.3360\n",
            "Epoch 3/150 - 0.07s - loss: 1.0967 - acc: 0.3475 - val_loss: 1.0984 - val_acc: 0.3381\n",
            "Epoch 4/150 - 0.07s - loss: 1.0965 - acc: 0.3489 - val_loss: 1.0983 - val_acc: 0.3421\n",
            "Epoch 5/150 - 0.08s - loss: 1.0964 - acc: 0.3498 - val_loss: 1.0981 - val_acc: 0.3421\n",
            "Epoch 6/150 - 0.07s - loss: 1.0962 - acc: 0.3509 - val_loss: 1.0980 - val_acc: 0.3482\n",
            "Epoch 7/150 - 0.07s - loss: 1.0961 - acc: 0.3507 - val_loss: 1.0979 - val_acc: 0.3482\n",
            "Epoch 8/150 - 0.07s - loss: 1.0959 - acc: 0.3525 - val_loss: 1.0977 - val_acc: 0.3482\n",
            "Epoch 9/150 - 0.07s - loss: 1.0958 - acc: 0.3536 - val_loss: 1.0976 - val_acc: 0.3502\n",
            "Epoch 10/150 - 0.07s - loss: 1.0957 - acc: 0.3540 - val_loss: 1.0975 - val_acc: 0.3522\n",
            "Epoch 11/150 - 0.08s - loss: 1.0955 - acc: 0.3534 - val_loss: 1.0974 - val_acc: 0.3563\n",
            "Epoch 12/150 - 0.07s - loss: 1.0954 - acc: 0.3545 - val_loss: 1.0973 - val_acc: 0.3583\n",
            "Epoch 13/150 - 0.07s - loss: 1.0953 - acc: 0.3570 - val_loss: 1.0971 - val_acc: 0.3563\n",
            "Epoch 14/150 - 0.07s - loss: 1.0952 - acc: 0.3574 - val_loss: 1.0970 - val_acc: 0.3563\n",
            "Epoch 15/150 - 0.07s - loss: 1.0950 - acc: 0.3572 - val_loss: 1.0969 - val_acc: 0.3543\n",
            "Epoch 16/150 - 0.08s - loss: 1.0949 - acc: 0.3581 - val_loss: 1.0968 - val_acc: 0.3583\n",
            "Epoch 17/150 - 0.08s - loss: 1.0948 - acc: 0.3592 - val_loss: 1.0967 - val_acc: 0.3603\n",
            "Epoch 18/150 - 0.07s - loss: 1.0947 - acc: 0.3596 - val_loss: 1.0966 - val_acc: 0.3664\n",
            "Epoch 19/150 - 0.07s - loss: 1.0946 - acc: 0.3596 - val_loss: 1.0965 - val_acc: 0.3644\n",
            "Epoch 20/150 - 0.07s - loss: 1.0944 - acc: 0.3610 - val_loss: 1.0964 - val_acc: 0.3664\n",
            "Epoch 21/150 - 0.07s - loss: 1.0943 - acc: 0.3623 - val_loss: 1.0963 - val_acc: 0.3704\n",
            "Epoch 22/150 - 0.07s - loss: 1.0942 - acc: 0.3626 - val_loss: 1.0962 - val_acc: 0.3684\n",
            "Epoch 23/150 - 0.08s - loss: 1.0941 - acc: 0.3650 - val_loss: 1.0961 - val_acc: 0.3664\n",
            "Epoch 24/150 - 0.07s - loss: 1.0940 - acc: 0.3675 - val_loss: 1.0960 - val_acc: 0.3644\n",
            "Epoch 25/150 - 0.07s - loss: 1.0939 - acc: 0.3693 - val_loss: 1.0959 - val_acc: 0.3644\n",
            "Epoch 26/150 - 0.07s - loss: 1.0938 - acc: 0.3702 - val_loss: 1.0958 - val_acc: 0.3664\n",
            "Epoch 27/150 - 0.07s - loss: 1.0937 - acc: 0.3702 - val_loss: 1.0957 - val_acc: 0.3664\n",
            "Epoch 28/150 - 0.07s - loss: 1.0936 - acc: 0.3704 - val_loss: 1.0956 - val_acc: 0.3664\n",
            "Epoch 29/150 - 0.08s - loss: 1.0935 - acc: 0.3720 - val_loss: 1.0956 - val_acc: 0.3684\n",
            "Epoch 30/150 - 0.07s - loss: 1.0934 - acc: 0.3718 - val_loss: 1.0955 - val_acc: 0.3684\n",
            "Epoch 31/150 - 0.07s - loss: 1.0933 - acc: 0.3731 - val_loss: 1.0954 - val_acc: 0.3725\n",
            "Epoch 32/150 - 0.07s - loss: 1.0932 - acc: 0.3740 - val_loss: 1.0953 - val_acc: 0.3745\n",
            "Epoch 33/150 - 0.07s - loss: 1.0931 - acc: 0.3747 - val_loss: 1.0952 - val_acc: 0.3765\n",
            "Epoch 34/150 - 0.07s - loss: 1.0930 - acc: 0.3745 - val_loss: 1.0951 - val_acc: 0.3745\n",
            "Epoch 35/150 - 0.09s - loss: 1.0929 - acc: 0.3765 - val_loss: 1.0951 - val_acc: 0.3806\n",
            "Epoch 36/150 - 0.07s - loss: 1.0928 - acc: 0.3761 - val_loss: 1.0950 - val_acc: 0.3826\n",
            "Epoch 37/150 - 0.07s - loss: 1.0927 - acc: 0.3765 - val_loss: 1.0949 - val_acc: 0.3846\n",
            "Epoch 38/150 - 0.07s - loss: 1.0927 - acc: 0.3788 - val_loss: 1.0948 - val_acc: 0.3846\n",
            "Epoch 39/150 - 0.07s - loss: 1.0926 - acc: 0.3779 - val_loss: 1.0948 - val_acc: 0.3826\n",
            "Epoch 40/150 - 0.07s - loss: 1.0925 - acc: 0.3788 - val_loss: 1.0947 - val_acc: 0.3826\n",
            "Epoch 41/150 - 0.08s - loss: 1.0924 - acc: 0.3794 - val_loss: 1.0946 - val_acc: 0.3806\n",
            "Epoch 42/150 - 0.07s - loss: 1.0923 - acc: 0.3792 - val_loss: 1.0945 - val_acc: 0.3785\n",
            "Epoch 43/150 - 0.07s - loss: 1.0922 - acc: 0.3812 - val_loss: 1.0945 - val_acc: 0.3785\n",
            "Epoch 44/150 - 0.09s - loss: 1.0921 - acc: 0.3812 - val_loss: 1.0944 - val_acc: 0.3806\n",
            "Epoch 45/150 - 0.07s - loss: 1.0920 - acc: 0.3824 - val_loss: 1.0943 - val_acc: 0.3785\n",
            "Epoch 46/150 - 0.08s - loss: 1.0920 - acc: 0.3812 - val_loss: 1.0942 - val_acc: 0.3806\n",
            "Epoch 47/150 - 0.07s - loss: 1.0919 - acc: 0.3830 - val_loss: 1.0942 - val_acc: 0.3826\n",
            "Epoch 48/150 - 0.07s - loss: 1.0918 - acc: 0.3846 - val_loss: 1.0941 - val_acc: 0.3826\n",
            "Epoch 49/150 - 0.07s - loss: 1.0917 - acc: 0.3844 - val_loss: 1.0940 - val_acc: 0.3826\n",
            "Epoch 50/150 - 0.07s - loss: 1.0916 - acc: 0.3842 - val_loss: 1.0940 - val_acc: 0.3806\n",
            "Epoch 51/150 - 0.07s - loss: 1.0916 - acc: 0.3844 - val_loss: 1.0939 - val_acc: 0.3846\n",
            "Epoch 52/150 - 0.07s - loss: 1.0915 - acc: 0.3842 - val_loss: 1.0939 - val_acc: 0.3846\n",
            "Epoch 53/150 - 0.08s - loss: 1.0914 - acc: 0.3853 - val_loss: 1.0938 - val_acc: 0.3846\n",
            "Epoch 54/150 - 0.07s - loss: 1.0913 - acc: 0.3860 - val_loss: 1.0937 - val_acc: 0.3866\n",
            "Epoch 55/150 - 0.07s - loss: 1.0912 - acc: 0.3866 - val_loss: 1.0937 - val_acc: 0.3846\n",
            "Epoch 56/150 - 0.07s - loss: 1.0912 - acc: 0.3875 - val_loss: 1.0936 - val_acc: 0.3846\n",
            "Epoch 57/150 - 0.07s - loss: 1.0911 - acc: 0.3875 - val_loss: 1.0935 - val_acc: 0.3866\n",
            "Epoch 58/150 - 0.07s - loss: 1.0910 - acc: 0.3878 - val_loss: 1.0935 - val_acc: 0.3887\n",
            "Epoch 59/150 - 0.08s - loss: 1.0909 - acc: 0.3880 - val_loss: 1.0934 - val_acc: 0.3887\n",
            "Epoch 60/150 - 0.07s - loss: 1.0908 - acc: 0.3880 - val_loss: 1.0933 - val_acc: 0.3907\n",
            "Epoch 61/150 - 0.07s - loss: 1.0908 - acc: 0.3887 - val_loss: 1.0933 - val_acc: 0.3866\n",
            "Epoch 62/150 - 0.07s - loss: 1.0907 - acc: 0.3896 - val_loss: 1.0932 - val_acc: 0.3866\n",
            "Epoch 63/150 - 0.07s - loss: 1.0906 - acc: 0.3902 - val_loss: 1.0932 - val_acc: 0.3907\n",
            "Epoch 64/150 - 0.07s - loss: 1.0905 - acc: 0.3898 - val_loss: 1.0931 - val_acc: 0.3927\n",
            "Epoch 65/150 - 0.08s - loss: 1.0905 - acc: 0.3889 - val_loss: 1.0931 - val_acc: 0.3927\n",
            "Epoch 66/150 - 0.07s - loss: 1.0904 - acc: 0.3887 - val_loss: 1.0930 - val_acc: 0.3927\n",
            "Epoch 67/150 - 0.07s - loss: 1.0903 - acc: 0.3896 - val_loss: 1.0929 - val_acc: 0.3927\n",
            "Epoch 68/150 - 0.08s - loss: 1.0902 - acc: 0.3893 - val_loss: 1.0929 - val_acc: 0.3927\n",
            "Epoch 69/150 - 0.08s - loss: 1.0902 - acc: 0.3905 - val_loss: 1.0928 - val_acc: 0.3927\n",
            "Epoch 70/150 - 0.07s - loss: 1.0901 - acc: 0.3905 - val_loss: 1.0928 - val_acc: 0.3927\n",
            "Epoch 71/150 - 0.08s - loss: 1.0900 - acc: 0.3907 - val_loss: 1.0927 - val_acc: 0.3947\n",
            "Epoch 72/150 - 0.07s - loss: 1.0899 - acc: 0.3911 - val_loss: 1.0926 - val_acc: 0.3947\n",
            "Epoch 73/150 - 0.07s - loss: 1.0899 - acc: 0.3916 - val_loss: 1.0926 - val_acc: 0.3947\n",
            "Epoch 74/150 - 0.08s - loss: 1.0898 - acc: 0.3920 - val_loss: 1.0925 - val_acc: 0.3947\n",
            "Epoch 75/150 - 0.07s - loss: 1.0897 - acc: 0.3916 - val_loss: 1.0925 - val_acc: 0.3947\n",
            "Epoch 76/150 - 0.07s - loss: 1.0896 - acc: 0.3920 - val_loss: 1.0924 - val_acc: 0.3947\n",
            "Epoch 77/150 - 0.08s - loss: 1.0896 - acc: 0.3920 - val_loss: 1.0924 - val_acc: 0.3927\n",
            "Epoch 78/150 - 0.07s - loss: 1.0895 - acc: 0.3929 - val_loss: 1.0923 - val_acc: 0.3927\n",
            "Epoch 79/150 - 0.07s - loss: 1.0894 - acc: 0.3936 - val_loss: 1.0922 - val_acc: 0.3927\n",
            "Epoch 80/150 - 0.07s - loss: 1.0893 - acc: 0.3934 - val_loss: 1.0922 - val_acc: 0.3927\n",
            "Epoch 81/150 - 0.07s - loss: 1.0893 - acc: 0.3938 - val_loss: 1.0921 - val_acc: 0.3947\n",
            "Epoch 82/150 - 0.07s - loss: 1.0892 - acc: 0.3943 - val_loss: 1.0921 - val_acc: 0.3947\n",
            "Epoch 83/150 - 0.08s - loss: 1.0891 - acc: 0.3950 - val_loss: 1.0920 - val_acc: 0.3927\n",
            "Epoch 84/150 - 0.07s - loss: 1.0890 - acc: 0.3963 - val_loss: 1.0920 - val_acc: 0.3927\n",
            "Epoch 85/150 - 0.07s - loss: 1.0889 - acc: 0.3972 - val_loss: 1.0919 - val_acc: 0.3968\n",
            "Epoch 86/150 - 0.07s - loss: 1.0889 - acc: 0.3970 - val_loss: 1.0918 - val_acc: 0.3968\n",
            "Epoch 87/150 - 0.07s - loss: 1.0888 - acc: 0.3979 - val_loss: 1.0918 - val_acc: 0.3968\n",
            "Epoch 88/150 - 0.07s - loss: 1.0887 - acc: 0.3979 - val_loss: 1.0917 - val_acc: 0.3907\n",
            "Epoch 89/150 - 0.08s - loss: 1.0886 - acc: 0.3990 - val_loss: 1.0917 - val_acc: 0.3887\n",
            "Epoch 90/150 - 0.07s - loss: 1.0886 - acc: 0.3990 - val_loss: 1.0916 - val_acc: 0.3887\n",
            "Epoch 91/150 - 0.07s - loss: 1.0885 - acc: 0.3990 - val_loss: 1.0916 - val_acc: 0.3846\n",
            "Epoch 92/150 - 0.07s - loss: 1.0884 - acc: 0.3981 - val_loss: 1.0915 - val_acc: 0.3846\n",
            "Epoch 93/150 - 0.07s - loss: 1.0884 - acc: 0.3983 - val_loss: 1.0915 - val_acc: 0.3806\n",
            "Epoch 94/150 - 0.07s - loss: 1.0883 - acc: 0.3981 - val_loss: 1.0914 - val_acc: 0.3785\n",
            "Epoch 95/150 - 0.09s - loss: 1.0882 - acc: 0.3983 - val_loss: 1.0913 - val_acc: 0.3785\n",
            "Epoch 96/150 - 0.07s - loss: 1.0881 - acc: 0.3992 - val_loss: 1.0913 - val_acc: 0.3785\n",
            "Epoch 97/150 - 0.07s - loss: 1.0881 - acc: 0.4004 - val_loss: 1.0912 - val_acc: 0.3785\n",
            "Epoch 98/150 - 0.07s - loss: 1.0880 - acc: 0.4006 - val_loss: 1.0912 - val_acc: 0.3806\n",
            "Epoch 99/150 - 0.07s - loss: 1.0879 - acc: 0.4001 - val_loss: 1.0911 - val_acc: 0.3806\n",
            "Epoch 100/150 - 0.07s - loss: 1.0878 - acc: 0.4001 - val_loss: 1.0911 - val_acc: 0.3785\n",
            "Epoch 101/150 - 0.08s - loss: 1.0878 - acc: 0.4004 - val_loss: 1.0910 - val_acc: 0.3806\n",
            "Epoch 102/150 - 0.07s - loss: 1.0877 - acc: 0.4008 - val_loss: 1.0910 - val_acc: 0.3806\n",
            "Epoch 103/150 - 0.07s - loss: 1.0876 - acc: 0.4010 - val_loss: 1.0909 - val_acc: 0.3806\n",
            "Epoch 104/150 - 0.08s - loss: 1.0876 - acc: 0.4013 - val_loss: 1.0909 - val_acc: 0.3806\n",
            "Epoch 105/150 - 0.07s - loss: 1.0875 - acc: 0.4026 - val_loss: 1.0908 - val_acc: 0.3806\n",
            "Epoch 106/150 - 0.07s - loss: 1.0874 - acc: 0.4031 - val_loss: 1.0908 - val_acc: 0.3826\n",
            "Epoch 107/150 - 0.08s - loss: 1.0873 - acc: 0.4028 - val_loss: 1.0907 - val_acc: 0.3806\n",
            "Epoch 108/150 - 0.07s - loss: 1.0873 - acc: 0.4033 - val_loss: 1.0907 - val_acc: 0.3806\n",
            "Epoch 109/150 - 0.07s - loss: 1.0872 - acc: 0.4031 - val_loss: 1.0906 - val_acc: 0.3806\n",
            "Epoch 110/150 - 0.08s - loss: 1.0871 - acc: 0.4040 - val_loss: 1.0906 - val_acc: 0.3806\n",
            "Epoch 111/150 - 0.07s - loss: 1.0870 - acc: 0.4040 - val_loss: 1.0905 - val_acc: 0.3806\n",
            "Epoch 112/150 - 0.08s - loss: 1.0870 - acc: 0.4044 - val_loss: 1.0904 - val_acc: 0.3806\n",
            "Epoch 113/150 - 0.07s - loss: 1.0869 - acc: 0.4046 - val_loss: 1.0904 - val_acc: 0.3806\n",
            "Epoch 114/150 - 0.08s - loss: 1.0868 - acc: 0.4044 - val_loss: 1.0903 - val_acc: 0.3826\n",
            "Epoch 115/150 - 0.08s - loss: 1.0868 - acc: 0.4051 - val_loss: 1.0903 - val_acc: 0.3806\n",
            "Epoch 116/150 - 0.08s - loss: 1.0867 - acc: 0.4051 - val_loss: 1.0902 - val_acc: 0.3806\n",
            "Epoch 117/150 - 0.08s - loss: 1.0866 - acc: 0.4051 - val_loss: 1.0902 - val_acc: 0.3806\n",
            "Epoch 118/150 - 0.08s - loss: 1.0866 - acc: 0.4046 - val_loss: 1.0901 - val_acc: 0.3806\n",
            "Epoch 119/150 - 0.08s - loss: 1.0865 - acc: 0.4053 - val_loss: 1.0901 - val_acc: 0.3806\n",
            "Epoch 120/150 - 0.08s - loss: 1.0864 - acc: 0.4067 - val_loss: 1.0900 - val_acc: 0.3785\n",
            "Epoch 121/150 - 0.07s - loss: 1.0864 - acc: 0.4076 - val_loss: 1.0900 - val_acc: 0.3765\n",
            "Epoch 122/150 - 0.07s - loss: 1.0863 - acc: 0.4078 - val_loss: 1.0899 - val_acc: 0.3826\n",
            "Epoch 123/150 - 0.07s - loss: 1.0862 - acc: 0.4076 - val_loss: 1.0899 - val_acc: 0.3826\n",
            "Epoch 124/150 - 0.08s - loss: 1.0861 - acc: 0.4078 - val_loss: 1.0898 - val_acc: 0.3866\n",
            "Epoch 125/150 - 0.08s - loss: 1.0861 - acc: 0.4080 - val_loss: 1.0898 - val_acc: 0.3866\n",
            "Epoch 126/150 - 0.07s - loss: 1.0860 - acc: 0.4094 - val_loss: 1.0897 - val_acc: 0.3866\n",
            "Epoch 127/150 - 0.07s - loss: 1.0859 - acc: 0.4096 - val_loss: 1.0897 - val_acc: 0.3866\n",
            "Epoch 128/150 - 0.07s - loss: 1.0859 - acc: 0.4098 - val_loss: 1.0896 - val_acc: 0.3866\n",
            "Epoch 129/150 - 0.07s - loss: 1.0858 - acc: 0.4098 - val_loss: 1.0896 - val_acc: 0.3866\n",
            "Epoch 130/150 - 0.07s - loss: 1.0857 - acc: 0.4100 - val_loss: 1.0895 - val_acc: 0.3907\n",
            "Epoch 131/150 - 0.08s - loss: 1.0857 - acc: 0.4116 - val_loss: 1.0895 - val_acc: 0.3907\n",
            "Epoch 132/150 - 0.07s - loss: 1.0856 - acc: 0.4109 - val_loss: 1.0894 - val_acc: 0.3907\n",
            "Epoch 133/150 - 0.07s - loss: 1.0855 - acc: 0.4112 - val_loss: 1.0894 - val_acc: 0.3907\n",
            "Epoch 134/150 - 0.07s - loss: 1.0855 - acc: 0.4107 - val_loss: 1.0893 - val_acc: 0.3927\n",
            "Epoch 135/150 - 0.07s - loss: 1.0854 - acc: 0.4114 - val_loss: 1.0893 - val_acc: 0.3927\n",
            "Epoch 136/150 - 0.07s - loss: 1.0853 - acc: 0.4125 - val_loss: 1.0892 - val_acc: 0.3927\n",
            "Epoch 137/150 - 0.07s - loss: 1.0852 - acc: 0.4123 - val_loss: 1.0892 - val_acc: 0.3927\n",
            "Epoch 138/150 - 0.07s - loss: 1.0852 - acc: 0.4130 - val_loss: 1.0891 - val_acc: 0.3927\n",
            "Epoch 139/150 - 0.08s - loss: 1.0851 - acc: 0.4132 - val_loss: 1.0891 - val_acc: 0.3947\n",
            "Epoch 140/150 - 0.07s - loss: 1.0850 - acc: 0.4134 - val_loss: 1.0891 - val_acc: 0.3947\n",
            "Epoch 141/150 - 0.07s - loss: 1.0850 - acc: 0.4134 - val_loss: 1.0890 - val_acc: 0.3947\n",
            "Epoch 142/150 - 0.07s - loss: 1.0849 - acc: 0.4141 - val_loss: 1.0890 - val_acc: 0.3947\n",
            "Epoch 143/150 - 0.07s - loss: 1.0848 - acc: 0.4136 - val_loss: 1.0889 - val_acc: 0.3968\n",
            "Epoch 144/150 - 0.07s - loss: 1.0848 - acc: 0.4136 - val_loss: 1.0889 - val_acc: 0.4008\n",
            "Epoch 145/150 - 0.07s - loss: 1.0847 - acc: 0.4145 - val_loss: 1.0888 - val_acc: 0.4008\n",
            "Epoch 146/150 - 0.07s - loss: 1.0846 - acc: 0.4150 - val_loss: 1.0888 - val_acc: 0.4028\n",
            "Epoch 147/150 - 0.07s - loss: 1.0845 - acc: 0.4157 - val_loss: 1.0887 - val_acc: 0.4028\n",
            "Epoch 148/150 - 0.07s - loss: 1.0845 - acc: 0.4157 - val_loss: 1.0887 - val_acc: 0.4069\n",
            "Epoch 149/150 - 0.07s - loss: 1.0844 - acc: 0.4159 - val_loss: 1.0886 - val_acc: 0.4069\n",
            "Epoch 150/150 - 0.07s - loss: 1.0843 - acc: 0.4152 - val_loss: 1.0886 - val_acc: 0.4069\n",
            "\n",
            "Combination 160/252:\n",
            "Hidden Layers: [128, 64, 32], Activation: relu, Learning Rate: 0.0001, Batch Size: 64, Epochs: 50\n",
            "Epoch 1/50 - 0.05s - loss: 1.1366 - acc: 0.3282 - val_loss: 1.1339 - val_acc: 0.3381\n",
            "Epoch 2/50 - 0.05s - loss: 1.1351 - acc: 0.3291 - val_loss: 1.1326 - val_acc: 0.3401\n",
            "Epoch 3/50 - 0.05s - loss: 1.1337 - acc: 0.3302 - val_loss: 1.1313 - val_acc: 0.3421\n",
            "Epoch 4/50 - 0.06s - loss: 1.1324 - acc: 0.3304 - val_loss: 1.1302 - val_acc: 0.3421\n",
            "Epoch 5/50 - 0.09s - loss: 1.1311 - acc: 0.3311 - val_loss: 1.1290 - val_acc: 0.3441\n",
            "Epoch 6/50 - 0.05s - loss: 1.1300 - acc: 0.3322 - val_loss: 1.1280 - val_acc: 0.3441\n",
            "Epoch 7/50 - 0.05s - loss: 1.1289 - acc: 0.3320 - val_loss: 1.1270 - val_acc: 0.3462\n",
            "Epoch 8/50 - 0.05s - loss: 1.1278 - acc: 0.3338 - val_loss: 1.1261 - val_acc: 0.3462\n",
            "Epoch 9/50 - 0.05s - loss: 1.1268 - acc: 0.3347 - val_loss: 1.1252 - val_acc: 0.3462\n",
            "Epoch 10/50 - 0.05s - loss: 1.1258 - acc: 0.3363 - val_loss: 1.1244 - val_acc: 0.3462\n",
            "Epoch 11/50 - 0.05s - loss: 1.1249 - acc: 0.3376 - val_loss: 1.1236 - val_acc: 0.3462\n",
            "Epoch 12/50 - 0.06s - loss: 1.1241 - acc: 0.3390 - val_loss: 1.1228 - val_acc: 0.3502\n",
            "Epoch 13/50 - 0.05s - loss: 1.1233 - acc: 0.3394 - val_loss: 1.1221 - val_acc: 0.3502\n",
            "Epoch 14/50 - 0.05s - loss: 1.1225 - acc: 0.3401 - val_loss: 1.1214 - val_acc: 0.3482\n",
            "Epoch 15/50 - 0.05s - loss: 1.1218 - acc: 0.3414 - val_loss: 1.1208 - val_acc: 0.3522\n",
            "Epoch 16/50 - 0.06s - loss: 1.1211 - acc: 0.3435 - val_loss: 1.1202 - val_acc: 0.3543\n",
            "Epoch 17/50 - 0.05s - loss: 1.1204 - acc: 0.3453 - val_loss: 1.1196 - val_acc: 0.3603\n",
            "Epoch 18/50 - 0.05s - loss: 1.1197 - acc: 0.3457 - val_loss: 1.1190 - val_acc: 0.3603\n",
            "Epoch 19/50 - 0.05s - loss: 1.1191 - acc: 0.3457 - val_loss: 1.1185 - val_acc: 0.3623\n",
            "Epoch 20/50 - 0.06s - loss: 1.1185 - acc: 0.3468 - val_loss: 1.1179 - val_acc: 0.3623\n",
            "Epoch 21/50 - 0.05s - loss: 1.1180 - acc: 0.3475 - val_loss: 1.1174 - val_acc: 0.3603\n",
            "Epoch 22/50 - 0.05s - loss: 1.1174 - acc: 0.3477 - val_loss: 1.1170 - val_acc: 0.3583\n",
            "Epoch 23/50 - 0.05s - loss: 1.1169 - acc: 0.3486 - val_loss: 1.1165 - val_acc: 0.3583\n",
            "Epoch 24/50 - 0.06s - loss: 1.1164 - acc: 0.3504 - val_loss: 1.1160 - val_acc: 0.3603\n",
            "Epoch 25/50 - 0.05s - loss: 1.1159 - acc: 0.3509 - val_loss: 1.1156 - val_acc: 0.3623\n",
            "Epoch 26/50 - 0.05s - loss: 1.1154 - acc: 0.3522 - val_loss: 1.1152 - val_acc: 0.3644\n",
            "Epoch 27/50 - 0.05s - loss: 1.1149 - acc: 0.3534 - val_loss: 1.1147 - val_acc: 0.3644\n",
            "Epoch 28/50 - 0.06s - loss: 1.1145 - acc: 0.3536 - val_loss: 1.1143 - val_acc: 0.3684\n",
            "Epoch 29/50 - 0.05s - loss: 1.1140 - acc: 0.3538 - val_loss: 1.1140 - val_acc: 0.3704\n",
            "Epoch 30/50 - 0.05s - loss: 1.1136 - acc: 0.3554 - val_loss: 1.1136 - val_acc: 0.3704\n",
            "Epoch 31/50 - 0.05s - loss: 1.1132 - acc: 0.3556 - val_loss: 1.1132 - val_acc: 0.3725\n",
            "Epoch 32/50 - 0.05s - loss: 1.1128 - acc: 0.3563 - val_loss: 1.1129 - val_acc: 0.3725\n",
            "Epoch 33/50 - 0.06s - loss: 1.1124 - acc: 0.3570 - val_loss: 1.1125 - val_acc: 0.3704\n",
            "Epoch 34/50 - 0.05s - loss: 1.1120 - acc: 0.3570 - val_loss: 1.1122 - val_acc: 0.3684\n",
            "Epoch 35/50 - 0.05s - loss: 1.1117 - acc: 0.3565 - val_loss: 1.1119 - val_acc: 0.3684\n",
            "Epoch 36/50 - 0.06s - loss: 1.1113 - acc: 0.3545 - val_loss: 1.1116 - val_acc: 0.3684\n",
            "Epoch 37/50 - 0.11s - loss: 1.1110 - acc: 0.3538 - val_loss: 1.1113 - val_acc: 0.3704\n",
            "Epoch 38/50 - 0.09s - loss: 1.1106 - acc: 0.3552 - val_loss: 1.1110 - val_acc: 0.3725\n",
            "Epoch 39/50 - 0.08s - loss: 1.1103 - acc: 0.3565 - val_loss: 1.1107 - val_acc: 0.3765\n",
            "Epoch 40/50 - 0.08s - loss: 1.1100 - acc: 0.3576 - val_loss: 1.1105 - val_acc: 0.3765\n",
            "Epoch 41/50 - 0.10s - loss: 1.1097 - acc: 0.3594 - val_loss: 1.1102 - val_acc: 0.3745\n",
            "Epoch 42/50 - 0.07s - loss: 1.1094 - acc: 0.3601 - val_loss: 1.1100 - val_acc: 0.3725\n",
            "Epoch 43/50 - 0.07s - loss: 1.1091 - acc: 0.3610 - val_loss: 1.1097 - val_acc: 0.3704\n",
            "Epoch 44/50 - 0.07s - loss: 1.1088 - acc: 0.3621 - val_loss: 1.1095 - val_acc: 0.3725\n",
            "Epoch 45/50 - 0.09s - loss: 1.1085 - acc: 0.3608 - val_loss: 1.1093 - val_acc: 0.3725\n",
            "Epoch 46/50 - 0.07s - loss: 1.1082 - acc: 0.3596 - val_loss: 1.1090 - val_acc: 0.3725\n",
            "Epoch 47/50 - 0.07s - loss: 1.1079 - acc: 0.3587 - val_loss: 1.1088 - val_acc: 0.3684\n",
            "Epoch 48/50 - 0.08s - loss: 1.1077 - acc: 0.3594 - val_loss: 1.1086 - val_acc: 0.3704\n",
            "Epoch 49/50 - 0.07s - loss: 1.1074 - acc: 0.3590 - val_loss: 1.1084 - val_acc: 0.3704\n",
            "Epoch 50/50 - 0.07s - loss: 1.1072 - acc: 0.3592 - val_loss: 1.1082 - val_acc: 0.3745\n",
            "\n",
            "Combination 161/252:\n",
            "Hidden Layers: [128, 64, 32], Activation: relu, Learning Rate: 0.0001, Batch Size: 64, Epochs: 100\n",
            "Epoch 1/100 - 0.07s - loss: 1.1101 - acc: 0.2996 - val_loss: 1.1138 - val_acc: 0.2692\n",
            "Epoch 2/100 - 0.06s - loss: 1.1099 - acc: 0.2996 - val_loss: 1.1136 - val_acc: 0.2692\n",
            "Epoch 3/100 - 0.07s - loss: 1.1097 - acc: 0.2989 - val_loss: 1.1134 - val_acc: 0.2692\n",
            "Epoch 4/100 - 0.08s - loss: 1.1096 - acc: 0.2994 - val_loss: 1.1133 - val_acc: 0.2672\n",
            "Epoch 5/100 - 0.06s - loss: 1.1094 - acc: 0.2982 - val_loss: 1.1131 - val_acc: 0.2692\n",
            "Epoch 6/100 - 0.07s - loss: 1.1093 - acc: 0.2980 - val_loss: 1.1130 - val_acc: 0.2672\n",
            "Epoch 7/100 - 0.06s - loss: 1.1091 - acc: 0.2976 - val_loss: 1.1128 - val_acc: 0.2672\n",
            "Epoch 8/100 - 0.07s - loss: 1.1090 - acc: 0.2978 - val_loss: 1.1127 - val_acc: 0.2672\n",
            "Epoch 9/100 - 0.10s - loss: 1.1088 - acc: 0.2973 - val_loss: 1.1126 - val_acc: 0.2672\n",
            "Epoch 10/100 - 0.06s - loss: 1.1087 - acc: 0.2967 - val_loss: 1.1124 - val_acc: 0.2652\n",
            "Epoch 11/100 - 0.06s - loss: 1.1085 - acc: 0.2969 - val_loss: 1.1123 - val_acc: 0.2632\n",
            "Epoch 12/100 - 0.08s - loss: 1.1084 - acc: 0.2967 - val_loss: 1.1122 - val_acc: 0.2611\n",
            "Epoch 13/100 - 0.08s - loss: 1.1083 - acc: 0.2978 - val_loss: 1.1120 - val_acc: 0.2611\n",
            "Epoch 14/100 - 0.07s - loss: 1.1081 - acc: 0.2973 - val_loss: 1.1119 - val_acc: 0.2611\n",
            "Epoch 15/100 - 0.06s - loss: 1.1080 - acc: 0.2976 - val_loss: 1.1118 - val_acc: 0.2611\n",
            "Epoch 16/100 - 0.07s - loss: 1.1079 - acc: 0.2976 - val_loss: 1.1116 - val_acc: 0.2551\n",
            "Epoch 17/100 - 0.07s - loss: 1.1077 - acc: 0.2980 - val_loss: 1.1115 - val_acc: 0.2530\n",
            "Epoch 18/100 - 0.08s - loss: 1.1076 - acc: 0.2989 - val_loss: 1.1114 - val_acc: 0.2551\n",
            "Epoch 19/100 - 0.07s - loss: 1.1075 - acc: 0.2998 - val_loss: 1.1113 - val_acc: 0.2551\n",
            "Epoch 20/100 - 0.07s - loss: 1.1074 - acc: 0.3005 - val_loss: 1.1112 - val_acc: 0.2571\n",
            "Epoch 21/100 - 0.07s - loss: 1.1072 - acc: 0.3003 - val_loss: 1.1111 - val_acc: 0.2551\n",
            "Epoch 22/100 - 0.07s - loss: 1.1071 - acc: 0.3003 - val_loss: 1.1109 - val_acc: 0.2571\n",
            "Epoch 23/100 - 0.06s - loss: 1.1070 - acc: 0.2998 - val_loss: 1.1108 - val_acc: 0.2591\n",
            "Epoch 24/100 - 0.08s - loss: 1.1069 - acc: 0.2994 - val_loss: 1.1107 - val_acc: 0.2632\n",
            "Epoch 25/100 - 0.08s - loss: 1.1068 - acc: 0.3000 - val_loss: 1.1106 - val_acc: 0.2632\n",
            "Epoch 26/100 - 0.07s - loss: 1.1067 - acc: 0.3018 - val_loss: 1.1105 - val_acc: 0.2632\n",
            "Epoch 27/100 - 0.06s - loss: 1.1065 - acc: 0.3007 - val_loss: 1.1104 - val_acc: 0.2591\n",
            "Epoch 28/100 - 0.06s - loss: 1.1064 - acc: 0.3005 - val_loss: 1.1103 - val_acc: 0.2591\n",
            "Epoch 29/100 - 0.07s - loss: 1.1063 - acc: 0.3009 - val_loss: 1.1102 - val_acc: 0.2652\n",
            "Epoch 30/100 - 0.06s - loss: 1.1062 - acc: 0.3012 - val_loss: 1.1101 - val_acc: 0.2692\n",
            "Epoch 31/100 - 0.06s - loss: 1.1061 - acc: 0.3005 - val_loss: 1.1100 - val_acc: 0.2652\n",
            "Epoch 32/100 - 0.07s - loss: 1.1060 - acc: 0.2991 - val_loss: 1.1099 - val_acc: 0.2692\n",
            "Epoch 33/100 - 0.07s - loss: 1.1059 - acc: 0.2996 - val_loss: 1.1099 - val_acc: 0.2733\n",
            "Epoch 34/100 - 0.06s - loss: 1.1058 - acc: 0.2978 - val_loss: 1.1098 - val_acc: 0.2733\n",
            "Epoch 35/100 - 0.07s - loss: 1.1057 - acc: 0.2969 - val_loss: 1.1097 - val_acc: 0.2713\n",
            "Epoch 36/100 - 0.08s - loss: 1.1056 - acc: 0.2969 - val_loss: 1.1096 - val_acc: 0.2692\n",
            "Epoch 37/100 - 0.08s - loss: 1.1055 - acc: 0.2964 - val_loss: 1.1095 - val_acc: 0.2713\n",
            "Epoch 38/100 - 0.07s - loss: 1.1054 - acc: 0.2955 - val_loss: 1.1094 - val_acc: 0.2713\n",
            "Epoch 39/100 - 0.14s - loss: 1.1053 - acc: 0.2960 - val_loss: 1.1093 - val_acc: 0.2713\n",
            "Epoch 40/100 - 0.06s - loss: 1.1052 - acc: 0.2951 - val_loss: 1.1092 - val_acc: 0.2692\n",
            "Epoch 41/100 - 0.06s - loss: 1.1051 - acc: 0.2960 - val_loss: 1.1092 - val_acc: 0.2692\n",
            "Epoch 42/100 - 0.06s - loss: 1.1050 - acc: 0.2955 - val_loss: 1.1091 - val_acc: 0.2733\n",
            "Epoch 43/100 - 0.06s - loss: 1.1049 - acc: 0.2967 - val_loss: 1.1090 - val_acc: 0.2753\n",
            "Epoch 44/100 - 0.06s - loss: 1.1048 - acc: 0.2969 - val_loss: 1.1089 - val_acc: 0.2794\n",
            "Epoch 45/100 - 0.05s - loss: 1.1047 - acc: 0.2962 - val_loss: 1.1088 - val_acc: 0.2794\n",
            "Epoch 46/100 - 0.05s - loss: 1.1046 - acc: 0.2969 - val_loss: 1.1087 - val_acc: 0.2753\n",
            "Epoch 47/100 - 0.05s - loss: 1.1045 - acc: 0.2960 - val_loss: 1.1087 - val_acc: 0.2773\n",
            "Epoch 48/100 - 0.06s - loss: 1.1044 - acc: 0.2976 - val_loss: 1.1086 - val_acc: 0.2753\n",
            "Epoch 49/100 - 0.05s - loss: 1.1043 - acc: 0.2969 - val_loss: 1.1085 - val_acc: 0.2753\n",
            "Epoch 50/100 - 0.06s - loss: 1.1042 - acc: 0.2953 - val_loss: 1.1084 - val_acc: 0.2733\n",
            "Epoch 51/100 - 0.07s - loss: 1.1041 - acc: 0.2951 - val_loss: 1.1084 - val_acc: 0.2713\n",
            "Epoch 52/100 - 0.06s - loss: 1.1040 - acc: 0.2940 - val_loss: 1.1083 - val_acc: 0.2773\n",
            "Epoch 53/100 - 0.06s - loss: 1.1040 - acc: 0.2917 - val_loss: 1.1082 - val_acc: 0.2753\n",
            "Epoch 54/100 - 0.06s - loss: 1.1039 - acc: 0.2922 - val_loss: 1.1081 - val_acc: 0.2814\n",
            "Epoch 55/100 - 0.06s - loss: 1.1038 - acc: 0.2922 - val_loss: 1.1080 - val_acc: 0.2794\n",
            "Epoch 56/100 - 0.06s - loss: 1.1037 - acc: 0.2931 - val_loss: 1.1080 - val_acc: 0.2794\n",
            "Epoch 57/100 - 0.05s - loss: 1.1036 - acc: 0.2931 - val_loss: 1.1079 - val_acc: 0.2753\n",
            "Epoch 58/100 - 0.05s - loss: 1.1035 - acc: 0.2933 - val_loss: 1.1078 - val_acc: 0.2692\n",
            "Epoch 59/100 - 0.06s - loss: 1.1035 - acc: 0.2955 - val_loss: 1.1077 - val_acc: 0.2672\n",
            "Epoch 60/100 - 0.06s - loss: 1.1034 - acc: 0.2962 - val_loss: 1.1077 - val_acc: 0.2713\n",
            "Epoch 61/100 - 0.05s - loss: 1.1033 - acc: 0.2955 - val_loss: 1.1076 - val_acc: 0.2733\n",
            "Epoch 62/100 - 0.05s - loss: 1.1032 - acc: 0.2953 - val_loss: 1.1075 - val_acc: 0.2753\n",
            "Epoch 63/100 - 0.06s - loss: 1.1031 - acc: 0.2951 - val_loss: 1.1074 - val_acc: 0.2713\n",
            "Epoch 64/100 - 0.07s - loss: 1.1030 - acc: 0.2958 - val_loss: 1.1074 - val_acc: 0.2713\n",
            "Epoch 65/100 - 0.05s - loss: 1.1030 - acc: 0.2958 - val_loss: 1.1073 - val_acc: 0.2733\n",
            "Epoch 66/100 - 0.05s - loss: 1.1029 - acc: 0.2967 - val_loss: 1.1072 - val_acc: 0.2733\n",
            "Epoch 67/100 - 0.06s - loss: 1.1028 - acc: 0.2967 - val_loss: 1.1072 - val_acc: 0.2733\n",
            "Epoch 68/100 - 0.06s - loss: 1.1027 - acc: 0.2980 - val_loss: 1.1071 - val_acc: 0.2672\n",
            "Epoch 69/100 - 0.07s - loss: 1.1026 - acc: 0.2985 - val_loss: 1.1070 - val_acc: 0.2652\n",
            "Epoch 70/100 - 0.05s - loss: 1.1026 - acc: 0.2994 - val_loss: 1.1069 - val_acc: 0.2632\n",
            "Epoch 71/100 - 0.08s - loss: 1.1025 - acc: 0.3007 - val_loss: 1.1069 - val_acc: 0.2611\n",
            "Epoch 72/100 - 0.07s - loss: 1.1024 - acc: 0.3007 - val_loss: 1.1068 - val_acc: 0.2632\n",
            "Epoch 73/100 - 0.06s - loss: 1.1023 - acc: 0.3005 - val_loss: 1.1067 - val_acc: 0.2632\n",
            "Epoch 74/100 - 0.06s - loss: 1.1022 - acc: 0.3012 - val_loss: 1.1067 - val_acc: 0.2632\n",
            "Epoch 75/100 - 0.06s - loss: 1.1022 - acc: 0.3009 - val_loss: 1.1066 - val_acc: 0.2652\n",
            "Epoch 76/100 - 0.06s - loss: 1.1021 - acc: 0.3007 - val_loss: 1.1065 - val_acc: 0.2713\n",
            "Epoch 77/100 - 0.05s - loss: 1.1020 - acc: 0.3009 - val_loss: 1.1065 - val_acc: 0.2713\n",
            "Epoch 78/100 - 0.05s - loss: 1.1019 - acc: 0.3018 - val_loss: 1.1064 - val_acc: 0.2753\n",
            "Epoch 79/100 - 0.06s - loss: 1.1019 - acc: 0.3023 - val_loss: 1.1063 - val_acc: 0.2733\n",
            "Epoch 80/100 - 0.06s - loss: 1.1018 - acc: 0.3014 - val_loss: 1.1063 - val_acc: 0.2733\n",
            "Epoch 81/100 - 0.05s - loss: 1.1017 - acc: 0.3021 - val_loss: 1.1062 - val_acc: 0.2733\n",
            "Epoch 82/100 - 0.05s - loss: 1.1017 - acc: 0.3048 - val_loss: 1.1061 - val_acc: 0.2692\n",
            "Epoch 83/100 - 0.06s - loss: 1.1016 - acc: 0.3059 - val_loss: 1.1061 - val_acc: 0.2733\n",
            "Epoch 84/100 - 0.07s - loss: 1.1015 - acc: 0.3063 - val_loss: 1.1060 - val_acc: 0.2733\n",
            "Epoch 85/100 - 0.06s - loss: 1.1014 - acc: 0.3072 - val_loss: 1.1059 - val_acc: 0.2733\n",
            "Epoch 86/100 - 0.06s - loss: 1.1014 - acc: 0.3075 - val_loss: 1.1059 - val_acc: 0.2733\n",
            "Epoch 87/100 - 0.07s - loss: 1.1013 - acc: 0.3090 - val_loss: 1.1058 - val_acc: 0.2713\n",
            "Epoch 88/100 - 0.07s - loss: 1.1012 - acc: 0.3099 - val_loss: 1.1057 - val_acc: 0.2713\n",
            "Epoch 89/100 - 0.06s - loss: 1.1012 - acc: 0.3117 - val_loss: 1.1057 - val_acc: 0.2692\n",
            "Epoch 90/100 - 0.06s - loss: 1.1011 - acc: 0.3120 - val_loss: 1.1056 - val_acc: 0.2672\n",
            "Epoch 91/100 - 0.06s - loss: 1.1010 - acc: 0.3108 - val_loss: 1.1056 - val_acc: 0.2672\n",
            "Epoch 92/100 - 0.07s - loss: 1.1009 - acc: 0.3115 - val_loss: 1.1055 - val_acc: 0.2652\n",
            "Epoch 93/100 - 0.06s - loss: 1.1009 - acc: 0.3120 - val_loss: 1.1054 - val_acc: 0.2672\n",
            "Epoch 94/100 - 0.05s - loss: 1.1008 - acc: 0.3120 - val_loss: 1.1054 - val_acc: 0.2713\n",
            "Epoch 95/100 - 0.06s - loss: 1.1007 - acc: 0.3135 - val_loss: 1.1053 - val_acc: 0.2713\n",
            "Epoch 96/100 - 0.06s - loss: 1.1007 - acc: 0.3138 - val_loss: 1.1053 - val_acc: 0.2692\n",
            "Epoch 97/100 - 0.05s - loss: 1.1006 - acc: 0.3144 - val_loss: 1.1052 - val_acc: 0.2672\n",
            "Epoch 98/100 - 0.05s - loss: 1.1005 - acc: 0.3156 - val_loss: 1.1051 - val_acc: 0.2692\n",
            "Epoch 99/100 - 0.06s - loss: 1.1005 - acc: 0.3160 - val_loss: 1.1051 - val_acc: 0.2672\n",
            "Epoch 100/100 - 0.06s - loss: 1.1004 - acc: 0.3162 - val_loss: 1.1050 - val_acc: 0.2713\n",
            "\n",
            "Combination 162/252:\n",
            "Hidden Layers: [128, 64, 32], Activation: relu, Learning Rate: 0.0001, Batch Size: 64, Epochs: 150\n",
            "Epoch 1/150 - 0.06s - loss: 1.1040 - acc: 0.3538 - val_loss: 1.0995 - val_acc: 0.3563\n",
            "Epoch 2/150 - 0.08s - loss: 1.1036 - acc: 0.3538 - val_loss: 1.0993 - val_acc: 0.3563\n",
            "Epoch 3/150 - 0.06s - loss: 1.1033 - acc: 0.3538 - val_loss: 1.0991 - val_acc: 0.3563\n",
            "Epoch 4/150 - 0.05s - loss: 1.1030 - acc: 0.3531 - val_loss: 1.0989 - val_acc: 0.3583\n",
            "Epoch 5/150 - 0.05s - loss: 1.1028 - acc: 0.3531 - val_loss: 1.0988 - val_acc: 0.3583\n",
            "Epoch 6/150 - 0.05s - loss: 1.1025 - acc: 0.3529 - val_loss: 1.0986 - val_acc: 0.3563\n",
            "Epoch 7/150 - 0.05s - loss: 1.1022 - acc: 0.3529 - val_loss: 1.0984 - val_acc: 0.3563\n",
            "Epoch 8/150 - 0.06s - loss: 1.1020 - acc: 0.3538 - val_loss: 1.0983 - val_acc: 0.3563\n",
            "Epoch 9/150 - 0.05s - loss: 1.1017 - acc: 0.3540 - val_loss: 1.0981 - val_acc: 0.3563\n",
            "Epoch 10/150 - 0.05s - loss: 1.1015 - acc: 0.3540 - val_loss: 1.0980 - val_acc: 0.3563\n",
            "Epoch 11/150 - 0.05s - loss: 1.1013 - acc: 0.3545 - val_loss: 1.0978 - val_acc: 0.3603\n",
            "Epoch 12/150 - 0.06s - loss: 1.1010 - acc: 0.3545 - val_loss: 1.0977 - val_acc: 0.3603\n",
            "Epoch 13/150 - 0.05s - loss: 1.1008 - acc: 0.3549 - val_loss: 1.0976 - val_acc: 0.3583\n",
            "Epoch 14/150 - 0.05s - loss: 1.1006 - acc: 0.3552 - val_loss: 1.0974 - val_acc: 0.3583\n",
            "Epoch 15/150 - 0.06s - loss: 1.1004 - acc: 0.3558 - val_loss: 1.0973 - val_acc: 0.3583\n",
            "Epoch 16/150 - 0.05s - loss: 1.1002 - acc: 0.3565 - val_loss: 1.0972 - val_acc: 0.3583\n",
            "Epoch 17/150 - 0.06s - loss: 1.1000 - acc: 0.3563 - val_loss: 1.0971 - val_acc: 0.3583\n",
            "Epoch 18/150 - 0.05s - loss: 1.0998 - acc: 0.3565 - val_loss: 1.0970 - val_acc: 0.3583\n",
            "Epoch 19/150 - 0.06s - loss: 1.0997 - acc: 0.3572 - val_loss: 1.0969 - val_acc: 0.3583\n",
            "Epoch 20/150 - 0.07s - loss: 1.0995 - acc: 0.3576 - val_loss: 1.0968 - val_acc: 0.3583\n",
            "Epoch 21/150 - 0.06s - loss: 1.0993 - acc: 0.3576 - val_loss: 1.0967 - val_acc: 0.3583\n",
            "Epoch 22/150 - 0.06s - loss: 1.0991 - acc: 0.3578 - val_loss: 1.0966 - val_acc: 0.3583\n",
            "Epoch 23/150 - 0.06s - loss: 1.0990 - acc: 0.3583 - val_loss: 1.0965 - val_acc: 0.3583\n",
            "Epoch 24/150 - 0.05s - loss: 1.0988 - acc: 0.3587 - val_loss: 1.0964 - val_acc: 0.3583\n",
            "Epoch 25/150 - 0.05s - loss: 1.0986 - acc: 0.3585 - val_loss: 1.0963 - val_acc: 0.3583\n",
            "Epoch 26/150 - 0.05s - loss: 1.0985 - acc: 0.3587 - val_loss: 1.0963 - val_acc: 0.3603\n",
            "Epoch 27/150 - 0.06s - loss: 1.0983 - acc: 0.3585 - val_loss: 1.0962 - val_acc: 0.3603\n",
            "Epoch 28/150 - 0.08s - loss: 1.0982 - acc: 0.3592 - val_loss: 1.0961 - val_acc: 0.3644\n",
            "Epoch 29/150 - 0.08s - loss: 1.0981 - acc: 0.3594 - val_loss: 1.0960 - val_acc: 0.3644\n",
            "Epoch 30/150 - 0.08s - loss: 1.0979 - acc: 0.3587 - val_loss: 1.0959 - val_acc: 0.3644\n",
            "Epoch 31/150 - 0.12s - loss: 1.0978 - acc: 0.3587 - val_loss: 1.0959 - val_acc: 0.3623\n",
            "Epoch 32/150 - 0.06s - loss: 1.0977 - acc: 0.3596 - val_loss: 1.0958 - val_acc: 0.3623\n",
            "Epoch 33/150 - 0.07s - loss: 1.0975 - acc: 0.3592 - val_loss: 1.0957 - val_acc: 0.3623\n",
            "Epoch 34/150 - 0.07s - loss: 1.0974 - acc: 0.3590 - val_loss: 1.0956 - val_acc: 0.3644\n",
            "Epoch 35/150 - 0.06s - loss: 1.0973 - acc: 0.3594 - val_loss: 1.0956 - val_acc: 0.3603\n",
            "Epoch 36/150 - 0.06s - loss: 1.0972 - acc: 0.3601 - val_loss: 1.0955 - val_acc: 0.3603\n",
            "Epoch 37/150 - 0.06s - loss: 1.0970 - acc: 0.3592 - val_loss: 1.0954 - val_acc: 0.3623\n",
            "Epoch 38/150 - 0.06s - loss: 1.0969 - acc: 0.3601 - val_loss: 1.0954 - val_acc: 0.3603\n",
            "Epoch 39/150 - 0.06s - loss: 1.0968 - acc: 0.3594 - val_loss: 1.0953 - val_acc: 0.3603\n",
            "Epoch 40/150 - 0.06s - loss: 1.0967 - acc: 0.3590 - val_loss: 1.0952 - val_acc: 0.3583\n",
            "Epoch 41/150 - 0.06s - loss: 1.0966 - acc: 0.3594 - val_loss: 1.0952 - val_acc: 0.3583\n",
            "Epoch 42/150 - 0.06s - loss: 1.0965 - acc: 0.3605 - val_loss: 1.0951 - val_acc: 0.3563\n",
            "Epoch 43/150 - 0.05s - loss: 1.0963 - acc: 0.3612 - val_loss: 1.0951 - val_acc: 0.3583\n",
            "Epoch 44/150 - 0.05s - loss: 1.0962 - acc: 0.3605 - val_loss: 1.0950 - val_acc: 0.3543\n",
            "Epoch 45/150 - 0.06s - loss: 1.0961 - acc: 0.3612 - val_loss: 1.0949 - val_acc: 0.3563\n",
            "Epoch 46/150 - 0.06s - loss: 1.0960 - acc: 0.3610 - val_loss: 1.0949 - val_acc: 0.3563\n",
            "Epoch 47/150 - 0.06s - loss: 1.0959 - acc: 0.3610 - val_loss: 1.0948 - val_acc: 0.3563\n",
            "Epoch 48/150 - 0.06s - loss: 1.0958 - acc: 0.3614 - val_loss: 1.0948 - val_acc: 0.3522\n",
            "Epoch 49/150 - 0.06s - loss: 1.0957 - acc: 0.3617 - val_loss: 1.0947 - val_acc: 0.3502\n",
            "Epoch 50/150 - 0.07s - loss: 1.0956 - acc: 0.3608 - val_loss: 1.0947 - val_acc: 0.3482\n",
            "Epoch 51/150 - 0.07s - loss: 1.0955 - acc: 0.3614 - val_loss: 1.0946 - val_acc: 0.3482\n",
            "Epoch 52/150 - 0.06s - loss: 1.0954 - acc: 0.3623 - val_loss: 1.0945 - val_acc: 0.3482\n",
            "Epoch 53/150 - 0.07s - loss: 1.0953 - acc: 0.3626 - val_loss: 1.0945 - val_acc: 0.3462\n",
            "Epoch 54/150 - 0.06s - loss: 1.0952 - acc: 0.3626 - val_loss: 1.0944 - val_acc: 0.3462\n",
            "Epoch 55/150 - 0.05s - loss: 1.0951 - acc: 0.3630 - val_loss: 1.0944 - val_acc: 0.3462\n",
            "Epoch 56/150 - 0.06s - loss: 1.0951 - acc: 0.3626 - val_loss: 1.0943 - val_acc: 0.3462\n",
            "Epoch 57/150 - 0.06s - loss: 1.0950 - acc: 0.3637 - val_loss: 1.0943 - val_acc: 0.3522\n",
            "Epoch 58/150 - 0.06s - loss: 1.0949 - acc: 0.3646 - val_loss: 1.0942 - val_acc: 0.3522\n",
            "Epoch 59/150 - 0.05s - loss: 1.0948 - acc: 0.3637 - val_loss: 1.0942 - val_acc: 0.3502\n",
            "Epoch 60/150 - 0.06s - loss: 1.0947 - acc: 0.3644 - val_loss: 1.0941 - val_acc: 0.3502\n",
            "Epoch 61/150 - 0.06s - loss: 1.0946 - acc: 0.3646 - val_loss: 1.0941 - val_acc: 0.3543\n",
            "Epoch 62/150 - 0.06s - loss: 1.0945 - acc: 0.3657 - val_loss: 1.0940 - val_acc: 0.3522\n",
            "Epoch 63/150 - 0.07s - loss: 1.0944 - acc: 0.3668 - val_loss: 1.0940 - val_acc: 0.3522\n",
            "Epoch 64/150 - 0.06s - loss: 1.0944 - acc: 0.3668 - val_loss: 1.0939 - val_acc: 0.3522\n",
            "Epoch 65/150 - 0.08s - loss: 1.0943 - acc: 0.3668 - val_loss: 1.0939 - val_acc: 0.3502\n",
            "Epoch 66/150 - 0.07s - loss: 1.0942 - acc: 0.3689 - val_loss: 1.0938 - val_acc: 0.3522\n",
            "Epoch 67/150 - 0.06s - loss: 1.0941 - acc: 0.3691 - val_loss: 1.0938 - val_acc: 0.3522\n",
            "Epoch 68/150 - 0.06s - loss: 1.0940 - acc: 0.3700 - val_loss: 1.0937 - val_acc: 0.3563\n",
            "Epoch 69/150 - 0.06s - loss: 1.0939 - acc: 0.3702 - val_loss: 1.0937 - val_acc: 0.3563\n",
            "Epoch 70/150 - 0.06s - loss: 1.0939 - acc: 0.3700 - val_loss: 1.0936 - val_acc: 0.3583\n",
            "Epoch 71/150 - 0.06s - loss: 1.0938 - acc: 0.3713 - val_loss: 1.0936 - val_acc: 0.3583\n",
            "Epoch 72/150 - 0.06s - loss: 1.0937 - acc: 0.3722 - val_loss: 1.0936 - val_acc: 0.3583\n",
            "Epoch 73/150 - 0.06s - loss: 1.0936 - acc: 0.3722 - val_loss: 1.0935 - val_acc: 0.3583\n",
            "Epoch 74/150 - 0.06s - loss: 1.0936 - acc: 0.3722 - val_loss: 1.0935 - val_acc: 0.3583\n",
            "Epoch 75/150 - 0.05s - loss: 1.0935 - acc: 0.3718 - val_loss: 1.0934 - val_acc: 0.3563\n",
            "Epoch 76/150 - 0.05s - loss: 1.0934 - acc: 0.3716 - val_loss: 1.0934 - val_acc: 0.3543\n",
            "Epoch 77/150 - 0.06s - loss: 1.0933 - acc: 0.3711 - val_loss: 1.0933 - val_acc: 0.3563\n",
            "Epoch 78/150 - 0.07s - loss: 1.0932 - acc: 0.3700 - val_loss: 1.0933 - val_acc: 0.3583\n",
            "Epoch 79/150 - 0.05s - loss: 1.0932 - acc: 0.3707 - val_loss: 1.0932 - val_acc: 0.3603\n",
            "Epoch 80/150 - 0.06s - loss: 1.0931 - acc: 0.3711 - val_loss: 1.0932 - val_acc: 0.3704\n",
            "Epoch 81/150 - 0.06s - loss: 1.0930 - acc: 0.3716 - val_loss: 1.0931 - val_acc: 0.3704\n",
            "Epoch 82/150 - 0.07s - loss: 1.0929 - acc: 0.3713 - val_loss: 1.0931 - val_acc: 0.3704\n",
            "Epoch 83/150 - 0.06s - loss: 1.0929 - acc: 0.3716 - val_loss: 1.0930 - val_acc: 0.3684\n",
            "Epoch 84/150 - 0.06s - loss: 1.0928 - acc: 0.3718 - val_loss: 1.0930 - val_acc: 0.3684\n",
            "Epoch 85/150 - 0.06s - loss: 1.0927 - acc: 0.3718 - val_loss: 1.0929 - val_acc: 0.3684\n",
            "Epoch 86/150 - 0.06s - loss: 1.0927 - acc: 0.3716 - val_loss: 1.0929 - val_acc: 0.3664\n",
            "Epoch 87/150 - 0.05s - loss: 1.0926 - acc: 0.3713 - val_loss: 1.0928 - val_acc: 0.3644\n",
            "Epoch 88/150 - 0.06s - loss: 1.0925 - acc: 0.3720 - val_loss: 1.0928 - val_acc: 0.3664\n",
            "Epoch 89/150 - 0.06s - loss: 1.0924 - acc: 0.3711 - val_loss: 1.0927 - val_acc: 0.3664\n",
            "Epoch 90/150 - 0.07s - loss: 1.0924 - acc: 0.3713 - val_loss: 1.0927 - val_acc: 0.3664\n",
            "Epoch 91/150 - 0.05s - loss: 1.0923 - acc: 0.3709 - val_loss: 1.0927 - val_acc: 0.3664\n",
            "Epoch 92/150 - 0.05s - loss: 1.0922 - acc: 0.3707 - val_loss: 1.0926 - val_acc: 0.3664\n",
            "Epoch 93/150 - 0.06s - loss: 1.0922 - acc: 0.3700 - val_loss: 1.0926 - val_acc: 0.3664\n",
            "Epoch 94/150 - 0.06s - loss: 1.0921 - acc: 0.3704 - val_loss: 1.0925 - val_acc: 0.3684\n",
            "Epoch 95/150 - 0.09s - loss: 1.0920 - acc: 0.3716 - val_loss: 1.0925 - val_acc: 0.3725\n",
            "Epoch 96/150 - 0.06s - loss: 1.0920 - acc: 0.3709 - val_loss: 1.0924 - val_acc: 0.3725\n",
            "Epoch 97/150 - 0.07s - loss: 1.0919 - acc: 0.3709 - val_loss: 1.0924 - val_acc: 0.3704\n",
            "Epoch 98/150 - 0.06s - loss: 1.0918 - acc: 0.3711 - val_loss: 1.0923 - val_acc: 0.3704\n",
            "Epoch 99/150 - 0.06s - loss: 1.0918 - acc: 0.3716 - val_loss: 1.0923 - val_acc: 0.3684\n",
            "Epoch 100/150 - 0.06s - loss: 1.0917 - acc: 0.3707 - val_loss: 1.0922 - val_acc: 0.3684\n",
            "Epoch 101/150 - 0.06s - loss: 1.0916 - acc: 0.3702 - val_loss: 1.0922 - val_acc: 0.3684\n",
            "Epoch 102/150 - 0.07s - loss: 1.0916 - acc: 0.3704 - val_loss: 1.0921 - val_acc: 0.3664\n",
            "Epoch 103/150 - 0.05s - loss: 1.0915 - acc: 0.3707 - val_loss: 1.0921 - val_acc: 0.3684\n",
            "Epoch 104/150 - 0.06s - loss: 1.0914 - acc: 0.3722 - val_loss: 1.0920 - val_acc: 0.3684\n",
            "Epoch 105/150 - 0.06s - loss: 1.0914 - acc: 0.3718 - val_loss: 1.0920 - val_acc: 0.3664\n",
            "Epoch 106/150 - 0.06s - loss: 1.0913 - acc: 0.3709 - val_loss: 1.0919 - val_acc: 0.3664\n",
            "Epoch 107/150 - 0.05s - loss: 1.0912 - acc: 0.3707 - val_loss: 1.0919 - val_acc: 0.3664\n",
            "Epoch 108/150 - 0.06s - loss: 1.0912 - acc: 0.3711 - val_loss: 1.0918 - val_acc: 0.3664\n",
            "Epoch 109/150 - 0.06s - loss: 1.0911 - acc: 0.3704 - val_loss: 1.0918 - val_acc: 0.3664\n",
            "Epoch 110/150 - 0.06s - loss: 1.0910 - acc: 0.3713 - val_loss: 1.0917 - val_acc: 0.3664\n",
            "Epoch 111/150 - 0.06s - loss: 1.0910 - acc: 0.3716 - val_loss: 1.0917 - val_acc: 0.3684\n",
            "Epoch 112/150 - 0.06s - loss: 1.0909 - acc: 0.3720 - val_loss: 1.0916 - val_acc: 0.3684\n",
            "Epoch 113/150 - 0.06s - loss: 1.0908 - acc: 0.3716 - val_loss: 1.0916 - val_acc: 0.3684\n",
            "Epoch 114/150 - 0.05s - loss: 1.0908 - acc: 0.3722 - val_loss: 1.0915 - val_acc: 0.3664\n",
            "Epoch 115/150 - 0.05s - loss: 1.0907 - acc: 0.3718 - val_loss: 1.0915 - val_acc: 0.3664\n",
            "Epoch 116/150 - 0.06s - loss: 1.0906 - acc: 0.3720 - val_loss: 1.0914 - val_acc: 0.3664\n",
            "Epoch 117/150 - 0.06s - loss: 1.0906 - acc: 0.3729 - val_loss: 1.0914 - val_acc: 0.3664\n",
            "Epoch 118/150 - 0.05s - loss: 1.0905 - acc: 0.3729 - val_loss: 1.0913 - val_acc: 0.3644\n",
            "Epoch 119/150 - 0.06s - loss: 1.0904 - acc: 0.3734 - val_loss: 1.0913 - val_acc: 0.3664\n",
            "Epoch 120/150 - 0.06s - loss: 1.0904 - acc: 0.3731 - val_loss: 1.0913 - val_acc: 0.3623\n",
            "Epoch 121/150 - 0.06s - loss: 1.0903 - acc: 0.3747 - val_loss: 1.0912 - val_acc: 0.3623\n",
            "Epoch 122/150 - 0.05s - loss: 1.0902 - acc: 0.3749 - val_loss: 1.0912 - val_acc: 0.3644\n",
            "Epoch 123/150 - 0.06s - loss: 1.0902 - acc: 0.3756 - val_loss: 1.0911 - val_acc: 0.3664\n",
            "Epoch 124/150 - 0.06s - loss: 1.0901 - acc: 0.3758 - val_loss: 1.0911 - val_acc: 0.3664\n",
            "Epoch 125/150 - 0.11s - loss: 1.0900 - acc: 0.3763 - val_loss: 1.0910 - val_acc: 0.3644\n",
            "Epoch 126/150 - 0.06s - loss: 1.0900 - acc: 0.3758 - val_loss: 1.0910 - val_acc: 0.3684\n",
            "Epoch 127/150 - 0.06s - loss: 1.0899 - acc: 0.3763 - val_loss: 1.0909 - val_acc: 0.3684\n",
            "Epoch 128/150 - 0.07s - loss: 1.0898 - acc: 0.3765 - val_loss: 1.0909 - val_acc: 0.3684\n",
            "Epoch 129/150 - 0.06s - loss: 1.0898 - acc: 0.3763 - val_loss: 1.0908 - val_acc: 0.3704\n",
            "Epoch 130/150 - 0.06s - loss: 1.0897 - acc: 0.3763 - val_loss: 1.0908 - val_acc: 0.3704\n",
            "Epoch 131/150 - 0.06s - loss: 1.0897 - acc: 0.3774 - val_loss: 1.0907 - val_acc: 0.3684\n",
            "Epoch 132/150 - 0.06s - loss: 1.0896 - acc: 0.3770 - val_loss: 1.0907 - val_acc: 0.3704\n",
            "Epoch 133/150 - 0.06s - loss: 1.0895 - acc: 0.3774 - val_loss: 1.0906 - val_acc: 0.3684\n",
            "Epoch 134/150 - 0.05s - loss: 1.0895 - acc: 0.3776 - val_loss: 1.0906 - val_acc: 0.3664\n",
            "Epoch 135/150 - 0.05s - loss: 1.0894 - acc: 0.3812 - val_loss: 1.0905 - val_acc: 0.3664\n",
            "Epoch 136/150 - 0.07s - loss: 1.0893 - acc: 0.3826 - val_loss: 1.0905 - val_acc: 0.3664\n",
            "Epoch 137/150 - 0.06s - loss: 1.0893 - acc: 0.3828 - val_loss: 1.0904 - val_acc: 0.3664\n",
            "Epoch 138/150 - 0.06s - loss: 1.0892 - acc: 0.3833 - val_loss: 1.0904 - val_acc: 0.3664\n",
            "Epoch 139/150 - 0.06s - loss: 1.0891 - acc: 0.3835 - val_loss: 1.0903 - val_acc: 0.3684\n",
            "Epoch 140/150 - 0.06s - loss: 1.0891 - acc: 0.3837 - val_loss: 1.0902 - val_acc: 0.3684\n",
            "Epoch 141/150 - 0.05s - loss: 1.0890 - acc: 0.3844 - val_loss: 1.0902 - val_acc: 0.3684\n",
            "Epoch 142/150 - 0.05s - loss: 1.0889 - acc: 0.3833 - val_loss: 1.0901 - val_acc: 0.3684\n",
            "Epoch 143/150 - 0.06s - loss: 1.0889 - acc: 0.3821 - val_loss: 1.0901 - val_acc: 0.3684\n",
            "Epoch 144/150 - 0.07s - loss: 1.0888 - acc: 0.3830 - val_loss: 1.0900 - val_acc: 0.3684\n",
            "Epoch 145/150 - 0.06s - loss: 1.0888 - acc: 0.3833 - val_loss: 1.0900 - val_acc: 0.3684\n",
            "Epoch 146/150 - 0.06s - loss: 1.0887 - acc: 0.3835 - val_loss: 1.0899 - val_acc: 0.3704\n",
            "Epoch 147/150 - 0.06s - loss: 1.0886 - acc: 0.3826 - val_loss: 1.0899 - val_acc: 0.3725\n",
            "Epoch 148/150 - 0.06s - loss: 1.0886 - acc: 0.3833 - val_loss: 1.0898 - val_acc: 0.3725\n",
            "Epoch 149/150 - 0.06s - loss: 1.0885 - acc: 0.3839 - val_loss: 1.0898 - val_acc: 0.3725\n",
            "Epoch 150/150 - 0.06s - loss: 1.0884 - acc: 0.3844 - val_loss: 1.0897 - val_acc: 0.3725\n",
            "\n",
            "Combination 163/252:\n",
            "Hidden Layers: [128, 64, 32], Activation: tanh, Learning Rate: 0.01, Batch Size: 32, Epochs: 50\n",
            "Epoch 1/50 - 0.11s - loss: 1.0779 - acc: 0.4107 - val_loss: 1.0822 - val_acc: 0.3988\n",
            "Epoch 2/50 - 0.10s - loss: 1.0641 - acc: 0.4483 - val_loss: 1.0701 - val_acc: 0.4393\n",
            "Epoch 3/50 - 0.10s - loss: 1.0518 - acc: 0.4629 - val_loss: 1.0620 - val_acc: 0.4534\n",
            "Epoch 4/50 - 0.10s - loss: 1.0427 - acc: 0.4739 - val_loss: 1.0550 - val_acc: 0.4615\n",
            "Epoch 5/50 - 0.10s - loss: 1.0311 - acc: 0.4858 - val_loss: 1.0469 - val_acc: 0.4757\n",
            "Epoch 6/50 - 0.11s - loss: 1.0237 - acc: 0.4901 - val_loss: 1.0411 - val_acc: 0.4818\n",
            "Epoch 7/50 - 0.11s - loss: 1.0123 - acc: 0.5016 - val_loss: 1.0344 - val_acc: 0.4980\n",
            "Epoch 8/50 - 0.10s - loss: 1.0034 - acc: 0.5088 - val_loss: 1.0280 - val_acc: 0.4980\n",
            "Epoch 9/50 - 0.10s - loss: 0.9954 - acc: 0.5090 - val_loss: 1.0210 - val_acc: 0.5000\n",
            "Epoch 10/50 - 0.10s - loss: 0.9930 - acc: 0.5175 - val_loss: 1.0216 - val_acc: 0.4879\n",
            "Epoch 11/50 - 0.11s - loss: 0.9803 - acc: 0.5187 - val_loss: 1.0095 - val_acc: 0.5142\n",
            "Epoch 12/50 - 0.10s - loss: 0.9782 - acc: 0.5252 - val_loss: 1.0106 - val_acc: 0.5040\n",
            "Epoch 13/50 - 0.10s - loss: 0.9670 - acc: 0.5346 - val_loss: 0.9977 - val_acc: 0.5162\n",
            "Epoch 14/50 - 0.13s - loss: 0.9673 - acc: 0.5306 - val_loss: 0.9984 - val_acc: 0.5283\n",
            "Epoch 15/50 - 0.10s - loss: 0.9747 - acc: 0.5180 - val_loss: 1.0102 - val_acc: 0.4919\n",
            "Epoch 16/50 - 0.10s - loss: 0.9589 - acc: 0.5405 - val_loss: 0.9957 - val_acc: 0.5182\n",
            "Epoch 17/50 - 0.12s - loss: 0.9449 - acc: 0.5472 - val_loss: 0.9830 - val_acc: 0.5304\n",
            "Epoch 18/50 - 0.11s - loss: 0.9387 - acc: 0.5538 - val_loss: 0.9781 - val_acc: 0.5243\n",
            "Epoch 19/50 - 0.10s - loss: 0.9405 - acc: 0.5524 - val_loss: 0.9825 - val_acc: 0.5344\n",
            "Epoch 20/50 - 0.10s - loss: 0.9325 - acc: 0.5535 - val_loss: 0.9730 - val_acc: 0.5304\n",
            "Epoch 21/50 - 0.11s - loss: 0.9316 - acc: 0.5596 - val_loss: 0.9743 - val_acc: 0.5405\n",
            "Epoch 22/50 - 0.10s - loss: 0.9237 - acc: 0.5612 - val_loss: 0.9707 - val_acc: 0.5324\n",
            "Epoch 23/50 - 0.10s - loss: 0.9225 - acc: 0.5682 - val_loss: 0.9680 - val_acc: 0.5324\n",
            "Epoch 24/50 - 0.10s - loss: 0.9186 - acc: 0.5607 - val_loss: 0.9670 - val_acc: 0.5243\n",
            "Epoch 25/50 - 0.11s - loss: 0.9338 - acc: 0.5452 - val_loss: 0.9818 - val_acc: 0.5000\n",
            "Epoch 26/50 - 0.10s - loss: 0.9174 - acc: 0.5607 - val_loss: 0.9733 - val_acc: 0.5202\n",
            "Epoch 27/50 - 0.10s - loss: 0.9067 - acc: 0.5787 - val_loss: 0.9578 - val_acc: 0.5405\n",
            "Epoch 28/50 - 0.10s - loss: 0.9154 - acc: 0.5666 - val_loss: 0.9739 - val_acc: 0.5223\n",
            "Epoch 29/50 - 0.10s - loss: 0.9001 - acc: 0.5794 - val_loss: 0.9559 - val_acc: 0.5324\n",
            "Epoch 30/50 - 0.10s - loss: 0.9498 - acc: 0.5502 - val_loss: 1.0001 - val_acc: 0.5405\n",
            "Epoch 31/50 - 0.11s - loss: 0.8991 - acc: 0.5803 - val_loss: 0.9630 - val_acc: 0.5344\n",
            "Epoch 32/50 - 0.10s - loss: 0.9304 - acc: 0.5423 - val_loss: 0.9914 - val_acc: 0.4960\n",
            "Epoch 33/50 - 0.10s - loss: 0.9041 - acc: 0.5713 - val_loss: 0.9698 - val_acc: 0.5121\n",
            "Epoch 34/50 - 0.10s - loss: 0.9083 - acc: 0.5789 - val_loss: 0.9723 - val_acc: 0.5445\n",
            "Epoch 35/50 - 0.10s - loss: 0.8860 - acc: 0.5852 - val_loss: 0.9543 - val_acc: 0.5486\n",
            "Epoch 36/50 - 0.10s - loss: 0.8837 - acc: 0.5870 - val_loss: 0.9508 - val_acc: 0.5506\n",
            "Epoch 37/50 - 0.11s - loss: 0.9213 - acc: 0.5677 - val_loss: 0.9835 - val_acc: 0.5364\n",
            "Epoch 38/50 - 0.10s - loss: 0.8944 - acc: 0.5765 - val_loss: 0.9761 - val_acc: 0.5040\n",
            "Epoch 39/50 - 0.10s - loss: 0.8780 - acc: 0.5911 - val_loss: 0.9552 - val_acc: 0.5425\n",
            "Epoch 40/50 - 0.10s - loss: 0.8766 - acc: 0.5915 - val_loss: 0.9518 - val_acc: 0.5405\n",
            "Epoch 41/50 - 0.10s - loss: 0.8815 - acc: 0.5873 - val_loss: 0.9641 - val_acc: 0.5304\n",
            "Epoch 42/50 - 0.10s - loss: 0.8970 - acc: 0.5735 - val_loss: 0.9842 - val_acc: 0.5040\n",
            "Epoch 43/50 - 0.11s - loss: 0.8715 - acc: 0.5945 - val_loss: 0.9514 - val_acc: 0.5567\n",
            "Epoch 44/50 - 0.10s - loss: 0.8776 - acc: 0.5870 - val_loss: 0.9551 - val_acc: 0.5607\n",
            "Epoch 45/50 - 0.10s - loss: 0.8786 - acc: 0.5855 - val_loss: 0.9632 - val_acc: 0.5547\n",
            "Epoch 46/50 - 0.14s - loss: 0.8680 - acc: 0.6039 - val_loss: 0.9557 - val_acc: 0.5506\n",
            "Epoch 47/50 - 0.10s - loss: 0.8753 - acc: 0.5913 - val_loss: 0.9621 - val_acc: 0.5405\n",
            "Epoch 48/50 - 0.10s - loss: 0.8726 - acc: 0.5936 - val_loss: 0.9537 - val_acc: 0.5547\n",
            "Epoch 49/50 - 0.11s - loss: 0.8611 - acc: 0.6003 - val_loss: 0.9516 - val_acc: 0.5425\n",
            "Epoch 50/50 - 0.11s - loss: 0.8757 - acc: 0.5929 - val_loss: 0.9782 - val_acc: 0.5263\n",
            "\n",
            "Combination 164/252:\n",
            "Hidden Layers: [128, 64, 32], Activation: tanh, Learning Rate: 0.01, Batch Size: 32, Epochs: 100\n",
            "Epoch 1/100 - 0.10s - loss: 1.0924 - acc: 0.3738 - val_loss: 1.0944 - val_acc: 0.3603\n",
            "Epoch 2/100 - 0.10s - loss: 1.0819 - acc: 0.4244 - val_loss: 1.0852 - val_acc: 0.4170\n",
            "Epoch 3/100 - 0.10s - loss: 1.0730 - acc: 0.4444 - val_loss: 1.0782 - val_acc: 0.4271\n",
            "Epoch 4/100 - 0.11s - loss: 1.0647 - acc: 0.4557 - val_loss: 1.0720 - val_acc: 0.4433\n",
            "Epoch 5/100 - 0.10s - loss: 1.0567 - acc: 0.4611 - val_loss: 1.0664 - val_acc: 0.4413\n",
            "Epoch 6/100 - 0.11s - loss: 1.0489 - acc: 0.4665 - val_loss: 1.0600 - val_acc: 0.4474\n",
            "Epoch 7/100 - 0.11s - loss: 1.0406 - acc: 0.4750 - val_loss: 1.0544 - val_acc: 0.4494\n",
            "Epoch 8/100 - 0.10s - loss: 1.0330 - acc: 0.4750 - val_loss: 1.0482 - val_acc: 0.4818\n",
            "Epoch 9/100 - 0.11s - loss: 1.0267 - acc: 0.4847 - val_loss: 1.0451 - val_acc: 0.4899\n",
            "Epoch 10/100 - 0.10s - loss: 1.0217 - acc: 0.4809 - val_loss: 1.0402 - val_acc: 0.4818\n",
            "Epoch 11/100 - 0.10s - loss: 1.0212 - acc: 0.4786 - val_loss: 1.0404 - val_acc: 0.4696\n",
            "Epoch 12/100 - 0.10s - loss: 1.0116 - acc: 0.4942 - val_loss: 1.0310 - val_acc: 0.4838\n",
            "Epoch 13/100 - 0.10s - loss: 1.0032 - acc: 0.4960 - val_loss: 1.0257 - val_acc: 0.4879\n",
            "Epoch 14/100 - 0.10s - loss: 0.9964 - acc: 0.5065 - val_loss: 1.0201 - val_acc: 0.4939\n",
            "Epoch 15/100 - 0.10s - loss: 0.9866 - acc: 0.5130 - val_loss: 1.0102 - val_acc: 0.5142\n",
            "Epoch 16/100 - 0.10s - loss: 0.9880 - acc: 0.5236 - val_loss: 1.0122 - val_acc: 0.5364\n",
            "Epoch 17/100 - 0.12s - loss: 0.9738 - acc: 0.5268 - val_loss: 0.9974 - val_acc: 0.5324\n",
            "Epoch 18/100 - 0.10s - loss: 0.9727 - acc: 0.5306 - val_loss: 0.9968 - val_acc: 0.5547\n",
            "Epoch 19/100 - 0.10s - loss: 0.9704 - acc: 0.5265 - val_loss: 0.9942 - val_acc: 0.5182\n",
            "Epoch 20/100 - 0.11s - loss: 0.9581 - acc: 0.5378 - val_loss: 0.9822 - val_acc: 0.5344\n",
            "Epoch 21/100 - 0.10s - loss: 0.9634 - acc: 0.5295 - val_loss: 0.9919 - val_acc: 0.5344\n",
            "Epoch 22/100 - 0.10s - loss: 0.9512 - acc: 0.5436 - val_loss: 0.9801 - val_acc: 0.5567\n",
            "Epoch 23/100 - 0.10s - loss: 0.9466 - acc: 0.5450 - val_loss: 0.9751 - val_acc: 0.5486\n",
            "Epoch 24/100 - 0.10s - loss: 0.9447 - acc: 0.5421 - val_loss: 0.9730 - val_acc: 0.5506\n",
            "Epoch 25/100 - 0.10s - loss: 0.9388 - acc: 0.5576 - val_loss: 0.9697 - val_acc: 0.5749\n",
            "Epoch 26/100 - 0.11s - loss: 0.9342 - acc: 0.5587 - val_loss: 0.9648 - val_acc: 0.5587\n",
            "Epoch 27/100 - 0.10s - loss: 0.9294 - acc: 0.5583 - val_loss: 0.9616 - val_acc: 0.5506\n",
            "Epoch 28/100 - 0.10s - loss: 0.9287 - acc: 0.5619 - val_loss: 0.9603 - val_acc: 0.5688\n",
            "Epoch 29/100 - 0.11s - loss: 0.9248 - acc: 0.5652 - val_loss: 0.9595 - val_acc: 0.5648\n",
            "Epoch 30/100 - 0.10s - loss: 0.9280 - acc: 0.5657 - val_loss: 0.9614 - val_acc: 0.5668\n",
            "Epoch 31/100 - 0.10s - loss: 0.9225 - acc: 0.5664 - val_loss: 0.9620 - val_acc: 0.5648\n",
            "Epoch 32/100 - 0.11s - loss: 0.9177 - acc: 0.5650 - val_loss: 0.9595 - val_acc: 0.5526\n",
            "Epoch 33/100 - 0.10s - loss: 0.9116 - acc: 0.5697 - val_loss: 0.9517 - val_acc: 0.5628\n",
            "Epoch 34/100 - 0.10s - loss: 0.9325 - acc: 0.5553 - val_loss: 0.9814 - val_acc: 0.5223\n",
            "Epoch 35/100 - 0.10s - loss: 0.9122 - acc: 0.5661 - val_loss: 0.9568 - val_acc: 0.5506\n",
            "Epoch 36/100 - 0.10s - loss: 0.9082 - acc: 0.5760 - val_loss: 0.9570 - val_acc: 0.5486\n",
            "Epoch 37/100 - 0.11s - loss: 0.9211 - acc: 0.5740 - val_loss: 0.9614 - val_acc: 0.5547\n",
            "Epoch 38/100 - 0.10s - loss: 0.8994 - acc: 0.5794 - val_loss: 0.9474 - val_acc: 0.5688\n",
            "Epoch 39/100 - 0.10s - loss: 0.9092 - acc: 0.5798 - val_loss: 0.9543 - val_acc: 0.5709\n",
            "Epoch 40/100 - 0.10s - loss: 0.8960 - acc: 0.5832 - val_loss: 0.9469 - val_acc: 0.5526\n",
            "Epoch 41/100 - 0.11s - loss: 0.9043 - acc: 0.5686 - val_loss: 0.9615 - val_acc: 0.5385\n",
            "Epoch 42/100 - 0.10s - loss: 0.9173 - acc: 0.5623 - val_loss: 0.9730 - val_acc: 0.5263\n",
            "Epoch 43/100 - 0.11s - loss: 0.9098 - acc: 0.5668 - val_loss: 0.9709 - val_acc: 0.5364\n",
            "Epoch 44/100 - 0.10s - loss: 0.8882 - acc: 0.5906 - val_loss: 0.9466 - val_acc: 0.5587\n",
            "Epoch 45/100 - 0.11s - loss: 0.8952 - acc: 0.5900 - val_loss: 0.9488 - val_acc: 0.5648\n",
            "Epoch 46/100 - 0.12s - loss: 0.8944 - acc: 0.5956 - val_loss: 0.9547 - val_acc: 0.5830\n",
            "Epoch 47/100 - 0.10s - loss: 0.9439 - acc: 0.5657 - val_loss: 0.9994 - val_acc: 0.5648\n",
            "Epoch 48/100 - 0.12s - loss: 0.8805 - acc: 0.5956 - val_loss: 0.9467 - val_acc: 0.5567\n",
            "Epoch 49/100 - 0.10s - loss: 0.8873 - acc: 0.5873 - val_loss: 0.9480 - val_acc: 0.5729\n",
            "Epoch 50/100 - 0.10s - loss: 0.8780 - acc: 0.5940 - val_loss: 0.9470 - val_acc: 0.5506\n",
            "Epoch 51/100 - 0.10s - loss: 0.8757 - acc: 0.5956 - val_loss: 0.9472 - val_acc: 0.5445\n",
            "Epoch 52/100 - 0.11s - loss: 0.8935 - acc: 0.5780 - val_loss: 0.9584 - val_acc: 0.5425\n",
            "Epoch 53/100 - 0.10s - loss: 0.8787 - acc: 0.5978 - val_loss: 0.9502 - val_acc: 0.5668\n",
            "Epoch 54/100 - 0.10s - loss: 0.8815 - acc: 0.5897 - val_loss: 0.9664 - val_acc: 0.5243\n",
            "Epoch 55/100 - 0.10s - loss: 0.8897 - acc: 0.5949 - val_loss: 0.9653 - val_acc: 0.5709\n",
            "Epoch 56/100 - 0.11s - loss: 0.8768 - acc: 0.5900 - val_loss: 0.9595 - val_acc: 0.5304\n",
            "Epoch 57/100 - 0.10s - loss: 0.9204 - acc: 0.5616 - val_loss: 1.0147 - val_acc: 0.4919\n",
            "Epoch 58/100 - 0.13s - loss: 0.8737 - acc: 0.5911 - val_loss: 0.9636 - val_acc: 0.5263\n",
            "Epoch 59/100 - 0.10s - loss: 0.8750 - acc: 0.5972 - val_loss: 0.9623 - val_acc: 0.5466\n",
            "Epoch 60/100 - 0.10s - loss: 0.8657 - acc: 0.6048 - val_loss: 0.9490 - val_acc: 0.5547\n",
            "Epoch 61/100 - 0.10s - loss: 0.8859 - acc: 0.5924 - val_loss: 0.9769 - val_acc: 0.5587\n",
            "Epoch 62/100 - 0.10s - loss: 0.8872 - acc: 0.5846 - val_loss: 0.9854 - val_acc: 0.5162\n",
            "Epoch 63/100 - 0.10s - loss: 0.8685 - acc: 0.5969 - val_loss: 0.9578 - val_acc: 0.5344\n",
            "Epoch 64/100 - 0.10s - loss: 0.8595 - acc: 0.6050 - val_loss: 0.9446 - val_acc: 0.5526\n",
            "Epoch 65/100 - 0.12s - loss: 0.8661 - acc: 0.6026 - val_loss: 0.9624 - val_acc: 0.5324\n",
            "Epoch 66/100 - 0.10s - loss: 0.8698 - acc: 0.5922 - val_loss: 0.9551 - val_acc: 0.5506\n",
            "Epoch 67/100 - 0.10s - loss: 0.8739 - acc: 0.5877 - val_loss: 0.9746 - val_acc: 0.5202\n",
            "Epoch 68/100 - 0.10s - loss: 0.8614 - acc: 0.6046 - val_loss: 0.9544 - val_acc: 0.5648\n",
            "Epoch 69/100 - 0.10s - loss: 0.8574 - acc: 0.6028 - val_loss: 0.9604 - val_acc: 0.5243\n",
            "Epoch 70/100 - 0.10s - loss: 0.8554 - acc: 0.6082 - val_loss: 0.9568 - val_acc: 0.5425\n",
            "Epoch 71/100 - 0.11s - loss: 0.8619 - acc: 0.5992 - val_loss: 0.9579 - val_acc: 0.5425\n",
            "Epoch 72/100 - 0.10s - loss: 0.8636 - acc: 0.6089 - val_loss: 0.9586 - val_acc: 0.5547\n",
            "Epoch 73/100 - 0.10s - loss: 0.8890 - acc: 0.5900 - val_loss: 0.9879 - val_acc: 0.5405\n",
            "Epoch 74/100 - 0.10s - loss: 0.8490 - acc: 0.6134 - val_loss: 0.9529 - val_acc: 0.5466\n",
            "Epoch 75/100 - 0.10s - loss: 0.8653 - acc: 0.5958 - val_loss: 0.9759 - val_acc: 0.5243\n",
            "Epoch 76/100 - 0.10s - loss: 0.8838 - acc: 0.5839 - val_loss: 0.9794 - val_acc: 0.5466\n",
            "Epoch 77/100 - 0.10s - loss: 0.8896 - acc: 0.5740 - val_loss: 1.0017 - val_acc: 0.4960\n",
            "Epoch 78/100 - 0.10s - loss: 0.8689 - acc: 0.5983 - val_loss: 0.9846 - val_acc: 0.5182\n",
            "Epoch 79/100 - 0.10s - loss: 0.8475 - acc: 0.6093 - val_loss: 0.9567 - val_acc: 0.5506\n",
            "Epoch 80/100 - 0.12s - loss: 0.8473 - acc: 0.6149 - val_loss: 0.9580 - val_acc: 0.5486\n",
            "Epoch 81/100 - 0.10s - loss: 0.8433 - acc: 0.6170 - val_loss: 0.9539 - val_acc: 0.5425\n",
            "Epoch 82/100 - 0.11s - loss: 0.8602 - acc: 0.6001 - val_loss: 0.9639 - val_acc: 0.5526\n",
            "Epoch 83/100 - 0.12s - loss: 0.8450 - acc: 0.6129 - val_loss: 0.9586 - val_acc: 0.5466\n",
            "Epoch 84/100 - 0.11s - loss: 0.8559 - acc: 0.6122 - val_loss: 0.9744 - val_acc: 0.5405\n",
            "Epoch 85/100 - 0.11s - loss: 0.8797 - acc: 0.5859 - val_loss: 0.9826 - val_acc: 0.5425\n",
            "Epoch 86/100 - 0.10s - loss: 0.8523 - acc: 0.6161 - val_loss: 0.9623 - val_acc: 0.5526\n",
            "Epoch 87/100 - 0.11s - loss: 0.8912 - acc: 0.5895 - val_loss: 0.9926 - val_acc: 0.5506\n",
            "Epoch 88/100 - 0.10s - loss: 0.8994 - acc: 0.5729 - val_loss: 1.0329 - val_acc: 0.4879\n",
            "Epoch 89/100 - 0.12s - loss: 0.8992 - acc: 0.5738 - val_loss: 1.0113 - val_acc: 0.5142\n",
            "Epoch 90/100 - 0.11s - loss: 0.8493 - acc: 0.6071 - val_loss: 0.9724 - val_acc: 0.5466\n",
            "Epoch 91/100 - 0.11s - loss: 0.8688 - acc: 0.5936 - val_loss: 0.9822 - val_acc: 0.5324\n",
            "Epoch 92/100 - 0.10s - loss: 0.8383 - acc: 0.6136 - val_loss: 0.9576 - val_acc: 0.5466\n",
            "Epoch 93/100 - 0.11s - loss: 0.8464 - acc: 0.6217 - val_loss: 0.9644 - val_acc: 0.5587\n",
            "Epoch 94/100 - 0.10s - loss: 0.8491 - acc: 0.6046 - val_loss: 0.9761 - val_acc: 0.5324\n",
            "Epoch 95/100 - 0.11s - loss: 0.8486 - acc: 0.6102 - val_loss: 0.9763 - val_acc: 0.5385\n",
            "Epoch 96/100 - 0.10s - loss: 0.8510 - acc: 0.6140 - val_loss: 0.9659 - val_acc: 0.5526\n",
            "Epoch 97/100 - 0.12s - loss: 0.8406 - acc: 0.6138 - val_loss: 0.9615 - val_acc: 0.5567\n",
            "Epoch 98/100 - 0.11s - loss: 0.8426 - acc: 0.6158 - val_loss: 0.9727 - val_acc: 0.5445\n",
            "Epoch 99/100 - 0.11s - loss: 0.9012 - acc: 0.5747 - val_loss: 1.0046 - val_acc: 0.5223\n",
            "Epoch 100/100 - 0.10s - loss: 0.8334 - acc: 0.6161 - val_loss: 0.9609 - val_acc: 0.5567\n",
            "\n",
            "Combination 165/252:\n",
            "Hidden Layers: [128, 64, 32], Activation: tanh, Learning Rate: 0.01, Batch Size: 32, Epochs: 150\n",
            "Epoch 1/150 - 0.10s - loss: 1.0771 - acc: 0.4226 - val_loss: 1.0896 - val_acc: 0.3644\n",
            "Epoch 2/150 - 0.10s - loss: 1.0653 - acc: 0.4399 - val_loss: 1.0817 - val_acc: 0.4008\n",
            "Epoch 3/150 - 0.11s - loss: 1.0547 - acc: 0.4615 - val_loss: 1.0726 - val_acc: 0.4211\n",
            "Epoch 4/150 - 0.10s - loss: 1.0452 - acc: 0.4678 - val_loss: 1.0650 - val_acc: 0.4474\n",
            "Epoch 5/150 - 0.10s - loss: 1.0376 - acc: 0.4802 - val_loss: 1.0597 - val_acc: 0.4474\n",
            "Epoch 6/150 - 0.10s - loss: 1.0375 - acc: 0.4633 - val_loss: 1.0647 - val_acc: 0.4231\n",
            "Epoch 7/150 - 0.10s - loss: 1.0214 - acc: 0.4939 - val_loss: 1.0469 - val_acc: 0.4818\n",
            "Epoch 8/150 - 0.11s - loss: 1.0150 - acc: 0.4973 - val_loss: 1.0435 - val_acc: 0.4777\n",
            "Epoch 9/150 - 0.10s - loss: 1.0101 - acc: 0.4960 - val_loss: 1.0364 - val_acc: 0.4737\n",
            "Epoch 10/150 - 0.10s - loss: 1.0004 - acc: 0.5045 - val_loss: 1.0302 - val_acc: 0.4838\n",
            "Epoch 11/150 - 0.10s - loss: 0.9918 - acc: 0.5166 - val_loss: 1.0227 - val_acc: 0.5182\n",
            "Epoch 12/150 - 0.10s - loss: 0.9847 - acc: 0.5256 - val_loss: 1.0169 - val_acc: 0.5121\n",
            "Epoch 13/150 - 0.10s - loss: 0.9799 - acc: 0.5283 - val_loss: 1.0138 - val_acc: 0.5243\n",
            "Epoch 14/150 - 0.12s - loss: 0.9780 - acc: 0.5288 - val_loss: 1.0149 - val_acc: 0.5061\n",
            "Epoch 15/150 - 0.10s - loss: 0.9794 - acc: 0.5151 - val_loss: 1.0141 - val_acc: 0.4899\n",
            "Epoch 16/150 - 0.10s - loss: 0.9617 - acc: 0.5387 - val_loss: 0.9993 - val_acc: 0.5101\n",
            "Epoch 17/150 - 0.13s - loss: 0.9570 - acc: 0.5385 - val_loss: 0.9955 - val_acc: 0.5101\n",
            "Epoch 18/150 - 0.10s - loss: 0.9480 - acc: 0.5517 - val_loss: 0.9856 - val_acc: 0.5283\n",
            "Epoch 19/150 - 0.10s - loss: 0.9451 - acc: 0.5513 - val_loss: 0.9851 - val_acc: 0.5223\n",
            "Epoch 20/150 - 0.11s - loss: 0.9435 - acc: 0.5486 - val_loss: 0.9877 - val_acc: 0.5223\n",
            "Epoch 21/150 - 0.10s - loss: 0.9398 - acc: 0.5560 - val_loss: 0.9848 - val_acc: 0.5344\n",
            "Epoch 22/150 - 0.10s - loss: 0.9317 - acc: 0.5583 - val_loss: 0.9776 - val_acc: 0.5263\n",
            "Epoch 23/150 - 0.10s - loss: 0.9279 - acc: 0.5621 - val_loss: 0.9734 - val_acc: 0.5445\n",
            "Epoch 24/150 - 0.10s - loss: 0.9310 - acc: 0.5612 - val_loss: 0.9721 - val_acc: 0.5223\n",
            "Epoch 25/150 - 0.11s - loss: 0.9210 - acc: 0.5661 - val_loss: 0.9678 - val_acc: 0.5445\n",
            "Epoch 26/150 - 0.11s - loss: 0.9142 - acc: 0.5717 - val_loss: 0.9633 - val_acc: 0.5385\n",
            "Epoch 27/150 - 0.10s - loss: 0.9269 - acc: 0.5655 - val_loss: 0.9776 - val_acc: 0.5425\n",
            "Epoch 28/150 - 0.10s - loss: 0.9089 - acc: 0.5709 - val_loss: 0.9636 - val_acc: 0.5344\n",
            "Epoch 29/150 - 0.10s - loss: 0.9676 - acc: 0.5207 - val_loss: 1.0301 - val_acc: 0.4717\n",
            "Epoch 30/150 - 0.10s - loss: 0.9160 - acc: 0.5756 - val_loss: 0.9780 - val_acc: 0.5142\n",
            "Epoch 31/150 - 0.10s - loss: 0.9090 - acc: 0.5625 - val_loss: 0.9687 - val_acc: 0.5263\n",
            "Epoch 32/150 - 0.11s - loss: 0.9131 - acc: 0.5749 - val_loss: 0.9696 - val_acc: 0.5425\n",
            "Epoch 33/150 - 0.11s - loss: 0.8935 - acc: 0.5848 - val_loss: 0.9547 - val_acc: 0.5385\n",
            "Epoch 34/150 - 0.11s - loss: 0.8954 - acc: 0.5861 - val_loss: 0.9544 - val_acc: 0.5486\n",
            "Epoch 35/150 - 0.11s - loss: 0.8905 - acc: 0.5848 - val_loss: 0.9536 - val_acc: 0.5547\n",
            "Epoch 36/150 - 0.10s - loss: 0.9399 - acc: 0.5533 - val_loss: 0.9952 - val_acc: 0.5405\n",
            "Epoch 37/150 - 0.11s - loss: 0.8984 - acc: 0.5726 - val_loss: 0.9700 - val_acc: 0.5243\n",
            "Epoch 38/150 - 0.10s - loss: 0.8830 - acc: 0.5911 - val_loss: 0.9519 - val_acc: 0.5587\n",
            "Epoch 39/150 - 0.10s - loss: 0.8882 - acc: 0.5866 - val_loss: 0.9558 - val_acc: 0.5628\n",
            "Epoch 40/150 - 0.11s - loss: 0.8791 - acc: 0.5969 - val_loss: 0.9554 - val_acc: 0.5506\n",
            "Epoch 41/150 - 0.10s - loss: 0.8811 - acc: 0.5906 - val_loss: 0.9540 - val_acc: 0.5587\n",
            "Epoch 42/150 - 0.10s - loss: 0.8896 - acc: 0.5902 - val_loss: 0.9652 - val_acc: 0.5587\n",
            "Epoch 43/150 - 0.10s - loss: 0.8901 - acc: 0.5879 - val_loss: 0.9787 - val_acc: 0.5121\n",
            "Epoch 44/150 - 0.10s - loss: 0.8986 - acc: 0.5767 - val_loss: 0.9887 - val_acc: 0.4960\n",
            "Epoch 45/150 - 0.10s - loss: 0.9061 - acc: 0.5720 - val_loss: 1.0011 - val_acc: 0.5040\n",
            "Epoch 46/150 - 0.10s - loss: 0.8872 - acc: 0.5879 - val_loss: 0.9640 - val_acc: 0.5486\n",
            "Epoch 47/150 - 0.10s - loss: 0.9000 - acc: 0.5666 - val_loss: 0.9905 - val_acc: 0.5182\n",
            "Epoch 48/150 - 0.10s - loss: 0.8831 - acc: 0.5927 - val_loss: 0.9696 - val_acc: 0.5243\n",
            "Epoch 49/150 - 0.10s - loss: 0.8907 - acc: 0.5762 - val_loss: 0.9846 - val_acc: 0.5283\n",
            "Epoch 50/150 - 0.10s - loss: 0.8769 - acc: 0.5904 - val_loss: 0.9658 - val_acc: 0.5263\n",
            "Epoch 51/150 - 0.10s - loss: 0.8652 - acc: 0.5996 - val_loss: 0.9540 - val_acc: 0.5526\n",
            "Epoch 52/150 - 0.11s - loss: 0.8802 - acc: 0.5900 - val_loss: 0.9841 - val_acc: 0.5061\n",
            "Epoch 53/150 - 0.10s - loss: 0.8720 - acc: 0.5927 - val_loss: 0.9622 - val_acc: 0.5466\n",
            "Epoch 54/150 - 0.10s - loss: 0.8938 - acc: 0.5771 - val_loss: 1.0010 - val_acc: 0.5061\n",
            "Epoch 55/150 - 0.10s - loss: 0.8653 - acc: 0.5983 - val_loss: 0.9578 - val_acc: 0.5445\n",
            "Epoch 56/150 - 0.10s - loss: 0.9079 - acc: 0.5657 - val_loss: 1.0069 - val_acc: 0.4980\n",
            "Epoch 57/150 - 0.10s - loss: 0.8700 - acc: 0.5954 - val_loss: 0.9778 - val_acc: 0.5223\n",
            "Epoch 58/150 - 0.11s - loss: 0.8882 - acc: 0.5861 - val_loss: 0.9998 - val_acc: 0.5020\n",
            "Epoch 59/150 - 0.10s - loss: 0.8757 - acc: 0.5888 - val_loss: 0.9868 - val_acc: 0.5202\n",
            "Epoch 60/150 - 0.10s - loss: 0.8785 - acc: 0.5920 - val_loss: 0.9949 - val_acc: 0.5121\n",
            "Epoch 61/150 - 0.11s - loss: 0.8562 - acc: 0.6071 - val_loss: 0.9653 - val_acc: 0.5405\n",
            "Epoch 62/150 - 0.10s - loss: 0.8868 - acc: 0.6001 - val_loss: 0.9829 - val_acc: 0.5526\n",
            "Epoch 63/150 - 0.10s - loss: 0.8620 - acc: 0.6091 - val_loss: 0.9676 - val_acc: 0.5526\n",
            "Epoch 64/150 - 0.12s - loss: 0.9074 - acc: 0.5650 - val_loss: 1.0116 - val_acc: 0.5081\n",
            "Epoch 65/150 - 0.11s - loss: 0.8609 - acc: 0.6125 - val_loss: 0.9702 - val_acc: 0.5445\n",
            "Epoch 66/150 - 0.10s - loss: 0.8793 - acc: 0.5884 - val_loss: 0.9923 - val_acc: 0.5263\n",
            "Epoch 67/150 - 0.11s - loss: 0.8592 - acc: 0.6068 - val_loss: 0.9637 - val_acc: 0.5688\n",
            "Epoch 68/150 - 0.10s - loss: 0.8571 - acc: 0.6068 - val_loss: 0.9744 - val_acc: 0.5243\n",
            "Epoch 69/150 - 0.10s - loss: 0.8466 - acc: 0.6138 - val_loss: 0.9614 - val_acc: 0.5445\n",
            "Epoch 70/150 - 0.10s - loss: 0.8643 - acc: 0.5949 - val_loss: 0.9718 - val_acc: 0.5466\n",
            "Epoch 71/150 - 0.10s - loss: 0.8964 - acc: 0.5888 - val_loss: 1.0042 - val_acc: 0.5304\n",
            "Epoch 72/150 - 0.11s - loss: 0.8701 - acc: 0.5873 - val_loss: 0.9820 - val_acc: 0.5506\n",
            "Epoch 73/150 - 0.10s - loss: 0.8567 - acc: 0.6046 - val_loss: 0.9785 - val_acc: 0.5304\n",
            "Epoch 74/150 - 0.11s - loss: 0.8624 - acc: 0.6055 - val_loss: 0.9885 - val_acc: 0.5243\n",
            "Epoch 75/150 - 0.11s - loss: 0.8485 - acc: 0.6206 - val_loss: 0.9646 - val_acc: 0.5547\n",
            "Epoch 76/150 - 0.10s - loss: 0.8418 - acc: 0.6217 - val_loss: 0.9601 - val_acc: 0.5526\n",
            "Epoch 77/150 - 0.11s - loss: 0.8612 - acc: 0.5974 - val_loss: 0.9850 - val_acc: 0.5283\n",
            "Epoch 78/150 - 0.10s - loss: 0.8612 - acc: 0.6093 - val_loss: 0.9758 - val_acc: 0.5628\n",
            "Epoch 79/150 - 0.11s - loss: 0.8565 - acc: 0.6158 - val_loss: 0.9734 - val_acc: 0.5405\n",
            "Epoch 80/150 - 0.10s - loss: 0.8578 - acc: 0.6071 - val_loss: 0.9835 - val_acc: 0.5202\n",
            "Epoch 81/150 - 0.10s - loss: 0.8478 - acc: 0.6111 - val_loss: 0.9725 - val_acc: 0.5405\n",
            "Epoch 82/150 - 0.11s - loss: 0.8439 - acc: 0.6212 - val_loss: 0.9657 - val_acc: 0.5385\n",
            "Epoch 83/150 - 0.10s - loss: 0.8484 - acc: 0.6100 - val_loss: 0.9672 - val_acc: 0.5526\n",
            "Epoch 84/150 - 0.10s - loss: 0.8450 - acc: 0.6208 - val_loss: 0.9642 - val_acc: 0.5648\n",
            "Epoch 85/150 - 0.11s - loss: 0.8539 - acc: 0.6154 - val_loss: 0.9732 - val_acc: 0.5466\n",
            "Epoch 86/150 - 0.11s - loss: 0.8600 - acc: 0.6048 - val_loss: 0.9995 - val_acc: 0.5202\n",
            "Epoch 87/150 - 0.10s - loss: 0.8389 - acc: 0.6224 - val_loss: 0.9606 - val_acc: 0.5486\n",
            "Epoch 88/150 - 0.10s - loss: 0.8473 - acc: 0.6212 - val_loss: 0.9758 - val_acc: 0.5344\n",
            "Epoch 89/150 - 0.10s - loss: 0.8376 - acc: 0.6174 - val_loss: 0.9714 - val_acc: 0.5344\n",
            "Epoch 90/150 - 0.10s - loss: 0.8326 - acc: 0.6255 - val_loss: 0.9631 - val_acc: 0.5445\n",
            "Epoch 91/150 - 0.10s - loss: 0.8449 - acc: 0.6176 - val_loss: 0.9809 - val_acc: 0.5283\n",
            "Epoch 92/150 - 0.11s - loss: 0.8839 - acc: 0.5828 - val_loss: 0.9958 - val_acc: 0.5344\n",
            "Epoch 93/150 - 0.10s - loss: 0.8335 - acc: 0.6260 - val_loss: 0.9603 - val_acc: 0.5506\n",
            "Epoch 94/150 - 0.10s - loss: 0.8357 - acc: 0.6167 - val_loss: 0.9727 - val_acc: 0.5547\n",
            "Epoch 95/150 - 0.10s - loss: 0.8547 - acc: 0.6077 - val_loss: 0.9980 - val_acc: 0.5162\n",
            "Epoch 96/150 - 0.10s - loss: 0.8452 - acc: 0.6089 - val_loss: 0.9720 - val_acc: 0.5425\n",
            "Epoch 97/150 - 0.10s - loss: 0.8724 - acc: 0.5915 - val_loss: 0.9887 - val_acc: 0.5324\n",
            "Epoch 98/150 - 0.10s - loss: 0.8430 - acc: 0.6080 - val_loss: 0.9659 - val_acc: 0.5425\n",
            "Epoch 99/150 - 0.10s - loss: 0.8581 - acc: 0.6136 - val_loss: 0.9895 - val_acc: 0.5324\n",
            "Epoch 100/150 - 0.10s - loss: 0.8430 - acc: 0.6165 - val_loss: 0.9853 - val_acc: 0.5385\n",
            "Epoch 101/150 - 0.10s - loss: 0.8413 - acc: 0.6255 - val_loss: 0.9670 - val_acc: 0.5628\n",
            "Epoch 102/150 - 0.10s - loss: 0.8332 - acc: 0.6284 - val_loss: 0.9650 - val_acc: 0.5607\n",
            "Epoch 103/150 - 0.10s - loss: 0.8398 - acc: 0.6228 - val_loss: 0.9685 - val_acc: 0.5628\n",
            "Epoch 104/150 - 0.10s - loss: 0.8377 - acc: 0.6298 - val_loss: 0.9719 - val_acc: 0.5587\n",
            "Epoch 105/150 - 0.10s - loss: 0.8268 - acc: 0.6293 - val_loss: 0.9632 - val_acc: 0.5506\n",
            "Epoch 106/150 - 0.11s - loss: 0.8428 - acc: 0.6212 - val_loss: 0.9709 - val_acc: 0.5526\n",
            "Epoch 107/150 - 0.10s - loss: 0.9022 - acc: 0.5722 - val_loss: 1.0565 - val_acc: 0.5061\n",
            "Epoch 108/150 - 0.11s - loss: 0.8307 - acc: 0.6210 - val_loss: 0.9621 - val_acc: 0.5567\n",
            "Epoch 109/150 - 0.11s - loss: 0.8307 - acc: 0.6201 - val_loss: 0.9764 - val_acc: 0.5425\n",
            "Epoch 110/150 - 0.11s - loss: 0.8355 - acc: 0.6140 - val_loss: 0.9685 - val_acc: 0.5486\n",
            "Epoch 111/150 - 0.10s - loss: 0.8470 - acc: 0.6118 - val_loss: 1.0014 - val_acc: 0.5263\n",
            "Epoch 112/150 - 0.10s - loss: 0.8459 - acc: 0.6026 - val_loss: 0.9791 - val_acc: 0.5607\n",
            "Epoch 113/150 - 0.11s - loss: 0.8430 - acc: 0.6185 - val_loss: 0.9779 - val_acc: 0.5526\n",
            "Epoch 114/150 - 0.11s - loss: 0.8558 - acc: 0.6066 - val_loss: 0.9988 - val_acc: 0.5425\n",
            "Epoch 115/150 - 0.10s - loss: 0.8330 - acc: 0.6161 - val_loss: 0.9739 - val_acc: 0.5567\n",
            "Epoch 116/150 - 0.11s - loss: 0.8340 - acc: 0.6271 - val_loss: 0.9780 - val_acc: 0.5526\n",
            "Epoch 117/150 - 0.10s - loss: 0.8272 - acc: 0.6237 - val_loss: 0.9792 - val_acc: 0.5466\n",
            "Epoch 118/150 - 0.10s - loss: 0.8393 - acc: 0.6152 - val_loss: 0.9799 - val_acc: 0.5445\n",
            "Epoch 119/150 - 0.11s - loss: 0.8238 - acc: 0.6361 - val_loss: 0.9663 - val_acc: 0.5688\n",
            "Epoch 120/150 - 0.10s - loss: 0.8185 - acc: 0.6305 - val_loss: 0.9676 - val_acc: 0.5405\n",
            "Epoch 121/150 - 0.10s - loss: 0.8215 - acc: 0.6293 - val_loss: 0.9747 - val_acc: 0.5486\n",
            "Epoch 122/150 - 0.10s - loss: 0.8343 - acc: 0.6242 - val_loss: 0.9846 - val_acc: 0.5385\n",
            "Epoch 123/150 - 0.10s - loss: 0.8173 - acc: 0.6345 - val_loss: 0.9670 - val_acc: 0.5567\n",
            "Epoch 124/150 - 0.10s - loss: 0.8764 - acc: 0.5873 - val_loss: 1.0090 - val_acc: 0.5283\n",
            "Epoch 125/150 - 0.10s - loss: 0.8250 - acc: 0.6260 - val_loss: 0.9826 - val_acc: 0.5405\n",
            "Epoch 126/150 - 0.10s - loss: 0.8231 - acc: 0.6183 - val_loss: 0.9681 - val_acc: 0.5587\n",
            "Epoch 127/150 - 0.10s - loss: 0.8404 - acc: 0.6127 - val_loss: 1.0013 - val_acc: 0.5061\n",
            "Epoch 128/150 - 0.11s - loss: 0.8144 - acc: 0.6356 - val_loss: 0.9694 - val_acc: 0.5405\n",
            "Epoch 129/150 - 0.10s - loss: 0.8138 - acc: 0.6381 - val_loss: 0.9642 - val_acc: 0.5445\n",
            "Epoch 130/150 - 0.11s - loss: 0.8136 - acc: 0.6354 - val_loss: 0.9648 - val_acc: 0.5547\n",
            "Epoch 131/150 - 0.10s - loss: 0.8323 - acc: 0.6275 - val_loss: 0.9807 - val_acc: 0.5668\n",
            "Epoch 132/150 - 0.10s - loss: 0.8128 - acc: 0.6314 - val_loss: 0.9723 - val_acc: 0.5405\n",
            "Epoch 133/150 - 0.10s - loss: 0.8497 - acc: 0.6059 - val_loss: 1.0121 - val_acc: 0.5223\n",
            "Epoch 134/150 - 0.10s - loss: 0.8884 - acc: 0.5722 - val_loss: 1.0445 - val_acc: 0.5000\n",
            "Epoch 135/150 - 0.10s - loss: 0.8148 - acc: 0.6230 - val_loss: 0.9667 - val_acc: 0.5607\n",
            "Epoch 136/150 - 0.11s - loss: 0.8571 - acc: 0.6019 - val_loss: 1.0261 - val_acc: 0.4939\n",
            "Epoch 137/150 - 0.10s - loss: 0.8213 - acc: 0.6239 - val_loss: 0.9901 - val_acc: 0.5405\n",
            "Epoch 138/150 - 0.10s - loss: 0.8307 - acc: 0.6226 - val_loss: 1.0003 - val_acc: 0.5162\n",
            "Epoch 139/150 - 0.10s - loss: 0.8222 - acc: 0.6273 - val_loss: 0.9971 - val_acc: 0.5445\n",
            "Epoch 140/150 - 0.10s - loss: 0.8095 - acc: 0.6370 - val_loss: 0.9729 - val_acc: 0.5466\n",
            "Epoch 141/150 - 0.10s - loss: 0.8359 - acc: 0.6226 - val_loss: 0.9948 - val_acc: 0.5628\n",
            "Epoch 142/150 - 0.10s - loss: 0.8211 - acc: 0.6237 - val_loss: 0.9872 - val_acc: 0.5466\n",
            "Epoch 143/150 - 0.10s - loss: 0.8188 - acc: 0.6262 - val_loss: 0.9933 - val_acc: 0.5445\n",
            "Epoch 144/150 - 0.10s - loss: 0.8221 - acc: 0.6237 - val_loss: 0.9996 - val_acc: 0.5304\n",
            "Epoch 145/150 - 0.10s - loss: 0.8210 - acc: 0.6255 - val_loss: 0.9947 - val_acc: 0.5364\n",
            "Epoch 146/150 - 0.10s - loss: 0.8106 - acc: 0.6298 - val_loss: 0.9751 - val_acc: 0.5567\n",
            "Epoch 147/150 - 0.10s - loss: 0.8059 - acc: 0.6338 - val_loss: 0.9731 - val_acc: 0.5547\n",
            "Epoch 148/150 - 0.10s - loss: 0.8119 - acc: 0.6273 - val_loss: 0.9746 - val_acc: 0.5688\n",
            "Epoch 149/150 - 0.10s - loss: 0.8174 - acc: 0.6296 - val_loss: 0.9768 - val_acc: 0.5526\n",
            "Epoch 150/150 - 0.10s - loss: 0.8143 - acc: 0.6327 - val_loss: 0.9968 - val_acc: 0.5445\n",
            "\n",
            "Combination 166/252:\n",
            "Hidden Layers: [128, 64, 32], Activation: tanh, Learning Rate: 0.01, Batch Size: 64, Epochs: 50\n",
            "Epoch 1/50 - 0.14s - loss: 1.0908 - acc: 0.3821 - val_loss: 1.0929 - val_acc: 0.3745\n",
            "Epoch 2/50 - 0.08s - loss: 1.0812 - acc: 0.4006 - val_loss: 1.0858 - val_acc: 0.3887\n",
            "Epoch 3/50 - 0.08s - loss: 1.0738 - acc: 0.4397 - val_loss: 1.0802 - val_acc: 0.4170\n",
            "Epoch 4/50 - 0.09s - loss: 1.0674 - acc: 0.4496 - val_loss: 1.0754 - val_acc: 0.4352\n",
            "Epoch 5/50 - 0.09s - loss: 1.0620 - acc: 0.4550 - val_loss: 1.0709 - val_acc: 0.4453\n",
            "Epoch 6/50 - 0.08s - loss: 1.0573 - acc: 0.4631 - val_loss: 1.0692 - val_acc: 0.4271\n",
            "Epoch 7/50 - 0.09s - loss: 1.0512 - acc: 0.4663 - val_loss: 1.0634 - val_acc: 0.4393\n",
            "Epoch 8/50 - 0.08s - loss: 1.0471 - acc: 0.4633 - val_loss: 1.0600 - val_acc: 0.4494\n",
            "Epoch 9/50 - 0.08s - loss: 1.0416 - acc: 0.4744 - val_loss: 1.0566 - val_acc: 0.4494\n",
            "Epoch 10/50 - 0.09s - loss: 1.0372 - acc: 0.4800 - val_loss: 1.0542 - val_acc: 0.4575\n",
            "Epoch 11/50 - 0.09s - loss: 1.0322 - acc: 0.4818 - val_loss: 1.0503 - val_acc: 0.4656\n",
            "Epoch 12/50 - 0.08s - loss: 1.0308 - acc: 0.4804 - val_loss: 1.0511 - val_acc: 0.4494\n",
            "Epoch 13/50 - 0.09s - loss: 1.0241 - acc: 0.4804 - val_loss: 1.0446 - val_acc: 0.4798\n",
            "Epoch 14/50 - 0.08s - loss: 1.0191 - acc: 0.4933 - val_loss: 1.0400 - val_acc: 0.4980\n",
            "Epoch 15/50 - 0.08s - loss: 1.0141 - acc: 0.5081 - val_loss: 1.0369 - val_acc: 0.4980\n",
            "Epoch 16/50 - 0.09s - loss: 1.0115 - acc: 0.4955 - val_loss: 1.0350 - val_acc: 0.4980\n",
            "Epoch 17/50 - 0.08s - loss: 1.0049 - acc: 0.5171 - val_loss: 1.0300 - val_acc: 0.5061\n",
            "Epoch 18/50 - 0.08s - loss: 1.0009 - acc: 0.5209 - val_loss: 1.0271 - val_acc: 0.5081\n",
            "Epoch 19/50 - 0.11s - loss: 1.0013 - acc: 0.5040 - val_loss: 1.0267 - val_acc: 0.5081\n",
            "Epoch 20/50 - 0.09s - loss: 0.9932 - acc: 0.5277 - val_loss: 1.0220 - val_acc: 0.5000\n",
            "Epoch 21/50 - 0.08s - loss: 0.9938 - acc: 0.5121 - val_loss: 1.0202 - val_acc: 0.5142\n",
            "Epoch 22/50 - 0.10s - loss: 0.9838 - acc: 0.5268 - val_loss: 1.0127 - val_acc: 0.5283\n",
            "Epoch 23/50 - 0.09s - loss: 0.9820 - acc: 0.5202 - val_loss: 1.0101 - val_acc: 0.5364\n",
            "Epoch 24/50 - 0.09s - loss: 0.9790 - acc: 0.5322 - val_loss: 1.0102 - val_acc: 0.5040\n",
            "Epoch 25/50 - 0.12s - loss: 0.9766 - acc: 0.5292 - val_loss: 1.0062 - val_acc: 0.5526\n",
            "Epoch 26/50 - 0.08s - loss: 0.9758 - acc: 0.5301 - val_loss: 1.0078 - val_acc: 0.4960\n",
            "Epoch 27/50 - 0.08s - loss: 0.9771 - acc: 0.5270 - val_loss: 1.0066 - val_acc: 0.5425\n",
            "Epoch 28/50 - 0.09s - loss: 0.9653 - acc: 0.5387 - val_loss: 0.9982 - val_acc: 0.5061\n",
            "Epoch 29/50 - 0.09s - loss: 0.9626 - acc: 0.5373 - val_loss: 0.9929 - val_acc: 0.5506\n",
            "Epoch 30/50 - 0.08s - loss: 0.9704 - acc: 0.5362 - val_loss: 1.0038 - val_acc: 0.5324\n",
            "Epoch 31/50 - 0.09s - loss: 0.9538 - acc: 0.5477 - val_loss: 0.9871 - val_acc: 0.5445\n",
            "Epoch 32/50 - 0.09s - loss: 0.9500 - acc: 0.5461 - val_loss: 0.9839 - val_acc: 0.5486\n",
            "Epoch 33/50 - 0.09s - loss: 0.9515 - acc: 0.5477 - val_loss: 0.9883 - val_acc: 0.5162\n",
            "Epoch 34/50 - 0.10s - loss: 0.9462 - acc: 0.5463 - val_loss: 0.9804 - val_acc: 0.5648\n",
            "Epoch 35/50 - 0.08s - loss: 0.9422 - acc: 0.5533 - val_loss: 0.9785 - val_acc: 0.5445\n",
            "Epoch 36/50 - 0.08s - loss: 0.9628 - acc: 0.5315 - val_loss: 1.0024 - val_acc: 0.4879\n",
            "Epoch 37/50 - 0.09s - loss: 0.9505 - acc: 0.5425 - val_loss: 0.9896 - val_acc: 0.5040\n",
            "Epoch 38/50 - 0.09s - loss: 0.9394 - acc: 0.5625 - val_loss: 0.9788 - val_acc: 0.5223\n",
            "Epoch 39/50 - 0.09s - loss: 0.9334 - acc: 0.5576 - val_loss: 0.9709 - val_acc: 0.5587\n",
            "Epoch 40/50 - 0.09s - loss: 0.9366 - acc: 0.5560 - val_loss: 0.9728 - val_acc: 0.5445\n",
            "Epoch 41/50 - 0.08s - loss: 0.9282 - acc: 0.5589 - val_loss: 0.9671 - val_acc: 0.5607\n",
            "Epoch 42/50 - 0.09s - loss: 0.9276 - acc: 0.5612 - val_loss: 0.9682 - val_acc: 0.5547\n",
            "Epoch 43/50 - 0.09s - loss: 0.9342 - acc: 0.5515 - val_loss: 0.9760 - val_acc: 0.5283\n",
            "Epoch 44/50 - 0.08s - loss: 0.9230 - acc: 0.5686 - val_loss: 0.9645 - val_acc: 0.5567\n",
            "Epoch 45/50 - 0.10s - loss: 0.9196 - acc: 0.5706 - val_loss: 0.9620 - val_acc: 0.5628\n",
            "Epoch 46/50 - 0.11s - loss: 0.9219 - acc: 0.5659 - val_loss: 0.9678 - val_acc: 0.5445\n",
            "Epoch 47/50 - 0.09s - loss: 0.9281 - acc: 0.5625 - val_loss: 0.9699 - val_acc: 0.5709\n",
            "Epoch 48/50 - 0.09s - loss: 0.9169 - acc: 0.5646 - val_loss: 0.9637 - val_acc: 0.5425\n",
            "Epoch 49/50 - 0.09s - loss: 0.9207 - acc: 0.5670 - val_loss: 0.9655 - val_acc: 0.5668\n",
            "Epoch 50/50 - 0.08s - loss: 0.9108 - acc: 0.5747 - val_loss: 0.9606 - val_acc: 0.5547\n",
            "\n",
            "Combination 167/252:\n",
            "Hidden Layers: [128, 64, 32], Activation: tanh, Learning Rate: 0.01, Batch Size: 64, Epochs: 100\n",
            "Epoch 1/100 - 0.09s - loss: 1.0973 - acc: 0.3390 - val_loss: 1.1032 - val_acc: 0.3300\n",
            "Epoch 2/100 - 0.10s - loss: 1.0913 - acc: 0.3662 - val_loss: 1.0976 - val_acc: 0.3664\n",
            "Epoch 3/100 - 0.09s - loss: 1.0857 - acc: 0.3914 - val_loss: 1.0942 - val_acc: 0.3279\n",
            "Epoch 4/100 - 0.09s - loss: 1.0801 - acc: 0.4240 - val_loss: 1.0888 - val_acc: 0.3522\n",
            "Epoch 5/100 - 0.09s - loss: 1.0750 - acc: 0.4256 - val_loss: 1.0840 - val_acc: 0.3846\n",
            "Epoch 6/100 - 0.09s - loss: 1.0708 - acc: 0.4435 - val_loss: 1.0818 - val_acc: 0.3968\n",
            "Epoch 7/100 - 0.09s - loss: 1.0664 - acc: 0.4498 - val_loss: 1.0782 - val_acc: 0.3988\n",
            "Epoch 8/100 - 0.10s - loss: 1.0628 - acc: 0.4408 - val_loss: 1.0737 - val_acc: 0.4170\n",
            "Epoch 9/100 - 0.08s - loss: 1.0582 - acc: 0.4471 - val_loss: 1.0709 - val_acc: 0.4109\n",
            "Epoch 10/100 - 0.08s - loss: 1.0541 - acc: 0.4561 - val_loss: 1.0680 - val_acc: 0.4251\n",
            "Epoch 11/100 - 0.09s - loss: 1.0504 - acc: 0.4615 - val_loss: 1.0651 - val_acc: 0.4332\n",
            "Epoch 12/100 - 0.08s - loss: 1.0471 - acc: 0.4737 - val_loss: 1.0640 - val_acc: 0.4231\n",
            "Epoch 13/100 - 0.08s - loss: 1.0437 - acc: 0.4710 - val_loss: 1.0616 - val_acc: 0.4372\n",
            "Epoch 14/100 - 0.09s - loss: 1.0401 - acc: 0.4735 - val_loss: 1.0571 - val_acc: 0.4636\n",
            "Epoch 15/100 - 0.09s - loss: 1.0358 - acc: 0.4820 - val_loss: 1.0542 - val_acc: 0.4717\n",
            "Epoch 16/100 - 0.08s - loss: 1.0333 - acc: 0.4917 - val_loss: 1.0549 - val_acc: 0.4433\n",
            "Epoch 17/100 - 0.10s - loss: 1.0282 - acc: 0.4926 - val_loss: 1.0492 - val_acc: 0.4656\n",
            "Epoch 18/100 - 0.09s - loss: 1.0259 - acc: 0.4843 - val_loss: 1.0491 - val_acc: 0.4676\n",
            "Epoch 19/100 - 0.09s - loss: 1.0201 - acc: 0.5038 - val_loss: 1.0433 - val_acc: 0.4899\n",
            "Epoch 20/100 - 0.09s - loss: 1.0169 - acc: 0.5058 - val_loss: 1.0415 - val_acc: 0.4838\n",
            "Epoch 21/100 - 0.09s - loss: 1.0122 - acc: 0.5092 - val_loss: 1.0364 - val_acc: 0.5040\n",
            "Epoch 22/100 - 0.09s - loss: 1.0087 - acc: 0.5148 - val_loss: 1.0346 - val_acc: 0.4919\n",
            "Epoch 23/100 - 0.09s - loss: 1.0048 - acc: 0.5146 - val_loss: 1.0303 - val_acc: 0.4939\n",
            "Epoch 24/100 - 0.09s - loss: 1.0036 - acc: 0.5038 - val_loss: 1.0282 - val_acc: 0.5020\n",
            "Epoch 25/100 - 0.09s - loss: 0.9962 - acc: 0.5241 - val_loss: 1.0231 - val_acc: 0.5101\n",
            "Epoch 26/100 - 0.11s - loss: 0.9924 - acc: 0.5243 - val_loss: 1.0202 - val_acc: 0.5101\n",
            "Epoch 27/100 - 0.10s - loss: 0.9883 - acc: 0.5252 - val_loss: 1.0162 - val_acc: 0.5162\n",
            "Epoch 28/100 - 0.09s - loss: 0.9872 - acc: 0.5254 - val_loss: 1.0161 - val_acc: 0.5162\n",
            "Epoch 29/100 - 0.12s - loss: 0.9875 - acc: 0.5247 - val_loss: 1.0146 - val_acc: 0.5081\n",
            "Epoch 30/100 - 0.09s - loss: 0.9786 - acc: 0.5315 - val_loss: 1.0080 - val_acc: 0.5263\n",
            "Epoch 31/100 - 0.08s - loss: 0.9740 - acc: 0.5362 - val_loss: 1.0045 - val_acc: 0.5182\n",
            "Epoch 32/100 - 0.10s - loss: 0.9768 - acc: 0.5263 - val_loss: 1.0064 - val_acc: 0.5040\n",
            "Epoch 33/100 - 0.09s - loss: 0.9673 - acc: 0.5418 - val_loss: 0.9987 - val_acc: 0.5182\n",
            "Epoch 34/100 - 0.09s - loss: 0.9645 - acc: 0.5445 - val_loss: 0.9943 - val_acc: 0.5324\n",
            "Epoch 35/100 - 0.09s - loss: 0.9623 - acc: 0.5414 - val_loss: 0.9922 - val_acc: 0.5385\n",
            "Epoch 36/100 - 0.09s - loss: 0.9592 - acc: 0.5477 - val_loss: 0.9916 - val_acc: 0.5324\n",
            "Epoch 37/100 - 0.09s - loss: 0.9551 - acc: 0.5450 - val_loss: 0.9874 - val_acc: 0.5385\n",
            "Epoch 38/100 - 0.10s - loss: 0.9582 - acc: 0.5407 - val_loss: 0.9927 - val_acc: 0.5283\n",
            "Epoch 39/100 - 0.09s - loss: 0.9490 - acc: 0.5580 - val_loss: 0.9846 - val_acc: 0.5304\n",
            "Epoch 40/100 - 0.09s - loss: 0.9564 - acc: 0.5335 - val_loss: 0.9870 - val_acc: 0.5425\n",
            "Epoch 41/100 - 0.09s - loss: 0.9446 - acc: 0.5634 - val_loss: 0.9802 - val_acc: 0.5364\n",
            "Epoch 42/100 - 0.09s - loss: 0.9963 - acc: 0.5283 - val_loss: 1.0288 - val_acc: 0.5202\n",
            "Epoch 43/100 - 0.08s - loss: 0.9463 - acc: 0.5477 - val_loss: 0.9851 - val_acc: 0.5344\n",
            "Epoch 44/100 - 0.10s - loss: 0.9371 - acc: 0.5641 - val_loss: 0.9754 - val_acc: 0.5567\n",
            "Epoch 45/100 - 0.08s - loss: 0.9344 - acc: 0.5589 - val_loss: 0.9736 - val_acc: 0.5506\n",
            "Epoch 46/100 - 0.08s - loss: 0.9378 - acc: 0.5583 - val_loss: 0.9810 - val_acc: 0.5364\n",
            "Epoch 47/100 - 0.09s - loss: 0.9288 - acc: 0.5682 - val_loss: 0.9703 - val_acc: 0.5506\n",
            "Epoch 48/100 - 0.08s - loss: 0.9315 - acc: 0.5571 - val_loss: 0.9734 - val_acc: 0.5324\n",
            "Epoch 49/100 - 0.08s - loss: 0.9284 - acc: 0.5709 - val_loss: 0.9749 - val_acc: 0.5324\n",
            "Epoch 50/100 - 0.09s - loss: 0.9430 - acc: 0.5488 - val_loss: 0.9930 - val_acc: 0.5162\n",
            "Epoch 51/100 - 0.09s - loss: 0.9207 - acc: 0.5697 - val_loss: 0.9658 - val_acc: 0.5587\n",
            "Epoch 52/100 - 0.08s - loss: 0.9431 - acc: 0.5355 - val_loss: 0.9820 - val_acc: 0.5405\n",
            "Epoch 53/100 - 0.09s - loss: 0.9190 - acc: 0.5706 - val_loss: 0.9640 - val_acc: 0.5567\n",
            "Epoch 54/100 - 0.08s - loss: 0.9221 - acc: 0.5688 - val_loss: 0.9749 - val_acc: 0.5344\n",
            "Epoch 55/100 - 0.08s - loss: 0.9201 - acc: 0.5637 - val_loss: 0.9711 - val_acc: 0.5344\n",
            "Epoch 56/100 - 0.09s - loss: 0.9170 - acc: 0.5697 - val_loss: 0.9626 - val_acc: 0.5526\n",
            "Epoch 57/100 - 0.08s - loss: 0.9131 - acc: 0.5861 - val_loss: 0.9641 - val_acc: 0.5486\n",
            "Epoch 58/100 - 0.08s - loss: 0.9140 - acc: 0.5722 - val_loss: 0.9626 - val_acc: 0.5567\n",
            "Epoch 59/100 - 0.10s - loss: 0.9403 - acc: 0.5457 - val_loss: 0.9979 - val_acc: 0.5061\n",
            "Epoch 60/100 - 0.09s - loss: 0.9193 - acc: 0.5634 - val_loss: 0.9683 - val_acc: 0.5587\n",
            "Epoch 61/100 - 0.08s - loss: 0.9041 - acc: 0.5895 - val_loss: 0.9619 - val_acc: 0.5567\n",
            "Epoch 62/100 - 0.09s - loss: 0.9123 - acc: 0.5684 - val_loss: 0.9699 - val_acc: 0.5324\n",
            "Epoch 63/100 - 0.08s - loss: 0.9157 - acc: 0.5753 - val_loss: 0.9689 - val_acc: 0.5688\n",
            "Epoch 64/100 - 0.08s - loss: 0.9087 - acc: 0.5700 - val_loss: 0.9680 - val_acc: 0.5364\n",
            "Epoch 65/100 - 0.09s - loss: 0.9101 - acc: 0.5798 - val_loss: 0.9660 - val_acc: 0.5607\n",
            "Epoch 66/100 - 0.08s - loss: 0.9304 - acc: 0.5587 - val_loss: 0.9898 - val_acc: 0.5202\n",
            "Epoch 67/100 - 0.09s - loss: 0.9033 - acc: 0.5776 - val_loss: 0.9699 - val_acc: 0.5223\n",
            "Epoch 68/100 - 0.09s - loss: 0.8967 - acc: 0.5744 - val_loss: 0.9592 - val_acc: 0.5385\n",
            "Epoch 69/100 - 0.09s - loss: 0.9601 - acc: 0.5306 - val_loss: 1.0319 - val_acc: 0.4757\n",
            "Epoch 70/100 - 0.08s - loss: 0.9089 - acc: 0.5711 - val_loss: 0.9800 - val_acc: 0.5142\n",
            "Epoch 71/100 - 0.09s - loss: 0.8934 - acc: 0.5814 - val_loss: 0.9595 - val_acc: 0.5506\n",
            "Epoch 72/100 - 0.08s - loss: 0.8884 - acc: 0.5913 - val_loss: 0.9557 - val_acc: 0.5567\n",
            "Epoch 73/100 - 0.08s - loss: 0.9668 - acc: 0.5367 - val_loss: 1.0226 - val_acc: 0.5243\n",
            "Epoch 74/100 - 0.09s - loss: 0.8856 - acc: 0.5906 - val_loss: 0.9562 - val_acc: 0.5486\n",
            "Epoch 75/100 - 0.09s - loss: 0.9248 - acc: 0.5562 - val_loss: 1.0048 - val_acc: 0.5020\n",
            "Epoch 76/100 - 0.08s - loss: 0.9443 - acc: 0.5416 - val_loss: 1.0287 - val_acc: 0.4818\n",
            "Epoch 77/100 - 0.09s - loss: 0.8894 - acc: 0.5981 - val_loss: 0.9651 - val_acc: 0.5304\n",
            "Epoch 78/100 - 0.08s - loss: 0.8922 - acc: 0.5821 - val_loss: 0.9619 - val_acc: 0.5607\n",
            "Epoch 79/100 - 0.08s - loss: 0.8801 - acc: 0.5933 - val_loss: 0.9534 - val_acc: 0.5587\n",
            "Epoch 80/100 - 0.10s - loss: 0.9126 - acc: 0.5792 - val_loss: 0.9841 - val_acc: 0.5344\n",
            "Epoch 81/100 - 0.09s - loss: 0.9608 - acc: 0.5526 - val_loss: 1.0260 - val_acc: 0.5486\n",
            "Epoch 82/100 - 0.08s - loss: 0.8837 - acc: 0.5969 - val_loss: 0.9631 - val_acc: 0.5344\n",
            "Epoch 83/100 - 0.09s - loss: 0.8804 - acc: 0.5990 - val_loss: 0.9636 - val_acc: 0.5324\n",
            "Epoch 84/100 - 0.08s - loss: 0.8755 - acc: 0.5967 - val_loss: 0.9591 - val_acc: 0.5304\n",
            "Epoch 85/100 - 0.09s - loss: 0.9001 - acc: 0.5733 - val_loss: 0.9890 - val_acc: 0.5142\n",
            "Epoch 86/100 - 0.09s - loss: 0.8830 - acc: 0.5870 - val_loss: 0.9733 - val_acc: 0.5304\n",
            "Epoch 87/100 - 0.09s - loss: 0.8859 - acc: 0.5949 - val_loss: 0.9687 - val_acc: 0.5344\n",
            "Epoch 88/100 - 0.08s - loss: 0.9251 - acc: 0.5697 - val_loss: 1.0004 - val_acc: 0.5466\n",
            "Epoch 89/100 - 0.09s - loss: 0.8745 - acc: 0.5920 - val_loss: 0.9574 - val_acc: 0.5547\n",
            "Epoch 90/100 - 0.08s - loss: 0.9159 - acc: 0.5700 - val_loss: 0.9921 - val_acc: 0.5466\n",
            "Epoch 91/100 - 0.08s - loss: 0.8687 - acc: 0.6014 - val_loss: 0.9583 - val_acc: 0.5405\n",
            "Epoch 92/100 - 0.09s - loss: 0.8719 - acc: 0.5954 - val_loss: 0.9593 - val_acc: 0.5607\n",
            "Epoch 93/100 - 0.09s - loss: 0.8879 - acc: 0.5877 - val_loss: 0.9697 - val_acc: 0.5567\n",
            "Epoch 94/100 - 0.08s - loss: 0.8679 - acc: 0.6001 - val_loss: 0.9605 - val_acc: 0.5486\n",
            "Epoch 95/100 - 0.09s - loss: 0.9286 - acc: 0.5493 - val_loss: 1.0289 - val_acc: 0.4960\n",
            "Epoch 96/100 - 0.08s - loss: 0.8784 - acc: 0.5951 - val_loss: 0.9745 - val_acc: 0.5243\n",
            "Epoch 97/100 - 0.08s - loss: 0.8661 - acc: 0.6021 - val_loss: 0.9600 - val_acc: 0.5506\n",
            "Epoch 98/100 - 0.09s - loss: 0.8978 - acc: 0.5717 - val_loss: 0.9945 - val_acc: 0.5202\n",
            "Epoch 99/100 - 0.08s - loss: 0.8950 - acc: 0.5864 - val_loss: 0.9823 - val_acc: 0.5628\n",
            "Epoch 100/100 - 0.08s - loss: 0.8734 - acc: 0.5938 - val_loss: 0.9766 - val_acc: 0.5202\n",
            "\n",
            "Combination 168/252:\n",
            "Hidden Layers: [128, 64, 32], Activation: tanh, Learning Rate: 0.01, Batch Size: 64, Epochs: 150\n",
            "Epoch 1/150 - 0.09s - loss: 1.0928 - acc: 0.3772 - val_loss: 1.0985 - val_acc: 0.3522\n",
            "Epoch 2/150 - 0.08s - loss: 1.0835 - acc: 0.4060 - val_loss: 1.0904 - val_acc: 0.3907\n",
            "Epoch 3/150 - 0.08s - loss: 1.0759 - acc: 0.4251 - val_loss: 1.0849 - val_acc: 0.3927\n",
            "Epoch 4/150 - 0.11s - loss: 1.0691 - acc: 0.4483 - val_loss: 1.0794 - val_acc: 0.4352\n",
            "Epoch 5/150 - 0.09s - loss: 1.0641 - acc: 0.4528 - val_loss: 1.0752 - val_acc: 0.4291\n",
            "Epoch 6/150 - 0.09s - loss: 1.0578 - acc: 0.4627 - val_loss: 1.0724 - val_acc: 0.4433\n",
            "Epoch 7/150 - 0.09s - loss: 1.0525 - acc: 0.4701 - val_loss: 1.0672 - val_acc: 0.4575\n",
            "Epoch 8/150 - 0.08s - loss: 1.0472 - acc: 0.4696 - val_loss: 1.0646 - val_acc: 0.4696\n",
            "Epoch 9/150 - 0.08s - loss: 1.0425 - acc: 0.4759 - val_loss: 1.0617 - val_acc: 0.4757\n",
            "Epoch 10/150 - 0.09s - loss: 1.0377 - acc: 0.4820 - val_loss: 1.0581 - val_acc: 0.4757\n",
            "Epoch 11/150 - 0.09s - loss: 1.0334 - acc: 0.4876 - val_loss: 1.0547 - val_acc: 0.4777\n",
            "Epoch 12/150 - 0.08s - loss: 1.0289 - acc: 0.4885 - val_loss: 1.0514 - val_acc: 0.4838\n",
            "Epoch 13/150 - 0.09s - loss: 1.0269 - acc: 0.4890 - val_loss: 1.0515 - val_acc: 0.4838\n",
            "Epoch 14/150 - 0.08s - loss: 1.0214 - acc: 0.4962 - val_loss: 1.0468 - val_acc: 0.4960\n",
            "Epoch 15/150 - 0.08s - loss: 1.0180 - acc: 0.4921 - val_loss: 1.0426 - val_acc: 0.4818\n",
            "Epoch 16/150 - 0.09s - loss: 1.0117 - acc: 0.5121 - val_loss: 1.0396 - val_acc: 0.4919\n",
            "Epoch 17/150 - 0.09s - loss: 1.0075 - acc: 0.5155 - val_loss: 1.0368 - val_acc: 0.5020\n",
            "Epoch 18/150 - 0.08s - loss: 1.0028 - acc: 0.5182 - val_loss: 1.0323 - val_acc: 0.5121\n",
            "Epoch 19/150 - 0.09s - loss: 0.9992 - acc: 0.5151 - val_loss: 1.0285 - val_acc: 0.5000\n",
            "Epoch 20/150 - 0.08s - loss: 0.9953 - acc: 0.5173 - val_loss: 1.0250 - val_acc: 0.5121\n",
            "Epoch 21/150 - 0.08s - loss: 0.9916 - acc: 0.5142 - val_loss: 1.0216 - val_acc: 0.5121\n",
            "Epoch 22/150 - 0.09s - loss: 0.9889 - acc: 0.5175 - val_loss: 1.0190 - val_acc: 0.5101\n",
            "Epoch 23/150 - 0.09s - loss: 0.9867 - acc: 0.5241 - val_loss: 1.0181 - val_acc: 0.5142\n",
            "Epoch 24/150 - 0.08s - loss: 0.9783 - acc: 0.5297 - val_loss: 1.0107 - val_acc: 0.5202\n",
            "Epoch 25/150 - 0.09s - loss: 0.9769 - acc: 0.5256 - val_loss: 1.0113 - val_acc: 0.5061\n",
            "Epoch 26/150 - 0.08s - loss: 0.9715 - acc: 0.5378 - val_loss: 1.0057 - val_acc: 0.5283\n",
            "Epoch 27/150 - 0.08s - loss: 0.9689 - acc: 0.5376 - val_loss: 1.0036 - val_acc: 0.5344\n",
            "Epoch 28/150 - 0.09s - loss: 0.9723 - acc: 0.5288 - val_loss: 1.0044 - val_acc: 0.5223\n",
            "Epoch 29/150 - 0.11s - loss: 0.9621 - acc: 0.5434 - val_loss: 0.9979 - val_acc: 0.5344\n",
            "Epoch 30/150 - 0.08s - loss: 0.9614 - acc: 0.5423 - val_loss: 0.9962 - val_acc: 0.5324\n",
            "Epoch 31/150 - 0.10s - loss: 0.9639 - acc: 0.5315 - val_loss: 1.0010 - val_acc: 0.5040\n",
            "Epoch 32/150 - 0.09s - loss: 0.9560 - acc: 0.5457 - val_loss: 0.9958 - val_acc: 0.5283\n",
            "Epoch 33/150 - 0.09s - loss: 0.9656 - acc: 0.5292 - val_loss: 1.0072 - val_acc: 0.5000\n",
            "Epoch 34/150 - 0.10s - loss: 0.9478 - acc: 0.5511 - val_loss: 0.9861 - val_acc: 0.5486\n",
            "Epoch 35/150 - 0.08s - loss: 0.9832 - acc: 0.5256 - val_loss: 1.0153 - val_acc: 0.5283\n",
            "Epoch 36/150 - 0.08s - loss: 0.9547 - acc: 0.5353 - val_loss: 0.9886 - val_acc: 0.5385\n",
            "Epoch 37/150 - 0.09s - loss: 0.9510 - acc: 0.5439 - val_loss: 0.9936 - val_acc: 0.5243\n",
            "Epoch 38/150 - 0.08s - loss: 0.9387 - acc: 0.5547 - val_loss: 0.9782 - val_acc: 0.5425\n",
            "Epoch 39/150 - 0.08s - loss: 0.9453 - acc: 0.5513 - val_loss: 0.9841 - val_acc: 0.5425\n",
            "Epoch 40/150 - 0.09s - loss: 0.9335 - acc: 0.5603 - val_loss: 0.9770 - val_acc: 0.5445\n",
            "Epoch 41/150 - 0.09s - loss: 0.9398 - acc: 0.5506 - val_loss: 0.9802 - val_acc: 0.5385\n",
            "Epoch 42/150 - 0.09s - loss: 0.9484 - acc: 0.5533 - val_loss: 0.9881 - val_acc: 0.5364\n",
            "Epoch 43/150 - 0.09s - loss: 0.9303 - acc: 0.5580 - val_loss: 0.9774 - val_acc: 0.5425\n",
            "Epoch 44/150 - 0.09s - loss: 0.9256 - acc: 0.5614 - val_loss: 0.9715 - val_acc: 0.5425\n",
            "Epoch 45/150 - 0.08s - loss: 0.9240 - acc: 0.5619 - val_loss: 0.9711 - val_acc: 0.5425\n",
            "Epoch 46/150 - 0.09s - loss: 0.9301 - acc: 0.5585 - val_loss: 0.9830 - val_acc: 0.5385\n",
            "Epoch 47/150 - 0.09s - loss: 0.9234 - acc: 0.5583 - val_loss: 0.9752 - val_acc: 0.5385\n",
            "Epoch 48/150 - 0.09s - loss: 0.9366 - acc: 0.5472 - val_loss: 0.9914 - val_acc: 0.5121\n",
            "Epoch 49/150 - 0.09s - loss: 0.9494 - acc: 0.5578 - val_loss: 0.9935 - val_acc: 0.5445\n",
            "Epoch 50/150 - 0.09s - loss: 0.9228 - acc: 0.5711 - val_loss: 0.9726 - val_acc: 0.5466\n",
            "Epoch 51/150 - 0.09s - loss: 0.9439 - acc: 0.5612 - val_loss: 0.9904 - val_acc: 0.5425\n",
            "Epoch 52/150 - 0.11s - loss: 0.9162 - acc: 0.5706 - val_loss: 0.9667 - val_acc: 0.5405\n",
            "Epoch 53/150 - 0.09s - loss: 0.9153 - acc: 0.5673 - val_loss: 0.9712 - val_acc: 0.5445\n",
            "Epoch 54/150 - 0.09s - loss: 0.9218 - acc: 0.5717 - val_loss: 0.9721 - val_acc: 0.5385\n",
            "Epoch 55/150 - 0.09s - loss: 0.9679 - acc: 0.5441 - val_loss: 1.0121 - val_acc: 0.5385\n",
            "Epoch 56/150 - 0.09s - loss: 0.9063 - acc: 0.5706 - val_loss: 0.9650 - val_acc: 0.5486\n",
            "Epoch 57/150 - 0.09s - loss: 0.9102 - acc: 0.5740 - val_loss: 0.9634 - val_acc: 0.5425\n",
            "Epoch 58/150 - 0.10s - loss: 0.9029 - acc: 0.5778 - val_loss: 0.9618 - val_acc: 0.5648\n",
            "Epoch 59/150 - 0.09s - loss: 0.9024 - acc: 0.5834 - val_loss: 0.9617 - val_acc: 0.5526\n",
            "Epoch 60/150 - 0.09s - loss: 0.9104 - acc: 0.5726 - val_loss: 0.9654 - val_acc: 0.5486\n",
            "Epoch 61/150 - 0.09s - loss: 0.9127 - acc: 0.5697 - val_loss: 0.9680 - val_acc: 0.5628\n",
            "Epoch 62/150 - 0.08s - loss: 0.8997 - acc: 0.5816 - val_loss: 0.9627 - val_acc: 0.5628\n",
            "Epoch 63/150 - 0.09s - loss: 0.9174 - acc: 0.5610 - val_loss: 0.9905 - val_acc: 0.5142\n",
            "Epoch 64/150 - 0.10s - loss: 0.8958 - acc: 0.5819 - val_loss: 0.9624 - val_acc: 0.5445\n",
            "Epoch 65/150 - 0.09s - loss: 0.9430 - acc: 0.5443 - val_loss: 1.0202 - val_acc: 0.4960\n",
            "Epoch 66/150 - 0.09s - loss: 0.8936 - acc: 0.5850 - val_loss: 0.9575 - val_acc: 0.5587\n",
            "Epoch 67/150 - 0.09s - loss: 0.8974 - acc: 0.5807 - val_loss: 0.9690 - val_acc: 0.5324\n",
            "Epoch 68/150 - 0.09s - loss: 0.9023 - acc: 0.5848 - val_loss: 0.9641 - val_acc: 0.5445\n",
            "Epoch 69/150 - 0.08s - loss: 0.8938 - acc: 0.5886 - val_loss: 0.9644 - val_acc: 0.5486\n",
            "Epoch 70/150 - 0.09s - loss: 0.8880 - acc: 0.5886 - val_loss: 0.9573 - val_acc: 0.5587\n",
            "Epoch 71/150 - 0.09s - loss: 0.8859 - acc: 0.5909 - val_loss: 0.9597 - val_acc: 0.5445\n",
            "Epoch 72/150 - 0.09s - loss: 0.8845 - acc: 0.5913 - val_loss: 0.9568 - val_acc: 0.5506\n",
            "Epoch 73/150 - 0.09s - loss: 0.9032 - acc: 0.5643 - val_loss: 0.9802 - val_acc: 0.5425\n",
            "Epoch 74/150 - 0.08s - loss: 0.8908 - acc: 0.5927 - val_loss: 0.9644 - val_acc: 0.5405\n",
            "Epoch 75/150 - 0.08s - loss: 0.8947 - acc: 0.5744 - val_loss: 0.9764 - val_acc: 0.5263\n",
            "Epoch 76/150 - 0.09s - loss: 0.8810 - acc: 0.5924 - val_loss: 0.9601 - val_acc: 0.5364\n",
            "Epoch 77/150 - 0.11s - loss: 0.8915 - acc: 0.5821 - val_loss: 0.9629 - val_acc: 0.5466\n",
            "Epoch 78/150 - 0.09s - loss: 0.8995 - acc: 0.5909 - val_loss: 0.9717 - val_acc: 0.5506\n",
            "Epoch 79/150 - 0.09s - loss: 0.9027 - acc: 0.5697 - val_loss: 0.9948 - val_acc: 0.4960\n",
            "Epoch 80/150 - 0.08s - loss: 0.8833 - acc: 0.5857 - val_loss: 0.9723 - val_acc: 0.5263\n",
            "Epoch 81/150 - 0.09s - loss: 0.9052 - acc: 0.5688 - val_loss: 0.9995 - val_acc: 0.5000\n",
            "Epoch 82/150 - 0.10s - loss: 0.9028 - acc: 0.5704 - val_loss: 0.9947 - val_acc: 0.4980\n",
            "Epoch 83/150 - 0.09s - loss: 0.8771 - acc: 0.5906 - val_loss: 0.9651 - val_acc: 0.5263\n",
            "Epoch 84/150 - 0.09s - loss: 0.9360 - acc: 0.5488 - val_loss: 1.0346 - val_acc: 0.4818\n",
            "Epoch 85/150 - 0.09s - loss: 0.8712 - acc: 0.6019 - val_loss: 0.9605 - val_acc: 0.5405\n",
            "Epoch 86/150 - 0.09s - loss: 0.8895 - acc: 0.5897 - val_loss: 0.9732 - val_acc: 0.5445\n",
            "Epoch 87/150 - 0.08s - loss: 0.8746 - acc: 0.6005 - val_loss: 0.9589 - val_acc: 0.5547\n",
            "Epoch 88/150 - 0.10s - loss: 0.8778 - acc: 0.5891 - val_loss: 0.9652 - val_acc: 0.5304\n",
            "Epoch 89/150 - 0.09s - loss: 0.9507 - acc: 0.5531 - val_loss: 1.0234 - val_acc: 0.5344\n",
            "Epoch 90/150 - 0.09s - loss: 0.8957 - acc: 0.5767 - val_loss: 0.9985 - val_acc: 0.4960\n",
            "Epoch 91/150 - 0.10s - loss: 0.8752 - acc: 0.6012 - val_loss: 0.9657 - val_acc: 0.5364\n",
            "Epoch 92/150 - 0.09s - loss: 0.9284 - acc: 0.5670 - val_loss: 1.0080 - val_acc: 0.5506\n",
            "Epoch 93/150 - 0.08s - loss: 0.9314 - acc: 0.5652 - val_loss: 1.0095 - val_acc: 0.5486\n",
            "Epoch 94/150 - 0.10s - loss: 0.8730 - acc: 0.5933 - val_loss: 0.9611 - val_acc: 0.5567\n",
            "Epoch 95/150 - 0.09s - loss: 0.8655 - acc: 0.5965 - val_loss: 0.9600 - val_acc: 0.5445\n",
            "Epoch 96/150 - 0.08s - loss: 0.8666 - acc: 0.5974 - val_loss: 0.9676 - val_acc: 0.5364\n",
            "Epoch 97/150 - 0.09s - loss: 0.9090 - acc: 0.5553 - val_loss: 0.9927 - val_acc: 0.5304\n",
            "Epoch 98/150 - 0.09s - loss: 0.8831 - acc: 0.5866 - val_loss: 0.9914 - val_acc: 0.5040\n",
            "Epoch 99/150 - 0.09s - loss: 0.8655 - acc: 0.6010 - val_loss: 0.9696 - val_acc: 0.5263\n",
            "Epoch 100/150 - 0.10s - loss: 0.8717 - acc: 0.5981 - val_loss: 0.9794 - val_acc: 0.5304\n",
            "Epoch 101/150 - 0.11s - loss: 0.8626 - acc: 0.5992 - val_loss: 0.9705 - val_acc: 0.5324\n",
            "Epoch 102/150 - 0.08s - loss: 0.8929 - acc: 0.5733 - val_loss: 1.0057 - val_acc: 0.4919\n",
            "Epoch 103/150 - 0.09s - loss: 0.8673 - acc: 0.6014 - val_loss: 0.9773 - val_acc: 0.5364\n",
            "Epoch 104/150 - 0.08s - loss: 0.8676 - acc: 0.5956 - val_loss: 0.9639 - val_acc: 0.5547\n",
            "Epoch 105/150 - 0.08s - loss: 0.8720 - acc: 0.6046 - val_loss: 0.9723 - val_acc: 0.5344\n",
            "Epoch 106/150 - 0.09s - loss: 0.8587 - acc: 0.6116 - val_loss: 0.9624 - val_acc: 0.5425\n",
            "Epoch 107/150 - 0.09s - loss: 0.8811 - acc: 0.5864 - val_loss: 0.9957 - val_acc: 0.5040\n",
            "Epoch 108/150 - 0.08s - loss: 0.8737 - acc: 0.5983 - val_loss: 0.9913 - val_acc: 0.5182\n",
            "Epoch 109/150 - 0.09s - loss: 0.9311 - acc: 0.5677 - val_loss: 1.0289 - val_acc: 0.5101\n",
            "Epoch 110/150 - 0.09s - loss: 0.8664 - acc: 0.6010 - val_loss: 0.9681 - val_acc: 0.5648\n",
            "Epoch 111/150 - 0.09s - loss: 0.8582 - acc: 0.6032 - val_loss: 0.9658 - val_acc: 0.5304\n",
            "Epoch 112/150 - 0.10s - loss: 0.8841 - acc: 0.5756 - val_loss: 0.9861 - val_acc: 0.5101\n",
            "Epoch 113/150 - 0.09s - loss: 0.9135 - acc: 0.5529 - val_loss: 1.0057 - val_acc: 0.5324\n",
            "Epoch 114/150 - 0.09s - loss: 0.9260 - acc: 0.5758 - val_loss: 1.0242 - val_acc: 0.5263\n",
            "Epoch 115/150 - 0.09s - loss: 0.8606 - acc: 0.6037 - val_loss: 0.9654 - val_acc: 0.5587\n",
            "Epoch 116/150 - 0.09s - loss: 0.9310 - acc: 0.5439 - val_loss: 1.0218 - val_acc: 0.5040\n",
            "Epoch 117/150 - 0.09s - loss: 0.8669 - acc: 0.5927 - val_loss: 0.9711 - val_acc: 0.5263\n",
            "Epoch 118/150 - 0.09s - loss: 0.8852 - acc: 0.5783 - val_loss: 1.0105 - val_acc: 0.4879\n",
            "Epoch 119/150 - 0.09s - loss: 0.9048 - acc: 0.5776 - val_loss: 1.0021 - val_acc: 0.5385\n",
            "Epoch 120/150 - 0.09s - loss: 0.8480 - acc: 0.6104 - val_loss: 0.9619 - val_acc: 0.5486\n",
            "Epoch 121/150 - 0.09s - loss: 0.8758 - acc: 0.5965 - val_loss: 0.9976 - val_acc: 0.5202\n",
            "Epoch 122/150 - 0.08s - loss: 0.8807 - acc: 0.5884 - val_loss: 0.9975 - val_acc: 0.5223\n",
            "Epoch 123/150 - 0.08s - loss: 0.8749 - acc: 0.5895 - val_loss: 0.9798 - val_acc: 0.5607\n",
            "Epoch 124/150 - 0.09s - loss: 0.8580 - acc: 0.6120 - val_loss: 0.9719 - val_acc: 0.5405\n",
            "Epoch 125/150 - 0.11s - loss: 0.8647 - acc: 0.5960 - val_loss: 0.9705 - val_acc: 0.5628\n",
            "Epoch 126/150 - 0.09s - loss: 0.9076 - acc: 0.5637 - val_loss: 1.0361 - val_acc: 0.5081\n",
            "Epoch 127/150 - 0.09s - loss: 0.8478 - acc: 0.6174 - val_loss: 0.9681 - val_acc: 0.5486\n",
            "Epoch 128/150 - 0.08s - loss: 0.8689 - acc: 0.6062 - val_loss: 0.9774 - val_acc: 0.5648\n",
            "Epoch 129/150 - 0.09s - loss: 0.8610 - acc: 0.6064 - val_loss: 0.9785 - val_acc: 0.5466\n",
            "Epoch 130/150 - 0.09s - loss: 0.8473 - acc: 0.6154 - val_loss: 0.9705 - val_acc: 0.5486\n",
            "Epoch 131/150 - 0.09s - loss: 0.8478 - acc: 0.6102 - val_loss: 0.9742 - val_acc: 0.5324\n",
            "Epoch 132/150 - 0.09s - loss: 0.8483 - acc: 0.6129 - val_loss: 0.9737 - val_acc: 0.5405\n",
            "Epoch 133/150 - 0.09s - loss: 0.8567 - acc: 0.6109 - val_loss: 0.9711 - val_acc: 0.5769\n",
            "Epoch 134/150 - 0.08s - loss: 0.9077 - acc: 0.5639 - val_loss: 1.0153 - val_acc: 0.5142\n",
            "Epoch 135/150 - 0.08s - loss: 0.9255 - acc: 0.5562 - val_loss: 1.0258 - val_acc: 0.5283\n",
            "Epoch 136/150 - 0.10s - loss: 0.8416 - acc: 0.6149 - val_loss: 0.9619 - val_acc: 0.5567\n",
            "Epoch 137/150 - 0.09s - loss: 0.8479 - acc: 0.6125 - val_loss: 0.9712 - val_acc: 0.5466\n",
            "Epoch 138/150 - 0.09s - loss: 0.8501 - acc: 0.6098 - val_loss: 0.9801 - val_acc: 0.5324\n",
            "Epoch 139/150 - 0.10s - loss: 0.8569 - acc: 0.6093 - val_loss: 0.9843 - val_acc: 0.5344\n",
            "Epoch 140/150 - 0.09s - loss: 0.8521 - acc: 0.6156 - val_loss: 0.9686 - val_acc: 0.5668\n",
            "Epoch 141/150 - 0.08s - loss: 0.9178 - acc: 0.5598 - val_loss: 1.0583 - val_acc: 0.4818\n",
            "Epoch 142/150 - 0.09s - loss: 0.8915 - acc: 0.5720 - val_loss: 0.9974 - val_acc: 0.5344\n",
            "Epoch 143/150 - 0.09s - loss: 0.8731 - acc: 0.6068 - val_loss: 0.9879 - val_acc: 0.5628\n",
            "Epoch 144/150 - 0.08s - loss: 0.8518 - acc: 0.6152 - val_loss: 0.9740 - val_acc: 0.5466\n",
            "Epoch 145/150 - 0.09s - loss: 0.8455 - acc: 0.6095 - val_loss: 0.9634 - val_acc: 0.5405\n",
            "Epoch 146/150 - 0.09s - loss: 0.8516 - acc: 0.6147 - val_loss: 0.9705 - val_acc: 0.5587\n",
            "Epoch 147/150 - 0.09s - loss: 0.8520 - acc: 0.6057 - val_loss: 0.9820 - val_acc: 0.5405\n",
            "Epoch 148/150 - 0.10s - loss: 0.8460 - acc: 0.6215 - val_loss: 0.9727 - val_acc: 0.5526\n",
            "Epoch 149/150 - 0.09s - loss: 0.8433 - acc: 0.6143 - val_loss: 0.9754 - val_acc: 0.5243\n",
            "Epoch 150/150 - 0.10s - loss: 0.8800 - acc: 0.5794 - val_loss: 0.9926 - val_acc: 0.5547\n",
            "\n",
            "Combination 169/252:\n",
            "Hidden Layers: [128, 64, 32], Activation: tanh, Learning Rate: 0.001, Batch Size: 32, Epochs: 50\n",
            "Epoch 1/50 - 0.10s - loss: 1.0956 - acc: 0.3596 - val_loss: 1.0975 - val_acc: 0.3320\n",
            "Epoch 2/50 - 0.10s - loss: 1.0921 - acc: 0.3779 - val_loss: 1.0940 - val_acc: 0.3623\n",
            "Epoch 3/50 - 0.11s - loss: 1.0900 - acc: 0.3851 - val_loss: 1.0924 - val_acc: 0.3603\n",
            "Epoch 4/50 - 0.10s - loss: 1.0882 - acc: 0.3891 - val_loss: 1.0907 - val_acc: 0.3745\n",
            "Epoch 5/50 - 0.10s - loss: 1.0865 - acc: 0.3941 - val_loss: 1.0890 - val_acc: 0.3765\n",
            "Epoch 6/50 - 0.10s - loss: 1.0850 - acc: 0.3990 - val_loss: 1.0874 - val_acc: 0.3846\n",
            "Epoch 7/50 - 0.10s - loss: 1.0834 - acc: 0.4073 - val_loss: 1.0863 - val_acc: 0.3887\n",
            "Epoch 8/50 - 0.10s - loss: 1.0819 - acc: 0.4116 - val_loss: 1.0848 - val_acc: 0.4008\n",
            "Epoch 9/50 - 0.11s - loss: 1.0805 - acc: 0.4163 - val_loss: 1.0835 - val_acc: 0.4049\n",
            "Epoch 10/50 - 0.10s - loss: 1.0792 - acc: 0.4217 - val_loss: 1.0823 - val_acc: 0.4170\n",
            "Epoch 11/50 - 0.10s - loss: 1.0779 - acc: 0.4278 - val_loss: 1.0813 - val_acc: 0.4130\n",
            "Epoch 12/50 - 0.10s - loss: 1.0767 - acc: 0.4274 - val_loss: 1.0798 - val_acc: 0.4251\n",
            "Epoch 13/50 - 0.10s - loss: 1.0755 - acc: 0.4325 - val_loss: 1.0787 - val_acc: 0.4332\n",
            "Epoch 14/50 - 0.10s - loss: 1.0742 - acc: 0.4345 - val_loss: 1.0779 - val_acc: 0.4271\n",
            "Epoch 15/50 - 0.11s - loss: 1.0731 - acc: 0.4372 - val_loss: 1.0771 - val_acc: 0.4291\n",
            "Epoch 16/50 - 0.10s - loss: 1.0720 - acc: 0.4377 - val_loss: 1.0759 - val_acc: 0.4251\n",
            "Epoch 17/50 - 0.10s - loss: 1.0708 - acc: 0.4411 - val_loss: 1.0748 - val_acc: 0.4352\n",
            "Epoch 18/50 - 0.10s - loss: 1.0698 - acc: 0.4422 - val_loss: 1.0739 - val_acc: 0.4332\n",
            "Epoch 19/50 - 0.10s - loss: 1.0687 - acc: 0.4420 - val_loss: 1.0731 - val_acc: 0.4332\n",
            "Epoch 20/50 - 0.10s - loss: 1.0677 - acc: 0.4510 - val_loss: 1.0719 - val_acc: 0.4494\n",
            "Epoch 21/50 - 0.12s - loss: 1.0666 - acc: 0.4519 - val_loss: 1.0711 - val_acc: 0.4494\n",
            "Epoch 22/50 - 0.10s - loss: 1.0657 - acc: 0.4514 - val_loss: 1.0703 - val_acc: 0.4555\n",
            "Epoch 23/50 - 0.10s - loss: 1.0646 - acc: 0.4566 - val_loss: 1.0694 - val_acc: 0.4555\n",
            "Epoch 24/50 - 0.11s - loss: 1.0636 - acc: 0.4566 - val_loss: 1.0686 - val_acc: 0.4555\n",
            "Epoch 25/50 - 0.10s - loss: 1.0627 - acc: 0.4561 - val_loss: 1.0679 - val_acc: 0.4595\n",
            "Epoch 26/50 - 0.10s - loss: 1.0617 - acc: 0.4588 - val_loss: 1.0670 - val_acc: 0.4615\n",
            "Epoch 27/50 - 0.11s - loss: 1.0607 - acc: 0.4633 - val_loss: 1.0660 - val_acc: 0.4534\n",
            "Epoch 28/50 - 0.10s - loss: 1.0598 - acc: 0.4602 - val_loss: 1.0654 - val_acc: 0.4575\n",
            "Epoch 29/50 - 0.10s - loss: 1.0588 - acc: 0.4618 - val_loss: 1.0645 - val_acc: 0.4494\n",
            "Epoch 30/50 - 0.10s - loss: 1.0579 - acc: 0.4613 - val_loss: 1.0636 - val_acc: 0.4514\n",
            "Epoch 31/50 - 0.10s - loss: 1.0569 - acc: 0.4633 - val_loss: 1.0628 - val_acc: 0.4555\n",
            "Epoch 32/50 - 0.10s - loss: 1.0560 - acc: 0.4620 - val_loss: 1.0621 - val_acc: 0.4514\n",
            "Epoch 33/50 - 0.10s - loss: 1.0551 - acc: 0.4665 - val_loss: 1.0611 - val_acc: 0.4555\n",
            "Epoch 34/50 - 0.10s - loss: 1.0541 - acc: 0.4647 - val_loss: 1.0604 - val_acc: 0.4514\n",
            "Epoch 35/50 - 0.10s - loss: 1.0532 - acc: 0.4663 - val_loss: 1.0595 - val_acc: 0.4555\n",
            "Epoch 36/50 - 0.10s - loss: 1.0523 - acc: 0.4674 - val_loss: 1.0587 - val_acc: 0.4575\n",
            "Epoch 37/50 - 0.10s - loss: 1.0514 - acc: 0.4696 - val_loss: 1.0579 - val_acc: 0.4595\n",
            "Epoch 38/50 - 0.10s - loss: 1.0504 - acc: 0.4701 - val_loss: 1.0572 - val_acc: 0.4615\n",
            "Epoch 39/50 - 0.11s - loss: 1.0495 - acc: 0.4699 - val_loss: 1.0565 - val_acc: 0.4656\n",
            "Epoch 40/50 - 0.10s - loss: 1.0486 - acc: 0.4710 - val_loss: 1.0556 - val_acc: 0.4696\n",
            "Epoch 41/50 - 0.10s - loss: 1.0477 - acc: 0.4723 - val_loss: 1.0548 - val_acc: 0.4656\n",
            "Epoch 42/50 - 0.10s - loss: 1.0468 - acc: 0.4753 - val_loss: 1.0541 - val_acc: 0.4717\n",
            "Epoch 43/50 - 0.10s - loss: 1.0458 - acc: 0.4757 - val_loss: 1.0534 - val_acc: 0.4777\n",
            "Epoch 44/50 - 0.10s - loss: 1.0449 - acc: 0.4764 - val_loss: 1.0528 - val_acc: 0.4737\n",
            "Epoch 45/50 - 0.11s - loss: 1.0440 - acc: 0.4764 - val_loss: 1.0519 - val_acc: 0.4737\n",
            "Epoch 46/50 - 0.11s - loss: 1.0431 - acc: 0.4771 - val_loss: 1.0512 - val_acc: 0.4737\n",
            "Epoch 47/50 - 0.10s - loss: 1.0422 - acc: 0.4750 - val_loss: 1.0505 - val_acc: 0.4676\n",
            "Epoch 48/50 - 0.10s - loss: 1.0412 - acc: 0.4773 - val_loss: 1.0496 - val_acc: 0.4696\n",
            "Epoch 49/50 - 0.10s - loss: 1.0403 - acc: 0.4768 - val_loss: 1.0488 - val_acc: 0.4737\n",
            "Epoch 50/50 - 0.11s - loss: 1.0394 - acc: 0.4780 - val_loss: 1.0481 - val_acc: 0.4757\n",
            "\n",
            "Combination 170/252:\n",
            "Hidden Layers: [128, 64, 32], Activation: tanh, Learning Rate: 0.001, Batch Size: 32, Epochs: 100\n",
            "Epoch 1/100 - 0.10s - loss: 1.1035 - acc: 0.3142 - val_loss: 1.1086 - val_acc: 0.3057\n",
            "Epoch 2/100 - 0.10s - loss: 1.1010 - acc: 0.3349 - val_loss: 1.1061 - val_acc: 0.3340\n",
            "Epoch 3/100 - 0.10s - loss: 1.0991 - acc: 0.3365 - val_loss: 1.1044 - val_acc: 0.3340\n",
            "Epoch 4/100 - 0.10s - loss: 1.0973 - acc: 0.3450 - val_loss: 1.1028 - val_acc: 0.3381\n",
            "Epoch 5/100 - 0.11s - loss: 1.0956 - acc: 0.3468 - val_loss: 1.1014 - val_acc: 0.3320\n",
            "Epoch 6/100 - 0.10s - loss: 1.0940 - acc: 0.3522 - val_loss: 1.1002 - val_acc: 0.3279\n",
            "Epoch 7/100 - 0.10s - loss: 1.0925 - acc: 0.3552 - val_loss: 1.0989 - val_acc: 0.3340\n",
            "Epoch 8/100 - 0.11s - loss: 1.0911 - acc: 0.3594 - val_loss: 1.0976 - val_acc: 0.3360\n",
            "Epoch 9/100 - 0.10s - loss: 1.0897 - acc: 0.3603 - val_loss: 1.0964 - val_acc: 0.3360\n",
            "Epoch 10/100 - 0.10s - loss: 1.0884 - acc: 0.3662 - val_loss: 1.0955 - val_acc: 0.3543\n",
            "Epoch 11/100 - 0.11s - loss: 1.0871 - acc: 0.3709 - val_loss: 1.0944 - val_acc: 0.3441\n",
            "Epoch 12/100 - 0.10s - loss: 1.0858 - acc: 0.3754 - val_loss: 1.0935 - val_acc: 0.3482\n",
            "Epoch 13/100 - 0.10s - loss: 1.0846 - acc: 0.3785 - val_loss: 1.0925 - val_acc: 0.3522\n",
            "Epoch 14/100 - 0.10s - loss: 1.0834 - acc: 0.3846 - val_loss: 1.0916 - val_acc: 0.3563\n",
            "Epoch 15/100 - 0.10s - loss: 1.0823 - acc: 0.3869 - val_loss: 1.0907 - val_acc: 0.3502\n",
            "Epoch 16/100 - 0.10s - loss: 1.0812 - acc: 0.3954 - val_loss: 1.0898 - val_acc: 0.3684\n",
            "Epoch 17/100 - 0.11s - loss: 1.0801 - acc: 0.3990 - val_loss: 1.0890 - val_acc: 0.3745\n",
            "Epoch 18/100 - 0.11s - loss: 1.0791 - acc: 0.4058 - val_loss: 1.0882 - val_acc: 0.3644\n",
            "Epoch 19/100 - 0.11s - loss: 1.0780 - acc: 0.4100 - val_loss: 1.0873 - val_acc: 0.3704\n",
            "Epoch 20/100 - 0.12s - loss: 1.0770 - acc: 0.4109 - val_loss: 1.0866 - val_acc: 0.3684\n",
            "Epoch 21/100 - 0.11s - loss: 1.0760 - acc: 0.4130 - val_loss: 1.0858 - val_acc: 0.3765\n",
            "Epoch 22/100 - 0.11s - loss: 1.0750 - acc: 0.4175 - val_loss: 1.0850 - val_acc: 0.3826\n",
            "Epoch 23/100 - 0.10s - loss: 1.0740 - acc: 0.4211 - val_loss: 1.0843 - val_acc: 0.3806\n",
            "Epoch 24/100 - 0.11s - loss: 1.0730 - acc: 0.4247 - val_loss: 1.0836 - val_acc: 0.3826\n",
            "Epoch 25/100 - 0.10s - loss: 1.0721 - acc: 0.4260 - val_loss: 1.0828 - val_acc: 0.3887\n",
            "Epoch 26/100 - 0.11s - loss: 1.0712 - acc: 0.4298 - val_loss: 1.0821 - val_acc: 0.3866\n",
            "Epoch 27/100 - 0.10s - loss: 1.0702 - acc: 0.4267 - val_loss: 1.0815 - val_acc: 0.3907\n",
            "Epoch 28/100 - 0.10s - loss: 1.0693 - acc: 0.4305 - val_loss: 1.0807 - val_acc: 0.3968\n",
            "Epoch 29/100 - 0.10s - loss: 1.0684 - acc: 0.4330 - val_loss: 1.0800 - val_acc: 0.3927\n",
            "Epoch 30/100 - 0.12s - loss: 1.0675 - acc: 0.4318 - val_loss: 1.0794 - val_acc: 0.3968\n",
            "Epoch 31/100 - 0.10s - loss: 1.0666 - acc: 0.4334 - val_loss: 1.0788 - val_acc: 0.3866\n",
            "Epoch 32/100 - 0.10s - loss: 1.0657 - acc: 0.4336 - val_loss: 1.0779 - val_acc: 0.4008\n",
            "Epoch 33/100 - 0.10s - loss: 1.0648 - acc: 0.4399 - val_loss: 1.0772 - val_acc: 0.4049\n",
            "Epoch 34/100 - 0.10s - loss: 1.0639 - acc: 0.4442 - val_loss: 1.0765 - val_acc: 0.4109\n",
            "Epoch 35/100 - 0.12s - loss: 1.0630 - acc: 0.4444 - val_loss: 1.0759 - val_acc: 0.4089\n",
            "Epoch 36/100 - 0.11s - loss: 1.0621 - acc: 0.4489 - val_loss: 1.0752 - val_acc: 0.4008\n",
            "Epoch 37/100 - 0.10s - loss: 1.0612 - acc: 0.4476 - val_loss: 1.0746 - val_acc: 0.4130\n",
            "Epoch 38/100 - 0.11s - loss: 1.0604 - acc: 0.4465 - val_loss: 1.0739 - val_acc: 0.4150\n",
            "Epoch 39/100 - 0.10s - loss: 1.0595 - acc: 0.4489 - val_loss: 1.0732 - val_acc: 0.4069\n",
            "Epoch 40/100 - 0.11s - loss: 1.0586 - acc: 0.4498 - val_loss: 1.0726 - val_acc: 0.4069\n",
            "Epoch 41/100 - 0.10s - loss: 1.0578 - acc: 0.4525 - val_loss: 1.0718 - val_acc: 0.4109\n",
            "Epoch 42/100 - 0.10s - loss: 1.0569 - acc: 0.4528 - val_loss: 1.0712 - val_acc: 0.4130\n",
            "Epoch 43/100 - 0.10s - loss: 1.0560 - acc: 0.4539 - val_loss: 1.0705 - val_acc: 0.4130\n",
            "Epoch 44/100 - 0.10s - loss: 1.0552 - acc: 0.4548 - val_loss: 1.0700 - val_acc: 0.4170\n",
            "Epoch 45/100 - 0.10s - loss: 1.0543 - acc: 0.4559 - val_loss: 1.0693 - val_acc: 0.4190\n",
            "Epoch 46/100 - 0.11s - loss: 1.0534 - acc: 0.4579 - val_loss: 1.0686 - val_acc: 0.4170\n",
            "Epoch 47/100 - 0.11s - loss: 1.0526 - acc: 0.4613 - val_loss: 1.0678 - val_acc: 0.4271\n",
            "Epoch 48/100 - 0.10s - loss: 1.0517 - acc: 0.4618 - val_loss: 1.0672 - val_acc: 0.4291\n",
            "Epoch 49/100 - 0.10s - loss: 1.0509 - acc: 0.4618 - val_loss: 1.0665 - val_acc: 0.4312\n",
            "Epoch 50/100 - 0.10s - loss: 1.0500 - acc: 0.4636 - val_loss: 1.0659 - val_acc: 0.4372\n",
            "Epoch 51/100 - 0.11s - loss: 1.0491 - acc: 0.4656 - val_loss: 1.0653 - val_acc: 0.4352\n",
            "Epoch 52/100 - 0.10s - loss: 1.0483 - acc: 0.4658 - val_loss: 1.0647 - val_acc: 0.4352\n",
            "Epoch 53/100 - 0.10s - loss: 1.0475 - acc: 0.4660 - val_loss: 1.0642 - val_acc: 0.4332\n",
            "Epoch 54/100 - 0.10s - loss: 1.0466 - acc: 0.4665 - val_loss: 1.0634 - val_acc: 0.4413\n",
            "Epoch 55/100 - 0.10s - loss: 1.0457 - acc: 0.4678 - val_loss: 1.0627 - val_acc: 0.4413\n",
            "Epoch 56/100 - 0.10s - loss: 1.0449 - acc: 0.4687 - val_loss: 1.0622 - val_acc: 0.4352\n",
            "Epoch 57/100 - 0.11s - loss: 1.0440 - acc: 0.4701 - val_loss: 1.0615 - val_acc: 0.4413\n",
            "Epoch 58/100 - 0.11s - loss: 1.0432 - acc: 0.4672 - val_loss: 1.0608 - val_acc: 0.4494\n",
            "Epoch 59/100 - 0.12s - loss: 1.0423 - acc: 0.4710 - val_loss: 1.0602 - val_acc: 0.4474\n",
            "Epoch 60/100 - 0.10s - loss: 1.0415 - acc: 0.4730 - val_loss: 1.0597 - val_acc: 0.4372\n",
            "Epoch 61/100 - 0.10s - loss: 1.0406 - acc: 0.4737 - val_loss: 1.0590 - val_acc: 0.4453\n",
            "Epoch 62/100 - 0.11s - loss: 1.0397 - acc: 0.4717 - val_loss: 1.0583 - val_acc: 0.4534\n",
            "Epoch 63/100 - 0.10s - loss: 1.0390 - acc: 0.4728 - val_loss: 1.0577 - val_acc: 0.4494\n",
            "Epoch 64/100 - 0.11s - loss: 1.0381 - acc: 0.4732 - val_loss: 1.0569 - val_acc: 0.4534\n",
            "Epoch 65/100 - 0.10s - loss: 1.0372 - acc: 0.4741 - val_loss: 1.0563 - val_acc: 0.4555\n",
            "Epoch 66/100 - 0.11s - loss: 1.0363 - acc: 0.4764 - val_loss: 1.0555 - val_acc: 0.4595\n",
            "Epoch 67/100 - 0.10s - loss: 1.0355 - acc: 0.4784 - val_loss: 1.0549 - val_acc: 0.4656\n",
            "Epoch 68/100 - 0.10s - loss: 1.0346 - acc: 0.4782 - val_loss: 1.0542 - val_acc: 0.4615\n",
            "Epoch 69/100 - 0.12s - loss: 1.0337 - acc: 0.4809 - val_loss: 1.0537 - val_acc: 0.4636\n",
            "Epoch 70/100 - 0.13s - loss: 1.0329 - acc: 0.4836 - val_loss: 1.0531 - val_acc: 0.4676\n",
            "Epoch 71/100 - 0.11s - loss: 1.0320 - acc: 0.4843 - val_loss: 1.0525 - val_acc: 0.4636\n",
            "Epoch 72/100 - 0.11s - loss: 1.0312 - acc: 0.4840 - val_loss: 1.0517 - val_acc: 0.4717\n",
            "Epoch 73/100 - 0.10s - loss: 1.0303 - acc: 0.4874 - val_loss: 1.0511 - val_acc: 0.4717\n",
            "Epoch 74/100 - 0.11s - loss: 1.0295 - acc: 0.4872 - val_loss: 1.0504 - val_acc: 0.4717\n",
            "Epoch 75/100 - 0.10s - loss: 1.0286 - acc: 0.4872 - val_loss: 1.0498 - val_acc: 0.4717\n",
            "Epoch 76/100 - 0.11s - loss: 1.0278 - acc: 0.4874 - val_loss: 1.0491 - val_acc: 0.4717\n",
            "Epoch 77/100 - 0.11s - loss: 1.0269 - acc: 0.4894 - val_loss: 1.0485 - val_acc: 0.4757\n",
            "Epoch 78/100 - 0.11s - loss: 1.0260 - acc: 0.4921 - val_loss: 1.0478 - val_acc: 0.4777\n",
            "Epoch 79/100 - 0.10s - loss: 1.0252 - acc: 0.4919 - val_loss: 1.0471 - val_acc: 0.4798\n",
            "Epoch 80/100 - 0.11s - loss: 1.0243 - acc: 0.4926 - val_loss: 1.0465 - val_acc: 0.4777\n",
            "Epoch 81/100 - 0.10s - loss: 1.0235 - acc: 0.4937 - val_loss: 1.0460 - val_acc: 0.4798\n",
            "Epoch 82/100 - 0.11s - loss: 1.0226 - acc: 0.4935 - val_loss: 1.0452 - val_acc: 0.4838\n",
            "Epoch 83/100 - 0.10s - loss: 1.0218 - acc: 0.4946 - val_loss: 1.0445 - val_acc: 0.4858\n",
            "Epoch 84/100 - 0.11s - loss: 1.0210 - acc: 0.4948 - val_loss: 1.0438 - val_acc: 0.4980\n",
            "Epoch 85/100 - 0.10s - loss: 1.0200 - acc: 0.4962 - val_loss: 1.0431 - val_acc: 0.4879\n",
            "Epoch 86/100 - 0.10s - loss: 1.0192 - acc: 0.4980 - val_loss: 1.0425 - val_acc: 0.4899\n",
            "Epoch 87/100 - 0.11s - loss: 1.0183 - acc: 0.4984 - val_loss: 1.0419 - val_acc: 0.4879\n",
            "Epoch 88/100 - 0.11s - loss: 1.0175 - acc: 0.4980 - val_loss: 1.0412 - val_acc: 0.4879\n",
            "Epoch 89/100 - 0.10s - loss: 1.0166 - acc: 0.4998 - val_loss: 1.0403 - val_acc: 0.4838\n",
            "Epoch 90/100 - 0.10s - loss: 1.0157 - acc: 0.5000 - val_loss: 1.0398 - val_acc: 0.4919\n",
            "Epoch 91/100 - 0.10s - loss: 1.0148 - acc: 0.5018 - val_loss: 1.0391 - val_acc: 0.4919\n",
            "Epoch 92/100 - 0.10s - loss: 1.0140 - acc: 0.5036 - val_loss: 1.0384 - val_acc: 0.4919\n",
            "Epoch 93/100 - 0.10s - loss: 1.0132 - acc: 0.5034 - val_loss: 1.0375 - val_acc: 0.4960\n",
            "Epoch 94/100 - 0.11s - loss: 1.0123 - acc: 0.5040 - val_loss: 1.0368 - val_acc: 0.4960\n",
            "Epoch 95/100 - 0.12s - loss: 1.0114 - acc: 0.5022 - val_loss: 1.0361 - val_acc: 0.4960\n",
            "Epoch 96/100 - 0.10s - loss: 1.0105 - acc: 0.5036 - val_loss: 1.0354 - val_acc: 0.4980\n",
            "Epoch 97/100 - 0.11s - loss: 1.0097 - acc: 0.5047 - val_loss: 1.0348 - val_acc: 0.4899\n",
            "Epoch 98/100 - 0.10s - loss: 1.0089 - acc: 0.5067 - val_loss: 1.0343 - val_acc: 0.4939\n",
            "Epoch 99/100 - 0.11s - loss: 1.0080 - acc: 0.5065 - val_loss: 1.0335 - val_acc: 0.4939\n",
            "Epoch 100/100 - 0.10s - loss: 1.0071 - acc: 0.5076 - val_loss: 1.0327 - val_acc: 0.4960\n",
            "\n",
            "Combination 171/252:\n",
            "Hidden Layers: [128, 64, 32], Activation: tanh, Learning Rate: 0.001, Batch Size: 32, Epochs: 150\n",
            "Epoch 1/150 - 0.10s - loss: 1.0982 - acc: 0.3399 - val_loss: 1.1007 - val_acc: 0.3381\n",
            "Epoch 2/150 - 0.10s - loss: 1.0965 - acc: 0.3383 - val_loss: 1.0997 - val_acc: 0.3300\n",
            "Epoch 3/150 - 0.10s - loss: 1.0950 - acc: 0.3414 - val_loss: 1.0986 - val_acc: 0.3360\n",
            "Epoch 4/150 - 0.10s - loss: 1.0936 - acc: 0.3477 - val_loss: 1.0974 - val_acc: 0.3401\n",
            "Epoch 5/150 - 0.10s - loss: 1.0922 - acc: 0.3522 - val_loss: 1.0964 - val_acc: 0.3401\n",
            "Epoch 6/150 - 0.10s - loss: 1.0909 - acc: 0.3628 - val_loss: 1.0954 - val_acc: 0.3462\n",
            "Epoch 7/150 - 0.10s - loss: 1.0896 - acc: 0.3668 - val_loss: 1.0944 - val_acc: 0.3462\n",
            "Epoch 8/150 - 0.10s - loss: 1.0884 - acc: 0.3716 - val_loss: 1.0934 - val_acc: 0.3482\n",
            "Epoch 9/150 - 0.10s - loss: 1.0872 - acc: 0.3770 - val_loss: 1.0925 - val_acc: 0.3563\n",
            "Epoch 10/150 - 0.10s - loss: 1.0860 - acc: 0.3884 - val_loss: 1.0916 - val_acc: 0.3664\n",
            "Epoch 11/150 - 0.10s - loss: 1.0849 - acc: 0.3981 - val_loss: 1.0908 - val_acc: 0.3725\n",
            "Epoch 12/150 - 0.10s - loss: 1.0838 - acc: 0.3983 - val_loss: 1.0899 - val_acc: 0.3725\n",
            "Epoch 13/150 - 0.10s - loss: 1.0827 - acc: 0.3992 - val_loss: 1.0891 - val_acc: 0.3826\n",
            "Epoch 14/150 - 0.10s - loss: 1.0817 - acc: 0.4080 - val_loss: 1.0882 - val_acc: 0.3887\n",
            "Epoch 15/150 - 0.12s - loss: 1.0806 - acc: 0.4114 - val_loss: 1.0874 - val_acc: 0.3846\n",
            "Epoch 16/150 - 0.10s - loss: 1.0796 - acc: 0.4145 - val_loss: 1.0866 - val_acc: 0.3927\n",
            "Epoch 17/150 - 0.10s - loss: 1.0786 - acc: 0.4217 - val_loss: 1.0859 - val_acc: 0.3988\n",
            "Epoch 18/150 - 0.10s - loss: 1.0777 - acc: 0.4256 - val_loss: 1.0851 - val_acc: 0.3968\n",
            "Epoch 19/150 - 0.10s - loss: 1.0767 - acc: 0.4249 - val_loss: 1.0845 - val_acc: 0.3927\n",
            "Epoch 20/150 - 0.10s - loss: 1.0757 - acc: 0.4274 - val_loss: 1.0837 - val_acc: 0.4008\n",
            "Epoch 21/150 - 0.11s - loss: 1.0748 - acc: 0.4300 - val_loss: 1.0831 - val_acc: 0.4008\n",
            "Epoch 22/150 - 0.10s - loss: 1.0739 - acc: 0.4312 - val_loss: 1.0824 - val_acc: 0.4028\n",
            "Epoch 23/150 - 0.10s - loss: 1.0730 - acc: 0.4323 - val_loss: 1.0817 - val_acc: 0.4069\n",
            "Epoch 24/150 - 0.10s - loss: 1.0721 - acc: 0.4359 - val_loss: 1.0810 - val_acc: 0.4089\n",
            "Epoch 25/150 - 0.10s - loss: 1.0712 - acc: 0.4404 - val_loss: 1.0803 - val_acc: 0.4069\n",
            "Epoch 26/150 - 0.10s - loss: 1.0703 - acc: 0.4433 - val_loss: 1.0797 - val_acc: 0.4049\n",
            "Epoch 27/150 - 0.11s - loss: 1.0694 - acc: 0.4451 - val_loss: 1.0791 - val_acc: 0.4028\n",
            "Epoch 28/150 - 0.10s - loss: 1.0685 - acc: 0.4442 - val_loss: 1.0785 - val_acc: 0.4069\n",
            "Epoch 29/150 - 0.10s - loss: 1.0676 - acc: 0.4492 - val_loss: 1.0777 - val_acc: 0.3968\n",
            "Epoch 30/150 - 0.11s - loss: 1.0667 - acc: 0.4498 - val_loss: 1.0771 - val_acc: 0.3988\n",
            "Epoch 31/150 - 0.10s - loss: 1.0659 - acc: 0.4496 - val_loss: 1.0765 - val_acc: 0.3968\n",
            "Epoch 32/150 - 0.10s - loss: 1.0650 - acc: 0.4523 - val_loss: 1.0758 - val_acc: 0.3927\n",
            "Epoch 33/150 - 0.10s - loss: 1.0641 - acc: 0.4543 - val_loss: 1.0753 - val_acc: 0.3907\n",
            "Epoch 34/150 - 0.10s - loss: 1.0633 - acc: 0.4568 - val_loss: 1.0747 - val_acc: 0.3927\n",
            "Epoch 35/150 - 0.10s - loss: 1.0624 - acc: 0.4568 - val_loss: 1.0741 - val_acc: 0.3907\n",
            "Epoch 36/150 - 0.10s - loss: 1.0616 - acc: 0.4579 - val_loss: 1.0734 - val_acc: 0.3927\n",
            "Epoch 37/150 - 0.10s - loss: 1.0607 - acc: 0.4579 - val_loss: 1.0729 - val_acc: 0.3947\n",
            "Epoch 38/150 - 0.10s - loss: 1.0599 - acc: 0.4615 - val_loss: 1.0722 - val_acc: 0.4089\n",
            "Epoch 39/150 - 0.10s - loss: 1.0590 - acc: 0.4624 - val_loss: 1.0717 - val_acc: 0.4150\n",
            "Epoch 40/150 - 0.10s - loss: 1.0582 - acc: 0.4640 - val_loss: 1.0712 - val_acc: 0.4089\n",
            "Epoch 41/150 - 0.10s - loss: 1.0573 - acc: 0.4638 - val_loss: 1.0705 - val_acc: 0.4251\n",
            "Epoch 42/150 - 0.10s - loss: 1.0565 - acc: 0.4642 - val_loss: 1.0699 - val_acc: 0.4150\n",
            "Epoch 43/150 - 0.10s - loss: 1.0556 - acc: 0.4627 - val_loss: 1.0694 - val_acc: 0.4130\n",
            "Epoch 44/150 - 0.10s - loss: 1.0548 - acc: 0.4681 - val_loss: 1.0688 - val_acc: 0.4150\n",
            "Epoch 45/150 - 0.10s - loss: 1.0539 - acc: 0.4651 - val_loss: 1.0682 - val_acc: 0.4069\n",
            "Epoch 46/150 - 0.10s - loss: 1.0531 - acc: 0.4683 - val_loss: 1.0676 - val_acc: 0.4069\n",
            "Epoch 47/150 - 0.10s - loss: 1.0522 - acc: 0.4663 - val_loss: 1.0672 - val_acc: 0.4069\n",
            "Epoch 48/150 - 0.10s - loss: 1.0514 - acc: 0.4660 - val_loss: 1.0666 - val_acc: 0.4049\n",
            "Epoch 49/150 - 0.10s - loss: 1.0505 - acc: 0.4696 - val_loss: 1.0660 - val_acc: 0.4089\n",
            "Epoch 50/150 - 0.10s - loss: 1.0497 - acc: 0.4705 - val_loss: 1.0653 - val_acc: 0.4170\n",
            "Epoch 51/150 - 0.10s - loss: 1.0488 - acc: 0.4721 - val_loss: 1.0647 - val_acc: 0.4231\n",
            "Epoch 52/150 - 0.10s - loss: 1.0480 - acc: 0.4714 - val_loss: 1.0643 - val_acc: 0.4150\n",
            "Epoch 53/150 - 0.10s - loss: 1.0471 - acc: 0.4755 - val_loss: 1.0636 - val_acc: 0.4251\n",
            "Epoch 54/150 - 0.10s - loss: 1.0462 - acc: 0.4746 - val_loss: 1.0629 - val_acc: 0.4291\n",
            "Epoch 55/150 - 0.10s - loss: 1.0454 - acc: 0.4766 - val_loss: 1.0624 - val_acc: 0.4251\n",
            "Epoch 56/150 - 0.10s - loss: 1.0445 - acc: 0.4777 - val_loss: 1.0619 - val_acc: 0.4271\n",
            "Epoch 57/150 - 0.11s - loss: 1.0436 - acc: 0.4764 - val_loss: 1.0612 - val_acc: 0.4291\n",
            "Epoch 58/150 - 0.10s - loss: 1.0428 - acc: 0.4757 - val_loss: 1.0605 - val_acc: 0.4393\n",
            "Epoch 59/150 - 0.10s - loss: 1.0419 - acc: 0.4775 - val_loss: 1.0600 - val_acc: 0.4332\n",
            "Epoch 60/150 - 0.10s - loss: 1.0411 - acc: 0.4764 - val_loss: 1.0593 - val_acc: 0.4393\n",
            "Epoch 61/150 - 0.10s - loss: 1.0401 - acc: 0.4780 - val_loss: 1.0589 - val_acc: 0.4413\n",
            "Epoch 62/150 - 0.10s - loss: 1.0393 - acc: 0.4777 - val_loss: 1.0582 - val_acc: 0.4413\n",
            "Epoch 63/150 - 0.10s - loss: 1.0384 - acc: 0.4802 - val_loss: 1.0577 - val_acc: 0.4453\n",
            "Epoch 64/150 - 0.11s - loss: 1.0375 - acc: 0.4807 - val_loss: 1.0571 - val_acc: 0.4494\n",
            "Epoch 65/150 - 0.10s - loss: 1.0366 - acc: 0.4825 - val_loss: 1.0566 - val_acc: 0.4514\n",
            "Epoch 66/150 - 0.10s - loss: 1.0358 - acc: 0.4804 - val_loss: 1.0558 - val_acc: 0.4514\n",
            "Epoch 67/150 - 0.10s - loss: 1.0348 - acc: 0.4834 - val_loss: 1.0553 - val_acc: 0.4555\n",
            "Epoch 68/150 - 0.10s - loss: 1.0340 - acc: 0.4863 - val_loss: 1.0549 - val_acc: 0.4514\n",
            "Epoch 69/150 - 0.10s - loss: 1.0331 - acc: 0.4867 - val_loss: 1.0543 - val_acc: 0.4494\n",
            "Epoch 70/150 - 0.10s - loss: 1.0322 - acc: 0.4879 - val_loss: 1.0536 - val_acc: 0.4595\n",
            "Epoch 71/150 - 0.10s - loss: 1.0313 - acc: 0.4881 - val_loss: 1.0529 - val_acc: 0.4656\n",
            "Epoch 72/150 - 0.10s - loss: 1.0304 - acc: 0.4854 - val_loss: 1.0523 - val_acc: 0.4676\n",
            "Epoch 73/150 - 0.10s - loss: 1.0294 - acc: 0.4888 - val_loss: 1.0517 - val_acc: 0.4676\n",
            "Epoch 74/150 - 0.11s - loss: 1.0285 - acc: 0.4915 - val_loss: 1.0511 - val_acc: 0.4676\n",
            "Epoch 75/150 - 0.10s - loss: 1.0276 - acc: 0.4919 - val_loss: 1.0505 - val_acc: 0.4676\n",
            "Epoch 76/150 - 0.10s - loss: 1.0268 - acc: 0.4978 - val_loss: 1.0502 - val_acc: 0.4676\n",
            "Epoch 77/150 - 0.10s - loss: 1.0258 - acc: 0.4975 - val_loss: 1.0494 - val_acc: 0.4676\n",
            "Epoch 78/150 - 0.10s - loss: 1.0249 - acc: 0.4975 - val_loss: 1.0488 - val_acc: 0.4656\n",
            "Epoch 79/150 - 0.10s - loss: 1.0240 - acc: 0.4962 - val_loss: 1.0479 - val_acc: 0.4737\n",
            "Epoch 80/150 - 0.11s - loss: 1.0231 - acc: 0.4948 - val_loss: 1.0472 - val_acc: 0.4696\n",
            "Epoch 81/150 - 0.10s - loss: 1.0221 - acc: 0.4975 - val_loss: 1.0468 - val_acc: 0.4757\n",
            "Epoch 82/150 - 0.10s - loss: 1.0212 - acc: 0.4982 - val_loss: 1.0460 - val_acc: 0.4757\n",
            "Epoch 83/150 - 0.10s - loss: 1.0203 - acc: 0.5013 - val_loss: 1.0455 - val_acc: 0.4818\n",
            "Epoch 84/150 - 0.10s - loss: 1.0193 - acc: 0.5007 - val_loss: 1.0448 - val_acc: 0.4757\n",
            "Epoch 85/150 - 0.10s - loss: 1.0184 - acc: 0.5054 - val_loss: 1.0444 - val_acc: 0.4798\n",
            "Epoch 86/150 - 0.11s - loss: 1.0175 - acc: 0.5047 - val_loss: 1.0435 - val_acc: 0.4838\n",
            "Epoch 87/150 - 0.10s - loss: 1.0166 - acc: 0.5038 - val_loss: 1.0428 - val_acc: 0.4777\n",
            "Epoch 88/150 - 0.10s - loss: 1.0156 - acc: 0.5034 - val_loss: 1.0419 - val_acc: 0.4838\n",
            "Epoch 89/150 - 0.10s - loss: 1.0147 - acc: 0.5040 - val_loss: 1.0413 - val_acc: 0.4858\n",
            "Epoch 90/150 - 0.10s - loss: 1.0137 - acc: 0.5061 - val_loss: 1.0407 - val_acc: 0.4919\n",
            "Epoch 91/150 - 0.10s - loss: 1.0128 - acc: 0.5045 - val_loss: 1.0399 - val_acc: 0.4879\n",
            "Epoch 92/150 - 0.11s - loss: 1.0118 - acc: 0.5103 - val_loss: 1.0393 - val_acc: 0.4919\n",
            "Epoch 93/150 - 0.10s - loss: 1.0109 - acc: 0.5094 - val_loss: 1.0387 - val_acc: 0.4939\n",
            "Epoch 94/150 - 0.10s - loss: 1.0100 - acc: 0.5085 - val_loss: 1.0379 - val_acc: 0.4980\n",
            "Epoch 95/150 - 0.10s - loss: 1.0090 - acc: 0.5124 - val_loss: 1.0373 - val_acc: 0.4939\n",
            "Epoch 96/150 - 0.10s - loss: 1.0081 - acc: 0.5121 - val_loss: 1.0365 - val_acc: 0.5061\n",
            "Epoch 97/150 - 0.10s - loss: 1.0071 - acc: 0.5146 - val_loss: 1.0360 - val_acc: 0.4939\n",
            "Epoch 98/150 - 0.10s - loss: 1.0062 - acc: 0.5162 - val_loss: 1.0352 - val_acc: 0.4980\n",
            "Epoch 99/150 - 0.10s - loss: 1.0053 - acc: 0.5157 - val_loss: 1.0347 - val_acc: 0.4960\n",
            "Epoch 100/150 - 0.10s - loss: 1.0045 - acc: 0.5160 - val_loss: 1.0337 - val_acc: 0.5040\n",
            "Epoch 101/150 - 0.11s - loss: 1.0036 - acc: 0.5130 - val_loss: 1.0333 - val_acc: 0.5020\n",
            "Epoch 102/150 - 0.10s - loss: 1.0024 - acc: 0.5175 - val_loss: 1.0321 - val_acc: 0.5101\n",
            "Epoch 103/150 - 0.10s - loss: 1.0016 - acc: 0.5157 - val_loss: 1.0313 - val_acc: 0.5101\n",
            "Epoch 104/150 - 0.10s - loss: 1.0007 - acc: 0.5189 - val_loss: 1.0307 - val_acc: 0.5101\n",
            "Epoch 105/150 - 0.10s - loss: 0.9996 - acc: 0.5193 - val_loss: 1.0300 - val_acc: 0.5101\n",
            "Epoch 106/150 - 0.10s - loss: 0.9987 - acc: 0.5198 - val_loss: 1.0292 - val_acc: 0.5162\n",
            "Epoch 107/150 - 0.10s - loss: 0.9980 - acc: 0.5220 - val_loss: 1.0285 - val_acc: 0.5121\n",
            "Epoch 108/150 - 0.10s - loss: 0.9969 - acc: 0.5182 - val_loss: 1.0279 - val_acc: 0.5121\n",
            "Epoch 109/150 - 0.10s - loss: 0.9963 - acc: 0.5227 - val_loss: 1.0271 - val_acc: 0.5142\n",
            "Epoch 110/150 - 0.12s - loss: 0.9950 - acc: 0.5216 - val_loss: 1.0263 - val_acc: 0.5223\n",
            "Epoch 111/150 - 0.10s - loss: 0.9942 - acc: 0.5238 - val_loss: 1.0256 - val_acc: 0.5223\n",
            "Epoch 112/150 - 0.10s - loss: 0.9935 - acc: 0.5236 - val_loss: 1.0248 - val_acc: 0.5162\n",
            "Epoch 113/150 - 0.10s - loss: 0.9923 - acc: 0.5205 - val_loss: 1.0242 - val_acc: 0.5121\n",
            "Epoch 114/150 - 0.10s - loss: 0.9914 - acc: 0.5189 - val_loss: 1.0233 - val_acc: 0.5182\n",
            "Epoch 115/150 - 0.10s - loss: 0.9905 - acc: 0.5191 - val_loss: 1.0225 - val_acc: 0.5182\n",
            "Epoch 116/150 - 0.10s - loss: 0.9900 - acc: 0.5207 - val_loss: 1.0223 - val_acc: 0.5142\n",
            "Epoch 117/150 - 0.10s - loss: 0.9889 - acc: 0.5227 - val_loss: 1.0210 - val_acc: 0.5243\n",
            "Epoch 118/150 - 0.10s - loss: 0.9879 - acc: 0.5218 - val_loss: 1.0205 - val_acc: 0.5162\n",
            "Epoch 119/150 - 0.10s - loss: 0.9871 - acc: 0.5236 - val_loss: 1.0196 - val_acc: 0.5283\n",
            "Epoch 120/150 - 0.10s - loss: 0.9863 - acc: 0.5243 - val_loss: 1.0189 - val_acc: 0.5304\n",
            "Epoch 121/150 - 0.10s - loss: 0.9853 - acc: 0.5256 - val_loss: 1.0180 - val_acc: 0.5243\n",
            "Epoch 122/150 - 0.10s - loss: 0.9844 - acc: 0.5252 - val_loss: 1.0173 - val_acc: 0.5243\n",
            "Epoch 123/150 - 0.10s - loss: 0.9835 - acc: 0.5263 - val_loss: 1.0166 - val_acc: 0.5223\n",
            "Epoch 124/150 - 0.10s - loss: 0.9832 - acc: 0.5279 - val_loss: 1.0160 - val_acc: 0.5304\n",
            "Epoch 125/150 - 0.10s - loss: 0.9821 - acc: 0.5272 - val_loss: 1.0158 - val_acc: 0.5121\n",
            "Epoch 126/150 - 0.10s - loss: 0.9810 - acc: 0.5288 - val_loss: 1.0144 - val_acc: 0.5243\n",
            "Epoch 127/150 - 0.10s - loss: 0.9803 - acc: 0.5295 - val_loss: 1.0136 - val_acc: 0.5324\n",
            "Epoch 128/150 - 0.10s - loss: 0.9794 - acc: 0.5297 - val_loss: 1.0128 - val_acc: 0.5283\n",
            "Epoch 129/150 - 0.10s - loss: 0.9788 - acc: 0.5317 - val_loss: 1.0122 - val_acc: 0.5304\n",
            "Epoch 130/150 - 0.10s - loss: 0.9777 - acc: 0.5310 - val_loss: 1.0115 - val_acc: 0.5304\n",
            "Epoch 131/150 - 0.10s - loss: 0.9769 - acc: 0.5322 - val_loss: 1.0108 - val_acc: 0.5364\n",
            "Epoch 132/150 - 0.10s - loss: 0.9764 - acc: 0.5315 - val_loss: 1.0103 - val_acc: 0.5344\n",
            "Epoch 133/150 - 0.10s - loss: 0.9758 - acc: 0.5301 - val_loss: 1.0102 - val_acc: 0.5162\n",
            "Epoch 134/150 - 0.11s - loss: 0.9746 - acc: 0.5335 - val_loss: 1.0088 - val_acc: 0.5385\n",
            "Epoch 135/150 - 0.10s - loss: 0.9739 - acc: 0.5337 - val_loss: 1.0082 - val_acc: 0.5425\n",
            "Epoch 136/150 - 0.10s - loss: 0.9732 - acc: 0.5342 - val_loss: 1.0080 - val_acc: 0.5223\n",
            "Epoch 137/150 - 0.11s - loss: 0.9723 - acc: 0.5355 - val_loss: 1.0068 - val_acc: 0.5243\n",
            "Epoch 138/150 - 0.10s - loss: 0.9716 - acc: 0.5349 - val_loss: 1.0059 - val_acc: 0.5425\n",
            "Epoch 139/150 - 0.10s - loss: 0.9708 - acc: 0.5346 - val_loss: 1.0057 - val_acc: 0.5182\n",
            "Epoch 140/150 - 0.11s - loss: 0.9702 - acc: 0.5360 - val_loss: 1.0053 - val_acc: 0.5223\n",
            "Epoch 141/150 - 0.10s - loss: 0.9699 - acc: 0.5344 - val_loss: 1.0050 - val_acc: 0.5182\n",
            "Epoch 142/150 - 0.10s - loss: 0.9688 - acc: 0.5351 - val_loss: 1.0039 - val_acc: 0.5223\n",
            "Epoch 143/150 - 0.10s - loss: 0.9682 - acc: 0.5378 - val_loss: 1.0029 - val_acc: 0.5425\n",
            "Epoch 144/150 - 0.10s - loss: 0.9671 - acc: 0.5378 - val_loss: 1.0023 - val_acc: 0.5385\n",
            "Epoch 145/150 - 0.10s - loss: 0.9667 - acc: 0.5387 - val_loss: 1.0023 - val_acc: 0.5243\n",
            "Epoch 146/150 - 0.11s - loss: 0.9658 - acc: 0.5378 - val_loss: 1.0012 - val_acc: 0.5445\n",
            "Epoch 147/150 - 0.10s - loss: 0.9650 - acc: 0.5376 - val_loss: 1.0006 - val_acc: 0.5324\n",
            "Epoch 148/150 - 0.10s - loss: 0.9643 - acc: 0.5398 - val_loss: 0.9999 - val_acc: 0.5364\n",
            "Epoch 149/150 - 0.10s - loss: 0.9640 - acc: 0.5378 - val_loss: 0.9992 - val_acc: 0.5425\n",
            "Epoch 150/150 - 0.10s - loss: 0.9634 - acc: 0.5396 - val_loss: 0.9988 - val_acc: 0.5405\n",
            "\n",
            "Combination 172/252:\n",
            "Hidden Layers: [128, 64, 32], Activation: tanh, Learning Rate: 0.001, Batch Size: 64, Epochs: 50\n",
            "Epoch 1/50 - 0.09s - loss: 1.1071 - acc: 0.3650 - val_loss: 1.1094 - val_acc: 0.3623\n",
            "Epoch 2/50 - 0.09s - loss: 1.1031 - acc: 0.3583 - val_loss: 1.1066 - val_acc: 0.3462\n",
            "Epoch 3/50 - 0.09s - loss: 1.1007 - acc: 0.3516 - val_loss: 1.1051 - val_acc: 0.3198\n",
            "Epoch 4/50 - 0.09s - loss: 1.0992 - acc: 0.3417 - val_loss: 1.1040 - val_acc: 0.2996\n",
            "Epoch 5/50 - 0.09s - loss: 1.0979 - acc: 0.3374 - val_loss: 1.1031 - val_acc: 0.3036\n",
            "Epoch 6/50 - 0.09s - loss: 1.0968 - acc: 0.3374 - val_loss: 1.1024 - val_acc: 0.2976\n",
            "Epoch 7/50 - 0.08s - loss: 1.0958 - acc: 0.3399 - val_loss: 1.1016 - val_acc: 0.2976\n",
            "Epoch 8/50 - 0.10s - loss: 1.0949 - acc: 0.3426 - val_loss: 1.1008 - val_acc: 0.3158\n",
            "Epoch 9/50 - 0.09s - loss: 1.0940 - acc: 0.3464 - val_loss: 1.1001 - val_acc: 0.3178\n",
            "Epoch 10/50 - 0.08s - loss: 1.0931 - acc: 0.3486 - val_loss: 1.0994 - val_acc: 0.3219\n",
            "Epoch 11/50 - 0.09s - loss: 1.0922 - acc: 0.3561 - val_loss: 1.0986 - val_acc: 0.3340\n",
            "Epoch 12/50 - 0.08s - loss: 1.0914 - acc: 0.3605 - val_loss: 1.0978 - val_acc: 0.3360\n",
            "Epoch 13/50 - 0.08s - loss: 1.0905 - acc: 0.3644 - val_loss: 1.0970 - val_acc: 0.3381\n",
            "Epoch 14/50 - 0.09s - loss: 1.0897 - acc: 0.3695 - val_loss: 1.0964 - val_acc: 0.3360\n",
            "Epoch 15/50 - 0.08s - loss: 1.0889 - acc: 0.3727 - val_loss: 1.0957 - val_acc: 0.3401\n",
            "Epoch 16/50 - 0.09s - loss: 1.0882 - acc: 0.3752 - val_loss: 1.0950 - val_acc: 0.3462\n",
            "Epoch 17/50 - 0.09s - loss: 1.0874 - acc: 0.3819 - val_loss: 1.0943 - val_acc: 0.3543\n",
            "Epoch 18/50 - 0.09s - loss: 1.0866 - acc: 0.3880 - val_loss: 1.0936 - val_acc: 0.3563\n",
            "Epoch 19/50 - 0.09s - loss: 1.0859 - acc: 0.3938 - val_loss: 1.0929 - val_acc: 0.3502\n",
            "Epoch 20/50 - 0.09s - loss: 1.0852 - acc: 0.3977 - val_loss: 1.0923 - val_acc: 0.3603\n",
            "Epoch 21/50 - 0.09s - loss: 1.0844 - acc: 0.3959 - val_loss: 1.0918 - val_acc: 0.3603\n",
            "Epoch 22/50 - 0.09s - loss: 1.0837 - acc: 0.3992 - val_loss: 1.0912 - val_acc: 0.3725\n",
            "Epoch 23/50 - 0.09s - loss: 1.0830 - acc: 0.4026 - val_loss: 1.0906 - val_acc: 0.3684\n",
            "Epoch 24/50 - 0.09s - loss: 1.0824 - acc: 0.4060 - val_loss: 1.0900 - val_acc: 0.3704\n",
            "Epoch 25/50 - 0.08s - loss: 1.0817 - acc: 0.4089 - val_loss: 1.0894 - val_acc: 0.3725\n",
            "Epoch 26/50 - 0.09s - loss: 1.0810 - acc: 0.4161 - val_loss: 1.0888 - val_acc: 0.3765\n",
            "Epoch 27/50 - 0.09s - loss: 1.0804 - acc: 0.4215 - val_loss: 1.0882 - val_acc: 0.3785\n",
            "Epoch 28/50 - 0.08s - loss: 1.0797 - acc: 0.4249 - val_loss: 1.0877 - val_acc: 0.3785\n",
            "Epoch 29/50 - 0.09s - loss: 1.0791 - acc: 0.4256 - val_loss: 1.0872 - val_acc: 0.3826\n",
            "Epoch 30/50 - 0.09s - loss: 1.0784 - acc: 0.4294 - val_loss: 1.0867 - val_acc: 0.3826\n",
            "Epoch 31/50 - 0.09s - loss: 1.0778 - acc: 0.4303 - val_loss: 1.0862 - val_acc: 0.3846\n",
            "Epoch 32/50 - 0.09s - loss: 1.0772 - acc: 0.4330 - val_loss: 1.0857 - val_acc: 0.3846\n",
            "Epoch 33/50 - 0.10s - loss: 1.0766 - acc: 0.4345 - val_loss: 1.0852 - val_acc: 0.3846\n",
            "Epoch 34/50 - 0.09s - loss: 1.0760 - acc: 0.4377 - val_loss: 1.0847 - val_acc: 0.3907\n",
            "Epoch 35/50 - 0.09s - loss: 1.0754 - acc: 0.4424 - val_loss: 1.0842 - val_acc: 0.3968\n",
            "Epoch 36/50 - 0.08s - loss: 1.0748 - acc: 0.4449 - val_loss: 1.0837 - val_acc: 0.3988\n",
            "Epoch 37/50 - 0.08s - loss: 1.0742 - acc: 0.4444 - val_loss: 1.0832 - val_acc: 0.4028\n",
            "Epoch 38/50 - 0.10s - loss: 1.0736 - acc: 0.4474 - val_loss: 1.0828 - val_acc: 0.4049\n",
            "Epoch 39/50 - 0.08s - loss: 1.0730 - acc: 0.4496 - val_loss: 1.0823 - val_acc: 0.4069\n",
            "Epoch 40/50 - 0.08s - loss: 1.0724 - acc: 0.4514 - val_loss: 1.0818 - val_acc: 0.4089\n",
            "Epoch 41/50 - 0.09s - loss: 1.0719 - acc: 0.4543 - val_loss: 1.0813 - val_acc: 0.4089\n",
            "Epoch 42/50 - 0.09s - loss: 1.0713 - acc: 0.4537 - val_loss: 1.0809 - val_acc: 0.4089\n",
            "Epoch 43/50 - 0.08s - loss: 1.0708 - acc: 0.4570 - val_loss: 1.0805 - val_acc: 0.4109\n",
            "Epoch 44/50 - 0.09s - loss: 1.0702 - acc: 0.4582 - val_loss: 1.0801 - val_acc: 0.4130\n",
            "Epoch 45/50 - 0.09s - loss: 1.0697 - acc: 0.4613 - val_loss: 1.0797 - val_acc: 0.4150\n",
            "Epoch 46/50 - 0.08s - loss: 1.0691 - acc: 0.4618 - val_loss: 1.0793 - val_acc: 0.4109\n",
            "Epoch 47/50 - 0.09s - loss: 1.0686 - acc: 0.4620 - val_loss: 1.0788 - val_acc: 0.4069\n",
            "Epoch 48/50 - 0.09s - loss: 1.0681 - acc: 0.4624 - val_loss: 1.0784 - val_acc: 0.4150\n",
            "Epoch 49/50 - 0.09s - loss: 1.0675 - acc: 0.4618 - val_loss: 1.0781 - val_acc: 0.4170\n",
            "Epoch 50/50 - 0.09s - loss: 1.0670 - acc: 0.4620 - val_loss: 1.0776 - val_acc: 0.4170\n",
            "\n",
            "Combination 173/252:\n",
            "Hidden Layers: [128, 64, 32], Activation: tanh, Learning Rate: 0.001, Batch Size: 64, Epochs: 100\n",
            "Epoch 1/100 - 0.08s - loss: 1.1299 - acc: 0.3372 - val_loss: 1.1344 - val_acc: 0.3381\n",
            "Epoch 2/100 - 0.08s - loss: 1.1172 - acc: 0.3171 - val_loss: 1.1216 - val_acc: 0.3178\n",
            "Epoch 3/100 - 0.09s - loss: 1.1126 - acc: 0.3030 - val_loss: 1.1171 - val_acc: 0.2814\n",
            "Epoch 4/100 - 0.09s - loss: 1.1101 - acc: 0.2967 - val_loss: 1.1149 - val_acc: 0.2692\n",
            "Epoch 5/100 - 0.09s - loss: 1.1082 - acc: 0.2949 - val_loss: 1.1133 - val_acc: 0.2692\n",
            "Epoch 6/100 - 0.10s - loss: 1.1066 - acc: 0.3025 - val_loss: 1.1120 - val_acc: 0.2692\n",
            "Epoch 7/100 - 0.09s - loss: 1.1050 - acc: 0.3104 - val_loss: 1.1108 - val_acc: 0.2834\n",
            "Epoch 8/100 - 0.10s - loss: 1.1035 - acc: 0.3239 - val_loss: 1.1097 - val_acc: 0.2895\n",
            "Epoch 9/100 - 0.10s - loss: 1.1021 - acc: 0.3293 - val_loss: 1.1085 - val_acc: 0.3016\n",
            "Epoch 10/100 - 0.09s - loss: 1.1007 - acc: 0.3372 - val_loss: 1.1074 - val_acc: 0.3016\n",
            "Epoch 11/100 - 0.09s - loss: 1.0994 - acc: 0.3444 - val_loss: 1.1064 - val_acc: 0.3117\n",
            "Epoch 12/100 - 0.13s - loss: 1.0982 - acc: 0.3498 - val_loss: 1.1054 - val_acc: 0.3239\n",
            "Epoch 13/100 - 0.09s - loss: 1.0969 - acc: 0.3572 - val_loss: 1.1043 - val_acc: 0.3401\n",
            "Epoch 14/100 - 0.09s - loss: 1.0957 - acc: 0.3621 - val_loss: 1.1034 - val_acc: 0.3340\n",
            "Epoch 15/100 - 0.09s - loss: 1.0946 - acc: 0.3662 - val_loss: 1.1025 - val_acc: 0.3401\n",
            "Epoch 16/100 - 0.08s - loss: 1.0934 - acc: 0.3680 - val_loss: 1.1016 - val_acc: 0.3462\n",
            "Epoch 17/100 - 0.08s - loss: 1.0923 - acc: 0.3720 - val_loss: 1.1006 - val_acc: 0.3462\n",
            "Epoch 18/100 - 0.09s - loss: 1.0913 - acc: 0.3720 - val_loss: 1.0999 - val_acc: 0.3401\n",
            "Epoch 19/100 - 0.09s - loss: 1.0902 - acc: 0.3779 - val_loss: 1.0990 - val_acc: 0.3482\n",
            "Epoch 20/100 - 0.09s - loss: 1.0892 - acc: 0.3792 - val_loss: 1.0982 - val_acc: 0.3462\n",
            "Epoch 21/100 - 0.09s - loss: 1.0882 - acc: 0.3848 - val_loss: 1.0974 - val_acc: 0.3502\n",
            "Epoch 22/100 - 0.10s - loss: 1.0872 - acc: 0.3853 - val_loss: 1.0967 - val_acc: 0.3522\n",
            "Epoch 23/100 - 0.09s - loss: 1.0862 - acc: 0.3898 - val_loss: 1.0959 - val_acc: 0.3543\n",
            "Epoch 24/100 - 0.10s - loss: 1.0853 - acc: 0.3963 - val_loss: 1.0951 - val_acc: 0.3664\n",
            "Epoch 25/100 - 0.09s - loss: 1.0844 - acc: 0.3992 - val_loss: 1.0944 - val_acc: 0.3704\n",
            "Epoch 26/100 - 0.09s - loss: 1.0835 - acc: 0.3997 - val_loss: 1.0937 - val_acc: 0.3745\n",
            "Epoch 27/100 - 0.11s - loss: 1.0826 - acc: 0.3999 - val_loss: 1.0930 - val_acc: 0.3704\n",
            "Epoch 28/100 - 0.09s - loss: 1.0817 - acc: 0.4026 - val_loss: 1.0923 - val_acc: 0.3765\n",
            "Epoch 29/100 - 0.09s - loss: 1.0808 - acc: 0.4055 - val_loss: 1.0917 - val_acc: 0.3745\n",
            "Epoch 30/100 - 0.10s - loss: 1.0800 - acc: 0.4091 - val_loss: 1.0910 - val_acc: 0.3846\n",
            "Epoch 31/100 - 0.10s - loss: 1.0791 - acc: 0.4148 - val_loss: 1.0903 - val_acc: 0.3846\n",
            "Epoch 32/100 - 0.10s - loss: 1.0783 - acc: 0.4184 - val_loss: 1.0897 - val_acc: 0.3907\n",
            "Epoch 33/100 - 0.09s - loss: 1.0775 - acc: 0.4202 - val_loss: 1.0891 - val_acc: 0.3907\n",
            "Epoch 34/100 - 0.09s - loss: 1.0767 - acc: 0.4199 - val_loss: 1.0884 - val_acc: 0.3806\n",
            "Epoch 35/100 - 0.09s - loss: 1.0759 - acc: 0.4235 - val_loss: 1.0879 - val_acc: 0.3866\n",
            "Epoch 36/100 - 0.10s - loss: 1.0752 - acc: 0.4247 - val_loss: 1.0873 - val_acc: 0.3866\n",
            "Epoch 37/100 - 0.09s - loss: 1.0744 - acc: 0.4303 - val_loss: 1.0867 - val_acc: 0.3846\n",
            "Epoch 38/100 - 0.09s - loss: 1.0736 - acc: 0.4312 - val_loss: 1.0861 - val_acc: 0.3846\n",
            "Epoch 39/100 - 0.11s - loss: 1.0729 - acc: 0.4312 - val_loss: 1.0855 - val_acc: 0.3846\n",
            "Epoch 40/100 - 0.09s - loss: 1.0721 - acc: 0.4343 - val_loss: 1.0849 - val_acc: 0.3846\n",
            "Epoch 41/100 - 0.08s - loss: 1.0714 - acc: 0.4350 - val_loss: 1.0844 - val_acc: 0.3947\n",
            "Epoch 42/100 - 0.10s - loss: 1.0707 - acc: 0.4361 - val_loss: 1.0838 - val_acc: 0.3968\n",
            "Epoch 43/100 - 0.09s - loss: 1.0700 - acc: 0.4384 - val_loss: 1.0833 - val_acc: 0.3947\n",
            "Epoch 44/100 - 0.09s - loss: 1.0693 - acc: 0.4393 - val_loss: 1.0829 - val_acc: 0.4008\n",
            "Epoch 45/100 - 0.10s - loss: 1.0686 - acc: 0.4417 - val_loss: 1.0823 - val_acc: 0.4008\n",
            "Epoch 46/100 - 0.09s - loss: 1.0679 - acc: 0.4429 - val_loss: 1.0818 - val_acc: 0.4008\n",
            "Epoch 47/100 - 0.09s - loss: 1.0672 - acc: 0.4429 - val_loss: 1.0812 - val_acc: 0.3947\n",
            "Epoch 48/100 - 0.10s - loss: 1.0665 - acc: 0.4449 - val_loss: 1.0807 - val_acc: 0.4028\n",
            "Epoch 49/100 - 0.09s - loss: 1.0658 - acc: 0.4458 - val_loss: 1.0802 - val_acc: 0.4049\n",
            "Epoch 50/100 - 0.09s - loss: 1.0651 - acc: 0.4469 - val_loss: 1.0797 - val_acc: 0.4049\n",
            "Epoch 51/100 - 0.09s - loss: 1.0645 - acc: 0.4476 - val_loss: 1.0792 - val_acc: 0.4109\n",
            "Epoch 52/100 - 0.08s - loss: 1.0638 - acc: 0.4489 - val_loss: 1.0788 - val_acc: 0.4109\n",
            "Epoch 53/100 - 0.09s - loss: 1.0632 - acc: 0.4492 - val_loss: 1.0781 - val_acc: 0.4109\n",
            "Epoch 54/100 - 0.10s - loss: 1.0625 - acc: 0.4519 - val_loss: 1.0776 - val_acc: 0.4109\n",
            "Epoch 55/100 - 0.08s - loss: 1.0619 - acc: 0.4537 - val_loss: 1.0771 - val_acc: 0.4130\n",
            "Epoch 56/100 - 0.09s - loss: 1.0612 - acc: 0.4552 - val_loss: 1.0766 - val_acc: 0.4170\n",
            "Epoch 57/100 - 0.09s - loss: 1.0606 - acc: 0.4557 - val_loss: 1.0762 - val_acc: 0.4170\n",
            "Epoch 58/100 - 0.08s - loss: 1.0600 - acc: 0.4584 - val_loss: 1.0758 - val_acc: 0.4170\n",
            "Epoch 59/100 - 0.09s - loss: 1.0593 - acc: 0.4588 - val_loss: 1.0753 - val_acc: 0.4211\n",
            "Epoch 60/100 - 0.09s - loss: 1.0587 - acc: 0.4613 - val_loss: 1.0748 - val_acc: 0.4211\n",
            "Epoch 61/100 - 0.08s - loss: 1.0581 - acc: 0.4638 - val_loss: 1.0744 - val_acc: 0.4251\n",
            "Epoch 62/100 - 0.09s - loss: 1.0575 - acc: 0.4624 - val_loss: 1.0738 - val_acc: 0.4211\n",
            "Epoch 63/100 - 0.09s - loss: 1.0569 - acc: 0.4660 - val_loss: 1.0735 - val_acc: 0.4291\n",
            "Epoch 64/100 - 0.09s - loss: 1.0563 - acc: 0.4663 - val_loss: 1.0730 - val_acc: 0.4291\n",
            "Epoch 65/100 - 0.11s - loss: 1.0557 - acc: 0.4674 - val_loss: 1.0726 - val_acc: 0.4291\n",
            "Epoch 66/100 - 0.09s - loss: 1.0551 - acc: 0.4681 - val_loss: 1.0721 - val_acc: 0.4291\n",
            "Epoch 67/100 - 0.08s - loss: 1.0545 - acc: 0.4699 - val_loss: 1.0717 - val_acc: 0.4291\n",
            "Epoch 68/100 - 0.08s - loss: 1.0539 - acc: 0.4694 - val_loss: 1.0711 - val_acc: 0.4312\n",
            "Epoch 69/100 - 0.09s - loss: 1.0533 - acc: 0.4721 - val_loss: 1.0707 - val_acc: 0.4312\n",
            "Epoch 70/100 - 0.10s - loss: 1.0528 - acc: 0.4719 - val_loss: 1.0702 - val_acc: 0.4332\n",
            "Epoch 71/100 - 0.10s - loss: 1.0522 - acc: 0.4757 - val_loss: 1.0700 - val_acc: 0.4312\n",
            "Epoch 72/100 - 0.10s - loss: 1.0516 - acc: 0.4735 - val_loss: 1.0694 - val_acc: 0.4291\n",
            "Epoch 73/100 - 0.09s - loss: 1.0510 - acc: 0.4755 - val_loss: 1.0690 - val_acc: 0.4312\n",
            "Epoch 74/100 - 0.09s - loss: 1.0505 - acc: 0.4757 - val_loss: 1.0685 - val_acc: 0.4332\n",
            "Epoch 75/100 - 0.09s - loss: 1.0499 - acc: 0.4737 - val_loss: 1.0680 - val_acc: 0.4433\n",
            "Epoch 76/100 - 0.09s - loss: 1.0493 - acc: 0.4766 - val_loss: 1.0677 - val_acc: 0.4372\n",
            "Epoch 77/100 - 0.08s - loss: 1.0488 - acc: 0.4784 - val_loss: 1.0673 - val_acc: 0.4393\n",
            "Epoch 78/100 - 0.09s - loss: 1.0482 - acc: 0.4777 - val_loss: 1.0669 - val_acc: 0.4453\n",
            "Epoch 79/100 - 0.09s - loss: 1.0477 - acc: 0.4789 - val_loss: 1.0664 - val_acc: 0.4453\n",
            "Epoch 80/100 - 0.10s - loss: 1.0471 - acc: 0.4804 - val_loss: 1.0660 - val_acc: 0.4474\n",
            "Epoch 81/100 - 0.10s - loss: 1.0466 - acc: 0.4809 - val_loss: 1.0657 - val_acc: 0.4494\n",
            "Epoch 82/100 - 0.09s - loss: 1.0460 - acc: 0.4818 - val_loss: 1.0653 - val_acc: 0.4514\n",
            "Epoch 83/100 - 0.09s - loss: 1.0455 - acc: 0.4800 - val_loss: 1.0647 - val_acc: 0.4453\n",
            "Epoch 84/100 - 0.11s - loss: 1.0450 - acc: 0.4818 - val_loss: 1.0642 - val_acc: 0.4433\n",
            "Epoch 85/100 - 0.10s - loss: 1.0444 - acc: 0.4822 - val_loss: 1.0639 - val_acc: 0.4474\n",
            "Epoch 86/100 - 0.09s - loss: 1.0439 - acc: 0.4825 - val_loss: 1.0635 - val_acc: 0.4474\n",
            "Epoch 87/100 - 0.09s - loss: 1.0433 - acc: 0.4840 - val_loss: 1.0630 - val_acc: 0.4453\n",
            "Epoch 88/100 - 0.09s - loss: 1.0428 - acc: 0.4838 - val_loss: 1.0626 - val_acc: 0.4494\n",
            "Epoch 89/100 - 0.08s - loss: 1.0423 - acc: 0.4847 - val_loss: 1.0622 - val_acc: 0.4474\n",
            "Epoch 90/100 - 0.09s - loss: 1.0418 - acc: 0.4849 - val_loss: 1.0618 - val_acc: 0.4494\n",
            "Epoch 91/100 - 0.08s - loss: 1.0412 - acc: 0.4852 - val_loss: 1.0614 - val_acc: 0.4494\n",
            "Epoch 92/100 - 0.09s - loss: 1.0407 - acc: 0.4872 - val_loss: 1.0609 - val_acc: 0.4494\n",
            "Epoch 93/100 - 0.09s - loss: 1.0402 - acc: 0.4861 - val_loss: 1.0605 - val_acc: 0.4494\n",
            "Epoch 94/100 - 0.09s - loss: 1.0397 - acc: 0.4870 - val_loss: 1.0601 - val_acc: 0.4534\n",
            "Epoch 95/100 - 0.08s - loss: 1.0392 - acc: 0.4872 - val_loss: 1.0598 - val_acc: 0.4534\n",
            "Epoch 96/100 - 0.09s - loss: 1.0387 - acc: 0.4865 - val_loss: 1.0595 - val_acc: 0.4615\n",
            "Epoch 97/100 - 0.09s - loss: 1.0382 - acc: 0.4876 - val_loss: 1.0590 - val_acc: 0.4575\n",
            "Epoch 98/100 - 0.09s - loss: 1.0377 - acc: 0.4872 - val_loss: 1.0586 - val_acc: 0.4575\n",
            "Epoch 99/100 - 0.09s - loss: 1.0372 - acc: 0.4874 - val_loss: 1.0582 - val_acc: 0.4615\n",
            "Epoch 100/100 - 0.09s - loss: 1.0367 - acc: 0.4908 - val_loss: 1.0577 - val_acc: 0.4636\n",
            "\n",
            "Combination 174/252:\n",
            "Hidden Layers: [128, 64, 32], Activation: tanh, Learning Rate: 0.001, Batch Size: 64, Epochs: 150\n",
            "Epoch 1/150 - 0.09s - loss: 1.1147 - acc: 0.3441 - val_loss: 1.1139 - val_acc: 0.3644\n",
            "Epoch 2/150 - 0.10s - loss: 1.1044 - acc: 0.3500 - val_loss: 1.1045 - val_acc: 0.3300\n",
            "Epoch 3/150 - 0.11s - loss: 1.0992 - acc: 0.3522 - val_loss: 1.0999 - val_acc: 0.3441\n",
            "Epoch 4/150 - 0.09s - loss: 1.0962 - acc: 0.3587 - val_loss: 1.0973 - val_acc: 0.3381\n",
            "Epoch 5/150 - 0.09s - loss: 1.0944 - acc: 0.3707 - val_loss: 1.0959 - val_acc: 0.3360\n",
            "Epoch 6/150 - 0.09s - loss: 1.0932 - acc: 0.3803 - val_loss: 1.0949 - val_acc: 0.3421\n",
            "Epoch 7/150 - 0.09s - loss: 1.0922 - acc: 0.3875 - val_loss: 1.0942 - val_acc: 0.3664\n",
            "Epoch 8/150 - 0.10s - loss: 1.0914 - acc: 0.3889 - val_loss: 1.0935 - val_acc: 0.3745\n",
            "Epoch 9/150 - 0.09s - loss: 1.0907 - acc: 0.3941 - val_loss: 1.0929 - val_acc: 0.3765\n",
            "Epoch 10/150 - 0.09s - loss: 1.0899 - acc: 0.3952 - val_loss: 1.0923 - val_acc: 0.3887\n",
            "Epoch 11/150 - 0.09s - loss: 1.0892 - acc: 0.3970 - val_loss: 1.0917 - val_acc: 0.3947\n",
            "Epoch 12/150 - 0.09s - loss: 1.0885 - acc: 0.3981 - val_loss: 1.0911 - val_acc: 0.4008\n",
            "Epoch 13/150 - 0.09s - loss: 1.0879 - acc: 0.3995 - val_loss: 1.0905 - val_acc: 0.3988\n",
            "Epoch 14/150 - 0.10s - loss: 1.0872 - acc: 0.4024 - val_loss: 1.0900 - val_acc: 0.3988\n",
            "Epoch 15/150 - 0.09s - loss: 1.0865 - acc: 0.4046 - val_loss: 1.0895 - val_acc: 0.3968\n",
            "Epoch 16/150 - 0.09s - loss: 1.0859 - acc: 0.4060 - val_loss: 1.0889 - val_acc: 0.3988\n",
            "Epoch 17/150 - 0.09s - loss: 1.0852 - acc: 0.4091 - val_loss: 1.0884 - val_acc: 0.4049\n",
            "Epoch 18/150 - 0.09s - loss: 1.0846 - acc: 0.4112 - val_loss: 1.0879 - val_acc: 0.4069\n",
            "Epoch 19/150 - 0.09s - loss: 1.0840 - acc: 0.4112 - val_loss: 1.0874 - val_acc: 0.4049\n",
            "Epoch 20/150 - 0.10s - loss: 1.0834 - acc: 0.4130 - val_loss: 1.0869 - val_acc: 0.4049\n",
            "Epoch 21/150 - 0.10s - loss: 1.0828 - acc: 0.4157 - val_loss: 1.0864 - val_acc: 0.4049\n",
            "Epoch 22/150 - 0.09s - loss: 1.0822 - acc: 0.4166 - val_loss: 1.0858 - val_acc: 0.4069\n",
            "Epoch 23/150 - 0.09s - loss: 1.0816 - acc: 0.4190 - val_loss: 1.0854 - val_acc: 0.4089\n",
            "Epoch 24/150 - 0.09s - loss: 1.0810 - acc: 0.4188 - val_loss: 1.0849 - val_acc: 0.4069\n",
            "Epoch 25/150 - 0.09s - loss: 1.0805 - acc: 0.4208 - val_loss: 1.0844 - val_acc: 0.4089\n",
            "Epoch 26/150 - 0.11s - loss: 1.0799 - acc: 0.4215 - val_loss: 1.0840 - val_acc: 0.4130\n",
            "Epoch 27/150 - 0.11s - loss: 1.0793 - acc: 0.4231 - val_loss: 1.0835 - val_acc: 0.4150\n",
            "Epoch 28/150 - 0.08s - loss: 1.0788 - acc: 0.4240 - val_loss: 1.0831 - val_acc: 0.4150\n",
            "Epoch 29/150 - 0.09s - loss: 1.0782 - acc: 0.4244 - val_loss: 1.0826 - val_acc: 0.4190\n",
            "Epoch 30/150 - 0.09s - loss: 1.0777 - acc: 0.4260 - val_loss: 1.0822 - val_acc: 0.4211\n",
            "Epoch 31/150 - 0.09s - loss: 1.0771 - acc: 0.4267 - val_loss: 1.0818 - val_acc: 0.4231\n",
            "Epoch 32/150 - 0.10s - loss: 1.0766 - acc: 0.4287 - val_loss: 1.0814 - val_acc: 0.4231\n",
            "Epoch 33/150 - 0.08s - loss: 1.0761 - acc: 0.4289 - val_loss: 1.0809 - val_acc: 0.4271\n",
            "Epoch 34/150 - 0.08s - loss: 1.0756 - acc: 0.4314 - val_loss: 1.0805 - val_acc: 0.4190\n",
            "Epoch 35/150 - 0.09s - loss: 1.0750 - acc: 0.4339 - val_loss: 1.0802 - val_acc: 0.4190\n",
            "Epoch 36/150 - 0.08s - loss: 1.0745 - acc: 0.4341 - val_loss: 1.0797 - val_acc: 0.4231\n",
            "Epoch 37/150 - 0.09s - loss: 1.0740 - acc: 0.4345 - val_loss: 1.0793 - val_acc: 0.4251\n",
            "Epoch 38/150 - 0.09s - loss: 1.0735 - acc: 0.4352 - val_loss: 1.0789 - val_acc: 0.4251\n",
            "Epoch 39/150 - 0.09s - loss: 1.0730 - acc: 0.4359 - val_loss: 1.0785 - val_acc: 0.4251\n",
            "Epoch 40/150 - 0.09s - loss: 1.0725 - acc: 0.4370 - val_loss: 1.0781 - val_acc: 0.4312\n",
            "Epoch 41/150 - 0.09s - loss: 1.0720 - acc: 0.4395 - val_loss: 1.0777 - val_acc: 0.4372\n",
            "Epoch 42/150 - 0.08s - loss: 1.0715 - acc: 0.4420 - val_loss: 1.0773 - val_acc: 0.4372\n",
            "Epoch 43/150 - 0.09s - loss: 1.0710 - acc: 0.4422 - val_loss: 1.0769 - val_acc: 0.4312\n",
            "Epoch 44/150 - 0.10s - loss: 1.0705 - acc: 0.4435 - val_loss: 1.0764 - val_acc: 0.4271\n",
            "Epoch 45/150 - 0.08s - loss: 1.0700 - acc: 0.4456 - val_loss: 1.0760 - val_acc: 0.4271\n",
            "Epoch 46/150 - 0.08s - loss: 1.0695 - acc: 0.4465 - val_loss: 1.0757 - val_acc: 0.4251\n",
            "Epoch 47/150 - 0.09s - loss: 1.0690 - acc: 0.4462 - val_loss: 1.0753 - val_acc: 0.4271\n",
            "Epoch 48/150 - 0.08s - loss: 1.0686 - acc: 0.4483 - val_loss: 1.0750 - val_acc: 0.4332\n",
            "Epoch 49/150 - 0.09s - loss: 1.0681 - acc: 0.4483 - val_loss: 1.0746 - val_acc: 0.4332\n",
            "Epoch 50/150 - 0.12s - loss: 1.0676 - acc: 0.4503 - val_loss: 1.0742 - val_acc: 0.4312\n",
            "Epoch 51/150 - 0.11s - loss: 1.0671 - acc: 0.4507 - val_loss: 1.0739 - val_acc: 0.4312\n",
            "Epoch 52/150 - 0.09s - loss: 1.0667 - acc: 0.4505 - val_loss: 1.0735 - val_acc: 0.4312\n",
            "Epoch 53/150 - 0.10s - loss: 1.0662 - acc: 0.4514 - val_loss: 1.0731 - val_acc: 0.4332\n",
            "Epoch 54/150 - 0.10s - loss: 1.0657 - acc: 0.4532 - val_loss: 1.0729 - val_acc: 0.4312\n",
            "Epoch 55/150 - 0.10s - loss: 1.0653 - acc: 0.4548 - val_loss: 1.0725 - val_acc: 0.4312\n",
            "Epoch 56/150 - 0.10s - loss: 1.0648 - acc: 0.4568 - val_loss: 1.0721 - val_acc: 0.4352\n",
            "Epoch 57/150 - 0.09s - loss: 1.0643 - acc: 0.4570 - val_loss: 1.0717 - val_acc: 0.4393\n",
            "Epoch 58/150 - 0.09s - loss: 1.0639 - acc: 0.4573 - val_loss: 1.0714 - val_acc: 0.4393\n",
            "Epoch 59/150 - 0.09s - loss: 1.0634 - acc: 0.4591 - val_loss: 1.0711 - val_acc: 0.4393\n",
            "Epoch 60/150 - 0.09s - loss: 1.0630 - acc: 0.4606 - val_loss: 1.0708 - val_acc: 0.4352\n",
            "Epoch 61/150 - 0.08s - loss: 1.0625 - acc: 0.4600 - val_loss: 1.0704 - val_acc: 0.4332\n",
            "Epoch 62/150 - 0.10s - loss: 1.0621 - acc: 0.4609 - val_loss: 1.0700 - val_acc: 0.4413\n",
            "Epoch 63/150 - 0.09s - loss: 1.0616 - acc: 0.4613 - val_loss: 1.0697 - val_acc: 0.4393\n",
            "Epoch 64/150 - 0.09s - loss: 1.0611 - acc: 0.4627 - val_loss: 1.0694 - val_acc: 0.4413\n",
            "Epoch 65/150 - 0.09s - loss: 1.0607 - acc: 0.4647 - val_loss: 1.0690 - val_acc: 0.4474\n",
            "Epoch 66/150 - 0.09s - loss: 1.0602 - acc: 0.4636 - val_loss: 1.0686 - val_acc: 0.4474\n",
            "Epoch 67/150 - 0.09s - loss: 1.0598 - acc: 0.4636 - val_loss: 1.0683 - val_acc: 0.4474\n",
            "Epoch 68/150 - 0.10s - loss: 1.0593 - acc: 0.4667 - val_loss: 1.0680 - val_acc: 0.4494\n",
            "Epoch 69/150 - 0.09s - loss: 1.0589 - acc: 0.4647 - val_loss: 1.0676 - val_acc: 0.4474\n",
            "Epoch 70/150 - 0.09s - loss: 1.0584 - acc: 0.4654 - val_loss: 1.0673 - val_acc: 0.4453\n",
            "Epoch 71/150 - 0.09s - loss: 1.0580 - acc: 0.4656 - val_loss: 1.0669 - val_acc: 0.4453\n",
            "Epoch 72/150 - 0.09s - loss: 1.0575 - acc: 0.4667 - val_loss: 1.0666 - val_acc: 0.4474\n",
            "Epoch 73/150 - 0.09s - loss: 1.0571 - acc: 0.4669 - val_loss: 1.0662 - val_acc: 0.4514\n",
            "Epoch 74/150 - 0.10s - loss: 1.0567 - acc: 0.4692 - val_loss: 1.0660 - val_acc: 0.4453\n",
            "Epoch 75/150 - 0.11s - loss: 1.0562 - acc: 0.4690 - val_loss: 1.0657 - val_acc: 0.4413\n",
            "Epoch 76/150 - 0.09s - loss: 1.0558 - acc: 0.4699 - val_loss: 1.0654 - val_acc: 0.4433\n",
            "Epoch 77/150 - 0.10s - loss: 1.0553 - acc: 0.4681 - val_loss: 1.0650 - val_acc: 0.4433\n",
            "Epoch 78/150 - 0.09s - loss: 1.0549 - acc: 0.4699 - val_loss: 1.0647 - val_acc: 0.4494\n",
            "Epoch 79/150 - 0.09s - loss: 1.0544 - acc: 0.4703 - val_loss: 1.0643 - val_acc: 0.4474\n",
            "Epoch 80/150 - 0.09s - loss: 1.0540 - acc: 0.4710 - val_loss: 1.0640 - val_acc: 0.4474\n",
            "Epoch 81/150 - 0.08s - loss: 1.0536 - acc: 0.4712 - val_loss: 1.0636 - val_acc: 0.4474\n",
            "Epoch 82/150 - 0.09s - loss: 1.0531 - acc: 0.4719 - val_loss: 1.0634 - val_acc: 0.4514\n",
            "Epoch 83/150 - 0.09s - loss: 1.0527 - acc: 0.4726 - val_loss: 1.0631 - val_acc: 0.4453\n",
            "Epoch 84/150 - 0.09s - loss: 1.0522 - acc: 0.4728 - val_loss: 1.0628 - val_acc: 0.4514\n",
            "Epoch 85/150 - 0.09s - loss: 1.0518 - acc: 0.4732 - val_loss: 1.0625 - val_acc: 0.4494\n",
            "Epoch 86/150 - 0.09s - loss: 1.0514 - acc: 0.4737 - val_loss: 1.0622 - val_acc: 0.4453\n",
            "Epoch 87/150 - 0.08s - loss: 1.0509 - acc: 0.4735 - val_loss: 1.0620 - val_acc: 0.4534\n",
            "Epoch 88/150 - 0.08s - loss: 1.0505 - acc: 0.4735 - val_loss: 1.0616 - val_acc: 0.4514\n",
            "Epoch 89/150 - 0.09s - loss: 1.0501 - acc: 0.4750 - val_loss: 1.0612 - val_acc: 0.4514\n",
            "Epoch 90/150 - 0.08s - loss: 1.0496 - acc: 0.4744 - val_loss: 1.0609 - val_acc: 0.4534\n",
            "Epoch 91/150 - 0.08s - loss: 1.0492 - acc: 0.4759 - val_loss: 1.0606 - val_acc: 0.4595\n",
            "Epoch 92/150 - 0.09s - loss: 1.0487 - acc: 0.4764 - val_loss: 1.0603 - val_acc: 0.4534\n",
            "Epoch 93/150 - 0.08s - loss: 1.0483 - acc: 0.4744 - val_loss: 1.0599 - val_acc: 0.4534\n",
            "Epoch 94/150 - 0.08s - loss: 1.0479 - acc: 0.4764 - val_loss: 1.0596 - val_acc: 0.4514\n",
            "Epoch 95/150 - 0.09s - loss: 1.0474 - acc: 0.4771 - val_loss: 1.0593 - val_acc: 0.4534\n",
            "Epoch 96/150 - 0.08s - loss: 1.0470 - acc: 0.4766 - val_loss: 1.0590 - val_acc: 0.4575\n",
            "Epoch 97/150 - 0.08s - loss: 1.0466 - acc: 0.4768 - val_loss: 1.0587 - val_acc: 0.4595\n",
            "Epoch 98/150 - 0.10s - loss: 1.0462 - acc: 0.4768 - val_loss: 1.0584 - val_acc: 0.4615\n",
            "Epoch 99/150 - 0.10s - loss: 1.0457 - acc: 0.4766 - val_loss: 1.0581 - val_acc: 0.4636\n",
            "Epoch 100/150 - 0.08s - loss: 1.0453 - acc: 0.4766 - val_loss: 1.0578 - val_acc: 0.4656\n",
            "Epoch 101/150 - 0.09s - loss: 1.0449 - acc: 0.4784 - val_loss: 1.0575 - val_acc: 0.4717\n",
            "Epoch 102/150 - 0.09s - loss: 1.0445 - acc: 0.4764 - val_loss: 1.0572 - val_acc: 0.4696\n",
            "Epoch 103/150 - 0.08s - loss: 1.0440 - acc: 0.4773 - val_loss: 1.0569 - val_acc: 0.4696\n",
            "Epoch 104/150 - 0.09s - loss: 1.0436 - acc: 0.4780 - val_loss: 1.0566 - val_acc: 0.4737\n",
            "Epoch 105/150 - 0.08s - loss: 1.0432 - acc: 0.4771 - val_loss: 1.0563 - val_acc: 0.4717\n",
            "Epoch 106/150 - 0.08s - loss: 1.0428 - acc: 0.4780 - val_loss: 1.0560 - val_acc: 0.4676\n",
            "Epoch 107/150 - 0.09s - loss: 1.0423 - acc: 0.4782 - val_loss: 1.0557 - val_acc: 0.4717\n",
            "Epoch 108/150 - 0.09s - loss: 1.0419 - acc: 0.4777 - val_loss: 1.0554 - val_acc: 0.4737\n",
            "Epoch 109/150 - 0.08s - loss: 1.0415 - acc: 0.4800 - val_loss: 1.0552 - val_acc: 0.4777\n",
            "Epoch 110/150 - 0.09s - loss: 1.0411 - acc: 0.4804 - val_loss: 1.0549 - val_acc: 0.4757\n",
            "Epoch 111/150 - 0.08s - loss: 1.0406 - acc: 0.4807 - val_loss: 1.0546 - val_acc: 0.4777\n",
            "Epoch 112/150 - 0.08s - loss: 1.0402 - acc: 0.4813 - val_loss: 1.0542 - val_acc: 0.4757\n",
            "Epoch 113/150 - 0.09s - loss: 1.0398 - acc: 0.4816 - val_loss: 1.0539 - val_acc: 0.4717\n",
            "Epoch 114/150 - 0.08s - loss: 1.0394 - acc: 0.4784 - val_loss: 1.0535 - val_acc: 0.4737\n",
            "Epoch 115/150 - 0.09s - loss: 1.0390 - acc: 0.4795 - val_loss: 1.0533 - val_acc: 0.4777\n",
            "Epoch 116/150 - 0.10s - loss: 1.0385 - acc: 0.4802 - val_loss: 1.0530 - val_acc: 0.4777\n",
            "Epoch 117/150 - 0.09s - loss: 1.0381 - acc: 0.4834 - val_loss: 1.0528 - val_acc: 0.4818\n",
            "Epoch 118/150 - 0.08s - loss: 1.0377 - acc: 0.4836 - val_loss: 1.0525 - val_acc: 0.4838\n",
            "Epoch 119/150 - 0.09s - loss: 1.0373 - acc: 0.4829 - val_loss: 1.0522 - val_acc: 0.4818\n",
            "Epoch 120/150 - 0.08s - loss: 1.0369 - acc: 0.4856 - val_loss: 1.0519 - val_acc: 0.4798\n",
            "Epoch 121/150 - 0.08s - loss: 1.0365 - acc: 0.4856 - val_loss: 1.0517 - val_acc: 0.4899\n",
            "Epoch 122/150 - 0.10s - loss: 1.0360 - acc: 0.4854 - val_loss: 1.0513 - val_acc: 0.4838\n",
            "Epoch 123/150 - 0.10s - loss: 1.0356 - acc: 0.4872 - val_loss: 1.0511 - val_acc: 0.4818\n",
            "Epoch 124/150 - 0.08s - loss: 1.0352 - acc: 0.4874 - val_loss: 1.0508 - val_acc: 0.4838\n",
            "Epoch 125/150 - 0.09s - loss: 1.0348 - acc: 0.4870 - val_loss: 1.0504 - val_acc: 0.4838\n",
            "Epoch 126/150 - 0.08s - loss: 1.0344 - acc: 0.4867 - val_loss: 1.0501 - val_acc: 0.4818\n",
            "Epoch 127/150 - 0.08s - loss: 1.0340 - acc: 0.4876 - val_loss: 1.0498 - val_acc: 0.4879\n",
            "Epoch 128/150 - 0.09s - loss: 1.0335 - acc: 0.4881 - val_loss: 1.0496 - val_acc: 0.4879\n",
            "Epoch 129/150 - 0.09s - loss: 1.0331 - acc: 0.4890 - val_loss: 1.0494 - val_acc: 0.4939\n",
            "Epoch 130/150 - 0.09s - loss: 1.0327 - acc: 0.4901 - val_loss: 1.0491 - val_acc: 0.4919\n",
            "Epoch 131/150 - 0.09s - loss: 1.0323 - acc: 0.4901 - val_loss: 1.0488 - val_acc: 0.4939\n",
            "Epoch 132/150 - 0.08s - loss: 1.0319 - acc: 0.4899 - val_loss: 1.0484 - val_acc: 0.4939\n",
            "Epoch 133/150 - 0.08s - loss: 1.0315 - acc: 0.4910 - val_loss: 1.0482 - val_acc: 0.4980\n",
            "Epoch 134/150 - 0.09s - loss: 1.0311 - acc: 0.4894 - val_loss: 1.0479 - val_acc: 0.4960\n",
            "Epoch 135/150 - 0.08s - loss: 1.0307 - acc: 0.4903 - val_loss: 1.0475 - val_acc: 0.4899\n",
            "Epoch 136/150 - 0.08s - loss: 1.0302 - acc: 0.4908 - val_loss: 1.0473 - val_acc: 0.4980\n",
            "Epoch 137/150 - 0.09s - loss: 1.0298 - acc: 0.4899 - val_loss: 1.0470 - val_acc: 0.4939\n",
            "Epoch 138/150 - 0.08s - loss: 1.0294 - acc: 0.4901 - val_loss: 1.0467 - val_acc: 0.4939\n",
            "Epoch 139/150 - 0.08s - loss: 1.0290 - acc: 0.4899 - val_loss: 1.0464 - val_acc: 0.4939\n",
            "Epoch 140/150 - 0.09s - loss: 1.0286 - acc: 0.4919 - val_loss: 1.0462 - val_acc: 0.5020\n",
            "Epoch 141/150 - 0.08s - loss: 1.0282 - acc: 0.4933 - val_loss: 1.0460 - val_acc: 0.5061\n",
            "Epoch 142/150 - 0.08s - loss: 1.0278 - acc: 0.4930 - val_loss: 1.0458 - val_acc: 0.5020\n",
            "Epoch 143/150 - 0.09s - loss: 1.0274 - acc: 0.4937 - val_loss: 1.0454 - val_acc: 0.5020\n",
            "Epoch 144/150 - 0.08s - loss: 1.0270 - acc: 0.4939 - val_loss: 1.0451 - val_acc: 0.5020\n",
            "Epoch 145/150 - 0.09s - loss: 1.0266 - acc: 0.4937 - val_loss: 1.0447 - val_acc: 0.5000\n",
            "Epoch 146/150 - 0.10s - loss: 1.0262 - acc: 0.4910 - val_loss: 1.0444 - val_acc: 0.4919\n",
            "Epoch 147/150 - 0.10s - loss: 1.0258 - acc: 0.4933 - val_loss: 1.0442 - val_acc: 0.5000\n",
            "Epoch 148/150 - 0.09s - loss: 1.0254 - acc: 0.4933 - val_loss: 1.0439 - val_acc: 0.4960\n",
            "Epoch 149/150 - 0.10s - loss: 1.0250 - acc: 0.4944 - val_loss: 1.0437 - val_acc: 0.4980\n",
            "Epoch 150/150 - 0.08s - loss: 1.0245 - acc: 0.4960 - val_loss: 1.0434 - val_acc: 0.4980\n",
            "\n",
            "Combination 175/252:\n",
            "Hidden Layers: [128, 64, 32], Activation: tanh, Learning Rate: 0.0001, Batch Size: 32, Epochs: 50\n",
            "Epoch 1/50 - 0.10s - loss: 1.1228 - acc: 0.3394 - val_loss: 1.1206 - val_acc: 0.3360\n",
            "Epoch 2/50 - 0.11s - loss: 1.1194 - acc: 0.3372 - val_loss: 1.1178 - val_acc: 0.3279\n",
            "Epoch 3/50 - 0.10s - loss: 1.1167 - acc: 0.3320 - val_loss: 1.1156 - val_acc: 0.3279\n",
            "Epoch 4/50 - 0.10s - loss: 1.1145 - acc: 0.3300 - val_loss: 1.1140 - val_acc: 0.3219\n",
            "Epoch 5/50 - 0.10s - loss: 1.1128 - acc: 0.3282 - val_loss: 1.1127 - val_acc: 0.3158\n",
            "Epoch 6/50 - 0.10s - loss: 1.1115 - acc: 0.3266 - val_loss: 1.1117 - val_acc: 0.3117\n",
            "Epoch 7/50 - 0.10s - loss: 1.1104 - acc: 0.3250 - val_loss: 1.1108 - val_acc: 0.3097\n",
            "Epoch 8/50 - 0.11s - loss: 1.1094 - acc: 0.3221 - val_loss: 1.1102 - val_acc: 0.3057\n",
            "Epoch 9/50 - 0.11s - loss: 1.1086 - acc: 0.3174 - val_loss: 1.1096 - val_acc: 0.2996\n",
            "Epoch 10/50 - 0.10s - loss: 1.1080 - acc: 0.3158 - val_loss: 1.1091 - val_acc: 0.3036\n",
            "Epoch 11/50 - 0.10s - loss: 1.1074 - acc: 0.3129 - val_loss: 1.1086 - val_acc: 0.3057\n",
            "Epoch 12/50 - 0.10s - loss: 1.1069 - acc: 0.3135 - val_loss: 1.1083 - val_acc: 0.2996\n",
            "Epoch 13/50 - 0.11s - loss: 1.1064 - acc: 0.3138 - val_loss: 1.1079 - val_acc: 0.2996\n",
            "Epoch 14/50 - 0.10s - loss: 1.1059 - acc: 0.3124 - val_loss: 1.1075 - val_acc: 0.2976\n",
            "Epoch 15/50 - 0.10s - loss: 1.1055 - acc: 0.3149 - val_loss: 1.1072 - val_acc: 0.2915\n",
            "Epoch 16/50 - 0.10s - loss: 1.1051 - acc: 0.3160 - val_loss: 1.1069 - val_acc: 0.2935\n",
            "Epoch 17/50 - 0.10s - loss: 1.1047 - acc: 0.3160 - val_loss: 1.1066 - val_acc: 0.2955\n",
            "Epoch 18/50 - 0.11s - loss: 1.1044 - acc: 0.3160 - val_loss: 1.1063 - val_acc: 0.2955\n",
            "Epoch 19/50 - 0.10s - loss: 1.1040 - acc: 0.3169 - val_loss: 1.1060 - val_acc: 0.2915\n",
            "Epoch 20/50 - 0.10s - loss: 1.1037 - acc: 0.3183 - val_loss: 1.1057 - val_acc: 0.2874\n",
            "Epoch 21/50 - 0.10s - loss: 1.1034 - acc: 0.3180 - val_loss: 1.1054 - val_acc: 0.2874\n",
            "Epoch 22/50 - 0.10s - loss: 1.1031 - acc: 0.3192 - val_loss: 1.1051 - val_acc: 0.2874\n",
            "Epoch 23/50 - 0.10s - loss: 1.1027 - acc: 0.3210 - val_loss: 1.1048 - val_acc: 0.2935\n",
            "Epoch 24/50 - 0.10s - loss: 1.1024 - acc: 0.3230 - val_loss: 1.1045 - val_acc: 0.2996\n",
            "Epoch 25/50 - 0.10s - loss: 1.1021 - acc: 0.3239 - val_loss: 1.1043 - val_acc: 0.3016\n",
            "Epoch 26/50 - 0.10s - loss: 1.1018 - acc: 0.3239 - val_loss: 1.1040 - val_acc: 0.3016\n",
            "Epoch 27/50 - 0.10s - loss: 1.1015 - acc: 0.3259 - val_loss: 1.1037 - val_acc: 0.2996\n",
            "Epoch 28/50 - 0.10s - loss: 1.1013 - acc: 0.3277 - val_loss: 1.1034 - val_acc: 0.2955\n",
            "Epoch 29/50 - 0.10s - loss: 1.1010 - acc: 0.3309 - val_loss: 1.1032 - val_acc: 0.2955\n",
            "Epoch 30/50 - 0.11s - loss: 1.1007 - acc: 0.3349 - val_loss: 1.1029 - val_acc: 0.2935\n",
            "Epoch 31/50 - 0.12s - loss: 1.1004 - acc: 0.3367 - val_loss: 1.1026 - val_acc: 0.2996\n",
            "Epoch 32/50 - 0.12s - loss: 1.1001 - acc: 0.3381 - val_loss: 1.1024 - val_acc: 0.2955\n",
            "Epoch 33/50 - 0.10s - loss: 1.0999 - acc: 0.3387 - val_loss: 1.1021 - val_acc: 0.2996\n",
            "Epoch 34/50 - 0.10s - loss: 1.0996 - acc: 0.3432 - val_loss: 1.1018 - val_acc: 0.2976\n",
            "Epoch 35/50 - 0.10s - loss: 1.0993 - acc: 0.3428 - val_loss: 1.1016 - val_acc: 0.2996\n",
            "Epoch 36/50 - 0.10s - loss: 1.0991 - acc: 0.3448 - val_loss: 1.1013 - val_acc: 0.3016\n",
            "Epoch 37/50 - 0.10s - loss: 1.0988 - acc: 0.3477 - val_loss: 1.1011 - val_acc: 0.3036\n",
            "Epoch 38/50 - 0.10s - loss: 1.0985 - acc: 0.3484 - val_loss: 1.1009 - val_acc: 0.3097\n",
            "Epoch 39/50 - 0.10s - loss: 1.0983 - acc: 0.3489 - val_loss: 1.1006 - val_acc: 0.3097\n",
            "Epoch 40/50 - 0.10s - loss: 1.0980 - acc: 0.3500 - val_loss: 1.1004 - val_acc: 0.3138\n",
            "Epoch 41/50 - 0.11s - loss: 1.0978 - acc: 0.3516 - val_loss: 1.1001 - val_acc: 0.3117\n",
            "Epoch 42/50 - 0.10s - loss: 1.0975 - acc: 0.3540 - val_loss: 1.0999 - val_acc: 0.3057\n",
            "Epoch 43/50 - 0.10s - loss: 1.0973 - acc: 0.3572 - val_loss: 1.0997 - val_acc: 0.3138\n",
            "Epoch 44/50 - 0.10s - loss: 1.0970 - acc: 0.3592 - val_loss: 1.0994 - val_acc: 0.3178\n",
            "Epoch 45/50 - 0.10s - loss: 1.0968 - acc: 0.3567 - val_loss: 1.0992 - val_acc: 0.3198\n",
            "Epoch 46/50 - 0.10s - loss: 1.0965 - acc: 0.3587 - val_loss: 1.0990 - val_acc: 0.3239\n",
            "Epoch 47/50 - 0.10s - loss: 1.0963 - acc: 0.3574 - val_loss: 1.0987 - val_acc: 0.3381\n",
            "Epoch 48/50 - 0.10s - loss: 1.0961 - acc: 0.3587 - val_loss: 1.0985 - val_acc: 0.3401\n",
            "Epoch 49/50 - 0.10s - loss: 1.0958 - acc: 0.3603 - val_loss: 1.0983 - val_acc: 0.3421\n",
            "Epoch 50/50 - 0.10s - loss: 1.0956 - acc: 0.3612 - val_loss: 1.0981 - val_acc: 0.3401\n",
            "\n",
            "Combination 176/252:\n",
            "Hidden Layers: [128, 64, 32], Activation: tanh, Learning Rate: 0.0001, Batch Size: 32, Epochs: 100\n",
            "Epoch 1/100 - 0.11s - loss: 1.1077 - acc: 0.3603 - val_loss: 1.1137 - val_acc: 0.3502\n",
            "Epoch 2/100 - 0.10s - loss: 1.1059 - acc: 0.3630 - val_loss: 1.1118 - val_acc: 0.3543\n",
            "Epoch 3/100 - 0.11s - loss: 1.1045 - acc: 0.3639 - val_loss: 1.1101 - val_acc: 0.3462\n",
            "Epoch 4/100 - 0.10s - loss: 1.1033 - acc: 0.3680 - val_loss: 1.1088 - val_acc: 0.3502\n",
            "Epoch 5/100 - 0.10s - loss: 1.1024 - acc: 0.3673 - val_loss: 1.1077 - val_acc: 0.3563\n",
            "Epoch 6/100 - 0.10s - loss: 1.1016 - acc: 0.3680 - val_loss: 1.1067 - val_acc: 0.3664\n",
            "Epoch 7/100 - 0.12s - loss: 1.1009 - acc: 0.3686 - val_loss: 1.1059 - val_acc: 0.3664\n",
            "Epoch 8/100 - 0.10s - loss: 1.1003 - acc: 0.3682 - val_loss: 1.1052 - val_acc: 0.3603\n",
            "Epoch 9/100 - 0.11s - loss: 1.0998 - acc: 0.3673 - val_loss: 1.1046 - val_acc: 0.3623\n",
            "Epoch 10/100 - 0.10s - loss: 1.0993 - acc: 0.3671 - val_loss: 1.1041 - val_acc: 0.3644\n",
            "Epoch 11/100 - 0.11s - loss: 1.0989 - acc: 0.3682 - val_loss: 1.1036 - val_acc: 0.3623\n",
            "Epoch 12/100 - 0.10s - loss: 1.0985 - acc: 0.3693 - val_loss: 1.1031 - val_acc: 0.3684\n",
            "Epoch 13/100 - 0.10s - loss: 1.0982 - acc: 0.3680 - val_loss: 1.1027 - val_acc: 0.3684\n",
            "Epoch 14/100 - 0.10s - loss: 1.0979 - acc: 0.3677 - val_loss: 1.1024 - val_acc: 0.3704\n",
            "Epoch 15/100 - 0.11s - loss: 1.0976 - acc: 0.3695 - val_loss: 1.1020 - val_acc: 0.3704\n",
            "Epoch 16/100 - 0.11s - loss: 1.0973 - acc: 0.3695 - val_loss: 1.1017 - val_acc: 0.3745\n",
            "Epoch 17/100 - 0.10s - loss: 1.0970 - acc: 0.3695 - val_loss: 1.1014 - val_acc: 0.3725\n",
            "Epoch 18/100 - 0.11s - loss: 1.0967 - acc: 0.3702 - val_loss: 1.1011 - val_acc: 0.3745\n",
            "Epoch 19/100 - 0.10s - loss: 1.0965 - acc: 0.3711 - val_loss: 1.1009 - val_acc: 0.3725\n",
            "Epoch 20/100 - 0.11s - loss: 1.0963 - acc: 0.3695 - val_loss: 1.1006 - val_acc: 0.3725\n",
            "Epoch 21/100 - 0.10s - loss: 1.0960 - acc: 0.3709 - val_loss: 1.1004 - val_acc: 0.3704\n",
            "Epoch 22/100 - 0.10s - loss: 1.0958 - acc: 0.3702 - val_loss: 1.1001 - val_acc: 0.3725\n",
            "Epoch 23/100 - 0.10s - loss: 1.0956 - acc: 0.3702 - val_loss: 1.0999 - val_acc: 0.3725\n",
            "Epoch 24/100 - 0.11s - loss: 1.0953 - acc: 0.3704 - val_loss: 1.0997 - val_acc: 0.3725\n",
            "Epoch 25/100 - 0.11s - loss: 1.0951 - acc: 0.3702 - val_loss: 1.0995 - val_acc: 0.3745\n",
            "Epoch 26/100 - 0.11s - loss: 1.0949 - acc: 0.3700 - val_loss: 1.0992 - val_acc: 0.3725\n",
            "Epoch 27/100 - 0.11s - loss: 1.0947 - acc: 0.3718 - val_loss: 1.0990 - val_acc: 0.3704\n",
            "Epoch 28/100 - 0.10s - loss: 1.0945 - acc: 0.3722 - val_loss: 1.0988 - val_acc: 0.3684\n",
            "Epoch 29/100 - 0.10s - loss: 1.0942 - acc: 0.3725 - val_loss: 1.0986 - val_acc: 0.3704\n",
            "Epoch 30/100 - 0.11s - loss: 1.0940 - acc: 0.3718 - val_loss: 1.0984 - val_acc: 0.3765\n",
            "Epoch 31/100 - 0.10s - loss: 1.0938 - acc: 0.3731 - val_loss: 1.0982 - val_acc: 0.3785\n",
            "Epoch 32/100 - 0.10s - loss: 1.0936 - acc: 0.3743 - val_loss: 1.0981 - val_acc: 0.3785\n",
            "Epoch 33/100 - 0.10s - loss: 1.0934 - acc: 0.3758 - val_loss: 1.0979 - val_acc: 0.3826\n",
            "Epoch 34/100 - 0.10s - loss: 1.0932 - acc: 0.3758 - val_loss: 1.0977 - val_acc: 0.3806\n",
            "Epoch 35/100 - 0.12s - loss: 1.0930 - acc: 0.3761 - val_loss: 1.0975 - val_acc: 0.3765\n",
            "Epoch 36/100 - 0.10s - loss: 1.0928 - acc: 0.3761 - val_loss: 1.0973 - val_acc: 0.3765\n",
            "Epoch 37/100 - 0.10s - loss: 1.0926 - acc: 0.3776 - val_loss: 1.0972 - val_acc: 0.3765\n",
            "Epoch 38/100 - 0.10s - loss: 1.0924 - acc: 0.3785 - val_loss: 1.0970 - val_acc: 0.3765\n",
            "Epoch 39/100 - 0.10s - loss: 1.0922 - acc: 0.3792 - val_loss: 1.0968 - val_acc: 0.3806\n",
            "Epoch 40/100 - 0.10s - loss: 1.0920 - acc: 0.3815 - val_loss: 1.0966 - val_acc: 0.3846\n",
            "Epoch 41/100 - 0.11s - loss: 1.0918 - acc: 0.3824 - val_loss: 1.0965 - val_acc: 0.3846\n",
            "Epoch 42/100 - 0.10s - loss: 1.0916 - acc: 0.3830 - val_loss: 1.0963 - val_acc: 0.3826\n",
            "Epoch 43/100 - 0.10s - loss: 1.0915 - acc: 0.3839 - val_loss: 1.0961 - val_acc: 0.3826\n",
            "Epoch 44/100 - 0.10s - loss: 1.0913 - acc: 0.3844 - val_loss: 1.0960 - val_acc: 0.3806\n",
            "Epoch 45/100 - 0.11s - loss: 1.0911 - acc: 0.3848 - val_loss: 1.0958 - val_acc: 0.3806\n",
            "Epoch 46/100 - 0.10s - loss: 1.0909 - acc: 0.3848 - val_loss: 1.0956 - val_acc: 0.3806\n",
            "Epoch 47/100 - 0.14s - loss: 1.0907 - acc: 0.3857 - val_loss: 1.0955 - val_acc: 0.3826\n",
            "Epoch 48/100 - 0.11s - loss: 1.0905 - acc: 0.3862 - val_loss: 1.0953 - val_acc: 0.3866\n",
            "Epoch 49/100 - 0.11s - loss: 1.0903 - acc: 0.3871 - val_loss: 1.0952 - val_acc: 0.3866\n",
            "Epoch 50/100 - 0.10s - loss: 1.0901 - acc: 0.3871 - val_loss: 1.0950 - val_acc: 0.3866\n",
            "Epoch 51/100 - 0.11s - loss: 1.0900 - acc: 0.3887 - val_loss: 1.0948 - val_acc: 0.3846\n",
            "Epoch 52/100 - 0.11s - loss: 1.0898 - acc: 0.3896 - val_loss: 1.0947 - val_acc: 0.3866\n",
            "Epoch 53/100 - 0.11s - loss: 1.0896 - acc: 0.3905 - val_loss: 1.0945 - val_acc: 0.3887\n",
            "Epoch 54/100 - 0.11s - loss: 1.0894 - acc: 0.3907 - val_loss: 1.0944 - val_acc: 0.3887\n",
            "Epoch 55/100 - 0.11s - loss: 1.0892 - acc: 0.3911 - val_loss: 1.0942 - val_acc: 0.3907\n",
            "Epoch 56/100 - 0.12s - loss: 1.0890 - acc: 0.3909 - val_loss: 1.0941 - val_acc: 0.3907\n",
            "Epoch 57/100 - 0.11s - loss: 1.0889 - acc: 0.3925 - val_loss: 1.0939 - val_acc: 0.3887\n",
            "Epoch 58/100 - 0.10s - loss: 1.0887 - acc: 0.3932 - val_loss: 1.0938 - val_acc: 0.3887\n",
            "Epoch 59/100 - 0.10s - loss: 1.0885 - acc: 0.3936 - val_loss: 1.0936 - val_acc: 0.3866\n",
            "Epoch 60/100 - 0.11s - loss: 1.0883 - acc: 0.3947 - val_loss: 1.0935 - val_acc: 0.3866\n",
            "Epoch 61/100 - 0.10s - loss: 1.0882 - acc: 0.3963 - val_loss: 1.0933 - val_acc: 0.3866\n",
            "Epoch 62/100 - 0.11s - loss: 1.0880 - acc: 0.3972 - val_loss: 1.0932 - val_acc: 0.3887\n",
            "Epoch 63/100 - 0.10s - loss: 1.0878 - acc: 0.3974 - val_loss: 1.0930 - val_acc: 0.3887\n",
            "Epoch 64/100 - 0.10s - loss: 1.0876 - acc: 0.3979 - val_loss: 1.0929 - val_acc: 0.3866\n",
            "Epoch 65/100 - 0.13s - loss: 1.0875 - acc: 0.3979 - val_loss: 1.0927 - val_acc: 0.3866\n",
            "Epoch 66/100 - 0.10s - loss: 1.0873 - acc: 0.3979 - val_loss: 1.0926 - val_acc: 0.3826\n",
            "Epoch 67/100 - 0.10s - loss: 1.0871 - acc: 0.3979 - val_loss: 1.0925 - val_acc: 0.3826\n",
            "Epoch 68/100 - 0.10s - loss: 1.0870 - acc: 0.3986 - val_loss: 1.0923 - val_acc: 0.3806\n",
            "Epoch 69/100 - 0.10s - loss: 1.0868 - acc: 0.3992 - val_loss: 1.0922 - val_acc: 0.3826\n",
            "Epoch 70/100 - 0.11s - loss: 1.0866 - acc: 0.3992 - val_loss: 1.0920 - val_acc: 0.3806\n",
            "Epoch 71/100 - 0.11s - loss: 1.0865 - acc: 0.3997 - val_loss: 1.0919 - val_acc: 0.3806\n",
            "Epoch 72/100 - 0.12s - loss: 1.0863 - acc: 0.3999 - val_loss: 1.0918 - val_acc: 0.3806\n",
            "Epoch 73/100 - 0.11s - loss: 1.0861 - acc: 0.4001 - val_loss: 1.0916 - val_acc: 0.3806\n",
            "Epoch 74/100 - 0.10s - loss: 1.0860 - acc: 0.3999 - val_loss: 1.0915 - val_acc: 0.3806\n",
            "Epoch 75/100 - 0.11s - loss: 1.0858 - acc: 0.4004 - val_loss: 1.0913 - val_acc: 0.3785\n",
            "Epoch 76/100 - 0.11s - loss: 1.0856 - acc: 0.4006 - val_loss: 1.0912 - val_acc: 0.3806\n",
            "Epoch 77/100 - 0.11s - loss: 1.0855 - acc: 0.4008 - val_loss: 1.0911 - val_acc: 0.3826\n",
            "Epoch 78/100 - 0.13s - loss: 1.0853 - acc: 0.4010 - val_loss: 1.0909 - val_acc: 0.3806\n",
            "Epoch 79/100 - 0.11s - loss: 1.0851 - acc: 0.4017 - val_loss: 1.0908 - val_acc: 0.3806\n",
            "Epoch 80/100 - 0.11s - loss: 1.0850 - acc: 0.4013 - val_loss: 1.0907 - val_acc: 0.3826\n",
            "Epoch 81/100 - 0.11s - loss: 1.0848 - acc: 0.4013 - val_loss: 1.0905 - val_acc: 0.3846\n",
            "Epoch 82/100 - 0.11s - loss: 1.0847 - acc: 0.4019 - val_loss: 1.0904 - val_acc: 0.3846\n",
            "Epoch 83/100 - 0.10s - loss: 1.0845 - acc: 0.4026 - val_loss: 1.0903 - val_acc: 0.3846\n",
            "Epoch 84/100 - 0.12s - loss: 1.0843 - acc: 0.4035 - val_loss: 1.0901 - val_acc: 0.3846\n",
            "Epoch 85/100 - 0.12s - loss: 1.0842 - acc: 0.4046 - val_loss: 1.0900 - val_acc: 0.3846\n",
            "Epoch 86/100 - 0.11s - loss: 1.0840 - acc: 0.4053 - val_loss: 1.0899 - val_acc: 0.3846\n",
            "Epoch 87/100 - 0.11s - loss: 1.0839 - acc: 0.4055 - val_loss: 1.0897 - val_acc: 0.3866\n",
            "Epoch 88/100 - 0.11s - loss: 1.0837 - acc: 0.4051 - val_loss: 1.0896 - val_acc: 0.3866\n",
            "Epoch 89/100 - 0.12s - loss: 1.0835 - acc: 0.4062 - val_loss: 1.0895 - val_acc: 0.3866\n",
            "Epoch 90/100 - 0.10s - loss: 1.0834 - acc: 0.4064 - val_loss: 1.0894 - val_acc: 0.3846\n",
            "Epoch 91/100 - 0.10s - loss: 1.0832 - acc: 0.4069 - val_loss: 1.0892 - val_acc: 0.3846\n",
            "Epoch 92/100 - 0.10s - loss: 1.0831 - acc: 0.4076 - val_loss: 1.0891 - val_acc: 0.3887\n",
            "Epoch 93/100 - 0.11s - loss: 1.0829 - acc: 0.4071 - val_loss: 1.0890 - val_acc: 0.3887\n",
            "Epoch 94/100 - 0.10s - loss: 1.0828 - acc: 0.4076 - val_loss: 1.0888 - val_acc: 0.3907\n",
            "Epoch 95/100 - 0.10s - loss: 1.0826 - acc: 0.4080 - val_loss: 1.0887 - val_acc: 0.3927\n",
            "Epoch 96/100 - 0.10s - loss: 1.0825 - acc: 0.4082 - val_loss: 1.0886 - val_acc: 0.3927\n",
            "Epoch 97/100 - 0.10s - loss: 1.0823 - acc: 0.4078 - val_loss: 1.0885 - val_acc: 0.3947\n",
            "Epoch 98/100 - 0.11s - loss: 1.0822 - acc: 0.4082 - val_loss: 1.0883 - val_acc: 0.3947\n",
            "Epoch 99/100 - 0.10s - loss: 1.0820 - acc: 0.4089 - val_loss: 1.0882 - val_acc: 0.3968\n",
            "Epoch 100/100 - 0.10s - loss: 1.0819 - acc: 0.4100 - val_loss: 1.0881 - val_acc: 0.4008\n",
            "\n",
            "Combination 177/252:\n",
            "Hidden Layers: [128, 64, 32], Activation: tanh, Learning Rate: 0.0001, Batch Size: 32, Epochs: 150\n",
            "Epoch 1/150 - 0.10s - loss: 1.1056 - acc: 0.3286 - val_loss: 1.1046 - val_acc: 0.3178\n",
            "Epoch 2/150 - 0.11s - loss: 1.1044 - acc: 0.3291 - val_loss: 1.1032 - val_acc: 0.3097\n",
            "Epoch 3/150 - 0.13s - loss: 1.1034 - acc: 0.3333 - val_loss: 1.1020 - val_acc: 0.3097\n",
            "Epoch 4/150 - 0.10s - loss: 1.1025 - acc: 0.3322 - val_loss: 1.1010 - val_acc: 0.3158\n",
            "Epoch 5/150 - 0.11s - loss: 1.1017 - acc: 0.3333 - val_loss: 1.1000 - val_acc: 0.3279\n",
            "Epoch 6/150 - 0.11s - loss: 1.1011 - acc: 0.3336 - val_loss: 1.0992 - val_acc: 0.3239\n",
            "Epoch 7/150 - 0.11s - loss: 1.1004 - acc: 0.3354 - val_loss: 1.0985 - val_acc: 0.3300\n",
            "Epoch 8/150 - 0.13s - loss: 1.0999 - acc: 0.3390 - val_loss: 1.0979 - val_acc: 0.3401\n",
            "Epoch 9/150 - 0.11s - loss: 1.0994 - acc: 0.3394 - val_loss: 1.0973 - val_acc: 0.3482\n",
            "Epoch 10/150 - 0.11s - loss: 1.0989 - acc: 0.3385 - val_loss: 1.0968 - val_acc: 0.3543\n",
            "Epoch 11/150 - 0.11s - loss: 1.0985 - acc: 0.3383 - val_loss: 1.0963 - val_acc: 0.3603\n",
            "Epoch 12/150 - 0.10s - loss: 1.0981 - acc: 0.3381 - val_loss: 1.0959 - val_acc: 0.3583\n",
            "Epoch 13/150 - 0.11s - loss: 1.0978 - acc: 0.3394 - val_loss: 1.0955 - val_acc: 0.3603\n",
            "Epoch 14/150 - 0.10s - loss: 1.0974 - acc: 0.3367 - val_loss: 1.0952 - val_acc: 0.3603\n",
            "Epoch 15/150 - 0.11s - loss: 1.0971 - acc: 0.3387 - val_loss: 1.0948 - val_acc: 0.3603\n",
            "Epoch 16/150 - 0.10s - loss: 1.0968 - acc: 0.3383 - val_loss: 1.0945 - val_acc: 0.3623\n",
            "Epoch 17/150 - 0.10s - loss: 1.0965 - acc: 0.3374 - val_loss: 1.0942 - val_acc: 0.3644\n",
            "Epoch 18/150 - 0.10s - loss: 1.0963 - acc: 0.3358 - val_loss: 1.0939 - val_acc: 0.3603\n",
            "Epoch 19/150 - 0.12s - loss: 1.0960 - acc: 0.3399 - val_loss: 1.0936 - val_acc: 0.3603\n",
            "Epoch 20/150 - 0.10s - loss: 1.0957 - acc: 0.3414 - val_loss: 1.0934 - val_acc: 0.3644\n",
            "Epoch 21/150 - 0.10s - loss: 1.0955 - acc: 0.3439 - val_loss: 1.0931 - val_acc: 0.3684\n",
            "Epoch 22/150 - 0.10s - loss: 1.0953 - acc: 0.3482 - val_loss: 1.0929 - val_acc: 0.3704\n",
            "Epoch 23/150 - 0.10s - loss: 1.0950 - acc: 0.3509 - val_loss: 1.0927 - val_acc: 0.3725\n",
            "Epoch 24/150 - 0.10s - loss: 1.0948 - acc: 0.3522 - val_loss: 1.0925 - val_acc: 0.3745\n",
            "Epoch 25/150 - 0.11s - loss: 1.0946 - acc: 0.3527 - val_loss: 1.0923 - val_acc: 0.3806\n",
            "Epoch 26/150 - 0.10s - loss: 1.0944 - acc: 0.3525 - val_loss: 1.0921 - val_acc: 0.3806\n",
            "Epoch 27/150 - 0.10s - loss: 1.0942 - acc: 0.3538 - val_loss: 1.0919 - val_acc: 0.3866\n",
            "Epoch 28/150 - 0.11s - loss: 1.0939 - acc: 0.3563 - val_loss: 1.0917 - val_acc: 0.3968\n",
            "Epoch 29/150 - 0.10s - loss: 1.0937 - acc: 0.3565 - val_loss: 1.0915 - val_acc: 0.3927\n",
            "Epoch 30/150 - 0.11s - loss: 1.0935 - acc: 0.3583 - val_loss: 1.0913 - val_acc: 0.3907\n",
            "Epoch 31/150 - 0.10s - loss: 1.0933 - acc: 0.3596 - val_loss: 1.0911 - val_acc: 0.3947\n",
            "Epoch 32/150 - 0.10s - loss: 1.0931 - acc: 0.3594 - val_loss: 1.0909 - val_acc: 0.3927\n",
            "Epoch 33/150 - 0.10s - loss: 1.0929 - acc: 0.3617 - val_loss: 1.0908 - val_acc: 0.3927\n",
            "Epoch 34/150 - 0.10s - loss: 1.0927 - acc: 0.3617 - val_loss: 1.0906 - val_acc: 0.3947\n",
            "Epoch 35/150 - 0.11s - loss: 1.0925 - acc: 0.3635 - val_loss: 1.0904 - val_acc: 0.3947\n",
            "Epoch 36/150 - 0.10s - loss: 1.0924 - acc: 0.3641 - val_loss: 1.0902 - val_acc: 0.3846\n",
            "Epoch 37/150 - 0.10s - loss: 1.0922 - acc: 0.3662 - val_loss: 1.0901 - val_acc: 0.3866\n",
            "Epoch 38/150 - 0.10s - loss: 1.0920 - acc: 0.3659 - val_loss: 1.0899 - val_acc: 0.3846\n",
            "Epoch 39/150 - 0.10s - loss: 1.0918 - acc: 0.3662 - val_loss: 1.0898 - val_acc: 0.3887\n",
            "Epoch 40/150 - 0.10s - loss: 1.0916 - acc: 0.3655 - val_loss: 1.0896 - val_acc: 0.3866\n",
            "Epoch 41/150 - 0.13s - loss: 1.0914 - acc: 0.3666 - val_loss: 1.0894 - val_acc: 0.3866\n",
            "Epoch 42/150 - 0.10s - loss: 1.0912 - acc: 0.3677 - val_loss: 1.0893 - val_acc: 0.3887\n",
            "Epoch 43/150 - 0.10s - loss: 1.0911 - acc: 0.3682 - val_loss: 1.0891 - val_acc: 0.3866\n",
            "Epoch 44/150 - 0.10s - loss: 1.0909 - acc: 0.3684 - val_loss: 1.0890 - val_acc: 0.3866\n",
            "Epoch 45/150 - 0.11s - loss: 1.0907 - acc: 0.3691 - val_loss: 1.0888 - val_acc: 0.3866\n",
            "Epoch 46/150 - 0.10s - loss: 1.0905 - acc: 0.3702 - val_loss: 1.0887 - val_acc: 0.3826\n",
            "Epoch 47/150 - 0.11s - loss: 1.0903 - acc: 0.3702 - val_loss: 1.0885 - val_acc: 0.3826\n",
            "Epoch 48/150 - 0.10s - loss: 1.0902 - acc: 0.3709 - val_loss: 1.0883 - val_acc: 0.3826\n",
            "Epoch 49/150 - 0.11s - loss: 1.0900 - acc: 0.3731 - val_loss: 1.0882 - val_acc: 0.3887\n",
            "Epoch 50/150 - 0.10s - loss: 1.0898 - acc: 0.3740 - val_loss: 1.0880 - val_acc: 0.3907\n",
            "Epoch 51/150 - 0.10s - loss: 1.0896 - acc: 0.3752 - val_loss: 1.0879 - val_acc: 0.3907\n",
            "Epoch 52/150 - 0.10s - loss: 1.0895 - acc: 0.3765 - val_loss: 1.0878 - val_acc: 0.3907\n",
            "Epoch 53/150 - 0.11s - loss: 1.0893 - acc: 0.3785 - val_loss: 1.0876 - val_acc: 0.3907\n",
            "Epoch 54/150 - 0.10s - loss: 1.0891 - acc: 0.3797 - val_loss: 1.0875 - val_acc: 0.3887\n",
            "Epoch 55/150 - 0.10s - loss: 1.0889 - acc: 0.3806 - val_loss: 1.0873 - val_acc: 0.3927\n",
            "Epoch 56/150 - 0.10s - loss: 1.0888 - acc: 0.3830 - val_loss: 1.0872 - val_acc: 0.3927\n",
            "Epoch 57/150 - 0.10s - loss: 1.0886 - acc: 0.3839 - val_loss: 1.0870 - val_acc: 0.3907\n",
            "Epoch 58/150 - 0.10s - loss: 1.0884 - acc: 0.3851 - val_loss: 1.0869 - val_acc: 0.3907\n",
            "Epoch 59/150 - 0.12s - loss: 1.0883 - acc: 0.3857 - val_loss: 1.0867 - val_acc: 0.3907\n",
            "Epoch 60/150 - 0.10s - loss: 1.0881 - acc: 0.3862 - val_loss: 1.0866 - val_acc: 0.3927\n",
            "Epoch 61/150 - 0.10s - loss: 1.0879 - acc: 0.3866 - val_loss: 1.0865 - val_acc: 0.3947\n",
            "Epoch 62/150 - 0.10s - loss: 1.0878 - acc: 0.3866 - val_loss: 1.0863 - val_acc: 0.3947\n",
            "Epoch 63/150 - 0.11s - loss: 1.0876 - acc: 0.3880 - val_loss: 1.0862 - val_acc: 0.3947\n",
            "Epoch 64/150 - 0.10s - loss: 1.0874 - acc: 0.3887 - val_loss: 1.0860 - val_acc: 0.3927\n",
            "Epoch 65/150 - 0.10s - loss: 1.0873 - acc: 0.3896 - val_loss: 1.0859 - val_acc: 0.3947\n",
            "Epoch 66/150 - 0.11s - loss: 1.0871 - acc: 0.3900 - val_loss: 1.0858 - val_acc: 0.3927\n",
            "Epoch 67/150 - 0.10s - loss: 1.0869 - acc: 0.3898 - val_loss: 1.0856 - val_acc: 0.3968\n",
            "Epoch 68/150 - 0.10s - loss: 1.0868 - acc: 0.3896 - val_loss: 1.0855 - val_acc: 0.3947\n",
            "Epoch 69/150 - 0.11s - loss: 1.0866 - acc: 0.3905 - val_loss: 1.0853 - val_acc: 0.3988\n",
            "Epoch 70/150 - 0.10s - loss: 1.0865 - acc: 0.3918 - val_loss: 1.0852 - val_acc: 0.4008\n",
            "Epoch 71/150 - 0.10s - loss: 1.0863 - acc: 0.3920 - val_loss: 1.0851 - val_acc: 0.3988\n",
            "Epoch 72/150 - 0.10s - loss: 1.0861 - acc: 0.3923 - val_loss: 1.0849 - val_acc: 0.4008\n",
            "Epoch 73/150 - 0.10s - loss: 1.0860 - acc: 0.3936 - val_loss: 1.0848 - val_acc: 0.4028\n",
            "Epoch 74/150 - 0.10s - loss: 1.0858 - acc: 0.3936 - val_loss: 1.0847 - val_acc: 0.4049\n",
            "Epoch 75/150 - 0.10s - loss: 1.0857 - acc: 0.3938 - val_loss: 1.0845 - val_acc: 0.4028\n",
            "Epoch 76/150 - 0.10s - loss: 1.0855 - acc: 0.3963 - val_loss: 1.0844 - val_acc: 0.4028\n",
            "Epoch 77/150 - 0.10s - loss: 1.0853 - acc: 0.3963 - val_loss: 1.0843 - val_acc: 0.4089\n",
            "Epoch 78/150 - 0.10s - loss: 1.0852 - acc: 0.3968 - val_loss: 1.0841 - val_acc: 0.4130\n",
            "Epoch 79/150 - 0.10s - loss: 1.0850 - acc: 0.3952 - val_loss: 1.0840 - val_acc: 0.4130\n",
            "Epoch 80/150 - 0.10s - loss: 1.0849 - acc: 0.3956 - val_loss: 1.0839 - val_acc: 0.4150\n",
            "Epoch 81/150 - 0.12s - loss: 1.0847 - acc: 0.3952 - val_loss: 1.0838 - val_acc: 0.4150\n",
            "Epoch 82/150 - 0.10s - loss: 1.0846 - acc: 0.3950 - val_loss: 1.0836 - val_acc: 0.4190\n",
            "Epoch 83/150 - 0.10s - loss: 1.0844 - acc: 0.3954 - val_loss: 1.0835 - val_acc: 0.4211\n",
            "Epoch 84/150 - 0.10s - loss: 1.0842 - acc: 0.3970 - val_loss: 1.0834 - val_acc: 0.4231\n",
            "Epoch 85/150 - 0.10s - loss: 1.0841 - acc: 0.3965 - val_loss: 1.0832 - val_acc: 0.4291\n",
            "Epoch 86/150 - 0.11s - loss: 1.0839 - acc: 0.3977 - val_loss: 1.0831 - val_acc: 0.4312\n",
            "Epoch 87/150 - 0.10s - loss: 1.0838 - acc: 0.3979 - val_loss: 1.0830 - val_acc: 0.4312\n",
            "Epoch 88/150 - 0.10s - loss: 1.0836 - acc: 0.3997 - val_loss: 1.0829 - val_acc: 0.4291\n",
            "Epoch 89/150 - 0.10s - loss: 1.0835 - acc: 0.4004 - val_loss: 1.0827 - val_acc: 0.4332\n",
            "Epoch 90/150 - 0.10s - loss: 1.0833 - acc: 0.4010 - val_loss: 1.0826 - val_acc: 0.4332\n",
            "Epoch 91/150 - 0.10s - loss: 1.0832 - acc: 0.4026 - val_loss: 1.0825 - val_acc: 0.4332\n",
            "Epoch 92/150 - 0.11s - loss: 1.0830 - acc: 0.4031 - val_loss: 1.0824 - val_acc: 0.4372\n",
            "Epoch 93/150 - 0.10s - loss: 1.0829 - acc: 0.4042 - val_loss: 1.0822 - val_acc: 0.4393\n",
            "Epoch 94/150 - 0.10s - loss: 1.0827 - acc: 0.4042 - val_loss: 1.0821 - val_acc: 0.4372\n",
            "Epoch 95/150 - 0.10s - loss: 1.0826 - acc: 0.4058 - val_loss: 1.0820 - val_acc: 0.4393\n",
            "Epoch 96/150 - 0.10s - loss: 1.0824 - acc: 0.4071 - val_loss: 1.0819 - val_acc: 0.4413\n",
            "Epoch 97/150 - 0.11s - loss: 1.0823 - acc: 0.4067 - val_loss: 1.0817 - val_acc: 0.4372\n",
            "Epoch 98/150 - 0.10s - loss: 1.0821 - acc: 0.4064 - val_loss: 1.0816 - val_acc: 0.4352\n",
            "Epoch 99/150 - 0.10s - loss: 1.0820 - acc: 0.4067 - val_loss: 1.0815 - val_acc: 0.4332\n",
            "Epoch 100/150 - 0.10s - loss: 1.0818 - acc: 0.4069 - val_loss: 1.0814 - val_acc: 0.4372\n",
            "Epoch 101/150 - 0.12s - loss: 1.0817 - acc: 0.4085 - val_loss: 1.0813 - val_acc: 0.4372\n",
            "Epoch 102/150 - 0.10s - loss: 1.0816 - acc: 0.4098 - val_loss: 1.0811 - val_acc: 0.4413\n",
            "Epoch 103/150 - 0.11s - loss: 1.0814 - acc: 0.4114 - val_loss: 1.0810 - val_acc: 0.4393\n",
            "Epoch 104/150 - 0.12s - loss: 1.0813 - acc: 0.4125 - val_loss: 1.0809 - val_acc: 0.4393\n",
            "Epoch 105/150 - 0.11s - loss: 1.0811 - acc: 0.4134 - val_loss: 1.0808 - val_acc: 0.4393\n",
            "Epoch 106/150 - 0.11s - loss: 1.0810 - acc: 0.4141 - val_loss: 1.0807 - val_acc: 0.4372\n",
            "Epoch 107/150 - 0.10s - loss: 1.0808 - acc: 0.4159 - val_loss: 1.0805 - val_acc: 0.4332\n",
            "Epoch 108/150 - 0.10s - loss: 1.0807 - acc: 0.4159 - val_loss: 1.0804 - val_acc: 0.4312\n",
            "Epoch 109/150 - 0.10s - loss: 1.0806 - acc: 0.4159 - val_loss: 1.0803 - val_acc: 0.4291\n",
            "Epoch 110/150 - 0.10s - loss: 1.0804 - acc: 0.4163 - val_loss: 1.0802 - val_acc: 0.4312\n",
            "Epoch 111/150 - 0.11s - loss: 1.0803 - acc: 0.4161 - val_loss: 1.0801 - val_acc: 0.4291\n",
            "Epoch 112/150 - 0.10s - loss: 1.0801 - acc: 0.4177 - val_loss: 1.0800 - val_acc: 0.4271\n",
            "Epoch 113/150 - 0.10s - loss: 1.0800 - acc: 0.4175 - val_loss: 1.0799 - val_acc: 0.4251\n",
            "Epoch 114/150 - 0.11s - loss: 1.0798 - acc: 0.4172 - val_loss: 1.0797 - val_acc: 0.4251\n",
            "Epoch 115/150 - 0.11s - loss: 1.0797 - acc: 0.4168 - val_loss: 1.0796 - val_acc: 0.4291\n",
            "Epoch 116/150 - 0.11s - loss: 1.0796 - acc: 0.4177 - val_loss: 1.0795 - val_acc: 0.4291\n",
            "Epoch 117/150 - 0.11s - loss: 1.0794 - acc: 0.4188 - val_loss: 1.0794 - val_acc: 0.4312\n",
            "Epoch 118/150 - 0.11s - loss: 1.0793 - acc: 0.4190 - val_loss: 1.0793 - val_acc: 0.4312\n",
            "Epoch 119/150 - 0.11s - loss: 1.0792 - acc: 0.4181 - val_loss: 1.0792 - val_acc: 0.4332\n",
            "Epoch 120/150 - 0.11s - loss: 1.0790 - acc: 0.4181 - val_loss: 1.0791 - val_acc: 0.4332\n",
            "Epoch 121/150 - 0.13s - loss: 1.0789 - acc: 0.4179 - val_loss: 1.0789 - val_acc: 0.4332\n",
            "Epoch 122/150 - 0.10s - loss: 1.0787 - acc: 0.4181 - val_loss: 1.0788 - val_acc: 0.4332\n",
            "Epoch 123/150 - 0.11s - loss: 1.0786 - acc: 0.4193 - val_loss: 1.0787 - val_acc: 0.4332\n",
            "Epoch 124/150 - 0.10s - loss: 1.0785 - acc: 0.4202 - val_loss: 1.0786 - val_acc: 0.4332\n",
            "Epoch 125/150 - 0.11s - loss: 1.0783 - acc: 0.4202 - val_loss: 1.0785 - val_acc: 0.4332\n",
            "Epoch 126/150 - 0.10s - loss: 1.0782 - acc: 0.4204 - val_loss: 1.0784 - val_acc: 0.4312\n",
            "Epoch 127/150 - 0.11s - loss: 1.0781 - acc: 0.4202 - val_loss: 1.0783 - val_acc: 0.4312\n",
            "Epoch 128/150 - 0.10s - loss: 1.0779 - acc: 0.4197 - val_loss: 1.0782 - val_acc: 0.4312\n",
            "Epoch 129/150 - 0.11s - loss: 1.0778 - acc: 0.4204 - val_loss: 1.0781 - val_acc: 0.4312\n",
            "Epoch 130/150 - 0.10s - loss: 1.0777 - acc: 0.4208 - val_loss: 1.0780 - val_acc: 0.4332\n",
            "Epoch 131/150 - 0.10s - loss: 1.0775 - acc: 0.4204 - val_loss: 1.0779 - val_acc: 0.4332\n",
            "Epoch 132/150 - 0.10s - loss: 1.0774 - acc: 0.4208 - val_loss: 1.0777 - val_acc: 0.4291\n",
            "Epoch 133/150 - 0.10s - loss: 1.0773 - acc: 0.4208 - val_loss: 1.0776 - val_acc: 0.4291\n",
            "Epoch 134/150 - 0.11s - loss: 1.0771 - acc: 0.4217 - val_loss: 1.0775 - val_acc: 0.4271\n",
            "Epoch 135/150 - 0.10s - loss: 1.0770 - acc: 0.4215 - val_loss: 1.0774 - val_acc: 0.4271\n",
            "Epoch 136/150 - 0.10s - loss: 1.0769 - acc: 0.4213 - val_loss: 1.0773 - val_acc: 0.4312\n",
            "Epoch 137/150 - 0.10s - loss: 1.0767 - acc: 0.4204 - val_loss: 1.0772 - val_acc: 0.4332\n",
            "Epoch 138/150 - 0.10s - loss: 1.0766 - acc: 0.4199 - val_loss: 1.0771 - val_acc: 0.4352\n",
            "Epoch 139/150 - 0.12s - loss: 1.0765 - acc: 0.4193 - val_loss: 1.0770 - val_acc: 0.4352\n",
            "Epoch 140/150 - 0.10s - loss: 1.0763 - acc: 0.4197 - val_loss: 1.0769 - val_acc: 0.4332\n",
            "Epoch 141/150 - 0.10s - loss: 1.0762 - acc: 0.4204 - val_loss: 1.0768 - val_acc: 0.4312\n",
            "Epoch 142/150 - 0.10s - loss: 1.0761 - acc: 0.4208 - val_loss: 1.0767 - val_acc: 0.4312\n",
            "Epoch 143/150 - 0.10s - loss: 1.0760 - acc: 0.4211 - val_loss: 1.0766 - val_acc: 0.4332\n",
            "Epoch 144/150 - 0.11s - loss: 1.0758 - acc: 0.4215 - val_loss: 1.0765 - val_acc: 0.4352\n",
            "Epoch 145/150 - 0.10s - loss: 1.0757 - acc: 0.4213 - val_loss: 1.0764 - val_acc: 0.4352\n",
            "Epoch 146/150 - 0.10s - loss: 1.0756 - acc: 0.4222 - val_loss: 1.0763 - val_acc: 0.4352\n",
            "Epoch 147/150 - 0.10s - loss: 1.0755 - acc: 0.4229 - val_loss: 1.0762 - val_acc: 0.4352\n",
            "Epoch 148/150 - 0.11s - loss: 1.0753 - acc: 0.4226 - val_loss: 1.0761 - val_acc: 0.4372\n",
            "Epoch 149/150 - 0.10s - loss: 1.0752 - acc: 0.4226 - val_loss: 1.0760 - val_acc: 0.4352\n",
            "Epoch 150/150 - 0.12s - loss: 1.0751 - acc: 0.4224 - val_loss: 1.0759 - val_acc: 0.4352\n",
            "\n",
            "Combination 178/252:\n",
            "Hidden Layers: [128, 64, 32], Activation: tanh, Learning Rate: 0.0001, Batch Size: 64, Epochs: 50\n",
            "Epoch 1/50 - 0.09s - loss: 1.1101 - acc: 0.3475 - val_loss: 1.1073 - val_acc: 0.3583\n",
            "Epoch 2/50 - 0.09s - loss: 1.1088 - acc: 0.3495 - val_loss: 1.1063 - val_acc: 0.3543\n",
            "Epoch 3/50 - 0.09s - loss: 1.1076 - acc: 0.3513 - val_loss: 1.1053 - val_acc: 0.3543\n",
            "Epoch 4/50 - 0.10s - loss: 1.1066 - acc: 0.3502 - val_loss: 1.1045 - val_acc: 0.3502\n",
            "Epoch 5/50 - 0.09s - loss: 1.1057 - acc: 0.3511 - val_loss: 1.1038 - val_acc: 0.3502\n",
            "Epoch 6/50 - 0.09s - loss: 1.1048 - acc: 0.3516 - val_loss: 1.1032 - val_acc: 0.3522\n",
            "Epoch 7/50 - 0.09s - loss: 1.1041 - acc: 0.3525 - val_loss: 1.1027 - val_acc: 0.3502\n",
            "Epoch 8/50 - 0.09s - loss: 1.1034 - acc: 0.3518 - val_loss: 1.1022 - val_acc: 0.3563\n",
            "Epoch 9/50 - 0.09s - loss: 1.1028 - acc: 0.3504 - val_loss: 1.1018 - val_acc: 0.3563\n",
            "Epoch 10/50 - 0.12s - loss: 1.1023 - acc: 0.3516 - val_loss: 1.1014 - val_acc: 0.3563\n",
            "Epoch 11/50 - 0.09s - loss: 1.1018 - acc: 0.3513 - val_loss: 1.1011 - val_acc: 0.3543\n",
            "Epoch 12/50 - 0.09s - loss: 1.1014 - acc: 0.3507 - val_loss: 1.1008 - val_acc: 0.3522\n",
            "Epoch 13/50 - 0.09s - loss: 1.1009 - acc: 0.3511 - val_loss: 1.1005 - val_acc: 0.3583\n",
            "Epoch 14/50 - 0.09s - loss: 1.1006 - acc: 0.3507 - val_loss: 1.1002 - val_acc: 0.3543\n",
            "Epoch 15/50 - 0.09s - loss: 1.1002 - acc: 0.3493 - val_loss: 1.1000 - val_acc: 0.3543\n",
            "Epoch 16/50 - 0.10s - loss: 1.0999 - acc: 0.3453 - val_loss: 1.0998 - val_acc: 0.3563\n",
            "Epoch 17/50 - 0.09s - loss: 1.0996 - acc: 0.3450 - val_loss: 1.0996 - val_acc: 0.3583\n",
            "Epoch 18/50 - 0.09s - loss: 1.0993 - acc: 0.3439 - val_loss: 1.0994 - val_acc: 0.3543\n",
            "Epoch 19/50 - 0.09s - loss: 1.0990 - acc: 0.3450 - val_loss: 1.0993 - val_acc: 0.3583\n",
            "Epoch 20/50 - 0.09s - loss: 1.0988 - acc: 0.3477 - val_loss: 1.0992 - val_acc: 0.3603\n",
            "Epoch 21/50 - 0.09s - loss: 1.0986 - acc: 0.3489 - val_loss: 1.0990 - val_acc: 0.3664\n",
            "Epoch 22/50 - 0.10s - loss: 1.0983 - acc: 0.3486 - val_loss: 1.0989 - val_acc: 0.3623\n",
            "Epoch 23/50 - 0.09s - loss: 1.0981 - acc: 0.3509 - val_loss: 1.0988 - val_acc: 0.3583\n",
            "Epoch 24/50 - 0.09s - loss: 1.0979 - acc: 0.3491 - val_loss: 1.0986 - val_acc: 0.3543\n",
            "Epoch 25/50 - 0.09s - loss: 1.0977 - acc: 0.3486 - val_loss: 1.0985 - val_acc: 0.3543\n",
            "Epoch 26/50 - 0.09s - loss: 1.0975 - acc: 0.3498 - val_loss: 1.0984 - val_acc: 0.3502\n",
            "Epoch 27/50 - 0.09s - loss: 1.0974 - acc: 0.3482 - val_loss: 1.0983 - val_acc: 0.3502\n",
            "Epoch 28/50 - 0.10s - loss: 1.0972 - acc: 0.3482 - val_loss: 1.0982 - val_acc: 0.3522\n",
            "Epoch 29/50 - 0.09s - loss: 1.0970 - acc: 0.3491 - val_loss: 1.0981 - val_acc: 0.3522\n",
            "Epoch 30/50 - 0.09s - loss: 1.0969 - acc: 0.3495 - val_loss: 1.0981 - val_acc: 0.3502\n",
            "Epoch 31/50 - 0.09s - loss: 1.0967 - acc: 0.3493 - val_loss: 1.0980 - val_acc: 0.3502\n",
            "Epoch 32/50 - 0.09s - loss: 1.0966 - acc: 0.3493 - val_loss: 1.0979 - val_acc: 0.3502\n",
            "Epoch 33/50 - 0.09s - loss: 1.0964 - acc: 0.3498 - val_loss: 1.0978 - val_acc: 0.3543\n",
            "Epoch 34/50 - 0.10s - loss: 1.0963 - acc: 0.3486 - val_loss: 1.0977 - val_acc: 0.3543\n",
            "Epoch 35/50 - 0.09s - loss: 1.0961 - acc: 0.3486 - val_loss: 1.0976 - val_acc: 0.3563\n",
            "Epoch 36/50 - 0.09s - loss: 1.0960 - acc: 0.3504 - val_loss: 1.0976 - val_acc: 0.3563\n",
            "Epoch 37/50 - 0.09s - loss: 1.0958 - acc: 0.3513 - val_loss: 1.0975 - val_acc: 0.3563\n",
            "Epoch 38/50 - 0.09s - loss: 1.0957 - acc: 0.3513 - val_loss: 1.0974 - val_acc: 0.3563\n",
            "Epoch 39/50 - 0.09s - loss: 1.0956 - acc: 0.3534 - val_loss: 1.0973 - val_acc: 0.3583\n",
            "Epoch 40/50 - 0.09s - loss: 1.0955 - acc: 0.3513 - val_loss: 1.0972 - val_acc: 0.3603\n",
            "Epoch 41/50 - 0.09s - loss: 1.0953 - acc: 0.3518 - val_loss: 1.0972 - val_acc: 0.3603\n",
            "Epoch 42/50 - 0.09s - loss: 1.0952 - acc: 0.3534 - val_loss: 1.0971 - val_acc: 0.3623\n",
            "Epoch 43/50 - 0.09s - loss: 1.0951 - acc: 0.3538 - val_loss: 1.0970 - val_acc: 0.3603\n",
            "Epoch 44/50 - 0.09s - loss: 1.0950 - acc: 0.3536 - val_loss: 1.0970 - val_acc: 0.3623\n",
            "Epoch 45/50 - 0.08s - loss: 1.0948 - acc: 0.3549 - val_loss: 1.0969 - val_acc: 0.3603\n",
            "Epoch 46/50 - 0.09s - loss: 1.0947 - acc: 0.3547 - val_loss: 1.0968 - val_acc: 0.3603\n",
            "Epoch 47/50 - 0.09s - loss: 1.0946 - acc: 0.3547 - val_loss: 1.0967 - val_acc: 0.3623\n",
            "Epoch 48/50 - 0.10s - loss: 1.0945 - acc: 0.3545 - val_loss: 1.0967 - val_acc: 0.3644\n",
            "Epoch 49/50 - 0.09s - loss: 1.0944 - acc: 0.3556 - val_loss: 1.0966 - val_acc: 0.3664\n",
            "Epoch 50/50 - 0.09s - loss: 1.0943 - acc: 0.3572 - val_loss: 1.0965 - val_acc: 0.3664\n",
            "\n",
            "Combination 179/252:\n",
            "Hidden Layers: [128, 64, 32], Activation: tanh, Learning Rate: 0.0001, Batch Size: 64, Epochs: 100\n",
            "Epoch 1/100 - 0.09s - loss: 1.1143 - acc: 0.3201 - val_loss: 1.1016 - val_acc: 0.3785\n",
            "Epoch 2/100 - 0.10s - loss: 1.1136 - acc: 0.3205 - val_loss: 1.1011 - val_acc: 0.3785\n",
            "Epoch 3/100 - 0.10s - loss: 1.1129 - acc: 0.3194 - val_loss: 1.1006 - val_acc: 0.3785\n",
            "Epoch 4/100 - 0.10s - loss: 1.1123 - acc: 0.3171 - val_loss: 1.1001 - val_acc: 0.3806\n",
            "Epoch 5/100 - 0.10s - loss: 1.1118 - acc: 0.3183 - val_loss: 1.0997 - val_acc: 0.3826\n",
            "Epoch 6/100 - 0.10s - loss: 1.1113 - acc: 0.3194 - val_loss: 1.0994 - val_acc: 0.3866\n",
            "Epoch 7/100 - 0.10s - loss: 1.1108 - acc: 0.3194 - val_loss: 1.0991 - val_acc: 0.3846\n",
            "Epoch 8/100 - 0.12s - loss: 1.1104 - acc: 0.3216 - val_loss: 1.0988 - val_acc: 0.3887\n",
            "Epoch 9/100 - 0.10s - loss: 1.1100 - acc: 0.3239 - val_loss: 1.0985 - val_acc: 0.3927\n",
            "Epoch 10/100 - 0.10s - loss: 1.1096 - acc: 0.3268 - val_loss: 1.0983 - val_acc: 0.3907\n",
            "Epoch 11/100 - 0.10s - loss: 1.1092 - acc: 0.3284 - val_loss: 1.0980 - val_acc: 0.3907\n",
            "Epoch 12/100 - 0.10s - loss: 1.1089 - acc: 0.3304 - val_loss: 1.0978 - val_acc: 0.3866\n",
            "Epoch 13/100 - 0.10s - loss: 1.1086 - acc: 0.3288 - val_loss: 1.0976 - val_acc: 0.3826\n",
            "Epoch 14/100 - 0.12s - loss: 1.1083 - acc: 0.3273 - val_loss: 1.0974 - val_acc: 0.3846\n",
            "Epoch 15/100 - 0.10s - loss: 1.1080 - acc: 0.3261 - val_loss: 1.0973 - val_acc: 0.3846\n",
            "Epoch 16/100 - 0.09s - loss: 1.1078 - acc: 0.3264 - val_loss: 1.0971 - val_acc: 0.3846\n",
            "Epoch 17/100 - 0.11s - loss: 1.1075 - acc: 0.3246 - val_loss: 1.0970 - val_acc: 0.3826\n",
            "Epoch 18/100 - 0.10s - loss: 1.1073 - acc: 0.3268 - val_loss: 1.0968 - val_acc: 0.3806\n",
            "Epoch 19/100 - 0.10s - loss: 1.1071 - acc: 0.3270 - val_loss: 1.0967 - val_acc: 0.3785\n",
            "Epoch 20/100 - 0.11s - loss: 1.1069 - acc: 0.3250 - val_loss: 1.0965 - val_acc: 0.3765\n",
            "Epoch 21/100 - 0.10s - loss: 1.1066 - acc: 0.3248 - val_loss: 1.0964 - val_acc: 0.3725\n",
            "Epoch 22/100 - 0.10s - loss: 1.1064 - acc: 0.3250 - val_loss: 1.0963 - val_acc: 0.3765\n",
            "Epoch 23/100 - 0.10s - loss: 1.1063 - acc: 0.3252 - val_loss: 1.0962 - val_acc: 0.3725\n",
            "Epoch 24/100 - 0.10s - loss: 1.1061 - acc: 0.3264 - val_loss: 1.0961 - val_acc: 0.3745\n",
            "Epoch 25/100 - 0.10s - loss: 1.1059 - acc: 0.3246 - val_loss: 1.0960 - val_acc: 0.3745\n",
            "Epoch 26/100 - 0.10s - loss: 1.1057 - acc: 0.3264 - val_loss: 1.0958 - val_acc: 0.3704\n",
            "Epoch 27/100 - 0.10s - loss: 1.1055 - acc: 0.3282 - val_loss: 1.0957 - val_acc: 0.3725\n",
            "Epoch 28/100 - 0.10s - loss: 1.1054 - acc: 0.3291 - val_loss: 1.0956 - val_acc: 0.3704\n",
            "Epoch 29/100 - 0.10s - loss: 1.1052 - acc: 0.3311 - val_loss: 1.0955 - val_acc: 0.3664\n",
            "Epoch 30/100 - 0.10s - loss: 1.1050 - acc: 0.3306 - val_loss: 1.0954 - val_acc: 0.3684\n",
            "Epoch 31/100 - 0.10s - loss: 1.1049 - acc: 0.3309 - val_loss: 1.0953 - val_acc: 0.3664\n",
            "Epoch 32/100 - 0.12s - loss: 1.1047 - acc: 0.3304 - val_loss: 1.0952 - val_acc: 0.3684\n",
            "Epoch 33/100 - 0.10s - loss: 1.1046 - acc: 0.3311 - val_loss: 1.0951 - val_acc: 0.3623\n",
            "Epoch 34/100 - 0.10s - loss: 1.1044 - acc: 0.3300 - val_loss: 1.0950 - val_acc: 0.3623\n",
            "Epoch 35/100 - 0.11s - loss: 1.1043 - acc: 0.3293 - val_loss: 1.0949 - val_acc: 0.3644\n",
            "Epoch 36/100 - 0.11s - loss: 1.1041 - acc: 0.3284 - val_loss: 1.0948 - val_acc: 0.3623\n",
            "Epoch 37/100 - 0.10s - loss: 1.1040 - acc: 0.3288 - val_loss: 1.0947 - val_acc: 0.3603\n",
            "Epoch 38/100 - 0.11s - loss: 1.1038 - acc: 0.3306 - val_loss: 1.0946 - val_acc: 0.3623\n",
            "Epoch 39/100 - 0.10s - loss: 1.1037 - acc: 0.3295 - val_loss: 1.0946 - val_acc: 0.3623\n",
            "Epoch 40/100 - 0.10s - loss: 1.1035 - acc: 0.3309 - val_loss: 1.0945 - val_acc: 0.3644\n",
            "Epoch 41/100 - 0.10s - loss: 1.1034 - acc: 0.3311 - val_loss: 1.0944 - val_acc: 0.3644\n",
            "Epoch 42/100 - 0.10s - loss: 1.1033 - acc: 0.3320 - val_loss: 1.0943 - val_acc: 0.3664\n",
            "Epoch 43/100 - 0.10s - loss: 1.1031 - acc: 0.3336 - val_loss: 1.0942 - val_acc: 0.3684\n",
            "Epoch 44/100 - 0.11s - loss: 1.1030 - acc: 0.3349 - val_loss: 1.0941 - val_acc: 0.3684\n",
            "Epoch 45/100 - 0.10s - loss: 1.1029 - acc: 0.3342 - val_loss: 1.0940 - val_acc: 0.3684\n",
            "Epoch 46/100 - 0.10s - loss: 1.1027 - acc: 0.3365 - val_loss: 1.0939 - val_acc: 0.3664\n",
            "Epoch 47/100 - 0.12s - loss: 1.1026 - acc: 0.3374 - val_loss: 1.0938 - val_acc: 0.3704\n",
            "Epoch 48/100 - 0.10s - loss: 1.1025 - acc: 0.3372 - val_loss: 1.0937 - val_acc: 0.3745\n",
            "Epoch 49/100 - 0.10s - loss: 1.1023 - acc: 0.3372 - val_loss: 1.0936 - val_acc: 0.3745\n",
            "Epoch 50/100 - 0.11s - loss: 1.1022 - acc: 0.3378 - val_loss: 1.0935 - val_acc: 0.3745\n",
            "Epoch 51/100 - 0.10s - loss: 1.1021 - acc: 0.3396 - val_loss: 1.0934 - val_acc: 0.3725\n",
            "Epoch 52/100 - 0.10s - loss: 1.1019 - acc: 0.3403 - val_loss: 1.0934 - val_acc: 0.3745\n",
            "Epoch 53/100 - 0.10s - loss: 1.1018 - acc: 0.3408 - val_loss: 1.0933 - val_acc: 0.3725\n",
            "Epoch 54/100 - 0.10s - loss: 1.1017 - acc: 0.3414 - val_loss: 1.0932 - val_acc: 0.3765\n",
            "Epoch 55/100 - 0.10s - loss: 1.1016 - acc: 0.3414 - val_loss: 1.0931 - val_acc: 0.3765\n",
            "Epoch 56/100 - 0.11s - loss: 1.1014 - acc: 0.3417 - val_loss: 1.0930 - val_acc: 0.3745\n",
            "Epoch 57/100 - 0.12s - loss: 1.1013 - acc: 0.3417 - val_loss: 1.0929 - val_acc: 0.3745\n",
            "Epoch 58/100 - 0.10s - loss: 1.1012 - acc: 0.3414 - val_loss: 1.0928 - val_acc: 0.3745\n",
            "Epoch 59/100 - 0.11s - loss: 1.1011 - acc: 0.3421 - val_loss: 1.0927 - val_acc: 0.3745\n",
            "Epoch 60/100 - 0.10s - loss: 1.1009 - acc: 0.3421 - val_loss: 1.0926 - val_acc: 0.3745\n",
            "Epoch 61/100 - 0.10s - loss: 1.1008 - acc: 0.3423 - val_loss: 1.0925 - val_acc: 0.3745\n",
            "Epoch 62/100 - 0.10s - loss: 1.1007 - acc: 0.3432 - val_loss: 1.0924 - val_acc: 0.3745\n",
            "Epoch 63/100 - 0.10s - loss: 1.1006 - acc: 0.3437 - val_loss: 1.0923 - val_acc: 0.3765\n",
            "Epoch 64/100 - 0.10s - loss: 1.1005 - acc: 0.3435 - val_loss: 1.0923 - val_acc: 0.3785\n",
            "Epoch 65/100 - 0.10s - loss: 1.1003 - acc: 0.3439 - val_loss: 1.0922 - val_acc: 0.3826\n",
            "Epoch 66/100 - 0.10s - loss: 1.1002 - acc: 0.3439 - val_loss: 1.0921 - val_acc: 0.3826\n",
            "Epoch 67/100 - 0.10s - loss: 1.1001 - acc: 0.3441 - val_loss: 1.0920 - val_acc: 0.3826\n",
            "Epoch 68/100 - 0.10s - loss: 1.1000 - acc: 0.3448 - val_loss: 1.0919 - val_acc: 0.3806\n",
            "Epoch 69/100 - 0.10s - loss: 1.0999 - acc: 0.3446 - val_loss: 1.0918 - val_acc: 0.3826\n",
            "Epoch 70/100 - 0.10s - loss: 1.0997 - acc: 0.3453 - val_loss: 1.0917 - val_acc: 0.3826\n",
            "Epoch 71/100 - 0.10s - loss: 1.0996 - acc: 0.3455 - val_loss: 1.0916 - val_acc: 0.3826\n",
            "Epoch 72/100 - 0.10s - loss: 1.0995 - acc: 0.3464 - val_loss: 1.0915 - val_acc: 0.3826\n",
            "Epoch 73/100 - 0.10s - loss: 1.0994 - acc: 0.3471 - val_loss: 1.0914 - val_acc: 0.3826\n",
            "Epoch 74/100 - 0.10s - loss: 1.0993 - acc: 0.3475 - val_loss: 1.0913 - val_acc: 0.3826\n",
            "Epoch 75/100 - 0.10s - loss: 1.0992 - acc: 0.3475 - val_loss: 1.0913 - val_acc: 0.3806\n",
            "Epoch 76/100 - 0.10s - loss: 1.0990 - acc: 0.3477 - val_loss: 1.0912 - val_acc: 0.3826\n",
            "Epoch 77/100 - 0.10s - loss: 1.0989 - acc: 0.3489 - val_loss: 1.0911 - val_acc: 0.3826\n",
            "Epoch 78/100 - 0.10s - loss: 1.0988 - acc: 0.3498 - val_loss: 1.0910 - val_acc: 0.3806\n",
            "Epoch 79/100 - 0.15s - loss: 1.0987 - acc: 0.3498 - val_loss: 1.0909 - val_acc: 0.3806\n",
            "Epoch 80/100 - 0.10s - loss: 1.0986 - acc: 0.3511 - val_loss: 1.0908 - val_acc: 0.3806\n",
            "Epoch 81/100 - 0.10s - loss: 1.0985 - acc: 0.3520 - val_loss: 1.0907 - val_acc: 0.3806\n",
            "Epoch 82/100 - 0.11s - loss: 1.0983 - acc: 0.3520 - val_loss: 1.0906 - val_acc: 0.3806\n",
            "Epoch 83/100 - 0.14s - loss: 1.0982 - acc: 0.3518 - val_loss: 1.0906 - val_acc: 0.3806\n",
            "Epoch 84/100 - 0.13s - loss: 1.0981 - acc: 0.3518 - val_loss: 1.0905 - val_acc: 0.3785\n",
            "Epoch 85/100 - 0.11s - loss: 1.0980 - acc: 0.3513 - val_loss: 1.0904 - val_acc: 0.3785\n",
            "Epoch 86/100 - 0.10s - loss: 1.0979 - acc: 0.3513 - val_loss: 1.0903 - val_acc: 0.3806\n",
            "Epoch 87/100 - 0.11s - loss: 1.0978 - acc: 0.3513 - val_loss: 1.0902 - val_acc: 0.3806\n",
            "Epoch 88/100 - 0.10s - loss: 1.0977 - acc: 0.3516 - val_loss: 1.0901 - val_acc: 0.3785\n",
            "Epoch 89/100 - 0.10s - loss: 1.0976 - acc: 0.3522 - val_loss: 1.0900 - val_acc: 0.3806\n",
            "Epoch 90/100 - 0.11s - loss: 1.0974 - acc: 0.3520 - val_loss: 1.0900 - val_acc: 0.3806\n",
            "Epoch 91/100 - 0.10s - loss: 1.0973 - acc: 0.3518 - val_loss: 1.0899 - val_acc: 0.3806\n",
            "Epoch 92/100 - 0.10s - loss: 1.0972 - acc: 0.3516 - val_loss: 1.0898 - val_acc: 0.3826\n",
            "Epoch 93/100 - 0.10s - loss: 1.0971 - acc: 0.3516 - val_loss: 1.0897 - val_acc: 0.3846\n",
            "Epoch 94/100 - 0.10s - loss: 1.0970 - acc: 0.3513 - val_loss: 1.0896 - val_acc: 0.3866\n",
            "Epoch 95/100 - 0.10s - loss: 1.0969 - acc: 0.3516 - val_loss: 1.0895 - val_acc: 0.3866\n",
            "Epoch 96/100 - 0.11s - loss: 1.0968 - acc: 0.3525 - val_loss: 1.0894 - val_acc: 0.3887\n",
            "Epoch 97/100 - 0.10s - loss: 1.0967 - acc: 0.3525 - val_loss: 1.0893 - val_acc: 0.3907\n",
            "Epoch 98/100 - 0.10s - loss: 1.0966 - acc: 0.3531 - val_loss: 1.0893 - val_acc: 0.3907\n",
            "Epoch 99/100 - 0.10s - loss: 1.0965 - acc: 0.3522 - val_loss: 1.0892 - val_acc: 0.3907\n",
            "Epoch 100/100 - 0.11s - loss: 1.0964 - acc: 0.3525 - val_loss: 1.0891 - val_acc: 0.3887\n",
            "\n",
            "Combination 180/252:\n",
            "Hidden Layers: [128, 64, 32], Activation: tanh, Learning Rate: 0.0001, Batch Size: 64, Epochs: 150\n",
            "Epoch 1/150 - 0.10s - loss: 1.1103 - acc: 0.3614 - val_loss: 1.1117 - val_acc: 0.3664\n",
            "Epoch 2/150 - 0.11s - loss: 1.1099 - acc: 0.3614 - val_loss: 1.1113 - val_acc: 0.3664\n",
            "Epoch 3/150 - 0.10s - loss: 1.1095 - acc: 0.3621 - val_loss: 1.1108 - val_acc: 0.3644\n",
            "Epoch 4/150 - 0.10s - loss: 1.1091 - acc: 0.3626 - val_loss: 1.1104 - val_acc: 0.3644\n",
            "Epoch 5/150 - 0.10s - loss: 1.1087 - acc: 0.3626 - val_loss: 1.1099 - val_acc: 0.3623\n",
            "Epoch 6/150 - 0.10s - loss: 1.1083 - acc: 0.3614 - val_loss: 1.1095 - val_acc: 0.3623\n",
            "Epoch 7/150 - 0.11s - loss: 1.1080 - acc: 0.3594 - val_loss: 1.1091 - val_acc: 0.3644\n",
            "Epoch 8/150 - 0.10s - loss: 1.1077 - acc: 0.3603 - val_loss: 1.1087 - val_acc: 0.3664\n",
            "Epoch 9/150 - 0.10s - loss: 1.1073 - acc: 0.3583 - val_loss: 1.1084 - val_acc: 0.3664\n",
            "Epoch 10/150 - 0.11s - loss: 1.1070 - acc: 0.3592 - val_loss: 1.1080 - val_acc: 0.3684\n",
            "Epoch 11/150 - 0.10s - loss: 1.1067 - acc: 0.3596 - val_loss: 1.1077 - val_acc: 0.3704\n",
            "Epoch 12/150 - 0.10s - loss: 1.1064 - acc: 0.3596 - val_loss: 1.1073 - val_acc: 0.3704\n",
            "Epoch 13/150 - 0.11s - loss: 1.1062 - acc: 0.3594 - val_loss: 1.1070 - val_acc: 0.3684\n",
            "Epoch 14/150 - 0.10s - loss: 1.1059 - acc: 0.3601 - val_loss: 1.1067 - val_acc: 0.3725\n",
            "Epoch 15/150 - 0.10s - loss: 1.1057 - acc: 0.3594 - val_loss: 1.1064 - val_acc: 0.3765\n",
            "Epoch 16/150 - 0.10s - loss: 1.1054 - acc: 0.3601 - val_loss: 1.1062 - val_acc: 0.3725\n",
            "Epoch 17/150 - 0.10s - loss: 1.1052 - acc: 0.3610 - val_loss: 1.1059 - val_acc: 0.3725\n",
            "Epoch 18/150 - 0.10s - loss: 1.1049 - acc: 0.3619 - val_loss: 1.1056 - val_acc: 0.3704\n",
            "Epoch 19/150 - 0.11s - loss: 1.1047 - acc: 0.3628 - val_loss: 1.1054 - val_acc: 0.3664\n",
            "Epoch 20/150 - 0.10s - loss: 1.1045 - acc: 0.3639 - val_loss: 1.1051 - val_acc: 0.3664\n",
            "Epoch 21/150 - 0.10s - loss: 1.1043 - acc: 0.3632 - val_loss: 1.1049 - val_acc: 0.3664\n",
            "Epoch 22/150 - 0.12s - loss: 1.1041 - acc: 0.3659 - val_loss: 1.1047 - val_acc: 0.3664\n",
            "Epoch 23/150 - 0.10s - loss: 1.1039 - acc: 0.3657 - val_loss: 1.1044 - val_acc: 0.3603\n",
            "Epoch 24/150 - 0.10s - loss: 1.1037 - acc: 0.3657 - val_loss: 1.1042 - val_acc: 0.3623\n",
            "Epoch 25/150 - 0.11s - loss: 1.1035 - acc: 0.3657 - val_loss: 1.1040 - val_acc: 0.3603\n",
            "Epoch 26/150 - 0.10s - loss: 1.1034 - acc: 0.3650 - val_loss: 1.1038 - val_acc: 0.3583\n",
            "Epoch 27/150 - 0.10s - loss: 1.1032 - acc: 0.3648 - val_loss: 1.1036 - val_acc: 0.3583\n",
            "Epoch 28/150 - 0.10s - loss: 1.1030 - acc: 0.3655 - val_loss: 1.1034 - val_acc: 0.3623\n",
            "Epoch 29/150 - 0.10s - loss: 1.1029 - acc: 0.3650 - val_loss: 1.1032 - val_acc: 0.3623\n",
            "Epoch 30/150 - 0.10s - loss: 1.1027 - acc: 0.3653 - val_loss: 1.1031 - val_acc: 0.3664\n",
            "Epoch 31/150 - 0.10s - loss: 1.1025 - acc: 0.3646 - val_loss: 1.1029 - val_acc: 0.3644\n",
            "Epoch 32/150 - 0.09s - loss: 1.1024 - acc: 0.3648 - val_loss: 1.1027 - val_acc: 0.3644\n",
            "Epoch 33/150 - 0.09s - loss: 1.1022 - acc: 0.3644 - val_loss: 1.1025 - val_acc: 0.3623\n",
            "Epoch 34/150 - 0.09s - loss: 1.1021 - acc: 0.3630 - val_loss: 1.1024 - val_acc: 0.3603\n",
            "Epoch 35/150 - 0.09s - loss: 1.1019 - acc: 0.3619 - val_loss: 1.1022 - val_acc: 0.3603\n",
            "Epoch 36/150 - 0.09s - loss: 1.1018 - acc: 0.3610 - val_loss: 1.1020 - val_acc: 0.3603\n",
            "Epoch 37/150 - 0.10s - loss: 1.1017 - acc: 0.3603 - val_loss: 1.1019 - val_acc: 0.3603\n",
            "Epoch 38/150 - 0.09s - loss: 1.1015 - acc: 0.3608 - val_loss: 1.1017 - val_acc: 0.3623\n",
            "Epoch 39/150 - 0.09s - loss: 1.1014 - acc: 0.3612 - val_loss: 1.1016 - val_acc: 0.3623\n",
            "Epoch 40/150 - 0.09s - loss: 1.1013 - acc: 0.3608 - val_loss: 1.1014 - val_acc: 0.3644\n",
            "Epoch 41/150 - 0.09s - loss: 1.1011 - acc: 0.3605 - val_loss: 1.1013 - val_acc: 0.3603\n",
            "Epoch 42/150 - 0.10s - loss: 1.1010 - acc: 0.3603 - val_loss: 1.1012 - val_acc: 0.3644\n",
            "Epoch 43/150 - 0.13s - loss: 1.1009 - acc: 0.3605 - val_loss: 1.1010 - val_acc: 0.3644\n",
            "Epoch 44/150 - 0.12s - loss: 1.1008 - acc: 0.3614 - val_loss: 1.1009 - val_acc: 0.3644\n",
            "Epoch 45/150 - 0.09s - loss: 1.1007 - acc: 0.3617 - val_loss: 1.1008 - val_acc: 0.3623\n",
            "Epoch 46/150 - 0.09s - loss: 1.1005 - acc: 0.3619 - val_loss: 1.1006 - val_acc: 0.3623\n",
            "Epoch 47/150 - 0.09s - loss: 1.1004 - acc: 0.3612 - val_loss: 1.1005 - val_acc: 0.3644\n",
            "Epoch 48/150 - 0.09s - loss: 1.1003 - acc: 0.3614 - val_loss: 1.1004 - val_acc: 0.3644\n",
            "Epoch 49/150 - 0.10s - loss: 1.1002 - acc: 0.3610 - val_loss: 1.1002 - val_acc: 0.3644\n",
            "Epoch 50/150 - 0.09s - loss: 1.1001 - acc: 0.3614 - val_loss: 1.1001 - val_acc: 0.3644\n",
            "Epoch 51/150 - 0.09s - loss: 1.1000 - acc: 0.3610 - val_loss: 1.1000 - val_acc: 0.3644\n",
            "Epoch 52/150 - 0.09s - loss: 1.0999 - acc: 0.3614 - val_loss: 1.0999 - val_acc: 0.3644\n",
            "Epoch 53/150 - 0.09s - loss: 1.0998 - acc: 0.3632 - val_loss: 1.0998 - val_acc: 0.3644\n",
            "Epoch 54/150 - 0.09s - loss: 1.0997 - acc: 0.3621 - val_loss: 1.0996 - val_acc: 0.3644\n",
            "Epoch 55/150 - 0.10s - loss: 1.0995 - acc: 0.3610 - val_loss: 1.0995 - val_acc: 0.3644\n",
            "Epoch 56/150 - 0.09s - loss: 1.0994 - acc: 0.3605 - val_loss: 1.0994 - val_acc: 0.3644\n",
            "Epoch 57/150 - 0.09s - loss: 1.0993 - acc: 0.3594 - val_loss: 1.0993 - val_acc: 0.3644\n",
            "Epoch 58/150 - 0.09s - loss: 1.0992 - acc: 0.3603 - val_loss: 1.0992 - val_acc: 0.3644\n",
            "Epoch 59/150 - 0.09s - loss: 1.0991 - acc: 0.3603 - val_loss: 1.0991 - val_acc: 0.3664\n",
            "Epoch 60/150 - 0.09s - loss: 1.0990 - acc: 0.3608 - val_loss: 1.0990 - val_acc: 0.3664\n",
            "Epoch 61/150 - 0.10s - loss: 1.0989 - acc: 0.3603 - val_loss: 1.0989 - val_acc: 0.3644\n",
            "Epoch 62/150 - 0.09s - loss: 1.0988 - acc: 0.3601 - val_loss: 1.0988 - val_acc: 0.3623\n",
            "Epoch 63/150 - 0.09s - loss: 1.0988 - acc: 0.3608 - val_loss: 1.0987 - val_acc: 0.3623\n",
            "Epoch 64/150 - 0.09s - loss: 1.0987 - acc: 0.3603 - val_loss: 1.0986 - val_acc: 0.3623\n",
            "Epoch 65/150 - 0.10s - loss: 1.0986 - acc: 0.3603 - val_loss: 1.0985 - val_acc: 0.3623\n",
            "Epoch 66/150 - 0.09s - loss: 1.0985 - acc: 0.3596 - val_loss: 1.0984 - val_acc: 0.3623\n",
            "Epoch 67/150 - 0.09s - loss: 1.0984 - acc: 0.3596 - val_loss: 1.0983 - val_acc: 0.3623\n",
            "Epoch 68/150 - 0.09s - loss: 1.0983 - acc: 0.3601 - val_loss: 1.0982 - val_acc: 0.3623\n",
            "Epoch 69/150 - 0.09s - loss: 1.0982 - acc: 0.3610 - val_loss: 1.0981 - val_acc: 0.3623\n",
            "Epoch 70/150 - 0.10s - loss: 1.0981 - acc: 0.3599 - val_loss: 1.0980 - val_acc: 0.3603\n",
            "Epoch 71/150 - 0.10s - loss: 1.0980 - acc: 0.3608 - val_loss: 1.0979 - val_acc: 0.3603\n",
            "Epoch 72/150 - 0.10s - loss: 1.0979 - acc: 0.3612 - val_loss: 1.0978 - val_acc: 0.3623\n",
            "Epoch 73/150 - 0.10s - loss: 1.0978 - acc: 0.3619 - val_loss: 1.0977 - val_acc: 0.3603\n",
            "Epoch 74/150 - 0.09s - loss: 1.0977 - acc: 0.3619 - val_loss: 1.0976 - val_acc: 0.3603\n",
            "Epoch 75/150 - 0.09s - loss: 1.0977 - acc: 0.3623 - val_loss: 1.0975 - val_acc: 0.3603\n",
            "Epoch 76/150 - 0.10s - loss: 1.0976 - acc: 0.3621 - val_loss: 1.0975 - val_acc: 0.3583\n",
            "Epoch 77/150 - 0.09s - loss: 1.0975 - acc: 0.3619 - val_loss: 1.0974 - val_acc: 0.3583\n",
            "Epoch 78/150 - 0.08s - loss: 1.0974 - acc: 0.3623 - val_loss: 1.0973 - val_acc: 0.3583\n",
            "Epoch 79/150 - 0.10s - loss: 1.0973 - acc: 0.3628 - val_loss: 1.0972 - val_acc: 0.3623\n",
            "Epoch 80/150 - 0.09s - loss: 1.0972 - acc: 0.3626 - val_loss: 1.0971 - val_acc: 0.3623\n",
            "Epoch 81/150 - 0.09s - loss: 1.0971 - acc: 0.3632 - val_loss: 1.0970 - val_acc: 0.3623\n",
            "Epoch 82/150 - 0.09s - loss: 1.0970 - acc: 0.3635 - val_loss: 1.0969 - val_acc: 0.3623\n",
            "Epoch 83/150 - 0.10s - loss: 1.0970 - acc: 0.3637 - val_loss: 1.0968 - val_acc: 0.3644\n",
            "Epoch 84/150 - 0.09s - loss: 1.0969 - acc: 0.3641 - val_loss: 1.0968 - val_acc: 0.3644\n",
            "Epoch 85/150 - 0.12s - loss: 1.0968 - acc: 0.3653 - val_loss: 1.0967 - val_acc: 0.3644\n",
            "Epoch 86/150 - 0.09s - loss: 1.0967 - acc: 0.3653 - val_loss: 1.0966 - val_acc: 0.3664\n",
            "Epoch 87/150 - 0.09s - loss: 1.0966 - acc: 0.3657 - val_loss: 1.0965 - val_acc: 0.3664\n",
            "Epoch 88/150 - 0.09s - loss: 1.0965 - acc: 0.3659 - val_loss: 1.0964 - val_acc: 0.3664\n",
            "Epoch 89/150 - 0.09s - loss: 1.0965 - acc: 0.3666 - val_loss: 1.0963 - val_acc: 0.3684\n",
            "Epoch 90/150 - 0.09s - loss: 1.0964 - acc: 0.3664 - val_loss: 1.0963 - val_acc: 0.3684\n",
            "Epoch 91/150 - 0.10s - loss: 1.0963 - acc: 0.3671 - val_loss: 1.0962 - val_acc: 0.3684\n",
            "Epoch 92/150 - 0.09s - loss: 1.0962 - acc: 0.3671 - val_loss: 1.0961 - val_acc: 0.3644\n",
            "Epoch 93/150 - 0.09s - loss: 1.0961 - acc: 0.3677 - val_loss: 1.0960 - val_acc: 0.3644\n",
            "Epoch 94/150 - 0.09s - loss: 1.0960 - acc: 0.3686 - val_loss: 1.0959 - val_acc: 0.3644\n",
            "Epoch 95/150 - 0.09s - loss: 1.0960 - acc: 0.3689 - val_loss: 1.0959 - val_acc: 0.3664\n",
            "Epoch 96/150 - 0.09s - loss: 1.0959 - acc: 0.3700 - val_loss: 1.0958 - val_acc: 0.3664\n",
            "Epoch 97/150 - 0.10s - loss: 1.0958 - acc: 0.3711 - val_loss: 1.0957 - val_acc: 0.3684\n",
            "Epoch 98/150 - 0.09s - loss: 1.0957 - acc: 0.3722 - val_loss: 1.0956 - val_acc: 0.3684\n",
            "Epoch 99/150 - 0.09s - loss: 1.0956 - acc: 0.3725 - val_loss: 1.0955 - val_acc: 0.3684\n",
            "Epoch 100/150 - 0.11s - loss: 1.0956 - acc: 0.3727 - val_loss: 1.0955 - val_acc: 0.3684\n",
            "Epoch 101/150 - 0.09s - loss: 1.0955 - acc: 0.3729 - val_loss: 1.0954 - val_acc: 0.3704\n",
            "Epoch 102/150 - 0.09s - loss: 1.0954 - acc: 0.3731 - val_loss: 1.0953 - val_acc: 0.3704\n",
            "Epoch 103/150 - 0.10s - loss: 1.0953 - acc: 0.3738 - val_loss: 1.0952 - val_acc: 0.3704\n",
            "Epoch 104/150 - 0.09s - loss: 1.0952 - acc: 0.3745 - val_loss: 1.0951 - val_acc: 0.3684\n",
            "Epoch 105/150 - 0.09s - loss: 1.0952 - acc: 0.3743 - val_loss: 1.0951 - val_acc: 0.3704\n",
            "Epoch 106/150 - 0.09s - loss: 1.0951 - acc: 0.3747 - val_loss: 1.0950 - val_acc: 0.3725\n",
            "Epoch 107/150 - 0.09s - loss: 1.0950 - acc: 0.3740 - val_loss: 1.0949 - val_acc: 0.3725\n",
            "Epoch 108/150 - 0.09s - loss: 1.0949 - acc: 0.3740 - val_loss: 1.0948 - val_acc: 0.3684\n",
            "Epoch 109/150 - 0.13s - loss: 1.0949 - acc: 0.3745 - val_loss: 1.0948 - val_acc: 0.3704\n",
            "Epoch 110/150 - 0.09s - loss: 1.0948 - acc: 0.3745 - val_loss: 1.0947 - val_acc: 0.3704\n",
            "Epoch 111/150 - 0.09s - loss: 1.0947 - acc: 0.3747 - val_loss: 1.0946 - val_acc: 0.3704\n",
            "Epoch 112/150 - 0.09s - loss: 1.0946 - acc: 0.3752 - val_loss: 1.0945 - val_acc: 0.3725\n",
            "Epoch 113/150 - 0.09s - loss: 1.0945 - acc: 0.3749 - val_loss: 1.0945 - val_acc: 0.3725\n",
            "Epoch 114/150 - 0.09s - loss: 1.0945 - acc: 0.3752 - val_loss: 1.0944 - val_acc: 0.3725\n",
            "Epoch 115/150 - 0.10s - loss: 1.0944 - acc: 0.3752 - val_loss: 1.0943 - val_acc: 0.3704\n",
            "Epoch 116/150 - 0.09s - loss: 1.0943 - acc: 0.3754 - val_loss: 1.0942 - val_acc: 0.3704\n",
            "Epoch 117/150 - 0.09s - loss: 1.0942 - acc: 0.3763 - val_loss: 1.0942 - val_acc: 0.3704\n",
            "Epoch 118/150 - 0.09s - loss: 1.0942 - acc: 0.3763 - val_loss: 1.0941 - val_acc: 0.3704\n",
            "Epoch 119/150 - 0.09s - loss: 1.0941 - acc: 0.3765 - val_loss: 1.0940 - val_acc: 0.3704\n",
            "Epoch 120/150 - 0.09s - loss: 1.0940 - acc: 0.3774 - val_loss: 1.0940 - val_acc: 0.3704\n",
            "Epoch 121/150 - 0.10s - loss: 1.0939 - acc: 0.3770 - val_loss: 1.0939 - val_acc: 0.3704\n",
            "Epoch 122/150 - 0.09s - loss: 1.0939 - acc: 0.3767 - val_loss: 1.0938 - val_acc: 0.3725\n",
            "Epoch 123/150 - 0.09s - loss: 1.0938 - acc: 0.3770 - val_loss: 1.0937 - val_acc: 0.3745\n",
            "Epoch 124/150 - 0.09s - loss: 1.0937 - acc: 0.3774 - val_loss: 1.0937 - val_acc: 0.3745\n",
            "Epoch 125/150 - 0.09s - loss: 1.0936 - acc: 0.3783 - val_loss: 1.0936 - val_acc: 0.3725\n",
            "Epoch 126/150 - 0.09s - loss: 1.0936 - acc: 0.3781 - val_loss: 1.0935 - val_acc: 0.3725\n",
            "Epoch 127/150 - 0.09s - loss: 1.0935 - acc: 0.3779 - val_loss: 1.0935 - val_acc: 0.3725\n",
            "Epoch 128/150 - 0.09s - loss: 1.0934 - acc: 0.3788 - val_loss: 1.0934 - val_acc: 0.3745\n",
            "Epoch 129/150 - 0.09s - loss: 1.0933 - acc: 0.3790 - val_loss: 1.0933 - val_acc: 0.3745\n",
            "Epoch 130/150 - 0.09s - loss: 1.0933 - acc: 0.3794 - val_loss: 1.0933 - val_acc: 0.3745\n",
            "Epoch 131/150 - 0.09s - loss: 1.0932 - acc: 0.3801 - val_loss: 1.0932 - val_acc: 0.3745\n",
            "Epoch 132/150 - 0.10s - loss: 1.0931 - acc: 0.3815 - val_loss: 1.0931 - val_acc: 0.3745\n",
            "Epoch 133/150 - 0.09s - loss: 1.0931 - acc: 0.3824 - val_loss: 1.0930 - val_acc: 0.3745\n",
            "Epoch 134/150 - 0.09s - loss: 1.0930 - acc: 0.3819 - val_loss: 1.0930 - val_acc: 0.3745\n",
            "Epoch 135/150 - 0.09s - loss: 1.0929 - acc: 0.3819 - val_loss: 1.0929 - val_acc: 0.3745\n",
            "Epoch 136/150 - 0.09s - loss: 1.0928 - acc: 0.3821 - val_loss: 1.0928 - val_acc: 0.3745\n",
            "Epoch 137/150 - 0.09s - loss: 1.0928 - acc: 0.3826 - val_loss: 1.0928 - val_acc: 0.3745\n",
            "Epoch 138/150 - 0.09s - loss: 1.0927 - acc: 0.3830 - val_loss: 1.0927 - val_acc: 0.3765\n",
            "Epoch 139/150 - 0.09s - loss: 1.0926 - acc: 0.3828 - val_loss: 1.0926 - val_acc: 0.3745\n",
            "Epoch 140/150 - 0.09s - loss: 1.0926 - acc: 0.3830 - val_loss: 1.0926 - val_acc: 0.3745\n",
            "Epoch 141/150 - 0.09s - loss: 1.0925 - acc: 0.3844 - val_loss: 1.0925 - val_acc: 0.3765\n",
            "Epoch 142/150 - 0.09s - loss: 1.0924 - acc: 0.3844 - val_loss: 1.0924 - val_acc: 0.3765\n",
            "Epoch 143/150 - 0.09s - loss: 1.0923 - acc: 0.3844 - val_loss: 1.0924 - val_acc: 0.3765\n",
            "Epoch 144/150 - 0.09s - loss: 1.0923 - acc: 0.3853 - val_loss: 1.0923 - val_acc: 0.3806\n",
            "Epoch 145/150 - 0.10s - loss: 1.0922 - acc: 0.3853 - val_loss: 1.0922 - val_acc: 0.3785\n",
            "Epoch 146/150 - 0.09s - loss: 1.0921 - acc: 0.3855 - val_loss: 1.0922 - val_acc: 0.3785\n",
            "Epoch 147/150 - 0.09s - loss: 1.0921 - acc: 0.3857 - val_loss: 1.0921 - val_acc: 0.3785\n",
            "Epoch 148/150 - 0.10s - loss: 1.0920 - acc: 0.3853 - val_loss: 1.0920 - val_acc: 0.3785\n",
            "Epoch 149/150 - 0.09s - loss: 1.0919 - acc: 0.3862 - val_loss: 1.0920 - val_acc: 0.3785\n",
            "Epoch 150/150 - 0.09s - loss: 1.0918 - acc: 0.3871 - val_loss: 1.0919 - val_acc: 0.3785\n",
            "\n",
            "Combination 181/252:\n",
            "Hidden Layers: [256, 128, 64], Activation: relu, Learning Rate: 0.01, Batch Size: 32, Epochs: 50\n",
            "Epoch 1/50 - 0.17s - loss: 1.0807 - acc: 0.4327 - val_loss: 1.0872 - val_acc: 0.4271\n",
            "Epoch 2/50 - 0.14s - loss: 1.0666 - acc: 0.4397 - val_loss: 1.0769 - val_acc: 0.4352\n",
            "Epoch 3/50 - 0.14s - loss: 1.0544 - acc: 0.4649 - val_loss: 1.0697 - val_acc: 0.4291\n",
            "Epoch 4/50 - 0.14s - loss: 1.0491 - acc: 0.4516 - val_loss: 1.0641 - val_acc: 0.4312\n",
            "Epoch 5/50 - 0.15s - loss: 1.0323 - acc: 0.4881 - val_loss: 1.0537 - val_acc: 0.4676\n",
            "Epoch 6/50 - 0.14s - loss: 1.0221 - acc: 0.4971 - val_loss: 1.0463 - val_acc: 0.5020\n",
            "Epoch 7/50 - 0.14s - loss: 1.0126 - acc: 0.4991 - val_loss: 1.0400 - val_acc: 0.5061\n",
            "Epoch 8/50 - 0.14s - loss: 1.0042 - acc: 0.5184 - val_loss: 1.0351 - val_acc: 0.4777\n",
            "Epoch 9/50 - 0.15s - loss: 0.9940 - acc: 0.5121 - val_loss: 1.0248 - val_acc: 0.5081\n",
            "Epoch 10/50 - 0.15s - loss: 0.9845 - acc: 0.5301 - val_loss: 1.0197 - val_acc: 0.5162\n",
            "Epoch 11/50 - 0.17s - loss: 0.9766 - acc: 0.5292 - val_loss: 1.0165 - val_acc: 0.5020\n",
            "Epoch 12/50 - 0.15s - loss: 0.9657 - acc: 0.5412 - val_loss: 1.0088 - val_acc: 0.5182\n",
            "Epoch 13/50 - 0.15s - loss: 0.9551 - acc: 0.5452 - val_loss: 0.9976 - val_acc: 0.5202\n",
            "Epoch 14/50 - 0.14s - loss: 0.9473 - acc: 0.5515 - val_loss: 0.9914 - val_acc: 0.5425\n",
            "Epoch 15/50 - 0.15s - loss: 0.9400 - acc: 0.5616 - val_loss: 0.9875 - val_acc: 0.5445\n",
            "Epoch 16/50 - 0.20s - loss: 0.9335 - acc: 0.5605 - val_loss: 0.9829 - val_acc: 0.5445\n",
            "Epoch 17/50 - 0.18s - loss: 0.9276 - acc: 0.5652 - val_loss: 0.9805 - val_acc: 0.5445\n",
            "Epoch 18/50 - 0.15s - loss: 0.9248 - acc: 0.5688 - val_loss: 0.9832 - val_acc: 0.5364\n",
            "Epoch 19/50 - 0.15s - loss: 0.9236 - acc: 0.5650 - val_loss: 0.9901 - val_acc: 0.5283\n",
            "Epoch 20/50 - 0.18s - loss: 0.9172 - acc: 0.5684 - val_loss: 0.9834 - val_acc: 0.5344\n",
            "Epoch 21/50 - 0.17s - loss: 0.9515 - acc: 0.5349 - val_loss: 1.0242 - val_acc: 0.4798\n",
            "Epoch 22/50 - 0.15s - loss: 0.9077 - acc: 0.5717 - val_loss: 0.9712 - val_acc: 0.5567\n",
            "Epoch 23/50 - 0.14s - loss: 0.8960 - acc: 0.5823 - val_loss: 0.9701 - val_acc: 0.5344\n",
            "Epoch 24/50 - 0.14s - loss: 0.8924 - acc: 0.5855 - val_loss: 0.9714 - val_acc: 0.5364\n",
            "Epoch 25/50 - 0.15s - loss: 0.8884 - acc: 0.5882 - val_loss: 0.9658 - val_acc: 0.5648\n",
            "Epoch 26/50 - 0.15s - loss: 0.9013 - acc: 0.5762 - val_loss: 0.9828 - val_acc: 0.5466\n",
            "Epoch 27/50 - 0.15s - loss: 0.8751 - acc: 0.5992 - val_loss: 0.9601 - val_acc: 0.5526\n",
            "Epoch 28/50 - 0.14s - loss: 0.9131 - acc: 0.5731 - val_loss: 0.9879 - val_acc: 0.5344\n",
            "Epoch 29/50 - 0.16s - loss: 0.9367 - acc: 0.5445 - val_loss: 1.0403 - val_acc: 0.4818\n",
            "Epoch 30/50 - 0.14s - loss: 0.8605 - acc: 0.6068 - val_loss: 0.9562 - val_acc: 0.5445\n",
            "Epoch 31/50 - 0.16s - loss: 0.8727 - acc: 0.6055 - val_loss: 0.9634 - val_acc: 0.5648\n",
            "Epoch 32/50 - 0.15s - loss: 0.8756 - acc: 0.5958 - val_loss: 0.9833 - val_acc: 0.5020\n",
            "Epoch 33/50 - 0.16s - loss: 0.8766 - acc: 0.5837 - val_loss: 0.9783 - val_acc: 0.5364\n",
            "Epoch 34/50 - 0.14s - loss: 0.8557 - acc: 0.6098 - val_loss: 0.9582 - val_acc: 0.5648\n",
            "Epoch 35/50 - 0.14s - loss: 0.8433 - acc: 0.6120 - val_loss: 0.9491 - val_acc: 0.5445\n",
            "Epoch 36/50 - 0.14s - loss: 0.8925 - acc: 0.5812 - val_loss: 1.0290 - val_acc: 0.5020\n",
            "Epoch 37/50 - 0.15s - loss: 0.8736 - acc: 0.5767 - val_loss: 0.9808 - val_acc: 0.5223\n",
            "Epoch 38/50 - 0.14s - loss: 0.8398 - acc: 0.6129 - val_loss: 0.9578 - val_acc: 0.5607\n",
            "Epoch 39/50 - 0.15s - loss: 0.8577 - acc: 0.6041 - val_loss: 0.9763 - val_acc: 0.5425\n",
            "Epoch 40/50 - 0.14s - loss: 0.8269 - acc: 0.6275 - val_loss: 0.9557 - val_acc: 0.5729\n",
            "Epoch 41/50 - 0.15s - loss: 0.8257 - acc: 0.6237 - val_loss: 0.9773 - val_acc: 0.5182\n",
            "Epoch 42/50 - 0.14s - loss: 0.8357 - acc: 0.6242 - val_loss: 0.9724 - val_acc: 0.5567\n",
            "Epoch 43/50 - 0.14s - loss: 0.8132 - acc: 0.6307 - val_loss: 0.9699 - val_acc: 0.5466\n",
            "Epoch 44/50 - 0.14s - loss: 0.7981 - acc: 0.6442 - val_loss: 0.9501 - val_acc: 0.5466\n",
            "Epoch 45/50 - 0.15s - loss: 0.8010 - acc: 0.6410 - val_loss: 0.9524 - val_acc: 0.5628\n",
            "Epoch 46/50 - 0.14s - loss: 0.9000 - acc: 0.5744 - val_loss: 1.0996 - val_acc: 0.4615\n",
            "Epoch 47/50 - 0.17s - loss: 0.8113 - acc: 0.6327 - val_loss: 0.9749 - val_acc: 0.5445\n",
            "Epoch 48/50 - 0.15s - loss: 0.8247 - acc: 0.6287 - val_loss: 1.0153 - val_acc: 0.5162\n",
            "Epoch 49/50 - 0.16s - loss: 0.7781 - acc: 0.6556 - val_loss: 0.9626 - val_acc: 0.5526\n",
            "Epoch 50/50 - 0.14s - loss: 0.7930 - acc: 0.6469 - val_loss: 0.9659 - val_acc: 0.5526\n",
            "\n",
            "Combination 182/252:\n",
            "Hidden Layers: [256, 128, 64], Activation: relu, Learning Rate: 0.01, Batch Size: 32, Epochs: 100\n",
            "Epoch 1/100 - 0.14s - loss: 1.0761 - acc: 0.4222 - val_loss: 1.0870 - val_acc: 0.3664\n",
            "Epoch 2/100 - 0.14s - loss: 1.0586 - acc: 0.4552 - val_loss: 1.0741 - val_acc: 0.4251\n",
            "Epoch 3/100 - 0.14s - loss: 1.0458 - acc: 0.4642 - val_loss: 1.0635 - val_acc: 0.4413\n",
            "Epoch 4/100 - 0.13s - loss: 1.0337 - acc: 0.4849 - val_loss: 1.0560 - val_acc: 0.4453\n",
            "Epoch 5/100 - 0.14s - loss: 1.0253 - acc: 0.4890 - val_loss: 1.0537 - val_acc: 0.4595\n",
            "Epoch 6/100 - 0.14s - loss: 1.0151 - acc: 0.5016 - val_loss: 1.0452 - val_acc: 0.4798\n",
            "Epoch 7/100 - 0.15s - loss: 1.0072 - acc: 0.5119 - val_loss: 1.0388 - val_acc: 0.4879\n",
            "Epoch 8/100 - 0.13s - loss: 0.9993 - acc: 0.5135 - val_loss: 1.0309 - val_acc: 0.4919\n",
            "Epoch 9/100 - 0.14s - loss: 0.9905 - acc: 0.5272 - val_loss: 1.0256 - val_acc: 0.4960\n",
            "Epoch 10/100 - 0.14s - loss: 0.9815 - acc: 0.5290 - val_loss: 1.0178 - val_acc: 0.5101\n",
            "Epoch 11/100 - 0.18s - loss: 0.9770 - acc: 0.5342 - val_loss: 1.0168 - val_acc: 0.5061\n",
            "Epoch 12/100 - 0.16s - loss: 0.9683 - acc: 0.5398 - val_loss: 1.0071 - val_acc: 0.5364\n",
            "Epoch 13/100 - 0.14s - loss: 0.9577 - acc: 0.5421 - val_loss: 1.0004 - val_acc: 0.5223\n",
            "Epoch 14/100 - 0.14s - loss: 0.9648 - acc: 0.5430 - val_loss: 1.0068 - val_acc: 0.5304\n",
            "Epoch 15/100 - 0.15s - loss: 0.9465 - acc: 0.5479 - val_loss: 0.9934 - val_acc: 0.5202\n",
            "Epoch 16/100 - 0.14s - loss: 0.9435 - acc: 0.5450 - val_loss: 0.9919 - val_acc: 0.5182\n",
            "Epoch 17/100 - 0.14s - loss: 0.9592 - acc: 0.5331 - val_loss: 1.0183 - val_acc: 0.4798\n",
            "Epoch 18/100 - 0.13s - loss: 0.9487 - acc: 0.5538 - val_loss: 0.9923 - val_acc: 0.5364\n",
            "Epoch 19/100 - 0.15s - loss: 0.9279 - acc: 0.5630 - val_loss: 0.9868 - val_acc: 0.5182\n",
            "Epoch 20/100 - 0.14s - loss: 0.9248 - acc: 0.5621 - val_loss: 0.9753 - val_acc: 0.5385\n",
            "Epoch 21/100 - 0.15s - loss: 0.9112 - acc: 0.5670 - val_loss: 0.9753 - val_acc: 0.5304\n",
            "Epoch 22/100 - 0.14s - loss: 0.9138 - acc: 0.5765 - val_loss: 0.9700 - val_acc: 0.5648\n",
            "Epoch 23/100 - 0.15s - loss: 0.9250 - acc: 0.5571 - val_loss: 0.9962 - val_acc: 0.4939\n",
            "Epoch 24/100 - 0.14s - loss: 0.9155 - acc: 0.5682 - val_loss: 0.9948 - val_acc: 0.4980\n",
            "Epoch 25/100 - 0.14s - loss: 0.8934 - acc: 0.5839 - val_loss: 0.9708 - val_acc: 0.5162\n",
            "Epoch 26/100 - 0.16s - loss: 0.8870 - acc: 0.5870 - val_loss: 0.9666 - val_acc: 0.5283\n",
            "Epoch 27/100 - 0.15s - loss: 0.8727 - acc: 0.5947 - val_loss: 0.9538 - val_acc: 0.5526\n",
            "Epoch 28/100 - 0.15s - loss: 0.8746 - acc: 0.5954 - val_loss: 0.9512 - val_acc: 0.5506\n",
            "Epoch 29/100 - 0.15s - loss: 0.8831 - acc: 0.5951 - val_loss: 0.9569 - val_acc: 0.5749\n",
            "Epoch 30/100 - 0.14s - loss: 0.8679 - acc: 0.5963 - val_loss: 0.9513 - val_acc: 0.5668\n",
            "Epoch 31/100 - 0.16s - loss: 0.8740 - acc: 0.5909 - val_loss: 0.9743 - val_acc: 0.5101\n",
            "Epoch 32/100 - 0.15s - loss: 0.8623 - acc: 0.6055 - val_loss: 0.9499 - val_acc: 0.5729\n",
            "Epoch 33/100 - 0.16s - loss: 0.8620 - acc: 0.5915 - val_loss: 0.9692 - val_acc: 0.5223\n",
            "Epoch 34/100 - 0.14s - loss: 0.8582 - acc: 0.6104 - val_loss: 0.9557 - val_acc: 0.5789\n",
            "Epoch 35/100 - 0.15s - loss: 0.8359 - acc: 0.6181 - val_loss: 0.9443 - val_acc: 0.5486\n",
            "Epoch 36/100 - 0.14s - loss: 0.8535 - acc: 0.6129 - val_loss: 0.9623 - val_acc: 0.5648\n",
            "Epoch 37/100 - 0.17s - loss: 0.8378 - acc: 0.6147 - val_loss: 0.9562 - val_acc: 0.5405\n",
            "Epoch 38/100 - 0.15s - loss: 0.8335 - acc: 0.6156 - val_loss: 0.9651 - val_acc: 0.5283\n",
            "Epoch 39/100 - 0.17s - loss: 0.8170 - acc: 0.6307 - val_loss: 0.9416 - val_acc: 0.5547\n",
            "Epoch 40/100 - 0.16s - loss: 0.8131 - acc: 0.6329 - val_loss: 0.9454 - val_acc: 0.5587\n",
            "Epoch 41/100 - 0.18s - loss: 0.8658 - acc: 0.6084 - val_loss: 0.9829 - val_acc: 0.5587\n",
            "Epoch 42/100 - 0.16s - loss: 0.8185 - acc: 0.6269 - val_loss: 0.9603 - val_acc: 0.5202\n",
            "Epoch 43/100 - 0.17s - loss: 0.8287 - acc: 0.6248 - val_loss: 0.9565 - val_acc: 0.5628\n",
            "Epoch 44/100 - 0.15s - loss: 0.8034 - acc: 0.6395 - val_loss: 0.9404 - val_acc: 0.5709\n",
            "Epoch 45/100 - 0.15s - loss: 0.7969 - acc: 0.6460 - val_loss: 0.9372 - val_acc: 0.5668\n",
            "Epoch 46/100 - 0.14s - loss: 0.8009 - acc: 0.6368 - val_loss: 0.9417 - val_acc: 0.5587\n",
            "Epoch 47/100 - 0.17s - loss: 0.7923 - acc: 0.6460 - val_loss: 0.9543 - val_acc: 0.5304\n",
            "Epoch 48/100 - 0.15s - loss: 0.7933 - acc: 0.6500 - val_loss: 0.9526 - val_acc: 0.5526\n",
            "Epoch 49/100 - 0.15s - loss: 0.8902 - acc: 0.5909 - val_loss: 1.0373 - val_acc: 0.5263\n",
            "Epoch 50/100 - 0.15s - loss: 0.8376 - acc: 0.6125 - val_loss: 1.0265 - val_acc: 0.5020\n",
            "Epoch 51/100 - 0.16s - loss: 0.7719 - acc: 0.6543 - val_loss: 0.9366 - val_acc: 0.5769\n",
            "Epoch 52/100 - 0.15s - loss: 0.7969 - acc: 0.6527 - val_loss: 0.9583 - val_acc: 0.5587\n",
            "Epoch 53/100 - 0.15s - loss: 0.7771 - acc: 0.6453 - val_loss: 0.9443 - val_acc: 0.5648\n",
            "Epoch 54/100 - 0.14s - loss: 0.7630 - acc: 0.6712 - val_loss: 0.9552 - val_acc: 0.5425\n",
            "Epoch 55/100 - 0.17s - loss: 0.7617 - acc: 0.6671 - val_loss: 0.9484 - val_acc: 0.5749\n",
            "Epoch 56/100 - 0.15s - loss: 0.7999 - acc: 0.6329 - val_loss: 1.0211 - val_acc: 0.5081\n",
            "Epoch 57/100 - 0.14s - loss: 0.7571 - acc: 0.6682 - val_loss: 0.9633 - val_acc: 0.5405\n",
            "Epoch 58/100 - 0.14s - loss: 0.7427 - acc: 0.6822 - val_loss: 0.9625 - val_acc: 0.5445\n",
            "Epoch 59/100 - 0.17s - loss: 0.7330 - acc: 0.6790 - val_loss: 0.9455 - val_acc: 0.5547\n",
            "Epoch 60/100 - 0.15s - loss: 0.7322 - acc: 0.6804 - val_loss: 0.9584 - val_acc: 0.5344\n",
            "Epoch 61/100 - 0.15s - loss: 0.7227 - acc: 0.6905 - val_loss: 0.9398 - val_acc: 0.5648\n",
            "Epoch 62/100 - 0.15s - loss: 0.7413 - acc: 0.6716 - val_loss: 0.9581 - val_acc: 0.5729\n",
            "Epoch 63/100 - 0.16s - loss: 0.8535 - acc: 0.5920 - val_loss: 1.1242 - val_acc: 0.4960\n",
            "Epoch 64/100 - 0.14s - loss: 0.7356 - acc: 0.6718 - val_loss: 0.9734 - val_acc: 0.5425\n",
            "Epoch 65/100 - 0.15s - loss: 0.7068 - acc: 0.7006 - val_loss: 0.9609 - val_acc: 0.5607\n",
            "Epoch 66/100 - 0.14s - loss: 0.7139 - acc: 0.6948 - val_loss: 0.9514 - val_acc: 0.5688\n",
            "Epoch 67/100 - 0.15s - loss: 0.6909 - acc: 0.7090 - val_loss: 0.9375 - val_acc: 0.5709\n",
            "Epoch 68/100 - 0.14s - loss: 0.6933 - acc: 0.7027 - val_loss: 0.9552 - val_acc: 0.5607\n",
            "Epoch 69/100 - 0.14s - loss: 0.6983 - acc: 0.7020 - val_loss: 0.9510 - val_acc: 0.5648\n",
            "Epoch 70/100 - 0.14s - loss: 0.6824 - acc: 0.7168 - val_loss: 0.9432 - val_acc: 0.5607\n",
            "Epoch 71/100 - 0.15s - loss: 0.6816 - acc: 0.7056 - val_loss: 0.9636 - val_acc: 0.5445\n",
            "Epoch 72/100 - 0.13s - loss: 0.7618 - acc: 0.6563 - val_loss: 1.0742 - val_acc: 0.5263\n",
            "Epoch 73/100 - 0.16s - loss: 0.6763 - acc: 0.7161 - val_loss: 0.9747 - val_acc: 0.5344\n",
            "Epoch 74/100 - 0.15s - loss: 0.6530 - acc: 0.7301 - val_loss: 0.9483 - val_acc: 0.5587\n",
            "Epoch 75/100 - 0.21s - loss: 0.6666 - acc: 0.7123 - val_loss: 0.9621 - val_acc: 0.5648\n",
            "Epoch 76/100 - 0.16s - loss: 0.6482 - acc: 0.7393 - val_loss: 0.9657 - val_acc: 0.5526\n",
            "Epoch 77/100 - 0.15s - loss: 0.6875 - acc: 0.7036 - val_loss: 0.9938 - val_acc: 0.5628\n",
            "Epoch 78/100 - 0.14s - loss: 0.6685 - acc: 0.7132 - val_loss: 1.0194 - val_acc: 0.5283\n",
            "Epoch 79/100 - 0.16s - loss: 0.6295 - acc: 0.7506 - val_loss: 0.9676 - val_acc: 0.5445\n",
            "Epoch 80/100 - 0.14s - loss: 0.6308 - acc: 0.7494 - val_loss: 0.9662 - val_acc: 0.5547\n",
            "Epoch 81/100 - 0.15s - loss: 0.7455 - acc: 0.6669 - val_loss: 1.1024 - val_acc: 0.4939\n",
            "Epoch 82/100 - 0.14s - loss: 0.6150 - acc: 0.7557 - val_loss: 0.9513 - val_acc: 0.5648\n",
            "Epoch 83/100 - 0.15s - loss: 0.6055 - acc: 0.7645 - val_loss: 0.9530 - val_acc: 0.5628\n",
            "Epoch 84/100 - 0.14s - loss: 0.6169 - acc: 0.7465 - val_loss: 0.9874 - val_acc: 0.5607\n",
            "Epoch 85/100 - 0.14s - loss: 0.6967 - acc: 0.6844 - val_loss: 1.1105 - val_acc: 0.5182\n",
            "Epoch 86/100 - 0.14s - loss: 0.6304 - acc: 0.7350 - val_loss: 1.0251 - val_acc: 0.5344\n",
            "Epoch 87/100 - 0.15s - loss: 0.5739 - acc: 0.7785 - val_loss: 0.9688 - val_acc: 0.5648\n",
            "Epoch 88/100 - 0.14s - loss: 0.5773 - acc: 0.7735 - val_loss: 0.9611 - val_acc: 0.5688\n",
            "Epoch 89/100 - 0.14s - loss: 0.5835 - acc: 0.7614 - val_loss: 0.9812 - val_acc: 0.5709\n",
            "Epoch 90/100 - 0.14s - loss: 0.6064 - acc: 0.7481 - val_loss: 0.9845 - val_acc: 0.5850\n",
            "Epoch 91/100 - 0.14s - loss: 0.5525 - acc: 0.7785 - val_loss: 0.9660 - val_acc: 0.5709\n",
            "Epoch 92/100 - 0.14s - loss: 0.5766 - acc: 0.7744 - val_loss: 1.0264 - val_acc: 0.5385\n",
            "Epoch 93/100 - 0.14s - loss: 0.5969 - acc: 0.7321 - val_loss: 0.9993 - val_acc: 0.5729\n",
            "Epoch 94/100 - 0.14s - loss: 0.5914 - acc: 0.7481 - val_loss: 1.0302 - val_acc: 0.5304\n",
            "Epoch 95/100 - 0.14s - loss: 0.5985 - acc: 0.7393 - val_loss: 1.0138 - val_acc: 0.5567\n",
            "Epoch 96/100 - 0.13s - loss: 0.5805 - acc: 0.7665 - val_loss: 1.0780 - val_acc: 0.5243\n",
            "Epoch 97/100 - 0.14s - loss: 0.5117 - acc: 0.8124 - val_loss: 0.9658 - val_acc: 0.5607\n",
            "Epoch 98/100 - 0.14s - loss: 0.5288 - acc: 0.7962 - val_loss: 0.9950 - val_acc: 0.5385\n",
            "Epoch 99/100 - 0.15s - loss: 0.5099 - acc: 0.7978 - val_loss: 0.9938 - val_acc: 0.5931\n",
            "Epoch 100/100 - 0.14s - loss: 0.5513 - acc: 0.7841 - val_loss: 1.0641 - val_acc: 0.5385\n",
            "\n",
            "Combination 183/252:\n",
            "Hidden Layers: [256, 128, 64], Activation: relu, Learning Rate: 0.01, Batch Size: 32, Epochs: 150\n",
            "Epoch 1/150 - 0.14s - loss: 1.0739 - acc: 0.4386 - val_loss: 1.0836 - val_acc: 0.4150\n",
            "Epoch 2/150 - 0.13s - loss: 1.0605 - acc: 0.4615 - val_loss: 1.0744 - val_acc: 0.4312\n",
            "Epoch 3/150 - 0.14s - loss: 1.0501 - acc: 0.4649 - val_loss: 1.0690 - val_acc: 0.4312\n",
            "Epoch 4/150 - 0.13s - loss: 1.0392 - acc: 0.4735 - val_loss: 1.0602 - val_acc: 0.4514\n",
            "Epoch 5/150 - 0.14s - loss: 1.0287 - acc: 0.4937 - val_loss: 1.0554 - val_acc: 0.4514\n",
            "Epoch 6/150 - 0.13s - loss: 1.0157 - acc: 0.5065 - val_loss: 1.0439 - val_acc: 0.4798\n",
            "Epoch 7/150 - 0.14s - loss: 1.0052 - acc: 0.5094 - val_loss: 1.0345 - val_acc: 0.4899\n",
            "Epoch 8/150 - 0.13s - loss: 0.9963 - acc: 0.5207 - val_loss: 1.0320 - val_acc: 0.4757\n",
            "Epoch 9/150 - 0.14s - loss: 0.9827 - acc: 0.5283 - val_loss: 1.0187 - val_acc: 0.5000\n",
            "Epoch 10/150 - 0.13s - loss: 0.9760 - acc: 0.5342 - val_loss: 1.0171 - val_acc: 0.5304\n",
            "Epoch 11/150 - 0.18s - loss: 0.9671 - acc: 0.5450 - val_loss: 1.0124 - val_acc: 0.5263\n",
            "Epoch 12/150 - 0.13s - loss: 0.9575 - acc: 0.5448 - val_loss: 0.9994 - val_acc: 0.5182\n",
            "Epoch 13/150 - 0.14s - loss: 0.9495 - acc: 0.5520 - val_loss: 0.9977 - val_acc: 0.5445\n",
            "Epoch 14/150 - 0.13s - loss: 0.9421 - acc: 0.5531 - val_loss: 0.9870 - val_acc: 0.5263\n",
            "Epoch 15/150 - 0.14s - loss: 0.9846 - acc: 0.5054 - val_loss: 1.0366 - val_acc: 0.4676\n",
            "Epoch 16/150 - 0.13s - loss: 0.9252 - acc: 0.5693 - val_loss: 0.9805 - val_acc: 0.5547\n",
            "Epoch 17/150 - 0.14s - loss: 0.9229 - acc: 0.5697 - val_loss: 0.9798 - val_acc: 0.5567\n",
            "Epoch 18/150 - 0.14s - loss: 0.9448 - acc: 0.5493 - val_loss: 1.0048 - val_acc: 0.5425\n",
            "Epoch 19/150 - 0.17s - loss: 0.9151 - acc: 0.5706 - val_loss: 0.9771 - val_acc: 0.5385\n",
            "Epoch 20/150 - 0.14s - loss: 0.9136 - acc: 0.5715 - val_loss: 0.9729 - val_acc: 0.5587\n",
            "Epoch 21/150 - 0.14s - loss: 0.8979 - acc: 0.5789 - val_loss: 0.9633 - val_acc: 0.5526\n",
            "Epoch 22/150 - 0.14s - loss: 0.8955 - acc: 0.5823 - val_loss: 0.9618 - val_acc: 0.5547\n",
            "Epoch 23/150 - 0.15s - loss: 0.8934 - acc: 0.5918 - val_loss: 0.9651 - val_acc: 0.5648\n",
            "Epoch 24/150 - 0.14s - loss: 0.8919 - acc: 0.5783 - val_loss: 0.9715 - val_acc: 0.5223\n",
            "Epoch 25/150 - 0.14s - loss: 0.8838 - acc: 0.5981 - val_loss: 0.9528 - val_acc: 0.5668\n",
            "Epoch 26/150 - 0.16s - loss: 0.8738 - acc: 0.6037 - val_loss: 0.9548 - val_acc: 0.5688\n",
            "Epoch 27/150 - 0.15s - loss: 0.8976 - acc: 0.5861 - val_loss: 0.9799 - val_acc: 0.5385\n",
            "Epoch 28/150 - 0.14s - loss: 0.8679 - acc: 0.6041 - val_loss: 0.9561 - val_acc: 0.5607\n",
            "Epoch 29/150 - 0.14s - loss: 0.8971 - acc: 0.5744 - val_loss: 0.9985 - val_acc: 0.4980\n",
            "Epoch 30/150 - 0.15s - loss: 0.8725 - acc: 0.5927 - val_loss: 0.9765 - val_acc: 0.4960\n",
            "Epoch 31/150 - 0.15s - loss: 0.8665 - acc: 0.6035 - val_loss: 0.9592 - val_acc: 0.5668\n",
            "Epoch 32/150 - 0.14s - loss: 0.9012 - acc: 0.5834 - val_loss: 0.9943 - val_acc: 0.5526\n",
            "Epoch 33/150 - 0.14s - loss: 0.8674 - acc: 0.6089 - val_loss: 0.9673 - val_acc: 0.5607\n",
            "Epoch 34/150 - 0.14s - loss: 0.8837 - acc: 0.5945 - val_loss: 0.9864 - val_acc: 0.5445\n",
            "Epoch 35/150 - 0.15s - loss: 0.8304 - acc: 0.6273 - val_loss: 0.9517 - val_acc: 0.5607\n",
            "Epoch 36/150 - 0.13s - loss: 0.8418 - acc: 0.6206 - val_loss: 0.9539 - val_acc: 0.5789\n",
            "Epoch 37/150 - 0.14s - loss: 0.8468 - acc: 0.6208 - val_loss: 0.9555 - val_acc: 0.5729\n",
            "Epoch 38/150 - 0.13s - loss: 0.8096 - acc: 0.6363 - val_loss: 0.9385 - val_acc: 0.5506\n",
            "Epoch 39/150 - 0.14s - loss: 0.8335 - acc: 0.6201 - val_loss: 0.9734 - val_acc: 0.5101\n",
            "Epoch 40/150 - 0.13s - loss: 0.8212 - acc: 0.6255 - val_loss: 0.9729 - val_acc: 0.5263\n",
            "Epoch 41/150 - 0.15s - loss: 0.8483 - acc: 0.6206 - val_loss: 0.9791 - val_acc: 0.5486\n",
            "Epoch 42/150 - 0.17s - loss: 0.8098 - acc: 0.6397 - val_loss: 0.9565 - val_acc: 0.5607\n",
            "Epoch 43/150 - 0.17s - loss: 0.7890 - acc: 0.6595 - val_loss: 0.9385 - val_acc: 0.5567\n",
            "Epoch 44/150 - 0.14s - loss: 0.7968 - acc: 0.6453 - val_loss: 0.9439 - val_acc: 0.5729\n",
            "Epoch 45/150 - 0.14s - loss: 0.7885 - acc: 0.6482 - val_loss: 0.9380 - val_acc: 0.5911\n",
            "Epoch 46/150 - 0.13s - loss: 0.7768 - acc: 0.6559 - val_loss: 0.9261 - val_acc: 0.5850\n",
            "Epoch 47/150 - 0.14s - loss: 0.7993 - acc: 0.6224 - val_loss: 0.9558 - val_acc: 0.5304\n",
            "Epoch 48/150 - 0.13s - loss: 0.7701 - acc: 0.6577 - val_loss: 0.9412 - val_acc: 0.5769\n",
            "Epoch 49/150 - 0.13s - loss: 0.7562 - acc: 0.6732 - val_loss: 0.9452 - val_acc: 0.5648\n",
            "Epoch 50/150 - 0.13s - loss: 0.7505 - acc: 0.6788 - val_loss: 0.9375 - val_acc: 0.5628\n",
            "Epoch 51/150 - 0.14s - loss: 0.7475 - acc: 0.6754 - val_loss: 0.9493 - val_acc: 0.5648\n",
            "Epoch 52/150 - 0.13s - loss: 0.8128 - acc: 0.6228 - val_loss: 1.0052 - val_acc: 0.5425\n",
            "Epoch 53/150 - 0.13s - loss: 0.7337 - acc: 0.6860 - val_loss: 0.9386 - val_acc: 0.5668\n",
            "Epoch 54/150 - 0.15s - loss: 0.7472 - acc: 0.6804 - val_loss: 0.9487 - val_acc: 0.5526\n",
            "Epoch 55/150 - 0.14s - loss: 0.7723 - acc: 0.6408 - val_loss: 0.9709 - val_acc: 0.5526\n",
            "Epoch 56/150 - 0.13s - loss: 0.7452 - acc: 0.6736 - val_loss: 0.9546 - val_acc: 0.5486\n",
            "Epoch 57/150 - 0.14s - loss: 0.8279 - acc: 0.6284 - val_loss: 1.0292 - val_acc: 0.5526\n",
            "Epoch 58/150 - 0.13s - loss: 0.7132 - acc: 0.6977 - val_loss: 0.9342 - val_acc: 0.5749\n",
            "Epoch 59/150 - 0.15s - loss: 0.8174 - acc: 0.6152 - val_loss: 1.0537 - val_acc: 0.5405\n",
            "Epoch 60/150 - 0.14s - loss: 0.7084 - acc: 0.7013 - val_loss: 0.9441 - val_acc: 0.5648\n",
            "Epoch 61/150 - 0.15s - loss: 0.7262 - acc: 0.6808 - val_loss: 0.9581 - val_acc: 0.5567\n",
            "Epoch 62/150 - 0.16s - loss: 0.7094 - acc: 0.6932 - val_loss: 0.9595 - val_acc: 0.5506\n",
            "Epoch 63/150 - 0.17s - loss: 0.6932 - acc: 0.7022 - val_loss: 0.9599 - val_acc: 0.5486\n",
            "Epoch 64/150 - 0.14s - loss: 0.6877 - acc: 0.7119 - val_loss: 0.9410 - val_acc: 0.5810\n",
            "Epoch 65/150 - 0.14s - loss: 0.6781 - acc: 0.7197 - val_loss: 0.9484 - val_acc: 0.5607\n",
            "Epoch 66/150 - 0.14s - loss: 0.6830 - acc: 0.7087 - val_loss: 0.9623 - val_acc: 0.5486\n",
            "Epoch 67/150 - 0.15s - loss: 0.6684 - acc: 0.7197 - val_loss: 0.9664 - val_acc: 0.5486\n",
            "Epoch 68/150 - 0.13s - loss: 0.7375 - acc: 0.6739 - val_loss: 1.0413 - val_acc: 0.5283\n",
            "Epoch 69/150 - 0.14s - loss: 0.7304 - acc: 0.6754 - val_loss: 1.0186 - val_acc: 0.5202\n",
            "Epoch 70/150 - 0.14s - loss: 0.7571 - acc: 0.6613 - val_loss: 1.0447 - val_acc: 0.5628\n",
            "Epoch 71/150 - 0.16s - loss: 0.6870 - acc: 0.6961 - val_loss: 0.9855 - val_acc: 0.5607\n",
            "Epoch 72/150 - 0.14s - loss: 0.6268 - acc: 0.7400 - val_loss: 0.9540 - val_acc: 0.5587\n",
            "Epoch 73/150 - 0.16s - loss: 0.6720 - acc: 0.7099 - val_loss: 0.9913 - val_acc: 0.5506\n",
            "Epoch 74/150 - 0.14s - loss: 0.6635 - acc: 0.7110 - val_loss: 1.0026 - val_acc: 0.5628\n",
            "Epoch 75/150 - 0.16s - loss: 0.6054 - acc: 0.7620 - val_loss: 0.9455 - val_acc: 0.5709\n",
            "Epoch 76/150 - 0.14s - loss: 0.6843 - acc: 0.6937 - val_loss: 1.0064 - val_acc: 0.5688\n",
            "Epoch 77/150 - 0.15s - loss: 0.6691 - acc: 0.6966 - val_loss: 0.9938 - val_acc: 0.5587\n",
            "Epoch 78/150 - 0.16s - loss: 0.6325 - acc: 0.7355 - val_loss: 0.9848 - val_acc: 0.5648\n",
            "Epoch 79/150 - 0.16s - loss: 0.7220 - acc: 0.6752 - val_loss: 1.1162 - val_acc: 0.5101\n",
            "Epoch 80/150 - 0.15s - loss: 0.5722 - acc: 0.7814 - val_loss: 0.9532 - val_acc: 0.5709\n",
            "Epoch 81/150 - 0.15s - loss: 0.6187 - acc: 0.7364 - val_loss: 1.0004 - val_acc: 0.5648\n",
            "Epoch 82/150 - 0.14s - loss: 0.6452 - acc: 0.7251 - val_loss: 1.0481 - val_acc: 0.5283\n",
            "Epoch 83/150 - 0.15s - loss: 0.5818 - acc: 0.7600 - val_loss: 1.0029 - val_acc: 0.5607\n",
            "Epoch 84/150 - 0.14s - loss: 0.5820 - acc: 0.7629 - val_loss: 0.9965 - val_acc: 0.5607\n",
            "Epoch 85/150 - 0.14s - loss: 0.5453 - acc: 0.7895 - val_loss: 0.9591 - val_acc: 0.5729\n",
            "Epoch 86/150 - 0.14s - loss: 0.5612 - acc: 0.7726 - val_loss: 0.9771 - val_acc: 0.5749\n",
            "Epoch 87/150 - 0.22s - loss: 0.5470 - acc: 0.7892 - val_loss: 0.9723 - val_acc: 0.5709\n",
            "Epoch 88/150 - 0.15s - loss: 0.5285 - acc: 0.7908 - val_loss: 0.9737 - val_acc: 0.5810\n",
            "Epoch 89/150 - 0.14s - loss: 0.5663 - acc: 0.7717 - val_loss: 1.0378 - val_acc: 0.5466\n",
            "Epoch 90/150 - 0.14s - loss: 0.5694 - acc: 0.7654 - val_loss: 1.0798 - val_acc: 0.5304\n",
            "Epoch 91/150 - 0.16s - loss: 0.6227 - acc: 0.7265 - val_loss: 1.1096 - val_acc: 0.5344\n",
            "Epoch 92/150 - 0.15s - loss: 0.5673 - acc: 0.7548 - val_loss: 1.0244 - val_acc: 0.5668\n",
            "Epoch 93/150 - 0.15s - loss: 0.4884 - acc: 0.8187 - val_loss: 0.9911 - val_acc: 0.5526\n",
            "Epoch 94/150 - 0.14s - loss: 0.5968 - acc: 0.7436 - val_loss: 1.1143 - val_acc: 0.5223\n",
            "Epoch 95/150 - 0.16s - loss: 0.5514 - acc: 0.7740 - val_loss: 1.0523 - val_acc: 0.5486\n",
            "Epoch 96/150 - 0.15s - loss: 0.5833 - acc: 0.7481 - val_loss: 1.1166 - val_acc: 0.5466\n",
            "Epoch 97/150 - 0.15s - loss: 0.5471 - acc: 0.7641 - val_loss: 1.0410 - val_acc: 0.5607\n",
            "Epoch 98/150 - 0.14s - loss: 0.5816 - acc: 0.7409 - val_loss: 1.0922 - val_acc: 0.5486\n",
            "Epoch 99/150 - 0.14s - loss: 0.5201 - acc: 0.7863 - val_loss: 1.0850 - val_acc: 0.5607\n",
            "Epoch 100/150 - 0.15s - loss: 0.5704 - acc: 0.7492 - val_loss: 1.1515 - val_acc: 0.5385\n",
            "Epoch 101/150 - 0.15s - loss: 0.5746 - acc: 0.7418 - val_loss: 1.1462 - val_acc: 0.5283\n",
            "Epoch 102/150 - 0.16s - loss: 0.4280 - acc: 0.8412 - val_loss: 0.9856 - val_acc: 0.5789\n",
            "Epoch 103/150 - 0.15s - loss: 0.7451 - acc: 0.6473 - val_loss: 1.2718 - val_acc: 0.5182\n",
            "Epoch 104/150 - 0.14s - loss: 0.4533 - acc: 0.8225 - val_loss: 1.0878 - val_acc: 0.5547\n",
            "Epoch 105/150 - 0.13s - loss: 0.5253 - acc: 0.7796 - val_loss: 1.1688 - val_acc: 0.5364\n",
            "Epoch 106/150 - 0.13s - loss: 0.4051 - acc: 0.8565 - val_loss: 1.0138 - val_acc: 0.5668\n",
            "Epoch 107/150 - 0.16s - loss: 0.3886 - acc: 0.8621 - val_loss: 1.0042 - val_acc: 0.5850\n",
            "Epoch 108/150 - 0.15s - loss: 0.3833 - acc: 0.8682 - val_loss: 1.0103 - val_acc: 0.5668\n",
            "Epoch 109/150 - 0.16s - loss: 0.5739 - acc: 0.7562 - val_loss: 1.2260 - val_acc: 0.5526\n",
            "Epoch 110/150 - 0.14s - loss: 0.4052 - acc: 0.8473 - val_loss: 1.0412 - val_acc: 0.5688\n",
            "Epoch 111/150 - 0.15s - loss: 0.5187 - acc: 0.7609 - val_loss: 1.1433 - val_acc: 0.5445\n",
            "Epoch 112/150 - 0.13s - loss: 0.4594 - acc: 0.7949 - val_loss: 1.1134 - val_acc: 0.5526\n",
            "Epoch 113/150 - 0.14s - loss: 0.3942 - acc: 0.8605 - val_loss: 1.0403 - val_acc: 0.5688\n",
            "Epoch 114/150 - 0.13s - loss: 0.3726 - acc: 0.8720 - val_loss: 1.0574 - val_acc: 0.5628\n",
            "Epoch 115/150 - 0.15s - loss: 0.4031 - acc: 0.8578 - val_loss: 1.0855 - val_acc: 0.5587\n",
            "Epoch 116/150 - 0.16s - loss: 0.3296 - acc: 0.8891 - val_loss: 1.0686 - val_acc: 0.5789\n",
            "Epoch 117/150 - 0.18s - loss: 0.3099 - acc: 0.9100 - val_loss: 1.0617 - val_acc: 0.5668\n",
            "Epoch 118/150 - 0.15s - loss: 0.3997 - acc: 0.8367 - val_loss: 1.1056 - val_acc: 0.5607\n",
            "Epoch 119/150 - 0.18s - loss: 0.3756 - acc: 0.8471 - val_loss: 1.0865 - val_acc: 0.5850\n",
            "Epoch 120/150 - 0.14s - loss: 0.4994 - acc: 0.7627 - val_loss: 1.2234 - val_acc: 0.5344\n",
            "Epoch 121/150 - 0.16s - loss: 0.3285 - acc: 0.8914 - val_loss: 1.0963 - val_acc: 0.5749\n",
            "Epoch 122/150 - 0.14s - loss: 0.3325 - acc: 0.8808 - val_loss: 1.1718 - val_acc: 0.5709\n",
            "Epoch 123/150 - 0.15s - loss: 0.2707 - acc: 0.9159 - val_loss: 1.0982 - val_acc: 0.5769\n",
            "Epoch 124/150 - 0.14s - loss: 0.2780 - acc: 0.9170 - val_loss: 1.0602 - val_acc: 0.5972\n",
            "Epoch 125/150 - 0.15s - loss: 0.2966 - acc: 0.9015 - val_loss: 1.1670 - val_acc: 0.5607\n",
            "Epoch 126/150 - 0.14s - loss: 0.3675 - acc: 0.8455 - val_loss: 1.2226 - val_acc: 0.5648\n",
            "Epoch 127/150 - 0.14s - loss: 0.2703 - acc: 0.9204 - val_loss: 1.1374 - val_acc: 0.5445\n",
            "Epoch 128/150 - 0.17s - loss: 0.3023 - acc: 0.8842 - val_loss: 1.1697 - val_acc: 0.5769\n",
            "Epoch 129/150 - 0.24s - loss: 0.3319 - acc: 0.8851 - val_loss: 1.1737 - val_acc: 0.5486\n",
            "Epoch 130/150 - 0.15s - loss: 0.2369 - acc: 0.9386 - val_loss: 1.1802 - val_acc: 0.5870\n",
            "Epoch 131/150 - 0.17s - loss: 0.2431 - acc: 0.9285 - val_loss: 1.2027 - val_acc: 0.5688\n",
            "Epoch 132/150 - 0.15s - loss: 0.2444 - acc: 0.9330 - val_loss: 1.2021 - val_acc: 0.5587\n",
            "Epoch 133/150 - 0.15s - loss: 0.3881 - acc: 0.8383 - val_loss: 1.2476 - val_acc: 0.5547\n",
            "Epoch 134/150 - 0.15s - loss: 0.6454 - acc: 0.7042 - val_loss: 1.6243 - val_acc: 0.4980\n",
            "Epoch 135/150 - 0.16s - loss: 0.3006 - acc: 0.8945 - val_loss: 1.1189 - val_acc: 0.5850\n",
            "Epoch 136/150 - 0.14s - loss: 0.3432 - acc: 0.8504 - val_loss: 1.3065 - val_acc: 0.5425\n",
            "Epoch 137/150 - 0.14s - loss: 0.7208 - acc: 0.6637 - val_loss: 1.7892 - val_acc: 0.4757\n",
            "Epoch 138/150 - 0.14s - loss: 0.4573 - acc: 0.7949 - val_loss: 1.3851 - val_acc: 0.5445\n",
            "Epoch 139/150 - 0.15s - loss: 0.2654 - acc: 0.9046 - val_loss: 1.3353 - val_acc: 0.5526\n",
            "Epoch 140/150 - 0.13s - loss: 0.1885 - acc: 0.9503 - val_loss: 1.2175 - val_acc: 0.5870\n",
            "Epoch 141/150 - 0.14s - loss: 0.1775 - acc: 0.9584 - val_loss: 1.2749 - val_acc: 0.5891\n",
            "Epoch 142/150 - 0.14s - loss: 0.2039 - acc: 0.9453 - val_loss: 1.2244 - val_acc: 0.5769\n",
            "Epoch 143/150 - 0.14s - loss: 0.2682 - acc: 0.8905 - val_loss: 1.4131 - val_acc: 0.5628\n",
            "Epoch 144/150 - 0.17s - loss: 0.3231 - acc: 0.8614 - val_loss: 1.3991 - val_acc: 0.5789\n",
            "Epoch 145/150 - 0.15s - loss: 0.3024 - acc: 0.8788 - val_loss: 1.3481 - val_acc: 0.5526\n",
            "Epoch 146/150 - 0.14s - loss: 0.1821 - acc: 0.9530 - val_loss: 1.2951 - val_acc: 0.5688\n",
            "Epoch 147/150 - 0.14s - loss: 0.1492 - acc: 0.9640 - val_loss: 1.2385 - val_acc: 0.5870\n",
            "Epoch 148/150 - 0.14s - loss: 0.1544 - acc: 0.9629 - val_loss: 1.2573 - val_acc: 0.5870\n",
            "Epoch 149/150 - 0.14s - loss: 0.1706 - acc: 0.9611 - val_loss: 1.2789 - val_acc: 0.5870\n",
            "Epoch 150/150 - 0.14s - loss: 0.1573 - acc: 0.9593 - val_loss: 1.3442 - val_acc: 0.5810\n",
            "\n",
            "Combination 184/252:\n",
            "Hidden Layers: [256, 128, 64], Activation: relu, Learning Rate: 0.01, Batch Size: 64, Epochs: 50\n",
            "Epoch 1/50 - 0.13s - loss: 1.0767 - acc: 0.4274 - val_loss: 1.0855 - val_acc: 0.3765\n",
            "Epoch 2/50 - 0.11s - loss: 1.0629 - acc: 0.4530 - val_loss: 1.0726 - val_acc: 0.4170\n",
            "Epoch 3/50 - 0.10s - loss: 1.0544 - acc: 0.4591 - val_loss: 1.0683 - val_acc: 0.4251\n",
            "Epoch 4/50 - 0.10s - loss: 1.0475 - acc: 0.4674 - val_loss: 1.0650 - val_acc: 0.4453\n",
            "Epoch 5/50 - 0.10s - loss: 1.0406 - acc: 0.4802 - val_loss: 1.0594 - val_acc: 0.4595\n",
            "Epoch 6/50 - 0.11s - loss: 1.0351 - acc: 0.4816 - val_loss: 1.0555 - val_acc: 0.4636\n",
            "Epoch 7/50 - 0.10s - loss: 1.0293 - acc: 0.4912 - val_loss: 1.0524 - val_acc: 0.4534\n",
            "Epoch 8/50 - 0.10s - loss: 1.0255 - acc: 0.4915 - val_loss: 1.0506 - val_acc: 0.4595\n",
            "Epoch 9/50 - 0.10s - loss: 1.0214 - acc: 0.4971 - val_loss: 1.0468 - val_acc: 0.4798\n",
            "Epoch 10/50 - 0.11s - loss: 1.0134 - acc: 0.5020 - val_loss: 1.0442 - val_acc: 0.4858\n",
            "Epoch 11/50 - 0.10s - loss: 1.0077 - acc: 0.5052 - val_loss: 1.0403 - val_acc: 0.4798\n",
            "Epoch 12/50 - 0.10s - loss: 1.0030 - acc: 0.5088 - val_loss: 1.0367 - val_acc: 0.4879\n",
            "Epoch 13/50 - 0.10s - loss: 0.9988 - acc: 0.5142 - val_loss: 1.0324 - val_acc: 0.5101\n",
            "Epoch 14/50 - 0.11s - loss: 0.9932 - acc: 0.5227 - val_loss: 1.0293 - val_acc: 0.4798\n",
            "Epoch 15/50 - 0.12s - loss: 0.9875 - acc: 0.5223 - val_loss: 1.0229 - val_acc: 0.5162\n",
            "Epoch 16/50 - 0.10s - loss: 0.9827 - acc: 0.5286 - val_loss: 1.0189 - val_acc: 0.5061\n",
            "Epoch 17/50 - 0.10s - loss: 1.0015 - acc: 0.4903 - val_loss: 1.0469 - val_acc: 0.4271\n",
            "Epoch 18/50 - 0.10s - loss: 0.9732 - acc: 0.5295 - val_loss: 1.0120 - val_acc: 0.5202\n",
            "Epoch 19/50 - 0.12s - loss: 0.9715 - acc: 0.5380 - val_loss: 1.0162 - val_acc: 0.4798\n",
            "Epoch 20/50 - 0.11s - loss: 0.9773 - acc: 0.5292 - val_loss: 1.0175 - val_acc: 0.5162\n",
            "Epoch 21/50 - 0.11s - loss: 0.9609 - acc: 0.5439 - val_loss: 1.0047 - val_acc: 0.5364\n",
            "Epoch 22/50 - 0.12s - loss: 0.9811 - acc: 0.5099 - val_loss: 1.0331 - val_acc: 0.4575\n",
            "Epoch 23/50 - 0.11s - loss: 0.9556 - acc: 0.5434 - val_loss: 1.0005 - val_acc: 0.5263\n",
            "Epoch 24/50 - 0.14s - loss: 0.9425 - acc: 0.5547 - val_loss: 0.9916 - val_acc: 0.5263\n",
            "Epoch 25/50 - 0.11s - loss: 0.9441 - acc: 0.5513 - val_loss: 0.9923 - val_acc: 0.5385\n",
            "Epoch 26/50 - 0.12s - loss: 0.9445 - acc: 0.5535 - val_loss: 0.9977 - val_acc: 0.5101\n",
            "Epoch 27/50 - 0.10s - loss: 0.9332 - acc: 0.5558 - val_loss: 0.9872 - val_acc: 0.5324\n",
            "Epoch 28/50 - 0.12s - loss: 0.9284 - acc: 0.5641 - val_loss: 0.9798 - val_acc: 0.5364\n",
            "Epoch 29/50 - 0.13s - loss: 0.9234 - acc: 0.5668 - val_loss: 0.9794 - val_acc: 0.5243\n",
            "Epoch 30/50 - 0.12s - loss: 0.9322 - acc: 0.5479 - val_loss: 0.9899 - val_acc: 0.5425\n",
            "Epoch 31/50 - 0.13s - loss: 0.9163 - acc: 0.5715 - val_loss: 0.9793 - val_acc: 0.5283\n",
            "Epoch 32/50 - 0.13s - loss: 0.9145 - acc: 0.5691 - val_loss: 0.9726 - val_acc: 0.5425\n",
            "Epoch 33/50 - 0.11s - loss: 0.9797 - acc: 0.5117 - val_loss: 1.0558 - val_acc: 0.4494\n",
            "Epoch 34/50 - 0.11s - loss: 0.9059 - acc: 0.5771 - val_loss: 0.9720 - val_acc: 0.5385\n",
            "Epoch 35/50 - 0.11s - loss: 0.9347 - acc: 0.5502 - val_loss: 0.9917 - val_acc: 0.5283\n",
            "Epoch 36/50 - 0.12s - loss: 0.9035 - acc: 0.5729 - val_loss: 0.9674 - val_acc: 0.5364\n",
            "Epoch 37/50 - 0.11s - loss: 0.8966 - acc: 0.5816 - val_loss: 0.9672 - val_acc: 0.5506\n",
            "Epoch 38/50 - 0.11s - loss: 0.9219 - acc: 0.5639 - val_loss: 0.9838 - val_acc: 0.5364\n",
            "Epoch 39/50 - 0.10s - loss: 0.8883 - acc: 0.5891 - val_loss: 0.9622 - val_acc: 0.5385\n",
            "Epoch 40/50 - 0.11s - loss: 0.9064 - acc: 0.5693 - val_loss: 0.9742 - val_acc: 0.5547\n",
            "Epoch 41/50 - 0.10s - loss: 0.8822 - acc: 0.5904 - val_loss: 0.9602 - val_acc: 0.5425\n",
            "Epoch 42/50 - 0.10s - loss: 0.8941 - acc: 0.5821 - val_loss: 0.9824 - val_acc: 0.5223\n",
            "Epoch 43/50 - 0.10s - loss: 0.8946 - acc: 0.5801 - val_loss: 0.9829 - val_acc: 0.5142\n",
            "Epoch 44/50 - 0.11s - loss: 0.8853 - acc: 0.5816 - val_loss: 0.9610 - val_acc: 0.5385\n",
            "Epoch 45/50 - 0.10s - loss: 0.8789 - acc: 0.5940 - val_loss: 0.9587 - val_acc: 0.5486\n",
            "Epoch 46/50 - 0.10s - loss: 0.9419 - acc: 0.5470 - val_loss: 1.0416 - val_acc: 0.4818\n",
            "Epoch 47/50 - 0.12s - loss: 0.9221 - acc: 0.5670 - val_loss: 1.0005 - val_acc: 0.5324\n",
            "Epoch 48/50 - 0.14s - loss: 0.8672 - acc: 0.5996 - val_loss: 0.9617 - val_acc: 0.5243\n",
            "Epoch 49/50 - 0.13s - loss: 0.8921 - acc: 0.5697 - val_loss: 0.9734 - val_acc: 0.5324\n",
            "Epoch 50/50 - 0.12s - loss: 0.8728 - acc: 0.5945 - val_loss: 0.9661 - val_acc: 0.5425\n",
            "\n",
            "Combination 185/252:\n",
            "Hidden Layers: [256, 128, 64], Activation: relu, Learning Rate: 0.01, Batch Size: 64, Epochs: 100\n",
            "Epoch 1/100 - 0.14s - loss: 1.0829 - acc: 0.4006 - val_loss: 1.0848 - val_acc: 0.3907\n",
            "Epoch 2/100 - 0.13s - loss: 1.0744 - acc: 0.4280 - val_loss: 1.0786 - val_acc: 0.4089\n",
            "Epoch 3/100 - 0.12s - loss: 1.0671 - acc: 0.4462 - val_loss: 1.0735 - val_acc: 0.4150\n",
            "Epoch 4/100 - 0.17s - loss: 1.0605 - acc: 0.4550 - val_loss: 1.0690 - val_acc: 0.4190\n",
            "Epoch 5/100 - 0.14s - loss: 1.0546 - acc: 0.4678 - val_loss: 1.0647 - val_acc: 0.4291\n",
            "Epoch 6/100 - 0.12s - loss: 1.0484 - acc: 0.4730 - val_loss: 1.0603 - val_acc: 0.4413\n",
            "Epoch 7/100 - 0.13s - loss: 1.0428 - acc: 0.4757 - val_loss: 1.0568 - val_acc: 0.4494\n",
            "Epoch 8/100 - 0.11s - loss: 1.0372 - acc: 0.4816 - val_loss: 1.0528 - val_acc: 0.4555\n",
            "Epoch 9/100 - 0.11s - loss: 1.0309 - acc: 0.4881 - val_loss: 1.0487 - val_acc: 0.4514\n",
            "Epoch 10/100 - 0.12s - loss: 1.0257 - acc: 0.4937 - val_loss: 1.0451 - val_acc: 0.4575\n",
            "Epoch 11/100 - 0.11s - loss: 1.0208 - acc: 0.4971 - val_loss: 1.0426 - val_acc: 0.4939\n",
            "Epoch 12/100 - 0.13s - loss: 1.0151 - acc: 0.4984 - val_loss: 1.0415 - val_acc: 0.4595\n",
            "Epoch 13/100 - 0.11s - loss: 1.0099 - acc: 0.5029 - val_loss: 1.0386 - val_acc: 0.4757\n",
            "Epoch 14/100 - 0.10s - loss: 1.0029 - acc: 0.5099 - val_loss: 1.0333 - val_acc: 0.4838\n",
            "Epoch 15/100 - 0.13s - loss: 0.9975 - acc: 0.5128 - val_loss: 1.0293 - val_acc: 0.5040\n",
            "Epoch 16/100 - 0.11s - loss: 0.9930 - acc: 0.5178 - val_loss: 1.0268 - val_acc: 0.5061\n",
            "Epoch 17/100 - 0.10s - loss: 0.9888 - acc: 0.5245 - val_loss: 1.0258 - val_acc: 0.4919\n",
            "Epoch 18/100 - 0.11s - loss: 0.9892 - acc: 0.5099 - val_loss: 1.0288 - val_acc: 0.4798\n",
            "Epoch 19/100 - 0.11s - loss: 0.9783 - acc: 0.5238 - val_loss: 1.0169 - val_acc: 0.5162\n",
            "Epoch 20/100 - 0.12s - loss: 0.9744 - acc: 0.5342 - val_loss: 1.0167 - val_acc: 0.5000\n",
            "Epoch 21/100 - 0.10s - loss: 0.9692 - acc: 0.5331 - val_loss: 1.0106 - val_acc: 0.5202\n",
            "Epoch 22/100 - 0.10s - loss: 0.9668 - acc: 0.5391 - val_loss: 1.0100 - val_acc: 0.5101\n",
            "Epoch 23/100 - 0.10s - loss: 0.9606 - acc: 0.5396 - val_loss: 1.0067 - val_acc: 0.5223\n",
            "Epoch 24/100 - 0.12s - loss: 0.9591 - acc: 0.5398 - val_loss: 1.0079 - val_acc: 0.5061\n",
            "Epoch 25/100 - 0.10s - loss: 0.9577 - acc: 0.5409 - val_loss: 1.0085 - val_acc: 0.5000\n",
            "Epoch 26/100 - 0.10s - loss: 0.9645 - acc: 0.5209 - val_loss: 1.0163 - val_acc: 0.4818\n",
            "Epoch 27/100 - 0.11s - loss: 0.9531 - acc: 0.5472 - val_loss: 0.9995 - val_acc: 0.5405\n",
            "Epoch 28/100 - 0.11s - loss: 0.9475 - acc: 0.5407 - val_loss: 1.0021 - val_acc: 0.5142\n",
            "Epoch 29/100 - 0.15s - loss: 0.9698 - acc: 0.5315 - val_loss: 1.0129 - val_acc: 0.5263\n",
            "Epoch 30/100 - 0.13s - loss: 0.9397 - acc: 0.5511 - val_loss: 0.9925 - val_acc: 0.5263\n",
            "Epoch 31/100 - 0.13s - loss: 0.9339 - acc: 0.5567 - val_loss: 0.9915 - val_acc: 0.5182\n",
            "Epoch 32/100 - 0.12s - loss: 0.9290 - acc: 0.5634 - val_loss: 0.9850 - val_acc: 0.5486\n",
            "Epoch 33/100 - 0.16s - loss: 0.9342 - acc: 0.5580 - val_loss: 0.9876 - val_acc: 0.5466\n",
            "Epoch 34/100 - 0.11s - loss: 0.9226 - acc: 0.5657 - val_loss: 0.9831 - val_acc: 0.5324\n",
            "Epoch 35/100 - 0.11s - loss: 0.9294 - acc: 0.5634 - val_loss: 0.9843 - val_acc: 0.5547\n",
            "Epoch 36/100 - 0.11s - loss: 0.9299 - acc: 0.5625 - val_loss: 0.9856 - val_acc: 0.5526\n",
            "Epoch 37/100 - 0.12s - loss: 0.9226 - acc: 0.5632 - val_loss: 0.9923 - val_acc: 0.5061\n",
            "Epoch 38/100 - 0.10s - loss: 0.9183 - acc: 0.5632 - val_loss: 0.9877 - val_acc: 0.5202\n",
            "Epoch 39/100 - 0.10s - loss: 0.9170 - acc: 0.5664 - val_loss: 0.9778 - val_acc: 0.5466\n",
            "Epoch 40/100 - 0.10s - loss: 0.9242 - acc: 0.5562 - val_loss: 0.9995 - val_acc: 0.5000\n",
            "Epoch 41/100 - 0.12s - loss: 0.9213 - acc: 0.5580 - val_loss: 0.9988 - val_acc: 0.5081\n",
            "Epoch 42/100 - 0.10s - loss: 0.9134 - acc: 0.5682 - val_loss: 0.9920 - val_acc: 0.5182\n",
            "Epoch 43/100 - 0.10s - loss: 0.8957 - acc: 0.5812 - val_loss: 0.9703 - val_acc: 0.5486\n",
            "Epoch 44/100 - 0.10s - loss: 0.8963 - acc: 0.5792 - val_loss: 0.9742 - val_acc: 0.5385\n",
            "Epoch 45/100 - 0.10s - loss: 0.8900 - acc: 0.5832 - val_loss: 0.9688 - val_acc: 0.5425\n",
            "Epoch 46/100 - 0.11s - loss: 0.9071 - acc: 0.5693 - val_loss: 0.9942 - val_acc: 0.5121\n",
            "Epoch 47/100 - 0.15s - loss: 0.8928 - acc: 0.5823 - val_loss: 0.9694 - val_acc: 0.5587\n",
            "Epoch 48/100 - 0.11s - loss: 0.8860 - acc: 0.5900 - val_loss: 0.9642 - val_acc: 0.5526\n",
            "Epoch 49/100 - 0.11s - loss: 0.8798 - acc: 0.5927 - val_loss: 0.9696 - val_acc: 0.5405\n",
            "Epoch 50/100 - 0.11s - loss: 0.9013 - acc: 0.5688 - val_loss: 1.0004 - val_acc: 0.4980\n",
            "Epoch 51/100 - 0.10s - loss: 0.9769 - acc: 0.5364 - val_loss: 1.0408 - val_acc: 0.5263\n",
            "Epoch 52/100 - 0.12s - loss: 0.8971 - acc: 0.5801 - val_loss: 0.9767 - val_acc: 0.5567\n",
            "Epoch 53/100 - 0.15s - loss: 0.8673 - acc: 0.5985 - val_loss: 0.9613 - val_acc: 0.5526\n",
            "Epoch 54/100 - 0.12s - loss: 0.8699 - acc: 0.5967 - val_loss: 0.9661 - val_acc: 0.5324\n",
            "Epoch 55/100 - 0.13s - loss: 0.8656 - acc: 0.5981 - val_loss: 0.9634 - val_acc: 0.5283\n",
            "Epoch 56/100 - 0.13s - loss: 0.8593 - acc: 0.6059 - val_loss: 0.9567 - val_acc: 0.5466\n",
            "Epoch 57/100 - 0.11s - loss: 0.8602 - acc: 0.6037 - val_loss: 0.9580 - val_acc: 0.5405\n",
            "Epoch 58/100 - 0.11s - loss: 0.8527 - acc: 0.6089 - val_loss: 0.9581 - val_acc: 0.5425\n",
            "Epoch 59/100 - 0.11s - loss: 0.8703 - acc: 0.5965 - val_loss: 0.9694 - val_acc: 0.5405\n",
            "Epoch 60/100 - 0.14s - loss: 0.8780 - acc: 0.5868 - val_loss: 0.9695 - val_acc: 0.5466\n",
            "Epoch 61/100 - 0.11s - loss: 0.8565 - acc: 0.6059 - val_loss: 0.9562 - val_acc: 0.5547\n",
            "Epoch 62/100 - 0.11s - loss: 0.8648 - acc: 0.6017 - val_loss: 0.9671 - val_acc: 0.5466\n",
            "Epoch 63/100 - 0.10s - loss: 0.9203 - acc: 0.5520 - val_loss: 1.0544 - val_acc: 0.4737\n",
            "Epoch 64/100 - 0.15s - loss: 1.0253 - acc: 0.5274 - val_loss: 1.1008 - val_acc: 0.4960\n",
            "Epoch 65/100 - 0.11s - loss: 0.8439 - acc: 0.6152 - val_loss: 0.9689 - val_acc: 0.5263\n",
            "Epoch 66/100 - 0.10s - loss: 0.8550 - acc: 0.6059 - val_loss: 0.9698 - val_acc: 0.5405\n",
            "Epoch 67/100 - 0.09s - loss: 0.8594 - acc: 0.6008 - val_loss: 0.9754 - val_acc: 0.5445\n",
            "Epoch 68/100 - 0.11s - loss: 0.8314 - acc: 0.6278 - val_loss: 0.9610 - val_acc: 0.5364\n",
            "Epoch 69/100 - 0.10s - loss: 0.8314 - acc: 0.6221 - val_loss: 0.9619 - val_acc: 0.5304\n",
            "Epoch 70/100 - 0.11s - loss: 0.8400 - acc: 0.6129 - val_loss: 0.9686 - val_acc: 0.5283\n",
            "Epoch 71/100 - 0.11s - loss: 0.8184 - acc: 0.6314 - val_loss: 0.9525 - val_acc: 0.5385\n",
            "Epoch 72/100 - 0.10s - loss: 0.8607 - acc: 0.6046 - val_loss: 0.9762 - val_acc: 0.5506\n",
            "Epoch 73/100 - 0.12s - loss: 0.8157 - acc: 0.6336 - val_loss: 0.9506 - val_acc: 0.5405\n",
            "Epoch 74/100 - 0.10s - loss: 0.8160 - acc: 0.6327 - val_loss: 0.9561 - val_acc: 0.5547\n",
            "Epoch 75/100 - 0.10s - loss: 0.8125 - acc: 0.6417 - val_loss: 0.9616 - val_acc: 0.5344\n",
            "Epoch 76/100 - 0.12s - loss: 0.8150 - acc: 0.6311 - val_loss: 0.9554 - val_acc: 0.5364\n",
            "Epoch 77/100 - 0.13s - loss: 0.8299 - acc: 0.6224 - val_loss: 0.9945 - val_acc: 0.5142\n",
            "Epoch 78/100 - 0.13s - loss: 0.8124 - acc: 0.6388 - val_loss: 0.9580 - val_acc: 0.5587\n",
            "Epoch 79/100 - 0.14s - loss: 1.0190 - acc: 0.5112 - val_loss: 1.2056 - val_acc: 0.4474\n",
            "Epoch 80/100 - 0.12s - loss: 0.8107 - acc: 0.6390 - val_loss: 0.9787 - val_acc: 0.5162\n",
            "Epoch 81/100 - 0.13s - loss: 0.7905 - acc: 0.6511 - val_loss: 0.9565 - val_acc: 0.5405\n",
            "Epoch 82/100 - 0.11s - loss: 0.8470 - acc: 0.6053 - val_loss: 0.9857 - val_acc: 0.5405\n",
            "Epoch 83/100 - 0.11s - loss: 0.7963 - acc: 0.6408 - val_loss: 0.9704 - val_acc: 0.5607\n",
            "Epoch 84/100 - 0.10s - loss: 0.8078 - acc: 0.6275 - val_loss: 0.9663 - val_acc: 0.5648\n",
            "Epoch 85/100 - 0.11s - loss: 0.8067 - acc: 0.6372 - val_loss: 0.9941 - val_acc: 0.5162\n",
            "Epoch 86/100 - 0.11s - loss: 0.7873 - acc: 0.6518 - val_loss: 0.9699 - val_acc: 0.5324\n",
            "Epoch 87/100 - 0.13s - loss: 0.8012 - acc: 0.6365 - val_loss: 0.9922 - val_acc: 0.5162\n",
            "Epoch 88/100 - 0.12s - loss: 0.8038 - acc: 0.6300 - val_loss: 0.9816 - val_acc: 0.5283\n",
            "Epoch 89/100 - 0.12s - loss: 0.7855 - acc: 0.6437 - val_loss: 0.9594 - val_acc: 0.5709\n",
            "Epoch 90/100 - 0.13s - loss: 0.7797 - acc: 0.6606 - val_loss: 0.9817 - val_acc: 0.5202\n",
            "Epoch 91/100 - 0.10s - loss: 0.7856 - acc: 0.6561 - val_loss: 0.9691 - val_acc: 0.5385\n",
            "Epoch 92/100 - 0.09s - loss: 0.7890 - acc: 0.6466 - val_loss: 1.0012 - val_acc: 0.5142\n",
            "Epoch 93/100 - 0.10s - loss: 0.8769 - acc: 0.5792 - val_loss: 1.0596 - val_acc: 0.4939\n",
            "Epoch 94/100 - 0.10s - loss: 0.7837 - acc: 0.6536 - val_loss: 0.9986 - val_acc: 0.5162\n",
            "Epoch 95/100 - 0.09s - loss: 0.7574 - acc: 0.6745 - val_loss: 0.9707 - val_acc: 0.5344\n",
            "Epoch 96/100 - 0.14s - loss: 0.7926 - acc: 0.6345 - val_loss: 1.0012 - val_acc: 0.5405\n",
            "Epoch 97/100 - 0.09s - loss: 0.8421 - acc: 0.6075 - val_loss: 1.0805 - val_acc: 0.5040\n",
            "Epoch 98/100 - 0.09s - loss: 0.7618 - acc: 0.6595 - val_loss: 0.9726 - val_acc: 0.5567\n",
            "Epoch 99/100 - 0.09s - loss: 0.7389 - acc: 0.6840 - val_loss: 0.9656 - val_acc: 0.5425\n",
            "Epoch 100/100 - 0.10s - loss: 0.7707 - acc: 0.6572 - val_loss: 0.9745 - val_acc: 0.5668\n",
            "\n",
            "Combination 186/252:\n",
            "Hidden Layers: [256, 128, 64], Activation: relu, Learning Rate: 0.01, Batch Size: 64, Epochs: 150\n",
            "Epoch 1/150 - 0.09s - loss: 1.0953 - acc: 0.3590 - val_loss: 1.0935 - val_acc: 0.3806\n",
            "Epoch 2/150 - 0.11s - loss: 1.0830 - acc: 0.4001 - val_loss: 1.0849 - val_acc: 0.4008\n",
            "Epoch 3/150 - 0.11s - loss: 1.0732 - acc: 0.4298 - val_loss: 1.0776 - val_acc: 0.4413\n",
            "Epoch 4/150 - 0.10s - loss: 1.0651 - acc: 0.4442 - val_loss: 1.0721 - val_acc: 0.4433\n",
            "Epoch 5/150 - 0.16s - loss: 1.0579 - acc: 0.4532 - val_loss: 1.0669 - val_acc: 0.4433\n",
            "Epoch 6/150 - 0.11s - loss: 1.0517 - acc: 0.4606 - val_loss: 1.0623 - val_acc: 0.4656\n",
            "Epoch 7/150 - 0.09s - loss: 1.0461 - acc: 0.4600 - val_loss: 1.0585 - val_acc: 0.4413\n",
            "Epoch 8/150 - 0.10s - loss: 1.0428 - acc: 0.4737 - val_loss: 1.0574 - val_acc: 0.4879\n",
            "Epoch 9/150 - 0.10s - loss: 1.0350 - acc: 0.4798 - val_loss: 1.0501 - val_acc: 0.4737\n",
            "Epoch 10/150 - 0.10s - loss: 1.0290 - acc: 0.4780 - val_loss: 1.0454 - val_acc: 0.4615\n",
            "Epoch 11/150 - 0.10s - loss: 1.0237 - acc: 0.4836 - val_loss: 1.0407 - val_acc: 0.4656\n",
            "Epoch 12/150 - 0.12s - loss: 1.0184 - acc: 0.4919 - val_loss: 1.0357 - val_acc: 0.4798\n",
            "Epoch 13/150 - 0.10s - loss: 1.0143 - acc: 0.4971 - val_loss: 1.0327 - val_acc: 0.5000\n",
            "Epoch 14/150 - 0.10s - loss: 1.0086 - acc: 0.5020 - val_loss: 1.0256 - val_acc: 0.4879\n",
            "Epoch 15/150 - 0.10s - loss: 1.0038 - acc: 0.5076 - val_loss: 1.0229 - val_acc: 0.5121\n",
            "Epoch 16/150 - 0.14s - loss: 0.9988 - acc: 0.5097 - val_loss: 1.0166 - val_acc: 0.5020\n",
            "Epoch 17/150 - 0.09s - loss: 0.9950 - acc: 0.5110 - val_loss: 1.0133 - val_acc: 0.5162\n",
            "Epoch 18/150 - 0.10s - loss: 0.9926 - acc: 0.5133 - val_loss: 1.0126 - val_acc: 0.5020\n",
            "Epoch 19/150 - 0.09s - loss: 0.9868 - acc: 0.5180 - val_loss: 1.0063 - val_acc: 0.5283\n",
            "Epoch 20/150 - 0.10s - loss: 0.9831 - acc: 0.5175 - val_loss: 1.0037 - val_acc: 0.5101\n",
            "Epoch 21/150 - 0.09s - loss: 0.9761 - acc: 0.5315 - val_loss: 0.9969 - val_acc: 0.5223\n",
            "Epoch 22/150 - 0.10s - loss: 0.9800 - acc: 0.5209 - val_loss: 1.0018 - val_acc: 0.5121\n",
            "Epoch 23/150 - 0.10s - loss: 0.9677 - acc: 0.5351 - val_loss: 0.9904 - val_acc: 0.5304\n",
            "Epoch 24/150 - 0.10s - loss: 0.9637 - acc: 0.5333 - val_loss: 0.9865 - val_acc: 0.5283\n",
            "Epoch 25/150 - 0.11s - loss: 0.9595 - acc: 0.5371 - val_loss: 0.9844 - val_acc: 0.5405\n",
            "Epoch 26/150 - 0.13s - loss: 0.9592 - acc: 0.5396 - val_loss: 0.9831 - val_acc: 0.5466\n",
            "Epoch 27/150 - 0.12s - loss: 0.9526 - acc: 0.5423 - val_loss: 0.9791 - val_acc: 0.5486\n",
            "Epoch 28/150 - 0.11s - loss: 0.9731 - acc: 0.5200 - val_loss: 1.0036 - val_acc: 0.5040\n",
            "Epoch 29/150 - 0.11s - loss: 0.9456 - acc: 0.5459 - val_loss: 0.9753 - val_acc: 0.5405\n",
            "Epoch 30/150 - 0.14s - loss: 0.9528 - acc: 0.5362 - val_loss: 0.9807 - val_acc: 0.5526\n",
            "Epoch 31/150 - 0.11s - loss: 0.9397 - acc: 0.5517 - val_loss: 0.9711 - val_acc: 0.5466\n",
            "Epoch 32/150 - 0.14s - loss: 0.9388 - acc: 0.5486 - val_loss: 0.9709 - val_acc: 0.5567\n",
            "Epoch 33/150 - 0.12s - loss: 0.9789 - acc: 0.5142 - val_loss: 1.0178 - val_acc: 0.4838\n",
            "Epoch 34/150 - 0.10s - loss: 0.9285 - acc: 0.5578 - val_loss: 0.9654 - val_acc: 0.5506\n",
            "Epoch 35/150 - 0.10s - loss: 0.9295 - acc: 0.5567 - val_loss: 0.9700 - val_acc: 0.5506\n",
            "Epoch 36/150 - 0.11s - loss: 0.9220 - acc: 0.5625 - val_loss: 0.9616 - val_acc: 0.5668\n",
            "Epoch 37/150 - 0.10s - loss: 0.9229 - acc: 0.5614 - val_loss: 0.9662 - val_acc: 0.5648\n",
            "Epoch 38/150 - 0.10s - loss: 0.9165 - acc: 0.5592 - val_loss: 0.9585 - val_acc: 0.5547\n",
            "Epoch 39/150 - 0.12s - loss: 0.9394 - acc: 0.5529 - val_loss: 0.9783 - val_acc: 0.5567\n",
            "Epoch 40/150 - 0.10s - loss: 0.9348 - acc: 0.5472 - val_loss: 0.9821 - val_acc: 0.5223\n",
            "Epoch 41/150 - 0.10s - loss: 0.9114 - acc: 0.5691 - val_loss: 0.9573 - val_acc: 0.5668\n",
            "Epoch 42/150 - 0.11s - loss: 0.9040 - acc: 0.5720 - val_loss: 0.9550 - val_acc: 0.5729\n",
            "Epoch 43/150 - 0.11s - loss: 0.9097 - acc: 0.5693 - val_loss: 0.9559 - val_acc: 0.5891\n",
            "Epoch 44/150 - 0.11s - loss: 0.9237 - acc: 0.5693 - val_loss: 0.9706 - val_acc: 0.5688\n",
            "Epoch 45/150 - 0.12s - loss: 0.8943 - acc: 0.5868 - val_loss: 0.9508 - val_acc: 0.5668\n",
            "Epoch 46/150 - 0.13s - loss: 0.8942 - acc: 0.5767 - val_loss: 0.9516 - val_acc: 0.5628\n",
            "Epoch 47/150 - 0.11s - loss: 0.8901 - acc: 0.5839 - val_loss: 0.9470 - val_acc: 0.5830\n",
            "Epoch 48/150 - 0.11s - loss: 0.8934 - acc: 0.5771 - val_loss: 0.9550 - val_acc: 0.5486\n",
            "Epoch 49/150 - 0.12s - loss: 0.9813 - acc: 0.5378 - val_loss: 1.0283 - val_acc: 0.5405\n",
            "Epoch 50/150 - 0.14s - loss: 0.8820 - acc: 0.5888 - val_loss: 0.9509 - val_acc: 0.5729\n",
            "Epoch 51/150 - 0.10s - loss: 0.8852 - acc: 0.5805 - val_loss: 0.9533 - val_acc: 0.5567\n",
            "Epoch 52/150 - 0.11s - loss: 0.8824 - acc: 0.5850 - val_loss: 0.9533 - val_acc: 0.5567\n",
            "Epoch 53/150 - 0.13s - loss: 0.8734 - acc: 0.5922 - val_loss: 0.9423 - val_acc: 0.5830\n",
            "Epoch 54/150 - 0.11s - loss: 0.8739 - acc: 0.5893 - val_loss: 0.9505 - val_acc: 0.5668\n",
            "Epoch 55/150 - 0.11s - loss: 0.8994 - acc: 0.5677 - val_loss: 0.9612 - val_acc: 0.5506\n",
            "Epoch 56/150 - 0.10s - loss: 0.8862 - acc: 0.5735 - val_loss: 0.9570 - val_acc: 0.5466\n",
            "Epoch 57/150 - 0.13s - loss: 0.9162 - acc: 0.5717 - val_loss: 0.9880 - val_acc: 0.5567\n",
            "Epoch 58/150 - 0.12s - loss: 0.8713 - acc: 0.5913 - val_loss: 0.9448 - val_acc: 0.5425\n",
            "Epoch 59/150 - 0.12s - loss: 0.8946 - acc: 0.5785 - val_loss: 0.9887 - val_acc: 0.5202\n",
            "Epoch 60/150 - 0.12s - loss: 0.8807 - acc: 0.5875 - val_loss: 0.9759 - val_acc: 0.5425\n",
            "Epoch 61/150 - 0.11s - loss: 0.8516 - acc: 0.6030 - val_loss: 0.9462 - val_acc: 0.5628\n",
            "Epoch 62/150 - 0.12s - loss: 0.8929 - acc: 0.5713 - val_loss: 0.9910 - val_acc: 0.5364\n",
            "Epoch 63/150 - 0.10s - loss: 0.8486 - acc: 0.6050 - val_loss: 0.9424 - val_acc: 0.5506\n",
            "Epoch 64/150 - 0.11s - loss: 0.8946 - acc: 0.5700 - val_loss: 0.9878 - val_acc: 0.5243\n",
            "Epoch 65/150 - 0.12s - loss: 0.8601 - acc: 0.6055 - val_loss: 0.9468 - val_acc: 0.5648\n",
            "Epoch 66/150 - 0.12s - loss: 0.8344 - acc: 0.6131 - val_loss: 0.9317 - val_acc: 0.5587\n",
            "Epoch 67/150 - 0.10s - loss: 0.8395 - acc: 0.6102 - val_loss: 0.9503 - val_acc: 0.5425\n",
            "Epoch 68/150 - 0.11s - loss: 0.8289 - acc: 0.6185 - val_loss: 0.9386 - val_acc: 0.5628\n",
            "Epoch 69/150 - 0.11s - loss: 0.8432 - acc: 0.6066 - val_loss: 0.9569 - val_acc: 0.5486\n",
            "Epoch 70/150 - 0.12s - loss: 0.8530 - acc: 0.5996 - val_loss: 0.9719 - val_acc: 0.5425\n",
            "Epoch 71/150 - 0.10s - loss: 0.8369 - acc: 0.6149 - val_loss: 0.9544 - val_acc: 0.5567\n",
            "Epoch 72/150 - 0.10s - loss: 0.8191 - acc: 0.6273 - val_loss: 0.9308 - val_acc: 0.5830\n",
            "Epoch 73/150 - 0.10s - loss: 0.8802 - acc: 0.5875 - val_loss: 0.9801 - val_acc: 0.5425\n",
            "Epoch 74/150 - 0.11s - loss: 0.8231 - acc: 0.6287 - val_loss: 0.9436 - val_acc: 0.5789\n",
            "Epoch 75/150 - 0.10s - loss: 0.8553 - acc: 0.6122 - val_loss: 0.9678 - val_acc: 0.5648\n",
            "Epoch 76/150 - 0.11s - loss: 0.8261 - acc: 0.6192 - val_loss: 0.9681 - val_acc: 0.5364\n",
            "Epoch 77/150 - 0.11s - loss: 0.8132 - acc: 0.6262 - val_loss: 0.9523 - val_acc: 0.5466\n",
            "Epoch 78/150 - 0.10s - loss: 0.9275 - acc: 0.5542 - val_loss: 1.0843 - val_acc: 0.4980\n",
            "Epoch 79/150 - 0.13s - loss: 0.8241 - acc: 0.6224 - val_loss: 0.9690 - val_acc: 0.5324\n",
            "Epoch 80/150 - 0.10s - loss: 0.8004 - acc: 0.6457 - val_loss: 0.9401 - val_acc: 0.5729\n",
            "Epoch 81/150 - 0.11s - loss: 0.8709 - acc: 0.5882 - val_loss: 1.0300 - val_acc: 0.5202\n",
            "Epoch 82/150 - 0.10s - loss: 0.8702 - acc: 0.5904 - val_loss: 1.0305 - val_acc: 0.5182\n",
            "Epoch 83/150 - 0.11s - loss: 0.7930 - acc: 0.6455 - val_loss: 0.9380 - val_acc: 0.5709\n",
            "Epoch 84/150 - 0.11s - loss: 0.7848 - acc: 0.6498 - val_loss: 0.9337 - val_acc: 0.5607\n",
            "Epoch 85/150 - 0.12s - loss: 0.7957 - acc: 0.6413 - val_loss: 0.9352 - val_acc: 0.5668\n",
            "Epoch 86/150 - 0.11s - loss: 0.7807 - acc: 0.6523 - val_loss: 0.9280 - val_acc: 0.5567\n",
            "Epoch 87/150 - 0.11s - loss: 0.7916 - acc: 0.6516 - val_loss: 0.9417 - val_acc: 0.5830\n",
            "Epoch 88/150 - 0.10s - loss: 0.7744 - acc: 0.6581 - val_loss: 0.9339 - val_acc: 0.5769\n",
            "Epoch 89/150 - 0.10s - loss: 0.7702 - acc: 0.6599 - val_loss: 0.9371 - val_acc: 0.5648\n",
            "Epoch 90/150 - 0.10s - loss: 0.8396 - acc: 0.6073 - val_loss: 1.0176 - val_acc: 0.5202\n",
            "Epoch 91/150 - 0.11s - loss: 0.7645 - acc: 0.6671 - val_loss: 0.9298 - val_acc: 0.5709\n",
            "Epoch 92/150 - 0.10s - loss: 0.7639 - acc: 0.6671 - val_loss: 0.9394 - val_acc: 0.5668\n",
            "Epoch 93/150 - 0.10s - loss: 0.7747 - acc: 0.6628 - val_loss: 0.9414 - val_acc: 0.5567\n",
            "Epoch 94/150 - 0.10s - loss: 0.7609 - acc: 0.6640 - val_loss: 0.9327 - val_acc: 0.5830\n",
            "Epoch 95/150 - 0.10s - loss: 0.7982 - acc: 0.6377 - val_loss: 0.9952 - val_acc: 0.5101\n",
            "Epoch 96/150 - 0.11s - loss: 0.7654 - acc: 0.6601 - val_loss: 0.9581 - val_acc: 0.5445\n",
            "Epoch 97/150 - 0.10s - loss: 0.7501 - acc: 0.6754 - val_loss: 0.9417 - val_acc: 0.5749\n",
            "Epoch 98/150 - 0.13s - loss: 0.8222 - acc: 0.6174 - val_loss: 1.0394 - val_acc: 0.5243\n",
            "Epoch 99/150 - 0.10s - loss: 0.7673 - acc: 0.6482 - val_loss: 0.9472 - val_acc: 0.5547\n",
            "Epoch 100/150 - 0.11s - loss: 0.7788 - acc: 0.6509 - val_loss: 0.9812 - val_acc: 0.5283\n",
            "Epoch 101/150 - 0.10s - loss: 0.7515 - acc: 0.6680 - val_loss: 0.9474 - val_acc: 0.5709\n",
            "Epoch 102/150 - 0.11s - loss: 0.7638 - acc: 0.6586 - val_loss: 0.9843 - val_acc: 0.5506\n",
            "Epoch 103/150 - 0.10s - loss: 0.7924 - acc: 0.6469 - val_loss: 0.9927 - val_acc: 0.5344\n",
            "Epoch 104/150 - 0.12s - loss: 0.8780 - acc: 0.6003 - val_loss: 1.0642 - val_acc: 0.5405\n",
            "Epoch 105/150 - 0.11s - loss: 0.7293 - acc: 0.6880 - val_loss: 0.9412 - val_acc: 0.5769\n",
            "Epoch 106/150 - 0.11s - loss: 0.7568 - acc: 0.6527 - val_loss: 0.9716 - val_acc: 0.5668\n",
            "Epoch 107/150 - 0.10s - loss: 0.7594 - acc: 0.6563 - val_loss: 0.9900 - val_acc: 0.5506\n",
            "Epoch 108/150 - 0.10s - loss: 0.7147 - acc: 0.6939 - val_loss: 0.9492 - val_acc: 0.5688\n",
            "Epoch 109/150 - 0.11s - loss: 0.8173 - acc: 0.6395 - val_loss: 1.0247 - val_acc: 0.5567\n",
            "Epoch 110/150 - 0.10s - loss: 0.7210 - acc: 0.6842 - val_loss: 0.9523 - val_acc: 0.5749\n",
            "Epoch 111/150 - 0.10s - loss: 0.7805 - acc: 0.6345 - val_loss: 0.9926 - val_acc: 0.5486\n",
            "Epoch 112/150 - 0.10s - loss: 0.8470 - acc: 0.5837 - val_loss: 1.0873 - val_acc: 0.5040\n",
            "Epoch 113/150 - 0.10s - loss: 0.8056 - acc: 0.6269 - val_loss: 1.0448 - val_acc: 0.5364\n",
            "Epoch 114/150 - 0.10s - loss: 0.7160 - acc: 0.6887 - val_loss: 0.9547 - val_acc: 0.5749\n",
            "Epoch 115/150 - 0.12s - loss: 0.7116 - acc: 0.6932 - val_loss: 0.9636 - val_acc: 0.5445\n",
            "Epoch 116/150 - 0.15s - loss: 0.7749 - acc: 0.6615 - val_loss: 1.0088 - val_acc: 0.5628\n",
            "Epoch 117/150 - 0.10s - loss: 0.6949 - acc: 0.7024 - val_loss: 0.9503 - val_acc: 0.5870\n",
            "Epoch 118/150 - 0.10s - loss: 0.7478 - acc: 0.6651 - val_loss: 1.0213 - val_acc: 0.5324\n",
            "Epoch 119/150 - 0.11s - loss: 0.6988 - acc: 0.6966 - val_loss: 0.9513 - val_acc: 0.5769\n",
            "Epoch 120/150 - 0.11s - loss: 0.7593 - acc: 0.6667 - val_loss: 1.0079 - val_acc: 0.5425\n",
            "Epoch 121/150 - 0.15s - loss: 0.7060 - acc: 0.7004 - val_loss: 0.9663 - val_acc: 0.5769\n",
            "Epoch 122/150 - 0.13s - loss: 0.7715 - acc: 0.6395 - val_loss: 1.0257 - val_acc: 0.5364\n",
            "Epoch 123/150 - 0.12s - loss: 0.7843 - acc: 0.6586 - val_loss: 1.0324 - val_acc: 0.5729\n",
            "Epoch 124/150 - 0.11s - loss: 0.6729 - acc: 0.7220 - val_loss: 0.9492 - val_acc: 0.5911\n",
            "Epoch 125/150 - 0.12s - loss: 0.6854 - acc: 0.7063 - val_loss: 0.9710 - val_acc: 0.5789\n",
            "Epoch 126/150 - 0.11s - loss: 0.6572 - acc: 0.7285 - val_loss: 0.9467 - val_acc: 0.5911\n",
            "Epoch 127/150 - 0.11s - loss: 0.6533 - acc: 0.7344 - val_loss: 0.9443 - val_acc: 0.5951\n",
            "Epoch 128/150 - 0.11s - loss: 0.8338 - acc: 0.6111 - val_loss: 1.1583 - val_acc: 0.4798\n",
            "Epoch 129/150 - 0.13s - loss: 0.6641 - acc: 0.7173 - val_loss: 0.9769 - val_acc: 0.5769\n",
            "Epoch 130/150 - 0.10s - loss: 0.7172 - acc: 0.6912 - val_loss: 1.0133 - val_acc: 0.5425\n",
            "Epoch 131/150 - 0.15s - loss: 0.6390 - acc: 0.7407 - val_loss: 0.9590 - val_acc: 0.5830\n",
            "Epoch 132/150 - 0.11s - loss: 0.6503 - acc: 0.7292 - val_loss: 0.9771 - val_acc: 0.5547\n",
            "Epoch 133/150 - 0.10s - loss: 0.8479 - acc: 0.6019 - val_loss: 1.1274 - val_acc: 0.5263\n",
            "Epoch 134/150 - 0.11s - loss: 0.6407 - acc: 0.7359 - val_loss: 0.9559 - val_acc: 0.6053\n",
            "Epoch 135/150 - 0.11s - loss: 0.9542 - acc: 0.6017 - val_loss: 1.2393 - val_acc: 0.5121\n",
            "Epoch 136/150 - 0.11s - loss: 0.6615 - acc: 0.7200 - val_loss: 0.9814 - val_acc: 0.5688\n",
            "Epoch 137/150 - 0.11s - loss: 0.7470 - acc: 0.6543 - val_loss: 1.1009 - val_acc: 0.5263\n",
            "Epoch 138/150 - 0.11s - loss: 0.8260 - acc: 0.6149 - val_loss: 1.1203 - val_acc: 0.5040\n",
            "Epoch 139/150 - 0.11s - loss: 0.6709 - acc: 0.7117 - val_loss: 1.0052 - val_acc: 0.5385\n",
            "Epoch 140/150 - 0.11s - loss: 0.6357 - acc: 0.7386 - val_loss: 0.9666 - val_acc: 0.5830\n",
            "Epoch 141/150 - 0.11s - loss: 0.6160 - acc: 0.7548 - val_loss: 0.9765 - val_acc: 0.5709\n",
            "Epoch 142/150 - 0.12s - loss: 0.6200 - acc: 0.7454 - val_loss: 0.9607 - val_acc: 0.5951\n",
            "Epoch 143/150 - 0.11s - loss: 0.7508 - acc: 0.6804 - val_loss: 1.0791 - val_acc: 0.5526\n",
            "Epoch 144/150 - 0.11s - loss: 0.6485 - acc: 0.7229 - val_loss: 1.0142 - val_acc: 0.5324\n",
            "Epoch 145/150 - 0.10s - loss: 0.6028 - acc: 0.7578 - val_loss: 0.9777 - val_acc: 0.5648\n",
            "Epoch 146/150 - 0.15s - loss: 0.9385 - acc: 0.6073 - val_loss: 1.2564 - val_acc: 0.5182\n",
            "Epoch 147/150 - 0.11s - loss: 0.8116 - acc: 0.6206 - val_loss: 1.1941 - val_acc: 0.5121\n",
            "Epoch 148/150 - 0.10s - loss: 0.8656 - acc: 0.6203 - val_loss: 1.2110 - val_acc: 0.5182\n",
            "Epoch 149/150 - 0.11s - loss: 0.7295 - acc: 0.6669 - val_loss: 1.1020 - val_acc: 0.5547\n",
            "Epoch 150/150 - 0.13s - loss: 0.7037 - acc: 0.6806 - val_loss: 1.1062 - val_acc: 0.5243\n",
            "\n",
            "Combination 187/252:\n",
            "Hidden Layers: [256, 128, 64], Activation: relu, Learning Rate: 0.001, Batch Size: 32, Epochs: 50\n",
            "Epoch 1/50 - 0.15s - loss: 1.0950 - acc: 0.3556 - val_loss: 1.0907 - val_acc: 0.3806\n",
            "Epoch 2/50 - 0.16s - loss: 1.0936 - acc: 0.3610 - val_loss: 1.0890 - val_acc: 0.3806\n",
            "Epoch 3/50 - 0.14s - loss: 1.0922 - acc: 0.3713 - val_loss: 1.0876 - val_acc: 0.4008\n",
            "Epoch 4/50 - 0.17s - loss: 1.0910 - acc: 0.3848 - val_loss: 1.0862 - val_acc: 0.3968\n",
            "Epoch 5/50 - 0.14s - loss: 1.0897 - acc: 0.3927 - val_loss: 1.0849 - val_acc: 0.4049\n",
            "Epoch 6/50 - 0.16s - loss: 1.0885 - acc: 0.4042 - val_loss: 1.0837 - val_acc: 0.4130\n",
            "Epoch 7/50 - 0.14s - loss: 1.0872 - acc: 0.4096 - val_loss: 1.0825 - val_acc: 0.4271\n",
            "Epoch 8/50 - 0.14s - loss: 1.0858 - acc: 0.4159 - val_loss: 1.0812 - val_acc: 0.4211\n",
            "Epoch 9/50 - 0.15s - loss: 1.0844 - acc: 0.4231 - val_loss: 1.0800 - val_acc: 0.4211\n",
            "Epoch 10/50 - 0.17s - loss: 1.0831 - acc: 0.4291 - val_loss: 1.0788 - val_acc: 0.4190\n",
            "Epoch 11/50 - 0.14s - loss: 1.0817 - acc: 0.4361 - val_loss: 1.0775 - val_acc: 0.4393\n",
            "Epoch 12/50 - 0.15s - loss: 1.0803 - acc: 0.4393 - val_loss: 1.0763 - val_acc: 0.4332\n",
            "Epoch 13/50 - 0.13s - loss: 1.0789 - acc: 0.4402 - val_loss: 1.0751 - val_acc: 0.4393\n",
            "Epoch 14/50 - 0.14s - loss: 1.0775 - acc: 0.4492 - val_loss: 1.0740 - val_acc: 0.4453\n",
            "Epoch 15/50 - 0.13s - loss: 1.0762 - acc: 0.4532 - val_loss: 1.0730 - val_acc: 0.4474\n",
            "Epoch 16/50 - 0.14s - loss: 1.0749 - acc: 0.4548 - val_loss: 1.0719 - val_acc: 0.4555\n",
            "Epoch 17/50 - 0.13s - loss: 1.0735 - acc: 0.4595 - val_loss: 1.0708 - val_acc: 0.4534\n",
            "Epoch 18/50 - 0.14s - loss: 1.0722 - acc: 0.4615 - val_loss: 1.0698 - val_acc: 0.4555\n",
            "Epoch 19/50 - 0.13s - loss: 1.0709 - acc: 0.4627 - val_loss: 1.0687 - val_acc: 0.4615\n",
            "Epoch 20/50 - 0.15s - loss: 1.0696 - acc: 0.4690 - val_loss: 1.0676 - val_acc: 0.4575\n",
            "Epoch 21/50 - 0.13s - loss: 1.0683 - acc: 0.4701 - val_loss: 1.0667 - val_acc: 0.4636\n",
            "Epoch 22/50 - 0.14s - loss: 1.0670 - acc: 0.4750 - val_loss: 1.0658 - val_acc: 0.4575\n",
            "Epoch 23/50 - 0.13s - loss: 1.0657 - acc: 0.4735 - val_loss: 1.0646 - val_acc: 0.4575\n",
            "Epoch 24/50 - 0.15s - loss: 1.0644 - acc: 0.4764 - val_loss: 1.0638 - val_acc: 0.4696\n",
            "Epoch 25/50 - 0.16s - loss: 1.0630 - acc: 0.4764 - val_loss: 1.0628 - val_acc: 0.4717\n",
            "Epoch 26/50 - 0.13s - loss: 1.0617 - acc: 0.4768 - val_loss: 1.0619 - val_acc: 0.4717\n",
            "Epoch 27/50 - 0.13s - loss: 1.0603 - acc: 0.4784 - val_loss: 1.0610 - val_acc: 0.4656\n",
            "Epoch 28/50 - 0.14s - loss: 1.0590 - acc: 0.4775 - val_loss: 1.0600 - val_acc: 0.4717\n",
            "Epoch 29/50 - 0.13s - loss: 1.0577 - acc: 0.4798 - val_loss: 1.0592 - val_acc: 0.4656\n",
            "Epoch 30/50 - 0.13s - loss: 1.0563 - acc: 0.4816 - val_loss: 1.0585 - val_acc: 0.4636\n",
            "Epoch 31/50 - 0.13s - loss: 1.0550 - acc: 0.4816 - val_loss: 1.0576 - val_acc: 0.4615\n",
            "Epoch 32/50 - 0.15s - loss: 1.0537 - acc: 0.4849 - val_loss: 1.0568 - val_acc: 0.4676\n",
            "Epoch 33/50 - 0.13s - loss: 1.0524 - acc: 0.4847 - val_loss: 1.0559 - val_acc: 0.4676\n",
            "Epoch 34/50 - 0.14s - loss: 1.0511 - acc: 0.4843 - val_loss: 1.0553 - val_acc: 0.4636\n",
            "Epoch 35/50 - 0.13s - loss: 1.0498 - acc: 0.4870 - val_loss: 1.0542 - val_acc: 0.4737\n",
            "Epoch 36/50 - 0.15s - loss: 1.0486 - acc: 0.4861 - val_loss: 1.0535 - val_acc: 0.4737\n",
            "Epoch 37/50 - 0.15s - loss: 1.0474 - acc: 0.4849 - val_loss: 1.0523 - val_acc: 0.4737\n",
            "Epoch 38/50 - 0.15s - loss: 1.0461 - acc: 0.4858 - val_loss: 1.0518 - val_acc: 0.4757\n",
            "Epoch 39/50 - 0.16s - loss: 1.0449 - acc: 0.4881 - val_loss: 1.0513 - val_acc: 0.4777\n",
            "Epoch 40/50 - 0.15s - loss: 1.0436 - acc: 0.4879 - val_loss: 1.0503 - val_acc: 0.4777\n",
            "Epoch 41/50 - 0.13s - loss: 1.0424 - acc: 0.4858 - val_loss: 1.0493 - val_acc: 0.4798\n",
            "Epoch 42/50 - 0.15s - loss: 1.0413 - acc: 0.4867 - val_loss: 1.0485 - val_acc: 0.4757\n",
            "Epoch 43/50 - 0.15s - loss: 1.0401 - acc: 0.4883 - val_loss: 1.0484 - val_acc: 0.4879\n",
            "Epoch 44/50 - 0.15s - loss: 1.0389 - acc: 0.4890 - val_loss: 1.0474 - val_acc: 0.4818\n",
            "Epoch 45/50 - 0.14s - loss: 1.0377 - acc: 0.4885 - val_loss: 1.0465 - val_acc: 0.4818\n",
            "Epoch 46/50 - 0.14s - loss: 1.0365 - acc: 0.4897 - val_loss: 1.0456 - val_acc: 0.4798\n",
            "Epoch 47/50 - 0.14s - loss: 1.0355 - acc: 0.4865 - val_loss: 1.0446 - val_acc: 0.4858\n",
            "Epoch 48/50 - 0.15s - loss: 1.0342 - acc: 0.4901 - val_loss: 1.0442 - val_acc: 0.4798\n",
            "Epoch 49/50 - 0.14s - loss: 1.0331 - acc: 0.4910 - val_loss: 1.0433 - val_acc: 0.4858\n",
            "Epoch 50/50 - 0.15s - loss: 1.0319 - acc: 0.4917 - val_loss: 1.0426 - val_acc: 0.4818\n",
            "\n",
            "Combination 188/252:\n",
            "Hidden Layers: [256, 128, 64], Activation: relu, Learning Rate: 0.001, Batch Size: 32, Epochs: 100\n",
            "Epoch 1/100 - 0.14s - loss: 1.1061 - acc: 0.3315 - val_loss: 1.1090 - val_acc: 0.3178\n",
            "Epoch 2/100 - 0.16s - loss: 1.1001 - acc: 0.3605 - val_loss: 1.1029 - val_acc: 0.3279\n",
            "Epoch 3/100 - 0.14s - loss: 1.0969 - acc: 0.3765 - val_loss: 1.0998 - val_acc: 0.3219\n",
            "Epoch 4/100 - 0.14s - loss: 1.0942 - acc: 0.3842 - val_loss: 1.0975 - val_acc: 0.3259\n",
            "Epoch 5/100 - 0.14s - loss: 1.0918 - acc: 0.3943 - val_loss: 1.0954 - val_acc: 0.3462\n",
            "Epoch 6/100 - 0.15s - loss: 1.0895 - acc: 0.4076 - val_loss: 1.0934 - val_acc: 0.3704\n",
            "Epoch 7/100 - 0.14s - loss: 1.0873 - acc: 0.4062 - val_loss: 1.0917 - val_acc: 0.3765\n",
            "Epoch 8/100 - 0.14s - loss: 1.0852 - acc: 0.4127 - val_loss: 1.0901 - val_acc: 0.3968\n",
            "Epoch 9/100 - 0.14s - loss: 1.0832 - acc: 0.4217 - val_loss: 1.0885 - val_acc: 0.4008\n",
            "Epoch 10/100 - 0.15s - loss: 1.0812 - acc: 0.4294 - val_loss: 1.0869 - val_acc: 0.3907\n",
            "Epoch 11/100 - 0.14s - loss: 1.0794 - acc: 0.4417 - val_loss: 1.0854 - val_acc: 0.3988\n",
            "Epoch 12/100 - 0.14s - loss: 1.0775 - acc: 0.4435 - val_loss: 1.0841 - val_acc: 0.4049\n",
            "Epoch 13/100 - 0.13s - loss: 1.0756 - acc: 0.4478 - val_loss: 1.0828 - val_acc: 0.4028\n",
            "Epoch 14/100 - 0.15s - loss: 1.0738 - acc: 0.4512 - val_loss: 1.0814 - val_acc: 0.4109\n",
            "Epoch 15/100 - 0.13s - loss: 1.0720 - acc: 0.4570 - val_loss: 1.0799 - val_acc: 0.4251\n",
            "Epoch 16/100 - 0.13s - loss: 1.0702 - acc: 0.4602 - val_loss: 1.0786 - val_acc: 0.4352\n",
            "Epoch 17/100 - 0.15s - loss: 1.0686 - acc: 0.4642 - val_loss: 1.0773 - val_acc: 0.4433\n",
            "Epoch 18/100 - 0.18s - loss: 1.0669 - acc: 0.4647 - val_loss: 1.0761 - val_acc: 0.4393\n",
            "Epoch 19/100 - 0.13s - loss: 1.0653 - acc: 0.4710 - val_loss: 1.0748 - val_acc: 0.4372\n",
            "Epoch 20/100 - 0.14s - loss: 1.0637 - acc: 0.4735 - val_loss: 1.0737 - val_acc: 0.4494\n",
            "Epoch 21/100 - 0.14s - loss: 1.0621 - acc: 0.4748 - val_loss: 1.0727 - val_acc: 0.4474\n",
            "Epoch 22/100 - 0.14s - loss: 1.0606 - acc: 0.4721 - val_loss: 1.0716 - val_acc: 0.4413\n",
            "Epoch 23/100 - 0.13s - loss: 1.0590 - acc: 0.4750 - val_loss: 1.0705 - val_acc: 0.4575\n",
            "Epoch 24/100 - 0.13s - loss: 1.0575 - acc: 0.4732 - val_loss: 1.0695 - val_acc: 0.4575\n",
            "Epoch 25/100 - 0.13s - loss: 1.0560 - acc: 0.4780 - val_loss: 1.0683 - val_acc: 0.4636\n",
            "Epoch 26/100 - 0.14s - loss: 1.0545 - acc: 0.4800 - val_loss: 1.0672 - val_acc: 0.4757\n",
            "Epoch 27/100 - 0.13s - loss: 1.0530 - acc: 0.4804 - val_loss: 1.0661 - val_acc: 0.4656\n",
            "Epoch 28/100 - 0.15s - loss: 1.0516 - acc: 0.4838 - val_loss: 1.0651 - val_acc: 0.4615\n",
            "Epoch 29/100 - 0.13s - loss: 1.0501 - acc: 0.4838 - val_loss: 1.0642 - val_acc: 0.4615\n",
            "Epoch 30/100 - 0.15s - loss: 1.0487 - acc: 0.4834 - val_loss: 1.0632 - val_acc: 0.4615\n",
            "Epoch 31/100 - 0.17s - loss: 1.0473 - acc: 0.4854 - val_loss: 1.0622 - val_acc: 0.4615\n",
            "Epoch 32/100 - 0.13s - loss: 1.0459 - acc: 0.4861 - val_loss: 1.0613 - val_acc: 0.4575\n",
            "Epoch 33/100 - 0.14s - loss: 1.0445 - acc: 0.4876 - val_loss: 1.0603 - val_acc: 0.4595\n",
            "Epoch 34/100 - 0.15s - loss: 1.0431 - acc: 0.4888 - val_loss: 1.0594 - val_acc: 0.4656\n",
            "Epoch 35/100 - 0.14s - loss: 1.0418 - acc: 0.4897 - val_loss: 1.0587 - val_acc: 0.4676\n",
            "Epoch 36/100 - 0.13s - loss: 1.0404 - acc: 0.4899 - val_loss: 1.0577 - val_acc: 0.4676\n",
            "Epoch 37/100 - 0.13s - loss: 1.0390 - acc: 0.4906 - val_loss: 1.0567 - val_acc: 0.4696\n",
            "Epoch 38/100 - 0.14s - loss: 1.0377 - acc: 0.4908 - val_loss: 1.0556 - val_acc: 0.4676\n",
            "Epoch 39/100 - 0.13s - loss: 1.0363 - acc: 0.4915 - val_loss: 1.0546 - val_acc: 0.4717\n",
            "Epoch 40/100 - 0.14s - loss: 1.0350 - acc: 0.4944 - val_loss: 1.0537 - val_acc: 0.4757\n",
            "Epoch 41/100 - 0.14s - loss: 1.0336 - acc: 0.4939 - val_loss: 1.0526 - val_acc: 0.4737\n",
            "Epoch 42/100 - 0.14s - loss: 1.0323 - acc: 0.4971 - val_loss: 1.0517 - val_acc: 0.4757\n",
            "Epoch 43/100 - 0.13s - loss: 1.0310 - acc: 0.4969 - val_loss: 1.0507 - val_acc: 0.4757\n",
            "Epoch 44/100 - 0.15s - loss: 1.0297 - acc: 0.4987 - val_loss: 1.0497 - val_acc: 0.4798\n",
            "Epoch 45/100 - 0.15s - loss: 1.0284 - acc: 0.4987 - val_loss: 1.0488 - val_acc: 0.4818\n",
            "Epoch 46/100 - 0.14s - loss: 1.0272 - acc: 0.4966 - val_loss: 1.0478 - val_acc: 0.4879\n",
            "Epoch 47/100 - 0.12s - loss: 1.0258 - acc: 0.4998 - val_loss: 1.0469 - val_acc: 0.4838\n",
            "Epoch 48/100 - 0.13s - loss: 1.0246 - acc: 0.4996 - val_loss: 1.0460 - val_acc: 0.4818\n",
            "Epoch 49/100 - 0.13s - loss: 1.0232 - acc: 0.5016 - val_loss: 1.0449 - val_acc: 0.4858\n",
            "Epoch 50/100 - 0.14s - loss: 1.0219 - acc: 0.5013 - val_loss: 1.0439 - val_acc: 0.4818\n",
            "Epoch 51/100 - 0.13s - loss: 1.0207 - acc: 0.5000 - val_loss: 1.0429 - val_acc: 0.4858\n",
            "Epoch 52/100 - 0.13s - loss: 1.0195 - acc: 0.5007 - val_loss: 1.0420 - val_acc: 0.4858\n",
            "Epoch 53/100 - 0.13s - loss: 1.0181 - acc: 0.5045 - val_loss: 1.0409 - val_acc: 0.4858\n",
            "Epoch 54/100 - 0.14s - loss: 1.0169 - acc: 0.5020 - val_loss: 1.0401 - val_acc: 0.4879\n",
            "Epoch 55/100 - 0.13s - loss: 1.0157 - acc: 0.5036 - val_loss: 1.0391 - val_acc: 0.4879\n",
            "Epoch 56/100 - 0.13s - loss: 1.0145 - acc: 0.5047 - val_loss: 1.0380 - val_acc: 0.4980\n",
            "Epoch 57/100 - 0.13s - loss: 1.0131 - acc: 0.5047 - val_loss: 1.0371 - val_acc: 0.4879\n",
            "Epoch 58/100 - 0.15s - loss: 1.0119 - acc: 0.5052 - val_loss: 1.0362 - val_acc: 0.4919\n",
            "Epoch 59/100 - 0.15s - loss: 1.0107 - acc: 0.5067 - val_loss: 1.0352 - val_acc: 0.4939\n",
            "Epoch 60/100 - 0.16s - loss: 1.0094 - acc: 0.5047 - val_loss: 1.0341 - val_acc: 0.4939\n",
            "Epoch 61/100 - 0.15s - loss: 1.0081 - acc: 0.5081 - val_loss: 1.0332 - val_acc: 0.4919\n",
            "Epoch 62/100 - 0.16s - loss: 1.0069 - acc: 0.5058 - val_loss: 1.0321 - val_acc: 0.4980\n",
            "Epoch 63/100 - 0.14s - loss: 1.0058 - acc: 0.5063 - val_loss: 1.0313 - val_acc: 0.4939\n",
            "Epoch 64/100 - 0.14s - loss: 1.0045 - acc: 0.5094 - val_loss: 1.0304 - val_acc: 0.4960\n",
            "Epoch 65/100 - 0.15s - loss: 1.0032 - acc: 0.5097 - val_loss: 1.0294 - val_acc: 0.5000\n",
            "Epoch 66/100 - 0.16s - loss: 1.0023 - acc: 0.5112 - val_loss: 1.0290 - val_acc: 0.4980\n",
            "Epoch 67/100 - 0.16s - loss: 1.0013 - acc: 0.5072 - val_loss: 1.0277 - val_acc: 0.5040\n",
            "Epoch 68/100 - 0.14s - loss: 0.9998 - acc: 0.5133 - val_loss: 1.0269 - val_acc: 0.4960\n",
            "Epoch 69/100 - 0.14s - loss: 0.9984 - acc: 0.5110 - val_loss: 1.0259 - val_acc: 0.5020\n",
            "Epoch 70/100 - 0.16s - loss: 0.9972 - acc: 0.5130 - val_loss: 1.0249 - val_acc: 0.5020\n",
            "Epoch 71/100 - 0.14s - loss: 0.9959 - acc: 0.5117 - val_loss: 1.0239 - val_acc: 0.5081\n",
            "Epoch 72/100 - 0.15s - loss: 0.9948 - acc: 0.5094 - val_loss: 1.0230 - val_acc: 0.5020\n",
            "Epoch 73/100 - 0.17s - loss: 0.9936 - acc: 0.5119 - val_loss: 1.0219 - val_acc: 0.5081\n",
            "Epoch 74/100 - 0.15s - loss: 0.9924 - acc: 0.5135 - val_loss: 1.0212 - val_acc: 0.5081\n",
            "Epoch 75/100 - 0.13s - loss: 0.9914 - acc: 0.5099 - val_loss: 1.0206 - val_acc: 0.5040\n",
            "Epoch 76/100 - 0.17s - loss: 0.9901 - acc: 0.5126 - val_loss: 1.0195 - val_acc: 0.5061\n",
            "Epoch 77/100 - 0.14s - loss: 0.9890 - acc: 0.5110 - val_loss: 1.0188 - val_acc: 0.5061\n",
            "Epoch 78/100 - 0.16s - loss: 0.9879 - acc: 0.5106 - val_loss: 1.0179 - val_acc: 0.5081\n",
            "Epoch 79/100 - 0.14s - loss: 0.9867 - acc: 0.5148 - val_loss: 1.0172 - val_acc: 0.5061\n",
            "Epoch 80/100 - 0.15s - loss: 0.9858 - acc: 0.5191 - val_loss: 1.0166 - val_acc: 0.5040\n",
            "Epoch 81/100 - 0.15s - loss: 0.9844 - acc: 0.5180 - val_loss: 1.0153 - val_acc: 0.5101\n",
            "Epoch 82/100 - 0.16s - loss: 0.9834 - acc: 0.5180 - val_loss: 1.0143 - val_acc: 0.5162\n",
            "Epoch 83/100 - 0.14s - loss: 0.9830 - acc: 0.5146 - val_loss: 1.0145 - val_acc: 0.5182\n",
            "Epoch 84/100 - 0.17s - loss: 0.9812 - acc: 0.5229 - val_loss: 1.0130 - val_acc: 0.5061\n",
            "Epoch 85/100 - 0.14s - loss: 0.9802 - acc: 0.5180 - val_loss: 1.0120 - val_acc: 0.5182\n",
            "Epoch 86/100 - 0.16s - loss: 0.9795 - acc: 0.5236 - val_loss: 1.0118 - val_acc: 0.5142\n",
            "Epoch 87/100 - 0.15s - loss: 0.9779 - acc: 0.5243 - val_loss: 1.0104 - val_acc: 0.5162\n",
            "Epoch 88/100 - 0.14s - loss: 0.9774 - acc: 0.5178 - val_loss: 1.0100 - val_acc: 0.5182\n",
            "Epoch 89/100 - 0.14s - loss: 0.9764 - acc: 0.5207 - val_loss: 1.0093 - val_acc: 0.5202\n",
            "Epoch 90/100 - 0.14s - loss: 0.9748 - acc: 0.5268 - val_loss: 1.0081 - val_acc: 0.5162\n",
            "Epoch 91/100 - 0.14s - loss: 0.9747 - acc: 0.5290 - val_loss: 1.0083 - val_acc: 0.5101\n",
            "Epoch 92/100 - 0.14s - loss: 0.9729 - acc: 0.5220 - val_loss: 1.0064 - val_acc: 0.5243\n",
            "Epoch 93/100 - 0.14s - loss: 0.9718 - acc: 0.5245 - val_loss: 1.0057 - val_acc: 0.5202\n",
            "Epoch 94/100 - 0.14s - loss: 0.9724 - acc: 0.5295 - val_loss: 1.0069 - val_acc: 0.5061\n",
            "Epoch 95/100 - 0.14s - loss: 0.9699 - acc: 0.5250 - val_loss: 1.0044 - val_acc: 0.5243\n",
            "Epoch 96/100 - 0.14s - loss: 0.9689 - acc: 0.5270 - val_loss: 1.0037 - val_acc: 0.5202\n",
            "Epoch 97/100 - 0.14s - loss: 0.9680 - acc: 0.5243 - val_loss: 1.0028 - val_acc: 0.5283\n",
            "Epoch 98/100 - 0.15s - loss: 0.9671 - acc: 0.5310 - val_loss: 1.0024 - val_acc: 0.5223\n",
            "Epoch 99/100 - 0.14s - loss: 0.9661 - acc: 0.5308 - val_loss: 1.0018 - val_acc: 0.5202\n",
            "Epoch 100/100 - 0.13s - loss: 0.9663 - acc: 0.5328 - val_loss: 1.0023 - val_acc: 0.5101\n",
            "\n",
            "Combination 189/252:\n",
            "Hidden Layers: [256, 128, 64], Activation: relu, Learning Rate: 0.001, Batch Size: 32, Epochs: 150\n",
            "Epoch 1/150 - 0.13s - loss: 1.1011 - acc: 0.3486 - val_loss: 1.0980 - val_acc: 0.3381\n",
            "Epoch 2/150 - 0.17s - loss: 1.0966 - acc: 0.3574 - val_loss: 1.0952 - val_acc: 0.3583\n",
            "Epoch 3/150 - 0.13s - loss: 1.0936 - acc: 0.3639 - val_loss: 1.0934 - val_acc: 0.3664\n",
            "Epoch 4/150 - 0.14s - loss: 1.0911 - acc: 0.3772 - val_loss: 1.0920 - val_acc: 0.3745\n",
            "Epoch 5/150 - 0.13s - loss: 1.0891 - acc: 0.3826 - val_loss: 1.0908 - val_acc: 0.3684\n",
            "Epoch 6/150 - 0.15s - loss: 1.0873 - acc: 0.3943 - val_loss: 1.0896 - val_acc: 0.3704\n",
            "Epoch 7/150 - 0.13s - loss: 1.0856 - acc: 0.3995 - val_loss: 1.0886 - val_acc: 0.3846\n",
            "Epoch 8/150 - 0.14s - loss: 1.0840 - acc: 0.4067 - val_loss: 1.0875 - val_acc: 0.3907\n",
            "Epoch 9/150 - 0.13s - loss: 1.0825 - acc: 0.4130 - val_loss: 1.0865 - val_acc: 0.3887\n",
            "Epoch 10/150 - 0.16s - loss: 1.0811 - acc: 0.4168 - val_loss: 1.0855 - val_acc: 0.3846\n",
            "Epoch 11/150 - 0.15s - loss: 1.0798 - acc: 0.4222 - val_loss: 1.0846 - val_acc: 0.3887\n",
            "Epoch 12/150 - 0.15s - loss: 1.0786 - acc: 0.4267 - val_loss: 1.0837 - val_acc: 0.3988\n",
            "Epoch 13/150 - 0.14s - loss: 1.0773 - acc: 0.4258 - val_loss: 1.0828 - val_acc: 0.4069\n",
            "Epoch 14/150 - 0.15s - loss: 1.0761 - acc: 0.4296 - val_loss: 1.0820 - val_acc: 0.4109\n",
            "Epoch 15/150 - 0.15s - loss: 1.0749 - acc: 0.4332 - val_loss: 1.0812 - val_acc: 0.4028\n",
            "Epoch 16/150 - 0.16s - loss: 1.0738 - acc: 0.4357 - val_loss: 1.0803 - val_acc: 0.4089\n",
            "Epoch 17/150 - 0.15s - loss: 1.0727 - acc: 0.4388 - val_loss: 1.0796 - val_acc: 0.4069\n",
            "Epoch 18/150 - 0.14s - loss: 1.0715 - acc: 0.4413 - val_loss: 1.0789 - val_acc: 0.4069\n",
            "Epoch 19/150 - 0.13s - loss: 1.0704 - acc: 0.4415 - val_loss: 1.0781 - val_acc: 0.4109\n",
            "Epoch 20/150 - 0.13s - loss: 1.0693 - acc: 0.4426 - val_loss: 1.0773 - val_acc: 0.4150\n",
            "Epoch 21/150 - 0.13s - loss: 1.0682 - acc: 0.4476 - val_loss: 1.0766 - val_acc: 0.4190\n",
            "Epoch 22/150 - 0.15s - loss: 1.0671 - acc: 0.4474 - val_loss: 1.0758 - val_acc: 0.4231\n",
            "Epoch 23/150 - 0.14s - loss: 1.0660 - acc: 0.4485 - val_loss: 1.0750 - val_acc: 0.4251\n",
            "Epoch 24/150 - 0.14s - loss: 1.0649 - acc: 0.4510 - val_loss: 1.0742 - val_acc: 0.4271\n",
            "Epoch 25/150 - 0.15s - loss: 1.0639 - acc: 0.4521 - val_loss: 1.0735 - val_acc: 0.4251\n",
            "Epoch 26/150 - 0.16s - loss: 1.0628 - acc: 0.4525 - val_loss: 1.0727 - val_acc: 0.4291\n",
            "Epoch 27/150 - 0.14s - loss: 1.0617 - acc: 0.4568 - val_loss: 1.0720 - val_acc: 0.4291\n",
            "Epoch 28/150 - 0.16s - loss: 1.0607 - acc: 0.4568 - val_loss: 1.0712 - val_acc: 0.4312\n",
            "Epoch 29/150 - 0.15s - loss: 1.0597 - acc: 0.4597 - val_loss: 1.0704 - val_acc: 0.4271\n",
            "Epoch 30/150 - 0.17s - loss: 1.0586 - acc: 0.4602 - val_loss: 1.0696 - val_acc: 0.4352\n",
            "Epoch 31/150 - 0.15s - loss: 1.0576 - acc: 0.4593 - val_loss: 1.0688 - val_acc: 0.4372\n",
            "Epoch 32/150 - 0.15s - loss: 1.0566 - acc: 0.4588 - val_loss: 1.0680 - val_acc: 0.4393\n",
            "Epoch 33/150 - 0.14s - loss: 1.0556 - acc: 0.4627 - val_loss: 1.0674 - val_acc: 0.4372\n",
            "Epoch 34/150 - 0.15s - loss: 1.0546 - acc: 0.4615 - val_loss: 1.0667 - val_acc: 0.4393\n",
            "Epoch 35/150 - 0.13s - loss: 1.0536 - acc: 0.4658 - val_loss: 1.0658 - val_acc: 0.4332\n",
            "Epoch 36/150 - 0.14s - loss: 1.0526 - acc: 0.4640 - val_loss: 1.0651 - val_acc: 0.4393\n",
            "Epoch 37/150 - 0.14s - loss: 1.0516 - acc: 0.4649 - val_loss: 1.0643 - val_acc: 0.4393\n",
            "Epoch 38/150 - 0.18s - loss: 1.0505 - acc: 0.4658 - val_loss: 1.0635 - val_acc: 0.4393\n",
            "Epoch 39/150 - 0.14s - loss: 1.0495 - acc: 0.4669 - val_loss: 1.0626 - val_acc: 0.4352\n",
            "Epoch 40/150 - 0.14s - loss: 1.0485 - acc: 0.4712 - val_loss: 1.0619 - val_acc: 0.4372\n",
            "Epoch 41/150 - 0.14s - loss: 1.0476 - acc: 0.4703 - val_loss: 1.0611 - val_acc: 0.4393\n",
            "Epoch 42/150 - 0.15s - loss: 1.0466 - acc: 0.4717 - val_loss: 1.0605 - val_acc: 0.4474\n",
            "Epoch 43/150 - 0.13s - loss: 1.0456 - acc: 0.4701 - val_loss: 1.0594 - val_acc: 0.4393\n",
            "Epoch 44/150 - 0.14s - loss: 1.0446 - acc: 0.4732 - val_loss: 1.0586 - val_acc: 0.4413\n",
            "Epoch 45/150 - 0.16s - loss: 1.0436 - acc: 0.4710 - val_loss: 1.0577 - val_acc: 0.4453\n",
            "Epoch 46/150 - 0.14s - loss: 1.0427 - acc: 0.4726 - val_loss: 1.0567 - val_acc: 0.4453\n",
            "Epoch 47/150 - 0.13s - loss: 1.0417 - acc: 0.4744 - val_loss: 1.0561 - val_acc: 0.4555\n",
            "Epoch 48/150 - 0.14s - loss: 1.0407 - acc: 0.4744 - val_loss: 1.0552 - val_acc: 0.4575\n",
            "Epoch 49/150 - 0.15s - loss: 1.0398 - acc: 0.4748 - val_loss: 1.0544 - val_acc: 0.4534\n",
            "Epoch 50/150 - 0.17s - loss: 1.0388 - acc: 0.4804 - val_loss: 1.0538 - val_acc: 0.4615\n",
            "Epoch 51/150 - 0.13s - loss: 1.0378 - acc: 0.4836 - val_loss: 1.0532 - val_acc: 0.4615\n",
            "Epoch 52/150 - 0.13s - loss: 1.0368 - acc: 0.4795 - val_loss: 1.0522 - val_acc: 0.4676\n",
            "Epoch 53/150 - 0.14s - loss: 1.0359 - acc: 0.4852 - val_loss: 1.0515 - val_acc: 0.4615\n",
            "Epoch 54/150 - 0.15s - loss: 1.0349 - acc: 0.4876 - val_loss: 1.0507 - val_acc: 0.4615\n",
            "Epoch 55/150 - 0.13s - loss: 1.0339 - acc: 0.4885 - val_loss: 1.0500 - val_acc: 0.4676\n",
            "Epoch 56/150 - 0.14s - loss: 1.0329 - acc: 0.4883 - val_loss: 1.0492 - val_acc: 0.4656\n",
            "Epoch 57/150 - 0.13s - loss: 1.0319 - acc: 0.4885 - val_loss: 1.0480 - val_acc: 0.4656\n",
            "Epoch 58/150 - 0.15s - loss: 1.0310 - acc: 0.4876 - val_loss: 1.0476 - val_acc: 0.4737\n",
            "Epoch 59/150 - 0.18s - loss: 1.0300 - acc: 0.4903 - val_loss: 1.0466 - val_acc: 0.4676\n",
            "Epoch 60/150 - 0.15s - loss: 1.0290 - acc: 0.4901 - val_loss: 1.0455 - val_acc: 0.4676\n",
            "Epoch 61/150 - 0.14s - loss: 1.0280 - acc: 0.4885 - val_loss: 1.0448 - val_acc: 0.4615\n",
            "Epoch 62/150 - 0.15s - loss: 1.0270 - acc: 0.4901 - val_loss: 1.0440 - val_acc: 0.4636\n",
            "Epoch 63/150 - 0.14s - loss: 1.0260 - acc: 0.4921 - val_loss: 1.0434 - val_acc: 0.4717\n",
            "Epoch 64/150 - 0.13s - loss: 1.0251 - acc: 0.4924 - val_loss: 1.0429 - val_acc: 0.4757\n",
            "Epoch 65/150 - 0.14s - loss: 1.0241 - acc: 0.4926 - val_loss: 1.0421 - val_acc: 0.4737\n",
            "Epoch 66/150 - 0.14s - loss: 1.0231 - acc: 0.4926 - val_loss: 1.0411 - val_acc: 0.4676\n",
            "Epoch 67/150 - 0.14s - loss: 1.0221 - acc: 0.4975 - val_loss: 1.0407 - val_acc: 0.4777\n",
            "Epoch 68/150 - 0.15s - loss: 1.0211 - acc: 0.4978 - val_loss: 1.0398 - val_acc: 0.4777\n",
            "Epoch 69/150 - 0.14s - loss: 1.0200 - acc: 0.4969 - val_loss: 1.0386 - val_acc: 0.4696\n",
            "Epoch 70/150 - 0.18s - loss: 1.0190 - acc: 0.4969 - val_loss: 1.0379 - val_acc: 0.4757\n",
            "Epoch 71/150 - 0.15s - loss: 1.0180 - acc: 0.4989 - val_loss: 1.0370 - val_acc: 0.4737\n",
            "Epoch 72/150 - 0.16s - loss: 1.0170 - acc: 0.4991 - val_loss: 1.0364 - val_acc: 0.4798\n",
            "Epoch 73/150 - 0.22s - loss: 1.0161 - acc: 0.5009 - val_loss: 1.0354 - val_acc: 0.4757\n",
            "Epoch 74/150 - 0.14s - loss: 1.0150 - acc: 0.5049 - val_loss: 1.0350 - val_acc: 0.4818\n",
            "Epoch 75/150 - 0.15s - loss: 1.0139 - acc: 0.5040 - val_loss: 1.0339 - val_acc: 0.4777\n",
            "Epoch 76/150 - 0.14s - loss: 1.0130 - acc: 0.5040 - val_loss: 1.0335 - val_acc: 0.4818\n",
            "Epoch 77/150 - 0.14s - loss: 1.0119 - acc: 0.5083 - val_loss: 1.0321 - val_acc: 0.4818\n",
            "Epoch 78/150 - 0.13s - loss: 1.0108 - acc: 0.5061 - val_loss: 1.0316 - val_acc: 0.4879\n",
            "Epoch 79/150 - 0.13s - loss: 1.0098 - acc: 0.5072 - val_loss: 1.0309 - val_acc: 0.4798\n",
            "Epoch 80/150 - 0.13s - loss: 1.0088 - acc: 0.5099 - val_loss: 1.0299 - val_acc: 0.4858\n",
            "Epoch 81/150 - 0.14s - loss: 1.0078 - acc: 0.5101 - val_loss: 1.0292 - val_acc: 0.4939\n",
            "Epoch 82/150 - 0.15s - loss: 1.0068 - acc: 0.5108 - val_loss: 1.0283 - val_acc: 0.4939\n",
            "Epoch 83/150 - 0.14s - loss: 1.0060 - acc: 0.5101 - val_loss: 1.0272 - val_acc: 0.4919\n",
            "Epoch 84/150 - 0.13s - loss: 1.0047 - acc: 0.5110 - val_loss: 1.0264 - val_acc: 0.4858\n",
            "Epoch 85/150 - 0.16s - loss: 1.0038 - acc: 0.5128 - val_loss: 1.0256 - val_acc: 0.5000\n",
            "Epoch 86/150 - 0.14s - loss: 1.0028 - acc: 0.5130 - val_loss: 1.0248 - val_acc: 0.5020\n",
            "Epoch 87/150 - 0.14s - loss: 1.0018 - acc: 0.5137 - val_loss: 1.0241 - val_acc: 0.5000\n",
            "Epoch 88/150 - 0.14s - loss: 1.0009 - acc: 0.5153 - val_loss: 1.0237 - val_acc: 0.4899\n",
            "Epoch 89/150 - 0.19s - loss: 1.0000 - acc: 0.5108 - val_loss: 1.0225 - val_acc: 0.5061\n",
            "Epoch 90/150 - 0.14s - loss: 0.9987 - acc: 0.5148 - val_loss: 1.0216 - val_acc: 0.5020\n",
            "Epoch 91/150 - 0.15s - loss: 0.9977 - acc: 0.5171 - val_loss: 1.0210 - val_acc: 0.5020\n",
            "Epoch 92/150 - 0.15s - loss: 0.9967 - acc: 0.5160 - val_loss: 1.0200 - val_acc: 0.4939\n",
            "Epoch 93/150 - 0.19s - loss: 0.9957 - acc: 0.5157 - val_loss: 1.0191 - val_acc: 0.5040\n",
            "Epoch 94/150 - 0.14s - loss: 0.9948 - acc: 0.5189 - val_loss: 1.0189 - val_acc: 0.5040\n",
            "Epoch 95/150 - 0.13s - loss: 0.9936 - acc: 0.5205 - val_loss: 1.0176 - val_acc: 0.5000\n",
            "Epoch 96/150 - 0.14s - loss: 0.9926 - acc: 0.5200 - val_loss: 1.0168 - val_acc: 0.5000\n",
            "Epoch 97/150 - 0.15s - loss: 0.9918 - acc: 0.5187 - val_loss: 1.0160 - val_acc: 0.5081\n",
            "Epoch 98/150 - 0.14s - loss: 0.9905 - acc: 0.5211 - val_loss: 1.0151 - val_acc: 0.5061\n",
            "Epoch 99/150 - 0.17s - loss: 0.9896 - acc: 0.5234 - val_loss: 1.0141 - val_acc: 0.5081\n",
            "Epoch 100/150 - 0.14s - loss: 0.9885 - acc: 0.5243 - val_loss: 1.0133 - val_acc: 0.5061\n",
            "Epoch 101/150 - 0.15s - loss: 0.9880 - acc: 0.5220 - val_loss: 1.0123 - val_acc: 0.5061\n",
            "Epoch 102/150 - 0.14s - loss: 0.9866 - acc: 0.5263 - val_loss: 1.0119 - val_acc: 0.5162\n",
            "Epoch 103/150 - 0.14s - loss: 0.9856 - acc: 0.5288 - val_loss: 1.0108 - val_acc: 0.5121\n",
            "Epoch 104/150 - 0.14s - loss: 0.9848 - acc: 0.5308 - val_loss: 1.0105 - val_acc: 0.5182\n",
            "Epoch 105/150 - 0.15s - loss: 0.9838 - acc: 0.5333 - val_loss: 1.0097 - val_acc: 0.5182\n",
            "Epoch 106/150 - 0.13s - loss: 0.9828 - acc: 0.5331 - val_loss: 1.0091 - val_acc: 0.5283\n",
            "Epoch 107/150 - 0.14s - loss: 0.9818 - acc: 0.5340 - val_loss: 1.0083 - val_acc: 0.5243\n",
            "Epoch 108/150 - 0.13s - loss: 0.9810 - acc: 0.5308 - val_loss: 1.0072 - val_acc: 0.5243\n",
            "Epoch 109/150 - 0.15s - loss: 0.9797 - acc: 0.5362 - val_loss: 1.0061 - val_acc: 0.5223\n",
            "Epoch 110/150 - 0.14s - loss: 0.9787 - acc: 0.5367 - val_loss: 1.0053 - val_acc: 0.5162\n",
            "Epoch 111/150 - 0.14s - loss: 0.9781 - acc: 0.5373 - val_loss: 1.0050 - val_acc: 0.5202\n",
            "Epoch 112/150 - 0.14s - loss: 0.9768 - acc: 0.5382 - val_loss: 1.0040 - val_acc: 0.5283\n",
            "Epoch 113/150 - 0.15s - loss: 0.9759 - acc: 0.5389 - val_loss: 1.0030 - val_acc: 0.5324\n",
            "Epoch 114/150 - 0.16s - loss: 0.9750 - acc: 0.5394 - val_loss: 1.0020 - val_acc: 0.5263\n",
            "Epoch 115/150 - 0.17s - loss: 0.9741 - acc: 0.5405 - val_loss: 1.0014 - val_acc: 0.5304\n",
            "Epoch 116/150 - 0.14s - loss: 0.9732 - acc: 0.5405 - val_loss: 1.0012 - val_acc: 0.5344\n",
            "Epoch 117/150 - 0.20s - loss: 0.9725 - acc: 0.5396 - val_loss: 1.0007 - val_acc: 0.5263\n",
            "Epoch 118/150 - 0.14s - loss: 0.9720 - acc: 0.5378 - val_loss: 0.9992 - val_acc: 0.5263\n",
            "Epoch 119/150 - 0.14s - loss: 0.9705 - acc: 0.5450 - val_loss: 0.9985 - val_acc: 0.5425\n",
            "Epoch 120/150 - 0.14s - loss: 0.9696 - acc: 0.5445 - val_loss: 0.9980 - val_acc: 0.5385\n",
            "Epoch 121/150 - 0.15s - loss: 0.9686 - acc: 0.5466 - val_loss: 0.9971 - val_acc: 0.5425\n",
            "Epoch 122/150 - 0.13s - loss: 0.9679 - acc: 0.5452 - val_loss: 0.9967 - val_acc: 0.5263\n",
            "Epoch 123/150 - 0.14s - loss: 0.9669 - acc: 0.5468 - val_loss: 0.9957 - val_acc: 0.5466\n",
            "Epoch 124/150 - 0.13s - loss: 0.9661 - acc: 0.5475 - val_loss: 0.9952 - val_acc: 0.5405\n",
            "Epoch 125/150 - 0.14s - loss: 0.9652 - acc: 0.5466 - val_loss: 0.9946 - val_acc: 0.5385\n",
            "Epoch 126/150 - 0.13s - loss: 0.9644 - acc: 0.5450 - val_loss: 0.9941 - val_acc: 0.5324\n",
            "Epoch 127/150 - 0.14s - loss: 0.9635 - acc: 0.5468 - val_loss: 0.9930 - val_acc: 0.5405\n",
            "Epoch 128/150 - 0.15s - loss: 0.9627 - acc: 0.5466 - val_loss: 0.9921 - val_acc: 0.5385\n",
            "Epoch 129/150 - 0.15s - loss: 0.9620 - acc: 0.5477 - val_loss: 0.9923 - val_acc: 0.5324\n",
            "Epoch 130/150 - 0.14s - loss: 0.9611 - acc: 0.5488 - val_loss: 0.9918 - val_acc: 0.5405\n",
            "Epoch 131/150 - 0.14s - loss: 0.9603 - acc: 0.5484 - val_loss: 0.9909 - val_acc: 0.5324\n",
            "Epoch 132/150 - 0.13s - loss: 0.9596 - acc: 0.5461 - val_loss: 0.9904 - val_acc: 0.5324\n",
            "Epoch 133/150 - 0.14s - loss: 0.9585 - acc: 0.5497 - val_loss: 0.9895 - val_acc: 0.5344\n",
            "Epoch 134/150 - 0.13s - loss: 0.9578 - acc: 0.5493 - val_loss: 0.9890 - val_acc: 0.5405\n",
            "Epoch 135/150 - 0.14s - loss: 0.9571 - acc: 0.5484 - val_loss: 0.9880 - val_acc: 0.5445\n",
            "Epoch 136/150 - 0.14s - loss: 0.9561 - acc: 0.5504 - val_loss: 0.9872 - val_acc: 0.5405\n",
            "Epoch 137/150 - 0.16s - loss: 0.9558 - acc: 0.5472 - val_loss: 0.9868 - val_acc: 0.5364\n",
            "Epoch 138/150 - 0.14s - loss: 0.9546 - acc: 0.5499 - val_loss: 0.9862 - val_acc: 0.5344\n",
            "Epoch 139/150 - 0.15s - loss: 0.9545 - acc: 0.5481 - val_loss: 0.9861 - val_acc: 0.5506\n",
            "Epoch 140/150 - 0.15s - loss: 0.9529 - acc: 0.5522 - val_loss: 0.9850 - val_acc: 0.5466\n",
            "Epoch 141/150 - 0.18s - loss: 0.9524 - acc: 0.5524 - val_loss: 0.9852 - val_acc: 0.5405\n",
            "Epoch 142/150 - 0.14s - loss: 0.9513 - acc: 0.5522 - val_loss: 0.9840 - val_acc: 0.5385\n",
            "Epoch 143/150 - 0.14s - loss: 0.9514 - acc: 0.5504 - val_loss: 0.9841 - val_acc: 0.5587\n",
            "Epoch 144/150 - 0.18s - loss: 0.9509 - acc: 0.5488 - val_loss: 0.9833 - val_acc: 0.5547\n",
            "Epoch 145/150 - 0.17s - loss: 0.9495 - acc: 0.5520 - val_loss: 0.9830 - val_acc: 0.5405\n",
            "Epoch 146/150 - 0.15s - loss: 0.9482 - acc: 0.5558 - val_loss: 0.9822 - val_acc: 0.5405\n",
            "Epoch 147/150 - 0.15s - loss: 0.9480 - acc: 0.5533 - val_loss: 0.9822 - val_acc: 0.5425\n",
            "Epoch 148/150 - 0.14s - loss: 0.9474 - acc: 0.5535 - val_loss: 0.9820 - val_acc: 0.5445\n",
            "Epoch 149/150 - 0.15s - loss: 0.9459 - acc: 0.5567 - val_loss: 0.9799 - val_acc: 0.5405\n",
            "Epoch 150/150 - 0.14s - loss: 0.9469 - acc: 0.5531 - val_loss: 0.9823 - val_acc: 0.5304\n",
            "\n",
            "Combination 190/252:\n",
            "Hidden Layers: [256, 128, 64], Activation: relu, Learning Rate: 0.001, Batch Size: 64, Epochs: 50\n",
            "Epoch 1/50 - 0.11s - loss: 1.1336 - acc: 0.3295 - val_loss: 1.1316 - val_acc: 0.3158\n",
            "Epoch 2/50 - 0.10s - loss: 1.1162 - acc: 0.3288 - val_loss: 1.1144 - val_acc: 0.3138\n",
            "Epoch 3/50 - 0.10s - loss: 1.1074 - acc: 0.3291 - val_loss: 1.1057 - val_acc: 0.3178\n",
            "Epoch 4/50 - 0.11s - loss: 1.1024 - acc: 0.3385 - val_loss: 1.1010 - val_acc: 0.3219\n",
            "Epoch 5/50 - 0.10s - loss: 1.0995 - acc: 0.3507 - val_loss: 1.0984 - val_acc: 0.3138\n",
            "Epoch 6/50 - 0.11s - loss: 1.0976 - acc: 0.3552 - val_loss: 1.0968 - val_acc: 0.3421\n",
            "Epoch 7/50 - 0.11s - loss: 1.0961 - acc: 0.3574 - val_loss: 1.0955 - val_acc: 0.3583\n",
            "Epoch 8/50 - 0.11s - loss: 1.0949 - acc: 0.3596 - val_loss: 1.0945 - val_acc: 0.3522\n",
            "Epoch 9/50 - 0.12s - loss: 1.0938 - acc: 0.3608 - val_loss: 1.0937 - val_acc: 0.3664\n",
            "Epoch 10/50 - 0.11s - loss: 1.0928 - acc: 0.3677 - val_loss: 1.0928 - val_acc: 0.3664\n",
            "Epoch 11/50 - 0.11s - loss: 1.0919 - acc: 0.3731 - val_loss: 1.0920 - val_acc: 0.3664\n",
            "Epoch 12/50 - 0.10s - loss: 1.0910 - acc: 0.3725 - val_loss: 1.0913 - val_acc: 0.3684\n",
            "Epoch 13/50 - 0.11s - loss: 1.0901 - acc: 0.3776 - val_loss: 1.0905 - val_acc: 0.3704\n",
            "Epoch 14/50 - 0.10s - loss: 1.0892 - acc: 0.3833 - val_loss: 1.0898 - val_acc: 0.3745\n",
            "Epoch 15/50 - 0.10s - loss: 1.0884 - acc: 0.3833 - val_loss: 1.0892 - val_acc: 0.3826\n",
            "Epoch 16/50 - 0.11s - loss: 1.0876 - acc: 0.3857 - val_loss: 1.0885 - val_acc: 0.3806\n",
            "Epoch 17/50 - 0.10s - loss: 1.0868 - acc: 0.3900 - val_loss: 1.0878 - val_acc: 0.3907\n",
            "Epoch 18/50 - 0.11s - loss: 1.0860 - acc: 0.3943 - val_loss: 1.0871 - val_acc: 0.3927\n",
            "Epoch 19/50 - 0.10s - loss: 1.0852 - acc: 0.3965 - val_loss: 1.0864 - val_acc: 0.3968\n",
            "Epoch 20/50 - 0.10s - loss: 1.0844 - acc: 0.3977 - val_loss: 1.0857 - val_acc: 0.3988\n",
            "Epoch 21/50 - 0.11s - loss: 1.0837 - acc: 0.4049 - val_loss: 1.0850 - val_acc: 0.3988\n",
            "Epoch 22/50 - 0.10s - loss: 1.0829 - acc: 0.4082 - val_loss: 1.0844 - val_acc: 0.3927\n",
            "Epoch 23/50 - 0.10s - loss: 1.0822 - acc: 0.4107 - val_loss: 1.0837 - val_acc: 0.3988\n",
            "Epoch 24/50 - 0.15s - loss: 1.0815 - acc: 0.4152 - val_loss: 1.0831 - val_acc: 0.3907\n",
            "Epoch 25/50 - 0.10s - loss: 1.0807 - acc: 0.4188 - val_loss: 1.0824 - val_acc: 0.3887\n",
            "Epoch 26/50 - 0.10s - loss: 1.0800 - acc: 0.4224 - val_loss: 1.0818 - val_acc: 0.3826\n",
            "Epoch 27/50 - 0.10s - loss: 1.0793 - acc: 0.4244 - val_loss: 1.0813 - val_acc: 0.3846\n",
            "Epoch 28/50 - 0.11s - loss: 1.0786 - acc: 0.4278 - val_loss: 1.0808 - val_acc: 0.3866\n",
            "Epoch 29/50 - 0.10s - loss: 1.0779 - acc: 0.4305 - val_loss: 1.0802 - val_acc: 0.3826\n",
            "Epoch 30/50 - 0.10s - loss: 1.0772 - acc: 0.4314 - val_loss: 1.0796 - val_acc: 0.3887\n",
            "Epoch 31/50 - 0.12s - loss: 1.0766 - acc: 0.4361 - val_loss: 1.0791 - val_acc: 0.3887\n",
            "Epoch 32/50 - 0.10s - loss: 1.0759 - acc: 0.4372 - val_loss: 1.0786 - val_acc: 0.3947\n",
            "Epoch 33/50 - 0.10s - loss: 1.0753 - acc: 0.4402 - val_loss: 1.0781 - val_acc: 0.3968\n",
            "Epoch 34/50 - 0.12s - loss: 1.0747 - acc: 0.4424 - val_loss: 1.0776 - val_acc: 0.4008\n",
            "Epoch 35/50 - 0.11s - loss: 1.0740 - acc: 0.4438 - val_loss: 1.0770 - val_acc: 0.4049\n",
            "Epoch 36/50 - 0.10s - loss: 1.0734 - acc: 0.4449 - val_loss: 1.0766 - val_acc: 0.4089\n",
            "Epoch 37/50 - 0.12s - loss: 1.0728 - acc: 0.4462 - val_loss: 1.0761 - val_acc: 0.4089\n",
            "Epoch 38/50 - 0.10s - loss: 1.0722 - acc: 0.4485 - val_loss: 1.0756 - val_acc: 0.4109\n",
            "Epoch 39/50 - 0.11s - loss: 1.0716 - acc: 0.4512 - val_loss: 1.0751 - val_acc: 0.4150\n",
            "Epoch 40/50 - 0.12s - loss: 1.0710 - acc: 0.4543 - val_loss: 1.0747 - val_acc: 0.4150\n",
            "Epoch 41/50 - 0.13s - loss: 1.0704 - acc: 0.4550 - val_loss: 1.0742 - val_acc: 0.4211\n",
            "Epoch 42/50 - 0.18s - loss: 1.0698 - acc: 0.4559 - val_loss: 1.0738 - val_acc: 0.4211\n",
            "Epoch 43/50 - 0.10s - loss: 1.0693 - acc: 0.4561 - val_loss: 1.0733 - val_acc: 0.4231\n",
            "Epoch 44/50 - 0.10s - loss: 1.0687 - acc: 0.4575 - val_loss: 1.0729 - val_acc: 0.4211\n",
            "Epoch 45/50 - 0.11s - loss: 1.0681 - acc: 0.4606 - val_loss: 1.0724 - val_acc: 0.4271\n",
            "Epoch 46/50 - 0.10s - loss: 1.0675 - acc: 0.4595 - val_loss: 1.0720 - val_acc: 0.4312\n",
            "Epoch 47/50 - 0.10s - loss: 1.0670 - acc: 0.4618 - val_loss: 1.0716 - val_acc: 0.4291\n",
            "Epoch 48/50 - 0.12s - loss: 1.0664 - acc: 0.4638 - val_loss: 1.0712 - val_acc: 0.4291\n",
            "Epoch 49/50 - 0.11s - loss: 1.0659 - acc: 0.4676 - val_loss: 1.0707 - val_acc: 0.4312\n",
            "Epoch 50/50 - 0.14s - loss: 1.0653 - acc: 0.4660 - val_loss: 1.0704 - val_acc: 0.4291\n",
            "\n",
            "Combination 191/252:\n",
            "Hidden Layers: [256, 128, 64], Activation: relu, Learning Rate: 0.001, Batch Size: 64, Epochs: 100\n",
            "Epoch 1/100 - 0.14s - loss: 1.1120 - acc: 0.3104 - val_loss: 1.1167 - val_acc: 0.2935\n",
            "Epoch 2/100 - 0.11s - loss: 1.1038 - acc: 0.3336 - val_loss: 1.1086 - val_acc: 0.3239\n",
            "Epoch 3/100 - 0.11s - loss: 1.0993 - acc: 0.3599 - val_loss: 1.1048 - val_acc: 0.3340\n",
            "Epoch 4/100 - 0.12s - loss: 1.0964 - acc: 0.3752 - val_loss: 1.1024 - val_acc: 0.3259\n",
            "Epoch 5/100 - 0.11s - loss: 1.0940 - acc: 0.3819 - val_loss: 1.1006 - val_acc: 0.3381\n",
            "Epoch 6/100 - 0.12s - loss: 1.0920 - acc: 0.3893 - val_loss: 1.0992 - val_acc: 0.3502\n",
            "Epoch 7/100 - 0.10s - loss: 1.0901 - acc: 0.3972 - val_loss: 1.0978 - val_acc: 0.3644\n",
            "Epoch 8/100 - 0.11s - loss: 1.0884 - acc: 0.4026 - val_loss: 1.0964 - val_acc: 0.3664\n",
            "Epoch 9/100 - 0.12s - loss: 1.0868 - acc: 0.4037 - val_loss: 1.0950 - val_acc: 0.3644\n",
            "Epoch 10/100 - 0.12s - loss: 1.0853 - acc: 0.4096 - val_loss: 1.0938 - val_acc: 0.3704\n",
            "Epoch 11/100 - 0.10s - loss: 1.0839 - acc: 0.4114 - val_loss: 1.0928 - val_acc: 0.3725\n",
            "Epoch 12/100 - 0.12s - loss: 1.0825 - acc: 0.4141 - val_loss: 1.0918 - val_acc: 0.3826\n",
            "Epoch 13/100 - 0.11s - loss: 1.0812 - acc: 0.4184 - val_loss: 1.0907 - val_acc: 0.3704\n",
            "Epoch 14/100 - 0.13s - loss: 1.0800 - acc: 0.4213 - val_loss: 1.0897 - val_acc: 0.3785\n",
            "Epoch 15/100 - 0.13s - loss: 1.0788 - acc: 0.4231 - val_loss: 1.0888 - val_acc: 0.3927\n",
            "Epoch 16/100 - 0.11s - loss: 1.0776 - acc: 0.4265 - val_loss: 1.0880 - val_acc: 0.3968\n",
            "Epoch 17/100 - 0.11s - loss: 1.0765 - acc: 0.4265 - val_loss: 1.0871 - val_acc: 0.4028\n",
            "Epoch 18/100 - 0.14s - loss: 1.0754 - acc: 0.4303 - val_loss: 1.0863 - val_acc: 0.3988\n",
            "Epoch 19/100 - 0.12s - loss: 1.0744 - acc: 0.4321 - val_loss: 1.0856 - val_acc: 0.3968\n",
            "Epoch 20/100 - 0.11s - loss: 1.0734 - acc: 0.4327 - val_loss: 1.0848 - val_acc: 0.3927\n",
            "Epoch 21/100 - 0.11s - loss: 1.0724 - acc: 0.4350 - val_loss: 1.0841 - val_acc: 0.3927\n",
            "Epoch 22/100 - 0.12s - loss: 1.0715 - acc: 0.4388 - val_loss: 1.0834 - val_acc: 0.3947\n",
            "Epoch 23/100 - 0.11s - loss: 1.0705 - acc: 0.4417 - val_loss: 1.0828 - val_acc: 0.4049\n",
            "Epoch 24/100 - 0.10s - loss: 1.0696 - acc: 0.4406 - val_loss: 1.0822 - val_acc: 0.4069\n",
            "Epoch 25/100 - 0.10s - loss: 1.0688 - acc: 0.4399 - val_loss: 1.0815 - val_acc: 0.4089\n",
            "Epoch 26/100 - 0.11s - loss: 1.0679 - acc: 0.4429 - val_loss: 1.0810 - val_acc: 0.4089\n",
            "Epoch 27/100 - 0.12s - loss: 1.0671 - acc: 0.4438 - val_loss: 1.0806 - val_acc: 0.4049\n",
            "Epoch 28/100 - 0.13s - loss: 1.0662 - acc: 0.4429 - val_loss: 1.0800 - val_acc: 0.4008\n",
            "Epoch 29/100 - 0.11s - loss: 1.0654 - acc: 0.4435 - val_loss: 1.0794 - val_acc: 0.4069\n",
            "Epoch 30/100 - 0.11s - loss: 1.0646 - acc: 0.4458 - val_loss: 1.0789 - val_acc: 0.4069\n",
            "Epoch 31/100 - 0.15s - loss: 1.0638 - acc: 0.4453 - val_loss: 1.0783 - val_acc: 0.4170\n",
            "Epoch 32/100 - 0.12s - loss: 1.0631 - acc: 0.4483 - val_loss: 1.0778 - val_acc: 0.4211\n",
            "Epoch 33/100 - 0.12s - loss: 1.0623 - acc: 0.4521 - val_loss: 1.0774 - val_acc: 0.4190\n",
            "Epoch 34/100 - 0.12s - loss: 1.0616 - acc: 0.4534 - val_loss: 1.0768 - val_acc: 0.4231\n",
            "Epoch 35/100 - 0.11s - loss: 1.0608 - acc: 0.4528 - val_loss: 1.0764 - val_acc: 0.4190\n",
            "Epoch 36/100 - 0.11s - loss: 1.0601 - acc: 0.4525 - val_loss: 1.0760 - val_acc: 0.4190\n",
            "Epoch 37/100 - 0.10s - loss: 1.0594 - acc: 0.4532 - val_loss: 1.0755 - val_acc: 0.4251\n",
            "Epoch 38/100 - 0.10s - loss: 1.0587 - acc: 0.4534 - val_loss: 1.0751 - val_acc: 0.4190\n",
            "Epoch 39/100 - 0.12s - loss: 1.0581 - acc: 0.4564 - val_loss: 1.0747 - val_acc: 0.4312\n",
            "Epoch 40/100 - 0.10s - loss: 1.0574 - acc: 0.4577 - val_loss: 1.0743 - val_acc: 0.4332\n",
            "Epoch 41/100 - 0.12s - loss: 1.0567 - acc: 0.4584 - val_loss: 1.0739 - val_acc: 0.4231\n",
            "Epoch 42/100 - 0.11s - loss: 1.0560 - acc: 0.4584 - val_loss: 1.0736 - val_acc: 0.4211\n",
            "Epoch 43/100 - 0.11s - loss: 1.0554 - acc: 0.4586 - val_loss: 1.0732 - val_acc: 0.4271\n",
            "Epoch 44/100 - 0.10s - loss: 1.0548 - acc: 0.4586 - val_loss: 1.0728 - val_acc: 0.4251\n",
            "Epoch 45/100 - 0.15s - loss: 1.0541 - acc: 0.4602 - val_loss: 1.0724 - val_acc: 0.4271\n",
            "Epoch 46/100 - 0.12s - loss: 1.0535 - acc: 0.4595 - val_loss: 1.0721 - val_acc: 0.4291\n",
            "Epoch 47/100 - 0.11s - loss: 1.0529 - acc: 0.4588 - val_loss: 1.0717 - val_acc: 0.4271\n",
            "Epoch 48/100 - 0.12s - loss: 1.0523 - acc: 0.4615 - val_loss: 1.0715 - val_acc: 0.4251\n",
            "Epoch 49/100 - 0.13s - loss: 1.0517 - acc: 0.4618 - val_loss: 1.0711 - val_acc: 0.4271\n",
            "Epoch 50/100 - 0.12s - loss: 1.0511 - acc: 0.4604 - val_loss: 1.0706 - val_acc: 0.4271\n",
            "Epoch 51/100 - 0.11s - loss: 1.0505 - acc: 0.4620 - val_loss: 1.0703 - val_acc: 0.4291\n",
            "Epoch 52/100 - 0.12s - loss: 1.0499 - acc: 0.4631 - val_loss: 1.0700 - val_acc: 0.4291\n",
            "Epoch 53/100 - 0.11s - loss: 1.0493 - acc: 0.4631 - val_loss: 1.0698 - val_acc: 0.4291\n",
            "Epoch 54/100 - 0.11s - loss: 1.0488 - acc: 0.4638 - val_loss: 1.0695 - val_acc: 0.4291\n",
            "Epoch 55/100 - 0.13s - loss: 1.0482 - acc: 0.4656 - val_loss: 1.0692 - val_acc: 0.4312\n",
            "Epoch 56/100 - 0.10s - loss: 1.0476 - acc: 0.4645 - val_loss: 1.0689 - val_acc: 0.4291\n",
            "Epoch 57/100 - 0.13s - loss: 1.0471 - acc: 0.4663 - val_loss: 1.0685 - val_acc: 0.4251\n",
            "Epoch 58/100 - 0.11s - loss: 1.0465 - acc: 0.4669 - val_loss: 1.0681 - val_acc: 0.4291\n",
            "Epoch 59/100 - 0.11s - loss: 1.0460 - acc: 0.4674 - val_loss: 1.0677 - val_acc: 0.4211\n",
            "Epoch 60/100 - 0.11s - loss: 1.0454 - acc: 0.4687 - val_loss: 1.0675 - val_acc: 0.4251\n",
            "Epoch 61/100 - 0.11s - loss: 1.0449 - acc: 0.4687 - val_loss: 1.0672 - val_acc: 0.4231\n",
            "Epoch 62/100 - 0.11s - loss: 1.0443 - acc: 0.4701 - val_loss: 1.0670 - val_acc: 0.4291\n",
            "Epoch 63/100 - 0.12s - loss: 1.0438 - acc: 0.4696 - val_loss: 1.0666 - val_acc: 0.4231\n",
            "Epoch 64/100 - 0.11s - loss: 1.0432 - acc: 0.4685 - val_loss: 1.0665 - val_acc: 0.4312\n",
            "Epoch 65/100 - 0.11s - loss: 1.0427 - acc: 0.4687 - val_loss: 1.0662 - val_acc: 0.4291\n",
            "Epoch 66/100 - 0.10s - loss: 1.0422 - acc: 0.4683 - val_loss: 1.0660 - val_acc: 0.4332\n",
            "Epoch 67/100 - 0.11s - loss: 1.0416 - acc: 0.4685 - val_loss: 1.0656 - val_acc: 0.4291\n",
            "Epoch 68/100 - 0.11s - loss: 1.0411 - acc: 0.4692 - val_loss: 1.0653 - val_acc: 0.4271\n",
            "Epoch 69/100 - 0.11s - loss: 1.0406 - acc: 0.4692 - val_loss: 1.0651 - val_acc: 0.4312\n",
            "Epoch 70/100 - 0.11s - loss: 1.0401 - acc: 0.4699 - val_loss: 1.0647 - val_acc: 0.4291\n",
            "Epoch 71/100 - 0.15s - loss: 1.0395 - acc: 0.4678 - val_loss: 1.0647 - val_acc: 0.4413\n",
            "Epoch 72/100 - 0.11s - loss: 1.0390 - acc: 0.4728 - val_loss: 1.0643 - val_acc: 0.4372\n",
            "Epoch 73/100 - 0.10s - loss: 1.0385 - acc: 0.4741 - val_loss: 1.0641 - val_acc: 0.4372\n",
            "Epoch 74/100 - 0.10s - loss: 1.0380 - acc: 0.4741 - val_loss: 1.0639 - val_acc: 0.4372\n",
            "Epoch 75/100 - 0.13s - loss: 1.0374 - acc: 0.4719 - val_loss: 1.0636 - val_acc: 0.4413\n",
            "Epoch 76/100 - 0.10s - loss: 1.0369 - acc: 0.4757 - val_loss: 1.0633 - val_acc: 0.4413\n",
            "Epoch 77/100 - 0.10s - loss: 1.0364 - acc: 0.4762 - val_loss: 1.0629 - val_acc: 0.4433\n",
            "Epoch 78/100 - 0.11s - loss: 1.0359 - acc: 0.4757 - val_loss: 1.0627 - val_acc: 0.4433\n",
            "Epoch 79/100 - 0.10s - loss: 1.0354 - acc: 0.4755 - val_loss: 1.0624 - val_acc: 0.4453\n",
            "Epoch 80/100 - 0.11s - loss: 1.0349 - acc: 0.4746 - val_loss: 1.0621 - val_acc: 0.4453\n",
            "Epoch 81/100 - 0.11s - loss: 1.0343 - acc: 0.4777 - val_loss: 1.0620 - val_acc: 0.4413\n",
            "Epoch 82/100 - 0.11s - loss: 1.0338 - acc: 0.4791 - val_loss: 1.0616 - val_acc: 0.4453\n",
            "Epoch 83/100 - 0.11s - loss: 1.0334 - acc: 0.4813 - val_loss: 1.0616 - val_acc: 0.4433\n",
            "Epoch 84/100 - 0.10s - loss: 1.0328 - acc: 0.4811 - val_loss: 1.0611 - val_acc: 0.4433\n",
            "Epoch 85/100 - 0.11s - loss: 1.0323 - acc: 0.4798 - val_loss: 1.0607 - val_acc: 0.4433\n",
            "Epoch 86/100 - 0.11s - loss: 1.0318 - acc: 0.4789 - val_loss: 1.0604 - val_acc: 0.4453\n",
            "Epoch 87/100 - 0.11s - loss: 1.0313 - acc: 0.4771 - val_loss: 1.0603 - val_acc: 0.4494\n",
            "Epoch 88/100 - 0.11s - loss: 1.0308 - acc: 0.4800 - val_loss: 1.0600 - val_acc: 0.4413\n",
            "Epoch 89/100 - 0.11s - loss: 1.0303 - acc: 0.4813 - val_loss: 1.0596 - val_acc: 0.4453\n",
            "Epoch 90/100 - 0.10s - loss: 1.0298 - acc: 0.4845 - val_loss: 1.0592 - val_acc: 0.4534\n",
            "Epoch 91/100 - 0.11s - loss: 1.0293 - acc: 0.4863 - val_loss: 1.0591 - val_acc: 0.4514\n",
            "Epoch 92/100 - 0.11s - loss: 1.0288 - acc: 0.4847 - val_loss: 1.0587 - val_acc: 0.4534\n",
            "Epoch 93/100 - 0.11s - loss: 1.0283 - acc: 0.4849 - val_loss: 1.0584 - val_acc: 0.4534\n",
            "Epoch 94/100 - 0.10s - loss: 1.0278 - acc: 0.4849 - val_loss: 1.0585 - val_acc: 0.4575\n",
            "Epoch 95/100 - 0.11s - loss: 1.0272 - acc: 0.4858 - val_loss: 1.0579 - val_acc: 0.4555\n",
            "Epoch 96/100 - 0.11s - loss: 1.0267 - acc: 0.4849 - val_loss: 1.0576 - val_acc: 0.4595\n",
            "Epoch 97/100 - 0.14s - loss: 1.0262 - acc: 0.4858 - val_loss: 1.0573 - val_acc: 0.4555\n",
            "Epoch 98/100 - 0.11s - loss: 1.0257 - acc: 0.4847 - val_loss: 1.0571 - val_acc: 0.4595\n",
            "Epoch 99/100 - 0.10s - loss: 1.0252 - acc: 0.4881 - val_loss: 1.0570 - val_acc: 0.4575\n",
            "Epoch 100/100 - 0.10s - loss: 1.0247 - acc: 0.4888 - val_loss: 1.0565 - val_acc: 0.4615\n",
            "\n",
            "Combination 192/252:\n",
            "Hidden Layers: [256, 128, 64], Activation: relu, Learning Rate: 0.001, Batch Size: 64, Epochs: 150\n",
            "Epoch 1/150 - 0.11s - loss: 1.1413 - acc: 0.3225 - val_loss: 1.1317 - val_acc: 0.3360\n",
            "Epoch 2/150 - 0.10s - loss: 1.1229 - acc: 0.3225 - val_loss: 1.1154 - val_acc: 0.3360\n",
            "Epoch 3/150 - 0.10s - loss: 1.1128 - acc: 0.3225 - val_loss: 1.1068 - val_acc: 0.3360\n",
            "Epoch 4/150 - 0.10s - loss: 1.1067 - acc: 0.3248 - val_loss: 1.1019 - val_acc: 0.3360\n",
            "Epoch 5/150 - 0.12s - loss: 1.1026 - acc: 0.3239 - val_loss: 1.0988 - val_acc: 0.3381\n",
            "Epoch 6/150 - 0.11s - loss: 1.0998 - acc: 0.3268 - val_loss: 1.0967 - val_acc: 0.3300\n",
            "Epoch 7/150 - 0.10s - loss: 1.0976 - acc: 0.3390 - val_loss: 1.0952 - val_acc: 0.3522\n",
            "Epoch 8/150 - 0.10s - loss: 1.0959 - acc: 0.3525 - val_loss: 1.0941 - val_acc: 0.3644\n",
            "Epoch 9/150 - 0.11s - loss: 1.0945 - acc: 0.3698 - val_loss: 1.0932 - val_acc: 0.3765\n",
            "Epoch 10/150 - 0.13s - loss: 1.0933 - acc: 0.3792 - val_loss: 1.0925 - val_acc: 0.3947\n",
            "Epoch 11/150 - 0.11s - loss: 1.0922 - acc: 0.3896 - val_loss: 1.0918 - val_acc: 0.3927\n",
            "Epoch 12/150 - 0.11s - loss: 1.0913 - acc: 0.3983 - val_loss: 1.0912 - val_acc: 0.4008\n",
            "Epoch 13/150 - 0.12s - loss: 1.0903 - acc: 0.4031 - val_loss: 1.0906 - val_acc: 0.4109\n",
            "Epoch 14/150 - 0.12s - loss: 1.0894 - acc: 0.4100 - val_loss: 1.0901 - val_acc: 0.4069\n",
            "Epoch 15/150 - 0.11s - loss: 1.0885 - acc: 0.4121 - val_loss: 1.0896 - val_acc: 0.3968\n",
            "Epoch 16/150 - 0.10s - loss: 1.0877 - acc: 0.4175 - val_loss: 1.0892 - val_acc: 0.3968\n",
            "Epoch 17/150 - 0.11s - loss: 1.0869 - acc: 0.4267 - val_loss: 1.0887 - val_acc: 0.4049\n",
            "Epoch 18/150 - 0.11s - loss: 1.0861 - acc: 0.4256 - val_loss: 1.0882 - val_acc: 0.4089\n",
            "Epoch 19/150 - 0.13s - loss: 1.0853 - acc: 0.4262 - val_loss: 1.0877 - val_acc: 0.4089\n",
            "Epoch 20/150 - 0.10s - loss: 1.0846 - acc: 0.4303 - val_loss: 1.0872 - val_acc: 0.4130\n",
            "Epoch 21/150 - 0.10s - loss: 1.0839 - acc: 0.4316 - val_loss: 1.0866 - val_acc: 0.4170\n",
            "Epoch 22/150 - 0.12s - loss: 1.0831 - acc: 0.4334 - val_loss: 1.0861 - val_acc: 0.4231\n",
            "Epoch 23/150 - 0.12s - loss: 1.0824 - acc: 0.4363 - val_loss: 1.0856 - val_acc: 0.4251\n",
            "Epoch 24/150 - 0.11s - loss: 1.0817 - acc: 0.4386 - val_loss: 1.0850 - val_acc: 0.4271\n",
            "Epoch 25/150 - 0.10s - loss: 1.0810 - acc: 0.4415 - val_loss: 1.0845 - val_acc: 0.4251\n",
            "Epoch 26/150 - 0.10s - loss: 1.0802 - acc: 0.4413 - val_loss: 1.0839 - val_acc: 0.4251\n",
            "Epoch 27/150 - 0.11s - loss: 1.0795 - acc: 0.4415 - val_loss: 1.0834 - val_acc: 0.4211\n",
            "Epoch 28/150 - 0.10s - loss: 1.0788 - acc: 0.4458 - val_loss: 1.0828 - val_acc: 0.4271\n",
            "Epoch 29/150 - 0.10s - loss: 1.0781 - acc: 0.4474 - val_loss: 1.0823 - val_acc: 0.4190\n",
            "Epoch 30/150 - 0.10s - loss: 1.0773 - acc: 0.4483 - val_loss: 1.0817 - val_acc: 0.4211\n",
            "Epoch 31/150 - 0.11s - loss: 1.0766 - acc: 0.4494 - val_loss: 1.0812 - val_acc: 0.4271\n",
            "Epoch 32/150 - 0.10s - loss: 1.0759 - acc: 0.4503 - val_loss: 1.0807 - val_acc: 0.4231\n",
            "Epoch 33/150 - 0.11s - loss: 1.0752 - acc: 0.4514 - val_loss: 1.0802 - val_acc: 0.4312\n",
            "Epoch 34/150 - 0.10s - loss: 1.0745 - acc: 0.4521 - val_loss: 1.0797 - val_acc: 0.4312\n",
            "Epoch 35/150 - 0.10s - loss: 1.0737 - acc: 0.4541 - val_loss: 1.0791 - val_acc: 0.4332\n",
            "Epoch 36/150 - 0.10s - loss: 1.0730 - acc: 0.4561 - val_loss: 1.0786 - val_acc: 0.4352\n",
            "Epoch 37/150 - 0.12s - loss: 1.0723 - acc: 0.4546 - val_loss: 1.0780 - val_acc: 0.4352\n",
            "Epoch 38/150 - 0.10s - loss: 1.0716 - acc: 0.4564 - val_loss: 1.0775 - val_acc: 0.4352\n",
            "Epoch 39/150 - 0.10s - loss: 1.0710 - acc: 0.4575 - val_loss: 1.0771 - val_acc: 0.4352\n",
            "Epoch 40/150 - 0.10s - loss: 1.0703 - acc: 0.4588 - val_loss: 1.0766 - val_acc: 0.4372\n",
            "Epoch 41/150 - 0.12s - loss: 1.0696 - acc: 0.4597 - val_loss: 1.0760 - val_acc: 0.4352\n",
            "Epoch 42/150 - 0.10s - loss: 1.0689 - acc: 0.4606 - val_loss: 1.0755 - val_acc: 0.4372\n",
            "Epoch 43/150 - 0.11s - loss: 1.0683 - acc: 0.4615 - val_loss: 1.0750 - val_acc: 0.4393\n",
            "Epoch 44/150 - 0.10s - loss: 1.0676 - acc: 0.4649 - val_loss: 1.0745 - val_acc: 0.4413\n",
            "Epoch 45/150 - 0.10s - loss: 1.0669 - acc: 0.4649 - val_loss: 1.0741 - val_acc: 0.4413\n",
            "Epoch 46/150 - 0.10s - loss: 1.0663 - acc: 0.4663 - val_loss: 1.0736 - val_acc: 0.4413\n",
            "Epoch 47/150 - 0.12s - loss: 1.0656 - acc: 0.4674 - val_loss: 1.0731 - val_acc: 0.4413\n",
            "Epoch 48/150 - 0.11s - loss: 1.0649 - acc: 0.4681 - val_loss: 1.0726 - val_acc: 0.4453\n",
            "Epoch 49/150 - 0.10s - loss: 1.0643 - acc: 0.4699 - val_loss: 1.0721 - val_acc: 0.4413\n",
            "Epoch 50/150 - 0.10s - loss: 1.0636 - acc: 0.4701 - val_loss: 1.0716 - val_acc: 0.4413\n",
            "Epoch 51/150 - 0.11s - loss: 1.0629 - acc: 0.4701 - val_loss: 1.0711 - val_acc: 0.4453\n",
            "Epoch 52/150 - 0.10s - loss: 1.0623 - acc: 0.4708 - val_loss: 1.0706 - val_acc: 0.4453\n",
            "Epoch 53/150 - 0.11s - loss: 1.0617 - acc: 0.4714 - val_loss: 1.0702 - val_acc: 0.4474\n",
            "Epoch 54/150 - 0.10s - loss: 1.0610 - acc: 0.4726 - val_loss: 1.0697 - val_acc: 0.4453\n",
            "Epoch 55/150 - 0.10s - loss: 1.0604 - acc: 0.4719 - val_loss: 1.0692 - val_acc: 0.4474\n",
            "Epoch 56/150 - 0.11s - loss: 1.0598 - acc: 0.4732 - val_loss: 1.0688 - val_acc: 0.4453\n",
            "Epoch 57/150 - 0.10s - loss: 1.0592 - acc: 0.4735 - val_loss: 1.0683 - val_acc: 0.4413\n",
            "Epoch 58/150 - 0.10s - loss: 1.0585 - acc: 0.4753 - val_loss: 1.0679 - val_acc: 0.4393\n",
            "Epoch 59/150 - 0.11s - loss: 1.0579 - acc: 0.4766 - val_loss: 1.0675 - val_acc: 0.4433\n",
            "Epoch 60/150 - 0.10s - loss: 1.0573 - acc: 0.4773 - val_loss: 1.0670 - val_acc: 0.4393\n",
            "Epoch 61/150 - 0.10s - loss: 1.0567 - acc: 0.4773 - val_loss: 1.0666 - val_acc: 0.4352\n",
            "Epoch 62/150 - 0.11s - loss: 1.0561 - acc: 0.4762 - val_loss: 1.0662 - val_acc: 0.4413\n",
            "Epoch 63/150 - 0.10s - loss: 1.0555 - acc: 0.4771 - val_loss: 1.0658 - val_acc: 0.4413\n",
            "Epoch 64/150 - 0.10s - loss: 1.0549 - acc: 0.4773 - val_loss: 1.0654 - val_acc: 0.4372\n",
            "Epoch 65/150 - 0.10s - loss: 1.0543 - acc: 0.4775 - val_loss: 1.0649 - val_acc: 0.4393\n",
            "Epoch 66/150 - 0.14s - loss: 1.0537 - acc: 0.4775 - val_loss: 1.0645 - val_acc: 0.4393\n",
            "Epoch 67/150 - 0.11s - loss: 1.0531 - acc: 0.4775 - val_loss: 1.0641 - val_acc: 0.4413\n",
            "Epoch 68/150 - 0.11s - loss: 1.0526 - acc: 0.4780 - val_loss: 1.0636 - val_acc: 0.4413\n",
            "Epoch 69/150 - 0.10s - loss: 1.0520 - acc: 0.4771 - val_loss: 1.0632 - val_acc: 0.4433\n",
            "Epoch 70/150 - 0.10s - loss: 1.0514 - acc: 0.4775 - val_loss: 1.0627 - val_acc: 0.4413\n",
            "Epoch 71/150 - 0.10s - loss: 1.0508 - acc: 0.4777 - val_loss: 1.0623 - val_acc: 0.4433\n",
            "Epoch 72/150 - 0.11s - loss: 1.0502 - acc: 0.4789 - val_loss: 1.0619 - val_acc: 0.4453\n",
            "Epoch 73/150 - 0.10s - loss: 1.0496 - acc: 0.4807 - val_loss: 1.0615 - val_acc: 0.4474\n",
            "Epoch 74/150 - 0.11s - loss: 1.0490 - acc: 0.4807 - val_loss: 1.0611 - val_acc: 0.4474\n",
            "Epoch 75/150 - 0.11s - loss: 1.0485 - acc: 0.4807 - val_loss: 1.0607 - val_acc: 0.4474\n",
            "Epoch 76/150 - 0.12s - loss: 1.0479 - acc: 0.4816 - val_loss: 1.0603 - val_acc: 0.4474\n",
            "Epoch 77/150 - 0.11s - loss: 1.0473 - acc: 0.4822 - val_loss: 1.0599 - val_acc: 0.4474\n",
            "Epoch 78/150 - 0.11s - loss: 1.0467 - acc: 0.4816 - val_loss: 1.0595 - val_acc: 0.4474\n",
            "Epoch 79/150 - 0.11s - loss: 1.0461 - acc: 0.4829 - val_loss: 1.0591 - val_acc: 0.4494\n",
            "Epoch 80/150 - 0.13s - loss: 1.0455 - acc: 0.4840 - val_loss: 1.0587 - val_acc: 0.4494\n",
            "Epoch 81/150 - 0.13s - loss: 1.0450 - acc: 0.4834 - val_loss: 1.0583 - val_acc: 0.4514\n",
            "Epoch 82/150 - 0.12s - loss: 1.0444 - acc: 0.4838 - val_loss: 1.0578 - val_acc: 0.4494\n",
            "Epoch 83/150 - 0.12s - loss: 1.0438 - acc: 0.4858 - val_loss: 1.0575 - val_acc: 0.4494\n",
            "Epoch 84/150 - 0.11s - loss: 1.0433 - acc: 0.4849 - val_loss: 1.0570 - val_acc: 0.4514\n",
            "Epoch 85/150 - 0.12s - loss: 1.0427 - acc: 0.4861 - val_loss: 1.0566 - val_acc: 0.4534\n",
            "Epoch 86/150 - 0.11s - loss: 1.0421 - acc: 0.4876 - val_loss: 1.0563 - val_acc: 0.4514\n",
            "Epoch 87/150 - 0.11s - loss: 1.0416 - acc: 0.4858 - val_loss: 1.0559 - val_acc: 0.4555\n",
            "Epoch 88/150 - 0.11s - loss: 1.0410 - acc: 0.4872 - val_loss: 1.0555 - val_acc: 0.4555\n",
            "Epoch 89/150 - 0.11s - loss: 1.0405 - acc: 0.4863 - val_loss: 1.0551 - val_acc: 0.4676\n",
            "Epoch 90/150 - 0.10s - loss: 1.0399 - acc: 0.4876 - val_loss: 1.0547 - val_acc: 0.4696\n",
            "Epoch 91/150 - 0.11s - loss: 1.0393 - acc: 0.4903 - val_loss: 1.0543 - val_acc: 0.4555\n",
            "Epoch 92/150 - 0.11s - loss: 1.0388 - acc: 0.4894 - val_loss: 1.0539 - val_acc: 0.4676\n",
            "Epoch 93/150 - 0.11s - loss: 1.0382 - acc: 0.4908 - val_loss: 1.0536 - val_acc: 0.4534\n",
            "Epoch 94/150 - 0.11s - loss: 1.0377 - acc: 0.4906 - val_loss: 1.0532 - val_acc: 0.4636\n",
            "Epoch 95/150 - 0.11s - loss: 1.0371 - acc: 0.4926 - val_loss: 1.0529 - val_acc: 0.4555\n",
            "Epoch 96/150 - 0.10s - loss: 1.0366 - acc: 0.4919 - val_loss: 1.0525 - val_acc: 0.4575\n",
            "Epoch 97/150 - 0.12s - loss: 1.0360 - acc: 0.4935 - val_loss: 1.0521 - val_acc: 0.4555\n",
            "Epoch 98/150 - 0.10s - loss: 1.0355 - acc: 0.4928 - val_loss: 1.0517 - val_acc: 0.4575\n",
            "Epoch 99/150 - 0.12s - loss: 1.0349 - acc: 0.4951 - val_loss: 1.0514 - val_acc: 0.4575\n",
            "Epoch 100/150 - 0.10s - loss: 1.0344 - acc: 0.4930 - val_loss: 1.0509 - val_acc: 0.4615\n",
            "Epoch 101/150 - 0.11s - loss: 1.0338 - acc: 0.4960 - val_loss: 1.0506 - val_acc: 0.4595\n",
            "Epoch 102/150 - 0.12s - loss: 1.0333 - acc: 0.4966 - val_loss: 1.0503 - val_acc: 0.4595\n",
            "Epoch 103/150 - 0.10s - loss: 1.0328 - acc: 0.4957 - val_loss: 1.0500 - val_acc: 0.4534\n",
            "Epoch 104/150 - 0.10s - loss: 1.0323 - acc: 0.4962 - val_loss: 1.0496 - val_acc: 0.4514\n",
            "Epoch 105/150 - 0.11s - loss: 1.0317 - acc: 0.4973 - val_loss: 1.0492 - val_acc: 0.4575\n",
            "Epoch 106/150 - 0.10s - loss: 1.0312 - acc: 0.4980 - val_loss: 1.0489 - val_acc: 0.4575\n",
            "Epoch 107/150 - 0.10s - loss: 1.0307 - acc: 0.4973 - val_loss: 1.0485 - val_acc: 0.4575\n",
            "Epoch 108/150 - 0.10s - loss: 1.0301 - acc: 0.4978 - val_loss: 1.0480 - val_acc: 0.4636\n",
            "Epoch 109/150 - 0.10s - loss: 1.0296 - acc: 0.4980 - val_loss: 1.0476 - val_acc: 0.4656\n",
            "Epoch 110/150 - 0.11s - loss: 1.0290 - acc: 0.5002 - val_loss: 1.0472 - val_acc: 0.4656\n",
            "Epoch 111/150 - 0.13s - loss: 1.0285 - acc: 0.5011 - val_loss: 1.0469 - val_acc: 0.4615\n",
            "Epoch 112/150 - 0.12s - loss: 1.0279 - acc: 0.5007 - val_loss: 1.0465 - val_acc: 0.4636\n",
            "Epoch 113/150 - 0.13s - loss: 1.0274 - acc: 0.5018 - val_loss: 1.0461 - val_acc: 0.4656\n",
            "Epoch 114/150 - 0.12s - loss: 1.0269 - acc: 0.5007 - val_loss: 1.0459 - val_acc: 0.4595\n",
            "Epoch 115/150 - 0.12s - loss: 1.0263 - acc: 0.5018 - val_loss: 1.0453 - val_acc: 0.4656\n",
            "Epoch 116/150 - 0.11s - loss: 1.0258 - acc: 0.5022 - val_loss: 1.0448 - val_acc: 0.4656\n",
            "Epoch 117/150 - 0.13s - loss: 1.0252 - acc: 0.5036 - val_loss: 1.0446 - val_acc: 0.4636\n",
            "Epoch 118/150 - 0.11s - loss: 1.0247 - acc: 0.5031 - val_loss: 1.0440 - val_acc: 0.4676\n",
            "Epoch 119/150 - 0.11s - loss: 1.0241 - acc: 0.5038 - val_loss: 1.0436 - val_acc: 0.4717\n",
            "Epoch 120/150 - 0.10s - loss: 1.0236 - acc: 0.5049 - val_loss: 1.0432 - val_acc: 0.4696\n",
            "Epoch 121/150 - 0.10s - loss: 1.0231 - acc: 0.5056 - val_loss: 1.0428 - val_acc: 0.4737\n",
            "Epoch 122/150 - 0.10s - loss: 1.0225 - acc: 0.5058 - val_loss: 1.0425 - val_acc: 0.4696\n",
            "Epoch 123/150 - 0.12s - loss: 1.0220 - acc: 0.5054 - val_loss: 1.0423 - val_acc: 0.4615\n",
            "Epoch 124/150 - 0.11s - loss: 1.0214 - acc: 0.5063 - val_loss: 1.0418 - val_acc: 0.4636\n",
            "Epoch 125/150 - 0.10s - loss: 1.0209 - acc: 0.5067 - val_loss: 1.0413 - val_acc: 0.4717\n",
            "Epoch 126/150 - 0.10s - loss: 1.0204 - acc: 0.5065 - val_loss: 1.0411 - val_acc: 0.4656\n",
            "Epoch 127/150 - 0.11s - loss: 1.0198 - acc: 0.5072 - val_loss: 1.0406 - val_acc: 0.4696\n",
            "Epoch 128/150 - 0.10s - loss: 1.0192 - acc: 0.5081 - val_loss: 1.0402 - val_acc: 0.4696\n",
            "Epoch 129/150 - 0.10s - loss: 1.0187 - acc: 0.5092 - val_loss: 1.0398 - val_acc: 0.4696\n",
            "Epoch 130/150 - 0.10s - loss: 1.0182 - acc: 0.5088 - val_loss: 1.0393 - val_acc: 0.4737\n",
            "Epoch 131/150 - 0.10s - loss: 1.0177 - acc: 0.5088 - val_loss: 1.0392 - val_acc: 0.4676\n",
            "Epoch 132/150 - 0.10s - loss: 1.0171 - acc: 0.5099 - val_loss: 1.0387 - val_acc: 0.4717\n",
            "Epoch 133/150 - 0.12s - loss: 1.0165 - acc: 0.5103 - val_loss: 1.0382 - val_acc: 0.4757\n",
            "Epoch 134/150 - 0.12s - loss: 1.0160 - acc: 0.5117 - val_loss: 1.0378 - val_acc: 0.4757\n",
            "Epoch 135/150 - 0.11s - loss: 1.0155 - acc: 0.5108 - val_loss: 1.0376 - val_acc: 0.4737\n",
            "Epoch 136/150 - 0.10s - loss: 1.0149 - acc: 0.5108 - val_loss: 1.0372 - val_acc: 0.4757\n",
            "Epoch 137/150 - 0.10s - loss: 1.0144 - acc: 0.5128 - val_loss: 1.0369 - val_acc: 0.4696\n",
            "Epoch 138/150 - 0.13s - loss: 1.0139 - acc: 0.5142 - val_loss: 1.0363 - val_acc: 0.4777\n",
            "Epoch 139/150 - 0.10s - loss: 1.0133 - acc: 0.5144 - val_loss: 1.0359 - val_acc: 0.4798\n",
            "Epoch 140/150 - 0.10s - loss: 1.0128 - acc: 0.5135 - val_loss: 1.0357 - val_acc: 0.4798\n",
            "Epoch 141/150 - 0.10s - loss: 1.0122 - acc: 0.5142 - val_loss: 1.0353 - val_acc: 0.4818\n",
            "Epoch 142/150 - 0.11s - loss: 1.0117 - acc: 0.5124 - val_loss: 1.0350 - val_acc: 0.4777\n",
            "Epoch 143/150 - 0.10s - loss: 1.0111 - acc: 0.5148 - val_loss: 1.0345 - val_acc: 0.4818\n",
            "Epoch 144/150 - 0.10s - loss: 1.0106 - acc: 0.5153 - val_loss: 1.0339 - val_acc: 0.4798\n",
            "Epoch 145/150 - 0.12s - loss: 1.0101 - acc: 0.5164 - val_loss: 1.0334 - val_acc: 0.4858\n",
            "Epoch 146/150 - 0.10s - loss: 1.0096 - acc: 0.5139 - val_loss: 1.0330 - val_acc: 0.4858\n",
            "Epoch 147/150 - 0.10s - loss: 1.0089 - acc: 0.5173 - val_loss: 1.0327 - val_acc: 0.4858\n",
            "Epoch 148/150 - 0.12s - loss: 1.0084 - acc: 0.5175 - val_loss: 1.0325 - val_acc: 0.4879\n",
            "Epoch 149/150 - 0.11s - loss: 1.0078 - acc: 0.5187 - val_loss: 1.0320 - val_acc: 0.4858\n",
            "Epoch 150/150 - 0.11s - loss: 1.0073 - acc: 0.5184 - val_loss: 1.0316 - val_acc: 0.4838\n",
            "\n",
            "Combination 193/252:\n",
            "Hidden Layers: [256, 128, 64], Activation: relu, Learning Rate: 0.0001, Batch Size: 32, Epochs: 50\n",
            "Epoch 1/50 - 0.15s - loss: 1.1334 - acc: 0.3228 - val_loss: 1.1287 - val_acc: 0.3360\n",
            "Epoch 2/50 - 0.15s - loss: 1.1301 - acc: 0.3228 - val_loss: 1.1261 - val_acc: 0.3360\n",
            "Epoch 3/50 - 0.14s - loss: 1.1273 - acc: 0.3219 - val_loss: 1.1238 - val_acc: 0.3360\n",
            "Epoch 4/50 - 0.15s - loss: 1.1247 - acc: 0.3221 - val_loss: 1.1218 - val_acc: 0.3360\n",
            "Epoch 5/50 - 0.15s - loss: 1.1224 - acc: 0.3225 - val_loss: 1.1200 - val_acc: 0.3360\n",
            "Epoch 6/50 - 0.17s - loss: 1.1204 - acc: 0.3219 - val_loss: 1.1184 - val_acc: 0.3360\n",
            "Epoch 7/50 - 0.15s - loss: 1.1187 - acc: 0.3212 - val_loss: 1.1170 - val_acc: 0.3360\n",
            "Epoch 8/50 - 0.15s - loss: 1.1171 - acc: 0.3212 - val_loss: 1.1158 - val_acc: 0.3320\n",
            "Epoch 9/50 - 0.16s - loss: 1.1156 - acc: 0.3207 - val_loss: 1.1147 - val_acc: 0.3279\n",
            "Epoch 10/50 - 0.16s - loss: 1.1143 - acc: 0.3194 - val_loss: 1.1137 - val_acc: 0.3259\n",
            "Epoch 11/50 - 0.15s - loss: 1.1131 - acc: 0.3196 - val_loss: 1.1128 - val_acc: 0.3239\n",
            "Epoch 12/50 - 0.17s - loss: 1.1121 - acc: 0.3189 - val_loss: 1.1120 - val_acc: 0.3239\n",
            "Epoch 13/50 - 0.16s - loss: 1.1111 - acc: 0.3165 - val_loss: 1.1112 - val_acc: 0.3279\n",
            "Epoch 14/50 - 0.16s - loss: 1.1102 - acc: 0.3169 - val_loss: 1.1105 - val_acc: 0.3239\n",
            "Epoch 15/50 - 0.15s - loss: 1.1093 - acc: 0.3167 - val_loss: 1.1099 - val_acc: 0.3279\n",
            "Epoch 16/50 - 0.15s - loss: 1.1085 - acc: 0.3156 - val_loss: 1.1093 - val_acc: 0.3279\n",
            "Epoch 17/50 - 0.14s - loss: 1.1078 - acc: 0.3162 - val_loss: 1.1088 - val_acc: 0.3219\n",
            "Epoch 18/50 - 0.15s - loss: 1.1071 - acc: 0.3144 - val_loss: 1.1083 - val_acc: 0.3198\n",
            "Epoch 19/50 - 0.14s - loss: 1.1065 - acc: 0.3131 - val_loss: 1.1078 - val_acc: 0.3239\n",
            "Epoch 20/50 - 0.14s - loss: 1.1058 - acc: 0.3165 - val_loss: 1.1074 - val_acc: 0.3239\n",
            "Epoch 21/50 - 0.14s - loss: 1.1053 - acc: 0.3183 - val_loss: 1.1070 - val_acc: 0.3178\n",
            "Epoch 22/50 - 0.15s - loss: 1.1047 - acc: 0.3156 - val_loss: 1.1066 - val_acc: 0.3219\n",
            "Epoch 23/50 - 0.15s - loss: 1.1042 - acc: 0.3185 - val_loss: 1.1062 - val_acc: 0.3117\n",
            "Epoch 24/50 - 0.15s - loss: 1.1037 - acc: 0.3183 - val_loss: 1.1058 - val_acc: 0.3016\n",
            "Epoch 25/50 - 0.14s - loss: 1.1032 - acc: 0.3198 - val_loss: 1.1055 - val_acc: 0.2976\n",
            "Epoch 26/50 - 0.18s - loss: 1.1027 - acc: 0.3219 - val_loss: 1.1052 - val_acc: 0.2996\n",
            "Epoch 27/50 - 0.14s - loss: 1.1023 - acc: 0.3257 - val_loss: 1.1049 - val_acc: 0.3036\n",
            "Epoch 28/50 - 0.15s - loss: 1.1018 - acc: 0.3277 - val_loss: 1.1046 - val_acc: 0.3097\n",
            "Epoch 29/50 - 0.15s - loss: 1.1014 - acc: 0.3291 - val_loss: 1.1043 - val_acc: 0.3077\n",
            "Epoch 30/50 - 0.15s - loss: 1.1010 - acc: 0.3311 - val_loss: 1.1041 - val_acc: 0.3138\n",
            "Epoch 31/50 - 0.15s - loss: 1.1006 - acc: 0.3333 - val_loss: 1.1038 - val_acc: 0.3219\n",
            "Epoch 32/50 - 0.14s - loss: 1.1003 - acc: 0.3392 - val_loss: 1.1036 - val_acc: 0.3198\n",
            "Epoch 33/50 - 0.14s - loss: 1.0999 - acc: 0.3417 - val_loss: 1.1033 - val_acc: 0.3259\n",
            "Epoch 34/50 - 0.15s - loss: 1.0995 - acc: 0.3466 - val_loss: 1.1031 - val_acc: 0.3320\n",
            "Epoch 35/50 - 0.14s - loss: 1.0992 - acc: 0.3502 - val_loss: 1.1029 - val_acc: 0.3340\n",
            "Epoch 36/50 - 0.14s - loss: 1.0989 - acc: 0.3522 - val_loss: 1.1027 - val_acc: 0.3421\n",
            "Epoch 37/50 - 0.14s - loss: 1.0986 - acc: 0.3527 - val_loss: 1.1025 - val_acc: 0.3340\n",
            "Epoch 38/50 - 0.15s - loss: 1.0983 - acc: 0.3552 - val_loss: 1.1023 - val_acc: 0.3279\n",
            "Epoch 39/50 - 0.13s - loss: 1.0980 - acc: 0.3585 - val_loss: 1.1021 - val_acc: 0.3259\n",
            "Epoch 40/50 - 0.14s - loss: 1.0977 - acc: 0.3623 - val_loss: 1.1019 - val_acc: 0.3219\n",
            "Epoch 41/50 - 0.17s - loss: 1.0974 - acc: 0.3637 - val_loss: 1.1017 - val_acc: 0.3239\n",
            "Epoch 42/50 - 0.15s - loss: 1.0971 - acc: 0.3693 - val_loss: 1.1015 - val_acc: 0.3239\n",
            "Epoch 43/50 - 0.13s - loss: 1.0968 - acc: 0.3711 - val_loss: 1.1013 - val_acc: 0.3239\n",
            "Epoch 44/50 - 0.15s - loss: 1.0965 - acc: 0.3720 - val_loss: 1.1011 - val_acc: 0.3239\n",
            "Epoch 45/50 - 0.15s - loss: 1.0962 - acc: 0.3743 - val_loss: 1.1009 - val_acc: 0.3300\n",
            "Epoch 46/50 - 0.15s - loss: 1.0960 - acc: 0.3754 - val_loss: 1.1007 - val_acc: 0.3279\n",
            "Epoch 47/50 - 0.14s - loss: 1.0957 - acc: 0.3767 - val_loss: 1.1005 - val_acc: 0.3300\n",
            "Epoch 48/50 - 0.14s - loss: 1.0954 - acc: 0.3781 - val_loss: 1.1003 - val_acc: 0.3320\n",
            "Epoch 49/50 - 0.15s - loss: 1.0952 - acc: 0.3767 - val_loss: 1.1002 - val_acc: 0.3300\n",
            "Epoch 50/50 - 0.16s - loss: 1.0949 - acc: 0.3808 - val_loss: 1.1000 - val_acc: 0.3300\n",
            "\n",
            "Combination 194/252:\n",
            "Hidden Layers: [256, 128, 64], Activation: relu, Learning Rate: 0.0001, Batch Size: 32, Epochs: 100\n",
            "Epoch 1/100 - 0.14s - loss: 1.1244 - acc: 0.3302 - val_loss: 1.1200 - val_acc: 0.3360\n",
            "Epoch 2/100 - 0.14s - loss: 1.1200 - acc: 0.3291 - val_loss: 1.1161 - val_acc: 0.3401\n",
            "Epoch 3/100 - 0.13s - loss: 1.1164 - acc: 0.3288 - val_loss: 1.1129 - val_acc: 0.3441\n",
            "Epoch 4/100 - 0.14s - loss: 1.1133 - acc: 0.3315 - val_loss: 1.1102 - val_acc: 0.3421\n",
            "Epoch 5/100 - 0.16s - loss: 1.1107 - acc: 0.3322 - val_loss: 1.1080 - val_acc: 0.3462\n",
            "Epoch 6/100 - 0.13s - loss: 1.1085 - acc: 0.3324 - val_loss: 1.1061 - val_acc: 0.3340\n",
            "Epoch 7/100 - 0.13s - loss: 1.1066 - acc: 0.3342 - val_loss: 1.1044 - val_acc: 0.3259\n",
            "Epoch 8/100 - 0.14s - loss: 1.1049 - acc: 0.3354 - val_loss: 1.1030 - val_acc: 0.3279\n",
            "Epoch 9/100 - 0.14s - loss: 1.1035 - acc: 0.3342 - val_loss: 1.1018 - val_acc: 0.3340\n",
            "Epoch 10/100 - 0.14s - loss: 1.1022 - acc: 0.3417 - val_loss: 1.1007 - val_acc: 0.3360\n",
            "Epoch 11/100 - 0.14s - loss: 1.1011 - acc: 0.3446 - val_loss: 1.0998 - val_acc: 0.3340\n",
            "Epoch 12/100 - 0.15s - loss: 1.1002 - acc: 0.3466 - val_loss: 1.0989 - val_acc: 0.3360\n",
            "Epoch 13/100 - 0.14s - loss: 1.0993 - acc: 0.3468 - val_loss: 1.0982 - val_acc: 0.3441\n",
            "Epoch 14/100 - 0.15s - loss: 1.0985 - acc: 0.3480 - val_loss: 1.0975 - val_acc: 0.3502\n",
            "Epoch 15/100 - 0.13s - loss: 1.0978 - acc: 0.3504 - val_loss: 1.0968 - val_acc: 0.3543\n",
            "Epoch 16/100 - 0.15s - loss: 1.0971 - acc: 0.3516 - val_loss: 1.0963 - val_acc: 0.3603\n",
            "Epoch 17/100 - 0.14s - loss: 1.0965 - acc: 0.3529 - val_loss: 1.0958 - val_acc: 0.3522\n",
            "Epoch 18/100 - 0.13s - loss: 1.0960 - acc: 0.3538 - val_loss: 1.0953 - val_acc: 0.3502\n",
            "Epoch 19/100 - 0.15s - loss: 1.0954 - acc: 0.3556 - val_loss: 1.0949 - val_acc: 0.3522\n",
            "Epoch 20/100 - 0.14s - loss: 1.0950 - acc: 0.3567 - val_loss: 1.0945 - val_acc: 0.3482\n",
            "Epoch 21/100 - 0.13s - loss: 1.0945 - acc: 0.3585 - val_loss: 1.0941 - val_acc: 0.3543\n",
            "Epoch 22/100 - 0.14s - loss: 1.0941 - acc: 0.3599 - val_loss: 1.0938 - val_acc: 0.3603\n",
            "Epoch 23/100 - 0.13s - loss: 1.0937 - acc: 0.3630 - val_loss: 1.0934 - val_acc: 0.3664\n",
            "Epoch 24/100 - 0.15s - loss: 1.0933 - acc: 0.3655 - val_loss: 1.0931 - val_acc: 0.3623\n",
            "Epoch 25/100 - 0.13s - loss: 1.0929 - acc: 0.3684 - val_loss: 1.0928 - val_acc: 0.3563\n",
            "Epoch 26/100 - 0.14s - loss: 1.0925 - acc: 0.3682 - val_loss: 1.0925 - val_acc: 0.3684\n",
            "Epoch 27/100 - 0.13s - loss: 1.0922 - acc: 0.3695 - val_loss: 1.0922 - val_acc: 0.3684\n",
            "Epoch 28/100 - 0.14s - loss: 1.0919 - acc: 0.3713 - val_loss: 1.0919 - val_acc: 0.3745\n",
            "Epoch 29/100 - 0.13s - loss: 1.0915 - acc: 0.3720 - val_loss: 1.0917 - val_acc: 0.3866\n",
            "Epoch 30/100 - 0.14s - loss: 1.0912 - acc: 0.3743 - val_loss: 1.0914 - val_acc: 0.3846\n",
            "Epoch 31/100 - 0.13s - loss: 1.0909 - acc: 0.3785 - val_loss: 1.0911 - val_acc: 0.3826\n",
            "Epoch 32/100 - 0.14s - loss: 1.0906 - acc: 0.3790 - val_loss: 1.0909 - val_acc: 0.3725\n",
            "Epoch 33/100 - 0.14s - loss: 1.0903 - acc: 0.3835 - val_loss: 1.0906 - val_acc: 0.3664\n",
            "Epoch 34/100 - 0.15s - loss: 1.0900 - acc: 0.3837 - val_loss: 1.0904 - val_acc: 0.3684\n",
            "Epoch 35/100 - 0.13s - loss: 1.0897 - acc: 0.3821 - val_loss: 1.0902 - val_acc: 0.3684\n",
            "Epoch 36/100 - 0.15s - loss: 1.0894 - acc: 0.3833 - val_loss: 1.0899 - val_acc: 0.3684\n",
            "Epoch 37/100 - 0.14s - loss: 1.0892 - acc: 0.3848 - val_loss: 1.0897 - val_acc: 0.3664\n",
            "Epoch 38/100 - 0.14s - loss: 1.0889 - acc: 0.3844 - val_loss: 1.0895 - val_acc: 0.3623\n",
            "Epoch 39/100 - 0.14s - loss: 1.0886 - acc: 0.3860 - val_loss: 1.0892 - val_acc: 0.3684\n",
            "Epoch 40/100 - 0.15s - loss: 1.0883 - acc: 0.3878 - val_loss: 1.0890 - val_acc: 0.3725\n",
            "Epoch 41/100 - 0.14s - loss: 1.0880 - acc: 0.3907 - val_loss: 1.0888 - val_acc: 0.3785\n",
            "Epoch 42/100 - 0.14s - loss: 1.0878 - acc: 0.3929 - val_loss: 1.0886 - val_acc: 0.3826\n",
            "Epoch 43/100 - 0.14s - loss: 1.0875 - acc: 0.3945 - val_loss: 1.0884 - val_acc: 0.3806\n",
            "Epoch 44/100 - 0.15s - loss: 1.0872 - acc: 0.3950 - val_loss: 1.0882 - val_acc: 0.3806\n",
            "Epoch 45/100 - 0.14s - loss: 1.0870 - acc: 0.3952 - val_loss: 1.0879 - val_acc: 0.3806\n",
            "Epoch 46/100 - 0.13s - loss: 1.0867 - acc: 0.3972 - val_loss: 1.0877 - val_acc: 0.3806\n",
            "Epoch 47/100 - 0.16s - loss: 1.0865 - acc: 0.3992 - val_loss: 1.0875 - val_acc: 0.3846\n",
            "Epoch 48/100 - 0.15s - loss: 1.0862 - acc: 0.4004 - val_loss: 1.0873 - val_acc: 0.3907\n",
            "Epoch 49/100 - 0.14s - loss: 1.0859 - acc: 0.4008 - val_loss: 1.0871 - val_acc: 0.3887\n",
            "Epoch 50/100 - 0.14s - loss: 1.0857 - acc: 0.4037 - val_loss: 1.0869 - val_acc: 0.3826\n",
            "Epoch 51/100 - 0.14s - loss: 1.0854 - acc: 0.4046 - val_loss: 1.0867 - val_acc: 0.3806\n",
            "Epoch 52/100 - 0.15s - loss: 1.0852 - acc: 0.4076 - val_loss: 1.0865 - val_acc: 0.3826\n",
            "Epoch 53/100 - 0.13s - loss: 1.0849 - acc: 0.4091 - val_loss: 1.0863 - val_acc: 0.3866\n",
            "Epoch 54/100 - 0.14s - loss: 1.0847 - acc: 0.4098 - val_loss: 1.0861 - val_acc: 0.3887\n",
            "Epoch 55/100 - 0.14s - loss: 1.0844 - acc: 0.4103 - val_loss: 1.0859 - val_acc: 0.3927\n",
            "Epoch 56/100 - 0.17s - loss: 1.0842 - acc: 0.4109 - val_loss: 1.0857 - val_acc: 0.3927\n",
            "Epoch 57/100 - 0.14s - loss: 1.0839 - acc: 0.4109 - val_loss: 1.0855 - val_acc: 0.3947\n",
            "Epoch 58/100 - 0.15s - loss: 1.0837 - acc: 0.4112 - val_loss: 1.0853 - val_acc: 0.3968\n",
            "Epoch 59/100 - 0.15s - loss: 1.0834 - acc: 0.4116 - val_loss: 1.0851 - val_acc: 0.3947\n",
            "Epoch 60/100 - 0.16s - loss: 1.0832 - acc: 0.4125 - val_loss: 1.0849 - val_acc: 0.3947\n",
            "Epoch 61/100 - 0.17s - loss: 1.0830 - acc: 0.4148 - val_loss: 1.0847 - val_acc: 0.3968\n",
            "Epoch 62/100 - 0.14s - loss: 1.0827 - acc: 0.4154 - val_loss: 1.0846 - val_acc: 0.3968\n",
            "Epoch 63/100 - 0.14s - loss: 1.0825 - acc: 0.4170 - val_loss: 1.0844 - val_acc: 0.4028\n",
            "Epoch 64/100 - 0.15s - loss: 1.0823 - acc: 0.4170 - val_loss: 1.0842 - val_acc: 0.4028\n",
            "Epoch 65/100 - 0.17s - loss: 1.0820 - acc: 0.4177 - val_loss: 1.0840 - val_acc: 0.4008\n",
            "Epoch 66/100 - 0.16s - loss: 1.0818 - acc: 0.4199 - val_loss: 1.0838 - val_acc: 0.4008\n",
            "Epoch 67/100 - 0.15s - loss: 1.0816 - acc: 0.4217 - val_loss: 1.0836 - val_acc: 0.4028\n",
            "Epoch 68/100 - 0.15s - loss: 1.0813 - acc: 0.4217 - val_loss: 1.0834 - val_acc: 0.4028\n",
            "Epoch 69/100 - 0.14s - loss: 1.0811 - acc: 0.4233 - val_loss: 1.0833 - val_acc: 0.4028\n",
            "Epoch 70/100 - 0.15s - loss: 1.0809 - acc: 0.4258 - val_loss: 1.0831 - val_acc: 0.4008\n",
            "Epoch 71/100 - 0.14s - loss: 1.0806 - acc: 0.4271 - val_loss: 1.0829 - val_acc: 0.4008\n",
            "Epoch 72/100 - 0.15s - loss: 1.0804 - acc: 0.4271 - val_loss: 1.0827 - val_acc: 0.4008\n",
            "Epoch 73/100 - 0.14s - loss: 1.0802 - acc: 0.4285 - val_loss: 1.0825 - val_acc: 0.4049\n",
            "Epoch 74/100 - 0.14s - loss: 1.0800 - acc: 0.4305 - val_loss: 1.0824 - val_acc: 0.4109\n",
            "Epoch 75/100 - 0.14s - loss: 1.0797 - acc: 0.4314 - val_loss: 1.0822 - val_acc: 0.4089\n",
            "Epoch 76/100 - 0.15s - loss: 1.0795 - acc: 0.4321 - val_loss: 1.0820 - val_acc: 0.4089\n",
            "Epoch 77/100 - 0.14s - loss: 1.0793 - acc: 0.4341 - val_loss: 1.0818 - val_acc: 0.4089\n",
            "Epoch 78/100 - 0.13s - loss: 1.0790 - acc: 0.4350 - val_loss: 1.0817 - val_acc: 0.4049\n",
            "Epoch 79/100 - 0.13s - loss: 1.0788 - acc: 0.4354 - val_loss: 1.0815 - val_acc: 0.4028\n",
            "Epoch 80/100 - 0.14s - loss: 1.0786 - acc: 0.4381 - val_loss: 1.0813 - val_acc: 0.4049\n",
            "Epoch 81/100 - 0.13s - loss: 1.0784 - acc: 0.4372 - val_loss: 1.0811 - val_acc: 0.4089\n",
            "Epoch 82/100 - 0.14s - loss: 1.0782 - acc: 0.4386 - val_loss: 1.0809 - val_acc: 0.4130\n",
            "Epoch 83/100 - 0.13s - loss: 1.0779 - acc: 0.4402 - val_loss: 1.0807 - val_acc: 0.4069\n",
            "Epoch 84/100 - 0.15s - loss: 1.0777 - acc: 0.4413 - val_loss: 1.0805 - val_acc: 0.4028\n",
            "Epoch 85/100 - 0.14s - loss: 1.0775 - acc: 0.4415 - val_loss: 1.0804 - val_acc: 0.4028\n",
            "Epoch 86/100 - 0.14s - loss: 1.0773 - acc: 0.4424 - val_loss: 1.0802 - val_acc: 0.4028\n",
            "Epoch 87/100 - 0.13s - loss: 1.0771 - acc: 0.4420 - val_loss: 1.0800 - val_acc: 0.4049\n",
            "Epoch 88/100 - 0.15s - loss: 1.0769 - acc: 0.4433 - val_loss: 1.0798 - val_acc: 0.4028\n",
            "Epoch 89/100 - 0.14s - loss: 1.0766 - acc: 0.4456 - val_loss: 1.0796 - val_acc: 0.4028\n",
            "Epoch 90/100 - 0.13s - loss: 1.0764 - acc: 0.4460 - val_loss: 1.0794 - val_acc: 0.4028\n",
            "Epoch 91/100 - 0.14s - loss: 1.0762 - acc: 0.4469 - val_loss: 1.0792 - val_acc: 0.4028\n",
            "Epoch 92/100 - 0.14s - loss: 1.0760 - acc: 0.4474 - val_loss: 1.0791 - val_acc: 0.4028\n",
            "Epoch 93/100 - 0.14s - loss: 1.0758 - acc: 0.4483 - val_loss: 1.0789 - val_acc: 0.4069\n",
            "Epoch 94/100 - 0.14s - loss: 1.0756 - acc: 0.4485 - val_loss: 1.0787 - val_acc: 0.4089\n",
            "Epoch 95/100 - 0.14s - loss: 1.0754 - acc: 0.4501 - val_loss: 1.0785 - val_acc: 0.4130\n",
            "Epoch 96/100 - 0.14s - loss: 1.0752 - acc: 0.4503 - val_loss: 1.0784 - val_acc: 0.4150\n",
            "Epoch 97/100 - 0.13s - loss: 1.0749 - acc: 0.4510 - val_loss: 1.0782 - val_acc: 0.4170\n",
            "Epoch 98/100 - 0.15s - loss: 1.0747 - acc: 0.4519 - val_loss: 1.0780 - val_acc: 0.4190\n",
            "Epoch 99/100 - 0.15s - loss: 1.0745 - acc: 0.4507 - val_loss: 1.0778 - val_acc: 0.4170\n",
            "Epoch 100/100 - 0.18s - loss: 1.0743 - acc: 0.4530 - val_loss: 1.0777 - val_acc: 0.4170\n",
            "\n",
            "Combination 195/252:\n",
            "Hidden Layers: [256, 128, 64], Activation: relu, Learning Rate: 0.0001, Batch Size: 32, Epochs: 150\n",
            "Epoch 1/150 - 0.16s - loss: 1.1035 - acc: 0.3270 - val_loss: 1.0982 - val_acc: 0.3603\n",
            "Epoch 2/150 - 0.15s - loss: 1.1028 - acc: 0.3252 - val_loss: 1.0978 - val_acc: 0.3603\n",
            "Epoch 3/150 - 0.13s - loss: 1.1023 - acc: 0.3250 - val_loss: 1.0974 - val_acc: 0.3583\n",
            "Epoch 4/150 - 0.15s - loss: 1.1018 - acc: 0.3255 - val_loss: 1.0971 - val_acc: 0.3563\n",
            "Epoch 5/150 - 0.13s - loss: 1.1013 - acc: 0.3243 - val_loss: 1.0968 - val_acc: 0.3522\n",
            "Epoch 6/150 - 0.14s - loss: 1.1008 - acc: 0.3221 - val_loss: 1.0965 - val_acc: 0.3543\n",
            "Epoch 7/150 - 0.13s - loss: 1.1004 - acc: 0.3210 - val_loss: 1.0963 - val_acc: 0.3583\n",
            "Epoch 8/150 - 0.14s - loss: 1.1000 - acc: 0.3225 - val_loss: 1.0960 - val_acc: 0.3664\n",
            "Epoch 9/150 - 0.13s - loss: 1.0996 - acc: 0.3219 - val_loss: 1.0958 - val_acc: 0.3704\n",
            "Epoch 10/150 - 0.13s - loss: 1.0992 - acc: 0.3210 - val_loss: 1.0955 - val_acc: 0.3664\n",
            "Epoch 11/150 - 0.13s - loss: 1.0989 - acc: 0.3210 - val_loss: 1.0953 - val_acc: 0.3704\n",
            "Epoch 12/150 - 0.14s - loss: 1.0985 - acc: 0.3239 - val_loss: 1.0951 - val_acc: 0.3664\n",
            "Epoch 13/150 - 0.16s - loss: 1.0982 - acc: 0.3243 - val_loss: 1.0949 - val_acc: 0.3664\n",
            "Epoch 14/150 - 0.24s - loss: 1.0979 - acc: 0.3264 - val_loss: 1.0947 - val_acc: 0.3664\n",
            "Epoch 15/150 - 0.15s - loss: 1.0976 - acc: 0.3284 - val_loss: 1.0945 - val_acc: 0.3664\n",
            "Epoch 16/150 - 0.18s - loss: 1.0973 - acc: 0.3295 - val_loss: 1.0943 - val_acc: 0.3644\n",
            "Epoch 17/150 - 0.15s - loss: 1.0971 - acc: 0.3304 - val_loss: 1.0941 - val_acc: 0.3502\n",
            "Epoch 18/150 - 0.14s - loss: 1.0968 - acc: 0.3315 - val_loss: 1.0940 - val_acc: 0.3522\n",
            "Epoch 19/150 - 0.13s - loss: 1.0965 - acc: 0.3338 - val_loss: 1.0938 - val_acc: 0.3543\n",
            "Epoch 20/150 - 0.14s - loss: 1.0963 - acc: 0.3345 - val_loss: 1.0936 - val_acc: 0.3462\n",
            "Epoch 21/150 - 0.13s - loss: 1.0960 - acc: 0.3369 - val_loss: 1.0934 - val_acc: 0.3482\n",
            "Epoch 22/150 - 0.14s - loss: 1.0958 - acc: 0.3390 - val_loss: 1.0932 - val_acc: 0.3441\n",
            "Epoch 23/150 - 0.13s - loss: 1.0955 - acc: 0.3392 - val_loss: 1.0931 - val_acc: 0.3502\n",
            "Epoch 24/150 - 0.15s - loss: 1.0953 - acc: 0.3394 - val_loss: 1.0929 - val_acc: 0.3522\n",
            "Epoch 25/150 - 0.17s - loss: 1.0951 - acc: 0.3403 - val_loss: 1.0927 - val_acc: 0.3563\n",
            "Epoch 26/150 - 0.17s - loss: 1.0948 - acc: 0.3432 - val_loss: 1.0926 - val_acc: 0.3583\n",
            "Epoch 27/150 - 0.15s - loss: 1.0946 - acc: 0.3464 - val_loss: 1.0924 - val_acc: 0.3623\n",
            "Epoch 28/150 - 0.16s - loss: 1.0944 - acc: 0.3473 - val_loss: 1.0922 - val_acc: 0.3603\n",
            "Epoch 29/150 - 0.14s - loss: 1.0942 - acc: 0.3486 - val_loss: 1.0921 - val_acc: 0.3563\n",
            "Epoch 30/150 - 0.19s - loss: 1.0940 - acc: 0.3484 - val_loss: 1.0919 - val_acc: 0.3563\n",
            "Epoch 31/150 - 0.16s - loss: 1.0938 - acc: 0.3509 - val_loss: 1.0917 - val_acc: 0.3603\n",
            "Epoch 32/150 - 0.17s - loss: 1.0936 - acc: 0.3536 - val_loss: 1.0916 - val_acc: 0.3603\n",
            "Epoch 33/150 - 0.15s - loss: 1.0934 - acc: 0.3552 - val_loss: 1.0914 - val_acc: 0.3583\n",
            "Epoch 34/150 - 0.16s - loss: 1.0931 - acc: 0.3578 - val_loss: 1.0913 - val_acc: 0.3563\n",
            "Epoch 35/150 - 0.14s - loss: 1.0929 - acc: 0.3592 - val_loss: 1.0911 - val_acc: 0.3583\n",
            "Epoch 36/150 - 0.14s - loss: 1.0927 - acc: 0.3601 - val_loss: 1.0910 - val_acc: 0.3603\n",
            "Epoch 37/150 - 0.16s - loss: 1.0925 - acc: 0.3610 - val_loss: 1.0908 - val_acc: 0.3603\n",
            "Epoch 38/150 - 0.14s - loss: 1.0923 - acc: 0.3635 - val_loss: 1.0906 - val_acc: 0.3664\n",
            "Epoch 39/150 - 0.13s - loss: 1.0921 - acc: 0.3637 - val_loss: 1.0905 - val_acc: 0.3664\n",
            "Epoch 40/150 - 0.15s - loss: 1.0920 - acc: 0.3668 - val_loss: 1.0903 - val_acc: 0.3623\n",
            "Epoch 41/150 - 0.14s - loss: 1.0918 - acc: 0.3704 - val_loss: 1.0901 - val_acc: 0.3623\n",
            "Epoch 42/150 - 0.14s - loss: 1.0916 - acc: 0.3727 - val_loss: 1.0900 - val_acc: 0.3644\n",
            "Epoch 43/150 - 0.15s - loss: 1.0914 - acc: 0.3731 - val_loss: 1.0898 - val_acc: 0.3664\n",
            "Epoch 44/150 - 0.16s - loss: 1.0912 - acc: 0.3743 - val_loss: 1.0897 - val_acc: 0.3664\n",
            "Epoch 45/150 - 0.14s - loss: 1.0910 - acc: 0.3738 - val_loss: 1.0895 - val_acc: 0.3704\n",
            "Epoch 46/150 - 0.14s - loss: 1.0908 - acc: 0.3752 - val_loss: 1.0893 - val_acc: 0.3725\n",
            "Epoch 47/150 - 0.13s - loss: 1.0906 - acc: 0.3772 - val_loss: 1.0892 - val_acc: 0.3725\n",
            "Epoch 48/150 - 0.15s - loss: 1.0904 - acc: 0.3774 - val_loss: 1.0890 - val_acc: 0.3765\n",
            "Epoch 49/150 - 0.13s - loss: 1.0903 - acc: 0.3785 - val_loss: 1.0889 - val_acc: 0.3785\n",
            "Epoch 50/150 - 0.13s - loss: 1.0901 - acc: 0.3812 - val_loss: 1.0887 - val_acc: 0.3806\n",
            "Epoch 51/150 - 0.15s - loss: 1.0899 - acc: 0.3830 - val_loss: 1.0886 - val_acc: 0.3806\n",
            "Epoch 52/150 - 0.15s - loss: 1.0897 - acc: 0.3833 - val_loss: 1.0884 - val_acc: 0.3785\n",
            "Epoch 53/150 - 0.13s - loss: 1.0895 - acc: 0.3855 - val_loss: 1.0883 - val_acc: 0.3806\n",
            "Epoch 54/150 - 0.15s - loss: 1.0894 - acc: 0.3864 - val_loss: 1.0882 - val_acc: 0.3826\n",
            "Epoch 55/150 - 0.18s - loss: 1.0892 - acc: 0.3873 - val_loss: 1.0880 - val_acc: 0.3846\n",
            "Epoch 56/150 - 0.16s - loss: 1.0890 - acc: 0.3882 - val_loss: 1.0879 - val_acc: 0.3826\n",
            "Epoch 57/150 - 0.14s - loss: 1.0888 - acc: 0.3902 - val_loss: 1.0877 - val_acc: 0.3806\n",
            "Epoch 58/150 - 0.14s - loss: 1.0887 - acc: 0.3920 - val_loss: 1.0876 - val_acc: 0.3826\n",
            "Epoch 59/150 - 0.14s - loss: 1.0885 - acc: 0.3938 - val_loss: 1.0875 - val_acc: 0.3785\n",
            "Epoch 60/150 - 0.15s - loss: 1.0883 - acc: 0.3934 - val_loss: 1.0873 - val_acc: 0.3826\n",
            "Epoch 61/150 - 0.13s - loss: 1.0882 - acc: 0.3925 - val_loss: 1.0872 - val_acc: 0.3846\n",
            "Epoch 62/150 - 0.14s - loss: 1.0880 - acc: 0.3932 - val_loss: 1.0871 - val_acc: 0.3947\n",
            "Epoch 63/150 - 0.14s - loss: 1.0878 - acc: 0.3952 - val_loss: 1.0869 - val_acc: 0.3968\n",
            "Epoch 64/150 - 0.15s - loss: 1.0877 - acc: 0.3965 - val_loss: 1.0868 - val_acc: 0.3968\n",
            "Epoch 65/150 - 0.16s - loss: 1.0875 - acc: 0.3988 - val_loss: 1.0867 - val_acc: 0.3988\n",
            "Epoch 66/150 - 0.14s - loss: 1.0874 - acc: 0.3999 - val_loss: 1.0865 - val_acc: 0.3968\n",
            "Epoch 67/150 - 0.14s - loss: 1.0872 - acc: 0.4015 - val_loss: 1.0864 - val_acc: 0.3968\n",
            "Epoch 68/150 - 0.14s - loss: 1.0870 - acc: 0.4024 - val_loss: 1.0863 - val_acc: 0.3988\n",
            "Epoch 69/150 - 0.13s - loss: 1.0869 - acc: 0.4035 - val_loss: 1.0862 - val_acc: 0.3988\n",
            "Epoch 70/150 - 0.14s - loss: 1.0867 - acc: 0.4049 - val_loss: 1.0860 - val_acc: 0.3988\n",
            "Epoch 71/150 - 0.13s - loss: 1.0866 - acc: 0.4044 - val_loss: 1.0859 - val_acc: 0.3968\n",
            "Epoch 72/150 - 0.15s - loss: 1.0864 - acc: 0.4049 - val_loss: 1.0858 - val_acc: 0.3968\n",
            "Epoch 73/150 - 0.14s - loss: 1.0863 - acc: 0.4060 - val_loss: 1.0857 - val_acc: 0.3988\n",
            "Epoch 74/150 - 0.17s - loss: 1.0861 - acc: 0.4053 - val_loss: 1.0856 - val_acc: 0.3988\n",
            "Epoch 75/150 - 0.14s - loss: 1.0860 - acc: 0.4060 - val_loss: 1.0854 - val_acc: 0.4008\n",
            "Epoch 76/150 - 0.14s - loss: 1.0858 - acc: 0.4067 - val_loss: 1.0853 - val_acc: 0.4008\n",
            "Epoch 77/150 - 0.13s - loss: 1.0857 - acc: 0.4069 - val_loss: 1.0852 - val_acc: 0.4049\n",
            "Epoch 78/150 - 0.13s - loss: 1.0855 - acc: 0.4078 - val_loss: 1.0851 - val_acc: 0.4049\n",
            "Epoch 79/150 - 0.15s - loss: 1.0854 - acc: 0.4089 - val_loss: 1.0850 - val_acc: 0.4008\n",
            "Epoch 80/150 - 0.15s - loss: 1.0852 - acc: 0.4094 - val_loss: 1.0849 - val_acc: 0.4008\n",
            "Epoch 81/150 - 0.13s - loss: 1.0851 - acc: 0.4109 - val_loss: 1.0847 - val_acc: 0.4069\n",
            "Epoch 82/150 - 0.14s - loss: 1.0849 - acc: 0.4109 - val_loss: 1.0846 - val_acc: 0.4089\n",
            "Epoch 83/150 - 0.13s - loss: 1.0848 - acc: 0.4118 - val_loss: 1.0845 - val_acc: 0.4089\n",
            "Epoch 84/150 - 0.16s - loss: 1.0846 - acc: 0.4118 - val_loss: 1.0844 - val_acc: 0.4049\n",
            "Epoch 85/150 - 0.17s - loss: 1.0845 - acc: 0.4121 - val_loss: 1.0843 - val_acc: 0.4069\n",
            "Epoch 86/150 - 0.16s - loss: 1.0843 - acc: 0.4125 - val_loss: 1.0842 - val_acc: 0.4069\n",
            "Epoch 87/150 - 0.14s - loss: 1.0842 - acc: 0.4134 - val_loss: 1.0841 - val_acc: 0.4049\n",
            "Epoch 88/150 - 0.15s - loss: 1.0841 - acc: 0.4125 - val_loss: 1.0840 - val_acc: 0.4049\n",
            "Epoch 89/150 - 0.14s - loss: 1.0839 - acc: 0.4134 - val_loss: 1.0839 - val_acc: 0.4069\n",
            "Epoch 90/150 - 0.14s - loss: 1.0838 - acc: 0.4130 - val_loss: 1.0837 - val_acc: 0.4089\n",
            "Epoch 91/150 - 0.14s - loss: 1.0836 - acc: 0.4134 - val_loss: 1.0836 - val_acc: 0.4089\n",
            "Epoch 92/150 - 0.15s - loss: 1.0835 - acc: 0.4136 - val_loss: 1.0835 - val_acc: 0.4130\n",
            "Epoch 93/150 - 0.15s - loss: 1.0833 - acc: 0.4150 - val_loss: 1.0834 - val_acc: 0.4130\n",
            "Epoch 94/150 - 0.17s - loss: 1.0832 - acc: 0.4161 - val_loss: 1.0833 - val_acc: 0.4109\n",
            "Epoch 95/150 - 0.16s - loss: 1.0831 - acc: 0.4159 - val_loss: 1.0832 - val_acc: 0.4089\n",
            "Epoch 96/150 - 0.16s - loss: 1.0829 - acc: 0.4175 - val_loss: 1.0831 - val_acc: 0.4109\n",
            "Epoch 97/150 - 0.14s - loss: 1.0828 - acc: 0.4184 - val_loss: 1.0830 - val_acc: 0.4089\n",
            "Epoch 98/150 - 0.13s - loss: 1.0826 - acc: 0.4190 - val_loss: 1.0829 - val_acc: 0.4109\n",
            "Epoch 99/150 - 0.14s - loss: 1.0825 - acc: 0.4195 - val_loss: 1.0828 - val_acc: 0.4109\n",
            "Epoch 100/150 - 0.15s - loss: 1.0823 - acc: 0.4199 - val_loss: 1.0827 - val_acc: 0.4089\n",
            "Epoch 101/150 - 0.15s - loss: 1.0822 - acc: 0.4206 - val_loss: 1.0825 - val_acc: 0.4089\n",
            "Epoch 102/150 - 0.14s - loss: 1.0821 - acc: 0.4217 - val_loss: 1.0824 - val_acc: 0.4109\n",
            "Epoch 103/150 - 0.14s - loss: 1.0819 - acc: 0.4220 - val_loss: 1.0823 - val_acc: 0.4150\n",
            "Epoch 104/150 - 0.15s - loss: 1.0818 - acc: 0.4222 - val_loss: 1.0822 - val_acc: 0.4150\n",
            "Epoch 105/150 - 0.13s - loss: 1.0817 - acc: 0.4233 - val_loss: 1.0821 - val_acc: 0.4170\n",
            "Epoch 106/150 - 0.17s - loss: 1.0815 - acc: 0.4240 - val_loss: 1.0820 - val_acc: 0.4231\n",
            "Epoch 107/150 - 0.14s - loss: 1.0814 - acc: 0.4249 - val_loss: 1.0819 - val_acc: 0.4231\n",
            "Epoch 108/150 - 0.15s - loss: 1.0812 - acc: 0.4251 - val_loss: 1.0818 - val_acc: 0.4211\n",
            "Epoch 109/150 - 0.13s - loss: 1.0811 - acc: 0.4258 - val_loss: 1.0817 - val_acc: 0.4211\n",
            "Epoch 110/150 - 0.14s - loss: 1.0810 - acc: 0.4267 - val_loss: 1.0816 - val_acc: 0.4211\n",
            "Epoch 111/150 - 0.13s - loss: 1.0808 - acc: 0.4267 - val_loss: 1.0815 - val_acc: 0.4211\n",
            "Epoch 112/150 - 0.15s - loss: 1.0807 - acc: 0.4265 - val_loss: 1.0813 - val_acc: 0.4211\n",
            "Epoch 113/150 - 0.15s - loss: 1.0806 - acc: 0.4269 - val_loss: 1.0812 - val_acc: 0.4211\n",
            "Epoch 114/150 - 0.19s - loss: 1.0804 - acc: 0.4278 - val_loss: 1.0811 - val_acc: 0.4211\n",
            "Epoch 115/150 - 0.14s - loss: 1.0803 - acc: 0.4276 - val_loss: 1.0810 - val_acc: 0.4231\n",
            "Epoch 116/150 - 0.16s - loss: 1.0802 - acc: 0.4289 - val_loss: 1.0809 - val_acc: 0.4231\n",
            "Epoch 117/150 - 0.16s - loss: 1.0800 - acc: 0.4298 - val_loss: 1.0808 - val_acc: 0.4231\n",
            "Epoch 118/150 - 0.14s - loss: 1.0799 - acc: 0.4298 - val_loss: 1.0807 - val_acc: 0.4251\n",
            "Epoch 119/150 - 0.15s - loss: 1.0798 - acc: 0.4300 - val_loss: 1.0806 - val_acc: 0.4251\n",
            "Epoch 120/150 - 0.16s - loss: 1.0796 - acc: 0.4300 - val_loss: 1.0805 - val_acc: 0.4251\n",
            "Epoch 121/150 - 0.15s - loss: 1.0795 - acc: 0.4298 - val_loss: 1.0804 - val_acc: 0.4271\n",
            "Epoch 122/150 - 0.13s - loss: 1.0794 - acc: 0.4296 - val_loss: 1.0803 - val_acc: 0.4291\n",
            "Epoch 123/150 - 0.13s - loss: 1.0792 - acc: 0.4309 - val_loss: 1.0802 - val_acc: 0.4291\n",
            "Epoch 124/150 - 0.18s - loss: 1.0791 - acc: 0.4316 - val_loss: 1.0800 - val_acc: 0.4291\n",
            "Epoch 125/150 - 0.14s - loss: 1.0790 - acc: 0.4318 - val_loss: 1.0799 - val_acc: 0.4291\n",
            "Epoch 126/150 - 0.14s - loss: 1.0788 - acc: 0.4318 - val_loss: 1.0798 - val_acc: 0.4312\n",
            "Epoch 127/150 - 0.15s - loss: 1.0787 - acc: 0.4321 - val_loss: 1.0797 - val_acc: 0.4332\n",
            "Epoch 128/150 - 0.17s - loss: 1.0786 - acc: 0.4323 - val_loss: 1.0796 - val_acc: 0.4332\n",
            "Epoch 129/150 - 0.14s - loss: 1.0784 - acc: 0.4332 - val_loss: 1.0795 - val_acc: 0.4332\n",
            "Epoch 130/150 - 0.16s - loss: 1.0783 - acc: 0.4330 - val_loss: 1.0794 - val_acc: 0.4312\n",
            "Epoch 131/150 - 0.14s - loss: 1.0782 - acc: 0.4330 - val_loss: 1.0793 - val_acc: 0.4332\n",
            "Epoch 132/150 - 0.17s - loss: 1.0780 - acc: 0.4334 - val_loss: 1.0792 - val_acc: 0.4352\n",
            "Epoch 133/150 - 0.13s - loss: 1.0779 - acc: 0.4345 - val_loss: 1.0791 - val_acc: 0.4372\n",
            "Epoch 134/150 - 0.14s - loss: 1.0778 - acc: 0.4336 - val_loss: 1.0790 - val_acc: 0.4372\n",
            "Epoch 135/150 - 0.14s - loss: 1.0776 - acc: 0.4345 - val_loss: 1.0789 - val_acc: 0.4352\n",
            "Epoch 136/150 - 0.16s - loss: 1.0775 - acc: 0.4345 - val_loss: 1.0788 - val_acc: 0.4352\n",
            "Epoch 137/150 - 0.14s - loss: 1.0774 - acc: 0.4339 - val_loss: 1.0787 - val_acc: 0.4352\n",
            "Epoch 138/150 - 0.15s - loss: 1.0772 - acc: 0.4343 - val_loss: 1.0786 - val_acc: 0.4352\n",
            "Epoch 139/150 - 0.14s - loss: 1.0771 - acc: 0.4341 - val_loss: 1.0785 - val_acc: 0.4352\n",
            "Epoch 140/150 - 0.17s - loss: 1.0770 - acc: 0.4341 - val_loss: 1.0784 - val_acc: 0.4372\n",
            "Epoch 141/150 - 0.15s - loss: 1.0769 - acc: 0.4327 - val_loss: 1.0783 - val_acc: 0.4372\n",
            "Epoch 142/150 - 0.14s - loss: 1.0767 - acc: 0.4336 - val_loss: 1.0782 - val_acc: 0.4352\n",
            "Epoch 143/150 - 0.14s - loss: 1.0766 - acc: 0.4336 - val_loss: 1.0781 - val_acc: 0.4332\n",
            "Epoch 144/150 - 0.15s - loss: 1.0765 - acc: 0.4339 - val_loss: 1.0780 - val_acc: 0.4332\n",
            "Epoch 145/150 - 0.14s - loss: 1.0763 - acc: 0.4341 - val_loss: 1.0779 - val_acc: 0.4352\n",
            "Epoch 146/150 - 0.13s - loss: 1.0762 - acc: 0.4350 - val_loss: 1.0778 - val_acc: 0.4372\n",
            "Epoch 147/150 - 0.13s - loss: 1.0761 - acc: 0.4352 - val_loss: 1.0777 - val_acc: 0.4393\n",
            "Epoch 148/150 - 0.15s - loss: 1.0759 - acc: 0.4350 - val_loss: 1.0776 - val_acc: 0.4413\n",
            "Epoch 149/150 - 0.15s - loss: 1.0758 - acc: 0.4361 - val_loss: 1.0775 - val_acc: 0.4393\n",
            "Epoch 150/150 - 0.14s - loss: 1.0757 - acc: 0.4379 - val_loss: 1.0774 - val_acc: 0.4413\n",
            "\n",
            "Combination 196/252:\n",
            "Hidden Layers: [256, 128, 64], Activation: relu, Learning Rate: 0.0001, Batch Size: 64, Epochs: 50\n",
            "Epoch 1/50 - 0.10s - loss: 1.1333 - acc: 0.3225 - val_loss: 1.1329 - val_acc: 0.3360\n",
            "Epoch 2/50 - 0.10s - loss: 1.1310 - acc: 0.3225 - val_loss: 1.1308 - val_acc: 0.3360\n",
            "Epoch 3/50 - 0.11s - loss: 1.1289 - acc: 0.3225 - val_loss: 1.1289 - val_acc: 0.3360\n",
            "Epoch 4/50 - 0.10s - loss: 1.1270 - acc: 0.3225 - val_loss: 1.1271 - val_acc: 0.3360\n",
            "Epoch 5/50 - 0.10s - loss: 1.1252 - acc: 0.3225 - val_loss: 1.1255 - val_acc: 0.3360\n",
            "Epoch 6/50 - 0.11s - loss: 1.1235 - acc: 0.3225 - val_loss: 1.1239 - val_acc: 0.3360\n",
            "Epoch 7/50 - 0.10s - loss: 1.1219 - acc: 0.3225 - val_loss: 1.1225 - val_acc: 0.3360\n",
            "Epoch 8/50 - 0.17s - loss: 1.1204 - acc: 0.3225 - val_loss: 1.1211 - val_acc: 0.3360\n",
            "Epoch 9/50 - 0.13s - loss: 1.1190 - acc: 0.3225 - val_loss: 1.1199 - val_acc: 0.3360\n",
            "Epoch 10/50 - 0.12s - loss: 1.1177 - acc: 0.3225 - val_loss: 1.1187 - val_acc: 0.3360\n",
            "Epoch 11/50 - 0.13s - loss: 1.1165 - acc: 0.3223 - val_loss: 1.1176 - val_acc: 0.3360\n",
            "Epoch 12/50 - 0.11s - loss: 1.1154 - acc: 0.3221 - val_loss: 1.1166 - val_acc: 0.3360\n",
            "Epoch 13/50 - 0.11s - loss: 1.1143 - acc: 0.3221 - val_loss: 1.1157 - val_acc: 0.3360\n",
            "Epoch 14/50 - 0.11s - loss: 1.1133 - acc: 0.3219 - val_loss: 1.1148 - val_acc: 0.3360\n",
            "Epoch 15/50 - 0.11s - loss: 1.1124 - acc: 0.3219 - val_loss: 1.1140 - val_acc: 0.3360\n",
            "Epoch 16/50 - 0.13s - loss: 1.1115 - acc: 0.3219 - val_loss: 1.1132 - val_acc: 0.3360\n",
            "Epoch 17/50 - 0.15s - loss: 1.1107 - acc: 0.3221 - val_loss: 1.1124 - val_acc: 0.3360\n",
            "Epoch 18/50 - 0.12s - loss: 1.1099 - acc: 0.3221 - val_loss: 1.1117 - val_acc: 0.3340\n",
            "Epoch 19/50 - 0.12s - loss: 1.1092 - acc: 0.3225 - val_loss: 1.1111 - val_acc: 0.3320\n",
            "Epoch 20/50 - 0.12s - loss: 1.1085 - acc: 0.3230 - val_loss: 1.1105 - val_acc: 0.3320\n",
            "Epoch 21/50 - 0.11s - loss: 1.1079 - acc: 0.3246 - val_loss: 1.1099 - val_acc: 0.3320\n",
            "Epoch 22/50 - 0.18s - loss: 1.1073 - acc: 0.3239 - val_loss: 1.1094 - val_acc: 0.3320\n",
            "Epoch 23/50 - 0.13s - loss: 1.1067 - acc: 0.3243 - val_loss: 1.1089 - val_acc: 0.3320\n",
            "Epoch 24/50 - 0.11s - loss: 1.1061 - acc: 0.3230 - val_loss: 1.1084 - val_acc: 0.3300\n",
            "Epoch 25/50 - 0.11s - loss: 1.1056 - acc: 0.3250 - val_loss: 1.1080 - val_acc: 0.3320\n",
            "Epoch 26/50 - 0.12s - loss: 1.1051 - acc: 0.3257 - val_loss: 1.1075 - val_acc: 0.3360\n",
            "Epoch 27/50 - 0.11s - loss: 1.1046 - acc: 0.3257 - val_loss: 1.1071 - val_acc: 0.3340\n",
            "Epoch 28/50 - 0.14s - loss: 1.1042 - acc: 0.3273 - val_loss: 1.1068 - val_acc: 0.3340\n",
            "Epoch 29/50 - 0.14s - loss: 1.1038 - acc: 0.3291 - val_loss: 1.1064 - val_acc: 0.3320\n",
            "Epoch 30/50 - 0.11s - loss: 1.1034 - acc: 0.3304 - val_loss: 1.1061 - val_acc: 0.3320\n",
            "Epoch 31/50 - 0.13s - loss: 1.1030 - acc: 0.3304 - val_loss: 1.1058 - val_acc: 0.3279\n",
            "Epoch 32/50 - 0.11s - loss: 1.1026 - acc: 0.3300 - val_loss: 1.1055 - val_acc: 0.3320\n",
            "Epoch 33/50 - 0.12s - loss: 1.1023 - acc: 0.3327 - val_loss: 1.1052 - val_acc: 0.3279\n",
            "Epoch 34/50 - 0.14s - loss: 1.1020 - acc: 0.3354 - val_loss: 1.1049 - val_acc: 0.3259\n",
            "Epoch 35/50 - 0.13s - loss: 1.1016 - acc: 0.3383 - val_loss: 1.1047 - val_acc: 0.3239\n",
            "Epoch 36/50 - 0.11s - loss: 1.1013 - acc: 0.3374 - val_loss: 1.1045 - val_acc: 0.3117\n",
            "Epoch 37/50 - 0.10s - loss: 1.1011 - acc: 0.3383 - val_loss: 1.1042 - val_acc: 0.3057\n",
            "Epoch 38/50 - 0.11s - loss: 1.1008 - acc: 0.3403 - val_loss: 1.1040 - val_acc: 0.3036\n",
            "Epoch 39/50 - 0.10s - loss: 1.1005 - acc: 0.3412 - val_loss: 1.1038 - val_acc: 0.2996\n",
            "Epoch 40/50 - 0.11s - loss: 1.1003 - acc: 0.3390 - val_loss: 1.1036 - val_acc: 0.3036\n",
            "Epoch 41/50 - 0.10s - loss: 1.1000 - acc: 0.3399 - val_loss: 1.1034 - val_acc: 0.2996\n",
            "Epoch 42/50 - 0.10s - loss: 1.0998 - acc: 0.3412 - val_loss: 1.1032 - val_acc: 0.2996\n",
            "Epoch 43/50 - 0.10s - loss: 1.0995 - acc: 0.3453 - val_loss: 1.1031 - val_acc: 0.2976\n",
            "Epoch 44/50 - 0.11s - loss: 1.0993 - acc: 0.3468 - val_loss: 1.1029 - val_acc: 0.2955\n",
            "Epoch 45/50 - 0.10s - loss: 1.0991 - acc: 0.3493 - val_loss: 1.1027 - val_acc: 0.2895\n",
            "Epoch 46/50 - 0.10s - loss: 1.0989 - acc: 0.3502 - val_loss: 1.1026 - val_acc: 0.2874\n",
            "Epoch 47/50 - 0.19s - loss: 1.0987 - acc: 0.3525 - val_loss: 1.1024 - val_acc: 0.2895\n",
            "Epoch 48/50 - 0.14s - loss: 1.0985 - acc: 0.3538 - val_loss: 1.1023 - val_acc: 0.2955\n",
            "Epoch 49/50 - 0.12s - loss: 1.0983 - acc: 0.3576 - val_loss: 1.1022 - val_acc: 0.2976\n",
            "Epoch 50/50 - 0.11s - loss: 1.0982 - acc: 0.3547 - val_loss: 1.1020 - val_acc: 0.2895\n",
            "\n",
            "Combination 197/252:\n",
            "Hidden Layers: [256, 128, 64], Activation: relu, Learning Rate: 0.0001, Batch Size: 64, Epochs: 100\n",
            "Epoch 1/100 - 0.11s - loss: 1.1162 - acc: 0.3221 - val_loss: 1.1150 - val_acc: 0.3360\n",
            "Epoch 2/100 - 0.12s - loss: 1.1147 - acc: 0.3203 - val_loss: 1.1136 - val_acc: 0.3360\n",
            "Epoch 3/100 - 0.15s - loss: 1.1133 - acc: 0.3221 - val_loss: 1.1124 - val_acc: 0.3340\n",
            "Epoch 4/100 - 0.11s - loss: 1.1120 - acc: 0.3232 - val_loss: 1.1112 - val_acc: 0.3360\n",
            "Epoch 5/100 - 0.10s - loss: 1.1109 - acc: 0.3225 - val_loss: 1.1101 - val_acc: 0.3320\n",
            "Epoch 6/100 - 0.10s - loss: 1.1098 - acc: 0.3198 - val_loss: 1.1091 - val_acc: 0.3279\n",
            "Epoch 7/100 - 0.10s - loss: 1.1087 - acc: 0.3203 - val_loss: 1.1082 - val_acc: 0.3340\n",
            "Epoch 8/100 - 0.11s - loss: 1.1078 - acc: 0.3225 - val_loss: 1.1073 - val_acc: 0.3340\n",
            "Epoch 9/100 - 0.10s - loss: 1.1069 - acc: 0.3219 - val_loss: 1.1065 - val_acc: 0.3279\n",
            "Epoch 10/100 - 0.10s - loss: 1.1061 - acc: 0.3232 - val_loss: 1.1058 - val_acc: 0.3300\n",
            "Epoch 11/100 - 0.12s - loss: 1.1053 - acc: 0.3237 - val_loss: 1.1051 - val_acc: 0.3239\n",
            "Epoch 12/100 - 0.13s - loss: 1.1046 - acc: 0.3246 - val_loss: 1.1044 - val_acc: 0.3279\n",
            "Epoch 13/100 - 0.13s - loss: 1.1039 - acc: 0.3252 - val_loss: 1.1039 - val_acc: 0.3320\n",
            "Epoch 14/100 - 0.11s - loss: 1.1033 - acc: 0.3275 - val_loss: 1.1033 - val_acc: 0.3320\n",
            "Epoch 15/100 - 0.10s - loss: 1.1027 - acc: 0.3302 - val_loss: 1.1028 - val_acc: 0.3300\n",
            "Epoch 16/100 - 0.11s - loss: 1.1021 - acc: 0.3324 - val_loss: 1.1023 - val_acc: 0.3279\n",
            "Epoch 17/100 - 0.13s - loss: 1.1016 - acc: 0.3360 - val_loss: 1.1018 - val_acc: 0.3279\n",
            "Epoch 18/100 - 0.11s - loss: 1.1011 - acc: 0.3367 - val_loss: 1.1014 - val_acc: 0.3320\n",
            "Epoch 19/100 - 0.10s - loss: 1.1006 - acc: 0.3396 - val_loss: 1.1010 - val_acc: 0.3279\n",
            "Epoch 20/100 - 0.11s - loss: 1.1002 - acc: 0.3417 - val_loss: 1.1006 - val_acc: 0.3219\n",
            "Epoch 21/100 - 0.10s - loss: 1.0998 - acc: 0.3408 - val_loss: 1.1002 - val_acc: 0.3158\n",
            "Epoch 22/100 - 0.13s - loss: 1.0994 - acc: 0.3419 - val_loss: 1.0999 - val_acc: 0.3158\n",
            "Epoch 23/100 - 0.10s - loss: 1.0990 - acc: 0.3432 - val_loss: 1.0995 - val_acc: 0.3239\n",
            "Epoch 24/100 - 0.10s - loss: 1.0987 - acc: 0.3484 - val_loss: 1.0992 - val_acc: 0.3360\n",
            "Epoch 25/100 - 0.10s - loss: 1.0983 - acc: 0.3509 - val_loss: 1.0989 - val_acc: 0.3421\n",
            "Epoch 26/100 - 0.11s - loss: 1.0980 - acc: 0.3518 - val_loss: 1.0986 - val_acc: 0.3421\n",
            "Epoch 27/100 - 0.10s - loss: 1.0977 - acc: 0.3520 - val_loss: 1.0983 - val_acc: 0.3522\n",
            "Epoch 28/100 - 0.10s - loss: 1.0974 - acc: 0.3554 - val_loss: 1.0981 - val_acc: 0.3482\n",
            "Epoch 29/100 - 0.10s - loss: 1.0971 - acc: 0.3558 - val_loss: 1.0978 - val_acc: 0.3583\n",
            "Epoch 30/100 - 0.10s - loss: 1.0968 - acc: 0.3576 - val_loss: 1.0976 - val_acc: 0.3603\n",
            "Epoch 31/100 - 0.10s - loss: 1.0966 - acc: 0.3612 - val_loss: 1.0974 - val_acc: 0.3543\n",
            "Epoch 32/100 - 0.11s - loss: 1.0963 - acc: 0.3626 - val_loss: 1.0972 - val_acc: 0.3583\n",
            "Epoch 33/100 - 0.10s - loss: 1.0961 - acc: 0.3644 - val_loss: 1.0969 - val_acc: 0.3623\n",
            "Epoch 34/100 - 0.10s - loss: 1.0958 - acc: 0.3655 - val_loss: 1.0967 - val_acc: 0.3644\n",
            "Epoch 35/100 - 0.10s - loss: 1.0956 - acc: 0.3673 - val_loss: 1.0965 - val_acc: 0.3664\n",
            "Epoch 36/100 - 0.10s - loss: 1.0954 - acc: 0.3695 - val_loss: 1.0964 - val_acc: 0.3684\n",
            "Epoch 37/100 - 0.11s - loss: 1.0952 - acc: 0.3707 - val_loss: 1.0962 - val_acc: 0.3684\n",
            "Epoch 38/100 - 0.11s - loss: 1.0950 - acc: 0.3709 - val_loss: 1.0960 - val_acc: 0.3725\n",
            "Epoch 39/100 - 0.10s - loss: 1.0948 - acc: 0.3716 - val_loss: 1.0958 - val_acc: 0.3664\n",
            "Epoch 40/100 - 0.10s - loss: 1.0946 - acc: 0.3756 - val_loss: 1.0957 - val_acc: 0.3684\n",
            "Epoch 41/100 - 0.12s - loss: 1.0944 - acc: 0.3779 - val_loss: 1.0955 - val_acc: 0.3684\n",
            "Epoch 42/100 - 0.11s - loss: 1.0942 - acc: 0.3808 - val_loss: 1.0953 - val_acc: 0.3684\n",
            "Epoch 43/100 - 0.10s - loss: 1.0940 - acc: 0.3839 - val_loss: 1.0952 - val_acc: 0.3704\n",
            "Epoch 44/100 - 0.12s - loss: 1.0938 - acc: 0.3853 - val_loss: 1.0950 - val_acc: 0.3785\n",
            "Epoch 45/100 - 0.11s - loss: 1.0937 - acc: 0.3837 - val_loss: 1.0949 - val_acc: 0.3806\n",
            "Epoch 46/100 - 0.12s - loss: 1.0935 - acc: 0.3864 - val_loss: 1.0947 - val_acc: 0.3785\n",
            "Epoch 47/100 - 0.10s - loss: 1.0933 - acc: 0.3896 - val_loss: 1.0946 - val_acc: 0.3806\n",
            "Epoch 48/100 - 0.11s - loss: 1.0932 - acc: 0.3896 - val_loss: 1.0944 - val_acc: 0.3826\n",
            "Epoch 49/100 - 0.10s - loss: 1.0930 - acc: 0.3918 - val_loss: 1.0943 - val_acc: 0.3866\n",
            "Epoch 50/100 - 0.11s - loss: 1.0928 - acc: 0.3923 - val_loss: 1.0941 - val_acc: 0.3846\n",
            "Epoch 51/100 - 0.10s - loss: 1.0927 - acc: 0.3911 - val_loss: 1.0940 - val_acc: 0.3887\n",
            "Epoch 52/100 - 0.11s - loss: 1.0925 - acc: 0.3923 - val_loss: 1.0939 - val_acc: 0.3887\n",
            "Epoch 53/100 - 0.10s - loss: 1.0924 - acc: 0.3925 - val_loss: 1.0937 - val_acc: 0.3887\n",
            "Epoch 54/100 - 0.10s - loss: 1.0922 - acc: 0.3893 - val_loss: 1.0936 - val_acc: 0.3907\n",
            "Epoch 55/100 - 0.10s - loss: 1.0921 - acc: 0.3891 - val_loss: 1.0935 - val_acc: 0.3866\n",
            "Epoch 56/100 - 0.10s - loss: 1.0920 - acc: 0.3900 - val_loss: 1.0933 - val_acc: 0.3907\n",
            "Epoch 57/100 - 0.10s - loss: 1.0918 - acc: 0.3907 - val_loss: 1.0932 - val_acc: 0.3947\n",
            "Epoch 58/100 - 0.15s - loss: 1.0917 - acc: 0.3916 - val_loss: 1.0931 - val_acc: 0.3968\n",
            "Epoch 59/100 - 0.10s - loss: 1.0915 - acc: 0.3916 - val_loss: 1.0930 - val_acc: 0.3988\n",
            "Epoch 60/100 - 0.10s - loss: 1.0914 - acc: 0.3900 - val_loss: 1.0928 - val_acc: 0.3968\n",
            "Epoch 61/100 - 0.10s - loss: 1.0913 - acc: 0.3905 - val_loss: 1.0927 - val_acc: 0.3927\n",
            "Epoch 62/100 - 0.10s - loss: 1.0911 - acc: 0.3893 - val_loss: 1.0926 - val_acc: 0.3947\n",
            "Epoch 63/100 - 0.10s - loss: 1.0910 - acc: 0.3889 - val_loss: 1.0925 - val_acc: 0.3866\n",
            "Epoch 64/100 - 0.11s - loss: 1.0909 - acc: 0.3896 - val_loss: 1.0923 - val_acc: 0.3887\n",
            "Epoch 65/100 - 0.10s - loss: 1.0907 - acc: 0.3900 - val_loss: 1.0922 - val_acc: 0.3887\n",
            "Epoch 66/100 - 0.10s - loss: 1.0906 - acc: 0.3896 - val_loss: 1.0921 - val_acc: 0.3887\n",
            "Epoch 67/100 - 0.10s - loss: 1.0905 - acc: 0.3887 - val_loss: 1.0920 - val_acc: 0.3927\n",
            "Epoch 68/100 - 0.12s - loss: 1.0904 - acc: 0.3896 - val_loss: 1.0918 - val_acc: 0.3907\n",
            "Epoch 69/100 - 0.15s - loss: 1.0902 - acc: 0.3891 - val_loss: 1.0917 - val_acc: 0.3927\n",
            "Epoch 70/100 - 0.11s - loss: 1.0901 - acc: 0.3893 - val_loss: 1.0916 - val_acc: 0.3968\n",
            "Epoch 71/100 - 0.11s - loss: 1.0900 - acc: 0.3900 - val_loss: 1.0915 - val_acc: 0.3988\n",
            "Epoch 72/100 - 0.12s - loss: 1.0899 - acc: 0.3898 - val_loss: 1.0914 - val_acc: 0.3968\n",
            "Epoch 73/100 - 0.11s - loss: 1.0897 - acc: 0.3907 - val_loss: 1.0912 - val_acc: 0.3988\n",
            "Epoch 74/100 - 0.15s - loss: 1.0896 - acc: 0.3909 - val_loss: 1.0911 - val_acc: 0.4008\n",
            "Epoch 75/100 - 0.13s - loss: 1.0895 - acc: 0.3905 - val_loss: 1.0910 - val_acc: 0.4028\n",
            "Epoch 76/100 - 0.10s - loss: 1.0894 - acc: 0.3900 - val_loss: 1.0909 - val_acc: 0.4028\n",
            "Epoch 77/100 - 0.09s - loss: 1.0892 - acc: 0.3905 - val_loss: 1.0908 - val_acc: 0.4028\n",
            "Epoch 78/100 - 0.10s - loss: 1.0891 - acc: 0.3900 - val_loss: 1.0907 - val_acc: 0.4028\n",
            "Epoch 79/100 - 0.09s - loss: 1.0890 - acc: 0.3898 - val_loss: 1.0906 - val_acc: 0.4049\n",
            "Epoch 80/100 - 0.09s - loss: 1.0889 - acc: 0.3902 - val_loss: 1.0904 - val_acc: 0.4089\n",
            "Epoch 81/100 - 0.10s - loss: 1.0888 - acc: 0.3907 - val_loss: 1.0903 - val_acc: 0.4069\n",
            "Epoch 82/100 - 0.11s - loss: 1.0886 - acc: 0.3923 - val_loss: 1.0902 - val_acc: 0.4028\n",
            "Epoch 83/100 - 0.11s - loss: 1.0885 - acc: 0.3925 - val_loss: 1.0901 - val_acc: 0.4028\n",
            "Epoch 84/100 - 0.12s - loss: 1.0884 - acc: 0.3920 - val_loss: 1.0900 - val_acc: 0.4049\n",
            "Epoch 85/100 - 0.10s - loss: 1.0883 - acc: 0.3923 - val_loss: 1.0899 - val_acc: 0.4049\n",
            "Epoch 86/100 - 0.11s - loss: 1.0882 - acc: 0.3914 - val_loss: 1.0898 - val_acc: 0.4049\n",
            "Epoch 87/100 - 0.10s - loss: 1.0880 - acc: 0.3920 - val_loss: 1.0896 - val_acc: 0.4028\n",
            "Epoch 88/100 - 0.13s - loss: 1.0879 - acc: 0.3923 - val_loss: 1.0895 - val_acc: 0.4069\n",
            "Epoch 89/100 - 0.10s - loss: 1.0878 - acc: 0.3916 - val_loss: 1.0894 - val_acc: 0.4049\n",
            "Epoch 90/100 - 0.12s - loss: 1.0877 - acc: 0.3920 - val_loss: 1.0893 - val_acc: 0.4049\n",
            "Epoch 91/100 - 0.11s - loss: 1.0876 - acc: 0.3934 - val_loss: 1.0892 - val_acc: 0.4028\n",
            "Epoch 92/100 - 0.15s - loss: 1.0874 - acc: 0.3938 - val_loss: 1.0891 - val_acc: 0.4028\n",
            "Epoch 93/100 - 0.11s - loss: 1.0873 - acc: 0.3941 - val_loss: 1.0890 - val_acc: 0.4028\n",
            "Epoch 94/100 - 0.11s - loss: 1.0872 - acc: 0.3945 - val_loss: 1.0889 - val_acc: 0.4028\n",
            "Epoch 95/100 - 0.10s - loss: 1.0871 - acc: 0.3941 - val_loss: 1.0887 - val_acc: 0.4028\n",
            "Epoch 96/100 - 0.11s - loss: 1.0870 - acc: 0.3961 - val_loss: 1.0886 - val_acc: 0.4028\n",
            "Epoch 97/100 - 0.10s - loss: 1.0869 - acc: 0.3963 - val_loss: 1.0885 - val_acc: 0.4008\n",
            "Epoch 98/100 - 0.10s - loss: 1.0867 - acc: 0.3968 - val_loss: 1.0884 - val_acc: 0.4008\n",
            "Epoch 99/100 - 0.11s - loss: 1.0866 - acc: 0.3970 - val_loss: 1.0883 - val_acc: 0.4008\n",
            "Epoch 100/100 - 0.12s - loss: 1.0865 - acc: 0.3965 - val_loss: 1.0882 - val_acc: 0.4008\n",
            "\n",
            "Combination 198/252:\n",
            "Hidden Layers: [256, 128, 64], Activation: relu, Learning Rate: 0.0001, Batch Size: 64, Epochs: 150\n",
            "Epoch 1/150 - 0.11s - loss: 1.0979 - acc: 0.3567 - val_loss: 1.1025 - val_acc: 0.3421\n",
            "Epoch 2/150 - 0.11s - loss: 1.0978 - acc: 0.3570 - val_loss: 1.1024 - val_acc: 0.3421\n",
            "Epoch 3/150 - 0.11s - loss: 1.0977 - acc: 0.3587 - val_loss: 1.1023 - val_acc: 0.3462\n",
            "Epoch 4/150 - 0.11s - loss: 1.0975 - acc: 0.3590 - val_loss: 1.1022 - val_acc: 0.3441\n",
            "Epoch 5/150 - 0.10s - loss: 1.0974 - acc: 0.3599 - val_loss: 1.1021 - val_acc: 0.3441\n",
            "Epoch 6/150 - 0.11s - loss: 1.0973 - acc: 0.3601 - val_loss: 1.1019 - val_acc: 0.3462\n",
            "Epoch 7/150 - 0.10s - loss: 1.0971 - acc: 0.3567 - val_loss: 1.1018 - val_acc: 0.3421\n",
            "Epoch 8/150 - 0.12s - loss: 1.0970 - acc: 0.3587 - val_loss: 1.1017 - val_acc: 0.3401\n",
            "Epoch 9/150 - 0.14s - loss: 1.0969 - acc: 0.3612 - val_loss: 1.1016 - val_acc: 0.3401\n",
            "Epoch 10/150 - 0.11s - loss: 1.0967 - acc: 0.3635 - val_loss: 1.1015 - val_acc: 0.3360\n",
            "Epoch 11/150 - 0.11s - loss: 1.0966 - acc: 0.3648 - val_loss: 1.1014 - val_acc: 0.3381\n",
            "Epoch 12/150 - 0.11s - loss: 1.0965 - acc: 0.3657 - val_loss: 1.1013 - val_acc: 0.3360\n",
            "Epoch 13/150 - 0.10s - loss: 1.0963 - acc: 0.3659 - val_loss: 1.1012 - val_acc: 0.3360\n",
            "Epoch 14/150 - 0.12s - loss: 1.0962 - acc: 0.3662 - val_loss: 1.1010 - val_acc: 0.3381\n",
            "Epoch 15/150 - 0.10s - loss: 1.0961 - acc: 0.3659 - val_loss: 1.1009 - val_acc: 0.3381\n",
            "Epoch 16/150 - 0.11s - loss: 1.0960 - acc: 0.3641 - val_loss: 1.1008 - val_acc: 0.3401\n",
            "Epoch 17/150 - 0.10s - loss: 1.0958 - acc: 0.3655 - val_loss: 1.1007 - val_acc: 0.3401\n",
            "Epoch 18/150 - 0.10s - loss: 1.0957 - acc: 0.3657 - val_loss: 1.1006 - val_acc: 0.3462\n",
            "Epoch 19/150 - 0.11s - loss: 1.0956 - acc: 0.3677 - val_loss: 1.1005 - val_acc: 0.3482\n",
            "Epoch 20/150 - 0.12s - loss: 1.0955 - acc: 0.3677 - val_loss: 1.1004 - val_acc: 0.3502\n",
            "Epoch 21/150 - 0.10s - loss: 1.0953 - acc: 0.3691 - val_loss: 1.1003 - val_acc: 0.3522\n",
            "Epoch 22/150 - 0.14s - loss: 1.0952 - acc: 0.3693 - val_loss: 1.1002 - val_acc: 0.3502\n",
            "Epoch 23/150 - 0.14s - loss: 1.0951 - acc: 0.3691 - val_loss: 1.1001 - val_acc: 0.3502\n",
            "Epoch 24/150 - 0.12s - loss: 1.0950 - acc: 0.3704 - val_loss: 1.1000 - val_acc: 0.3522\n",
            "Epoch 25/150 - 0.12s - loss: 1.0948 - acc: 0.3718 - val_loss: 1.0999 - val_acc: 0.3543\n",
            "Epoch 26/150 - 0.11s - loss: 1.0947 - acc: 0.3738 - val_loss: 1.0998 - val_acc: 0.3522\n",
            "Epoch 27/150 - 0.11s - loss: 1.0946 - acc: 0.3752 - val_loss: 1.0997 - val_acc: 0.3502\n",
            "Epoch 28/150 - 0.10s - loss: 1.0945 - acc: 0.3752 - val_loss: 1.0996 - val_acc: 0.3502\n",
            "Epoch 29/150 - 0.12s - loss: 1.0944 - acc: 0.3752 - val_loss: 1.0995 - val_acc: 0.3482\n",
            "Epoch 30/150 - 0.10s - loss: 1.0942 - acc: 0.3761 - val_loss: 1.0994 - val_acc: 0.3462\n",
            "Epoch 31/150 - 0.15s - loss: 1.0941 - acc: 0.3765 - val_loss: 1.0993 - val_acc: 0.3462\n",
            "Epoch 32/150 - 0.10s - loss: 1.0940 - acc: 0.3792 - val_loss: 1.0992 - val_acc: 0.3462\n",
            "Epoch 33/150 - 0.10s - loss: 1.0939 - acc: 0.3803 - val_loss: 1.0991 - val_acc: 0.3462\n",
            "Epoch 34/150 - 0.10s - loss: 1.0938 - acc: 0.3815 - val_loss: 1.0990 - val_acc: 0.3482\n",
            "Epoch 35/150 - 0.12s - loss: 1.0936 - acc: 0.3812 - val_loss: 1.0989 - val_acc: 0.3482\n",
            "Epoch 36/150 - 0.10s - loss: 1.0935 - acc: 0.3799 - val_loss: 1.0988 - val_acc: 0.3522\n",
            "Epoch 37/150 - 0.10s - loss: 1.0934 - acc: 0.3799 - val_loss: 1.0987 - val_acc: 0.3522\n",
            "Epoch 38/150 - 0.12s - loss: 1.0933 - acc: 0.3794 - val_loss: 1.0986 - val_acc: 0.3522\n",
            "Epoch 39/150 - 0.10s - loss: 1.0932 - acc: 0.3803 - val_loss: 1.0985 - val_acc: 0.3482\n",
            "Epoch 40/150 - 0.10s - loss: 1.0930 - acc: 0.3797 - val_loss: 1.0985 - val_acc: 0.3482\n",
            "Epoch 41/150 - 0.10s - loss: 1.0929 - acc: 0.3799 - val_loss: 1.0984 - val_acc: 0.3502\n",
            "Epoch 42/150 - 0.10s - loss: 1.0928 - acc: 0.3810 - val_loss: 1.0983 - val_acc: 0.3502\n",
            "Epoch 43/150 - 0.10s - loss: 1.0927 - acc: 0.3821 - val_loss: 1.0982 - val_acc: 0.3502\n",
            "Epoch 44/150 - 0.11s - loss: 1.0926 - acc: 0.3828 - val_loss: 1.0981 - val_acc: 0.3543\n",
            "Epoch 45/150 - 0.10s - loss: 1.0925 - acc: 0.3835 - val_loss: 1.0980 - val_acc: 0.3543\n",
            "Epoch 46/150 - 0.10s - loss: 1.0923 - acc: 0.3837 - val_loss: 1.0979 - val_acc: 0.3563\n",
            "Epoch 47/150 - 0.10s - loss: 1.0922 - acc: 0.3844 - val_loss: 1.0978 - val_acc: 0.3583\n",
            "Epoch 48/150 - 0.10s - loss: 1.0921 - acc: 0.3851 - val_loss: 1.0977 - val_acc: 0.3583\n",
            "Epoch 49/150 - 0.10s - loss: 1.0920 - acc: 0.3855 - val_loss: 1.0976 - val_acc: 0.3563\n",
            "Epoch 50/150 - 0.11s - loss: 1.0919 - acc: 0.3860 - val_loss: 1.0976 - val_acc: 0.3563\n",
            "Epoch 51/150 - 0.10s - loss: 1.0918 - acc: 0.3862 - val_loss: 1.0975 - val_acc: 0.3563\n",
            "Epoch 52/150 - 0.10s - loss: 1.0917 - acc: 0.3855 - val_loss: 1.0974 - val_acc: 0.3603\n",
            "Epoch 53/150 - 0.12s - loss: 1.0916 - acc: 0.3866 - val_loss: 1.0973 - val_acc: 0.3623\n",
            "Epoch 54/150 - 0.10s - loss: 1.0914 - acc: 0.3873 - val_loss: 1.0972 - val_acc: 0.3684\n",
            "Epoch 55/150 - 0.11s - loss: 1.0913 - acc: 0.3882 - val_loss: 1.0971 - val_acc: 0.3684\n",
            "Epoch 56/150 - 0.14s - loss: 1.0912 - acc: 0.3878 - val_loss: 1.0970 - val_acc: 0.3644\n",
            "Epoch 57/150 - 0.11s - loss: 1.0911 - acc: 0.3884 - val_loss: 1.0970 - val_acc: 0.3664\n",
            "Epoch 58/150 - 0.11s - loss: 1.0910 - acc: 0.3893 - val_loss: 1.0969 - val_acc: 0.3664\n",
            "Epoch 59/150 - 0.10s - loss: 1.0909 - acc: 0.3898 - val_loss: 1.0968 - val_acc: 0.3664\n",
            "Epoch 60/150 - 0.11s - loss: 1.0908 - acc: 0.3902 - val_loss: 1.0967 - val_acc: 0.3664\n",
            "Epoch 61/150 - 0.11s - loss: 1.0907 - acc: 0.3909 - val_loss: 1.0966 - val_acc: 0.3664\n",
            "Epoch 62/150 - 0.12s - loss: 1.0906 - acc: 0.3918 - val_loss: 1.0965 - val_acc: 0.3644\n",
            "Epoch 63/150 - 0.10s - loss: 1.0905 - acc: 0.3920 - val_loss: 1.0965 - val_acc: 0.3644\n",
            "Epoch 64/150 - 0.12s - loss: 1.0904 - acc: 0.3936 - val_loss: 1.0964 - val_acc: 0.3603\n",
            "Epoch 65/150 - 0.10s - loss: 1.0902 - acc: 0.3936 - val_loss: 1.0963 - val_acc: 0.3603\n",
            "Epoch 66/150 - 0.11s - loss: 1.0901 - acc: 0.3936 - val_loss: 1.0962 - val_acc: 0.3644\n",
            "Epoch 67/150 - 0.10s - loss: 1.0900 - acc: 0.3947 - val_loss: 1.0961 - val_acc: 0.3623\n",
            "Epoch 68/150 - 0.12s - loss: 1.0899 - acc: 0.3947 - val_loss: 1.0961 - val_acc: 0.3623\n",
            "Epoch 69/150 - 0.10s - loss: 1.0898 - acc: 0.3947 - val_loss: 1.0960 - val_acc: 0.3644\n",
            "Epoch 70/150 - 0.13s - loss: 1.0897 - acc: 0.3945 - val_loss: 1.0959 - val_acc: 0.3623\n",
            "Epoch 71/150 - 0.13s - loss: 1.0896 - acc: 0.3952 - val_loss: 1.0958 - val_acc: 0.3623\n",
            "Epoch 72/150 - 0.12s - loss: 1.0895 - acc: 0.3956 - val_loss: 1.0958 - val_acc: 0.3623\n",
            "Epoch 73/150 - 0.11s - loss: 1.0894 - acc: 0.3959 - val_loss: 1.0957 - val_acc: 0.3664\n",
            "Epoch 74/150 - 0.10s - loss: 1.0893 - acc: 0.3965 - val_loss: 1.0956 - val_acc: 0.3644\n",
            "Epoch 75/150 - 0.10s - loss: 1.0892 - acc: 0.3972 - val_loss: 1.0955 - val_acc: 0.3644\n",
            "Epoch 76/150 - 0.12s - loss: 1.0890 - acc: 0.3995 - val_loss: 1.0955 - val_acc: 0.3603\n",
            "Epoch 77/150 - 0.11s - loss: 1.0889 - acc: 0.3997 - val_loss: 1.0954 - val_acc: 0.3603\n",
            "Epoch 78/150 - 0.11s - loss: 1.0888 - acc: 0.4008 - val_loss: 1.0953 - val_acc: 0.3623\n",
            "Epoch 79/150 - 0.10s - loss: 1.0887 - acc: 0.4008 - val_loss: 1.0952 - val_acc: 0.3623\n",
            "Epoch 80/150 - 0.11s - loss: 1.0886 - acc: 0.4008 - val_loss: 1.0951 - val_acc: 0.3623\n",
            "Epoch 81/150 - 0.10s - loss: 1.0885 - acc: 0.4006 - val_loss: 1.0951 - val_acc: 0.3623\n",
            "Epoch 82/150 - 0.12s - loss: 1.0884 - acc: 0.4006 - val_loss: 1.0950 - val_acc: 0.3644\n",
            "Epoch 83/150 - 0.11s - loss: 1.0883 - acc: 0.3999 - val_loss: 1.0949 - val_acc: 0.3623\n",
            "Epoch 84/150 - 0.11s - loss: 1.0882 - acc: 0.3999 - val_loss: 1.0948 - val_acc: 0.3644\n",
            "Epoch 85/150 - 0.13s - loss: 1.0881 - acc: 0.4017 - val_loss: 1.0947 - val_acc: 0.3664\n",
            "Epoch 86/150 - 0.15s - loss: 1.0880 - acc: 0.4028 - val_loss: 1.0947 - val_acc: 0.3644\n",
            "Epoch 87/150 - 0.10s - loss: 1.0879 - acc: 0.4033 - val_loss: 1.0946 - val_acc: 0.3644\n",
            "Epoch 88/150 - 0.10s - loss: 1.0878 - acc: 0.4040 - val_loss: 1.0945 - val_acc: 0.3644\n",
            "Epoch 89/150 - 0.11s - loss: 1.0877 - acc: 0.4040 - val_loss: 1.0944 - val_acc: 0.3623\n",
            "Epoch 90/150 - 0.11s - loss: 1.0876 - acc: 0.4046 - val_loss: 1.0943 - val_acc: 0.3623\n",
            "Epoch 91/150 - 0.11s - loss: 1.0875 - acc: 0.4049 - val_loss: 1.0943 - val_acc: 0.3623\n",
            "Epoch 92/150 - 0.10s - loss: 1.0874 - acc: 0.4060 - val_loss: 1.0942 - val_acc: 0.3623\n",
            "Epoch 93/150 - 0.10s - loss: 1.0872 - acc: 0.4060 - val_loss: 1.0941 - val_acc: 0.3623\n",
            "Epoch 94/150 - 0.11s - loss: 1.0871 - acc: 0.4060 - val_loss: 1.0940 - val_acc: 0.3583\n",
            "Epoch 95/150 - 0.10s - loss: 1.0870 - acc: 0.4069 - val_loss: 1.0939 - val_acc: 0.3583\n",
            "Epoch 96/150 - 0.11s - loss: 1.0869 - acc: 0.4069 - val_loss: 1.0939 - val_acc: 0.3583\n",
            "Epoch 97/150 - 0.11s - loss: 1.0868 - acc: 0.4076 - val_loss: 1.0938 - val_acc: 0.3563\n",
            "Epoch 98/150 - 0.10s - loss: 1.0867 - acc: 0.4069 - val_loss: 1.0937 - val_acc: 0.3583\n",
            "Epoch 99/150 - 0.13s - loss: 1.0866 - acc: 0.4067 - val_loss: 1.0936 - val_acc: 0.3583\n",
            "Epoch 100/150 - 0.11s - loss: 1.0865 - acc: 0.4069 - val_loss: 1.0935 - val_acc: 0.3603\n",
            "Epoch 101/150 - 0.10s - loss: 1.0864 - acc: 0.4080 - val_loss: 1.0935 - val_acc: 0.3603\n",
            "Epoch 102/150 - 0.11s - loss: 1.0863 - acc: 0.4087 - val_loss: 1.0934 - val_acc: 0.3603\n",
            "Epoch 103/150 - 0.15s - loss: 1.0862 - acc: 0.4089 - val_loss: 1.0933 - val_acc: 0.3644\n",
            "Epoch 104/150 - 0.11s - loss: 1.0861 - acc: 0.4089 - val_loss: 1.0932 - val_acc: 0.3644\n",
            "Epoch 105/150 - 0.12s - loss: 1.0860 - acc: 0.4094 - val_loss: 1.0931 - val_acc: 0.3664\n",
            "Epoch 106/150 - 0.11s - loss: 1.0859 - acc: 0.4096 - val_loss: 1.0931 - val_acc: 0.3664\n",
            "Epoch 107/150 - 0.12s - loss: 1.0858 - acc: 0.4103 - val_loss: 1.0930 - val_acc: 0.3704\n",
            "Epoch 108/150 - 0.11s - loss: 1.0857 - acc: 0.4121 - val_loss: 1.0929 - val_acc: 0.3704\n",
            "Epoch 109/150 - 0.10s - loss: 1.0856 - acc: 0.4112 - val_loss: 1.0928 - val_acc: 0.3684\n",
            "Epoch 110/150 - 0.10s - loss: 1.0855 - acc: 0.4118 - val_loss: 1.0927 - val_acc: 0.3684\n",
            "Epoch 111/150 - 0.16s - loss: 1.0854 - acc: 0.4118 - val_loss: 1.0927 - val_acc: 0.3704\n",
            "Epoch 112/150 - 0.10s - loss: 1.0853 - acc: 0.4123 - val_loss: 1.0926 - val_acc: 0.3684\n",
            "Epoch 113/150 - 0.11s - loss: 1.0852 - acc: 0.4125 - val_loss: 1.0925 - val_acc: 0.3704\n",
            "Epoch 114/150 - 0.11s - loss: 1.0851 - acc: 0.4132 - val_loss: 1.0924 - val_acc: 0.3704\n",
            "Epoch 115/150 - 0.10s - loss: 1.0850 - acc: 0.4127 - val_loss: 1.0924 - val_acc: 0.3704\n",
            "Epoch 116/150 - 0.12s - loss: 1.0850 - acc: 0.4132 - val_loss: 1.0923 - val_acc: 0.3725\n",
            "Epoch 117/150 - 0.11s - loss: 1.0849 - acc: 0.4132 - val_loss: 1.0922 - val_acc: 0.3725\n",
            "Epoch 118/150 - 0.14s - loss: 1.0848 - acc: 0.4139 - val_loss: 1.0921 - val_acc: 0.3725\n",
            "Epoch 119/150 - 0.12s - loss: 1.0847 - acc: 0.4148 - val_loss: 1.0921 - val_acc: 0.3725\n",
            "Epoch 120/150 - 0.11s - loss: 1.0846 - acc: 0.4161 - val_loss: 1.0920 - val_acc: 0.3725\n",
            "Epoch 121/150 - 0.10s - loss: 1.0845 - acc: 0.4172 - val_loss: 1.0919 - val_acc: 0.3725\n",
            "Epoch 122/150 - 0.11s - loss: 1.0844 - acc: 0.4177 - val_loss: 1.0918 - val_acc: 0.3725\n",
            "Epoch 123/150 - 0.12s - loss: 1.0843 - acc: 0.4184 - val_loss: 1.0918 - val_acc: 0.3704\n",
            "Epoch 124/150 - 0.11s - loss: 1.0842 - acc: 0.4184 - val_loss: 1.0917 - val_acc: 0.3725\n",
            "Epoch 125/150 - 0.10s - loss: 1.0841 - acc: 0.4190 - val_loss: 1.0916 - val_acc: 0.3725\n",
            "Epoch 126/150 - 0.12s - loss: 1.0840 - acc: 0.4190 - val_loss: 1.0916 - val_acc: 0.3745\n",
            "Epoch 127/150 - 0.10s - loss: 1.0839 - acc: 0.4193 - val_loss: 1.0915 - val_acc: 0.3725\n",
            "Epoch 128/150 - 0.11s - loss: 1.0838 - acc: 0.4190 - val_loss: 1.0914 - val_acc: 0.3704\n",
            "Epoch 129/150 - 0.10s - loss: 1.0837 - acc: 0.4184 - val_loss: 1.0913 - val_acc: 0.3704\n",
            "Epoch 130/150 - 0.11s - loss: 1.0836 - acc: 0.4190 - val_loss: 1.0913 - val_acc: 0.3704\n",
            "Epoch 131/150 - 0.10s - loss: 1.0835 - acc: 0.4193 - val_loss: 1.0912 - val_acc: 0.3704\n",
            "Epoch 132/150 - 0.15s - loss: 1.0834 - acc: 0.4199 - val_loss: 1.0911 - val_acc: 0.3684\n",
            "Epoch 133/150 - 0.10s - loss: 1.0833 - acc: 0.4211 - val_loss: 1.0911 - val_acc: 0.3684\n",
            "Epoch 134/150 - 0.10s - loss: 1.0832 - acc: 0.4217 - val_loss: 1.0910 - val_acc: 0.3684\n",
            "Epoch 135/150 - 0.11s - loss: 1.0832 - acc: 0.4217 - val_loss: 1.0909 - val_acc: 0.3684\n",
            "Epoch 136/150 - 0.11s - loss: 1.0831 - acc: 0.4226 - val_loss: 1.0909 - val_acc: 0.3664\n",
            "Epoch 137/150 - 0.12s - loss: 1.0830 - acc: 0.4226 - val_loss: 1.0908 - val_acc: 0.3664\n",
            "Epoch 138/150 - 0.11s - loss: 1.0829 - acc: 0.4231 - val_loss: 1.0907 - val_acc: 0.3704\n",
            "Epoch 139/150 - 0.11s - loss: 1.0828 - acc: 0.4226 - val_loss: 1.0906 - val_acc: 0.3704\n",
            "Epoch 140/150 - 0.10s - loss: 1.0827 - acc: 0.4229 - val_loss: 1.0906 - val_acc: 0.3684\n",
            "Epoch 141/150 - 0.12s - loss: 1.0826 - acc: 0.4229 - val_loss: 1.0905 - val_acc: 0.3664\n",
            "Epoch 142/150 - 0.11s - loss: 1.0825 - acc: 0.4231 - val_loss: 1.0904 - val_acc: 0.3664\n",
            "Epoch 143/150 - 0.11s - loss: 1.0824 - acc: 0.4233 - val_loss: 1.0903 - val_acc: 0.3664\n",
            "Epoch 144/150 - 0.11s - loss: 1.0823 - acc: 0.4233 - val_loss: 1.0903 - val_acc: 0.3684\n",
            "Epoch 145/150 - 0.13s - loss: 1.0822 - acc: 0.4240 - val_loss: 1.0902 - val_acc: 0.3664\n",
            "Epoch 146/150 - 0.10s - loss: 1.0821 - acc: 0.4240 - val_loss: 1.0901 - val_acc: 0.3664\n",
            "Epoch 147/150 - 0.12s - loss: 1.0820 - acc: 0.4256 - val_loss: 1.0901 - val_acc: 0.3664\n",
            "Epoch 148/150 - 0.11s - loss: 1.0819 - acc: 0.4256 - val_loss: 1.0900 - val_acc: 0.3684\n",
            "Epoch 149/150 - 0.13s - loss: 1.0818 - acc: 0.4260 - val_loss: 1.0899 - val_acc: 0.3684\n",
            "Epoch 150/150 - 0.10s - loss: 1.0818 - acc: 0.4265 - val_loss: 1.0899 - val_acc: 0.3664\n",
            "\n",
            "Combination 199/252:\n",
            "Hidden Layers: [256, 128, 64], Activation: tanh, Learning Rate: 0.01, Batch Size: 32, Epochs: 50\n",
            "Epoch 1/50 - 0.20s - loss: 1.0815 - acc: 0.3965 - val_loss: 1.0873 - val_acc: 0.4109\n",
            "Epoch 2/50 - 0.21s - loss: 1.0666 - acc: 0.4449 - val_loss: 1.0731 - val_acc: 0.4211\n",
            "Epoch 3/50 - 0.20s - loss: 1.0554 - acc: 0.4640 - val_loss: 1.0654 - val_acc: 0.4433\n",
            "Epoch 4/50 - 0.20s - loss: 1.0479 - acc: 0.4656 - val_loss: 1.0612 - val_acc: 0.4555\n",
            "Epoch 5/50 - 0.22s - loss: 1.0371 - acc: 0.4827 - val_loss: 1.0519 - val_acc: 0.4757\n",
            "Epoch 6/50 - 0.20s - loss: 1.0372 - acc: 0.4602 - val_loss: 1.0521 - val_acc: 0.4555\n",
            "Epoch 7/50 - 0.20s - loss: 1.0220 - acc: 0.4957 - val_loss: 1.0427 - val_acc: 0.4939\n",
            "Epoch 8/50 - 0.21s - loss: 1.0146 - acc: 0.5000 - val_loss: 1.0368 - val_acc: 0.5061\n",
            "Epoch 9/50 - 0.23s - loss: 1.0103 - acc: 0.4953 - val_loss: 1.0330 - val_acc: 0.4919\n",
            "Epoch 10/50 - 0.21s - loss: 0.9995 - acc: 0.5076 - val_loss: 1.0252 - val_acc: 0.4899\n",
            "Epoch 11/50 - 0.23s - loss: 0.9884 - acc: 0.5223 - val_loss: 1.0162 - val_acc: 0.5263\n",
            "Epoch 12/50 - 0.23s - loss: 0.9815 - acc: 0.5286 - val_loss: 1.0097 - val_acc: 0.5223\n",
            "Epoch 13/50 - 0.21s - loss: 0.9745 - acc: 0.5340 - val_loss: 1.0049 - val_acc: 0.5364\n",
            "Epoch 14/50 - 0.22s - loss: 0.9678 - acc: 0.5340 - val_loss: 0.9985 - val_acc: 0.5243\n",
            "Epoch 15/50 - 0.21s - loss: 0.9669 - acc: 0.5382 - val_loss: 0.9982 - val_acc: 0.5263\n",
            "Epoch 16/50 - 0.22s - loss: 0.9701 - acc: 0.5369 - val_loss: 1.0022 - val_acc: 0.5202\n",
            "Epoch 17/50 - 0.20s - loss: 0.9545 - acc: 0.5454 - val_loss: 0.9889 - val_acc: 0.5263\n",
            "Epoch 18/50 - 0.25s - loss: 0.9499 - acc: 0.5504 - val_loss: 0.9846 - val_acc: 0.5304\n",
            "Epoch 19/50 - 0.20s - loss: 0.9432 - acc: 0.5547 - val_loss: 0.9819 - val_acc: 0.5587\n",
            "Epoch 20/50 - 0.21s - loss: 0.9364 - acc: 0.5490 - val_loss: 0.9755 - val_acc: 0.5283\n",
            "Epoch 21/50 - 0.20s - loss: 0.9322 - acc: 0.5594 - val_loss: 0.9772 - val_acc: 0.5425\n",
            "Epoch 22/50 - 0.21s - loss: 0.9468 - acc: 0.5407 - val_loss: 0.9872 - val_acc: 0.5142\n",
            "Epoch 23/50 - 0.20s - loss: 0.9362 - acc: 0.5650 - val_loss: 0.9787 - val_acc: 0.5405\n",
            "Epoch 24/50 - 0.21s - loss: 0.9414 - acc: 0.5468 - val_loss: 0.9929 - val_acc: 0.5061\n",
            "Epoch 25/50 - 0.21s - loss: 0.9158 - acc: 0.5706 - val_loss: 0.9626 - val_acc: 0.5506\n",
            "Epoch 26/50 - 0.22s - loss: 0.9217 - acc: 0.5733 - val_loss: 0.9709 - val_acc: 0.5486\n",
            "Epoch 27/50 - 0.21s - loss: 0.9088 - acc: 0.5812 - val_loss: 0.9605 - val_acc: 0.5445\n",
            "Epoch 28/50 - 0.20s - loss: 0.9205 - acc: 0.5571 - val_loss: 0.9779 - val_acc: 0.5324\n",
            "Epoch 29/50 - 0.20s - loss: 0.9079 - acc: 0.5684 - val_loss: 0.9632 - val_acc: 0.5385\n",
            "Epoch 30/50 - 0.22s - loss: 0.9139 - acc: 0.5810 - val_loss: 0.9715 - val_acc: 0.5425\n",
            "Epoch 31/50 - 0.20s - loss: 0.9058 - acc: 0.5639 - val_loss: 0.9651 - val_acc: 0.5364\n",
            "Epoch 32/50 - 0.21s - loss: 0.8924 - acc: 0.5830 - val_loss: 0.9555 - val_acc: 0.5628\n",
            "Epoch 33/50 - 0.20s - loss: 0.8913 - acc: 0.5823 - val_loss: 0.9542 - val_acc: 0.5486\n",
            "Epoch 34/50 - 0.21s - loss: 0.8903 - acc: 0.5929 - val_loss: 0.9536 - val_acc: 0.5668\n",
            "Epoch 35/50 - 0.20s - loss: 0.8984 - acc: 0.5855 - val_loss: 0.9643 - val_acc: 0.5547\n",
            "Epoch 36/50 - 0.20s - loss: 0.9130 - acc: 0.5603 - val_loss: 0.9846 - val_acc: 0.5243\n",
            "Epoch 37/50 - 0.20s - loss: 0.8907 - acc: 0.5942 - val_loss: 0.9615 - val_acc: 0.5486\n",
            "Epoch 38/50 - 0.23s - loss: 0.8810 - acc: 0.5947 - val_loss: 0.9566 - val_acc: 0.5425\n",
            "Epoch 39/50 - 0.20s - loss: 0.8970 - acc: 0.5776 - val_loss: 0.9656 - val_acc: 0.5405\n",
            "Epoch 40/50 - 0.21s - loss: 0.9453 - acc: 0.5448 - val_loss: 1.0141 - val_acc: 0.5304\n",
            "Epoch 41/50 - 0.20s - loss: 0.8777 - acc: 0.5891 - val_loss: 0.9577 - val_acc: 0.5466\n",
            "Epoch 42/50 - 0.21s - loss: 0.8778 - acc: 0.5929 - val_loss: 0.9580 - val_acc: 0.5506\n",
            "Epoch 43/50 - 0.20s - loss: 0.8763 - acc: 0.5913 - val_loss: 0.9576 - val_acc: 0.5547\n",
            "Epoch 44/50 - 0.20s - loss: 0.8683 - acc: 0.5992 - val_loss: 0.9546 - val_acc: 0.5567\n",
            "Epoch 45/50 - 0.20s - loss: 0.9106 - acc: 0.5825 - val_loss: 0.9930 - val_acc: 0.5344\n",
            "Epoch 46/50 - 0.21s - loss: 0.8815 - acc: 0.5873 - val_loss: 0.9742 - val_acc: 0.5263\n",
            "Epoch 47/50 - 0.20s - loss: 0.9670 - acc: 0.5542 - val_loss: 1.0451 - val_acc: 0.5121\n",
            "Epoch 48/50 - 0.20s - loss: 0.8696 - acc: 0.5978 - val_loss: 0.9651 - val_acc: 0.5445\n",
            "Epoch 49/50 - 0.20s - loss: 0.8710 - acc: 0.5918 - val_loss: 0.9626 - val_acc: 0.5486\n",
            "Epoch 50/50 - 0.21s - loss: 0.8616 - acc: 0.6113 - val_loss: 0.9590 - val_acc: 0.5506\n",
            "\n",
            "Combination 200/252:\n",
            "Hidden Layers: [256, 128, 64], Activation: tanh, Learning Rate: 0.01, Batch Size: 32, Epochs: 100\n",
            "Epoch 1/100 - 0.20s - loss: 1.0810 - acc: 0.4082 - val_loss: 1.0829 - val_acc: 0.3846\n",
            "Epoch 2/100 - 0.21s - loss: 1.0698 - acc: 0.4269 - val_loss: 1.0738 - val_acc: 0.4109\n",
            "Epoch 3/100 - 0.22s - loss: 1.0581 - acc: 0.4501 - val_loss: 1.0634 - val_acc: 0.4271\n",
            "Epoch 4/100 - 0.20s - loss: 1.0505 - acc: 0.4557 - val_loss: 1.0558 - val_acc: 0.4575\n",
            "Epoch 5/100 - 0.20s - loss: 1.0425 - acc: 0.4647 - val_loss: 1.0496 - val_acc: 0.4737\n",
            "Epoch 6/100 - 0.21s - loss: 1.0357 - acc: 0.4753 - val_loss: 1.0470 - val_acc: 0.4757\n",
            "Epoch 7/100 - 0.20s - loss: 1.0282 - acc: 0.4827 - val_loss: 1.0381 - val_acc: 0.4879\n",
            "Epoch 8/100 - 0.21s - loss: 1.0226 - acc: 0.4894 - val_loss: 1.0356 - val_acc: 0.4838\n",
            "Epoch 9/100 - 0.20s - loss: 1.0110 - acc: 0.5108 - val_loss: 1.0252 - val_acc: 0.5121\n",
            "Epoch 10/100 - 0.21s - loss: 1.0025 - acc: 0.5142 - val_loss: 1.0185 - val_acc: 0.5223\n",
            "Epoch 11/100 - 0.20s - loss: 0.9981 - acc: 0.5117 - val_loss: 1.0133 - val_acc: 0.5202\n",
            "Epoch 12/100 - 0.20s - loss: 0.9876 - acc: 0.5259 - val_loss: 1.0055 - val_acc: 0.5385\n",
            "Epoch 13/100 - 0.20s - loss: 0.9799 - acc: 0.5340 - val_loss: 0.9996 - val_acc: 0.5486\n",
            "Epoch 14/100 - 0.21s - loss: 0.9725 - acc: 0.5346 - val_loss: 0.9921 - val_acc: 0.5425\n",
            "Epoch 15/100 - 0.22s - loss: 0.9730 - acc: 0.5290 - val_loss: 0.9961 - val_acc: 0.5283\n",
            "Epoch 16/100 - 0.21s - loss: 0.9611 - acc: 0.5378 - val_loss: 0.9848 - val_acc: 0.5405\n",
            "Epoch 17/100 - 0.21s - loss: 0.9544 - acc: 0.5436 - val_loss: 0.9806 - val_acc: 0.5385\n",
            "Epoch 18/100 - 0.21s - loss: 0.9536 - acc: 0.5367 - val_loss: 0.9813 - val_acc: 0.5304\n",
            "Epoch 19/100 - 0.20s - loss: 0.9524 - acc: 0.5468 - val_loss: 0.9775 - val_acc: 0.5607\n",
            "Epoch 20/100 - 0.20s - loss: 0.9415 - acc: 0.5490 - val_loss: 0.9682 - val_acc: 0.5506\n",
            "Epoch 21/100 - 0.20s - loss: 0.9357 - acc: 0.5547 - val_loss: 0.9634 - val_acc: 0.5688\n",
            "Epoch 22/100 - 0.22s - loss: 0.9295 - acc: 0.5567 - val_loss: 0.9623 - val_acc: 0.5587\n",
            "Epoch 23/100 - 0.20s - loss: 0.9289 - acc: 0.5598 - val_loss: 0.9588 - val_acc: 0.5547\n",
            "Epoch 24/100 - 0.24s - loss: 0.9210 - acc: 0.5630 - val_loss: 0.9573 - val_acc: 0.5709\n",
            "Epoch 25/100 - 0.22s - loss: 0.9215 - acc: 0.5614 - val_loss: 0.9575 - val_acc: 0.5567\n",
            "Epoch 26/100 - 0.24s - loss: 0.9587 - acc: 0.5274 - val_loss: 1.0042 - val_acc: 0.4980\n",
            "Epoch 27/100 - 0.20s - loss: 0.9108 - acc: 0.5679 - val_loss: 0.9541 - val_acc: 0.5567\n",
            "Epoch 28/100 - 0.24s - loss: 0.9081 - acc: 0.5744 - val_loss: 0.9534 - val_acc: 0.5668\n",
            "Epoch 29/100 - 0.21s - loss: 0.9445 - acc: 0.5385 - val_loss: 0.9795 - val_acc: 0.5364\n",
            "Epoch 30/100 - 0.21s - loss: 0.9056 - acc: 0.5713 - val_loss: 0.9507 - val_acc: 0.5425\n",
            "Epoch 31/100 - 0.20s - loss: 0.9042 - acc: 0.5850 - val_loss: 0.9564 - val_acc: 0.5587\n",
            "Epoch 32/100 - 0.21s - loss: 0.9278 - acc: 0.5646 - val_loss: 0.9789 - val_acc: 0.5425\n",
            "Epoch 33/100 - 0.20s - loss: 0.9123 - acc: 0.5632 - val_loss: 0.9700 - val_acc: 0.5304\n",
            "Epoch 34/100 - 0.21s - loss: 0.8962 - acc: 0.5780 - val_loss: 0.9545 - val_acc: 0.5385\n",
            "Epoch 35/100 - 0.20s - loss: 0.9163 - acc: 0.5756 - val_loss: 0.9687 - val_acc: 0.5607\n",
            "Epoch 36/100 - 0.21s - loss: 0.8898 - acc: 0.5828 - val_loss: 0.9484 - val_acc: 0.5526\n",
            "Epoch 37/100 - 0.20s - loss: 0.8844 - acc: 0.5821 - val_loss: 0.9470 - val_acc: 0.5506\n",
            "Epoch 38/100 - 0.22s - loss: 0.9067 - acc: 0.5713 - val_loss: 0.9790 - val_acc: 0.5142\n",
            "Epoch 39/100 - 0.20s - loss: 0.9284 - acc: 0.5578 - val_loss: 0.9948 - val_acc: 0.5223\n",
            "Epoch 40/100 - 0.21s - loss: 0.8887 - acc: 0.5915 - val_loss: 0.9567 - val_acc: 0.5486\n",
            "Epoch 41/100 - 0.20s - loss: 0.8812 - acc: 0.5830 - val_loss: 0.9557 - val_acc: 0.5304\n",
            "Epoch 42/100 - 0.21s - loss: 0.9227 - acc: 0.5614 - val_loss: 0.9814 - val_acc: 0.5526\n",
            "Epoch 43/100 - 0.20s - loss: 0.8802 - acc: 0.5823 - val_loss: 0.9558 - val_acc: 0.5405\n",
            "Epoch 44/100 - 0.21s - loss: 0.8780 - acc: 0.6005 - val_loss: 0.9525 - val_acc: 0.5628\n",
            "Epoch 45/100 - 0.20s - loss: 0.8874 - acc: 0.5776 - val_loss: 0.9554 - val_acc: 0.5567\n",
            "Epoch 46/100 - 0.21s - loss: 0.8921 - acc: 0.5684 - val_loss: 0.9668 - val_acc: 0.5445\n",
            "Epoch 47/100 - 0.20s - loss: 0.8637 - acc: 0.6014 - val_loss: 0.9477 - val_acc: 0.5385\n",
            "Epoch 48/100 - 0.20s - loss: 0.8715 - acc: 0.6077 - val_loss: 0.9557 - val_acc: 0.5506\n",
            "Epoch 49/100 - 0.19s - loss: 0.8790 - acc: 0.5902 - val_loss: 0.9717 - val_acc: 0.5223\n",
            "Epoch 50/100 - 0.20s - loss: 0.8613 - acc: 0.6118 - val_loss: 0.9485 - val_acc: 0.5466\n",
            "Epoch 51/100 - 0.20s - loss: 0.8800 - acc: 0.6017 - val_loss: 0.9706 - val_acc: 0.5425\n",
            "Epoch 52/100 - 0.22s - loss: 0.8632 - acc: 0.6100 - val_loss: 0.9575 - val_acc: 0.5445\n",
            "Epoch 53/100 - 0.19s - loss: 0.8678 - acc: 0.5940 - val_loss: 0.9571 - val_acc: 0.5506\n",
            "Epoch 54/100 - 0.20s - loss: 0.8909 - acc: 0.5792 - val_loss: 0.9977 - val_acc: 0.5081\n",
            "Epoch 55/100 - 0.19s - loss: 0.8625 - acc: 0.6057 - val_loss: 0.9633 - val_acc: 0.5385\n",
            "Epoch 56/100 - 0.20s - loss: 0.9368 - acc: 0.5423 - val_loss: 1.0161 - val_acc: 0.5243\n",
            "Epoch 57/100 - 0.19s - loss: 0.8550 - acc: 0.6041 - val_loss: 0.9512 - val_acc: 0.5466\n",
            "Epoch 58/100 - 0.20s - loss: 0.8596 - acc: 0.6001 - val_loss: 0.9651 - val_acc: 0.5324\n",
            "Epoch 59/100 - 0.20s - loss: 0.8543 - acc: 0.6102 - val_loss: 0.9553 - val_acc: 0.5425\n",
            "Epoch 60/100 - 0.21s - loss: 0.8488 - acc: 0.6149 - val_loss: 0.9545 - val_acc: 0.5385\n",
            "Epoch 61/100 - 0.20s - loss: 0.8813 - acc: 0.5837 - val_loss: 0.9785 - val_acc: 0.5344\n",
            "Epoch 62/100 - 0.21s - loss: 0.8539 - acc: 0.6050 - val_loss: 0.9512 - val_acc: 0.5506\n",
            "Epoch 63/100 - 0.20s - loss: 0.8678 - acc: 0.5936 - val_loss: 0.9660 - val_acc: 0.5506\n",
            "Epoch 64/100 - 0.21s - loss: 0.8714 - acc: 0.5882 - val_loss: 0.9643 - val_acc: 0.5526\n",
            "Epoch 65/100 - 0.21s - loss: 0.8675 - acc: 0.5954 - val_loss: 0.9849 - val_acc: 0.5344\n",
            "Epoch 66/100 - 0.23s - loss: 0.8445 - acc: 0.6125 - val_loss: 0.9574 - val_acc: 0.5425\n",
            "Epoch 67/100 - 0.21s - loss: 0.8431 - acc: 0.6158 - val_loss: 0.9538 - val_acc: 0.5547\n",
            "Epoch 68/100 - 0.20s - loss: 0.8616 - acc: 0.6120 - val_loss: 0.9699 - val_acc: 0.5567\n",
            "Epoch 69/100 - 0.21s - loss: 0.8651 - acc: 0.5976 - val_loss: 0.9802 - val_acc: 0.5283\n",
            "Epoch 70/100 - 0.19s - loss: 0.8670 - acc: 0.5972 - val_loss: 0.9910 - val_acc: 0.5162\n",
            "Epoch 71/100 - 0.20s - loss: 0.8472 - acc: 0.6167 - val_loss: 0.9664 - val_acc: 0.5445\n",
            "Epoch 72/100 - 0.20s - loss: 0.8561 - acc: 0.6118 - val_loss: 0.9742 - val_acc: 0.5466\n",
            "Epoch 73/100 - 0.21s - loss: 0.8620 - acc: 0.6037 - val_loss: 0.9861 - val_acc: 0.5304\n",
            "Epoch 74/100 - 0.20s - loss: 0.8638 - acc: 0.5967 - val_loss: 0.9863 - val_acc: 0.5344\n",
            "Epoch 75/100 - 0.21s - loss: 0.8389 - acc: 0.6190 - val_loss: 0.9649 - val_acc: 0.5445\n",
            "Epoch 76/100 - 0.25s - loss: 0.8751 - acc: 0.5893 - val_loss: 0.9968 - val_acc: 0.5304\n",
            "Epoch 77/100 - 0.21s - loss: 0.8525 - acc: 0.6136 - val_loss: 0.9714 - val_acc: 0.5567\n",
            "Epoch 78/100 - 0.21s - loss: 0.8478 - acc: 0.6145 - val_loss: 0.9749 - val_acc: 0.5405\n",
            "Epoch 79/100 - 0.20s - loss: 0.8549 - acc: 0.6122 - val_loss: 0.9780 - val_acc: 0.5405\n",
            "Epoch 80/100 - 0.21s - loss: 0.8373 - acc: 0.6246 - val_loss: 0.9612 - val_acc: 0.5567\n",
            "Epoch 81/100 - 0.20s - loss: 0.8777 - acc: 0.5929 - val_loss: 1.0132 - val_acc: 0.5162\n",
            "Epoch 82/100 - 0.21s - loss: 0.8413 - acc: 0.6208 - val_loss: 0.9736 - val_acc: 0.5405\n",
            "Epoch 83/100 - 0.20s - loss: 0.8356 - acc: 0.6212 - val_loss: 0.9626 - val_acc: 0.5526\n",
            "Epoch 84/100 - 0.22s - loss: 0.8422 - acc: 0.6113 - val_loss: 0.9665 - val_acc: 0.5324\n",
            "Epoch 85/100 - 0.21s - loss: 0.8680 - acc: 0.5931 - val_loss: 0.9958 - val_acc: 0.5324\n",
            "Epoch 86/100 - 0.22s - loss: 0.8476 - acc: 0.6064 - val_loss: 0.9781 - val_acc: 0.5425\n",
            "Epoch 87/100 - 0.22s - loss: 0.8434 - acc: 0.6093 - val_loss: 0.9732 - val_acc: 0.5385\n",
            "Epoch 88/100 - 0.21s - loss: 0.8361 - acc: 0.6262 - val_loss: 0.9652 - val_acc: 0.5526\n",
            "Epoch 89/100 - 0.21s - loss: 0.8306 - acc: 0.6230 - val_loss: 0.9563 - val_acc: 0.5526\n",
            "Epoch 90/100 - 0.20s - loss: 0.8392 - acc: 0.6224 - val_loss: 0.9648 - val_acc: 0.5648\n",
            "Epoch 91/100 - 0.22s - loss: 0.8420 - acc: 0.6129 - val_loss: 0.9808 - val_acc: 0.5425\n",
            "Epoch 92/100 - 0.20s - loss: 0.9448 - acc: 0.5457 - val_loss: 1.0490 - val_acc: 0.5202\n",
            "Epoch 93/100 - 0.21s - loss: 0.8287 - acc: 0.6291 - val_loss: 0.9606 - val_acc: 0.5668\n",
            "Epoch 94/100 - 0.20s - loss: 0.8321 - acc: 0.6282 - val_loss: 0.9620 - val_acc: 0.5607\n",
            "Epoch 95/100 - 0.21s - loss: 0.8275 - acc: 0.6291 - val_loss: 0.9648 - val_acc: 0.5466\n",
            "Epoch 96/100 - 0.20s - loss: 0.8404 - acc: 0.6138 - val_loss: 0.9664 - val_acc: 0.5486\n",
            "Epoch 97/100 - 0.21s - loss: 0.8334 - acc: 0.6156 - val_loss: 0.9742 - val_acc: 0.5567\n",
            "Epoch 98/100 - 0.22s - loss: 0.8434 - acc: 0.6176 - val_loss: 0.9727 - val_acc: 0.5688\n",
            "Epoch 99/100 - 0.20s - loss: 0.8323 - acc: 0.6203 - val_loss: 0.9731 - val_acc: 0.5466\n",
            "Epoch 100/100 - 0.20s - loss: 0.8267 - acc: 0.6257 - val_loss: 0.9695 - val_acc: 0.5587\n",
            "\n",
            "Combination 201/252:\n",
            "Hidden Layers: [256, 128, 64], Activation: tanh, Learning Rate: 0.01, Batch Size: 32, Epochs: 150\n",
            "Epoch 1/150 - 0.21s - loss: 1.0831 - acc: 0.3810 - val_loss: 1.0863 - val_acc: 0.3846\n",
            "Epoch 2/150 - 0.19s - loss: 1.0675 - acc: 0.4433 - val_loss: 1.0715 - val_acc: 0.4433\n",
            "Epoch 3/150 - 0.21s - loss: 1.0559 - acc: 0.4501 - val_loss: 1.0637 - val_acc: 0.4514\n",
            "Epoch 4/150 - 0.20s - loss: 1.0485 - acc: 0.4631 - val_loss: 1.0604 - val_acc: 0.4555\n",
            "Epoch 5/150 - 0.22s - loss: 1.0380 - acc: 0.4759 - val_loss: 1.0519 - val_acc: 0.4737\n",
            "Epoch 6/150 - 0.23s - loss: 1.0308 - acc: 0.4672 - val_loss: 1.0460 - val_acc: 0.4676\n",
            "Epoch 7/150 - 0.23s - loss: 1.0236 - acc: 0.4906 - val_loss: 1.0403 - val_acc: 0.4676\n",
            "Epoch 8/150 - 0.29s - loss: 1.0118 - acc: 0.5029 - val_loss: 1.0327 - val_acc: 0.5121\n",
            "Epoch 9/150 - 0.22s - loss: 1.0044 - acc: 0.5022 - val_loss: 1.0295 - val_acc: 0.5121\n",
            "Epoch 10/150 - 0.25s - loss: 0.9962 - acc: 0.5135 - val_loss: 1.0232 - val_acc: 0.5182\n",
            "Epoch 11/150 - 0.23s - loss: 0.9885 - acc: 0.5178 - val_loss: 1.0153 - val_acc: 0.4919\n",
            "Epoch 12/150 - 0.25s - loss: 0.9817 - acc: 0.5193 - val_loss: 1.0129 - val_acc: 0.5263\n",
            "Epoch 13/150 - 0.22s - loss: 0.9770 - acc: 0.5265 - val_loss: 1.0052 - val_acc: 0.5364\n",
            "Epoch 14/150 - 0.22s - loss: 0.9675 - acc: 0.5346 - val_loss: 0.9966 - val_acc: 0.5364\n",
            "Epoch 15/150 - 0.22s - loss: 0.9595 - acc: 0.5364 - val_loss: 0.9920 - val_acc: 0.5263\n",
            "Epoch 16/150 - 0.25s - loss: 0.9514 - acc: 0.5389 - val_loss: 0.9853 - val_acc: 0.5263\n",
            "Epoch 17/150 - 0.20s - loss: 0.9496 - acc: 0.5441 - val_loss: 0.9815 - val_acc: 0.5364\n",
            "Epoch 18/150 - 0.21s - loss: 0.9568 - acc: 0.5265 - val_loss: 0.9939 - val_acc: 0.5020\n",
            "Epoch 19/150 - 0.21s - loss: 0.9360 - acc: 0.5553 - val_loss: 0.9710 - val_acc: 0.5486\n",
            "Epoch 20/150 - 0.20s - loss: 0.9327 - acc: 0.5567 - val_loss: 0.9724 - val_acc: 0.5607\n",
            "Epoch 21/150 - 0.20s - loss: 0.9295 - acc: 0.5641 - val_loss: 0.9714 - val_acc: 0.5506\n",
            "Epoch 22/150 - 0.20s - loss: 0.9486 - acc: 0.5306 - val_loss: 0.9942 - val_acc: 0.5223\n",
            "Epoch 23/150 - 0.20s - loss: 0.9169 - acc: 0.5657 - val_loss: 0.9593 - val_acc: 0.5567\n",
            "Epoch 24/150 - 0.20s - loss: 0.9165 - acc: 0.5711 - val_loss: 0.9607 - val_acc: 0.5688\n",
            "Epoch 25/150 - 0.21s - loss: 0.9128 - acc: 0.5771 - val_loss: 0.9591 - val_acc: 0.5628\n",
            "Epoch 26/150 - 0.21s - loss: 0.9369 - acc: 0.5443 - val_loss: 0.9901 - val_acc: 0.5162\n",
            "Epoch 27/150 - 0.21s - loss: 0.9024 - acc: 0.5747 - val_loss: 0.9581 - val_acc: 0.5567\n",
            "Epoch 28/150 - 0.22s - loss: 0.9021 - acc: 0.5828 - val_loss: 0.9601 - val_acc: 0.5445\n",
            "Epoch 29/150 - 0.20s - loss: 0.9401 - acc: 0.5362 - val_loss: 0.9956 - val_acc: 0.4960\n",
            "Epoch 30/150 - 0.21s - loss: 0.8968 - acc: 0.5848 - val_loss: 0.9573 - val_acc: 0.5385\n",
            "Epoch 31/150 - 0.19s - loss: 0.8975 - acc: 0.5830 - val_loss: 0.9603 - val_acc: 0.5223\n",
            "Epoch 32/150 - 0.21s - loss: 0.9028 - acc: 0.5893 - val_loss: 0.9630 - val_acc: 0.5405\n",
            "Epoch 33/150 - 0.19s - loss: 0.9242 - acc: 0.5641 - val_loss: 0.9763 - val_acc: 0.5466\n",
            "Epoch 34/150 - 0.21s - loss: 0.8842 - acc: 0.5922 - val_loss: 0.9512 - val_acc: 0.5506\n",
            "Epoch 35/150 - 0.20s - loss: 0.9331 - acc: 0.5459 - val_loss: 0.9871 - val_acc: 0.5223\n",
            "Epoch 36/150 - 0.22s - loss: 0.8823 - acc: 0.5965 - val_loss: 0.9562 - val_acc: 0.5506\n",
            "Epoch 37/150 - 0.19s - loss: 0.8817 - acc: 0.5825 - val_loss: 0.9540 - val_acc: 0.5466\n",
            "Epoch 38/150 - 0.20s - loss: 0.9071 - acc: 0.5839 - val_loss: 0.9769 - val_acc: 0.5405\n",
            "Epoch 39/150 - 0.19s - loss: 0.8856 - acc: 0.5837 - val_loss: 0.9592 - val_acc: 0.5466\n",
            "Epoch 40/150 - 0.19s - loss: 0.8899 - acc: 0.5848 - val_loss: 0.9631 - val_acc: 0.5567\n",
            "Epoch 41/150 - 0.19s - loss: 0.8958 - acc: 0.5810 - val_loss: 0.9706 - val_acc: 0.5486\n",
            "Epoch 42/150 - 0.20s - loss: 0.8870 - acc: 0.5792 - val_loss: 0.9643 - val_acc: 0.5385\n",
            "Epoch 43/150 - 0.19s - loss: 0.8803 - acc: 0.5870 - val_loss: 0.9584 - val_acc: 0.5628\n",
            "Epoch 44/150 - 0.19s - loss: 0.8656 - acc: 0.6021 - val_loss: 0.9516 - val_acc: 0.5526\n",
            "Epoch 45/150 - 0.19s - loss: 0.8836 - acc: 0.5960 - val_loss: 0.9669 - val_acc: 0.5466\n",
            "Epoch 46/150 - 0.20s - loss: 0.8663 - acc: 0.5965 - val_loss: 0.9574 - val_acc: 0.5283\n",
            "Epoch 47/150 - 0.19s - loss: 0.8856 - acc: 0.5785 - val_loss: 0.9673 - val_acc: 0.5486\n",
            "Epoch 48/150 - 0.19s - loss: 0.8986 - acc: 0.5879 - val_loss: 0.9861 - val_acc: 0.5324\n",
            "Epoch 49/150 - 0.19s - loss: 0.8898 - acc: 0.5785 - val_loss: 0.9728 - val_acc: 0.5526\n",
            "Epoch 50/150 - 0.22s - loss: 0.8653 - acc: 0.5976 - val_loss: 0.9644 - val_acc: 0.5202\n",
            "Epoch 51/150 - 0.19s - loss: 0.8753 - acc: 0.5879 - val_loss: 0.9689 - val_acc: 0.5364\n",
            "Epoch 52/150 - 0.20s - loss: 0.8598 - acc: 0.6003 - val_loss: 0.9550 - val_acc: 0.5506\n",
            "Epoch 53/150 - 0.19s - loss: 0.8928 - acc: 0.5798 - val_loss: 1.0082 - val_acc: 0.5020\n",
            "Epoch 54/150 - 0.22s - loss: 0.8557 - acc: 0.6125 - val_loss: 0.9582 - val_acc: 0.5466\n",
            "Epoch 55/150 - 0.20s - loss: 0.8803 - acc: 0.5861 - val_loss: 0.9765 - val_acc: 0.5243\n",
            "Epoch 56/150 - 0.19s - loss: 0.8837 - acc: 0.5801 - val_loss: 0.9782 - val_acc: 0.5344\n",
            "Epoch 57/150 - 0.19s - loss: 0.8545 - acc: 0.6143 - val_loss: 0.9588 - val_acc: 0.5405\n",
            "Epoch 58/150 - 0.20s - loss: 0.8663 - acc: 0.6093 - val_loss: 0.9705 - val_acc: 0.5526\n",
            "Epoch 59/150 - 0.19s - loss: 0.9036 - acc: 0.5731 - val_loss: 0.9940 - val_acc: 0.5324\n",
            "Epoch 60/150 - 0.20s - loss: 0.8644 - acc: 0.6107 - val_loss: 0.9717 - val_acc: 0.5587\n",
            "Epoch 61/150 - 0.19s - loss: 0.8545 - acc: 0.6089 - val_loss: 0.9634 - val_acc: 0.5344\n",
            "Epoch 62/150 - 0.20s - loss: 0.8727 - acc: 0.5848 - val_loss: 0.9818 - val_acc: 0.5223\n",
            "Epoch 63/150 - 0.19s - loss: 0.8504 - acc: 0.6089 - val_loss: 0.9592 - val_acc: 0.5547\n",
            "Epoch 64/150 - 0.20s - loss: 0.8649 - acc: 0.6017 - val_loss: 0.9715 - val_acc: 0.5506\n",
            "Epoch 65/150 - 0.20s - loss: 0.8611 - acc: 0.6048 - val_loss: 0.9689 - val_acc: 0.5587\n",
            "Epoch 66/150 - 0.20s - loss: 0.8528 - acc: 0.6093 - val_loss: 0.9701 - val_acc: 0.5364\n",
            "Epoch 67/150 - 0.19s - loss: 0.8626 - acc: 0.6003 - val_loss: 0.9682 - val_acc: 0.5506\n",
            "Epoch 68/150 - 0.19s - loss: 0.8706 - acc: 0.5999 - val_loss: 0.9948 - val_acc: 0.5263\n",
            "Epoch 69/150 - 0.19s - loss: 0.8452 - acc: 0.6156 - val_loss: 0.9634 - val_acc: 0.5526\n",
            "Epoch 70/150 - 0.20s - loss: 0.8477 - acc: 0.6129 - val_loss: 0.9711 - val_acc: 0.5344\n",
            "Epoch 71/150 - 0.19s - loss: 0.8605 - acc: 0.6147 - val_loss: 0.9729 - val_acc: 0.5526\n",
            "Epoch 72/150 - 0.20s - loss: 0.8524 - acc: 0.6050 - val_loss: 0.9692 - val_acc: 0.5283\n",
            "Epoch 73/150 - 0.19s - loss: 0.8533 - acc: 0.6055 - val_loss: 0.9636 - val_acc: 0.5547\n",
            "Epoch 74/150 - 0.20s - loss: 0.8769 - acc: 0.5933 - val_loss: 1.0015 - val_acc: 0.5283\n",
            "Epoch 75/150 - 0.19s - loss: 0.9200 - acc: 0.5578 - val_loss: 1.0428 - val_acc: 0.4980\n",
            "Epoch 76/150 - 0.19s - loss: 0.8665 - acc: 0.5897 - val_loss: 0.9762 - val_acc: 0.5445\n",
            "Epoch 77/150 - 0.19s - loss: 0.8707 - acc: 0.5947 - val_loss: 1.0017 - val_acc: 0.5101\n",
            "Epoch 78/150 - 0.22s - loss: 0.8898 - acc: 0.5774 - val_loss: 1.0147 - val_acc: 0.5182\n",
            "Epoch 79/150 - 0.19s - loss: 0.9336 - acc: 0.5544 - val_loss: 1.0761 - val_acc: 0.4696\n",
            "Epoch 80/150 - 0.20s - loss: 0.8448 - acc: 0.6143 - val_loss: 0.9697 - val_acc: 0.5445\n",
            "Epoch 81/150 - 0.19s - loss: 0.8518 - acc: 0.6183 - val_loss: 0.9679 - val_acc: 0.5648\n",
            "Epoch 82/150 - 0.20s - loss: 0.8427 - acc: 0.6194 - val_loss: 0.9670 - val_acc: 0.5324\n",
            "Epoch 83/150 - 0.19s - loss: 0.8429 - acc: 0.6127 - val_loss: 0.9673 - val_acc: 0.5425\n",
            "Epoch 84/150 - 0.19s - loss: 0.8383 - acc: 0.6167 - val_loss: 0.9623 - val_acc: 0.5587\n",
            "Epoch 85/150 - 0.19s - loss: 0.8745 - acc: 0.5960 - val_loss: 1.0106 - val_acc: 0.5324\n",
            "Epoch 86/150 - 0.20s - loss: 0.8548 - acc: 0.6021 - val_loss: 0.9691 - val_acc: 0.5567\n",
            "Epoch 87/150 - 0.19s - loss: 0.8395 - acc: 0.6183 - val_loss: 0.9608 - val_acc: 0.5628\n",
            "Epoch 88/150 - 0.19s - loss: 0.8521 - acc: 0.6059 - val_loss: 0.9836 - val_acc: 0.5263\n",
            "Epoch 89/150 - 0.20s - loss: 0.8439 - acc: 0.6224 - val_loss: 0.9693 - val_acc: 0.5587\n",
            "Epoch 90/150 - 0.22s - loss: 0.8512 - acc: 0.6179 - val_loss: 0.9830 - val_acc: 0.5385\n",
            "Epoch 91/150 - 0.20s - loss: 0.8520 - acc: 0.6185 - val_loss: 0.9731 - val_acc: 0.5607\n",
            "Epoch 92/150 - 0.26s - loss: 0.8361 - acc: 0.6235 - val_loss: 0.9666 - val_acc: 0.5547\n",
            "Epoch 93/150 - 0.20s - loss: 0.8721 - acc: 0.5913 - val_loss: 1.0094 - val_acc: 0.5162\n",
            "Epoch 94/150 - 0.21s - loss: 0.8512 - acc: 0.6098 - val_loss: 0.9863 - val_acc: 0.5364\n",
            "Epoch 95/150 - 0.20s - loss: 0.9117 - acc: 0.5695 - val_loss: 1.0593 - val_acc: 0.4757\n",
            "Epoch 96/150 - 0.20s - loss: 0.8598 - acc: 0.6048 - val_loss: 0.9985 - val_acc: 0.5142\n",
            "Epoch 97/150 - 0.21s - loss: 0.8487 - acc: 0.6068 - val_loss: 0.9698 - val_acc: 0.5466\n",
            "Epoch 98/150 - 0.21s - loss: 0.8326 - acc: 0.6242 - val_loss: 0.9622 - val_acc: 0.5628\n",
            "Epoch 99/150 - 0.20s - loss: 0.8374 - acc: 0.6190 - val_loss: 0.9676 - val_acc: 0.5607\n",
            "Epoch 100/150 - 0.22s - loss: 0.8940 - acc: 0.5744 - val_loss: 1.0302 - val_acc: 0.5121\n",
            "Epoch 101/150 - 0.20s - loss: 0.8371 - acc: 0.6170 - val_loss: 0.9636 - val_acc: 0.5526\n",
            "Epoch 102/150 - 0.22s - loss: 0.8333 - acc: 0.6289 - val_loss: 0.9678 - val_acc: 0.5587\n",
            "Epoch 103/150 - 0.21s - loss: 0.8373 - acc: 0.6185 - val_loss: 0.9641 - val_acc: 0.5486\n",
            "Epoch 104/150 - 0.22s - loss: 0.8345 - acc: 0.6264 - val_loss: 0.9694 - val_acc: 0.5587\n",
            "Epoch 105/150 - 0.22s - loss: 0.8698 - acc: 0.5960 - val_loss: 1.0174 - val_acc: 0.5121\n",
            "Epoch 106/150 - 0.21s - loss: 0.8335 - acc: 0.6278 - val_loss: 0.9647 - val_acc: 0.5567\n",
            "Epoch 107/150 - 0.21s - loss: 0.8431 - acc: 0.6174 - val_loss: 0.9711 - val_acc: 0.5709\n",
            "Epoch 108/150 - 0.20s - loss: 0.8301 - acc: 0.6275 - val_loss: 0.9697 - val_acc: 0.5526\n",
            "Epoch 109/150 - 0.21s - loss: 0.8627 - acc: 0.5965 - val_loss: 0.9928 - val_acc: 0.5263\n",
            "Epoch 110/150 - 0.25s - loss: 0.8845 - acc: 0.5850 - val_loss: 1.0306 - val_acc: 0.5081\n",
            "Epoch 111/150 - 0.20s - loss: 0.8445 - acc: 0.6032 - val_loss: 0.9809 - val_acc: 0.5263\n",
            "Epoch 112/150 - 0.21s - loss: 0.8601 - acc: 0.6044 - val_loss: 1.0037 - val_acc: 0.5142\n",
            "Epoch 113/150 - 0.21s - loss: 0.8299 - acc: 0.6212 - val_loss: 0.9715 - val_acc: 0.5526\n",
            "Epoch 114/150 - 0.20s - loss: 0.8279 - acc: 0.6305 - val_loss: 0.9676 - val_acc: 0.5668\n",
            "Epoch 115/150 - 0.21s - loss: 0.8277 - acc: 0.6273 - val_loss: 0.9660 - val_acc: 0.5567\n",
            "Epoch 116/150 - 0.24s - loss: 0.8599 - acc: 0.6163 - val_loss: 0.9950 - val_acc: 0.5648\n",
            "Epoch 117/150 - 0.20s - loss: 0.8307 - acc: 0.6327 - val_loss: 0.9689 - val_acc: 0.5628\n",
            "Epoch 118/150 - 0.23s - loss: 0.8342 - acc: 0.6280 - val_loss: 0.9690 - val_acc: 0.5709\n",
            "Epoch 119/150 - 0.21s - loss: 0.8283 - acc: 0.6230 - val_loss: 0.9687 - val_acc: 0.5425\n",
            "Epoch 120/150 - 0.22s - loss: 0.8391 - acc: 0.6170 - val_loss: 0.9873 - val_acc: 0.5425\n",
            "Epoch 121/150 - 0.22s - loss: 0.8256 - acc: 0.6269 - val_loss: 0.9679 - val_acc: 0.5445\n",
            "Epoch 122/150 - 0.21s - loss: 0.8274 - acc: 0.6264 - val_loss: 0.9651 - val_acc: 0.5607\n",
            "Epoch 123/150 - 0.21s - loss: 0.8657 - acc: 0.6001 - val_loss: 1.0243 - val_acc: 0.5121\n",
            "Epoch 124/150 - 0.20s - loss: 0.8241 - acc: 0.6302 - val_loss: 0.9723 - val_acc: 0.5628\n",
            "Epoch 125/150 - 0.21s - loss: 0.8654 - acc: 0.5985 - val_loss: 1.0199 - val_acc: 0.5202\n",
            "Epoch 126/150 - 0.24s - loss: 0.8332 - acc: 0.6199 - val_loss: 0.9788 - val_acc: 0.5405\n",
            "Epoch 127/150 - 0.24s - loss: 0.8341 - acc: 0.6172 - val_loss: 0.9752 - val_acc: 0.5425\n",
            "Epoch 128/150 - 0.21s - loss: 0.8352 - acc: 0.6197 - val_loss: 0.9830 - val_acc: 0.5385\n",
            "Epoch 129/150 - 0.24s - loss: 0.8241 - acc: 0.6338 - val_loss: 0.9673 - val_acc: 0.5628\n",
            "Epoch 130/150 - 0.22s - loss: 0.8333 - acc: 0.6300 - val_loss: 0.9786 - val_acc: 0.5729\n",
            "Epoch 131/150 - 0.26s - loss: 0.8499 - acc: 0.6206 - val_loss: 0.9940 - val_acc: 0.5547\n",
            "Epoch 132/150 - 0.24s - loss: 0.8310 - acc: 0.6179 - val_loss: 0.9856 - val_acc: 0.5506\n",
            "Epoch 133/150 - 0.21s - loss: 0.8519 - acc: 0.6062 - val_loss: 0.9858 - val_acc: 0.5506\n",
            "Epoch 134/150 - 0.25s - loss: 0.8335 - acc: 0.6125 - val_loss: 0.9714 - val_acc: 0.5587\n",
            "Epoch 135/150 - 0.24s - loss: 0.8400 - acc: 0.6257 - val_loss: 0.9832 - val_acc: 0.5506\n",
            "Epoch 136/150 - 0.22s - loss: 0.8230 - acc: 0.6343 - val_loss: 0.9697 - val_acc: 0.5628\n",
            "Epoch 137/150 - 0.22s - loss: 0.8253 - acc: 0.6271 - val_loss: 0.9789 - val_acc: 0.5526\n",
            "Epoch 138/150 - 0.24s - loss: 0.8322 - acc: 0.6197 - val_loss: 0.9879 - val_acc: 0.5506\n",
            "Epoch 139/150 - 0.21s - loss: 0.8512 - acc: 0.6008 - val_loss: 0.9877 - val_acc: 0.5628\n",
            "Epoch 140/150 - 0.22s - loss: 0.8256 - acc: 0.6194 - val_loss: 0.9742 - val_acc: 0.5486\n",
            "Epoch 141/150 - 0.22s - loss: 0.8232 - acc: 0.6257 - val_loss: 0.9775 - val_acc: 0.5567\n",
            "Epoch 142/150 - 0.25s - loss: 0.8411 - acc: 0.6109 - val_loss: 0.9822 - val_acc: 0.5385\n",
            "Epoch 143/150 - 0.21s - loss: 0.8221 - acc: 0.6282 - val_loss: 0.9788 - val_acc: 0.5547\n",
            "Epoch 144/150 - 0.22s - loss: 0.8209 - acc: 0.6248 - val_loss: 0.9656 - val_acc: 0.5466\n",
            "Epoch 145/150 - 0.29s - loss: 0.8207 - acc: 0.6316 - val_loss: 0.9675 - val_acc: 0.5567\n",
            "Epoch 146/150 - 0.22s - loss: 0.8342 - acc: 0.6176 - val_loss: 0.9947 - val_acc: 0.5364\n",
            "Epoch 147/150 - 0.22s - loss: 0.8292 - acc: 0.6325 - val_loss: 0.9782 - val_acc: 0.5567\n",
            "Epoch 148/150 - 0.23s - loss: 0.8155 - acc: 0.6336 - val_loss: 0.9672 - val_acc: 0.5668\n",
            "Epoch 149/150 - 0.24s - loss: 0.9052 - acc: 0.5648 - val_loss: 1.0372 - val_acc: 0.5344\n",
            "Epoch 150/150 - 0.22s - loss: 0.8502 - acc: 0.5985 - val_loss: 1.0049 - val_acc: 0.5263\n",
            "\n",
            "Combination 202/252:\n",
            "Hidden Layers: [256, 128, 64], Activation: tanh, Learning Rate: 0.01, Batch Size: 64, Epochs: 50\n",
            "Epoch 1/50 - 0.18s - loss: 1.0844 - acc: 0.4026 - val_loss: 1.0871 - val_acc: 0.3988\n",
            "Epoch 2/50 - 0.19s - loss: 1.0756 - acc: 0.4267 - val_loss: 1.0820 - val_acc: 0.3907\n",
            "Epoch 3/50 - 0.18s - loss: 1.0680 - acc: 0.4420 - val_loss: 1.0749 - val_acc: 0.4231\n",
            "Epoch 4/50 - 0.18s - loss: 1.0624 - acc: 0.4429 - val_loss: 1.0730 - val_acc: 0.4069\n",
            "Epoch 5/50 - 0.18s - loss: 1.0559 - acc: 0.4516 - val_loss: 1.0679 - val_acc: 0.4372\n",
            "Epoch 6/50 - 0.19s - loss: 1.0513 - acc: 0.4507 - val_loss: 1.0634 - val_acc: 0.4433\n",
            "Epoch 7/50 - 0.18s - loss: 1.0460 - acc: 0.4566 - val_loss: 1.0597 - val_acc: 0.4615\n",
            "Epoch 8/50 - 0.20s - loss: 1.0408 - acc: 0.4750 - val_loss: 1.0562 - val_acc: 0.4757\n",
            "Epoch 9/50 - 0.18s - loss: 1.0359 - acc: 0.4728 - val_loss: 1.0528 - val_acc: 0.4858\n",
            "Epoch 10/50 - 0.21s - loss: 1.0320 - acc: 0.4753 - val_loss: 1.0497 - val_acc: 0.4919\n",
            "Epoch 11/50 - 0.18s - loss: 1.0267 - acc: 0.4845 - val_loss: 1.0464 - val_acc: 0.5000\n",
            "Epoch 12/50 - 0.18s - loss: 1.0237 - acc: 0.4964 - val_loss: 1.0451 - val_acc: 0.4575\n",
            "Epoch 13/50 - 0.18s - loss: 1.0178 - acc: 0.4996 - val_loss: 1.0407 - val_acc: 0.4838\n",
            "Epoch 14/50 - 0.19s - loss: 1.0136 - acc: 0.4973 - val_loss: 1.0382 - val_acc: 0.4919\n",
            "Epoch 15/50 - 0.17s - loss: 1.0092 - acc: 0.5094 - val_loss: 1.0351 - val_acc: 0.4879\n",
            "Epoch 16/50 - 0.18s - loss: 1.0052 - acc: 0.5103 - val_loss: 1.0306 - val_acc: 0.5040\n",
            "Epoch 17/50 - 0.18s - loss: 1.0034 - acc: 0.5106 - val_loss: 1.0323 - val_acc: 0.4939\n",
            "Epoch 18/50 - 0.19s - loss: 0.9984 - acc: 0.5184 - val_loss: 1.0270 - val_acc: 0.4858\n",
            "Epoch 19/50 - 0.20s - loss: 0.9921 - acc: 0.5207 - val_loss: 1.0208 - val_acc: 0.5162\n",
            "Epoch 20/50 - 0.19s - loss: 0.9880 - acc: 0.5236 - val_loss: 1.0185 - val_acc: 0.5121\n",
            "Epoch 21/50 - 0.16s - loss: 0.9846 - acc: 0.5270 - val_loss: 1.0147 - val_acc: 0.5142\n",
            "Epoch 22/50 - 0.17s - loss: 0.9810 - acc: 0.5263 - val_loss: 1.0116 - val_acc: 0.5182\n",
            "Epoch 23/50 - 0.16s - loss: 0.9790 - acc: 0.5263 - val_loss: 1.0126 - val_acc: 0.5020\n",
            "Epoch 24/50 - 0.16s - loss: 0.9728 - acc: 0.5351 - val_loss: 1.0055 - val_acc: 0.5162\n",
            "Epoch 25/50 - 0.17s - loss: 0.9710 - acc: 0.5326 - val_loss: 1.0052 - val_acc: 0.5223\n",
            "Epoch 26/50 - 0.17s - loss: 0.9670 - acc: 0.5322 - val_loss: 1.0002 - val_acc: 0.5243\n",
            "Epoch 27/50 - 0.16s - loss: 0.9628 - acc: 0.5427 - val_loss: 0.9960 - val_acc: 0.5283\n",
            "Epoch 28/50 - 0.17s - loss: 0.9629 - acc: 0.5378 - val_loss: 0.9994 - val_acc: 0.5202\n",
            "Epoch 29/50 - 0.16s - loss: 0.9612 - acc: 0.5385 - val_loss: 1.0003 - val_acc: 0.5081\n",
            "Epoch 30/50 - 0.17s - loss: 0.9529 - acc: 0.5466 - val_loss: 0.9896 - val_acc: 0.5243\n",
            "Epoch 31/50 - 0.17s - loss: 0.9512 - acc: 0.5450 - val_loss: 0.9905 - val_acc: 0.5202\n",
            "Epoch 32/50 - 0.16s - loss: 0.9524 - acc: 0.5443 - val_loss: 0.9895 - val_acc: 0.5405\n",
            "Epoch 33/50 - 0.16s - loss: 0.9443 - acc: 0.5502 - val_loss: 0.9835 - val_acc: 0.5283\n",
            "Epoch 34/50 - 0.18s - loss: 0.9416 - acc: 0.5515 - val_loss: 0.9805 - val_acc: 0.5304\n",
            "Epoch 35/50 - 0.17s - loss: 0.9433 - acc: 0.5517 - val_loss: 0.9831 - val_acc: 0.5364\n",
            "Epoch 36/50 - 0.16s - loss: 0.9397 - acc: 0.5531 - val_loss: 0.9801 - val_acc: 0.5324\n",
            "Epoch 37/50 - 0.16s - loss: 0.9375 - acc: 0.5558 - val_loss: 0.9762 - val_acc: 0.5466\n",
            "Epoch 38/50 - 0.17s - loss: 0.9306 - acc: 0.5610 - val_loss: 0.9713 - val_acc: 0.5405\n",
            "Epoch 39/50 - 0.19s - loss: 0.9319 - acc: 0.5578 - val_loss: 0.9710 - val_acc: 0.5283\n",
            "Epoch 40/50 - 0.16s - loss: 0.9406 - acc: 0.5551 - val_loss: 0.9805 - val_acc: 0.5364\n",
            "Epoch 41/50 - 0.16s - loss: 0.9281 - acc: 0.5632 - val_loss: 0.9681 - val_acc: 0.5486\n",
            "Epoch 42/50 - 0.18s - loss: 0.9241 - acc: 0.5641 - val_loss: 0.9675 - val_acc: 0.5405\n",
            "Epoch 43/50 - 0.16s - loss: 0.9196 - acc: 0.5655 - val_loss: 0.9643 - val_acc: 0.5385\n",
            "Epoch 44/50 - 0.16s - loss: 0.9255 - acc: 0.5612 - val_loss: 0.9724 - val_acc: 0.5385\n",
            "Epoch 45/50 - 0.16s - loss: 0.9170 - acc: 0.5679 - val_loss: 0.9633 - val_acc: 0.5364\n",
            "Epoch 46/50 - 0.18s - loss: 0.9182 - acc: 0.5655 - val_loss: 0.9640 - val_acc: 0.5486\n",
            "Epoch 47/50 - 0.16s - loss: 0.9145 - acc: 0.5704 - val_loss: 0.9593 - val_acc: 0.5324\n",
            "Epoch 48/50 - 0.17s - loss: 0.9107 - acc: 0.5724 - val_loss: 0.9598 - val_acc: 0.5364\n",
            "Epoch 49/50 - 0.16s - loss: 0.9191 - acc: 0.5688 - val_loss: 0.9679 - val_acc: 0.5385\n",
            "Epoch 50/50 - 0.17s - loss: 0.9227 - acc: 0.5679 - val_loss: 0.9744 - val_acc: 0.5344\n",
            "\n",
            "Combination 203/252:\n",
            "Hidden Layers: [256, 128, 64], Activation: tanh, Learning Rate: 0.01, Batch Size: 64, Epochs: 100\n",
            "Epoch 1/100 - 0.16s - loss: 1.0892 - acc: 0.3785 - val_loss: 1.1013 - val_acc: 0.3421\n",
            "Epoch 2/100 - 0.17s - loss: 1.0759 - acc: 0.4217 - val_loss: 1.0895 - val_acc: 0.3522\n",
            "Epoch 3/100 - 0.17s - loss: 1.0661 - acc: 0.4478 - val_loss: 1.0821 - val_acc: 0.4109\n",
            "Epoch 4/100 - 0.17s - loss: 1.0592 - acc: 0.4525 - val_loss: 1.0768 - val_acc: 0.4453\n",
            "Epoch 5/100 - 0.16s - loss: 1.0518 - acc: 0.4672 - val_loss: 1.0722 - val_acc: 0.4251\n",
            "Epoch 6/100 - 0.16s - loss: 1.0454 - acc: 0.4730 - val_loss: 1.0672 - val_acc: 0.4474\n",
            "Epoch 7/100 - 0.16s - loss: 1.0411 - acc: 0.4699 - val_loss: 1.0650 - val_acc: 0.4494\n",
            "Epoch 8/100 - 0.19s - loss: 1.0350 - acc: 0.4750 - val_loss: 1.0598 - val_acc: 0.4453\n",
            "Epoch 9/100 - 0.16s - loss: 1.0290 - acc: 0.4836 - val_loss: 1.0548 - val_acc: 0.4636\n",
            "Epoch 10/100 - 0.16s - loss: 1.0242 - acc: 0.4856 - val_loss: 1.0514 - val_acc: 0.4818\n",
            "Epoch 11/100 - 0.16s - loss: 1.0203 - acc: 0.4978 - val_loss: 1.0492 - val_acc: 0.4676\n",
            "Epoch 12/100 - 0.17s - loss: 1.0160 - acc: 0.4964 - val_loss: 1.0467 - val_acc: 0.4939\n",
            "Epoch 13/100 - 0.16s - loss: 1.0101 - acc: 0.5052 - val_loss: 1.0401 - val_acc: 0.4838\n",
            "Epoch 14/100 - 0.17s - loss: 1.0046 - acc: 0.5110 - val_loss: 1.0356 - val_acc: 0.4879\n",
            "Epoch 15/100 - 0.17s - loss: 1.0067 - acc: 0.5000 - val_loss: 1.0411 - val_acc: 0.4757\n",
            "Epoch 16/100 - 0.21s - loss: 0.9955 - acc: 0.5157 - val_loss: 1.0282 - val_acc: 0.5000\n",
            "Epoch 17/100 - 0.17s - loss: 0.9918 - acc: 0.5223 - val_loss: 1.0250 - val_acc: 0.5121\n",
            "Epoch 18/100 - 0.17s - loss: 0.9889 - acc: 0.5209 - val_loss: 1.0244 - val_acc: 0.5162\n",
            "Epoch 19/100 - 0.16s - loss: 0.9941 - acc: 0.5029 - val_loss: 1.0300 - val_acc: 0.4737\n",
            "Epoch 20/100 - 0.18s - loss: 0.9780 - acc: 0.5326 - val_loss: 1.0128 - val_acc: 0.5162\n",
            "Epoch 21/100 - 0.17s - loss: 0.9740 - acc: 0.5331 - val_loss: 1.0087 - val_acc: 0.5182\n",
            "Epoch 22/100 - 0.16s - loss: 0.9710 - acc: 0.5360 - val_loss: 1.0055 - val_acc: 0.5142\n",
            "Epoch 23/100 - 0.16s - loss: 0.9665 - acc: 0.5376 - val_loss: 1.0031 - val_acc: 0.5162\n",
            "Epoch 24/100 - 0.18s - loss: 0.9628 - acc: 0.5403 - val_loss: 0.9988 - val_acc: 0.5344\n",
            "Epoch 25/100 - 0.16s - loss: 0.9776 - acc: 0.5286 - val_loss: 1.0124 - val_acc: 0.5263\n",
            "Epoch 26/100 - 0.17s - loss: 0.9554 - acc: 0.5427 - val_loss: 0.9929 - val_acc: 0.5243\n",
            "Epoch 27/100 - 0.17s - loss: 0.9519 - acc: 0.5457 - val_loss: 0.9896 - val_acc: 0.5283\n",
            "Epoch 28/100 - 0.19s - loss: 0.9488 - acc: 0.5515 - val_loss: 0.9894 - val_acc: 0.5243\n",
            "Epoch 29/100 - 0.17s - loss: 0.9457 - acc: 0.5511 - val_loss: 0.9856 - val_acc: 0.5344\n",
            "Epoch 30/100 - 0.16s - loss: 0.9436 - acc: 0.5535 - val_loss: 0.9859 - val_acc: 0.5283\n",
            "Epoch 31/100 - 0.20s - loss: 0.9489 - acc: 0.5414 - val_loss: 0.9914 - val_acc: 0.5263\n",
            "Epoch 32/100 - 0.17s - loss: 0.9373 - acc: 0.5556 - val_loss: 0.9806 - val_acc: 0.5344\n",
            "Epoch 33/100 - 0.16s - loss: 0.9344 - acc: 0.5632 - val_loss: 0.9784 - val_acc: 0.5526\n",
            "Epoch 34/100 - 0.16s - loss: 0.9335 - acc: 0.5616 - val_loss: 0.9776 - val_acc: 0.5547\n",
            "Epoch 35/100 - 0.16s - loss: 0.9311 - acc: 0.5621 - val_loss: 0.9772 - val_acc: 0.5445\n",
            "Epoch 36/100 - 0.17s - loss: 0.9300 - acc: 0.5583 - val_loss: 0.9720 - val_acc: 0.5486\n",
            "Epoch 37/100 - 0.17s - loss: 0.9254 - acc: 0.5648 - val_loss: 0.9715 - val_acc: 0.5466\n",
            "Epoch 38/100 - 0.19s - loss: 0.9433 - acc: 0.5569 - val_loss: 0.9853 - val_acc: 0.5587\n",
            "Epoch 39/100 - 0.17s - loss: 0.9455 - acc: 0.5396 - val_loss: 0.9947 - val_acc: 0.5081\n",
            "Epoch 40/100 - 0.17s - loss: 0.9283 - acc: 0.5664 - val_loss: 0.9771 - val_acc: 0.5466\n",
            "Epoch 41/100 - 0.16s - loss: 0.9232 - acc: 0.5682 - val_loss: 0.9739 - val_acc: 0.5547\n",
            "Epoch 42/100 - 0.16s - loss: 0.9185 - acc: 0.5711 - val_loss: 0.9675 - val_acc: 0.5466\n",
            "Epoch 43/100 - 0.16s - loss: 0.9142 - acc: 0.5700 - val_loss: 0.9647 - val_acc: 0.5506\n",
            "Epoch 44/100 - 0.19s - loss: 0.9236 - acc: 0.5580 - val_loss: 0.9788 - val_acc: 0.5385\n",
            "Epoch 45/100 - 0.16s - loss: 0.9208 - acc: 0.5560 - val_loss: 0.9724 - val_acc: 0.5385\n",
            "Epoch 46/100 - 0.16s - loss: 0.9098 - acc: 0.5792 - val_loss: 0.9642 - val_acc: 0.5567\n",
            "Epoch 47/100 - 0.19s - loss: 0.9071 - acc: 0.5711 - val_loss: 0.9628 - val_acc: 0.5506\n",
            "Epoch 48/100 - 0.19s - loss: 0.9151 - acc: 0.5603 - val_loss: 0.9677 - val_acc: 0.5324\n",
            "Epoch 49/100 - 0.17s - loss: 0.9089 - acc: 0.5792 - val_loss: 0.9639 - val_acc: 0.5526\n",
            "Epoch 50/100 - 0.17s - loss: 0.9012 - acc: 0.5805 - val_loss: 0.9582 - val_acc: 0.5547\n",
            "Epoch 51/100 - 0.16s - loss: 0.9191 - acc: 0.5812 - val_loss: 0.9754 - val_acc: 0.5547\n",
            "Epoch 52/100 - 0.17s - loss: 0.9071 - acc: 0.5717 - val_loss: 0.9711 - val_acc: 0.5364\n",
            "Epoch 53/100 - 0.16s - loss: 0.9054 - acc: 0.5884 - val_loss: 0.9657 - val_acc: 0.5648\n",
            "Epoch 54/100 - 0.17s - loss: 0.9321 - acc: 0.5744 - val_loss: 0.9896 - val_acc: 0.5486\n",
            "Epoch 55/100 - 0.16s - loss: 0.8992 - acc: 0.5825 - val_loss: 0.9603 - val_acc: 0.5769\n",
            "Epoch 56/100 - 0.21s - loss: 0.9071 - acc: 0.5756 - val_loss: 0.9655 - val_acc: 0.5547\n",
            "Epoch 57/100 - 0.16s - loss: 0.8937 - acc: 0.5841 - val_loss: 0.9581 - val_acc: 0.5668\n",
            "Epoch 58/100 - 0.20s - loss: 0.9704 - acc: 0.5193 - val_loss: 1.0234 - val_acc: 0.5040\n",
            "Epoch 59/100 - 0.16s - loss: 0.9015 - acc: 0.5805 - val_loss: 0.9689 - val_acc: 0.5283\n",
            "Epoch 60/100 - 0.17s - loss: 0.8881 - acc: 0.5843 - val_loss: 0.9585 - val_acc: 0.5547\n",
            "Epoch 61/100 - 0.16s - loss: 0.8948 - acc: 0.5787 - val_loss: 0.9681 - val_acc: 0.5324\n",
            "Epoch 62/100 - 0.16s - loss: 0.8981 - acc: 0.5861 - val_loss: 0.9674 - val_acc: 0.5364\n",
            "Epoch 63/100 - 0.16s - loss: 0.9104 - acc: 0.5684 - val_loss: 0.9871 - val_acc: 0.5020\n",
            "Epoch 64/100 - 0.19s - loss: 1.0091 - acc: 0.5349 - val_loss: 1.0699 - val_acc: 0.5283\n",
            "Epoch 65/100 - 0.16s - loss: 0.8824 - acc: 0.5837 - val_loss: 0.9541 - val_acc: 0.5506\n",
            "Epoch 66/100 - 0.16s - loss: 0.9344 - acc: 0.5607 - val_loss: 0.9978 - val_acc: 0.5425\n",
            "Epoch 67/100 - 0.16s - loss: 0.8914 - acc: 0.5909 - val_loss: 0.9684 - val_acc: 0.5304\n",
            "Epoch 68/100 - 0.17s - loss: 0.9000 - acc: 0.5735 - val_loss: 0.9835 - val_acc: 0.5162\n",
            "Epoch 69/100 - 0.17s - loss: 0.8834 - acc: 0.5931 - val_loss: 0.9586 - val_acc: 0.5668\n",
            "Epoch 70/100 - 0.16s - loss: 0.8970 - acc: 0.5807 - val_loss: 0.9695 - val_acc: 0.5466\n",
            "Epoch 71/100 - 0.16s - loss: 0.8827 - acc: 0.5972 - val_loss: 0.9665 - val_acc: 0.5344\n",
            "Epoch 72/100 - 0.21s - loss: 0.8886 - acc: 0.5821 - val_loss: 0.9762 - val_acc: 0.5142\n",
            "Epoch 73/100 - 0.16s - loss: 0.8722 - acc: 0.5965 - val_loss: 0.9535 - val_acc: 0.5547\n",
            "Epoch 74/100 - 0.16s - loss: 0.8874 - acc: 0.5839 - val_loss: 0.9756 - val_acc: 0.5162\n",
            "Epoch 75/100 - 0.16s - loss: 0.8757 - acc: 0.6001 - val_loss: 0.9633 - val_acc: 0.5405\n",
            "Epoch 76/100 - 0.17s - loss: 0.8697 - acc: 0.5958 - val_loss: 0.9585 - val_acc: 0.5364\n",
            "Epoch 77/100 - 0.16s - loss: 0.8785 - acc: 0.5927 - val_loss: 0.9620 - val_acc: 0.5587\n",
            "Epoch 78/100 - 0.17s - loss: 0.8821 - acc: 0.5837 - val_loss: 0.9713 - val_acc: 0.5283\n",
            "Epoch 79/100 - 0.17s - loss: 0.8767 - acc: 0.5936 - val_loss: 0.9624 - val_acc: 0.5547\n",
            "Epoch 80/100 - 0.17s - loss: 0.8761 - acc: 0.5870 - val_loss: 0.9614 - val_acc: 0.5364\n",
            "Epoch 81/100 - 0.16s - loss: 0.8697 - acc: 0.6059 - val_loss: 0.9635 - val_acc: 0.5324\n",
            "Epoch 82/100 - 0.17s - loss: 0.8730 - acc: 0.5960 - val_loss: 0.9710 - val_acc: 0.5385\n",
            "Epoch 83/100 - 0.16s - loss: 0.8957 - acc: 0.5771 - val_loss: 0.9983 - val_acc: 0.5000\n",
            "Epoch 84/100 - 0.17s - loss: 0.8641 - acc: 0.5947 - val_loss: 0.9571 - val_acc: 0.5628\n",
            "Epoch 85/100 - 0.16s - loss: 0.9024 - acc: 0.5938 - val_loss: 0.9935 - val_acc: 0.5466\n",
            "Epoch 86/100 - 0.16s - loss: 0.8712 - acc: 0.5983 - val_loss: 0.9629 - val_acc: 0.5486\n",
            "Epoch 87/100 - 0.19s - loss: 0.8951 - acc: 0.5713 - val_loss: 0.9991 - val_acc: 0.5000\n",
            "Epoch 88/100 - 0.17s - loss: 0.8664 - acc: 0.6010 - val_loss: 0.9679 - val_acc: 0.5283\n",
            "Epoch 89/100 - 0.16s - loss: 0.9190 - acc: 0.5612 - val_loss: 1.0311 - val_acc: 0.4858\n",
            "Epoch 90/100 - 0.16s - loss: 0.8853 - acc: 0.5751 - val_loss: 0.9748 - val_acc: 0.5385\n",
            "Epoch 91/100 - 0.16s - loss: 0.8671 - acc: 0.5951 - val_loss: 0.9701 - val_acc: 0.5263\n",
            "Epoch 92/100 - 0.17s - loss: 0.8567 - acc: 0.6102 - val_loss: 0.9608 - val_acc: 0.5486\n",
            "Epoch 93/100 - 0.17s - loss: 0.8881 - acc: 0.5760 - val_loss: 0.9811 - val_acc: 0.5364\n",
            "Epoch 94/100 - 0.16s - loss: 0.8809 - acc: 0.5920 - val_loss: 0.9769 - val_acc: 0.5486\n",
            "Epoch 95/100 - 0.16s - loss: 0.8755 - acc: 0.5877 - val_loss: 0.9783 - val_acc: 0.5202\n",
            "Epoch 96/100 - 0.17s - loss: 0.8665 - acc: 0.5938 - val_loss: 0.9675 - val_acc: 0.5445\n",
            "Epoch 97/100 - 0.16s - loss: 0.8583 - acc: 0.6041 - val_loss: 0.9684 - val_acc: 0.5324\n",
            "Epoch 98/100 - 0.17s - loss: 0.9444 - acc: 0.5430 - val_loss: 1.0583 - val_acc: 0.4838\n",
            "Epoch 99/100 - 0.16s - loss: 0.9478 - acc: 0.5355 - val_loss: 1.0559 - val_acc: 0.4777\n",
            "Epoch 100/100 - 0.22s - loss: 0.9464 - acc: 0.5461 - val_loss: 1.0666 - val_acc: 0.4636\n",
            "\n",
            "Combination 204/252:\n",
            "Hidden Layers: [256, 128, 64], Activation: tanh, Learning Rate: 0.01, Batch Size: 64, Epochs: 150\n",
            "Epoch 1/150 - 0.17s - loss: 1.0869 - acc: 0.3907 - val_loss: 1.0963 - val_acc: 0.3623\n",
            "Epoch 2/150 - 0.17s - loss: 1.0734 - acc: 0.4114 - val_loss: 1.0843 - val_acc: 0.3806\n",
            "Epoch 3/150 - 0.16s - loss: 1.0643 - acc: 0.4379 - val_loss: 1.0776 - val_acc: 0.3806\n",
            "Epoch 4/150 - 0.18s - loss: 1.0544 - acc: 0.4683 - val_loss: 1.0685 - val_acc: 0.4291\n",
            "Epoch 5/150 - 0.16s - loss: 1.0468 - acc: 0.4793 - val_loss: 1.0630 - val_acc: 0.4332\n",
            "Epoch 6/150 - 0.17s - loss: 1.0407 - acc: 0.4863 - val_loss: 1.0587 - val_acc: 0.4413\n",
            "Epoch 7/150 - 0.21s - loss: 1.0335 - acc: 0.4966 - val_loss: 1.0542 - val_acc: 0.4514\n",
            "Epoch 8/150 - 0.17s - loss: 1.0277 - acc: 0.4948 - val_loss: 1.0495 - val_acc: 0.4636\n",
            "Epoch 9/150 - 0.17s - loss: 1.0241 - acc: 0.4825 - val_loss: 1.0465 - val_acc: 0.4838\n",
            "Epoch 10/150 - 0.17s - loss: 1.0205 - acc: 0.4834 - val_loss: 1.0441 - val_acc: 0.4919\n",
            "Epoch 11/150 - 0.17s - loss: 1.0143 - acc: 0.5045 - val_loss: 1.0437 - val_acc: 0.4494\n",
            "Epoch 12/150 - 0.17s - loss: 1.0057 - acc: 0.5081 - val_loss: 1.0344 - val_acc: 0.5061\n",
            "Epoch 13/150 - 0.17s - loss: 1.0013 - acc: 0.5115 - val_loss: 1.0313 - val_acc: 0.5162\n",
            "Epoch 14/150 - 0.18s - loss: 1.0000 - acc: 0.5166 - val_loss: 1.0335 - val_acc: 0.4939\n",
            "Epoch 15/150 - 0.18s - loss: 0.9935 - acc: 0.5184 - val_loss: 1.0267 - val_acc: 0.4818\n",
            "Epoch 16/150 - 0.17s - loss: 0.9907 - acc: 0.5151 - val_loss: 1.0261 - val_acc: 0.4879\n",
            "Epoch 17/150 - 0.18s - loss: 0.9818 - acc: 0.5308 - val_loss: 1.0170 - val_acc: 0.5081\n",
            "Epoch 18/150 - 0.16s - loss: 0.9776 - acc: 0.5373 - val_loss: 1.0122 - val_acc: 0.5081\n",
            "Epoch 19/150 - 0.17s - loss: 0.9786 - acc: 0.5270 - val_loss: 1.0125 - val_acc: 0.5385\n",
            "Epoch 20/150 - 0.17s - loss: 0.9874 - acc: 0.5065 - val_loss: 1.0281 - val_acc: 0.4656\n",
            "Epoch 21/150 - 0.17s - loss: 0.9654 - acc: 0.5434 - val_loss: 1.0043 - val_acc: 0.5223\n",
            "Epoch 22/150 - 0.17s - loss: 0.9631 - acc: 0.5427 - val_loss: 1.0006 - val_acc: 0.5445\n",
            "Epoch 23/150 - 0.18s - loss: 0.9579 - acc: 0.5434 - val_loss: 0.9969 - val_acc: 0.5202\n",
            "Epoch 24/150 - 0.16s - loss: 0.9641 - acc: 0.5403 - val_loss: 1.0014 - val_acc: 0.5344\n",
            "Epoch 25/150 - 0.16s - loss: 0.9542 - acc: 0.5405 - val_loss: 0.9979 - val_acc: 0.5243\n",
            "Epoch 26/150 - 0.16s - loss: 0.9498 - acc: 0.5513 - val_loss: 0.9907 - val_acc: 0.5344\n",
            "Epoch 27/150 - 0.20s - loss: 0.9448 - acc: 0.5544 - val_loss: 0.9883 - val_acc: 0.5304\n",
            "Epoch 28/150 - 0.16s - loss: 0.9433 - acc: 0.5533 - val_loss: 0.9860 - val_acc: 0.5425\n",
            "Epoch 29/150 - 0.16s - loss: 0.9798 - acc: 0.5092 - val_loss: 1.0289 - val_acc: 0.4636\n",
            "Epoch 30/150 - 0.16s - loss: 0.9437 - acc: 0.5571 - val_loss: 0.9887 - val_acc: 0.5405\n",
            "Epoch 31/150 - 0.18s - loss: 0.9337 - acc: 0.5598 - val_loss: 0.9805 - val_acc: 0.5425\n",
            "Epoch 32/150 - 0.16s - loss: 0.9325 - acc: 0.5628 - val_loss: 0.9804 - val_acc: 0.5405\n",
            "Epoch 33/150 - 0.17s - loss: 0.9317 - acc: 0.5630 - val_loss: 0.9819 - val_acc: 0.5466\n",
            "Epoch 34/150 - 0.16s - loss: 0.9302 - acc: 0.5569 - val_loss: 0.9808 - val_acc: 0.5263\n",
            "Epoch 35/150 - 0.17s - loss: 0.9257 - acc: 0.5691 - val_loss: 0.9744 - val_acc: 0.5547\n",
            "Epoch 36/150 - 0.17s - loss: 0.9393 - acc: 0.5466 - val_loss: 0.9927 - val_acc: 0.4980\n",
            "Epoch 37/150 - 0.19s - loss: 0.9439 - acc: 0.5436 - val_loss: 0.9972 - val_acc: 0.4879\n",
            "Epoch 38/150 - 0.16s - loss: 0.9237 - acc: 0.5630 - val_loss: 0.9812 - val_acc: 0.5020\n",
            "Epoch 39/150 - 0.17s - loss: 0.9272 - acc: 0.5567 - val_loss: 0.9821 - val_acc: 0.5081\n",
            "Epoch 40/150 - 0.16s - loss: 0.9129 - acc: 0.5744 - val_loss: 0.9704 - val_acc: 0.5405\n",
            "Epoch 41/150 - 0.19s - loss: 0.9272 - acc: 0.5589 - val_loss: 0.9861 - val_acc: 0.5223\n",
            "Epoch 42/150 - 0.16s - loss: 0.9367 - acc: 0.5571 - val_loss: 0.9859 - val_acc: 0.5425\n",
            "Epoch 43/150 - 0.17s - loss: 0.9089 - acc: 0.5760 - val_loss: 0.9710 - val_acc: 0.5243\n",
            "Epoch 44/150 - 0.16s - loss: 0.9048 - acc: 0.5798 - val_loss: 0.9637 - val_acc: 0.5506\n",
            "Epoch 45/150 - 0.16s - loss: 0.9173 - acc: 0.5648 - val_loss: 0.9815 - val_acc: 0.4960\n",
            "Epoch 46/150 - 0.17s - loss: 0.9079 - acc: 0.5753 - val_loss: 0.9735 - val_acc: 0.5223\n",
            "Epoch 47/150 - 0.19s - loss: 0.9118 - acc: 0.5767 - val_loss: 0.9734 - val_acc: 0.5405\n",
            "Epoch 48/150 - 0.16s - loss: 0.9513 - acc: 0.5468 - val_loss: 1.0042 - val_acc: 0.5364\n",
            "Epoch 49/150 - 0.16s - loss: 0.8989 - acc: 0.5900 - val_loss: 0.9623 - val_acc: 0.5506\n",
            "Epoch 50/150 - 0.16s - loss: 0.8952 - acc: 0.5857 - val_loss: 0.9655 - val_acc: 0.5425\n",
            "Epoch 51/150 - 0.18s - loss: 0.8983 - acc: 0.5857 - val_loss: 0.9643 - val_acc: 0.5526\n",
            "Epoch 52/150 - 0.16s - loss: 0.8911 - acc: 0.5909 - val_loss: 0.9612 - val_acc: 0.5466\n",
            "Epoch 53/150 - 0.16s - loss: 0.9166 - acc: 0.5650 - val_loss: 0.9950 - val_acc: 0.4858\n",
            "Epoch 54/150 - 0.16s - loss: 0.9179 - acc: 0.5760 - val_loss: 0.9854 - val_acc: 0.5628\n",
            "Epoch 55/150 - 0.22s - loss: 0.9195 - acc: 0.5632 - val_loss: 0.9996 - val_acc: 0.4818\n",
            "Epoch 56/150 - 0.16s - loss: 0.9339 - acc: 0.5513 - val_loss: 1.0053 - val_acc: 0.5223\n",
            "Epoch 57/150 - 0.18s - loss: 0.8945 - acc: 0.5789 - val_loss: 0.9642 - val_acc: 0.5405\n",
            "Epoch 58/150 - 0.18s - loss: 0.8872 - acc: 0.5893 - val_loss: 0.9625 - val_acc: 0.5405\n",
            "Epoch 59/150 - 0.18s - loss: 0.8895 - acc: 0.5823 - val_loss: 0.9711 - val_acc: 0.5061\n",
            "Epoch 60/150 - 0.16s - loss: 0.8925 - acc: 0.5877 - val_loss: 0.9730 - val_acc: 0.5425\n",
            "Epoch 61/150 - 0.16s - loss: 0.9607 - acc: 0.5385 - val_loss: 1.0258 - val_acc: 0.5142\n",
            "Epoch 62/150 - 0.16s - loss: 0.8924 - acc: 0.5792 - val_loss: 0.9786 - val_acc: 0.5162\n",
            "Epoch 63/150 - 0.18s - loss: 0.9249 - acc: 0.5540 - val_loss: 1.0162 - val_acc: 0.4960\n",
            "Epoch 64/150 - 0.16s - loss: 0.8855 - acc: 0.5859 - val_loss: 0.9650 - val_acc: 0.5526\n",
            "Epoch 65/150 - 0.16s - loss: 0.8993 - acc: 0.5852 - val_loss: 0.9857 - val_acc: 0.5466\n",
            "Epoch 66/150 - 0.16s - loss: 0.9234 - acc: 0.5538 - val_loss: 0.9969 - val_acc: 0.5283\n",
            "Epoch 67/150 - 0.17s - loss: 0.8928 - acc: 0.5852 - val_loss: 0.9820 - val_acc: 0.5364\n",
            "Epoch 68/150 - 0.16s - loss: 0.8801 - acc: 0.5904 - val_loss: 0.9715 - val_acc: 0.5061\n",
            "Epoch 69/150 - 0.16s - loss: 0.9092 - acc: 0.5691 - val_loss: 0.9951 - val_acc: 0.5223\n",
            "Epoch 70/150 - 0.17s - loss: 0.8775 - acc: 0.5857 - val_loss: 0.9686 - val_acc: 0.5202\n",
            "Epoch 71/150 - 0.17s - loss: 0.8846 - acc: 0.5938 - val_loss: 0.9805 - val_acc: 0.5405\n",
            "Epoch 72/150 - 0.16s - loss: 0.8928 - acc: 0.5870 - val_loss: 0.9849 - val_acc: 0.5506\n",
            "Epoch 73/150 - 0.17s - loss: 0.8875 - acc: 0.5855 - val_loss: 0.9718 - val_acc: 0.5425\n",
            "Epoch 74/150 - 0.16s - loss: 0.8706 - acc: 0.6001 - val_loss: 0.9677 - val_acc: 0.5405\n",
            "Epoch 75/150 - 0.17s - loss: 0.8761 - acc: 0.6003 - val_loss: 0.9733 - val_acc: 0.5526\n",
            "Epoch 76/150 - 0.16s - loss: 0.8640 - acc: 0.6064 - val_loss: 0.9631 - val_acc: 0.5324\n",
            "Epoch 77/150 - 0.17s - loss: 0.8812 - acc: 0.5920 - val_loss: 0.9736 - val_acc: 0.5547\n",
            "Epoch 78/150 - 0.16s - loss: 0.9029 - acc: 0.5634 - val_loss: 0.9924 - val_acc: 0.5243\n",
            "Epoch 79/150 - 0.17s - loss: 0.8808 - acc: 0.5848 - val_loss: 0.9721 - val_acc: 0.5445\n",
            "Epoch 80/150 - 0.16s - loss: 0.8624 - acc: 0.6068 - val_loss: 0.9645 - val_acc: 0.5364\n",
            "Epoch 81/150 - 0.16s - loss: 0.8663 - acc: 0.6014 - val_loss: 0.9672 - val_acc: 0.5364\n",
            "Epoch 82/150 - 0.16s - loss: 0.8745 - acc: 0.5954 - val_loss: 0.9848 - val_acc: 0.5142\n",
            "Epoch 83/150 - 0.17s - loss: 1.0314 - acc: 0.4903 - val_loss: 1.1448 - val_acc: 0.4534\n",
            "Epoch 84/150 - 0.18s - loss: 0.8765 - acc: 0.5906 - val_loss: 0.9826 - val_acc: 0.5081\n",
            "Epoch 85/150 - 0.16s - loss: 0.9162 - acc: 0.5621 - val_loss: 1.0325 - val_acc: 0.4676\n",
            "Epoch 86/150 - 0.16s - loss: 0.9086 - acc: 0.5679 - val_loss: 1.0148 - val_acc: 0.5283\n",
            "Epoch 87/150 - 0.17s - loss: 0.8854 - acc: 0.5819 - val_loss: 0.9912 - val_acc: 0.5121\n",
            "Epoch 88/150 - 0.16s - loss: 0.9187 - acc: 0.5565 - val_loss: 1.0373 - val_acc: 0.4879\n",
            "Epoch 89/150 - 0.16s - loss: 0.9127 - acc: 0.5634 - val_loss: 1.0298 - val_acc: 0.4939\n",
            "Epoch 90/150 - 0.16s - loss: 0.8940 - acc: 0.5774 - val_loss: 1.0124 - val_acc: 0.4879\n",
            "Epoch 91/150 - 0.17s - loss: 0.8621 - acc: 0.5963 - val_loss: 0.9750 - val_acc: 0.5283\n",
            "Epoch 92/150 - 0.16s - loss: 0.8647 - acc: 0.6091 - val_loss: 0.9785 - val_acc: 0.5385\n",
            "Epoch 93/150 - 0.16s - loss: 0.8965 - acc: 0.5884 - val_loss: 0.9999 - val_acc: 0.5405\n",
            "Epoch 94/150 - 0.16s - loss: 0.8568 - acc: 0.6098 - val_loss: 0.9754 - val_acc: 0.5283\n",
            "Epoch 95/150 - 0.17s - loss: 0.8938 - acc: 0.5803 - val_loss: 1.0187 - val_acc: 0.4939\n",
            "Epoch 96/150 - 0.16s - loss: 0.8931 - acc: 0.5922 - val_loss: 1.0003 - val_acc: 0.5344\n",
            "Epoch 97/150 - 0.21s - loss: 0.8736 - acc: 0.5949 - val_loss: 0.9990 - val_acc: 0.5101\n",
            "Epoch 98/150 - 0.16s - loss: 0.8639 - acc: 0.6023 - val_loss: 0.9868 - val_acc: 0.5263\n",
            "Epoch 99/150 - 0.17s - loss: 0.8549 - acc: 0.6172 - val_loss: 0.9745 - val_acc: 0.5466\n",
            "Epoch 100/150 - 0.16s - loss: 0.8555 - acc: 0.6041 - val_loss: 0.9717 - val_acc: 0.5263\n",
            "Epoch 101/150 - 0.16s - loss: 0.8792 - acc: 0.5846 - val_loss: 0.9885 - val_acc: 0.5243\n",
            "Epoch 102/150 - 0.16s - loss: 0.8475 - acc: 0.6073 - val_loss: 0.9669 - val_acc: 0.5405\n",
            "Epoch 103/150 - 0.17s - loss: 0.8669 - acc: 0.6093 - val_loss: 0.9862 - val_acc: 0.5506\n",
            "Epoch 104/150 - 0.16s - loss: 0.8648 - acc: 0.5967 - val_loss: 0.9750 - val_acc: 0.5385\n",
            "Epoch 105/150 - 0.16s - loss: 0.9421 - acc: 0.5565 - val_loss: 1.0806 - val_acc: 0.4777\n",
            "Epoch 106/150 - 0.16s - loss: 0.8828 - acc: 0.5843 - val_loss: 1.0111 - val_acc: 0.5040\n",
            "Epoch 107/150 - 0.17s - loss: 0.8602 - acc: 0.5985 - val_loss: 0.9856 - val_acc: 0.5243\n",
            "Epoch 108/150 - 0.16s - loss: 0.8850 - acc: 0.5837 - val_loss: 1.0121 - val_acc: 0.5182\n",
            "Epoch 109/150 - 0.16s - loss: 0.8576 - acc: 0.6134 - val_loss: 0.9785 - val_acc: 0.5466\n",
            "Epoch 110/150 - 0.16s - loss: 0.8559 - acc: 0.6005 - val_loss: 0.9712 - val_acc: 0.5526\n",
            "Epoch 111/150 - 0.17s - loss: 0.8547 - acc: 0.6129 - val_loss: 0.9764 - val_acc: 0.5486\n",
            "Epoch 112/150 - 0.18s - loss: 0.8508 - acc: 0.6163 - val_loss: 0.9766 - val_acc: 0.5405\n",
            "Epoch 113/150 - 0.16s - loss: 0.8829 - acc: 0.5922 - val_loss: 1.0103 - val_acc: 0.5263\n",
            "Epoch 114/150 - 0.17s - loss: 0.9500 - acc: 0.5418 - val_loss: 1.0952 - val_acc: 0.4474\n",
            "Epoch 115/150 - 0.19s - loss: 0.8546 - acc: 0.6086 - val_loss: 0.9856 - val_acc: 0.5223\n",
            "Epoch 116/150 - 0.16s - loss: 0.8592 - acc: 0.6080 - val_loss: 0.9954 - val_acc: 0.5142\n",
            "Epoch 117/150 - 0.18s - loss: 0.8504 - acc: 0.6055 - val_loss: 0.9720 - val_acc: 0.5445\n",
            "Epoch 118/150 - 0.16s - loss: 0.9420 - acc: 0.5425 - val_loss: 1.0735 - val_acc: 0.4879\n",
            "Epoch 119/150 - 0.17s - loss: 0.8520 - acc: 0.6174 - val_loss: 0.9767 - val_acc: 0.5547\n",
            "Epoch 120/150 - 0.16s - loss: 0.8727 - acc: 0.5893 - val_loss: 0.9894 - val_acc: 0.5425\n",
            "Epoch 121/150 - 0.18s - loss: 0.8602 - acc: 0.6113 - val_loss: 0.9848 - val_acc: 0.5506\n",
            "Epoch 122/150 - 0.17s - loss: 0.8818 - acc: 0.5848 - val_loss: 1.0040 - val_acc: 0.5243\n",
            "Epoch 123/150 - 0.18s - loss: 0.9077 - acc: 0.5641 - val_loss: 1.0204 - val_acc: 0.5263\n",
            "Epoch 124/150 - 0.16s - loss: 0.8461 - acc: 0.6197 - val_loss: 0.9776 - val_acc: 0.5506\n",
            "Epoch 125/150 - 0.18s - loss: 0.8471 - acc: 0.6170 - val_loss: 0.9787 - val_acc: 0.5364\n",
            "Epoch 126/150 - 0.17s - loss: 0.8426 - acc: 0.6161 - val_loss: 0.9789 - val_acc: 0.5526\n",
            "Epoch 127/150 - 0.18s - loss: 0.8438 - acc: 0.6149 - val_loss: 0.9775 - val_acc: 0.5445\n",
            "Epoch 128/150 - 0.17s - loss: 0.8845 - acc: 0.5843 - val_loss: 1.0151 - val_acc: 0.5040\n",
            "Epoch 129/150 - 0.17s - loss: 0.8962 - acc: 0.5927 - val_loss: 1.0169 - val_acc: 0.5425\n",
            "Epoch 130/150 - 0.16s - loss: 0.8444 - acc: 0.6237 - val_loss: 0.9774 - val_acc: 0.5526\n",
            "Epoch 131/150 - 0.17s - loss: 0.8516 - acc: 0.6048 - val_loss: 0.9760 - val_acc: 0.5486\n",
            "Epoch 132/150 - 0.16s - loss: 0.8726 - acc: 0.5897 - val_loss: 1.0087 - val_acc: 0.5142\n",
            "Epoch 133/150 - 0.17s - loss: 0.8980 - acc: 0.5735 - val_loss: 1.0454 - val_acc: 0.4818\n",
            "Epoch 134/150 - 0.16s - loss: 0.9205 - acc: 0.5767 - val_loss: 1.0375 - val_acc: 0.5324\n",
            "Epoch 135/150 - 0.18s - loss: 0.8543 - acc: 0.6116 - val_loss: 0.9919 - val_acc: 0.5405\n",
            "Epoch 136/150 - 0.17s - loss: 0.8747 - acc: 0.6046 - val_loss: 1.0031 - val_acc: 0.5466\n",
            "Epoch 137/150 - 0.19s - loss: 0.8431 - acc: 0.6233 - val_loss: 0.9776 - val_acc: 0.5648\n",
            "Epoch 138/150 - 0.17s - loss: 0.8471 - acc: 0.6136 - val_loss: 0.9887 - val_acc: 0.5405\n",
            "Epoch 139/150 - 0.20s - loss: 0.9587 - acc: 0.5387 - val_loss: 1.1140 - val_acc: 0.4636\n",
            "Epoch 140/150 - 0.16s - loss: 0.8947 - acc: 0.5691 - val_loss: 1.0132 - val_acc: 0.5304\n",
            "Epoch 141/150 - 0.16s - loss: 0.8377 - acc: 0.6221 - val_loss: 0.9730 - val_acc: 0.5445\n",
            "Epoch 142/150 - 0.16s - loss: 0.8651 - acc: 0.5938 - val_loss: 1.0026 - val_acc: 0.5182\n",
            "Epoch 143/150 - 0.18s - loss: 0.9799 - acc: 0.5259 - val_loss: 1.0917 - val_acc: 0.5162\n",
            "Epoch 144/150 - 0.18s - loss: 0.8836 - acc: 0.5821 - val_loss: 1.0046 - val_acc: 0.5425\n",
            "Epoch 145/150 - 0.17s - loss: 0.8750 - acc: 0.5888 - val_loss: 1.0184 - val_acc: 0.5020\n",
            "Epoch 146/150 - 0.16s - loss: 0.8983 - acc: 0.5828 - val_loss: 1.0328 - val_acc: 0.5223\n",
            "Epoch 147/150 - 0.18s - loss: 0.8485 - acc: 0.6170 - val_loss: 0.9903 - val_acc: 0.5385\n",
            "Epoch 148/150 - 0.17s - loss: 0.8498 - acc: 0.6158 - val_loss: 0.9908 - val_acc: 0.5405\n",
            "Epoch 149/150 - 0.18s - loss: 0.8392 - acc: 0.6152 - val_loss: 0.9738 - val_acc: 0.5425\n",
            "Epoch 150/150 - 0.17s - loss: 0.8355 - acc: 0.6183 - val_loss: 0.9764 - val_acc: 0.5486\n",
            "\n",
            "Combination 205/252:\n",
            "Hidden Layers: [256, 128, 64], Activation: tanh, Learning Rate: 0.001, Batch Size: 32, Epochs: 50\n",
            "Epoch 1/50 - 0.22s - loss: 1.0913 - acc: 0.3754 - val_loss: 1.0954 - val_acc: 0.3583\n",
            "Epoch 2/50 - 0.21s - loss: 1.0877 - acc: 0.3956 - val_loss: 1.0926 - val_acc: 0.3725\n",
            "Epoch 3/50 - 0.25s - loss: 1.0847 - acc: 0.4064 - val_loss: 1.0902 - val_acc: 0.3907\n",
            "Epoch 4/50 - 0.28s - loss: 1.0819 - acc: 0.4242 - val_loss: 1.0880 - val_acc: 0.3968\n",
            "Epoch 5/50 - 0.21s - loss: 1.0794 - acc: 0.4314 - val_loss: 1.0860 - val_acc: 0.3866\n",
            "Epoch 6/50 - 0.22s - loss: 1.0770 - acc: 0.4357 - val_loss: 1.0838 - val_acc: 0.4049\n",
            "Epoch 7/50 - 0.20s - loss: 1.0748 - acc: 0.4375 - val_loss: 1.0820 - val_acc: 0.4008\n",
            "Epoch 8/50 - 0.21s - loss: 1.0727 - acc: 0.4363 - val_loss: 1.0805 - val_acc: 0.4089\n",
            "Epoch 9/50 - 0.20s - loss: 1.0706 - acc: 0.4449 - val_loss: 1.0789 - val_acc: 0.4109\n",
            "Epoch 10/50 - 0.20s - loss: 1.0688 - acc: 0.4415 - val_loss: 1.0778 - val_acc: 0.4089\n",
            "Epoch 11/50 - 0.20s - loss: 1.0669 - acc: 0.4474 - val_loss: 1.0759 - val_acc: 0.4352\n",
            "Epoch 12/50 - 0.22s - loss: 1.0652 - acc: 0.4487 - val_loss: 1.0747 - val_acc: 0.4312\n",
            "Epoch 13/50 - 0.21s - loss: 1.0635 - acc: 0.4539 - val_loss: 1.0733 - val_acc: 0.4433\n",
            "Epoch 14/50 - 0.25s - loss: 1.0619 - acc: 0.4519 - val_loss: 1.0721 - val_acc: 0.4433\n",
            "Epoch 15/50 - 0.20s - loss: 1.0604 - acc: 0.4523 - val_loss: 1.0709 - val_acc: 0.4433\n",
            "Epoch 16/50 - 0.20s - loss: 1.0588 - acc: 0.4566 - val_loss: 1.0698 - val_acc: 0.4433\n",
            "Epoch 17/50 - 0.21s - loss: 1.0574 - acc: 0.4642 - val_loss: 1.0686 - val_acc: 0.4534\n",
            "Epoch 18/50 - 0.21s - loss: 1.0560 - acc: 0.4656 - val_loss: 1.0674 - val_acc: 0.4514\n",
            "Epoch 19/50 - 0.22s - loss: 1.0545 - acc: 0.4606 - val_loss: 1.0668 - val_acc: 0.4494\n",
            "Epoch 20/50 - 0.20s - loss: 1.0531 - acc: 0.4636 - val_loss: 1.0656 - val_acc: 0.4555\n",
            "Epoch 21/50 - 0.21s - loss: 1.0517 - acc: 0.4667 - val_loss: 1.0645 - val_acc: 0.4656\n",
            "Epoch 22/50 - 0.20s - loss: 1.0504 - acc: 0.4663 - val_loss: 1.0637 - val_acc: 0.4575\n",
            "Epoch 23/50 - 0.22s - loss: 1.0491 - acc: 0.4676 - val_loss: 1.0627 - val_acc: 0.4615\n",
            "Epoch 24/50 - 0.22s - loss: 1.0478 - acc: 0.4683 - val_loss: 1.0620 - val_acc: 0.4615\n",
            "Epoch 25/50 - 0.23s - loss: 1.0465 - acc: 0.4690 - val_loss: 1.0610 - val_acc: 0.4656\n",
            "Epoch 26/50 - 0.24s - loss: 1.0453 - acc: 0.4692 - val_loss: 1.0600 - val_acc: 0.4717\n",
            "Epoch 27/50 - 0.22s - loss: 1.0440 - acc: 0.4699 - val_loss: 1.0591 - val_acc: 0.4737\n",
            "Epoch 28/50 - 0.22s - loss: 1.0428 - acc: 0.4730 - val_loss: 1.0583 - val_acc: 0.4737\n",
            "Epoch 29/50 - 0.23s - loss: 1.0417 - acc: 0.4757 - val_loss: 1.0570 - val_acc: 0.4737\n",
            "Epoch 30/50 - 0.21s - loss: 1.0404 - acc: 0.4773 - val_loss: 1.0561 - val_acc: 0.4676\n",
            "Epoch 31/50 - 0.23s - loss: 1.0392 - acc: 0.4764 - val_loss: 1.0553 - val_acc: 0.4798\n",
            "Epoch 32/50 - 0.23s - loss: 1.0381 - acc: 0.4793 - val_loss: 1.0544 - val_acc: 0.4798\n",
            "Epoch 33/50 - 0.26s - loss: 1.0370 - acc: 0.4793 - val_loss: 1.0536 - val_acc: 0.4757\n",
            "Epoch 34/50 - 0.21s - loss: 1.0358 - acc: 0.4804 - val_loss: 1.0528 - val_acc: 0.4818\n",
            "Epoch 35/50 - 0.23s - loss: 1.0347 - acc: 0.4804 - val_loss: 1.0522 - val_acc: 0.4838\n",
            "Epoch 36/50 - 0.22s - loss: 1.0336 - acc: 0.4825 - val_loss: 1.0513 - val_acc: 0.4818\n",
            "Epoch 37/50 - 0.23s - loss: 1.0325 - acc: 0.4847 - val_loss: 1.0505 - val_acc: 0.4838\n",
            "Epoch 38/50 - 0.22s - loss: 1.0313 - acc: 0.4858 - val_loss: 1.0495 - val_acc: 0.4919\n",
            "Epoch 39/50 - 0.24s - loss: 1.0303 - acc: 0.4863 - val_loss: 1.0488 - val_acc: 0.4919\n",
            "Epoch 40/50 - 0.23s - loss: 1.0293 - acc: 0.4885 - val_loss: 1.0482 - val_acc: 0.4858\n",
            "Epoch 41/50 - 0.24s - loss: 1.0282 - acc: 0.4874 - val_loss: 1.0470 - val_acc: 0.4899\n",
            "Epoch 42/50 - 0.23s - loss: 1.0271 - acc: 0.4894 - val_loss: 1.0462 - val_acc: 0.4919\n",
            "Epoch 43/50 - 0.23s - loss: 1.0260 - acc: 0.4892 - val_loss: 1.0456 - val_acc: 0.4919\n",
            "Epoch 44/50 - 0.21s - loss: 1.0252 - acc: 0.4926 - val_loss: 1.0454 - val_acc: 0.4960\n",
            "Epoch 45/50 - 0.22s - loss: 1.0241 - acc: 0.4919 - val_loss: 1.0446 - val_acc: 0.4980\n",
            "Epoch 46/50 - 0.21s - loss: 1.0230 - acc: 0.4912 - val_loss: 1.0430 - val_acc: 0.4980\n",
            "Epoch 47/50 - 0.22s - loss: 1.0219 - acc: 0.4915 - val_loss: 1.0426 - val_acc: 0.4899\n",
            "Epoch 48/50 - 0.24s - loss: 1.0209 - acc: 0.4924 - val_loss: 1.0418 - val_acc: 0.4919\n",
            "Epoch 49/50 - 0.22s - loss: 1.0199 - acc: 0.4917 - val_loss: 1.0408 - val_acc: 0.4980\n",
            "Epoch 50/50 - 0.23s - loss: 1.0190 - acc: 0.4964 - val_loss: 1.0404 - val_acc: 0.4919\n",
            "\n",
            "Combination 206/252:\n",
            "Hidden Layers: [256, 128, 64], Activation: tanh, Learning Rate: 0.001, Batch Size: 32, Epochs: 100\n",
            "Epoch 1/100 - 0.22s - loss: 1.0988 - acc: 0.3536 - val_loss: 1.1032 - val_acc: 0.3401\n",
            "Epoch 2/100 - 0.21s - loss: 1.0939 - acc: 0.3547 - val_loss: 1.0985 - val_acc: 0.3502\n",
            "Epoch 3/100 - 0.24s - loss: 1.0908 - acc: 0.3648 - val_loss: 1.0959 - val_acc: 0.3340\n",
            "Epoch 4/100 - 0.24s - loss: 1.0879 - acc: 0.3702 - val_loss: 1.0933 - val_acc: 0.3381\n",
            "Epoch 5/100 - 0.22s - loss: 1.0852 - acc: 0.3837 - val_loss: 1.0905 - val_acc: 0.3360\n",
            "Epoch 6/100 - 0.25s - loss: 1.0826 - acc: 0.3945 - val_loss: 1.0882 - val_acc: 0.3421\n",
            "Epoch 7/100 - 0.21s - loss: 1.0802 - acc: 0.3995 - val_loss: 1.0861 - val_acc: 0.3462\n",
            "Epoch 8/100 - 0.22s - loss: 1.0780 - acc: 0.4058 - val_loss: 1.0843 - val_acc: 0.3522\n",
            "Epoch 9/100 - 0.22s - loss: 1.0759 - acc: 0.4148 - val_loss: 1.0820 - val_acc: 0.3704\n",
            "Epoch 10/100 - 0.22s - loss: 1.0739 - acc: 0.4206 - val_loss: 1.0801 - val_acc: 0.3806\n",
            "Epoch 11/100 - 0.22s - loss: 1.0719 - acc: 0.4240 - val_loss: 1.0786 - val_acc: 0.3866\n",
            "Epoch 12/100 - 0.24s - loss: 1.0702 - acc: 0.4247 - val_loss: 1.0768 - val_acc: 0.4069\n",
            "Epoch 13/100 - 0.26s - loss: 1.0685 - acc: 0.4316 - val_loss: 1.0760 - val_acc: 0.4008\n",
            "Epoch 14/100 - 0.21s - loss: 1.0668 - acc: 0.4345 - val_loss: 1.0747 - val_acc: 0.3947\n",
            "Epoch 15/100 - 0.22s - loss: 1.0652 - acc: 0.4350 - val_loss: 1.0729 - val_acc: 0.4190\n",
            "Epoch 16/100 - 0.21s - loss: 1.0637 - acc: 0.4399 - val_loss: 1.0713 - val_acc: 0.4291\n",
            "Epoch 17/100 - 0.23s - loss: 1.0622 - acc: 0.4422 - val_loss: 1.0701 - val_acc: 0.4291\n",
            "Epoch 18/100 - 0.22s - loss: 1.0608 - acc: 0.4440 - val_loss: 1.0690 - val_acc: 0.4312\n",
            "Epoch 19/100 - 0.23s - loss: 1.0594 - acc: 0.4478 - val_loss: 1.0678 - val_acc: 0.4352\n",
            "Epoch 20/100 - 0.22s - loss: 1.0582 - acc: 0.4480 - val_loss: 1.0670 - val_acc: 0.4352\n",
            "Epoch 21/100 - 0.27s - loss: 1.0569 - acc: 0.4510 - val_loss: 1.0661 - val_acc: 0.4393\n",
            "Epoch 22/100 - 0.22s - loss: 1.0556 - acc: 0.4528 - val_loss: 1.0651 - val_acc: 0.4393\n",
            "Epoch 23/100 - 0.24s - loss: 1.0544 - acc: 0.4528 - val_loss: 1.0637 - val_acc: 0.4534\n",
            "Epoch 24/100 - 0.24s - loss: 1.0533 - acc: 0.4575 - val_loss: 1.0630 - val_acc: 0.4494\n",
            "Epoch 25/100 - 0.23s - loss: 1.0522 - acc: 0.4602 - val_loss: 1.0623 - val_acc: 0.4555\n",
            "Epoch 26/100 - 0.22s - loss: 1.0510 - acc: 0.4577 - val_loss: 1.0612 - val_acc: 0.4575\n",
            "Epoch 27/100 - 0.24s - loss: 1.0500 - acc: 0.4602 - val_loss: 1.0604 - val_acc: 0.4676\n",
            "Epoch 28/100 - 0.25s - loss: 1.0489 - acc: 0.4606 - val_loss: 1.0591 - val_acc: 0.4575\n",
            "Epoch 29/100 - 0.25s - loss: 1.0479 - acc: 0.4604 - val_loss: 1.0583 - val_acc: 0.4534\n",
            "Epoch 30/100 - 0.25s - loss: 1.0471 - acc: 0.4631 - val_loss: 1.0584 - val_acc: 0.4575\n",
            "Epoch 31/100 - 0.26s - loss: 1.0459 - acc: 0.4629 - val_loss: 1.0567 - val_acc: 0.4575\n",
            "Epoch 32/100 - 0.22s - loss: 1.0449 - acc: 0.4654 - val_loss: 1.0561 - val_acc: 0.4656\n",
            "Epoch 33/100 - 0.25s - loss: 1.0439 - acc: 0.4678 - val_loss: 1.0554 - val_acc: 0.4737\n",
            "Epoch 34/100 - 0.21s - loss: 1.0430 - acc: 0.4690 - val_loss: 1.0546 - val_acc: 0.4737\n",
            "Epoch 35/100 - 0.26s - loss: 1.0420 - acc: 0.4710 - val_loss: 1.0540 - val_acc: 0.4696\n",
            "Epoch 36/100 - 0.25s - loss: 1.0411 - acc: 0.4701 - val_loss: 1.0531 - val_acc: 0.4696\n",
            "Epoch 37/100 - 0.27s - loss: 1.0402 - acc: 0.4687 - val_loss: 1.0521 - val_acc: 0.4757\n",
            "Epoch 38/100 - 0.21s - loss: 1.0393 - acc: 0.4744 - val_loss: 1.0519 - val_acc: 0.4737\n",
            "Epoch 39/100 - 0.22s - loss: 1.0384 - acc: 0.4755 - val_loss: 1.0513 - val_acc: 0.4757\n",
            "Epoch 40/100 - 0.22s - loss: 1.0375 - acc: 0.4735 - val_loss: 1.0503 - val_acc: 0.4818\n",
            "Epoch 41/100 - 0.22s - loss: 1.0366 - acc: 0.4737 - val_loss: 1.0497 - val_acc: 0.4737\n",
            "Epoch 42/100 - 0.24s - loss: 1.0358 - acc: 0.4795 - val_loss: 1.0493 - val_acc: 0.4798\n",
            "Epoch 43/100 - 0.23s - loss: 1.0350 - acc: 0.4793 - val_loss: 1.0490 - val_acc: 0.4777\n",
            "Epoch 44/100 - 0.21s - loss: 1.0340 - acc: 0.4735 - val_loss: 1.0473 - val_acc: 0.4798\n",
            "Epoch 45/100 - 0.23s - loss: 1.0331 - acc: 0.4791 - val_loss: 1.0470 - val_acc: 0.4818\n",
            "Epoch 46/100 - 0.22s - loss: 1.0323 - acc: 0.4762 - val_loss: 1.0461 - val_acc: 0.4818\n",
            "Epoch 47/100 - 0.23s - loss: 1.0314 - acc: 0.4782 - val_loss: 1.0453 - val_acc: 0.4818\n",
            "Epoch 48/100 - 0.23s - loss: 1.0306 - acc: 0.4818 - val_loss: 1.0451 - val_acc: 0.4838\n",
            "Epoch 49/100 - 0.25s - loss: 1.0298 - acc: 0.4863 - val_loss: 1.0441 - val_acc: 0.4818\n",
            "Epoch 50/100 - 0.22s - loss: 1.0289 - acc: 0.4870 - val_loss: 1.0435 - val_acc: 0.4818\n",
            "Epoch 51/100 - 0.24s - loss: 1.0282 - acc: 0.4910 - val_loss: 1.0431 - val_acc: 0.4899\n",
            "Epoch 52/100 - 0.26s - loss: 1.0273 - acc: 0.4872 - val_loss: 1.0424 - val_acc: 0.4879\n",
            "Epoch 53/100 - 0.25s - loss: 1.0264 - acc: 0.4899 - val_loss: 1.0415 - val_acc: 0.4838\n",
            "Epoch 54/100 - 0.23s - loss: 1.0256 - acc: 0.4906 - val_loss: 1.0407 - val_acc: 0.4858\n",
            "Epoch 55/100 - 0.24s - loss: 1.0248 - acc: 0.4917 - val_loss: 1.0405 - val_acc: 0.4899\n",
            "Epoch 56/100 - 0.25s - loss: 1.0240 - acc: 0.4926 - val_loss: 1.0398 - val_acc: 0.4818\n",
            "Epoch 57/100 - 0.23s - loss: 1.0232 - acc: 0.4948 - val_loss: 1.0395 - val_acc: 0.4899\n",
            "Epoch 58/100 - 0.23s - loss: 1.0224 - acc: 0.4924 - val_loss: 1.0388 - val_acc: 0.4919\n",
            "Epoch 59/100 - 0.25s - loss: 1.0215 - acc: 0.4935 - val_loss: 1.0378 - val_acc: 0.4919\n",
            "Epoch 60/100 - 0.22s - loss: 1.0208 - acc: 0.4957 - val_loss: 1.0374 - val_acc: 0.4960\n",
            "Epoch 61/100 - 0.24s - loss: 1.0198 - acc: 0.4980 - val_loss: 1.0363 - val_acc: 0.4919\n",
            "Epoch 62/100 - 0.26s - loss: 1.0191 - acc: 0.4993 - val_loss: 1.0356 - val_acc: 0.4899\n",
            "Epoch 63/100 - 0.27s - loss: 1.0183 - acc: 0.4966 - val_loss: 1.0354 - val_acc: 0.4960\n",
            "Epoch 64/100 - 0.26s - loss: 1.0175 - acc: 0.4998 - val_loss: 1.0348 - val_acc: 0.4980\n",
            "Epoch 65/100 - 0.21s - loss: 1.0168 - acc: 0.5022 - val_loss: 1.0334 - val_acc: 0.4960\n",
            "Epoch 66/100 - 0.22s - loss: 1.0158 - acc: 0.5043 - val_loss: 1.0330 - val_acc: 0.5000\n",
            "Epoch 67/100 - 0.23s - loss: 1.0150 - acc: 0.5027 - val_loss: 1.0328 - val_acc: 0.5040\n",
            "Epoch 68/100 - 0.23s - loss: 1.0142 - acc: 0.5049 - val_loss: 1.0316 - val_acc: 0.5061\n",
            "Epoch 69/100 - 0.24s - loss: 1.0134 - acc: 0.5063 - val_loss: 1.0311 - val_acc: 0.5040\n",
            "Epoch 70/100 - 0.26s - loss: 1.0126 - acc: 0.5067 - val_loss: 1.0303 - val_acc: 0.5040\n",
            "Epoch 71/100 - 0.23s - loss: 1.0118 - acc: 0.5067 - val_loss: 1.0299 - val_acc: 0.5000\n",
            "Epoch 72/100 - 0.25s - loss: 1.0110 - acc: 0.5079 - val_loss: 1.0295 - val_acc: 0.5081\n",
            "Epoch 73/100 - 0.22s - loss: 1.0101 - acc: 0.5092 - val_loss: 1.0286 - val_acc: 0.5081\n",
            "Epoch 74/100 - 0.24s - loss: 1.0097 - acc: 0.5067 - val_loss: 1.0275 - val_acc: 0.4980\n",
            "Epoch 75/100 - 0.23s - loss: 1.0085 - acc: 0.5106 - val_loss: 1.0272 - val_acc: 0.5081\n",
            "Epoch 76/100 - 0.23s - loss: 1.0077 - acc: 0.5085 - val_loss: 1.0263 - val_acc: 0.5081\n",
            "Epoch 77/100 - 0.26s - loss: 1.0070 - acc: 0.5099 - val_loss: 1.0261 - val_acc: 0.5101\n",
            "Epoch 78/100 - 0.22s - loss: 1.0061 - acc: 0.5121 - val_loss: 1.0252 - val_acc: 0.5101\n",
            "Epoch 79/100 - 0.25s - loss: 1.0057 - acc: 0.5121 - val_loss: 1.0243 - val_acc: 0.5000\n",
            "Epoch 80/100 - 0.22s - loss: 1.0045 - acc: 0.5130 - val_loss: 1.0239 - val_acc: 0.5101\n",
            "Epoch 81/100 - 0.24s - loss: 1.0038 - acc: 0.5148 - val_loss: 1.0233 - val_acc: 0.5081\n",
            "Epoch 82/100 - 0.25s - loss: 1.0030 - acc: 0.5133 - val_loss: 1.0223 - val_acc: 0.5121\n",
            "Epoch 83/100 - 0.22s - loss: 1.0022 - acc: 0.5148 - val_loss: 1.0221 - val_acc: 0.5162\n",
            "Epoch 84/100 - 0.24s - loss: 1.0016 - acc: 0.5133 - val_loss: 1.0218 - val_acc: 0.5081\n",
            "Epoch 85/100 - 0.22s - loss: 1.0005 - acc: 0.5184 - val_loss: 1.0205 - val_acc: 0.5182\n",
            "Epoch 86/100 - 0.23s - loss: 0.9998 - acc: 0.5189 - val_loss: 1.0195 - val_acc: 0.5121\n",
            "Epoch 87/100 - 0.26s - loss: 0.9991 - acc: 0.5200 - val_loss: 1.0187 - val_acc: 0.5182\n",
            "Epoch 88/100 - 0.22s - loss: 0.9982 - acc: 0.5200 - val_loss: 1.0182 - val_acc: 0.5121\n",
            "Epoch 89/100 - 0.23s - loss: 0.9974 - acc: 0.5200 - val_loss: 1.0179 - val_acc: 0.5202\n",
            "Epoch 90/100 - 0.22s - loss: 0.9966 - acc: 0.5207 - val_loss: 1.0169 - val_acc: 0.5162\n",
            "Epoch 91/100 - 0.24s - loss: 0.9960 - acc: 0.5211 - val_loss: 1.0161 - val_acc: 0.5182\n",
            "Epoch 92/100 - 0.24s - loss: 0.9953 - acc: 0.5205 - val_loss: 1.0155 - val_acc: 0.5182\n",
            "Epoch 93/100 - 0.24s - loss: 0.9942 - acc: 0.5232 - val_loss: 1.0149 - val_acc: 0.5162\n",
            "Epoch 94/100 - 0.23s - loss: 0.9936 - acc: 0.5232 - val_loss: 1.0139 - val_acc: 0.5142\n",
            "Epoch 95/100 - 0.23s - loss: 0.9929 - acc: 0.5218 - val_loss: 1.0140 - val_acc: 0.5121\n",
            "Epoch 96/100 - 0.24s - loss: 0.9919 - acc: 0.5256 - val_loss: 1.0127 - val_acc: 0.5162\n",
            "Epoch 97/100 - 0.22s - loss: 0.9914 - acc: 0.5247 - val_loss: 1.0117 - val_acc: 0.5101\n",
            "Epoch 98/100 - 0.23s - loss: 0.9905 - acc: 0.5234 - val_loss: 1.0122 - val_acc: 0.5182\n",
            "Epoch 99/100 - 0.27s - loss: 0.9896 - acc: 0.5250 - val_loss: 1.0107 - val_acc: 0.5121\n",
            "Epoch 100/100 - 0.22s - loss: 0.9888 - acc: 0.5295 - val_loss: 1.0100 - val_acc: 0.5142\n",
            "\n",
            "Combination 207/252:\n",
            "Hidden Layers: [256, 128, 64], Activation: tanh, Learning Rate: 0.001, Batch Size: 32, Epochs: 150\n",
            "Epoch 1/150 - 0.23s - loss: 1.1035 - acc: 0.3219 - val_loss: 1.0996 - val_acc: 0.3482\n",
            "Epoch 2/150 - 0.25s - loss: 1.0993 - acc: 0.3450 - val_loss: 1.0961 - val_acc: 0.3644\n",
            "Epoch 3/150 - 0.22s - loss: 1.0959 - acc: 0.3632 - val_loss: 1.0929 - val_acc: 0.3846\n",
            "Epoch 4/150 - 0.22s - loss: 1.0927 - acc: 0.3846 - val_loss: 1.0903 - val_acc: 0.4049\n",
            "Epoch 5/150 - 0.23s - loss: 1.0898 - acc: 0.3988 - val_loss: 1.0875 - val_acc: 0.4190\n",
            "Epoch 6/150 - 0.24s - loss: 1.0870 - acc: 0.4096 - val_loss: 1.0854 - val_acc: 0.4231\n",
            "Epoch 7/150 - 0.23s - loss: 1.0845 - acc: 0.4206 - val_loss: 1.0839 - val_acc: 0.4312\n",
            "Epoch 8/150 - 0.22s - loss: 1.0821 - acc: 0.4300 - val_loss: 1.0819 - val_acc: 0.4271\n",
            "Epoch 9/150 - 0.23s - loss: 1.0799 - acc: 0.4348 - val_loss: 1.0801 - val_acc: 0.4291\n",
            "Epoch 10/150 - 0.25s - loss: 1.0779 - acc: 0.4487 - val_loss: 1.0785 - val_acc: 0.4413\n",
            "Epoch 11/150 - 0.23s - loss: 1.0757 - acc: 0.4485 - val_loss: 1.0766 - val_acc: 0.4595\n",
            "Epoch 12/150 - 0.23s - loss: 1.0738 - acc: 0.4505 - val_loss: 1.0752 - val_acc: 0.4534\n",
            "Epoch 13/150 - 0.25s - loss: 1.0720 - acc: 0.4582 - val_loss: 1.0740 - val_acc: 0.4534\n",
            "Epoch 14/150 - 0.22s - loss: 1.0703 - acc: 0.4606 - val_loss: 1.0726 - val_acc: 0.4636\n",
            "Epoch 15/150 - 0.23s - loss: 1.0686 - acc: 0.4609 - val_loss: 1.0714 - val_acc: 0.4676\n",
            "Epoch 16/150 - 0.22s - loss: 1.0670 - acc: 0.4618 - val_loss: 1.0702 - val_acc: 0.4676\n",
            "Epoch 17/150 - 0.23s - loss: 1.0654 - acc: 0.4642 - val_loss: 1.0688 - val_acc: 0.4696\n",
            "Epoch 18/150 - 0.23s - loss: 1.0640 - acc: 0.4672 - val_loss: 1.0680 - val_acc: 0.4696\n",
            "Epoch 19/150 - 0.25s - loss: 1.0625 - acc: 0.4681 - val_loss: 1.0669 - val_acc: 0.4717\n",
            "Epoch 20/150 - 0.25s - loss: 1.0611 - acc: 0.4699 - val_loss: 1.0662 - val_acc: 0.4777\n",
            "Epoch 21/150 - 0.24s - loss: 1.0597 - acc: 0.4721 - val_loss: 1.0649 - val_acc: 0.4777\n",
            "Epoch 22/150 - 0.23s - loss: 1.0583 - acc: 0.4723 - val_loss: 1.0640 - val_acc: 0.4717\n",
            "Epoch 23/150 - 0.24s - loss: 1.0570 - acc: 0.4730 - val_loss: 1.0629 - val_acc: 0.4960\n",
            "Epoch 24/150 - 0.21s - loss: 1.0558 - acc: 0.4771 - val_loss: 1.0621 - val_acc: 0.4737\n",
            "Epoch 25/150 - 0.24s - loss: 1.0545 - acc: 0.4757 - val_loss: 1.0615 - val_acc: 0.4838\n",
            "Epoch 26/150 - 0.22s - loss: 1.0532 - acc: 0.4759 - val_loss: 1.0604 - val_acc: 0.4879\n",
            "Epoch 27/150 - 0.26s - loss: 1.0520 - acc: 0.4777 - val_loss: 1.0598 - val_acc: 0.4838\n",
            "Epoch 28/150 - 0.21s - loss: 1.0508 - acc: 0.4789 - val_loss: 1.0588 - val_acc: 0.4838\n",
            "Epoch 29/150 - 0.23s - loss: 1.0496 - acc: 0.4809 - val_loss: 1.0582 - val_acc: 0.4798\n",
            "Epoch 30/150 - 0.22s - loss: 1.0485 - acc: 0.4800 - val_loss: 1.0573 - val_acc: 0.4919\n",
            "Epoch 31/150 - 0.22s - loss: 1.0474 - acc: 0.4858 - val_loss: 1.0567 - val_acc: 0.4777\n",
            "Epoch 32/150 - 0.25s - loss: 1.0463 - acc: 0.4854 - val_loss: 1.0560 - val_acc: 0.4777\n",
            "Epoch 33/150 - 0.23s - loss: 1.0451 - acc: 0.4843 - val_loss: 1.0550 - val_acc: 0.4858\n",
            "Epoch 34/150 - 0.25s - loss: 1.0440 - acc: 0.4843 - val_loss: 1.0548 - val_acc: 0.4919\n",
            "Epoch 35/150 - 0.22s - loss: 1.0428 - acc: 0.4856 - val_loss: 1.0539 - val_acc: 0.4818\n",
            "Epoch 36/150 - 0.23s - loss: 1.0418 - acc: 0.4867 - val_loss: 1.0529 - val_acc: 0.4980\n",
            "Epoch 37/150 - 0.23s - loss: 1.0407 - acc: 0.4867 - val_loss: 1.0522 - val_acc: 0.4858\n",
            "Epoch 38/150 - 0.22s - loss: 1.0396 - acc: 0.4876 - val_loss: 1.0516 - val_acc: 0.4919\n",
            "Epoch 39/150 - 0.23s - loss: 1.0386 - acc: 0.4876 - val_loss: 1.0509 - val_acc: 0.4858\n",
            "Epoch 40/150 - 0.22s - loss: 1.0375 - acc: 0.4867 - val_loss: 1.0505 - val_acc: 0.4939\n",
            "Epoch 41/150 - 0.25s - loss: 1.0364 - acc: 0.4897 - val_loss: 1.0500 - val_acc: 0.4879\n",
            "Epoch 42/150 - 0.22s - loss: 1.0354 - acc: 0.4892 - val_loss: 1.0491 - val_acc: 0.4980\n",
            "Epoch 43/150 - 0.23s - loss: 1.0343 - acc: 0.4892 - val_loss: 1.0486 - val_acc: 0.4858\n",
            "Epoch 44/150 - 0.22s - loss: 1.0333 - acc: 0.4921 - val_loss: 1.0481 - val_acc: 0.4858\n",
            "Epoch 45/150 - 0.23s - loss: 1.0323 - acc: 0.4915 - val_loss: 1.0471 - val_acc: 0.4899\n",
            "Epoch 46/150 - 0.22s - loss: 1.0313 - acc: 0.4928 - val_loss: 1.0467 - val_acc: 0.4939\n",
            "Epoch 47/150 - 0.23s - loss: 1.0304 - acc: 0.4969 - val_loss: 1.0467 - val_acc: 0.4899\n",
            "Epoch 48/150 - 0.25s - loss: 1.0294 - acc: 0.4984 - val_loss: 1.0460 - val_acc: 0.4838\n",
            "Epoch 49/150 - 0.22s - loss: 1.0284 - acc: 0.4966 - val_loss: 1.0446 - val_acc: 0.4838\n",
            "Epoch 50/150 - 0.22s - loss: 1.0274 - acc: 0.4955 - val_loss: 1.0448 - val_acc: 0.4899\n",
            "Epoch 51/150 - 0.24s - loss: 1.0264 - acc: 0.4984 - val_loss: 1.0441 - val_acc: 0.4899\n",
            "Epoch 52/150 - 0.21s - loss: 1.0254 - acc: 0.4984 - val_loss: 1.0432 - val_acc: 0.4879\n",
            "Epoch 53/150 - 0.24s - loss: 1.0244 - acc: 0.4964 - val_loss: 1.0420 - val_acc: 0.5040\n",
            "Epoch 54/150 - 0.21s - loss: 1.0234 - acc: 0.5011 - val_loss: 1.0418 - val_acc: 0.5000\n",
            "Epoch 55/150 - 0.26s - loss: 1.0224 - acc: 0.4993 - val_loss: 1.0409 - val_acc: 0.5020\n",
            "Epoch 56/150 - 0.22s - loss: 1.0215 - acc: 0.5007 - val_loss: 1.0401 - val_acc: 0.4980\n",
            "Epoch 57/150 - 0.23s - loss: 1.0204 - acc: 0.5013 - val_loss: 1.0399 - val_acc: 0.5020\n",
            "Epoch 58/150 - 0.22s - loss: 1.0195 - acc: 0.5029 - val_loss: 1.0396 - val_acc: 0.4980\n",
            "Epoch 59/150 - 0.23s - loss: 1.0186 - acc: 0.5045 - val_loss: 1.0385 - val_acc: 0.4939\n",
            "Epoch 60/150 - 0.22s - loss: 1.0175 - acc: 0.5022 - val_loss: 1.0378 - val_acc: 0.5081\n",
            "Epoch 61/150 - 0.25s - loss: 1.0167 - acc: 0.5034 - val_loss: 1.0369 - val_acc: 0.5020\n",
            "Epoch 62/150 - 0.24s - loss: 1.0156 - acc: 0.5034 - val_loss: 1.0364 - val_acc: 0.5040\n",
            "Epoch 63/150 - 0.25s - loss: 1.0148 - acc: 0.5052 - val_loss: 1.0366 - val_acc: 0.5000\n",
            "Epoch 64/150 - 0.25s - loss: 1.0139 - acc: 0.5076 - val_loss: 1.0360 - val_acc: 0.4980\n",
            "Epoch 65/150 - 0.22s - loss: 1.0128 - acc: 0.5065 - val_loss: 1.0349 - val_acc: 0.5020\n",
            "Epoch 66/150 - 0.22s - loss: 1.0119 - acc: 0.5070 - val_loss: 1.0338 - val_acc: 0.5020\n",
            "Epoch 67/150 - 0.23s - loss: 1.0109 - acc: 0.5088 - val_loss: 1.0335 - val_acc: 0.5000\n",
            "Epoch 68/150 - 0.22s - loss: 1.0101 - acc: 0.5099 - val_loss: 1.0332 - val_acc: 0.5040\n",
            "Epoch 69/150 - 0.25s - loss: 1.0091 - acc: 0.5079 - val_loss: 1.0321 - val_acc: 0.5040\n",
            "Epoch 70/150 - 0.21s - loss: 1.0082 - acc: 0.5110 - val_loss: 1.0311 - val_acc: 0.5000\n",
            "Epoch 71/150 - 0.24s - loss: 1.0072 - acc: 0.5117 - val_loss: 1.0310 - val_acc: 0.5020\n",
            "Epoch 72/150 - 0.21s - loss: 1.0065 - acc: 0.5121 - val_loss: 1.0301 - val_acc: 0.5040\n",
            "Epoch 73/150 - 0.24s - loss: 1.0055 - acc: 0.5137 - val_loss: 1.0299 - val_acc: 0.5101\n",
            "Epoch 74/150 - 0.22s - loss: 1.0045 - acc: 0.5142 - val_loss: 1.0288 - val_acc: 0.5061\n",
            "Epoch 75/150 - 0.22s - loss: 1.0035 - acc: 0.5153 - val_loss: 1.0279 - val_acc: 0.5061\n",
            "Epoch 76/150 - 0.22s - loss: 1.0028 - acc: 0.5153 - val_loss: 1.0270 - val_acc: 0.5020\n",
            "Epoch 77/150 - 0.24s - loss: 1.0019 - acc: 0.5164 - val_loss: 1.0263 - val_acc: 0.5000\n",
            "Epoch 78/150 - 0.24s - loss: 1.0008 - acc: 0.5175 - val_loss: 1.0258 - val_acc: 0.5081\n",
            "Epoch 79/150 - 0.27s - loss: 0.9999 - acc: 0.5180 - val_loss: 1.0251 - val_acc: 0.5081\n",
            "Epoch 80/150 - 0.21s - loss: 0.9991 - acc: 0.5175 - val_loss: 1.0249 - val_acc: 0.5142\n",
            "Epoch 81/150 - 0.23s - loss: 0.9982 - acc: 0.5211 - val_loss: 1.0235 - val_acc: 0.5101\n",
            "Epoch 82/150 - 0.21s - loss: 0.9975 - acc: 0.5193 - val_loss: 1.0229 - val_acc: 0.5162\n",
            "Epoch 83/150 - 0.25s - loss: 0.9964 - acc: 0.5182 - val_loss: 1.0223 - val_acc: 0.5081\n",
            "Epoch 84/150 - 0.23s - loss: 0.9957 - acc: 0.5178 - val_loss: 1.0225 - val_acc: 0.5121\n",
            "Epoch 85/150 - 0.25s - loss: 0.9947 - acc: 0.5211 - val_loss: 1.0209 - val_acc: 0.5202\n",
            "Epoch 86/150 - 0.21s - loss: 0.9938 - acc: 0.5238 - val_loss: 1.0201 - val_acc: 0.5182\n",
            "Epoch 87/150 - 0.23s - loss: 0.9928 - acc: 0.5241 - val_loss: 1.0196 - val_acc: 0.5121\n",
            "Epoch 88/150 - 0.23s - loss: 0.9919 - acc: 0.5232 - val_loss: 1.0188 - val_acc: 0.5142\n",
            "Epoch 89/150 - 0.23s - loss: 0.9914 - acc: 0.5243 - val_loss: 1.0178 - val_acc: 0.5202\n",
            "Epoch 90/150 - 0.22s - loss: 0.9902 - acc: 0.5245 - val_loss: 1.0177 - val_acc: 0.5263\n",
            "Epoch 91/150 - 0.23s - loss: 0.9894 - acc: 0.5227 - val_loss: 1.0173 - val_acc: 0.5162\n",
            "Epoch 92/150 - 0.25s - loss: 0.9884 - acc: 0.5241 - val_loss: 1.0163 - val_acc: 0.5243\n",
            "Epoch 93/150 - 0.23s - loss: 0.9875 - acc: 0.5281 - val_loss: 1.0152 - val_acc: 0.5223\n",
            "Epoch 94/150 - 0.22s - loss: 0.9867 - acc: 0.5263 - val_loss: 1.0146 - val_acc: 0.5243\n",
            "Epoch 95/150 - 0.22s - loss: 0.9861 - acc: 0.5279 - val_loss: 1.0134 - val_acc: 0.5243\n",
            "Epoch 96/150 - 0.22s - loss: 0.9851 - acc: 0.5265 - val_loss: 1.0136 - val_acc: 0.5243\n",
            "Epoch 97/150 - 0.23s - loss: 0.9842 - acc: 0.5274 - val_loss: 1.0128 - val_acc: 0.5263\n",
            "Epoch 98/150 - 0.22s - loss: 0.9834 - acc: 0.5250 - val_loss: 1.0123 - val_acc: 0.5243\n",
            "Epoch 99/150 - 0.24s - loss: 0.9826 - acc: 0.5286 - val_loss: 1.0112 - val_acc: 0.5223\n",
            "Epoch 100/150 - 0.21s - loss: 0.9816 - acc: 0.5279 - val_loss: 1.0105 - val_acc: 0.5263\n",
            "Epoch 101/150 - 0.22s - loss: 0.9818 - acc: 0.5315 - val_loss: 1.0099 - val_acc: 0.5223\n",
            "Epoch 102/150 - 0.22s - loss: 0.9804 - acc: 0.5290 - val_loss: 1.0094 - val_acc: 0.5101\n",
            "Epoch 103/150 - 0.24s - loss: 0.9793 - acc: 0.5306 - val_loss: 1.0078 - val_acc: 0.5283\n",
            "Epoch 104/150 - 0.22s - loss: 0.9785 - acc: 0.5315 - val_loss: 1.0070 - val_acc: 0.5283\n",
            "Epoch 105/150 - 0.23s - loss: 0.9781 - acc: 0.5313 - val_loss: 1.0078 - val_acc: 0.5142\n",
            "Epoch 106/150 - 0.24s - loss: 0.9769 - acc: 0.5324 - val_loss: 1.0068 - val_acc: 0.5304\n",
            "Epoch 107/150 - 0.23s - loss: 0.9759 - acc: 0.5349 - val_loss: 1.0054 - val_acc: 0.5223\n",
            "Epoch 108/150 - 0.24s - loss: 0.9759 - acc: 0.5324 - val_loss: 1.0048 - val_acc: 0.5243\n",
            "Epoch 109/150 - 0.22s - loss: 0.9747 - acc: 0.5344 - val_loss: 1.0037 - val_acc: 0.5283\n",
            "Epoch 110/150 - 0.22s - loss: 0.9735 - acc: 0.5346 - val_loss: 1.0030 - val_acc: 0.5324\n",
            "Epoch 111/150 - 0.23s - loss: 0.9728 - acc: 0.5349 - val_loss: 1.0024 - val_acc: 0.5283\n",
            "Epoch 112/150 - 0.22s - loss: 0.9720 - acc: 0.5367 - val_loss: 1.0023 - val_acc: 0.5202\n",
            "Epoch 113/150 - 0.28s - loss: 0.9716 - acc: 0.5349 - val_loss: 1.0013 - val_acc: 0.5324\n",
            "Epoch 114/150 - 0.21s - loss: 0.9707 - acc: 0.5378 - val_loss: 0.9999 - val_acc: 0.5304\n",
            "Epoch 115/150 - 0.23s - loss: 0.9698 - acc: 0.5385 - val_loss: 0.9994 - val_acc: 0.5304\n",
            "Epoch 116/150 - 0.22s - loss: 0.9689 - acc: 0.5400 - val_loss: 0.9988 - val_acc: 0.5304\n",
            "Epoch 117/150 - 0.22s - loss: 0.9682 - acc: 0.5398 - val_loss: 0.9981 - val_acc: 0.5324\n",
            "Epoch 118/150 - 0.22s - loss: 0.9674 - acc: 0.5412 - val_loss: 0.9974 - val_acc: 0.5324\n",
            "Epoch 119/150 - 0.23s - loss: 0.9667 - acc: 0.5394 - val_loss: 0.9976 - val_acc: 0.5182\n",
            "Epoch 120/150 - 0.24s - loss: 0.9658 - acc: 0.5409 - val_loss: 0.9966 - val_acc: 0.5263\n",
            "Epoch 121/150 - 0.22s - loss: 0.9652 - acc: 0.5405 - val_loss: 0.9960 - val_acc: 0.5223\n",
            "Epoch 122/150 - 0.22s - loss: 0.9645 - acc: 0.5436 - val_loss: 0.9948 - val_acc: 0.5344\n",
            "Epoch 123/150 - 0.26s - loss: 0.9650 - acc: 0.5400 - val_loss: 0.9970 - val_acc: 0.5243\n",
            "Epoch 124/150 - 0.22s - loss: 0.9632 - acc: 0.5416 - val_loss: 0.9949 - val_acc: 0.5243\n",
            "Epoch 125/150 - 0.23s - loss: 0.9623 - acc: 0.5409 - val_loss: 0.9940 - val_acc: 0.5385\n",
            "Epoch 126/150 - 0.22s - loss: 0.9624 - acc: 0.5421 - val_loss: 0.9927 - val_acc: 0.5364\n",
            "Epoch 127/150 - 0.25s - loss: 0.9608 - acc: 0.5409 - val_loss: 0.9923 - val_acc: 0.5304\n",
            "Epoch 128/150 - 0.22s - loss: 0.9601 - acc: 0.5427 - val_loss: 0.9914 - val_acc: 0.5304\n",
            "Epoch 129/150 - 0.24s - loss: 0.9597 - acc: 0.5472 - val_loss: 0.9904 - val_acc: 0.5385\n",
            "Epoch 130/150 - 0.22s - loss: 0.9588 - acc: 0.5463 - val_loss: 0.9899 - val_acc: 0.5364\n",
            "Epoch 131/150 - 0.23s - loss: 0.9580 - acc: 0.5432 - val_loss: 0.9901 - val_acc: 0.5445\n",
            "Epoch 132/150 - 0.22s - loss: 0.9572 - acc: 0.5452 - val_loss: 0.9891 - val_acc: 0.5405\n",
            "Epoch 133/150 - 0.24s - loss: 0.9566 - acc: 0.5450 - val_loss: 0.9885 - val_acc: 0.5324\n",
            "Epoch 134/150 - 0.24s - loss: 0.9561 - acc: 0.5443 - val_loss: 0.9886 - val_acc: 0.5445\n",
            "Epoch 135/150 - 0.22s - loss: 0.9552 - acc: 0.5459 - val_loss: 0.9875 - val_acc: 0.5445\n",
            "Epoch 136/150 - 0.22s - loss: 0.9553 - acc: 0.5479 - val_loss: 0.9864 - val_acc: 0.5385\n",
            "Epoch 137/150 - 0.26s - loss: 0.9539 - acc: 0.5457 - val_loss: 0.9866 - val_acc: 0.5445\n",
            "Epoch 138/150 - 0.21s - loss: 0.9532 - acc: 0.5488 - val_loss: 0.9858 - val_acc: 0.5445\n",
            "Epoch 139/150 - 0.23s - loss: 0.9526 - acc: 0.5466 - val_loss: 0.9855 - val_acc: 0.5466\n",
            "Epoch 140/150 - 0.23s - loss: 0.9530 - acc: 0.5495 - val_loss: 0.9852 - val_acc: 0.5466\n",
            "Epoch 141/150 - 0.25s - loss: 0.9516 - acc: 0.5504 - val_loss: 0.9839 - val_acc: 0.5506\n",
            "Epoch 142/150 - 0.22s - loss: 0.9509 - acc: 0.5484 - val_loss: 0.9838 - val_acc: 0.5445\n",
            "Epoch 143/150 - 0.24s - loss: 0.9500 - acc: 0.5493 - val_loss: 0.9828 - val_acc: 0.5466\n",
            "Epoch 144/150 - 0.25s - loss: 0.9493 - acc: 0.5490 - val_loss: 0.9827 - val_acc: 0.5526\n",
            "Epoch 145/150 - 0.22s - loss: 0.9491 - acc: 0.5486 - val_loss: 0.9821 - val_acc: 0.5486\n",
            "Epoch 146/150 - 0.22s - loss: 0.9485 - acc: 0.5484 - val_loss: 0.9815 - val_acc: 0.5486\n",
            "Epoch 147/150 - 0.22s - loss: 0.9479 - acc: 0.5506 - val_loss: 0.9814 - val_acc: 0.5466\n",
            "Epoch 148/150 - 0.24s - loss: 0.9468 - acc: 0.5499 - val_loss: 0.9801 - val_acc: 0.5607\n",
            "Epoch 149/150 - 0.22s - loss: 0.9466 - acc: 0.5493 - val_loss: 0.9803 - val_acc: 0.5506\n",
            "Epoch 150/150 - 0.22s - loss: 0.9455 - acc: 0.5526 - val_loss: 0.9799 - val_acc: 0.5506\n",
            "\n",
            "Combination 208/252:\n",
            "Hidden Layers: [256, 128, 64], Activation: tanh, Learning Rate: 0.001, Batch Size: 64, Epochs: 50\n",
            "Epoch 1/50 - 0.19s - loss: 1.0969 - acc: 0.3792 - val_loss: 1.1001 - val_acc: 0.3704\n",
            "Epoch 2/50 - 0.18s - loss: 1.0919 - acc: 0.3905 - val_loss: 1.0970 - val_acc: 0.3745\n",
            "Epoch 3/50 - 0.21s - loss: 1.0898 - acc: 0.3986 - val_loss: 1.0959 - val_acc: 0.3826\n",
            "Epoch 4/50 - 0.18s - loss: 1.0883 - acc: 0.4013 - val_loss: 1.0949 - val_acc: 0.3704\n",
            "Epoch 5/50 - 0.19s - loss: 1.0870 - acc: 0.4040 - val_loss: 1.0940 - val_acc: 0.3664\n",
            "Epoch 6/50 - 0.18s - loss: 1.0858 - acc: 0.4044 - val_loss: 1.0931 - val_acc: 0.3664\n",
            "Epoch 7/50 - 0.22s - loss: 1.0847 - acc: 0.4067 - val_loss: 1.0923 - val_acc: 0.3765\n",
            "Epoch 8/50 - 0.19s - loss: 1.0835 - acc: 0.4105 - val_loss: 1.0913 - val_acc: 0.3927\n",
            "Epoch 9/50 - 0.19s - loss: 1.0824 - acc: 0.4121 - val_loss: 1.0903 - val_acc: 0.3927\n",
            "Epoch 10/50 - 0.18s - loss: 1.0814 - acc: 0.4150 - val_loss: 1.0894 - val_acc: 0.3968\n",
            "Epoch 11/50 - 0.19s - loss: 1.0803 - acc: 0.4195 - val_loss: 1.0886 - val_acc: 0.3968\n",
            "Epoch 12/50 - 0.18s - loss: 1.0793 - acc: 0.4204 - val_loss: 1.0878 - val_acc: 0.3927\n",
            "Epoch 13/50 - 0.19s - loss: 1.0784 - acc: 0.4242 - val_loss: 1.0870 - val_acc: 0.3907\n",
            "Epoch 14/50 - 0.19s - loss: 1.0774 - acc: 0.4233 - val_loss: 1.0861 - val_acc: 0.3947\n",
            "Epoch 15/50 - 0.19s - loss: 1.0764 - acc: 0.4265 - val_loss: 1.0853 - val_acc: 0.4008\n",
            "Epoch 16/50 - 0.19s - loss: 1.0755 - acc: 0.4278 - val_loss: 1.0845 - val_acc: 0.3988\n",
            "Epoch 17/50 - 0.20s - loss: 1.0746 - acc: 0.4298 - val_loss: 1.0839 - val_acc: 0.4008\n",
            "Epoch 18/50 - 0.19s - loss: 1.0737 - acc: 0.4307 - val_loss: 1.0831 - val_acc: 0.4049\n",
            "Epoch 19/50 - 0.20s - loss: 1.0729 - acc: 0.4316 - val_loss: 1.0824 - val_acc: 0.4008\n",
            "Epoch 20/50 - 0.19s - loss: 1.0720 - acc: 0.4321 - val_loss: 1.0817 - val_acc: 0.4008\n",
            "Epoch 21/50 - 0.21s - loss: 1.0712 - acc: 0.4348 - val_loss: 1.0810 - val_acc: 0.4028\n",
            "Epoch 22/50 - 0.18s - loss: 1.0704 - acc: 0.4368 - val_loss: 1.0804 - val_acc: 0.4049\n",
            "Epoch 23/50 - 0.21s - loss: 1.0696 - acc: 0.4366 - val_loss: 1.0799 - val_acc: 0.4089\n",
            "Epoch 24/50 - 0.18s - loss: 1.0688 - acc: 0.4377 - val_loss: 1.0792 - val_acc: 0.4130\n",
            "Epoch 25/50 - 0.19s - loss: 1.0680 - acc: 0.4386 - val_loss: 1.0787 - val_acc: 0.4150\n",
            "Epoch 26/50 - 0.18s - loss: 1.0673 - acc: 0.4390 - val_loss: 1.0781 - val_acc: 0.4211\n",
            "Epoch 27/50 - 0.20s - loss: 1.0665 - acc: 0.4426 - val_loss: 1.0774 - val_acc: 0.4231\n",
            "Epoch 28/50 - 0.19s - loss: 1.0658 - acc: 0.4435 - val_loss: 1.0769 - val_acc: 0.4271\n",
            "Epoch 29/50 - 0.19s - loss: 1.0650 - acc: 0.4453 - val_loss: 1.0762 - val_acc: 0.4312\n",
            "Epoch 30/50 - 0.19s - loss: 1.0643 - acc: 0.4444 - val_loss: 1.0757 - val_acc: 0.4332\n",
            "Epoch 31/50 - 0.21s - loss: 1.0636 - acc: 0.4487 - val_loss: 1.0751 - val_acc: 0.4352\n",
            "Epoch 32/50 - 0.19s - loss: 1.0629 - acc: 0.4458 - val_loss: 1.0744 - val_acc: 0.4393\n",
            "Epoch 33/50 - 0.19s - loss: 1.0622 - acc: 0.4492 - val_loss: 1.0739 - val_acc: 0.4393\n",
            "Epoch 34/50 - 0.18s - loss: 1.0615 - acc: 0.4483 - val_loss: 1.0733 - val_acc: 0.4352\n",
            "Epoch 35/50 - 0.22s - loss: 1.0608 - acc: 0.4501 - val_loss: 1.0728 - val_acc: 0.4332\n",
            "Epoch 36/50 - 0.18s - loss: 1.0602 - acc: 0.4512 - val_loss: 1.0722 - val_acc: 0.4393\n",
            "Epoch 37/50 - 0.19s - loss: 1.0595 - acc: 0.4550 - val_loss: 1.0718 - val_acc: 0.4453\n",
            "Epoch 38/50 - 0.18s - loss: 1.0589 - acc: 0.4528 - val_loss: 1.0714 - val_acc: 0.4433\n",
            "Epoch 39/50 - 0.20s - loss: 1.0582 - acc: 0.4516 - val_loss: 1.0708 - val_acc: 0.4494\n",
            "Epoch 40/50 - 0.18s - loss: 1.0576 - acc: 0.4564 - val_loss: 1.0704 - val_acc: 0.4474\n",
            "Epoch 41/50 - 0.19s - loss: 1.0570 - acc: 0.4584 - val_loss: 1.0700 - val_acc: 0.4555\n",
            "Epoch 42/50 - 0.18s - loss: 1.0564 - acc: 0.4595 - val_loss: 1.0696 - val_acc: 0.4514\n",
            "Epoch 43/50 - 0.21s - loss: 1.0557 - acc: 0.4584 - val_loss: 1.0689 - val_acc: 0.4534\n",
            "Epoch 44/50 - 0.19s - loss: 1.0551 - acc: 0.4586 - val_loss: 1.0684 - val_acc: 0.4514\n",
            "Epoch 45/50 - 0.19s - loss: 1.0545 - acc: 0.4604 - val_loss: 1.0679 - val_acc: 0.4514\n",
            "Epoch 46/50 - 0.19s - loss: 1.0539 - acc: 0.4600 - val_loss: 1.0674 - val_acc: 0.4514\n",
            "Epoch 47/50 - 0.19s - loss: 1.0533 - acc: 0.4602 - val_loss: 1.0670 - val_acc: 0.4514\n",
            "Epoch 48/50 - 0.18s - loss: 1.0527 - acc: 0.4636 - val_loss: 1.0666 - val_acc: 0.4575\n",
            "Epoch 49/50 - 0.19s - loss: 1.0521 - acc: 0.4642 - val_loss: 1.0662 - val_acc: 0.4555\n",
            "Epoch 50/50 - 0.22s - loss: 1.0515 - acc: 0.4647 - val_loss: 1.0658 - val_acc: 0.4595\n",
            "\n",
            "Combination 209/252:\n",
            "Hidden Layers: [256, 128, 64], Activation: tanh, Learning Rate: 0.001, Batch Size: 64, Epochs: 100\n",
            "Epoch 1/100 - 0.19s - loss: 1.1076 - acc: 0.3167 - val_loss: 1.1090 - val_acc: 0.2895\n",
            "Epoch 2/100 - 0.19s - loss: 1.1040 - acc: 0.3142 - val_loss: 1.1054 - val_acc: 0.3077\n",
            "Epoch 3/100 - 0.19s - loss: 1.1018 - acc: 0.3192 - val_loss: 1.1032 - val_acc: 0.3300\n",
            "Epoch 4/100 - 0.18s - loss: 1.1000 - acc: 0.3225 - val_loss: 1.1016 - val_acc: 0.3340\n",
            "Epoch 5/100 - 0.18s - loss: 1.0983 - acc: 0.3327 - val_loss: 1.1003 - val_acc: 0.3381\n",
            "Epoch 6/100 - 0.18s - loss: 1.0968 - acc: 0.3426 - val_loss: 1.0989 - val_acc: 0.3623\n",
            "Epoch 7/100 - 0.20s - loss: 1.0953 - acc: 0.3540 - val_loss: 1.0976 - val_acc: 0.3623\n",
            "Epoch 8/100 - 0.18s - loss: 1.0939 - acc: 0.3617 - val_loss: 1.0964 - val_acc: 0.3684\n",
            "Epoch 9/100 - 0.19s - loss: 1.0926 - acc: 0.3680 - val_loss: 1.0953 - val_acc: 0.3704\n",
            "Epoch 10/100 - 0.18s - loss: 1.0912 - acc: 0.3785 - val_loss: 1.0941 - val_acc: 0.3765\n",
            "Epoch 11/100 - 0.24s - loss: 1.0900 - acc: 0.3815 - val_loss: 1.0931 - val_acc: 0.3826\n",
            "Epoch 12/100 - 0.18s - loss: 1.0888 - acc: 0.3833 - val_loss: 1.0921 - val_acc: 0.3927\n",
            "Epoch 13/100 - 0.19s - loss: 1.0876 - acc: 0.3875 - val_loss: 1.0912 - val_acc: 0.3968\n",
            "Epoch 14/100 - 0.19s - loss: 1.0865 - acc: 0.3889 - val_loss: 1.0902 - val_acc: 0.3927\n",
            "Epoch 15/100 - 0.20s - loss: 1.0854 - acc: 0.3954 - val_loss: 1.0894 - val_acc: 0.3907\n",
            "Epoch 16/100 - 0.18s - loss: 1.0843 - acc: 0.4004 - val_loss: 1.0884 - val_acc: 0.3806\n",
            "Epoch 17/100 - 0.19s - loss: 1.0833 - acc: 0.4051 - val_loss: 1.0876 - val_acc: 0.3826\n",
            "Epoch 18/100 - 0.18s - loss: 1.0822 - acc: 0.4058 - val_loss: 1.0868 - val_acc: 0.3785\n",
            "Epoch 19/100 - 0.19s - loss: 1.0812 - acc: 0.4100 - val_loss: 1.0860 - val_acc: 0.3765\n",
            "Epoch 20/100 - 0.18s - loss: 1.0803 - acc: 0.4127 - val_loss: 1.0852 - val_acc: 0.3765\n",
            "Epoch 21/100 - 0.19s - loss: 1.0793 - acc: 0.4157 - val_loss: 1.0845 - val_acc: 0.3866\n",
            "Epoch 22/100 - 0.18s - loss: 1.0784 - acc: 0.4179 - val_loss: 1.0838 - val_acc: 0.3846\n",
            "Epoch 23/100 - 0.19s - loss: 1.0775 - acc: 0.4193 - val_loss: 1.0830 - val_acc: 0.3846\n",
            "Epoch 24/100 - 0.18s - loss: 1.0766 - acc: 0.4213 - val_loss: 1.0824 - val_acc: 0.3826\n",
            "Epoch 25/100 - 0.21s - loss: 1.0758 - acc: 0.4224 - val_loss: 1.0817 - val_acc: 0.3826\n",
            "Epoch 26/100 - 0.18s - loss: 1.0749 - acc: 0.4258 - val_loss: 1.0810 - val_acc: 0.3907\n",
            "Epoch 27/100 - 0.19s - loss: 1.0741 - acc: 0.4271 - val_loss: 1.0805 - val_acc: 0.3907\n",
            "Epoch 28/100 - 0.18s - loss: 1.0733 - acc: 0.4280 - val_loss: 1.0798 - val_acc: 0.3947\n",
            "Epoch 29/100 - 0.19s - loss: 1.0725 - acc: 0.4300 - val_loss: 1.0793 - val_acc: 0.3947\n",
            "Epoch 30/100 - 0.18s - loss: 1.0717 - acc: 0.4370 - val_loss: 1.0785 - val_acc: 0.4028\n",
            "Epoch 31/100 - 0.21s - loss: 1.0709 - acc: 0.4404 - val_loss: 1.0779 - val_acc: 0.4089\n",
            "Epoch 32/100 - 0.18s - loss: 1.0702 - acc: 0.4393 - val_loss: 1.0774 - val_acc: 0.4190\n",
            "Epoch 33/100 - 0.19s - loss: 1.0694 - acc: 0.4402 - val_loss: 1.0768 - val_acc: 0.4109\n",
            "Epoch 34/100 - 0.18s - loss: 1.0686 - acc: 0.4458 - val_loss: 1.0762 - val_acc: 0.4251\n",
            "Epoch 35/100 - 0.19s - loss: 1.0679 - acc: 0.4471 - val_loss: 1.0756 - val_acc: 0.4271\n",
            "Epoch 36/100 - 0.18s - loss: 1.0672 - acc: 0.4492 - val_loss: 1.0750 - val_acc: 0.4251\n",
            "Epoch 37/100 - 0.19s - loss: 1.0664 - acc: 0.4503 - val_loss: 1.0745 - val_acc: 0.4312\n",
            "Epoch 38/100 - 0.18s - loss: 1.0657 - acc: 0.4514 - val_loss: 1.0740 - val_acc: 0.4372\n",
            "Epoch 39/100 - 0.20s - loss: 1.0650 - acc: 0.4530 - val_loss: 1.0736 - val_acc: 0.4433\n",
            "Epoch 40/100 - 0.19s - loss: 1.0643 - acc: 0.4519 - val_loss: 1.0730 - val_acc: 0.4433\n",
            "Epoch 41/100 - 0.19s - loss: 1.0636 - acc: 0.4557 - val_loss: 1.0724 - val_acc: 0.4413\n",
            "Epoch 42/100 - 0.18s - loss: 1.0629 - acc: 0.4570 - val_loss: 1.0719 - val_acc: 0.4433\n",
            "Epoch 43/100 - 0.19s - loss: 1.0623 - acc: 0.4575 - val_loss: 1.0715 - val_acc: 0.4474\n",
            "Epoch 44/100 - 0.18s - loss: 1.0616 - acc: 0.4600 - val_loss: 1.0710 - val_acc: 0.4575\n",
            "Epoch 45/100 - 0.19s - loss: 1.0609 - acc: 0.4622 - val_loss: 1.0704 - val_acc: 0.4656\n",
            "Epoch 46/100 - 0.19s - loss: 1.0603 - acc: 0.4645 - val_loss: 1.0700 - val_acc: 0.4676\n",
            "Epoch 47/100 - 0.19s - loss: 1.0596 - acc: 0.4647 - val_loss: 1.0696 - val_acc: 0.4676\n",
            "Epoch 48/100 - 0.18s - loss: 1.0590 - acc: 0.4647 - val_loss: 1.0693 - val_acc: 0.4595\n",
            "Epoch 49/100 - 0.18s - loss: 1.0583 - acc: 0.4638 - val_loss: 1.0687 - val_acc: 0.4636\n",
            "Epoch 50/100 - 0.18s - loss: 1.0577 - acc: 0.4660 - val_loss: 1.0682 - val_acc: 0.4595\n",
            "Epoch 51/100 - 0.21s - loss: 1.0570 - acc: 0.4674 - val_loss: 1.0678 - val_acc: 0.4676\n",
            "Epoch 52/100 - 0.18s - loss: 1.0564 - acc: 0.4678 - val_loss: 1.0674 - val_acc: 0.4656\n",
            "Epoch 53/100 - 0.20s - loss: 1.0558 - acc: 0.4681 - val_loss: 1.0670 - val_acc: 0.4636\n",
            "Epoch 54/100 - 0.18s - loss: 1.0552 - acc: 0.4685 - val_loss: 1.0665 - val_acc: 0.4676\n",
            "Epoch 55/100 - 0.20s - loss: 1.0545 - acc: 0.4703 - val_loss: 1.0661 - val_acc: 0.4636\n",
            "Epoch 56/100 - 0.18s - loss: 1.0539 - acc: 0.4712 - val_loss: 1.0657 - val_acc: 0.4636\n",
            "Epoch 57/100 - 0.19s - loss: 1.0533 - acc: 0.4714 - val_loss: 1.0652 - val_acc: 0.4636\n",
            "Epoch 58/100 - 0.18s - loss: 1.0527 - acc: 0.4717 - val_loss: 1.0647 - val_acc: 0.4636\n",
            "Epoch 59/100 - 0.19s - loss: 1.0521 - acc: 0.4732 - val_loss: 1.0643 - val_acc: 0.4636\n",
            "Epoch 60/100 - 0.18s - loss: 1.0515 - acc: 0.4719 - val_loss: 1.0639 - val_acc: 0.4717\n",
            "Epoch 61/100 - 0.19s - loss: 1.0509 - acc: 0.4714 - val_loss: 1.0634 - val_acc: 0.4757\n",
            "Epoch 62/100 - 0.18s - loss: 1.0503 - acc: 0.4737 - val_loss: 1.0631 - val_acc: 0.4656\n",
            "Epoch 63/100 - 0.19s - loss: 1.0498 - acc: 0.4753 - val_loss: 1.0627 - val_acc: 0.4737\n",
            "Epoch 64/100 - 0.18s - loss: 1.0492 - acc: 0.4759 - val_loss: 1.0623 - val_acc: 0.4676\n",
            "Epoch 65/100 - 0.19s - loss: 1.0486 - acc: 0.4753 - val_loss: 1.0618 - val_acc: 0.4717\n",
            "Epoch 66/100 - 0.18s - loss: 1.0480 - acc: 0.4766 - val_loss: 1.0615 - val_acc: 0.4696\n",
            "Epoch 67/100 - 0.21s - loss: 1.0475 - acc: 0.4759 - val_loss: 1.0611 - val_acc: 0.4717\n",
            "Epoch 68/100 - 0.18s - loss: 1.0469 - acc: 0.4789 - val_loss: 1.0607 - val_acc: 0.4696\n",
            "Epoch 69/100 - 0.18s - loss: 1.0463 - acc: 0.4786 - val_loss: 1.0603 - val_acc: 0.4737\n",
            "Epoch 70/100 - 0.18s - loss: 1.0458 - acc: 0.4807 - val_loss: 1.0599 - val_acc: 0.4757\n",
            "Epoch 71/100 - 0.21s - loss: 1.0452 - acc: 0.4813 - val_loss: 1.0595 - val_acc: 0.4737\n",
            "Epoch 72/100 - 0.18s - loss: 1.0447 - acc: 0.4813 - val_loss: 1.0591 - val_acc: 0.4777\n",
            "Epoch 73/100 - 0.22s - loss: 1.0441 - acc: 0.4827 - val_loss: 1.0587 - val_acc: 0.4777\n",
            "Epoch 74/100 - 0.19s - loss: 1.0436 - acc: 0.4813 - val_loss: 1.0584 - val_acc: 0.4798\n",
            "Epoch 75/100 - 0.19s - loss: 1.0430 - acc: 0.4813 - val_loss: 1.0579 - val_acc: 0.4737\n",
            "Epoch 76/100 - 0.18s - loss: 1.0425 - acc: 0.4838 - val_loss: 1.0577 - val_acc: 0.4777\n",
            "Epoch 77/100 - 0.20s - loss: 1.0419 - acc: 0.4845 - val_loss: 1.0572 - val_acc: 0.4717\n",
            "Epoch 78/100 - 0.18s - loss: 1.0414 - acc: 0.4834 - val_loss: 1.0569 - val_acc: 0.4717\n",
            "Epoch 79/100 - 0.18s - loss: 1.0409 - acc: 0.4831 - val_loss: 1.0566 - val_acc: 0.4798\n",
            "Epoch 80/100 - 0.18s - loss: 1.0403 - acc: 0.4829 - val_loss: 1.0563 - val_acc: 0.4798\n",
            "Epoch 81/100 - 0.20s - loss: 1.0398 - acc: 0.4843 - val_loss: 1.0558 - val_acc: 0.4717\n",
            "Epoch 82/100 - 0.18s - loss: 1.0393 - acc: 0.4856 - val_loss: 1.0555 - val_acc: 0.4777\n",
            "Epoch 83/100 - 0.18s - loss: 1.0387 - acc: 0.4858 - val_loss: 1.0551 - val_acc: 0.4777\n",
            "Epoch 84/100 - 0.17s - loss: 1.0382 - acc: 0.4847 - val_loss: 1.0548 - val_acc: 0.4777\n",
            "Epoch 85/100 - 0.18s - loss: 1.0377 - acc: 0.4865 - val_loss: 1.0545 - val_acc: 0.4818\n",
            "Epoch 86/100 - 0.17s - loss: 1.0372 - acc: 0.4861 - val_loss: 1.0543 - val_acc: 0.4798\n",
            "Epoch 87/100 - 0.18s - loss: 1.0367 - acc: 0.4849 - val_loss: 1.0541 - val_acc: 0.4757\n",
            "Epoch 88/100 - 0.20s - loss: 1.0362 - acc: 0.4863 - val_loss: 1.0536 - val_acc: 0.4818\n",
            "Epoch 89/100 - 0.20s - loss: 1.0356 - acc: 0.4885 - val_loss: 1.0531 - val_acc: 0.4798\n",
            "Epoch 90/100 - 0.17s - loss: 1.0351 - acc: 0.4870 - val_loss: 1.0527 - val_acc: 0.4777\n",
            "Epoch 91/100 - 0.19s - loss: 1.0346 - acc: 0.4865 - val_loss: 1.0524 - val_acc: 0.4777\n",
            "Epoch 92/100 - 0.18s - loss: 1.0341 - acc: 0.4879 - val_loss: 1.0519 - val_acc: 0.4818\n",
            "Epoch 93/100 - 0.18s - loss: 1.0336 - acc: 0.4876 - val_loss: 1.0517 - val_acc: 0.4798\n",
            "Epoch 94/100 - 0.17s - loss: 1.0331 - acc: 0.4894 - val_loss: 1.0514 - val_acc: 0.4838\n",
            "Epoch 95/100 - 0.22s - loss: 1.0326 - acc: 0.4910 - val_loss: 1.0511 - val_acc: 0.4798\n",
            "Epoch 96/100 - 0.19s - loss: 1.0321 - acc: 0.4912 - val_loss: 1.0507 - val_acc: 0.4838\n",
            "Epoch 97/100 - 0.19s - loss: 1.0316 - acc: 0.4910 - val_loss: 1.0503 - val_acc: 0.4818\n",
            "Epoch 98/100 - 0.18s - loss: 1.0311 - acc: 0.4912 - val_loss: 1.0502 - val_acc: 0.4858\n",
            "Epoch 99/100 - 0.19s - loss: 1.0306 - acc: 0.4924 - val_loss: 1.0498 - val_acc: 0.4858\n",
            "Epoch 100/100 - 0.18s - loss: 1.0301 - acc: 0.4924 - val_loss: 1.0494 - val_acc: 0.4899\n",
            "\n",
            "Combination 210/252:\n",
            "Hidden Layers: [256, 128, 64], Activation: tanh, Learning Rate: 0.001, Batch Size: 64, Epochs: 150\n",
            "Epoch 1/150 - 0.19s - loss: 1.0993 - acc: 0.3556 - val_loss: 1.1035 - val_acc: 0.3421\n",
            "Epoch 2/150 - 0.18s - loss: 1.0947 - acc: 0.3774 - val_loss: 1.0989 - val_acc: 0.3441\n",
            "Epoch 3/150 - 0.18s - loss: 1.0921 - acc: 0.3839 - val_loss: 1.0963 - val_acc: 0.3664\n",
            "Epoch 4/150 - 0.18s - loss: 1.0901 - acc: 0.3947 - val_loss: 1.0943 - val_acc: 0.3583\n",
            "Epoch 5/150 - 0.19s - loss: 1.0882 - acc: 0.4010 - val_loss: 1.0925 - val_acc: 0.3664\n",
            "Epoch 6/150 - 0.18s - loss: 1.0864 - acc: 0.4049 - val_loss: 1.0909 - val_acc: 0.3704\n",
            "Epoch 7/150 - 0.18s - loss: 1.0847 - acc: 0.4112 - val_loss: 1.0893 - val_acc: 0.3947\n",
            "Epoch 8/150 - 0.17s - loss: 1.0830 - acc: 0.4132 - val_loss: 1.0881 - val_acc: 0.4028\n",
            "Epoch 9/150 - 0.22s - loss: 1.0815 - acc: 0.4213 - val_loss: 1.0866 - val_acc: 0.4190\n",
            "Epoch 10/150 - 0.18s - loss: 1.0800 - acc: 0.4235 - val_loss: 1.0855 - val_acc: 0.4231\n",
            "Epoch 11/150 - 0.19s - loss: 1.0785 - acc: 0.4274 - val_loss: 1.0841 - val_acc: 0.4170\n",
            "Epoch 12/150 - 0.17s - loss: 1.0771 - acc: 0.4325 - val_loss: 1.0829 - val_acc: 0.4231\n",
            "Epoch 13/150 - 0.19s - loss: 1.0758 - acc: 0.4375 - val_loss: 1.0818 - val_acc: 0.4291\n",
            "Epoch 14/150 - 0.18s - loss: 1.0745 - acc: 0.4395 - val_loss: 1.0804 - val_acc: 0.4291\n",
            "Epoch 15/150 - 0.18s - loss: 1.0732 - acc: 0.4429 - val_loss: 1.0795 - val_acc: 0.4312\n",
            "Epoch 16/150 - 0.18s - loss: 1.0720 - acc: 0.4447 - val_loss: 1.0784 - val_acc: 0.4332\n",
            "Epoch 17/150 - 0.21s - loss: 1.0709 - acc: 0.4467 - val_loss: 1.0774 - val_acc: 0.4393\n",
            "Epoch 18/150 - 0.18s - loss: 1.0697 - acc: 0.4453 - val_loss: 1.0766 - val_acc: 0.4332\n",
            "Epoch 19/150 - 0.21s - loss: 1.0687 - acc: 0.4451 - val_loss: 1.0754 - val_acc: 0.4534\n",
            "Epoch 20/150 - 0.18s - loss: 1.0676 - acc: 0.4474 - val_loss: 1.0746 - val_acc: 0.4534\n",
            "Epoch 21/150 - 0.20s - loss: 1.0665 - acc: 0.4489 - val_loss: 1.0737 - val_acc: 0.4534\n",
            "Epoch 22/150 - 0.18s - loss: 1.0655 - acc: 0.4501 - val_loss: 1.0729 - val_acc: 0.4534\n",
            "Epoch 23/150 - 0.20s - loss: 1.0645 - acc: 0.4525 - val_loss: 1.0722 - val_acc: 0.4575\n",
            "Epoch 24/150 - 0.19s - loss: 1.0636 - acc: 0.4537 - val_loss: 1.0714 - val_acc: 0.4514\n",
            "Epoch 25/150 - 0.19s - loss: 1.0627 - acc: 0.4539 - val_loss: 1.0707 - val_acc: 0.4555\n",
            "Epoch 26/150 - 0.18s - loss: 1.0617 - acc: 0.4566 - val_loss: 1.0700 - val_acc: 0.4555\n",
            "Epoch 27/150 - 0.19s - loss: 1.0609 - acc: 0.4579 - val_loss: 1.0693 - val_acc: 0.4555\n",
            "Epoch 28/150 - 0.18s - loss: 1.0600 - acc: 0.4568 - val_loss: 1.0686 - val_acc: 0.4534\n",
            "Epoch 29/150 - 0.19s - loss: 1.0591 - acc: 0.4566 - val_loss: 1.0677 - val_acc: 0.4555\n",
            "Epoch 30/150 - 0.18s - loss: 1.0583 - acc: 0.4557 - val_loss: 1.0670 - val_acc: 0.4534\n",
            "Epoch 31/150 - 0.21s - loss: 1.0575 - acc: 0.4552 - val_loss: 1.0663 - val_acc: 0.4555\n",
            "Epoch 32/150 - 0.19s - loss: 1.0567 - acc: 0.4570 - val_loss: 1.0658 - val_acc: 0.4534\n",
            "Epoch 33/150 - 0.19s - loss: 1.0559 - acc: 0.4577 - val_loss: 1.0652 - val_acc: 0.4514\n",
            "Epoch 34/150 - 0.18s - loss: 1.0552 - acc: 0.4586 - val_loss: 1.0644 - val_acc: 0.4534\n",
            "Epoch 35/150 - 0.18s - loss: 1.0544 - acc: 0.4600 - val_loss: 1.0640 - val_acc: 0.4575\n",
            "Epoch 36/150 - 0.18s - loss: 1.0537 - acc: 0.4604 - val_loss: 1.0633 - val_acc: 0.4595\n",
            "Epoch 37/150 - 0.19s - loss: 1.0530 - acc: 0.4600 - val_loss: 1.0627 - val_acc: 0.4636\n",
            "Epoch 38/150 - 0.18s - loss: 1.0522 - acc: 0.4620 - val_loss: 1.0623 - val_acc: 0.4575\n",
            "Epoch 39/150 - 0.19s - loss: 1.0515 - acc: 0.4613 - val_loss: 1.0618 - val_acc: 0.4595\n",
            "Epoch 40/150 - 0.19s - loss: 1.0509 - acc: 0.4627 - val_loss: 1.0613 - val_acc: 0.4555\n",
            "Epoch 41/150 - 0.19s - loss: 1.0502 - acc: 0.4647 - val_loss: 1.0606 - val_acc: 0.4534\n",
            "Epoch 42/150 - 0.18s - loss: 1.0495 - acc: 0.4651 - val_loss: 1.0602 - val_acc: 0.4534\n",
            "Epoch 43/150 - 0.19s - loss: 1.0488 - acc: 0.4651 - val_loss: 1.0597 - val_acc: 0.4595\n",
            "Epoch 44/150 - 0.17s - loss: 1.0482 - acc: 0.4640 - val_loss: 1.0590 - val_acc: 0.4615\n",
            "Epoch 45/150 - 0.19s - loss: 1.0475 - acc: 0.4669 - val_loss: 1.0586 - val_acc: 0.4656\n",
            "Epoch 46/150 - 0.18s - loss: 1.0469 - acc: 0.4676 - val_loss: 1.0582 - val_acc: 0.4615\n",
            "Epoch 47/150 - 0.18s - loss: 1.0463 - acc: 0.4681 - val_loss: 1.0577 - val_acc: 0.4656\n",
            "Epoch 48/150 - 0.18s - loss: 1.0456 - acc: 0.4676 - val_loss: 1.0572 - val_acc: 0.4656\n",
            "Epoch 49/150 - 0.19s - loss: 1.0450 - acc: 0.4687 - val_loss: 1.0566 - val_acc: 0.4615\n",
            "Epoch 50/150 - 0.17s - loss: 1.0444 - acc: 0.4692 - val_loss: 1.0563 - val_acc: 0.4595\n",
            "Epoch 51/150 - 0.24s - loss: 1.0438 - acc: 0.4714 - val_loss: 1.0560 - val_acc: 0.4696\n",
            "Epoch 52/150 - 0.18s - loss: 1.0432 - acc: 0.4701 - val_loss: 1.0552 - val_acc: 0.4717\n",
            "Epoch 53/150 - 0.18s - loss: 1.0426 - acc: 0.4719 - val_loss: 1.0549 - val_acc: 0.4717\n",
            "Epoch 54/150 - 0.18s - loss: 1.0420 - acc: 0.4719 - val_loss: 1.0543 - val_acc: 0.4717\n",
            "Epoch 55/150 - 0.18s - loss: 1.0414 - acc: 0.4726 - val_loss: 1.0539 - val_acc: 0.4737\n",
            "Epoch 56/150 - 0.18s - loss: 1.0408 - acc: 0.4732 - val_loss: 1.0535 - val_acc: 0.4717\n",
            "Epoch 57/150 - 0.19s - loss: 1.0403 - acc: 0.4750 - val_loss: 1.0535 - val_acc: 0.4696\n",
            "Epoch 58/150 - 0.18s - loss: 1.0397 - acc: 0.4746 - val_loss: 1.0528 - val_acc: 0.4717\n",
            "Epoch 59/150 - 0.18s - loss: 1.0391 - acc: 0.4757 - val_loss: 1.0523 - val_acc: 0.4757\n",
            "Epoch 60/150 - 0.18s - loss: 1.0385 - acc: 0.4762 - val_loss: 1.0518 - val_acc: 0.4798\n",
            "Epoch 61/150 - 0.19s - loss: 1.0379 - acc: 0.4757 - val_loss: 1.0512 - val_acc: 0.4777\n",
            "Epoch 62/150 - 0.18s - loss: 1.0374 - acc: 0.4741 - val_loss: 1.0508 - val_acc: 0.4777\n",
            "Epoch 63/150 - 0.19s - loss: 1.0368 - acc: 0.4750 - val_loss: 1.0504 - val_acc: 0.4798\n",
            "Epoch 64/150 - 0.18s - loss: 1.0363 - acc: 0.4762 - val_loss: 1.0500 - val_acc: 0.4777\n",
            "Epoch 65/150 - 0.20s - loss: 1.0357 - acc: 0.4773 - val_loss: 1.0498 - val_acc: 0.4798\n",
            "Epoch 66/150 - 0.17s - loss: 1.0351 - acc: 0.4773 - val_loss: 1.0493 - val_acc: 0.4818\n",
            "Epoch 67/150 - 0.18s - loss: 1.0346 - acc: 0.4768 - val_loss: 1.0488 - val_acc: 0.4798\n",
            "Epoch 68/150 - 0.17s - loss: 1.0340 - acc: 0.4782 - val_loss: 1.0485 - val_acc: 0.4858\n",
            "Epoch 69/150 - 0.19s - loss: 1.0335 - acc: 0.4793 - val_loss: 1.0479 - val_acc: 0.4879\n",
            "Epoch 70/150 - 0.18s - loss: 1.0329 - acc: 0.4789 - val_loss: 1.0477 - val_acc: 0.4818\n",
            "Epoch 71/150 - 0.19s - loss: 1.0324 - acc: 0.4804 - val_loss: 1.0472 - val_acc: 0.4858\n",
            "Epoch 72/150 - 0.18s - loss: 1.0319 - acc: 0.4822 - val_loss: 1.0466 - val_acc: 0.4919\n",
            "Epoch 73/150 - 0.19s - loss: 1.0313 - acc: 0.4820 - val_loss: 1.0463 - val_acc: 0.4879\n",
            "Epoch 74/150 - 0.17s - loss: 1.0309 - acc: 0.4829 - val_loss: 1.0457 - val_acc: 0.4939\n",
            "Epoch 75/150 - 0.18s - loss: 1.0303 - acc: 0.4836 - val_loss: 1.0454 - val_acc: 0.4960\n",
            "Epoch 76/150 - 0.17s - loss: 1.0298 - acc: 0.4870 - val_loss: 1.0450 - val_acc: 0.4919\n",
            "Epoch 77/150 - 0.19s - loss: 1.0292 - acc: 0.4854 - val_loss: 1.0448 - val_acc: 0.4899\n",
            "Epoch 78/150 - 0.18s - loss: 1.0286 - acc: 0.4840 - val_loss: 1.0444 - val_acc: 0.4960\n",
            "Epoch 79/150 - 0.20s - loss: 1.0281 - acc: 0.4867 - val_loss: 1.0438 - val_acc: 0.4919\n",
            "Epoch 80/150 - 0.18s - loss: 1.0276 - acc: 0.4885 - val_loss: 1.0435 - val_acc: 0.4899\n",
            "Epoch 81/150 - 0.19s - loss: 1.0271 - acc: 0.4890 - val_loss: 1.0432 - val_acc: 0.4919\n",
            "Epoch 82/150 - 0.18s - loss: 1.0266 - acc: 0.4881 - val_loss: 1.0427 - val_acc: 0.4960\n",
            "Epoch 83/150 - 0.18s - loss: 1.0260 - acc: 0.4892 - val_loss: 1.0424 - val_acc: 0.5000\n",
            "Epoch 84/150 - 0.18s - loss: 1.0255 - acc: 0.4915 - val_loss: 1.0420 - val_acc: 0.4980\n",
            "Epoch 85/150 - 0.19s - loss: 1.0250 - acc: 0.4903 - val_loss: 1.0415 - val_acc: 0.5040\n",
            "Epoch 86/150 - 0.18s - loss: 1.0244 - acc: 0.4901 - val_loss: 1.0412 - val_acc: 0.5040\n",
            "Epoch 87/150 - 0.18s - loss: 1.0239 - acc: 0.4908 - val_loss: 1.0408 - val_acc: 0.5040\n",
            "Epoch 88/150 - 0.18s - loss: 1.0234 - acc: 0.4917 - val_loss: 1.0405 - val_acc: 0.5020\n",
            "Epoch 89/150 - 0.19s - loss: 1.0229 - acc: 0.4928 - val_loss: 1.0401 - val_acc: 0.5020\n",
            "Epoch 90/150 - 0.18s - loss: 1.0224 - acc: 0.4912 - val_loss: 1.0396 - val_acc: 0.5121\n",
            "Epoch 91/150 - 0.19s - loss: 1.0218 - acc: 0.4930 - val_loss: 1.0392 - val_acc: 0.5142\n",
            "Epoch 92/150 - 0.17s - loss: 1.0213 - acc: 0.4951 - val_loss: 1.0389 - val_acc: 0.5081\n",
            "Epoch 93/150 - 0.21s - loss: 1.0208 - acc: 0.4939 - val_loss: 1.0384 - val_acc: 0.5162\n",
            "Epoch 94/150 - 0.18s - loss: 1.0203 - acc: 0.4975 - val_loss: 1.0381 - val_acc: 0.5101\n",
            "Epoch 95/150 - 0.18s - loss: 1.0198 - acc: 0.4948 - val_loss: 1.0376 - val_acc: 0.5121\n",
            "Epoch 96/150 - 0.19s - loss: 1.0192 - acc: 0.4980 - val_loss: 1.0374 - val_acc: 0.5101\n",
            "Epoch 97/150 - 0.20s - loss: 1.0187 - acc: 0.4982 - val_loss: 1.0370 - val_acc: 0.5142\n",
            "Epoch 98/150 - 0.18s - loss: 1.0183 - acc: 0.4982 - val_loss: 1.0370 - val_acc: 0.5142\n",
            "Epoch 99/150 - 0.18s - loss: 1.0177 - acc: 0.4978 - val_loss: 1.0364 - val_acc: 0.5121\n",
            "Epoch 100/150 - 0.19s - loss: 1.0172 - acc: 0.4987 - val_loss: 1.0359 - val_acc: 0.5142\n",
            "Epoch 101/150 - 0.19s - loss: 1.0167 - acc: 0.5007 - val_loss: 1.0355 - val_acc: 0.5101\n",
            "Epoch 102/150 - 0.18s - loss: 1.0162 - acc: 0.4998 - val_loss: 1.0351 - val_acc: 0.5121\n",
            "Epoch 103/150 - 0.19s - loss: 1.0157 - acc: 0.4998 - val_loss: 1.0347 - val_acc: 0.5162\n",
            "Epoch 104/150 - 0.18s - loss: 1.0152 - acc: 0.5018 - val_loss: 1.0344 - val_acc: 0.5142\n",
            "Epoch 105/150 - 0.20s - loss: 1.0146 - acc: 0.5016 - val_loss: 1.0338 - val_acc: 0.5142\n",
            "Epoch 106/150 - 0.20s - loss: 1.0141 - acc: 0.5038 - val_loss: 1.0336 - val_acc: 0.5162\n",
            "Epoch 107/150 - 0.19s - loss: 1.0136 - acc: 0.5038 - val_loss: 1.0330 - val_acc: 0.5223\n",
            "Epoch 108/150 - 0.18s - loss: 1.0132 - acc: 0.5025 - val_loss: 1.0331 - val_acc: 0.5202\n",
            "Epoch 109/150 - 0.19s - loss: 1.0126 - acc: 0.5052 - val_loss: 1.0323 - val_acc: 0.5223\n",
            "Epoch 110/150 - 0.18s - loss: 1.0121 - acc: 0.5058 - val_loss: 1.0318 - val_acc: 0.5182\n",
            "Epoch 111/150 - 0.23s - loss: 1.0116 - acc: 0.5074 - val_loss: 1.0316 - val_acc: 0.5162\n",
            "Epoch 112/150 - 0.21s - loss: 1.0111 - acc: 0.5063 - val_loss: 1.0310 - val_acc: 0.5162\n",
            "Epoch 113/150 - 0.20s - loss: 1.0106 - acc: 0.5065 - val_loss: 1.0306 - val_acc: 0.5182\n",
            "Epoch 114/150 - 0.20s - loss: 1.0101 - acc: 0.5090 - val_loss: 1.0305 - val_acc: 0.5162\n",
            "Epoch 115/150 - 0.21s - loss: 1.0096 - acc: 0.5076 - val_loss: 1.0304 - val_acc: 0.5182\n",
            "Epoch 116/150 - 0.20s - loss: 1.0091 - acc: 0.5088 - val_loss: 1.0296 - val_acc: 0.5202\n",
            "Epoch 117/150 - 0.18s - loss: 1.0086 - acc: 0.5103 - val_loss: 1.0293 - val_acc: 0.5162\n",
            "Epoch 118/150 - 0.19s - loss: 1.0081 - acc: 0.5092 - val_loss: 1.0290 - val_acc: 0.5223\n",
            "Epoch 119/150 - 0.19s - loss: 1.0076 - acc: 0.5094 - val_loss: 1.0285 - val_acc: 0.5202\n",
            "Epoch 120/150 - 0.22s - loss: 1.0071 - acc: 0.5088 - val_loss: 1.0279 - val_acc: 0.5223\n",
            "Epoch 121/150 - 0.18s - loss: 1.0066 - acc: 0.5101 - val_loss: 1.0277 - val_acc: 0.5223\n",
            "Epoch 122/150 - 0.18s - loss: 1.0061 - acc: 0.5115 - val_loss: 1.0272 - val_acc: 0.5243\n",
            "Epoch 123/150 - 0.18s - loss: 1.0056 - acc: 0.5103 - val_loss: 1.0271 - val_acc: 0.5202\n",
            "Epoch 124/150 - 0.19s - loss: 1.0051 - acc: 0.5117 - val_loss: 1.0267 - val_acc: 0.5243\n",
            "Epoch 125/150 - 0.19s - loss: 1.0047 - acc: 0.5103 - val_loss: 1.0265 - val_acc: 0.5202\n",
            "Epoch 126/150 - 0.19s - loss: 1.0041 - acc: 0.5126 - val_loss: 1.0258 - val_acc: 0.5283\n",
            "Epoch 127/150 - 0.19s - loss: 1.0036 - acc: 0.5144 - val_loss: 1.0254 - val_acc: 0.5304\n",
            "Epoch 128/150 - 0.20s - loss: 1.0031 - acc: 0.5135 - val_loss: 1.0250 - val_acc: 0.5324\n",
            "Epoch 129/150 - 0.19s - loss: 1.0027 - acc: 0.5130 - val_loss: 1.0247 - val_acc: 0.5263\n",
            "Epoch 130/150 - 0.20s - loss: 1.0022 - acc: 0.5121 - val_loss: 1.0242 - val_acc: 0.5283\n",
            "Epoch 131/150 - 0.19s - loss: 1.0017 - acc: 0.5130 - val_loss: 1.0238 - val_acc: 0.5304\n",
            "Epoch 132/150 - 0.22s - loss: 1.0012 - acc: 0.5126 - val_loss: 1.0233 - val_acc: 0.5304\n",
            "Epoch 133/150 - 0.19s - loss: 1.0007 - acc: 0.5133 - val_loss: 1.0230 - val_acc: 0.5304\n",
            "Epoch 134/150 - 0.19s - loss: 1.0002 - acc: 0.5126 - val_loss: 1.0226 - val_acc: 0.5304\n",
            "Epoch 135/150 - 0.18s - loss: 0.9997 - acc: 0.5144 - val_loss: 1.0222 - val_acc: 0.5324\n",
            "Epoch 136/150 - 0.19s - loss: 0.9992 - acc: 0.5157 - val_loss: 1.0220 - val_acc: 0.5263\n",
            "Epoch 137/150 - 0.16s - loss: 0.9988 - acc: 0.5164 - val_loss: 1.0213 - val_acc: 0.5304\n",
            "Epoch 138/150 - 0.16s - loss: 0.9983 - acc: 0.5162 - val_loss: 1.0214 - val_acc: 0.5324\n",
            "Epoch 139/150 - 0.18s - loss: 0.9979 - acc: 0.5151 - val_loss: 1.0212 - val_acc: 0.5182\n",
            "Epoch 140/150 - 0.22s - loss: 0.9973 - acc: 0.5173 - val_loss: 1.0206 - val_acc: 0.5223\n",
            "Epoch 141/150 - 0.18s - loss: 0.9968 - acc: 0.5173 - val_loss: 1.0201 - val_acc: 0.5344\n",
            "Epoch 142/150 - 0.18s - loss: 0.9963 - acc: 0.5164 - val_loss: 1.0193 - val_acc: 0.5344\n",
            "Epoch 143/150 - 0.16s - loss: 0.9958 - acc: 0.5191 - val_loss: 1.0191 - val_acc: 0.5324\n",
            "Epoch 144/150 - 0.18s - loss: 0.9954 - acc: 0.5189 - val_loss: 1.0186 - val_acc: 0.5324\n",
            "Epoch 145/150 - 0.16s - loss: 0.9949 - acc: 0.5189 - val_loss: 1.0184 - val_acc: 0.5283\n",
            "Epoch 146/150 - 0.16s - loss: 0.9944 - acc: 0.5180 - val_loss: 1.0178 - val_acc: 0.5344\n",
            "Epoch 147/150 - 0.16s - loss: 0.9939 - acc: 0.5191 - val_loss: 1.0176 - val_acc: 0.5304\n",
            "Epoch 148/150 - 0.20s - loss: 0.9934 - acc: 0.5200 - val_loss: 1.0174 - val_acc: 0.5263\n",
            "Epoch 149/150 - 0.16s - loss: 0.9929 - acc: 0.5205 - val_loss: 1.0169 - val_acc: 0.5283\n",
            "Epoch 150/150 - 0.18s - loss: 0.9926 - acc: 0.5193 - val_loss: 1.0164 - val_acc: 0.5385\n",
            "\n",
            "Combination 211/252:\n",
            "Hidden Layers: [256, 128, 64], Activation: tanh, Learning Rate: 0.0001, Batch Size: 32, Epochs: 50\n",
            "Epoch 1/50 - 0.20s - loss: 1.1064 - acc: 0.3169 - val_loss: 1.1003 - val_acc: 0.3502\n",
            "Epoch 2/50 - 0.20s - loss: 1.1055 - acc: 0.3225 - val_loss: 1.0997 - val_acc: 0.3421\n",
            "Epoch 3/50 - 0.19s - loss: 1.1047 - acc: 0.3225 - val_loss: 1.0991 - val_acc: 0.3320\n",
            "Epoch 4/50 - 0.19s - loss: 1.1039 - acc: 0.3246 - val_loss: 1.0986 - val_acc: 0.3320\n",
            "Epoch 5/50 - 0.21s - loss: 1.1033 - acc: 0.3239 - val_loss: 1.0981 - val_acc: 0.3381\n",
            "Epoch 6/50 - 0.20s - loss: 1.1027 - acc: 0.3282 - val_loss: 1.0976 - val_acc: 0.3522\n",
            "Epoch 7/50 - 0.20s - loss: 1.1021 - acc: 0.3309 - val_loss: 1.0972 - val_acc: 0.3684\n",
            "Epoch 8/50 - 0.19s - loss: 1.1016 - acc: 0.3324 - val_loss: 1.0967 - val_acc: 0.3684\n",
            "Epoch 9/50 - 0.21s - loss: 1.1011 - acc: 0.3329 - val_loss: 1.0963 - val_acc: 0.3684\n",
            "Epoch 10/50 - 0.19s - loss: 1.1006 - acc: 0.3345 - val_loss: 1.0959 - val_acc: 0.3664\n",
            "Epoch 11/50 - 0.22s - loss: 1.1002 - acc: 0.3336 - val_loss: 1.0955 - val_acc: 0.3684\n",
            "Epoch 12/50 - 0.20s - loss: 1.0997 - acc: 0.3345 - val_loss: 1.0951 - val_acc: 0.3745\n",
            "Epoch 13/50 - 0.20s - loss: 1.0992 - acc: 0.3356 - val_loss: 1.0947 - val_acc: 0.3725\n",
            "Epoch 14/50 - 0.20s - loss: 1.0988 - acc: 0.3363 - val_loss: 1.0943 - val_acc: 0.3806\n",
            "Epoch 15/50 - 0.21s - loss: 1.0984 - acc: 0.3405 - val_loss: 1.0939 - val_acc: 0.3846\n",
            "Epoch 16/50 - 0.22s - loss: 1.0979 - acc: 0.3444 - val_loss: 1.0935 - val_acc: 0.3806\n",
            "Epoch 17/50 - 0.22s - loss: 1.0975 - acc: 0.3448 - val_loss: 1.0931 - val_acc: 0.3826\n",
            "Epoch 18/50 - 0.23s - loss: 1.0971 - acc: 0.3475 - val_loss: 1.0927 - val_acc: 0.3826\n",
            "Epoch 19/50 - 0.22s - loss: 1.0967 - acc: 0.3493 - val_loss: 1.0924 - val_acc: 0.3785\n",
            "Epoch 20/50 - 0.22s - loss: 1.0963 - acc: 0.3522 - val_loss: 1.0920 - val_acc: 0.3826\n",
            "Epoch 21/50 - 0.26s - loss: 1.0959 - acc: 0.3545 - val_loss: 1.0916 - val_acc: 0.3826\n",
            "Epoch 22/50 - 0.21s - loss: 1.0955 - acc: 0.3578 - val_loss: 1.0912 - val_acc: 0.3887\n",
            "Epoch 23/50 - 0.22s - loss: 1.0951 - acc: 0.3596 - val_loss: 1.0909 - val_acc: 0.3947\n",
            "Epoch 24/50 - 0.22s - loss: 1.0947 - acc: 0.3621 - val_loss: 1.0905 - val_acc: 0.4008\n",
            "Epoch 25/50 - 0.22s - loss: 1.0944 - acc: 0.3653 - val_loss: 1.0902 - val_acc: 0.4028\n",
            "Epoch 26/50 - 0.21s - loss: 1.0940 - acc: 0.3671 - val_loss: 1.0898 - val_acc: 0.3968\n",
            "Epoch 27/50 - 0.22s - loss: 1.0936 - acc: 0.3691 - val_loss: 1.0895 - val_acc: 0.3988\n",
            "Epoch 28/50 - 0.27s - loss: 1.0933 - acc: 0.3711 - val_loss: 1.0891 - val_acc: 0.3988\n",
            "Epoch 29/50 - 0.21s - loss: 1.0929 - acc: 0.3722 - val_loss: 1.0888 - val_acc: 0.3968\n",
            "Epoch 30/50 - 0.23s - loss: 1.0925 - acc: 0.3752 - val_loss: 1.0884 - val_acc: 0.4008\n",
            "Epoch 31/50 - 0.22s - loss: 1.0922 - acc: 0.3761 - val_loss: 1.0881 - val_acc: 0.4028\n",
            "Epoch 32/50 - 0.22s - loss: 1.0918 - acc: 0.3792 - val_loss: 1.0878 - val_acc: 0.4008\n",
            "Epoch 33/50 - 0.22s - loss: 1.0915 - acc: 0.3817 - val_loss: 1.0875 - val_acc: 0.3988\n",
            "Epoch 34/50 - 0.21s - loss: 1.0911 - acc: 0.3830 - val_loss: 1.0872 - val_acc: 0.3988\n",
            "Epoch 35/50 - 0.25s - loss: 1.0908 - acc: 0.3855 - val_loss: 1.0868 - val_acc: 0.4028\n",
            "Epoch 36/50 - 0.22s - loss: 1.0905 - acc: 0.3866 - val_loss: 1.0865 - val_acc: 0.4049\n",
            "Epoch 37/50 - 0.23s - loss: 1.0901 - acc: 0.3860 - val_loss: 1.0862 - val_acc: 0.4028\n",
            "Epoch 38/50 - 0.24s - loss: 1.0898 - acc: 0.3878 - val_loss: 1.0859 - val_acc: 0.4008\n",
            "Epoch 39/50 - 0.22s - loss: 1.0895 - acc: 0.3875 - val_loss: 1.0856 - val_acc: 0.3968\n",
            "Epoch 40/50 - 0.22s - loss: 1.0892 - acc: 0.3898 - val_loss: 1.0853 - val_acc: 0.3968\n",
            "Epoch 41/50 - 0.23s - loss: 1.0888 - acc: 0.3905 - val_loss: 1.0850 - val_acc: 0.3968\n",
            "Epoch 42/50 - 0.24s - loss: 1.0885 - acc: 0.3907 - val_loss: 1.0847 - val_acc: 0.3927\n",
            "Epoch 43/50 - 0.21s - loss: 1.0882 - acc: 0.3902 - val_loss: 1.0844 - val_acc: 0.3866\n",
            "Epoch 44/50 - 0.22s - loss: 1.0879 - acc: 0.3918 - val_loss: 1.0842 - val_acc: 0.3887\n",
            "Epoch 45/50 - 0.22s - loss: 1.0876 - acc: 0.3925 - val_loss: 1.0839 - val_acc: 0.3947\n",
            "Epoch 46/50 - 0.22s - loss: 1.0873 - acc: 0.3959 - val_loss: 1.0836 - val_acc: 0.3947\n",
            "Epoch 47/50 - 0.22s - loss: 1.0870 - acc: 0.3977 - val_loss: 1.0833 - val_acc: 0.3947\n",
            "Epoch 48/50 - 0.23s - loss: 1.0867 - acc: 0.3997 - val_loss: 1.0830 - val_acc: 0.3947\n",
            "Epoch 49/50 - 0.24s - loss: 1.0864 - acc: 0.4013 - val_loss: 1.0828 - val_acc: 0.3887\n",
            "Epoch 50/50 - 0.24s - loss: 1.0861 - acc: 0.4044 - val_loss: 1.0825 - val_acc: 0.3927\n",
            "\n",
            "Combination 212/252:\n",
            "Hidden Layers: [256, 128, 64], Activation: tanh, Learning Rate: 0.0001, Batch Size: 32, Epochs: 100\n",
            "Epoch 1/100 - 0.23s - loss: 1.1111 - acc: 0.3324 - val_loss: 1.1105 - val_acc: 0.3441\n",
            "Epoch 2/100 - 0.22s - loss: 1.1078 - acc: 0.3279 - val_loss: 1.1079 - val_acc: 0.3360\n",
            "Epoch 3/100 - 0.22s - loss: 1.1053 - acc: 0.3304 - val_loss: 1.1059 - val_acc: 0.3320\n",
            "Epoch 4/100 - 0.22s - loss: 1.1033 - acc: 0.3304 - val_loss: 1.1044 - val_acc: 0.3320\n",
            "Epoch 5/100 - 0.24s - loss: 1.1018 - acc: 0.3309 - val_loss: 1.1032 - val_acc: 0.3300\n",
            "Epoch 6/100 - 0.27s - loss: 1.1005 - acc: 0.3356 - val_loss: 1.1023 - val_acc: 0.3320\n",
            "Epoch 7/100 - 0.22s - loss: 1.0995 - acc: 0.3392 - val_loss: 1.1015 - val_acc: 0.3320\n",
            "Epoch 8/100 - 0.23s - loss: 1.0986 - acc: 0.3459 - val_loss: 1.1009 - val_acc: 0.3340\n",
            "Epoch 9/100 - 0.22s - loss: 1.0979 - acc: 0.3468 - val_loss: 1.1003 - val_acc: 0.3421\n",
            "Epoch 10/100 - 0.22s - loss: 1.0973 - acc: 0.3507 - val_loss: 1.0999 - val_acc: 0.3543\n",
            "Epoch 11/100 - 0.22s - loss: 1.0967 - acc: 0.3527 - val_loss: 1.0995 - val_acc: 0.3421\n",
            "Epoch 12/100 - 0.24s - loss: 1.0962 - acc: 0.3484 - val_loss: 1.0991 - val_acc: 0.3259\n",
            "Epoch 13/100 - 0.22s - loss: 1.0957 - acc: 0.3520 - val_loss: 1.0987 - val_acc: 0.3300\n",
            "Epoch 14/100 - 0.22s - loss: 1.0952 - acc: 0.3547 - val_loss: 1.0984 - val_acc: 0.3320\n",
            "Epoch 15/100 - 0.22s - loss: 1.0948 - acc: 0.3552 - val_loss: 1.0980 - val_acc: 0.3340\n",
            "Epoch 16/100 - 0.22s - loss: 1.0944 - acc: 0.3592 - val_loss: 1.0977 - val_acc: 0.3279\n",
            "Epoch 17/100 - 0.23s - loss: 1.0941 - acc: 0.3628 - val_loss: 1.0974 - val_acc: 0.3320\n",
            "Epoch 18/100 - 0.24s - loss: 1.0937 - acc: 0.3644 - val_loss: 1.0971 - val_acc: 0.3421\n",
            "Epoch 19/100 - 0.25s - loss: 1.0933 - acc: 0.3666 - val_loss: 1.0968 - val_acc: 0.3360\n",
            "Epoch 20/100 - 0.23s - loss: 1.0930 - acc: 0.3655 - val_loss: 1.0966 - val_acc: 0.3381\n",
            "Epoch 21/100 - 0.22s - loss: 1.0926 - acc: 0.3668 - val_loss: 1.0963 - val_acc: 0.3441\n",
            "Epoch 22/100 - 0.22s - loss: 1.0923 - acc: 0.3662 - val_loss: 1.0960 - val_acc: 0.3401\n",
            "Epoch 23/100 - 0.22s - loss: 1.0920 - acc: 0.3689 - val_loss: 1.0957 - val_acc: 0.3340\n",
            "Epoch 24/100 - 0.22s - loss: 1.0916 - acc: 0.3691 - val_loss: 1.0954 - val_acc: 0.3340\n",
            "Epoch 25/100 - 0.24s - loss: 1.0913 - acc: 0.3716 - val_loss: 1.0952 - val_acc: 0.3360\n",
            "Epoch 26/100 - 0.32s - loss: 1.0910 - acc: 0.3738 - val_loss: 1.0949 - val_acc: 0.3360\n",
            "Epoch 27/100 - 0.23s - loss: 1.0907 - acc: 0.3761 - val_loss: 1.0946 - val_acc: 0.3381\n",
            "Epoch 28/100 - 0.25s - loss: 1.0904 - acc: 0.3765 - val_loss: 1.0944 - val_acc: 0.3401\n",
            "Epoch 29/100 - 0.22s - loss: 1.0901 - acc: 0.3776 - val_loss: 1.0941 - val_acc: 0.3421\n",
            "Epoch 30/100 - 0.22s - loss: 1.0898 - acc: 0.3794 - val_loss: 1.0938 - val_acc: 0.3462\n",
            "Epoch 31/100 - 0.24s - loss: 1.0895 - acc: 0.3837 - val_loss: 1.0936 - val_acc: 0.3462\n",
            "Epoch 32/100 - 0.25s - loss: 1.0892 - acc: 0.3869 - val_loss: 1.0933 - val_acc: 0.3563\n",
            "Epoch 33/100 - 0.22s - loss: 1.0889 - acc: 0.3898 - val_loss: 1.0931 - val_acc: 0.3603\n",
            "Epoch 34/100 - 0.25s - loss: 1.0886 - acc: 0.3905 - val_loss: 1.0928 - val_acc: 0.3644\n",
            "Epoch 35/100 - 0.25s - loss: 1.0883 - acc: 0.3923 - val_loss: 1.0925 - val_acc: 0.3644\n",
            "Epoch 36/100 - 0.22s - loss: 1.0880 - acc: 0.3947 - val_loss: 1.0923 - val_acc: 0.3623\n",
            "Epoch 37/100 - 0.24s - loss: 1.0877 - acc: 0.3961 - val_loss: 1.0920 - val_acc: 0.3644\n",
            "Epoch 38/100 - 0.24s - loss: 1.0874 - acc: 0.3961 - val_loss: 1.0918 - val_acc: 0.3623\n",
            "Epoch 39/100 - 0.23s - loss: 1.0872 - acc: 0.3986 - val_loss: 1.0916 - val_acc: 0.3644\n",
            "Epoch 40/100 - 0.31s - loss: 1.0869 - acc: 0.4008 - val_loss: 1.0913 - val_acc: 0.3623\n",
            "Epoch 41/100 - 0.22s - loss: 1.0866 - acc: 0.4022 - val_loss: 1.0911 - val_acc: 0.3603\n",
            "Epoch 42/100 - 0.23s - loss: 1.0863 - acc: 0.4037 - val_loss: 1.0908 - val_acc: 0.3583\n",
            "Epoch 43/100 - 0.23s - loss: 1.0861 - acc: 0.4051 - val_loss: 1.0906 - val_acc: 0.3623\n",
            "Epoch 44/100 - 0.24s - loss: 1.0858 - acc: 0.4062 - val_loss: 1.0904 - val_acc: 0.3644\n",
            "Epoch 45/100 - 0.23s - loss: 1.0855 - acc: 0.4073 - val_loss: 1.0901 - val_acc: 0.3664\n",
            "Epoch 46/100 - 0.25s - loss: 1.0853 - acc: 0.4078 - val_loss: 1.0899 - val_acc: 0.3684\n",
            "Epoch 47/100 - 0.24s - loss: 1.0850 - acc: 0.4091 - val_loss: 1.0897 - val_acc: 0.3684\n",
            "Epoch 48/100 - 0.23s - loss: 1.0847 - acc: 0.4100 - val_loss: 1.0894 - val_acc: 0.3704\n",
            "Epoch 49/100 - 0.22s - loss: 1.0845 - acc: 0.4109 - val_loss: 1.0892 - val_acc: 0.3664\n",
            "Epoch 50/100 - 0.21s - loss: 1.0842 - acc: 0.4123 - val_loss: 1.0890 - val_acc: 0.3664\n",
            "Epoch 51/100 - 0.21s - loss: 1.0840 - acc: 0.4125 - val_loss: 1.0888 - val_acc: 0.3644\n",
            "Epoch 52/100 - 0.20s - loss: 1.0837 - acc: 0.4145 - val_loss: 1.0885 - val_acc: 0.3644\n",
            "Epoch 53/100 - 0.20s - loss: 1.0835 - acc: 0.4168 - val_loss: 1.0883 - val_acc: 0.3664\n",
            "Epoch 54/100 - 0.22s - loss: 1.0832 - acc: 0.4177 - val_loss: 1.0881 - val_acc: 0.3684\n",
            "Epoch 55/100 - 0.20s - loss: 1.0830 - acc: 0.4175 - val_loss: 1.0879 - val_acc: 0.3684\n",
            "Epoch 56/100 - 0.20s - loss: 1.0827 - acc: 0.4175 - val_loss: 1.0877 - val_acc: 0.3725\n",
            "Epoch 57/100 - 0.20s - loss: 1.0825 - acc: 0.4179 - val_loss: 1.0875 - val_acc: 0.3725\n",
            "Epoch 58/100 - 0.21s - loss: 1.0822 - acc: 0.4181 - val_loss: 1.0872 - val_acc: 0.3725\n",
            "Epoch 59/100 - 0.22s - loss: 1.0820 - acc: 0.4188 - val_loss: 1.0870 - val_acc: 0.3725\n",
            "Epoch 60/100 - 0.24s - loss: 1.0817 - acc: 0.4204 - val_loss: 1.0868 - val_acc: 0.3704\n",
            "Epoch 61/100 - 0.22s - loss: 1.0815 - acc: 0.4222 - val_loss: 1.0866 - val_acc: 0.3684\n",
            "Epoch 62/100 - 0.22s - loss: 1.0813 - acc: 0.4224 - val_loss: 1.0864 - val_acc: 0.3725\n",
            "Epoch 63/100 - 0.22s - loss: 1.0810 - acc: 0.4233 - val_loss: 1.0862 - val_acc: 0.3725\n",
            "Epoch 64/100 - 0.22s - loss: 1.0808 - acc: 0.4253 - val_loss: 1.0860 - val_acc: 0.3806\n",
            "Epoch 65/100 - 0.23s - loss: 1.0806 - acc: 0.4265 - val_loss: 1.0858 - val_acc: 0.3846\n",
            "Epoch 66/100 - 0.28s - loss: 1.0803 - acc: 0.4265 - val_loss: 1.0856 - val_acc: 0.3907\n",
            "Epoch 67/100 - 0.23s - loss: 1.0801 - acc: 0.4262 - val_loss: 1.0854 - val_acc: 0.3907\n",
            "Epoch 68/100 - 0.23s - loss: 1.0799 - acc: 0.4278 - val_loss: 1.0852 - val_acc: 0.3927\n",
            "Epoch 69/100 - 0.25s - loss: 1.0797 - acc: 0.4278 - val_loss: 1.0851 - val_acc: 0.3927\n",
            "Epoch 70/100 - 0.28s - loss: 1.0794 - acc: 0.4280 - val_loss: 1.0849 - val_acc: 0.3927\n",
            "Epoch 71/100 - 0.25s - loss: 1.0792 - acc: 0.4294 - val_loss: 1.0847 - val_acc: 0.3927\n",
            "Epoch 72/100 - 0.24s - loss: 1.0790 - acc: 0.4296 - val_loss: 1.0845 - val_acc: 0.3968\n",
            "Epoch 73/100 - 0.23s - loss: 1.0788 - acc: 0.4314 - val_loss: 1.0843 - val_acc: 0.3968\n",
            "Epoch 74/100 - 0.22s - loss: 1.0786 - acc: 0.4309 - val_loss: 1.0841 - val_acc: 0.3947\n",
            "Epoch 75/100 - 0.23s - loss: 1.0783 - acc: 0.4305 - val_loss: 1.0839 - val_acc: 0.3947\n",
            "Epoch 76/100 - 0.24s - loss: 1.0781 - acc: 0.4305 - val_loss: 1.0837 - val_acc: 0.3968\n",
            "Epoch 77/100 - 0.22s - loss: 1.0779 - acc: 0.4314 - val_loss: 1.0835 - val_acc: 0.4008\n",
            "Epoch 78/100 - 0.21s - loss: 1.0777 - acc: 0.4312 - val_loss: 1.0834 - val_acc: 0.4008\n",
            "Epoch 79/100 - 0.22s - loss: 1.0775 - acc: 0.4307 - val_loss: 1.0832 - val_acc: 0.4008\n",
            "Epoch 80/100 - 0.20s - loss: 1.0773 - acc: 0.4312 - val_loss: 1.0830 - val_acc: 0.4008\n",
            "Epoch 81/100 - 0.21s - loss: 1.0771 - acc: 0.4332 - val_loss: 1.0828 - val_acc: 0.4049\n",
            "Epoch 82/100 - 0.20s - loss: 1.0769 - acc: 0.4334 - val_loss: 1.0826 - val_acc: 0.4028\n",
            "Epoch 83/100 - 0.25s - loss: 1.0767 - acc: 0.4330 - val_loss: 1.0825 - val_acc: 0.4049\n",
            "Epoch 84/100 - 0.20s - loss: 1.0765 - acc: 0.4345 - val_loss: 1.0823 - val_acc: 0.4028\n",
            "Epoch 85/100 - 0.20s - loss: 1.0762 - acc: 0.4345 - val_loss: 1.0821 - val_acc: 0.4028\n",
            "Epoch 86/100 - 0.20s - loss: 1.0760 - acc: 0.4354 - val_loss: 1.0820 - val_acc: 0.4008\n",
            "Epoch 87/100 - 0.20s - loss: 1.0758 - acc: 0.4348 - val_loss: 1.0818 - val_acc: 0.4028\n",
            "Epoch 88/100 - 0.20s - loss: 1.0756 - acc: 0.4350 - val_loss: 1.0816 - val_acc: 0.4049\n",
            "Epoch 89/100 - 0.21s - loss: 1.0754 - acc: 0.4354 - val_loss: 1.0815 - val_acc: 0.4069\n",
            "Epoch 90/100 - 0.20s - loss: 1.0752 - acc: 0.4345 - val_loss: 1.0813 - val_acc: 0.4089\n",
            "Epoch 91/100 - 0.20s - loss: 1.0750 - acc: 0.4354 - val_loss: 1.0811 - val_acc: 0.4109\n",
            "Epoch 92/100 - 0.20s - loss: 1.0749 - acc: 0.4357 - val_loss: 1.0810 - val_acc: 0.4130\n",
            "Epoch 93/100 - 0.21s - loss: 1.0747 - acc: 0.4357 - val_loss: 1.0808 - val_acc: 0.4130\n",
            "Epoch 94/100 - 0.20s - loss: 1.0745 - acc: 0.4370 - val_loss: 1.0806 - val_acc: 0.4170\n",
            "Epoch 95/100 - 0.23s - loss: 1.0743 - acc: 0.4366 - val_loss: 1.0805 - val_acc: 0.4170\n",
            "Epoch 96/100 - 0.20s - loss: 1.0741 - acc: 0.4375 - val_loss: 1.0803 - val_acc: 0.4150\n",
            "Epoch 97/100 - 0.21s - loss: 1.0739 - acc: 0.4377 - val_loss: 1.0801 - val_acc: 0.4130\n",
            "Epoch 98/100 - 0.20s - loss: 1.0737 - acc: 0.4390 - val_loss: 1.0800 - val_acc: 0.4150\n",
            "Epoch 99/100 - 0.21s - loss: 1.0735 - acc: 0.4399 - val_loss: 1.0798 - val_acc: 0.4170\n",
            "Epoch 100/100 - 0.21s - loss: 1.0733 - acc: 0.4393 - val_loss: 1.0797 - val_acc: 0.4190\n",
            "\n",
            "Combination 213/252:\n",
            "Hidden Layers: [256, 128, 64], Activation: tanh, Learning Rate: 0.0001, Batch Size: 32, Epochs: 150\n",
            "Epoch 1/150 - 0.22s - loss: 1.0935 - acc: 0.3783 - val_loss: 1.0880 - val_acc: 0.3947\n",
            "Epoch 2/150 - 0.20s - loss: 1.0926 - acc: 0.3855 - val_loss: 1.0874 - val_acc: 0.3988\n",
            "Epoch 3/150 - 0.21s - loss: 1.0918 - acc: 0.3848 - val_loss: 1.0869 - val_acc: 0.3968\n",
            "Epoch 4/150 - 0.20s - loss: 1.0912 - acc: 0.3887 - val_loss: 1.0865 - val_acc: 0.3988\n",
            "Epoch 5/150 - 0.20s - loss: 1.0906 - acc: 0.3911 - val_loss: 1.0862 - val_acc: 0.3927\n",
            "Epoch 6/150 - 0.19s - loss: 1.0902 - acc: 0.3932 - val_loss: 1.0859 - val_acc: 0.3988\n",
            "Epoch 7/150 - 0.21s - loss: 1.0897 - acc: 0.3945 - val_loss: 1.0856 - val_acc: 0.4008\n",
            "Epoch 8/150 - 0.20s - loss: 1.0894 - acc: 0.3983 - val_loss: 1.0854 - val_acc: 0.4069\n",
            "Epoch 9/150 - 0.20s - loss: 1.0890 - acc: 0.3986 - val_loss: 1.0851 - val_acc: 0.4049\n",
            "Epoch 10/150 - 0.20s - loss: 1.0887 - acc: 0.3997 - val_loss: 1.0849 - val_acc: 0.4049\n",
            "Epoch 11/150 - 0.21s - loss: 1.0883 - acc: 0.4013 - val_loss: 1.0847 - val_acc: 0.4028\n",
            "Epoch 12/150 - 0.21s - loss: 1.0880 - acc: 0.4013 - val_loss: 1.0845 - val_acc: 0.4028\n",
            "Epoch 13/150 - 0.21s - loss: 1.0877 - acc: 0.4031 - val_loss: 1.0843 - val_acc: 0.4049\n",
            "Epoch 14/150 - 0.19s - loss: 1.0874 - acc: 0.4051 - val_loss: 1.0841 - val_acc: 0.4049\n",
            "Epoch 15/150 - 0.21s - loss: 1.0871 - acc: 0.4064 - val_loss: 1.0839 - val_acc: 0.4069\n",
            "Epoch 16/150 - 0.19s - loss: 1.0868 - acc: 0.4085 - val_loss: 1.0836 - val_acc: 0.4109\n",
            "Epoch 17/150 - 0.22s - loss: 1.0866 - acc: 0.4107 - val_loss: 1.0834 - val_acc: 0.4130\n",
            "Epoch 18/150 - 0.20s - loss: 1.0863 - acc: 0.4121 - val_loss: 1.0832 - val_acc: 0.4150\n",
            "Epoch 19/150 - 0.21s - loss: 1.0860 - acc: 0.4125 - val_loss: 1.0830 - val_acc: 0.4170\n",
            "Epoch 20/150 - 0.21s - loss: 1.0857 - acc: 0.4136 - val_loss: 1.0828 - val_acc: 0.4190\n",
            "Epoch 21/150 - 0.21s - loss: 1.0854 - acc: 0.4148 - val_loss: 1.0826 - val_acc: 0.4211\n",
            "Epoch 22/150 - 0.22s - loss: 1.0851 - acc: 0.4148 - val_loss: 1.0824 - val_acc: 0.4211\n",
            "Epoch 23/150 - 0.20s - loss: 1.0849 - acc: 0.4168 - val_loss: 1.0821 - val_acc: 0.4231\n",
            "Epoch 24/150 - 0.22s - loss: 1.0846 - acc: 0.4175 - val_loss: 1.0819 - val_acc: 0.4211\n",
            "Epoch 25/150 - 0.19s - loss: 1.0843 - acc: 0.4177 - val_loss: 1.0817 - val_acc: 0.4211\n",
            "Epoch 26/150 - 0.20s - loss: 1.0841 - acc: 0.4184 - val_loss: 1.0815 - val_acc: 0.4211\n",
            "Epoch 27/150 - 0.20s - loss: 1.0838 - acc: 0.4195 - val_loss: 1.0813 - val_acc: 0.4211\n",
            "Epoch 28/150 - 0.20s - loss: 1.0835 - acc: 0.4211 - val_loss: 1.0811 - val_acc: 0.4211\n",
            "Epoch 29/150 - 0.20s - loss: 1.0833 - acc: 0.4208 - val_loss: 1.0809 - val_acc: 0.4231\n",
            "Epoch 30/150 - 0.20s - loss: 1.0830 - acc: 0.4220 - val_loss: 1.0807 - val_acc: 0.4211\n",
            "Epoch 31/150 - 0.20s - loss: 1.0827 - acc: 0.4215 - val_loss: 1.0805 - val_acc: 0.4170\n",
            "Epoch 32/150 - 0.22s - loss: 1.0825 - acc: 0.4226 - val_loss: 1.0803 - val_acc: 0.4170\n",
            "Epoch 33/150 - 0.20s - loss: 1.0822 - acc: 0.4242 - val_loss: 1.0800 - val_acc: 0.4190\n",
            "Epoch 34/150 - 0.21s - loss: 1.0820 - acc: 0.4231 - val_loss: 1.0799 - val_acc: 0.4190\n",
            "Epoch 35/150 - 0.19s - loss: 1.0817 - acc: 0.4251 - val_loss: 1.0796 - val_acc: 0.4190\n",
            "Epoch 36/150 - 0.22s - loss: 1.0815 - acc: 0.4260 - val_loss: 1.0794 - val_acc: 0.4190\n",
            "Epoch 37/150 - 0.20s - loss: 1.0812 - acc: 0.4267 - val_loss: 1.0793 - val_acc: 0.4190\n",
            "Epoch 38/150 - 0.20s - loss: 1.0810 - acc: 0.4276 - val_loss: 1.0791 - val_acc: 0.4190\n",
            "Epoch 39/150 - 0.20s - loss: 1.0807 - acc: 0.4278 - val_loss: 1.0789 - val_acc: 0.4190\n",
            "Epoch 40/150 - 0.20s - loss: 1.0805 - acc: 0.4285 - val_loss: 1.0787 - val_acc: 0.4190\n",
            "Epoch 41/150 - 0.19s - loss: 1.0802 - acc: 0.4283 - val_loss: 1.0785 - val_acc: 0.4211\n",
            "Epoch 42/150 - 0.19s - loss: 1.0800 - acc: 0.4276 - val_loss: 1.0783 - val_acc: 0.4190\n",
            "Epoch 43/150 - 0.19s - loss: 1.0797 - acc: 0.4287 - val_loss: 1.0781 - val_acc: 0.4190\n",
            "Epoch 44/150 - 0.20s - loss: 1.0795 - acc: 0.4296 - val_loss: 1.0779 - val_acc: 0.4211\n",
            "Epoch 45/150 - 0.19s - loss: 1.0792 - acc: 0.4296 - val_loss: 1.0777 - val_acc: 0.4211\n",
            "Epoch 46/150 - 0.21s - loss: 1.0790 - acc: 0.4296 - val_loss: 1.0775 - val_acc: 0.4231\n",
            "Epoch 47/150 - 0.19s - loss: 1.0788 - acc: 0.4289 - val_loss: 1.0773 - val_acc: 0.4231\n",
            "Epoch 48/150 - 0.20s - loss: 1.0785 - acc: 0.4309 - val_loss: 1.0772 - val_acc: 0.4231\n",
            "Epoch 49/150 - 0.19s - loss: 1.0783 - acc: 0.4314 - val_loss: 1.0770 - val_acc: 0.4251\n",
            "Epoch 50/150 - 0.20s - loss: 1.0781 - acc: 0.4307 - val_loss: 1.0768 - val_acc: 0.4312\n",
            "Epoch 51/150 - 0.19s - loss: 1.0778 - acc: 0.4318 - val_loss: 1.0766 - val_acc: 0.4271\n",
            "Epoch 52/150 - 0.20s - loss: 1.0776 - acc: 0.4323 - val_loss: 1.0764 - val_acc: 0.4312\n",
            "Epoch 53/150 - 0.19s - loss: 1.0774 - acc: 0.4336 - val_loss: 1.0763 - val_acc: 0.4312\n",
            "Epoch 54/150 - 0.19s - loss: 1.0771 - acc: 0.4348 - val_loss: 1.0761 - val_acc: 0.4312\n",
            "Epoch 55/150 - 0.20s - loss: 1.0769 - acc: 0.4345 - val_loss: 1.0759 - val_acc: 0.4352\n",
            "Epoch 56/150 - 0.20s - loss: 1.0767 - acc: 0.4339 - val_loss: 1.0757 - val_acc: 0.4352\n",
            "Epoch 57/150 - 0.19s - loss: 1.0764 - acc: 0.4336 - val_loss: 1.0756 - val_acc: 0.4372\n",
            "Epoch 58/150 - 0.19s - loss: 1.0762 - acc: 0.4345 - val_loss: 1.0754 - val_acc: 0.4352\n",
            "Epoch 59/150 - 0.21s - loss: 1.0760 - acc: 0.4345 - val_loss: 1.0752 - val_acc: 0.4352\n",
            "Epoch 60/150 - 0.20s - loss: 1.0758 - acc: 0.4348 - val_loss: 1.0750 - val_acc: 0.4352\n",
            "Epoch 61/150 - 0.20s - loss: 1.0756 - acc: 0.4345 - val_loss: 1.0749 - val_acc: 0.4372\n",
            "Epoch 62/150 - 0.19s - loss: 1.0753 - acc: 0.4357 - val_loss: 1.0747 - val_acc: 0.4393\n",
            "Epoch 63/150 - 0.20s - loss: 1.0751 - acc: 0.4357 - val_loss: 1.0745 - val_acc: 0.4372\n",
            "Epoch 64/150 - 0.19s - loss: 1.0749 - acc: 0.4370 - val_loss: 1.0744 - val_acc: 0.4393\n",
            "Epoch 65/150 - 0.22s - loss: 1.0747 - acc: 0.4372 - val_loss: 1.0742 - val_acc: 0.4393\n",
            "Epoch 66/150 - 0.19s - loss: 1.0745 - acc: 0.4375 - val_loss: 1.0740 - val_acc: 0.4393\n",
            "Epoch 67/150 - 0.21s - loss: 1.0742 - acc: 0.4384 - val_loss: 1.0739 - val_acc: 0.4393\n",
            "Epoch 68/150 - 0.21s - loss: 1.0740 - acc: 0.4386 - val_loss: 1.0737 - val_acc: 0.4372\n",
            "Epoch 69/150 - 0.19s - loss: 1.0738 - acc: 0.4390 - val_loss: 1.0735 - val_acc: 0.4372\n",
            "Epoch 70/150 - 0.22s - loss: 1.0736 - acc: 0.4402 - val_loss: 1.0734 - val_acc: 0.4372\n",
            "Epoch 71/150 - 0.19s - loss: 1.0734 - acc: 0.4397 - val_loss: 1.0732 - val_acc: 0.4372\n",
            "Epoch 72/150 - 0.20s - loss: 1.0732 - acc: 0.4406 - val_loss: 1.0731 - val_acc: 0.4372\n",
            "Epoch 73/150 - 0.20s - loss: 1.0730 - acc: 0.4406 - val_loss: 1.0729 - val_acc: 0.4372\n",
            "Epoch 74/150 - 0.24s - loss: 1.0728 - acc: 0.4415 - val_loss: 1.0727 - val_acc: 0.4372\n",
            "Epoch 75/150 - 0.21s - loss: 1.0726 - acc: 0.4426 - val_loss: 1.0726 - val_acc: 0.4372\n",
            "Epoch 76/150 - 0.20s - loss: 1.0724 - acc: 0.4433 - val_loss: 1.0724 - val_acc: 0.4393\n",
            "Epoch 77/150 - 0.21s - loss: 1.0721 - acc: 0.4438 - val_loss: 1.0723 - val_acc: 0.4372\n",
            "Epoch 78/150 - 0.20s - loss: 1.0719 - acc: 0.4438 - val_loss: 1.0721 - val_acc: 0.4352\n",
            "Epoch 79/150 - 0.20s - loss: 1.0717 - acc: 0.4440 - val_loss: 1.0720 - val_acc: 0.4352\n",
            "Epoch 80/150 - 0.24s - loss: 1.0715 - acc: 0.4451 - val_loss: 1.0718 - val_acc: 0.4332\n",
            "Epoch 81/150 - 0.19s - loss: 1.0713 - acc: 0.4467 - val_loss: 1.0717 - val_acc: 0.4312\n",
            "Epoch 82/150 - 0.21s - loss: 1.0711 - acc: 0.4467 - val_loss: 1.0715 - val_acc: 0.4312\n",
            "Epoch 83/150 - 0.20s - loss: 1.0709 - acc: 0.4471 - val_loss: 1.0714 - val_acc: 0.4312\n",
            "Epoch 84/150 - 0.20s - loss: 1.0707 - acc: 0.4460 - val_loss: 1.0712 - val_acc: 0.4332\n",
            "Epoch 85/150 - 0.21s - loss: 1.0705 - acc: 0.4467 - val_loss: 1.0711 - val_acc: 0.4332\n",
            "Epoch 86/150 - 0.21s - loss: 1.0703 - acc: 0.4467 - val_loss: 1.0709 - val_acc: 0.4332\n",
            "Epoch 87/150 - 0.20s - loss: 1.0701 - acc: 0.4476 - val_loss: 1.0708 - val_acc: 0.4372\n",
            "Epoch 88/150 - 0.21s - loss: 1.0699 - acc: 0.4476 - val_loss: 1.0706 - val_acc: 0.4393\n",
            "Epoch 89/150 - 0.23s - loss: 1.0697 - acc: 0.4474 - val_loss: 1.0705 - val_acc: 0.4393\n",
            "Epoch 90/150 - 0.22s - loss: 1.0696 - acc: 0.4474 - val_loss: 1.0703 - val_acc: 0.4413\n",
            "Epoch 91/150 - 0.24s - loss: 1.0694 - acc: 0.4487 - val_loss: 1.0702 - val_acc: 0.4413\n",
            "Epoch 92/150 - 0.19s - loss: 1.0692 - acc: 0.4483 - val_loss: 1.0700 - val_acc: 0.4413\n",
            "Epoch 93/150 - 0.20s - loss: 1.0690 - acc: 0.4492 - val_loss: 1.0699 - val_acc: 0.4413\n",
            "Epoch 94/150 - 0.20s - loss: 1.0688 - acc: 0.4492 - val_loss: 1.0698 - val_acc: 0.4433\n",
            "Epoch 95/150 - 0.19s - loss: 1.0686 - acc: 0.4494 - val_loss: 1.0696 - val_acc: 0.4433\n",
            "Epoch 96/150 - 0.20s - loss: 1.0684 - acc: 0.4494 - val_loss: 1.0695 - val_acc: 0.4433\n",
            "Epoch 97/150 - 0.26s - loss: 1.0682 - acc: 0.4501 - val_loss: 1.0693 - val_acc: 0.4433\n",
            "Epoch 98/150 - 0.23s - loss: 1.0680 - acc: 0.4512 - val_loss: 1.0692 - val_acc: 0.4433\n",
            "Epoch 99/150 - 0.22s - loss: 1.0678 - acc: 0.4512 - val_loss: 1.0691 - val_acc: 0.4433\n",
            "Epoch 100/150 - 0.24s - loss: 1.0676 - acc: 0.4519 - val_loss: 1.0689 - val_acc: 0.4453\n",
            "Epoch 101/150 - 0.21s - loss: 1.0675 - acc: 0.4519 - val_loss: 1.0688 - val_acc: 0.4453\n",
            "Epoch 102/150 - 0.22s - loss: 1.0673 - acc: 0.4523 - val_loss: 1.0686 - val_acc: 0.4453\n",
            "Epoch 103/150 - 0.22s - loss: 1.0671 - acc: 0.4530 - val_loss: 1.0685 - val_acc: 0.4433\n",
            "Epoch 104/150 - 0.21s - loss: 1.0669 - acc: 0.4537 - val_loss: 1.0684 - val_acc: 0.4433\n",
            "Epoch 105/150 - 0.22s - loss: 1.0667 - acc: 0.4539 - val_loss: 1.0682 - val_acc: 0.4433\n",
            "Epoch 106/150 - 0.23s - loss: 1.0665 - acc: 0.4537 - val_loss: 1.0681 - val_acc: 0.4453\n",
            "Epoch 107/150 - 0.23s - loss: 1.0664 - acc: 0.4543 - val_loss: 1.0680 - val_acc: 0.4453\n",
            "Epoch 108/150 - 0.22s - loss: 1.0662 - acc: 0.4552 - val_loss: 1.0678 - val_acc: 0.4474\n",
            "Epoch 109/150 - 0.22s - loss: 1.0660 - acc: 0.4548 - val_loss: 1.0677 - val_acc: 0.4474\n",
            "Epoch 110/150 - 0.21s - loss: 1.0658 - acc: 0.4550 - val_loss: 1.0676 - val_acc: 0.4474\n",
            "Epoch 111/150 - 0.22s - loss: 1.0656 - acc: 0.4559 - val_loss: 1.0674 - val_acc: 0.4474\n",
            "Epoch 112/150 - 0.22s - loss: 1.0654 - acc: 0.4568 - val_loss: 1.0673 - val_acc: 0.4474\n",
            "Epoch 113/150 - 0.23s - loss: 1.0653 - acc: 0.4568 - val_loss: 1.0672 - val_acc: 0.4474\n",
            "Epoch 114/150 - 0.25s - loss: 1.0651 - acc: 0.4573 - val_loss: 1.0670 - val_acc: 0.4474\n",
            "Epoch 115/150 - 0.23s - loss: 1.0649 - acc: 0.4570 - val_loss: 1.0669 - val_acc: 0.4514\n",
            "Epoch 116/150 - 0.22s - loss: 1.0647 - acc: 0.4575 - val_loss: 1.0668 - val_acc: 0.4514\n",
            "Epoch 117/150 - 0.23s - loss: 1.0646 - acc: 0.4577 - val_loss: 1.0667 - val_acc: 0.4514\n",
            "Epoch 118/150 - 0.22s - loss: 1.0644 - acc: 0.4575 - val_loss: 1.0665 - val_acc: 0.4514\n",
            "Epoch 119/150 - 0.23s - loss: 1.0642 - acc: 0.4575 - val_loss: 1.0664 - val_acc: 0.4534\n",
            "Epoch 120/150 - 0.23s - loss: 1.0640 - acc: 0.4575 - val_loss: 1.0663 - val_acc: 0.4534\n",
            "Epoch 121/150 - 0.25s - loss: 1.0639 - acc: 0.4573 - val_loss: 1.0661 - val_acc: 0.4514\n",
            "Epoch 122/150 - 0.21s - loss: 1.0637 - acc: 0.4586 - val_loss: 1.0660 - val_acc: 0.4514\n",
            "Epoch 123/150 - 0.23s - loss: 1.0635 - acc: 0.4586 - val_loss: 1.0659 - val_acc: 0.4514\n",
            "Epoch 124/150 - 0.23s - loss: 1.0633 - acc: 0.4584 - val_loss: 1.0658 - val_acc: 0.4514\n",
            "Epoch 125/150 - 0.23s - loss: 1.0632 - acc: 0.4586 - val_loss: 1.0657 - val_acc: 0.4534\n",
            "Epoch 126/150 - 0.22s - loss: 1.0630 - acc: 0.4584 - val_loss: 1.0655 - val_acc: 0.4534\n",
            "Epoch 127/150 - 0.23s - loss: 1.0628 - acc: 0.4588 - val_loss: 1.0654 - val_acc: 0.4534\n",
            "Epoch 128/150 - 0.24s - loss: 1.0627 - acc: 0.4593 - val_loss: 1.0653 - val_acc: 0.4534\n",
            "Epoch 129/150 - 0.22s - loss: 1.0625 - acc: 0.4597 - val_loss: 1.0652 - val_acc: 0.4575\n",
            "Epoch 130/150 - 0.21s - loss: 1.0623 - acc: 0.4606 - val_loss: 1.0650 - val_acc: 0.4575\n",
            "Epoch 131/150 - 0.23s - loss: 1.0621 - acc: 0.4604 - val_loss: 1.0649 - val_acc: 0.4575\n",
            "Epoch 132/150 - 0.21s - loss: 1.0620 - acc: 0.4606 - val_loss: 1.0648 - val_acc: 0.4575\n",
            "Epoch 133/150 - 0.24s - loss: 1.0618 - acc: 0.4613 - val_loss: 1.0647 - val_acc: 0.4575\n",
            "Epoch 134/150 - 0.23s - loss: 1.0616 - acc: 0.4620 - val_loss: 1.0646 - val_acc: 0.4575\n",
            "Epoch 135/150 - 0.24s - loss: 1.0615 - acc: 0.4622 - val_loss: 1.0644 - val_acc: 0.4575\n",
            "Epoch 136/150 - 0.21s - loss: 1.0613 - acc: 0.4629 - val_loss: 1.0643 - val_acc: 0.4575\n",
            "Epoch 137/150 - 0.22s - loss: 1.0611 - acc: 0.4627 - val_loss: 1.0642 - val_acc: 0.4595\n",
            "Epoch 138/150 - 0.21s - loss: 1.0610 - acc: 0.4629 - val_loss: 1.0641 - val_acc: 0.4595\n",
            "Epoch 139/150 - 0.21s - loss: 1.0608 - acc: 0.4627 - val_loss: 1.0640 - val_acc: 0.4595\n",
            "Epoch 140/150 - 0.23s - loss: 1.0607 - acc: 0.4627 - val_loss: 1.0639 - val_acc: 0.4595\n",
            "Epoch 141/150 - 0.22s - loss: 1.0605 - acc: 0.4633 - val_loss: 1.0637 - val_acc: 0.4595\n",
            "Epoch 142/150 - 0.22s - loss: 1.0603 - acc: 0.4638 - val_loss: 1.0636 - val_acc: 0.4595\n",
            "Epoch 143/150 - 0.26s - loss: 1.0602 - acc: 0.4649 - val_loss: 1.0635 - val_acc: 0.4615\n",
            "Epoch 144/150 - 0.20s - loss: 1.0600 - acc: 0.4656 - val_loss: 1.0634 - val_acc: 0.4615\n",
            "Epoch 145/150 - 0.22s - loss: 1.0598 - acc: 0.4654 - val_loss: 1.0633 - val_acc: 0.4636\n",
            "Epoch 146/150 - 0.22s - loss: 1.0597 - acc: 0.4658 - val_loss: 1.0632 - val_acc: 0.4615\n",
            "Epoch 147/150 - 0.21s - loss: 1.0595 - acc: 0.4660 - val_loss: 1.0631 - val_acc: 0.4636\n",
            "Epoch 148/150 - 0.24s - loss: 1.0594 - acc: 0.4660 - val_loss: 1.0629 - val_acc: 0.4636\n",
            "Epoch 149/150 - 0.23s - loss: 1.0592 - acc: 0.4660 - val_loss: 1.0628 - val_acc: 0.4615\n",
            "Epoch 150/150 - 0.24s - loss: 1.0590 - acc: 0.4660 - val_loss: 1.0627 - val_acc: 0.4615\n",
            "\n",
            "Combination 214/252:\n",
            "Hidden Layers: [256, 128, 64], Activation: tanh, Learning Rate: 0.0001, Batch Size: 64, Epochs: 50\n",
            "Epoch 1/50 - 0.18s - loss: 1.1017 - acc: 0.3446 - val_loss: 1.1030 - val_acc: 0.3421\n",
            "Epoch 2/50 - 0.21s - loss: 1.1013 - acc: 0.3446 - val_loss: 1.1027 - val_acc: 0.3401\n",
            "Epoch 3/50 - 0.18s - loss: 1.1010 - acc: 0.3435 - val_loss: 1.1024 - val_acc: 0.3401\n",
            "Epoch 4/50 - 0.18s - loss: 1.1007 - acc: 0.3419 - val_loss: 1.1022 - val_acc: 0.3421\n",
            "Epoch 5/50 - 0.18s - loss: 1.1004 - acc: 0.3408 - val_loss: 1.1019 - val_acc: 0.3441\n",
            "Epoch 6/50 - 0.19s - loss: 1.1001 - acc: 0.3419 - val_loss: 1.1017 - val_acc: 0.3421\n",
            "Epoch 7/50 - 0.18s - loss: 1.0999 - acc: 0.3408 - val_loss: 1.1015 - val_acc: 0.3381\n",
            "Epoch 8/50 - 0.18s - loss: 1.0996 - acc: 0.3437 - val_loss: 1.1012 - val_acc: 0.3401\n",
            "Epoch 9/50 - 0.17s - loss: 1.0994 - acc: 0.3430 - val_loss: 1.1010 - val_acc: 0.3421\n",
            "Epoch 10/50 - 0.19s - loss: 1.0992 - acc: 0.3419 - val_loss: 1.1008 - val_acc: 0.3441\n",
            "Epoch 11/50 - 0.17s - loss: 1.0990 - acc: 0.3435 - val_loss: 1.1007 - val_acc: 0.3462\n",
            "Epoch 12/50 - 0.20s - loss: 1.0988 - acc: 0.3428 - val_loss: 1.1005 - val_acc: 0.3441\n",
            "Epoch 13/50 - 0.17s - loss: 1.0986 - acc: 0.3441 - val_loss: 1.1003 - val_acc: 0.3421\n",
            "Epoch 14/50 - 0.18s - loss: 1.0984 - acc: 0.3459 - val_loss: 1.1002 - val_acc: 0.3360\n",
            "Epoch 15/50 - 0.17s - loss: 1.0982 - acc: 0.3471 - val_loss: 1.1000 - val_acc: 0.3381\n",
            "Epoch 16/50 - 0.18s - loss: 1.0980 - acc: 0.3473 - val_loss: 1.0999 - val_acc: 0.3320\n",
            "Epoch 17/50 - 0.17s - loss: 1.0978 - acc: 0.3480 - val_loss: 1.0997 - val_acc: 0.3279\n",
            "Epoch 18/50 - 0.19s - loss: 1.0976 - acc: 0.3486 - val_loss: 1.0996 - val_acc: 0.3340\n",
            "Epoch 19/50 - 0.17s - loss: 1.0975 - acc: 0.3480 - val_loss: 1.0994 - val_acc: 0.3320\n",
            "Epoch 20/50 - 0.20s - loss: 1.0973 - acc: 0.3480 - val_loss: 1.0993 - val_acc: 0.3320\n",
            "Epoch 21/50 - 0.18s - loss: 1.0971 - acc: 0.3475 - val_loss: 1.0991 - val_acc: 0.3300\n",
            "Epoch 22/50 - 0.19s - loss: 1.0969 - acc: 0.3477 - val_loss: 1.0990 - val_acc: 0.3300\n",
            "Epoch 23/50 - 0.17s - loss: 1.0968 - acc: 0.3491 - val_loss: 1.0988 - val_acc: 0.3300\n",
            "Epoch 24/50 - 0.18s - loss: 1.0966 - acc: 0.3484 - val_loss: 1.0987 - val_acc: 0.3340\n",
            "Epoch 25/50 - 0.17s - loss: 1.0964 - acc: 0.3498 - val_loss: 1.0985 - val_acc: 0.3320\n",
            "Epoch 26/50 - 0.26s - loss: 1.0963 - acc: 0.3500 - val_loss: 1.0984 - val_acc: 0.3320\n",
            "Epoch 27/50 - 0.19s - loss: 1.0961 - acc: 0.3511 - val_loss: 1.0983 - val_acc: 0.3300\n",
            "Epoch 28/50 - 0.18s - loss: 1.0959 - acc: 0.3520 - val_loss: 1.0981 - val_acc: 0.3320\n",
            "Epoch 29/50 - 0.18s - loss: 1.0958 - acc: 0.3525 - val_loss: 1.0980 - val_acc: 0.3300\n",
            "Epoch 30/50 - 0.23s - loss: 1.0956 - acc: 0.3536 - val_loss: 1.0979 - val_acc: 0.3340\n",
            "Epoch 31/50 - 0.21s - loss: 1.0954 - acc: 0.3554 - val_loss: 1.0977 - val_acc: 0.3360\n",
            "Epoch 32/50 - 0.18s - loss: 1.0953 - acc: 0.3554 - val_loss: 1.0976 - val_acc: 0.3340\n",
            "Epoch 33/50 - 0.18s - loss: 1.0951 - acc: 0.3565 - val_loss: 1.0975 - val_acc: 0.3360\n",
            "Epoch 34/50 - 0.19s - loss: 1.0950 - acc: 0.3572 - val_loss: 1.0973 - val_acc: 0.3381\n",
            "Epoch 35/50 - 0.18s - loss: 1.0948 - acc: 0.3574 - val_loss: 1.0972 - val_acc: 0.3421\n",
            "Epoch 36/50 - 0.18s - loss: 1.0947 - acc: 0.3583 - val_loss: 1.0971 - val_acc: 0.3421\n",
            "Epoch 37/50 - 0.18s - loss: 1.0945 - acc: 0.3612 - val_loss: 1.0970 - val_acc: 0.3441\n",
            "Epoch 38/50 - 0.21s - loss: 1.0943 - acc: 0.3614 - val_loss: 1.0968 - val_acc: 0.3421\n",
            "Epoch 39/50 - 0.20s - loss: 1.0942 - acc: 0.3619 - val_loss: 1.0967 - val_acc: 0.3421\n",
            "Epoch 40/50 - 0.21s - loss: 1.0940 - acc: 0.3630 - val_loss: 1.0966 - val_acc: 0.3381\n",
            "Epoch 41/50 - 0.18s - loss: 1.0939 - acc: 0.3632 - val_loss: 1.0964 - val_acc: 0.3381\n",
            "Epoch 42/50 - 0.19s - loss: 1.0937 - acc: 0.3664 - val_loss: 1.0963 - val_acc: 0.3381\n",
            "Epoch 43/50 - 0.18s - loss: 1.0936 - acc: 0.3673 - val_loss: 1.0962 - val_acc: 0.3401\n",
            "Epoch 44/50 - 0.18s - loss: 1.0934 - acc: 0.3673 - val_loss: 1.0961 - val_acc: 0.3401\n",
            "Epoch 45/50 - 0.17s - loss: 1.0933 - acc: 0.3668 - val_loss: 1.0959 - val_acc: 0.3401\n",
            "Epoch 46/50 - 0.19s - loss: 1.0931 - acc: 0.3675 - val_loss: 1.0958 - val_acc: 0.3421\n",
            "Epoch 47/50 - 0.17s - loss: 1.0930 - acc: 0.3686 - val_loss: 1.0957 - val_acc: 0.3482\n",
            "Epoch 48/50 - 0.18s - loss: 1.0928 - acc: 0.3695 - val_loss: 1.0956 - val_acc: 0.3502\n",
            "Epoch 49/50 - 0.18s - loss: 1.0927 - acc: 0.3700 - val_loss: 1.0954 - val_acc: 0.3502\n",
            "Epoch 50/50 - 0.19s - loss: 1.0925 - acc: 0.3707 - val_loss: 1.0953 - val_acc: 0.3482\n",
            "\n",
            "Combination 215/252:\n",
            "Hidden Layers: [256, 128, 64], Activation: tanh, Learning Rate: 0.0001, Batch Size: 64, Epochs: 100\n",
            "Epoch 1/100 - 0.19s - loss: 1.1319 - acc: 0.3097 - val_loss: 1.1285 - val_acc: 0.2935\n",
            "Epoch 2/100 - 0.19s - loss: 1.1283 - acc: 0.3120 - val_loss: 1.1252 - val_acc: 0.3036\n",
            "Epoch 3/100 - 0.16s - loss: 1.1253 - acc: 0.3104 - val_loss: 1.1224 - val_acc: 0.2955\n",
            "Epoch 4/100 - 0.19s - loss: 1.1225 - acc: 0.3050 - val_loss: 1.1199 - val_acc: 0.2996\n",
            "Epoch 5/100 - 0.15s - loss: 1.1201 - acc: 0.3025 - val_loss: 1.1178 - val_acc: 0.2955\n",
            "Epoch 6/100 - 0.17s - loss: 1.1180 - acc: 0.3032 - val_loss: 1.1159 - val_acc: 0.2935\n",
            "Epoch 7/100 - 0.16s - loss: 1.1162 - acc: 0.3016 - val_loss: 1.1143 - val_acc: 0.2955\n",
            "Epoch 8/100 - 0.17s - loss: 1.1146 - acc: 0.3030 - val_loss: 1.1129 - val_acc: 0.2955\n",
            "Epoch 9/100 - 0.16s - loss: 1.1132 - acc: 0.3021 - val_loss: 1.1116 - val_acc: 0.2955\n",
            "Epoch 10/100 - 0.16s - loss: 1.1120 - acc: 0.3025 - val_loss: 1.1105 - val_acc: 0.2955\n",
            "Epoch 11/100 - 0.16s - loss: 1.1109 - acc: 0.3034 - val_loss: 1.1096 - val_acc: 0.3036\n",
            "Epoch 12/100 - 0.17s - loss: 1.1099 - acc: 0.3023 - val_loss: 1.1087 - val_acc: 0.2976\n",
            "Epoch 13/100 - 0.16s - loss: 1.1091 - acc: 0.3007 - val_loss: 1.1080 - val_acc: 0.3016\n",
            "Epoch 14/100 - 0.16s - loss: 1.1083 - acc: 0.2985 - val_loss: 1.1074 - val_acc: 0.3097\n",
            "Epoch 15/100 - 0.16s - loss: 1.1076 - acc: 0.2982 - val_loss: 1.1068 - val_acc: 0.3178\n",
            "Epoch 16/100 - 0.16s - loss: 1.1070 - acc: 0.3005 - val_loss: 1.1063 - val_acc: 0.3259\n",
            "Epoch 17/100 - 0.18s - loss: 1.1065 - acc: 0.3030 - val_loss: 1.1058 - val_acc: 0.3239\n",
            "Epoch 18/100 - 0.22s - loss: 1.1060 - acc: 0.3025 - val_loss: 1.1054 - val_acc: 0.3219\n",
            "Epoch 19/100 - 0.16s - loss: 1.1055 - acc: 0.3079 - val_loss: 1.1050 - val_acc: 0.3198\n",
            "Epoch 20/100 - 0.18s - loss: 1.1051 - acc: 0.3077 - val_loss: 1.1046 - val_acc: 0.3219\n",
            "Epoch 21/100 - 0.18s - loss: 1.1047 - acc: 0.3104 - val_loss: 1.1043 - val_acc: 0.3300\n",
            "Epoch 22/100 - 0.17s - loss: 1.1044 - acc: 0.3088 - val_loss: 1.1040 - val_acc: 0.3300\n",
            "Epoch 23/100 - 0.16s - loss: 1.1040 - acc: 0.3088 - val_loss: 1.1037 - val_acc: 0.3279\n",
            "Epoch 24/100 - 0.21s - loss: 1.1037 - acc: 0.3079 - val_loss: 1.1035 - val_acc: 0.3198\n",
            "Epoch 25/100 - 0.17s - loss: 1.1034 - acc: 0.3086 - val_loss: 1.1032 - val_acc: 0.3198\n",
            "Epoch 26/100 - 0.17s - loss: 1.1031 - acc: 0.3113 - val_loss: 1.1030 - val_acc: 0.3259\n",
            "Epoch 27/100 - 0.17s - loss: 1.1029 - acc: 0.3117 - val_loss: 1.1028 - val_acc: 0.3320\n",
            "Epoch 28/100 - 0.18s - loss: 1.1026 - acc: 0.3126 - val_loss: 1.1026 - val_acc: 0.3421\n",
            "Epoch 29/100 - 0.16s - loss: 1.1024 - acc: 0.3113 - val_loss: 1.1024 - val_acc: 0.3421\n",
            "Epoch 30/100 - 0.18s - loss: 1.1022 - acc: 0.3149 - val_loss: 1.1022 - val_acc: 0.3421\n",
            "Epoch 31/100 - 0.16s - loss: 1.1019 - acc: 0.3165 - val_loss: 1.1020 - val_acc: 0.3462\n",
            "Epoch 32/100 - 0.17s - loss: 1.1017 - acc: 0.3162 - val_loss: 1.1018 - val_acc: 0.3462\n",
            "Epoch 33/100 - 0.18s - loss: 1.1015 - acc: 0.3160 - val_loss: 1.1017 - val_acc: 0.3462\n",
            "Epoch 34/100 - 0.18s - loss: 1.1013 - acc: 0.3169 - val_loss: 1.1015 - val_acc: 0.3482\n",
            "Epoch 35/100 - 0.17s - loss: 1.1011 - acc: 0.3187 - val_loss: 1.1013 - val_acc: 0.3482\n",
            "Epoch 36/100 - 0.17s - loss: 1.1009 - acc: 0.3237 - val_loss: 1.1012 - val_acc: 0.3482\n",
            "Epoch 37/100 - 0.16s - loss: 1.1007 - acc: 0.3243 - val_loss: 1.1010 - val_acc: 0.3462\n",
            "Epoch 38/100 - 0.16s - loss: 1.1005 - acc: 0.3255 - val_loss: 1.1009 - val_acc: 0.3441\n",
            "Epoch 39/100 - 0.15s - loss: 1.1003 - acc: 0.3268 - val_loss: 1.1007 - val_acc: 0.3482\n",
            "Epoch 40/100 - 0.17s - loss: 1.1002 - acc: 0.3286 - val_loss: 1.1005 - val_acc: 0.3502\n",
            "Epoch 41/100 - 0.16s - loss: 1.1000 - acc: 0.3322 - val_loss: 1.1004 - val_acc: 0.3543\n",
            "Epoch 42/100 - 0.17s - loss: 1.0998 - acc: 0.3333 - val_loss: 1.1002 - val_acc: 0.3543\n",
            "Epoch 43/100 - 0.16s - loss: 1.0996 - acc: 0.3347 - val_loss: 1.1001 - val_acc: 0.3583\n",
            "Epoch 44/100 - 0.17s - loss: 1.0995 - acc: 0.3345 - val_loss: 1.0999 - val_acc: 0.3583\n",
            "Epoch 45/100 - 0.20s - loss: 1.0993 - acc: 0.3376 - val_loss: 1.0998 - val_acc: 0.3563\n",
            "Epoch 46/100 - 0.17s - loss: 1.0991 - acc: 0.3387 - val_loss: 1.0996 - val_acc: 0.3583\n",
            "Epoch 47/100 - 0.18s - loss: 1.0989 - acc: 0.3412 - val_loss: 1.0995 - val_acc: 0.3623\n",
            "Epoch 48/100 - 0.18s - loss: 1.0988 - acc: 0.3421 - val_loss: 1.0994 - val_acc: 0.3644\n",
            "Epoch 49/100 - 0.15s - loss: 1.0986 - acc: 0.3432 - val_loss: 1.0992 - val_acc: 0.3623\n",
            "Epoch 50/100 - 0.17s - loss: 1.0984 - acc: 0.3450 - val_loss: 1.0991 - val_acc: 0.3644\n",
            "Epoch 51/100 - 0.16s - loss: 1.0983 - acc: 0.3432 - val_loss: 1.0989 - val_acc: 0.3684\n",
            "Epoch 52/100 - 0.17s - loss: 1.0981 - acc: 0.3450 - val_loss: 1.0988 - val_acc: 0.3704\n",
            "Epoch 53/100 - 0.16s - loss: 1.0979 - acc: 0.3466 - val_loss: 1.0987 - val_acc: 0.3704\n",
            "Epoch 54/100 - 0.16s - loss: 1.0978 - acc: 0.3500 - val_loss: 1.0985 - val_acc: 0.3704\n",
            "Epoch 55/100 - 0.16s - loss: 1.0976 - acc: 0.3509 - val_loss: 1.0984 - val_acc: 0.3664\n",
            "Epoch 56/100 - 0.17s - loss: 1.0974 - acc: 0.3516 - val_loss: 1.0983 - val_acc: 0.3644\n",
            "Epoch 57/100 - 0.16s - loss: 1.0973 - acc: 0.3536 - val_loss: 1.0981 - val_acc: 0.3623\n",
            "Epoch 58/100 - 0.16s - loss: 1.0971 - acc: 0.3538 - val_loss: 1.0980 - val_acc: 0.3623\n",
            "Epoch 59/100 - 0.17s - loss: 1.0970 - acc: 0.3554 - val_loss: 1.0979 - val_acc: 0.3644\n",
            "Epoch 60/100 - 0.18s - loss: 1.0968 - acc: 0.3565 - val_loss: 1.0977 - val_acc: 0.3603\n",
            "Epoch 61/100 - 0.16s - loss: 1.0966 - acc: 0.3558 - val_loss: 1.0976 - val_acc: 0.3644\n",
            "Epoch 62/100 - 0.16s - loss: 1.0965 - acc: 0.3578 - val_loss: 1.0975 - val_acc: 0.3623\n",
            "Epoch 63/100 - 0.20s - loss: 1.0963 - acc: 0.3574 - val_loss: 1.0973 - val_acc: 0.3603\n",
            "Epoch 64/100 - 0.19s - loss: 1.0962 - acc: 0.3581 - val_loss: 1.0972 - val_acc: 0.3603\n",
            "Epoch 65/100 - 0.16s - loss: 1.0960 - acc: 0.3590 - val_loss: 1.0971 - val_acc: 0.3603\n",
            "Epoch 66/100 - 0.17s - loss: 1.0959 - acc: 0.3596 - val_loss: 1.0970 - val_acc: 0.3623\n",
            "Epoch 67/100 - 0.19s - loss: 1.0957 - acc: 0.3601 - val_loss: 1.0968 - val_acc: 0.3623\n",
            "Epoch 68/100 - 0.19s - loss: 1.0955 - acc: 0.3608 - val_loss: 1.0967 - val_acc: 0.3644\n",
            "Epoch 69/100 - 0.17s - loss: 1.0954 - acc: 0.3619 - val_loss: 1.0966 - val_acc: 0.3603\n",
            "Epoch 70/100 - 0.19s - loss: 1.0952 - acc: 0.3644 - val_loss: 1.0964 - val_acc: 0.3603\n",
            "Epoch 71/100 - 0.17s - loss: 1.0951 - acc: 0.3653 - val_loss: 1.0963 - val_acc: 0.3603\n",
            "Epoch 72/100 - 0.22s - loss: 1.0949 - acc: 0.3655 - val_loss: 1.0962 - val_acc: 0.3623\n",
            "Epoch 73/100 - 0.17s - loss: 1.0948 - acc: 0.3659 - val_loss: 1.0961 - val_acc: 0.3623\n",
            "Epoch 74/100 - 0.17s - loss: 1.0946 - acc: 0.3673 - val_loss: 1.0959 - val_acc: 0.3623\n",
            "Epoch 75/100 - 0.16s - loss: 1.0945 - acc: 0.3680 - val_loss: 1.0958 - val_acc: 0.3623\n",
            "Epoch 76/100 - 0.18s - loss: 1.0943 - acc: 0.3675 - val_loss: 1.0957 - val_acc: 0.3623\n",
            "Epoch 77/100 - 0.17s - loss: 1.0942 - acc: 0.3684 - val_loss: 1.0956 - val_acc: 0.3623\n",
            "Epoch 78/100 - 0.18s - loss: 1.0940 - acc: 0.3677 - val_loss: 1.0955 - val_acc: 0.3664\n",
            "Epoch 79/100 - 0.16s - loss: 1.0939 - acc: 0.3684 - val_loss: 1.0953 - val_acc: 0.3684\n",
            "Epoch 80/100 - 0.18s - loss: 1.0938 - acc: 0.3686 - val_loss: 1.0952 - val_acc: 0.3684\n",
            "Epoch 81/100 - 0.16s - loss: 1.0936 - acc: 0.3691 - val_loss: 1.0951 - val_acc: 0.3684\n",
            "Epoch 82/100 - 0.16s - loss: 1.0935 - acc: 0.3700 - val_loss: 1.0950 - val_acc: 0.3684\n",
            "Epoch 83/100 - 0.16s - loss: 1.0933 - acc: 0.3707 - val_loss: 1.0949 - val_acc: 0.3725\n",
            "Epoch 84/100 - 0.17s - loss: 1.0932 - acc: 0.3722 - val_loss: 1.0947 - val_acc: 0.3725\n",
            "Epoch 85/100 - 0.16s - loss: 1.0930 - acc: 0.3727 - val_loss: 1.0946 - val_acc: 0.3704\n",
            "Epoch 86/100 - 0.16s - loss: 1.0929 - acc: 0.3740 - val_loss: 1.0945 - val_acc: 0.3704\n",
            "Epoch 87/100 - 0.16s - loss: 1.0927 - acc: 0.3745 - val_loss: 1.0944 - val_acc: 0.3704\n",
            "Epoch 88/100 - 0.17s - loss: 1.0926 - acc: 0.3758 - val_loss: 1.0943 - val_acc: 0.3704\n",
            "Epoch 89/100 - 0.16s - loss: 1.0925 - acc: 0.3763 - val_loss: 1.0942 - val_acc: 0.3704\n",
            "Epoch 90/100 - 0.18s - loss: 1.0923 - acc: 0.3758 - val_loss: 1.0940 - val_acc: 0.3725\n",
            "Epoch 91/100 - 0.16s - loss: 1.0922 - acc: 0.3765 - val_loss: 1.0939 - val_acc: 0.3704\n",
            "Epoch 92/100 - 0.17s - loss: 1.0920 - acc: 0.3776 - val_loss: 1.0938 - val_acc: 0.3684\n",
            "Epoch 93/100 - 0.16s - loss: 1.0919 - acc: 0.3774 - val_loss: 1.0937 - val_acc: 0.3725\n",
            "Epoch 94/100 - 0.16s - loss: 1.0918 - acc: 0.3779 - val_loss: 1.0936 - val_acc: 0.3725\n",
            "Epoch 95/100 - 0.16s - loss: 1.0916 - acc: 0.3797 - val_loss: 1.0935 - val_acc: 0.3725\n",
            "Epoch 96/100 - 0.18s - loss: 1.0915 - acc: 0.3803 - val_loss: 1.0933 - val_acc: 0.3704\n",
            "Epoch 97/100 - 0.19s - loss: 1.0913 - acc: 0.3797 - val_loss: 1.0932 - val_acc: 0.3664\n",
            "Epoch 98/100 - 0.17s - loss: 1.0912 - acc: 0.3812 - val_loss: 1.0931 - val_acc: 0.3664\n",
            "Epoch 99/100 - 0.16s - loss: 1.0911 - acc: 0.3812 - val_loss: 1.0930 - val_acc: 0.3664\n",
            "Epoch 100/100 - 0.17s - loss: 1.0909 - acc: 0.3821 - val_loss: 1.0929 - val_acc: 0.3644\n",
            "\n",
            "Combination 216/252:\n",
            "Hidden Layers: [256, 128, 64], Activation: tanh, Learning Rate: 0.0001, Batch Size: 64, Epochs: 150\n",
            "Epoch 1/150 - 0.16s - loss: 1.1259 - acc: 0.3347 - val_loss: 1.1217 - val_acc: 0.3401\n",
            "Epoch 2/150 - 0.17s - loss: 1.1221 - acc: 0.3369 - val_loss: 1.1182 - val_acc: 0.3360\n",
            "Epoch 3/150 - 0.18s - loss: 1.1189 - acc: 0.3372 - val_loss: 1.1153 - val_acc: 0.3219\n",
            "Epoch 4/150 - 0.17s - loss: 1.1162 - acc: 0.3354 - val_loss: 1.1128 - val_acc: 0.3198\n",
            "Epoch 5/150 - 0.16s - loss: 1.1139 - acc: 0.3372 - val_loss: 1.1108 - val_acc: 0.3178\n",
            "Epoch 6/150 - 0.17s - loss: 1.1119 - acc: 0.3333 - val_loss: 1.1090 - val_acc: 0.3057\n",
            "Epoch 7/150 - 0.16s - loss: 1.1103 - acc: 0.3351 - val_loss: 1.1076 - val_acc: 0.3077\n",
            "Epoch 8/150 - 0.18s - loss: 1.1088 - acc: 0.3381 - val_loss: 1.1063 - val_acc: 0.3117\n",
            "Epoch 9/150 - 0.17s - loss: 1.1076 - acc: 0.3401 - val_loss: 1.1052 - val_acc: 0.3117\n",
            "Epoch 10/150 - 0.17s - loss: 1.1065 - acc: 0.3423 - val_loss: 1.1043 - val_acc: 0.3158\n",
            "Epoch 11/150 - 0.16s - loss: 1.1056 - acc: 0.3450 - val_loss: 1.1035 - val_acc: 0.3219\n",
            "Epoch 12/150 - 0.17s - loss: 1.1048 - acc: 0.3484 - val_loss: 1.1029 - val_acc: 0.3239\n",
            "Epoch 13/150 - 0.16s - loss: 1.1041 - acc: 0.3493 - val_loss: 1.1023 - val_acc: 0.3219\n",
            "Epoch 14/150 - 0.22s - loss: 1.1035 - acc: 0.3516 - val_loss: 1.1018 - val_acc: 0.3320\n",
            "Epoch 15/150 - 0.16s - loss: 1.1030 - acc: 0.3538 - val_loss: 1.1013 - val_acc: 0.3279\n",
            "Epoch 16/150 - 0.17s - loss: 1.1025 - acc: 0.3516 - val_loss: 1.1009 - val_acc: 0.3279\n",
            "Epoch 17/150 - 0.16s - loss: 1.1020 - acc: 0.3534 - val_loss: 1.1006 - val_acc: 0.3279\n",
            "Epoch 18/150 - 0.16s - loss: 1.1016 - acc: 0.3518 - val_loss: 1.1002 - val_acc: 0.3340\n",
            "Epoch 19/150 - 0.16s - loss: 1.1013 - acc: 0.3529 - val_loss: 1.1000 - val_acc: 0.3239\n",
            "Epoch 20/150 - 0.17s - loss: 1.1009 - acc: 0.3529 - val_loss: 1.0997 - val_acc: 0.3320\n",
            "Epoch 21/150 - 0.16s - loss: 1.1006 - acc: 0.3520 - val_loss: 1.0994 - val_acc: 0.3441\n",
            "Epoch 22/150 - 0.17s - loss: 1.1003 - acc: 0.3520 - val_loss: 1.0992 - val_acc: 0.3502\n",
            "Epoch 23/150 - 0.16s - loss: 1.1000 - acc: 0.3502 - val_loss: 1.0990 - val_acc: 0.3482\n",
            "Epoch 24/150 - 0.17s - loss: 1.0997 - acc: 0.3536 - val_loss: 1.0988 - val_acc: 0.3502\n",
            "Epoch 25/150 - 0.16s - loss: 1.0995 - acc: 0.3531 - val_loss: 1.0986 - val_acc: 0.3441\n",
            "Epoch 26/150 - 0.16s - loss: 1.0992 - acc: 0.3511 - val_loss: 1.0984 - val_acc: 0.3360\n",
            "Epoch 27/150 - 0.18s - loss: 1.0990 - acc: 0.3549 - val_loss: 1.0982 - val_acc: 0.3381\n",
            "Epoch 28/150 - 0.18s - loss: 1.0987 - acc: 0.3536 - val_loss: 1.0980 - val_acc: 0.3340\n",
            "Epoch 29/150 - 0.16s - loss: 1.0985 - acc: 0.3543 - val_loss: 1.0978 - val_acc: 0.3320\n",
            "Epoch 30/150 - 0.18s - loss: 1.0983 - acc: 0.3540 - val_loss: 1.0976 - val_acc: 0.3320\n",
            "Epoch 31/150 - 0.21s - loss: 1.0981 - acc: 0.3558 - val_loss: 1.0975 - val_acc: 0.3300\n",
            "Epoch 32/150 - 0.20s - loss: 1.0979 - acc: 0.3554 - val_loss: 1.0973 - val_acc: 0.3381\n",
            "Epoch 33/150 - 0.18s - loss: 1.0976 - acc: 0.3565 - val_loss: 1.0972 - val_acc: 0.3360\n",
            "Epoch 34/150 - 0.19s - loss: 1.0974 - acc: 0.3567 - val_loss: 1.0970 - val_acc: 0.3320\n",
            "Epoch 35/150 - 0.17s - loss: 1.0972 - acc: 0.3583 - val_loss: 1.0968 - val_acc: 0.3401\n",
            "Epoch 36/150 - 0.18s - loss: 1.0970 - acc: 0.3574 - val_loss: 1.0967 - val_acc: 0.3421\n",
            "Epoch 37/150 - 0.18s - loss: 1.0968 - acc: 0.3574 - val_loss: 1.0965 - val_acc: 0.3421\n",
            "Epoch 38/150 - 0.16s - loss: 1.0966 - acc: 0.3585 - val_loss: 1.0964 - val_acc: 0.3421\n",
            "Epoch 39/150 - 0.18s - loss: 1.0964 - acc: 0.3605 - val_loss: 1.0962 - val_acc: 0.3381\n",
            "Epoch 40/150 - 0.17s - loss: 1.0962 - acc: 0.3621 - val_loss: 1.0961 - val_acc: 0.3401\n",
            "Epoch 41/150 - 0.16s - loss: 1.0960 - acc: 0.3637 - val_loss: 1.0959 - val_acc: 0.3401\n",
            "Epoch 42/150 - 0.19s - loss: 1.0959 - acc: 0.3641 - val_loss: 1.0957 - val_acc: 0.3401\n",
            "Epoch 43/150 - 0.19s - loss: 1.0957 - acc: 0.3657 - val_loss: 1.0956 - val_acc: 0.3401\n",
            "Epoch 44/150 - 0.18s - loss: 1.0955 - acc: 0.3664 - val_loss: 1.0954 - val_acc: 0.3401\n",
            "Epoch 45/150 - 0.17s - loss: 1.0953 - acc: 0.3671 - val_loss: 1.0953 - val_acc: 0.3441\n",
            "Epoch 46/150 - 0.18s - loss: 1.0951 - acc: 0.3684 - val_loss: 1.0951 - val_acc: 0.3441\n",
            "Epoch 47/150 - 0.16s - loss: 1.0949 - acc: 0.3689 - val_loss: 1.0950 - val_acc: 0.3462\n",
            "Epoch 48/150 - 0.17s - loss: 1.0947 - acc: 0.3686 - val_loss: 1.0948 - val_acc: 0.3482\n",
            "Epoch 49/150 - 0.16s - loss: 1.0945 - acc: 0.3698 - val_loss: 1.0947 - val_acc: 0.3502\n",
            "Epoch 50/150 - 0.21s - loss: 1.0943 - acc: 0.3695 - val_loss: 1.0945 - val_acc: 0.3522\n",
            "Epoch 51/150 - 0.19s - loss: 1.0942 - acc: 0.3718 - val_loss: 1.0944 - val_acc: 0.3522\n",
            "Epoch 52/150 - 0.19s - loss: 1.0940 - acc: 0.3722 - val_loss: 1.0942 - val_acc: 0.3543\n",
            "Epoch 53/150 - 0.17s - loss: 1.0938 - acc: 0.3727 - val_loss: 1.0941 - val_acc: 0.3543\n",
            "Epoch 54/150 - 0.18s - loss: 1.0936 - acc: 0.3727 - val_loss: 1.0940 - val_acc: 0.3522\n",
            "Epoch 55/150 - 0.18s - loss: 1.0934 - acc: 0.3731 - val_loss: 1.0938 - val_acc: 0.3543\n",
            "Epoch 56/150 - 0.18s - loss: 1.0933 - acc: 0.3729 - val_loss: 1.0937 - val_acc: 0.3543\n",
            "Epoch 57/150 - 0.18s - loss: 1.0931 - acc: 0.3736 - val_loss: 1.0935 - val_acc: 0.3502\n",
            "Epoch 58/150 - 0.18s - loss: 1.0929 - acc: 0.3734 - val_loss: 1.0934 - val_acc: 0.3543\n",
            "Epoch 59/150 - 0.17s - loss: 1.0927 - acc: 0.3738 - val_loss: 1.0933 - val_acc: 0.3502\n",
            "Epoch 60/150 - 0.18s - loss: 1.0925 - acc: 0.3740 - val_loss: 1.0931 - val_acc: 0.3482\n",
            "Epoch 61/150 - 0.17s - loss: 1.0924 - acc: 0.3743 - val_loss: 1.0930 - val_acc: 0.3482\n",
            "Epoch 62/150 - 0.20s - loss: 1.0922 - acc: 0.3752 - val_loss: 1.0928 - val_acc: 0.3502\n",
            "Epoch 63/150 - 0.19s - loss: 1.0920 - acc: 0.3761 - val_loss: 1.0927 - val_acc: 0.3522\n",
            "Epoch 64/150 - 0.19s - loss: 1.0918 - acc: 0.3772 - val_loss: 1.0926 - val_acc: 0.3522\n",
            "Epoch 65/150 - 0.18s - loss: 1.0917 - acc: 0.3776 - val_loss: 1.0924 - val_acc: 0.3522\n",
            "Epoch 66/150 - 0.18s - loss: 1.0915 - acc: 0.3779 - val_loss: 1.0923 - val_acc: 0.3543\n",
            "Epoch 67/150 - 0.18s - loss: 1.0913 - acc: 0.3794 - val_loss: 1.0922 - val_acc: 0.3543\n",
            "Epoch 68/150 - 0.20s - loss: 1.0912 - acc: 0.3812 - val_loss: 1.0920 - val_acc: 0.3563\n",
            "Epoch 69/150 - 0.17s - loss: 1.0910 - acc: 0.3819 - val_loss: 1.0919 - val_acc: 0.3563\n",
            "Epoch 70/150 - 0.17s - loss: 1.0908 - acc: 0.3815 - val_loss: 1.0918 - val_acc: 0.3563\n",
            "Epoch 71/150 - 0.18s - loss: 1.0906 - acc: 0.3819 - val_loss: 1.0916 - val_acc: 0.3583\n",
            "Epoch 72/150 - 0.19s - loss: 1.0905 - acc: 0.3826 - val_loss: 1.0915 - val_acc: 0.3563\n",
            "Epoch 73/150 - 0.19s - loss: 1.0903 - acc: 0.3824 - val_loss: 1.0914 - val_acc: 0.3583\n",
            "Epoch 74/150 - 0.20s - loss: 1.0901 - acc: 0.3819 - val_loss: 1.0912 - val_acc: 0.3563\n",
            "Epoch 75/150 - 0.17s - loss: 1.0900 - acc: 0.3830 - val_loss: 1.0911 - val_acc: 0.3563\n",
            "Epoch 76/150 - 0.18s - loss: 1.0898 - acc: 0.3835 - val_loss: 1.0910 - val_acc: 0.3563\n",
            "Epoch 77/150 - 0.17s - loss: 1.0896 - acc: 0.3837 - val_loss: 1.0909 - val_acc: 0.3563\n",
            "Epoch 78/150 - 0.16s - loss: 1.0895 - acc: 0.3842 - val_loss: 1.0907 - val_acc: 0.3563\n",
            "Epoch 79/150 - 0.16s - loss: 1.0893 - acc: 0.3844 - val_loss: 1.0906 - val_acc: 0.3563\n",
            "Epoch 80/150 - 0.18s - loss: 1.0892 - acc: 0.3869 - val_loss: 1.0905 - val_acc: 0.3583\n",
            "Epoch 81/150 - 0.18s - loss: 1.0890 - acc: 0.3882 - val_loss: 1.0903 - val_acc: 0.3603\n",
            "Epoch 82/150 - 0.17s - loss: 1.0888 - acc: 0.3884 - val_loss: 1.0902 - val_acc: 0.3583\n",
            "Epoch 83/150 - 0.17s - loss: 1.0887 - acc: 0.3896 - val_loss: 1.0901 - val_acc: 0.3583\n",
            "Epoch 84/150 - 0.18s - loss: 1.0885 - acc: 0.3905 - val_loss: 1.0900 - val_acc: 0.3603\n",
            "Epoch 85/150 - 0.16s - loss: 1.0883 - acc: 0.3916 - val_loss: 1.0898 - val_acc: 0.3644\n",
            "Epoch 86/150 - 0.20s - loss: 1.0882 - acc: 0.3927 - val_loss: 1.0897 - val_acc: 0.3664\n",
            "Epoch 87/150 - 0.16s - loss: 1.0880 - acc: 0.3927 - val_loss: 1.0896 - val_acc: 0.3644\n",
            "Epoch 88/150 - 0.17s - loss: 1.0879 - acc: 0.3938 - val_loss: 1.0895 - val_acc: 0.3623\n",
            "Epoch 89/150 - 0.16s - loss: 1.0877 - acc: 0.3952 - val_loss: 1.0893 - val_acc: 0.3623\n",
            "Epoch 90/150 - 0.16s - loss: 1.0876 - acc: 0.3956 - val_loss: 1.0892 - val_acc: 0.3664\n",
            "Epoch 91/150 - 0.16s - loss: 1.0874 - acc: 0.3954 - val_loss: 1.0891 - val_acc: 0.3644\n",
            "Epoch 92/150 - 0.17s - loss: 1.0872 - acc: 0.3961 - val_loss: 1.0890 - val_acc: 0.3644\n",
            "Epoch 93/150 - 0.16s - loss: 1.0871 - acc: 0.3970 - val_loss: 1.0889 - val_acc: 0.3644\n",
            "Epoch 94/150 - 0.16s - loss: 1.0869 - acc: 0.4004 - val_loss: 1.0887 - val_acc: 0.3644\n",
            "Epoch 95/150 - 0.16s - loss: 1.0868 - acc: 0.4013 - val_loss: 1.0886 - val_acc: 0.3644\n",
            "Epoch 96/150 - 0.17s - loss: 1.0866 - acc: 0.4015 - val_loss: 1.0885 - val_acc: 0.3623\n",
            "Epoch 97/150 - 0.16s - loss: 1.0865 - acc: 0.4017 - val_loss: 1.0884 - val_acc: 0.3603\n",
            "Epoch 98/150 - 0.16s - loss: 1.0863 - acc: 0.4028 - val_loss: 1.0883 - val_acc: 0.3623\n",
            "Epoch 99/150 - 0.17s - loss: 1.0862 - acc: 0.4040 - val_loss: 1.0881 - val_acc: 0.3623\n",
            "Epoch 100/150 - 0.17s - loss: 1.0860 - acc: 0.4042 - val_loss: 1.0880 - val_acc: 0.3623\n",
            "Epoch 101/150 - 0.16s - loss: 1.0859 - acc: 0.4046 - val_loss: 1.0879 - val_acc: 0.3644\n",
            "Epoch 102/150 - 0.16s - loss: 1.0857 - acc: 0.4035 - val_loss: 1.0878 - val_acc: 0.3623\n",
            "Epoch 103/150 - 0.16s - loss: 1.0856 - acc: 0.4044 - val_loss: 1.0877 - val_acc: 0.3644\n",
            "Epoch 104/150 - 0.18s - loss: 1.0854 - acc: 0.4051 - val_loss: 1.0875 - val_acc: 0.3644\n",
            "Epoch 105/150 - 0.16s - loss: 1.0853 - acc: 0.4053 - val_loss: 1.0874 - val_acc: 0.3644\n",
            "Epoch 106/150 - 0.16s - loss: 1.0851 - acc: 0.4053 - val_loss: 1.0873 - val_acc: 0.3644\n",
            "Epoch 107/150 - 0.16s - loss: 1.0850 - acc: 0.4060 - val_loss: 1.0872 - val_acc: 0.3644\n",
            "Epoch 108/150 - 0.17s - loss: 1.0848 - acc: 0.4060 - val_loss: 1.0871 - val_acc: 0.3664\n",
            "Epoch 109/150 - 0.16s - loss: 1.0847 - acc: 0.4071 - val_loss: 1.0870 - val_acc: 0.3684\n",
            "Epoch 110/150 - 0.17s - loss: 1.0845 - acc: 0.4076 - val_loss: 1.0869 - val_acc: 0.3684\n",
            "Epoch 111/150 - 0.16s - loss: 1.0844 - acc: 0.4085 - val_loss: 1.0868 - val_acc: 0.3704\n",
            "Epoch 112/150 - 0.17s - loss: 1.0842 - acc: 0.4080 - val_loss: 1.0867 - val_acc: 0.3684\n",
            "Epoch 113/150 - 0.16s - loss: 1.0841 - acc: 0.4103 - val_loss: 1.0865 - val_acc: 0.3704\n",
            "Epoch 114/150 - 0.16s - loss: 1.0839 - acc: 0.4105 - val_loss: 1.0864 - val_acc: 0.3704\n",
            "Epoch 115/150 - 0.16s - loss: 1.0838 - acc: 0.4118 - val_loss: 1.0863 - val_acc: 0.3725\n",
            "Epoch 116/150 - 0.17s - loss: 1.0836 - acc: 0.4116 - val_loss: 1.0862 - val_acc: 0.3725\n",
            "Epoch 117/150 - 0.16s - loss: 1.0835 - acc: 0.4121 - val_loss: 1.0861 - val_acc: 0.3725\n",
            "Epoch 118/150 - 0.16s - loss: 1.0834 - acc: 0.4123 - val_loss: 1.0860 - val_acc: 0.3725\n",
            "Epoch 119/150 - 0.16s - loss: 1.0832 - acc: 0.4127 - val_loss: 1.0859 - val_acc: 0.3745\n",
            "Epoch 120/150 - 0.17s - loss: 1.0831 - acc: 0.4148 - val_loss: 1.0858 - val_acc: 0.3765\n",
            "Epoch 121/150 - 0.16s - loss: 1.0829 - acc: 0.4150 - val_loss: 1.0857 - val_acc: 0.3806\n",
            "Epoch 122/150 - 0.22s - loss: 1.0828 - acc: 0.4159 - val_loss: 1.0856 - val_acc: 0.3826\n",
            "Epoch 123/150 - 0.16s - loss: 1.0827 - acc: 0.4163 - val_loss: 1.0855 - val_acc: 0.3826\n",
            "Epoch 124/150 - 0.18s - loss: 1.0825 - acc: 0.4172 - val_loss: 1.0854 - val_acc: 0.3846\n",
            "Epoch 125/150 - 0.16s - loss: 1.0824 - acc: 0.4190 - val_loss: 1.0852 - val_acc: 0.3826\n",
            "Epoch 126/150 - 0.16s - loss: 1.0822 - acc: 0.4190 - val_loss: 1.0851 - val_acc: 0.3826\n",
            "Epoch 127/150 - 0.16s - loss: 1.0821 - acc: 0.4188 - val_loss: 1.0850 - val_acc: 0.3826\n",
            "Epoch 128/150 - 0.17s - loss: 1.0820 - acc: 0.4197 - val_loss: 1.0849 - val_acc: 0.3826\n",
            "Epoch 129/150 - 0.16s - loss: 1.0818 - acc: 0.4204 - val_loss: 1.0848 - val_acc: 0.3826\n",
            "Epoch 130/150 - 0.16s - loss: 1.0817 - acc: 0.4208 - val_loss: 1.0847 - val_acc: 0.3866\n",
            "Epoch 131/150 - 0.16s - loss: 1.0815 - acc: 0.4202 - val_loss: 1.0846 - val_acc: 0.3866\n",
            "Epoch 132/150 - 0.17s - loss: 1.0814 - acc: 0.4213 - val_loss: 1.0845 - val_acc: 0.3866\n",
            "Epoch 133/150 - 0.16s - loss: 1.0813 - acc: 0.4217 - val_loss: 1.0844 - val_acc: 0.3887\n",
            "Epoch 134/150 - 0.18s - loss: 1.0811 - acc: 0.4220 - val_loss: 1.0843 - val_acc: 0.3887\n",
            "Epoch 135/150 - 0.16s - loss: 1.0810 - acc: 0.4220 - val_loss: 1.0842 - val_acc: 0.3826\n",
            "Epoch 136/150 - 0.17s - loss: 1.0809 - acc: 0.4229 - val_loss: 1.0841 - val_acc: 0.3826\n",
            "Epoch 137/150 - 0.17s - loss: 1.0807 - acc: 0.4233 - val_loss: 1.0840 - val_acc: 0.3826\n",
            "Epoch 138/150 - 0.17s - loss: 1.0806 - acc: 0.4240 - val_loss: 1.0839 - val_acc: 0.3826\n",
            "Epoch 139/150 - 0.16s - loss: 1.0805 - acc: 0.4251 - val_loss: 1.0838 - val_acc: 0.3866\n",
            "Epoch 140/150 - 0.19s - loss: 1.0803 - acc: 0.4249 - val_loss: 1.0837 - val_acc: 0.3866\n",
            "Epoch 141/150 - 0.18s - loss: 1.0802 - acc: 0.4249 - val_loss: 1.0836 - val_acc: 0.3866\n",
            "Epoch 142/150 - 0.17s - loss: 1.0801 - acc: 0.4253 - val_loss: 1.0835 - val_acc: 0.3866\n",
            "Epoch 143/150 - 0.16s - loss: 1.0799 - acc: 0.4267 - val_loss: 1.0834 - val_acc: 0.3866\n",
            "Epoch 144/150 - 0.17s - loss: 1.0798 - acc: 0.4267 - val_loss: 1.0833 - val_acc: 0.3846\n",
            "Epoch 145/150 - 0.16s - loss: 1.0797 - acc: 0.4267 - val_loss: 1.0832 - val_acc: 0.3866\n",
            "Epoch 146/150 - 0.19s - loss: 1.0795 - acc: 0.4265 - val_loss: 1.0831 - val_acc: 0.3866\n",
            "Epoch 147/150 - 0.17s - loss: 1.0794 - acc: 0.4278 - val_loss: 1.0830 - val_acc: 0.3846\n",
            "Epoch 148/150 - 0.19s - loss: 1.0793 - acc: 0.4276 - val_loss: 1.0829 - val_acc: 0.3866\n",
            "Epoch 149/150 - 0.17s - loss: 1.0792 - acc: 0.4280 - val_loss: 1.0828 - val_acc: 0.3866\n",
            "Epoch 150/150 - 0.16s - loss: 1.0790 - acc: 0.4280 - val_loss: 1.0827 - val_acc: 0.3866\n",
            "\n",
            "Combination 217/252:\n",
            "Hidden Layers: [512, 256, 128], Activation: relu, Learning Rate: 0.01, Batch Size: 32, Epochs: 50\n",
            "Epoch 1/50 - 0.51s - loss: 1.0731 - acc: 0.4397 - val_loss: 1.0791 - val_acc: 0.4231\n",
            "Epoch 2/50 - 0.53s - loss: 1.0521 - acc: 0.4696 - val_loss: 1.0638 - val_acc: 0.4433\n",
            "Epoch 3/50 - 0.57s - loss: 1.0387 - acc: 0.4908 - val_loss: 1.0553 - val_acc: 0.4534\n",
            "Epoch 4/50 - 0.57s - loss: 1.0264 - acc: 0.4991 - val_loss: 1.0472 - val_acc: 0.4676\n",
            "Epoch 5/50 - 0.53s - loss: 1.0175 - acc: 0.5034 - val_loss: 1.0433 - val_acc: 0.4615\n",
            "Epoch 6/50 - 0.52s - loss: 0.9992 - acc: 0.5241 - val_loss: 1.0287 - val_acc: 0.4980\n",
            "Epoch 7/50 - 0.53s - loss: 0.9883 - acc: 0.5263 - val_loss: 1.0208 - val_acc: 0.5142\n",
            "Epoch 8/50 - 0.52s - loss: 0.9759 - acc: 0.5425 - val_loss: 1.0102 - val_acc: 0.5182\n",
            "Epoch 9/50 - 0.51s - loss: 0.9677 - acc: 0.5427 - val_loss: 1.0042 - val_acc: 0.5263\n",
            "Epoch 10/50 - 0.55s - loss: 0.9631 - acc: 0.5418 - val_loss: 1.0012 - val_acc: 0.5223\n",
            "Epoch 11/50 - 0.51s - loss: 0.9476 - acc: 0.5445 - val_loss: 0.9938 - val_acc: 0.5243\n",
            "Epoch 12/50 - 0.50s - loss: 0.9492 - acc: 0.5504 - val_loss: 0.9948 - val_acc: 0.5364\n",
            "Epoch 13/50 - 0.55s - loss: 0.9301 - acc: 0.5612 - val_loss: 0.9819 - val_acc: 0.5364\n",
            "Epoch 14/50 - 0.52s - loss: 0.9222 - acc: 0.5691 - val_loss: 0.9754 - val_acc: 0.5587\n",
            "Epoch 15/50 - 0.53s - loss: 0.9242 - acc: 0.5643 - val_loss: 0.9859 - val_acc: 0.5121\n",
            "Epoch 16/50 - 0.57s - loss: 0.9523 - acc: 0.5376 - val_loss: 1.0210 - val_acc: 0.4717\n",
            "Epoch 17/50 - 0.56s - loss: 0.9000 - acc: 0.5834 - val_loss: 0.9638 - val_acc: 0.5628\n",
            "Epoch 18/50 - 0.53s - loss: 0.8924 - acc: 0.5915 - val_loss: 0.9591 - val_acc: 0.5607\n",
            "Epoch 19/50 - 0.56s - loss: 0.8976 - acc: 0.5816 - val_loss: 0.9616 - val_acc: 0.5668\n",
            "Epoch 20/50 - 0.55s - loss: 0.8815 - acc: 0.5929 - val_loss: 0.9520 - val_acc: 0.5688\n",
            "Epoch 21/50 - 0.55s - loss: 0.8796 - acc: 0.5965 - val_loss: 0.9649 - val_acc: 0.5304\n",
            "Epoch 22/50 - 0.58s - loss: 0.8672 - acc: 0.6039 - val_loss: 0.9481 - val_acc: 0.5668\n",
            "Epoch 23/50 - 0.58s - loss: 0.8729 - acc: 0.5906 - val_loss: 0.9490 - val_acc: 0.5648\n",
            "Epoch 24/50 - 0.53s - loss: 0.8627 - acc: 0.6021 - val_loss: 0.9584 - val_acc: 0.5364\n",
            "Epoch 25/50 - 0.57s - loss: 0.8691 - acc: 0.5972 - val_loss: 0.9742 - val_acc: 0.5162\n",
            "Epoch 26/50 - 0.53s - loss: 0.8433 - acc: 0.6134 - val_loss: 0.9418 - val_acc: 0.5729\n",
            "Epoch 27/50 - 0.53s - loss: 0.8854 - acc: 0.5780 - val_loss: 1.0007 - val_acc: 0.5202\n",
            "Epoch 28/50 - 0.53s - loss: 0.8877 - acc: 0.5785 - val_loss: 1.0137 - val_acc: 0.5000\n",
            "Epoch 29/50 - 0.54s - loss: 0.8222 - acc: 0.6300 - val_loss: 0.9358 - val_acc: 0.5567\n",
            "Epoch 30/50 - 0.51s - loss: 0.8399 - acc: 0.6113 - val_loss: 0.9610 - val_acc: 0.5547\n",
            "Epoch 31/50 - 0.56s - loss: 0.8208 - acc: 0.6309 - val_loss: 0.9398 - val_acc: 0.5850\n",
            "Epoch 32/50 - 0.53s - loss: 0.8221 - acc: 0.6352 - val_loss: 0.9514 - val_acc: 0.5830\n",
            "Epoch 33/50 - 0.57s - loss: 0.8646 - acc: 0.6010 - val_loss: 1.0241 - val_acc: 0.4858\n",
            "Epoch 34/50 - 0.53s - loss: 0.7974 - acc: 0.6374 - val_loss: 0.9352 - val_acc: 0.5749\n",
            "Epoch 35/50 - 0.52s - loss: 0.7916 - acc: 0.6415 - val_loss: 0.9328 - val_acc: 0.5830\n",
            "Epoch 36/50 - 0.50s - loss: 0.7941 - acc: 0.6460 - val_loss: 0.9567 - val_acc: 0.5344\n",
            "Epoch 37/50 - 0.56s - loss: 0.7800 - acc: 0.6631 - val_loss: 0.9358 - val_acc: 0.5506\n",
            "Epoch 38/50 - 0.50s - loss: 0.7713 - acc: 0.6664 - val_loss: 0.9462 - val_acc: 0.5405\n",
            "Epoch 39/50 - 0.52s - loss: 0.7964 - acc: 0.6273 - val_loss: 0.9645 - val_acc: 0.5405\n",
            "Epoch 40/50 - 0.52s - loss: 0.7701 - acc: 0.6637 - val_loss: 0.9467 - val_acc: 0.5547\n",
            "Epoch 41/50 - 0.54s - loss: 0.7757 - acc: 0.6586 - val_loss: 0.9567 - val_acc: 0.5405\n",
            "Epoch 42/50 - 0.52s - loss: 0.7553 - acc: 0.6757 - val_loss: 0.9523 - val_acc: 0.5628\n",
            "Epoch 43/50 - 0.54s - loss: 0.7547 - acc: 0.6736 - val_loss: 0.9597 - val_acc: 0.5607\n",
            "Epoch 44/50 - 0.50s - loss: 0.8183 - acc: 0.6246 - val_loss: 1.0472 - val_acc: 0.5000\n",
            "Epoch 45/50 - 0.50s - loss: 0.7303 - acc: 0.6925 - val_loss: 0.9381 - val_acc: 0.5607\n",
            "Epoch 46/50 - 0.50s - loss: 0.7233 - acc: 0.6984 - val_loss: 0.9265 - val_acc: 0.5547\n",
            "Epoch 47/50 - 0.52s - loss: 0.8979 - acc: 0.5918 - val_loss: 1.1518 - val_acc: 0.4615\n",
            "Epoch 48/50 - 0.52s - loss: 0.7133 - acc: 0.7038 - val_loss: 0.9376 - val_acc: 0.5607\n",
            "Epoch 49/50 - 0.56s - loss: 0.8028 - acc: 0.6239 - val_loss: 1.0513 - val_acc: 0.5101\n",
            "Epoch 50/50 - 0.53s - loss: 0.7134 - acc: 0.6957 - val_loss: 0.9591 - val_acc: 0.5506\n",
            "\n",
            "Combination 218/252:\n",
            "Hidden Layers: [512, 256, 128], Activation: relu, Learning Rate: 0.01, Batch Size: 32, Epochs: 100\n",
            "Epoch 1/100 - 0.51s - loss: 1.0773 - acc: 0.4453 - val_loss: 1.0859 - val_acc: 0.4109\n",
            "Epoch 2/100 - 0.51s - loss: 1.0596 - acc: 0.4620 - val_loss: 1.0727 - val_acc: 0.4433\n",
            "Epoch 3/100 - 0.54s - loss: 1.0468 - acc: 0.4699 - val_loss: 1.0615 - val_acc: 0.4332\n",
            "Epoch 4/100 - 0.50s - loss: 1.0340 - acc: 0.4856 - val_loss: 1.0556 - val_acc: 0.4656\n",
            "Epoch 5/100 - 0.55s - loss: 1.0228 - acc: 0.4939 - val_loss: 1.0450 - val_acc: 0.4615\n",
            "Epoch 6/100 - 0.50s - loss: 1.0095 - acc: 0.5065 - val_loss: 1.0377 - val_acc: 0.4879\n",
            "Epoch 7/100 - 0.53s - loss: 0.9988 - acc: 0.5130 - val_loss: 1.0313 - val_acc: 0.4899\n",
            "Epoch 8/100 - 0.52s - loss: 0.9862 - acc: 0.5274 - val_loss: 1.0204 - val_acc: 0.4939\n",
            "Epoch 9/100 - 0.53s - loss: 0.9767 - acc: 0.5254 - val_loss: 1.0107 - val_acc: 0.5121\n",
            "Epoch 10/100 - 0.51s - loss: 0.9725 - acc: 0.5263 - val_loss: 1.0066 - val_acc: 0.5182\n",
            "Epoch 11/100 - 0.55s - loss: 0.9631 - acc: 0.5502 - val_loss: 1.0059 - val_acc: 0.5304\n",
            "Epoch 12/100 - 0.50s - loss: 0.9498 - acc: 0.5607 - val_loss: 0.9919 - val_acc: 0.5364\n",
            "Epoch 13/100 - 0.50s - loss: 0.9468 - acc: 0.5475 - val_loss: 0.9873 - val_acc: 0.5304\n",
            "Epoch 14/100 - 0.50s - loss: 0.9377 - acc: 0.5544 - val_loss: 0.9876 - val_acc: 0.5162\n",
            "Epoch 15/100 - 0.51s - loss: 0.9236 - acc: 0.5625 - val_loss: 0.9737 - val_acc: 0.5628\n",
            "Epoch 16/100 - 0.53s - loss: 0.9179 - acc: 0.5670 - val_loss: 0.9738 - val_acc: 0.5547\n",
            "Epoch 17/100 - 0.56s - loss: 0.9242 - acc: 0.5648 - val_loss: 0.9861 - val_acc: 0.5081\n",
            "Epoch 18/100 - 0.52s - loss: 0.9051 - acc: 0.5776 - val_loss: 0.9682 - val_acc: 0.5385\n",
            "Epoch 19/100 - 0.51s - loss: 0.9061 - acc: 0.5709 - val_loss: 0.9778 - val_acc: 0.5344\n",
            "Epoch 20/100 - 0.52s - loss: 0.9134 - acc: 0.5738 - val_loss: 0.9869 - val_acc: 0.5121\n",
            "Epoch 21/100 - 0.51s - loss: 0.8837 - acc: 0.5981 - val_loss: 0.9610 - val_acc: 0.5547\n",
            "Epoch 22/100 - 0.51s - loss: 0.8747 - acc: 0.6001 - val_loss: 0.9533 - val_acc: 0.5729\n",
            "Epoch 23/100 - 0.53s - loss: 0.8800 - acc: 0.5958 - val_loss: 0.9584 - val_acc: 0.5526\n",
            "Epoch 24/100 - 0.52s - loss: 0.8696 - acc: 0.5859 - val_loss: 0.9530 - val_acc: 0.5506\n",
            "Epoch 25/100 - 0.52s - loss: 0.8581 - acc: 0.6127 - val_loss: 0.9533 - val_acc: 0.5587\n",
            "Epoch 26/100 - 0.53s - loss: 0.8649 - acc: 0.6019 - val_loss: 0.9564 - val_acc: 0.5547\n",
            "Epoch 27/100 - 0.52s - loss: 0.8723 - acc: 0.5976 - val_loss: 0.9833 - val_acc: 0.5263\n",
            "Epoch 28/100 - 0.52s - loss: 0.8428 - acc: 0.6188 - val_loss: 0.9427 - val_acc: 0.5648\n",
            "Epoch 29/100 - 0.57s - loss: 0.8856 - acc: 0.5787 - val_loss: 1.0036 - val_acc: 0.5182\n",
            "Epoch 30/100 - 0.50s - loss: 0.8587 - acc: 0.6116 - val_loss: 0.9714 - val_acc: 0.5385\n",
            "Epoch 31/100 - 0.52s - loss: 0.8228 - acc: 0.6307 - val_loss: 0.9446 - val_acc: 0.5506\n",
            "Epoch 32/100 - 0.51s - loss: 0.8199 - acc: 0.6397 - val_loss: 0.9482 - val_acc: 0.5526\n",
            "Epoch 33/100 - 0.52s - loss: 0.8175 - acc: 0.6318 - val_loss: 0.9509 - val_acc: 0.5607\n",
            "Epoch 34/100 - 0.50s - loss: 0.9044 - acc: 0.5666 - val_loss: 1.0517 - val_acc: 0.4960\n",
            "Epoch 35/100 - 0.57s - loss: 0.8319 - acc: 0.6167 - val_loss: 0.9845 - val_acc: 0.5304\n",
            "Epoch 36/100 - 0.51s - loss: 0.8049 - acc: 0.6368 - val_loss: 0.9449 - val_acc: 0.5628\n",
            "Epoch 37/100 - 0.53s - loss: 0.8145 - acc: 0.6235 - val_loss: 0.9676 - val_acc: 0.5466\n",
            "Epoch 38/100 - 0.51s - loss: 0.8334 - acc: 0.5967 - val_loss: 0.9774 - val_acc: 0.5283\n",
            "Epoch 39/100 - 0.51s - loss: 0.7855 - acc: 0.6523 - val_loss: 0.9435 - val_acc: 0.5749\n",
            "Epoch 40/100 - 0.51s - loss: 0.8543 - acc: 0.6113 - val_loss: 1.0042 - val_acc: 0.5445\n",
            "Epoch 41/100 - 0.55s - loss: 0.7972 - acc: 0.6374 - val_loss: 0.9781 - val_acc: 0.5445\n",
            "Epoch 42/100 - 0.51s - loss: 0.8098 - acc: 0.6381 - val_loss: 0.9760 - val_acc: 0.5506\n",
            "Epoch 43/100 - 0.54s - loss: 0.7659 - acc: 0.6736 - val_loss: 0.9512 - val_acc: 0.5709\n",
            "Epoch 44/100 - 0.52s - loss: 0.8045 - acc: 0.6345 - val_loss: 0.9786 - val_acc: 0.5506\n",
            "Epoch 45/100 - 0.52s - loss: 0.7882 - acc: 0.6475 - val_loss: 0.9770 - val_acc: 0.5607\n",
            "Epoch 46/100 - 0.51s - loss: 0.7441 - acc: 0.6790 - val_loss: 0.9506 - val_acc: 0.5688\n",
            "Epoch 47/100 - 0.57s - loss: 0.7455 - acc: 0.6768 - val_loss: 0.9583 - val_acc: 0.5607\n",
            "Epoch 48/100 - 0.50s - loss: 0.7542 - acc: 0.6640 - val_loss: 0.9656 - val_acc: 0.5364\n",
            "Epoch 49/100 - 0.51s - loss: 0.7224 - acc: 0.6966 - val_loss: 0.9565 - val_acc: 0.5607\n",
            "Epoch 50/100 - 0.51s - loss: 0.9013 - acc: 0.5666 - val_loss: 1.1514 - val_acc: 0.4777\n",
            "Epoch 51/100 - 0.51s - loss: 0.7370 - acc: 0.6880 - val_loss: 0.9712 - val_acc: 0.5648\n",
            "Epoch 52/100 - 0.51s - loss: 0.7085 - acc: 0.7020 - val_loss: 0.9587 - val_acc: 0.5668\n",
            "Epoch 53/100 - 0.62s - loss: 0.7545 - acc: 0.6628 - val_loss: 0.9936 - val_acc: 0.5425\n",
            "Epoch 54/100 - 0.53s - loss: 0.6862 - acc: 0.7200 - val_loss: 0.9482 - val_acc: 0.5810\n",
            "Epoch 55/100 - 0.53s - loss: 0.7218 - acc: 0.6838 - val_loss: 0.9982 - val_acc: 0.5202\n",
            "Epoch 56/100 - 0.57s - loss: 0.6950 - acc: 0.7099 - val_loss: 0.9741 - val_acc: 0.5547\n",
            "Epoch 57/100 - 0.59s - loss: 0.6790 - acc: 0.7238 - val_loss: 0.9642 - val_acc: 0.5870\n",
            "Epoch 58/100 - 0.56s - loss: 0.7150 - acc: 0.7018 - val_loss: 0.9943 - val_acc: 0.5547\n",
            "Epoch 59/100 - 0.55s - loss: 0.7164 - acc: 0.6831 - val_loss: 1.0112 - val_acc: 0.5364\n",
            "Epoch 60/100 - 0.51s - loss: 0.7580 - acc: 0.6570 - val_loss: 1.0794 - val_acc: 0.4980\n",
            "Epoch 61/100 - 0.53s - loss: 0.7577 - acc: 0.6381 - val_loss: 1.0825 - val_acc: 0.5162\n",
            "Epoch 62/100 - 0.55s - loss: 0.6772 - acc: 0.7096 - val_loss: 1.0185 - val_acc: 0.5506\n",
            "Epoch 63/100 - 0.56s - loss: 0.6287 - acc: 0.7548 - val_loss: 0.9660 - val_acc: 0.5810\n",
            "Epoch 64/100 - 0.55s - loss: 0.6252 - acc: 0.7643 - val_loss: 0.9498 - val_acc: 0.5810\n",
            "Epoch 65/100 - 0.63s - loss: 0.6486 - acc: 0.7211 - val_loss: 0.9937 - val_acc: 0.5709\n",
            "Epoch 66/100 - 0.56s - loss: 0.7039 - acc: 0.6840 - val_loss: 1.0798 - val_acc: 0.5202\n",
            "Epoch 67/100 - 0.57s - loss: 0.6911 - acc: 0.6786 - val_loss: 1.0479 - val_acc: 0.5263\n",
            "Epoch 68/100 - 0.55s - loss: 0.7113 - acc: 0.6775 - val_loss: 1.0958 - val_acc: 0.4960\n",
            "Epoch 69/100 - 0.58s - loss: 0.5906 - acc: 0.7647 - val_loss: 0.9634 - val_acc: 0.5951\n",
            "Epoch 70/100 - 0.57s - loss: 0.6484 - acc: 0.7188 - val_loss: 1.0593 - val_acc: 0.5283\n",
            "Epoch 71/100 - 0.59s - loss: 0.9510 - acc: 0.5353 - val_loss: 1.3000 - val_acc: 0.4433\n",
            "Epoch 72/100 - 0.51s - loss: 0.6345 - acc: 0.7359 - val_loss: 1.0160 - val_acc: 0.5405\n",
            "Epoch 73/100 - 0.53s - loss: 0.5677 - acc: 0.7836 - val_loss: 0.9992 - val_acc: 0.5628\n",
            "Epoch 74/100 - 0.55s - loss: 0.5673 - acc: 0.7701 - val_loss: 0.9887 - val_acc: 0.5749\n",
            "Epoch 75/100 - 0.51s - loss: 0.5445 - acc: 0.7998 - val_loss: 0.9928 - val_acc: 0.5688\n",
            "Epoch 76/100 - 0.51s - loss: 0.5314 - acc: 0.8086 - val_loss: 0.9997 - val_acc: 0.5668\n",
            "Epoch 77/100 - 0.54s - loss: 0.5613 - acc: 0.7735 - val_loss: 1.0383 - val_acc: 0.5425\n",
            "Epoch 78/100 - 0.56s - loss: 0.6298 - acc: 0.7022 - val_loss: 1.0602 - val_acc: 0.5364\n",
            "Epoch 79/100 - 0.52s - loss: 0.5930 - acc: 0.7548 - val_loss: 1.0532 - val_acc: 0.5526\n",
            "Epoch 80/100 - 0.57s - loss: 0.5953 - acc: 0.7355 - val_loss: 1.0912 - val_acc: 0.5304\n",
            "Epoch 81/100 - 0.67s - loss: 0.4944 - acc: 0.8169 - val_loss: 1.0015 - val_acc: 0.5789\n",
            "Epoch 82/100 - 0.56s - loss: 0.4901 - acc: 0.8216 - val_loss: 0.9921 - val_acc: 0.5850\n",
            "Epoch 83/100 - 0.54s - loss: 0.5083 - acc: 0.8106 - val_loss: 1.0163 - val_acc: 0.5648\n",
            "Epoch 84/100 - 0.50s - loss: 0.5090 - acc: 0.8003 - val_loss: 1.0046 - val_acc: 0.5810\n",
            "Epoch 85/100 - 0.56s - loss: 0.5138 - acc: 0.8063 - val_loss: 1.0524 - val_acc: 0.5789\n",
            "Epoch 86/100 - 0.54s - loss: 0.5983 - acc: 0.7276 - val_loss: 1.1919 - val_acc: 0.5101\n",
            "Epoch 87/100 - 0.53s - loss: 0.4613 - acc: 0.8430 - val_loss: 1.0460 - val_acc: 0.5506\n",
            "Epoch 88/100 - 0.53s - loss: 0.4522 - acc: 0.8401 - val_loss: 1.0323 - val_acc: 0.5729\n",
            "Epoch 89/100 - 0.55s - loss: 0.4371 - acc: 0.8405 - val_loss: 1.0081 - val_acc: 0.5709\n",
            "Epoch 90/100 - 0.56s - loss: 0.5615 - acc: 0.7499 - val_loss: 1.1545 - val_acc: 0.5547\n",
            "Epoch 91/100 - 0.60s - loss: 0.4573 - acc: 0.8268 - val_loss: 1.0633 - val_acc: 0.5425\n",
            "Epoch 92/100 - 0.64s - loss: 0.5020 - acc: 0.7917 - val_loss: 1.1433 - val_acc: 0.5648\n",
            "Epoch 93/100 - 0.56s - loss: 0.5234 - acc: 0.7695 - val_loss: 1.1526 - val_acc: 0.5202\n",
            "Epoch 94/100 - 0.57s - loss: 0.4065 - acc: 0.8581 - val_loss: 1.0571 - val_acc: 0.5769\n",
            "Epoch 95/100 - 0.55s - loss: 0.4127 - acc: 0.8529 - val_loss: 1.0839 - val_acc: 0.5648\n",
            "Epoch 96/100 - 0.53s - loss: 0.4944 - acc: 0.7865 - val_loss: 1.1804 - val_acc: 0.5445\n",
            "Epoch 97/100 - 0.56s - loss: 0.3818 - acc: 0.8711 - val_loss: 1.0168 - val_acc: 0.5972\n",
            "Epoch 98/100 - 0.58s - loss: 0.4594 - acc: 0.8198 - val_loss: 1.1717 - val_acc: 0.5567\n",
            "Epoch 99/100 - 0.56s - loss: 0.3422 - acc: 0.8934 - val_loss: 1.0345 - val_acc: 0.5789\n",
            "Epoch 100/100 - 0.56s - loss: 0.3476 - acc: 0.8923 - val_loss: 1.0501 - val_acc: 0.5891\n",
            "Model saved to models/best_model.npy\n",
            "New best model found! Validation accuracy: 0.5891\n",
            "\n",
            "Combination 219/252:\n",
            "Hidden Layers: [512, 256, 128], Activation: relu, Learning Rate: 0.01, Batch Size: 32, Epochs: 150\n",
            "Epoch 1/150 - 0.56s - loss: 1.0688 - acc: 0.4449 - val_loss: 1.0700 - val_acc: 0.4494\n",
            "Epoch 2/150 - 0.55s - loss: 1.0515 - acc: 0.4613 - val_loss: 1.0590 - val_acc: 0.4555\n",
            "Epoch 3/150 - 0.56s - loss: 1.0344 - acc: 0.4818 - val_loss: 1.0477 - val_acc: 0.4838\n",
            "Epoch 4/150 - 0.60s - loss: 1.0247 - acc: 0.4825 - val_loss: 1.0434 - val_acc: 0.4737\n",
            "Epoch 5/150 - 0.56s - loss: 1.0083 - acc: 0.5135 - val_loss: 1.0321 - val_acc: 0.4939\n",
            "Epoch 6/150 - 0.59s - loss: 1.0212 - acc: 0.4741 - val_loss: 1.0472 - val_acc: 0.4453\n",
            "Epoch 7/150 - 0.56s - loss: 0.9918 - acc: 0.5142 - val_loss: 1.0249 - val_acc: 0.4939\n",
            "Epoch 8/150 - 0.59s - loss: 0.9858 - acc: 0.5234 - val_loss: 1.0203 - val_acc: 0.5243\n",
            "Epoch 9/150 - 0.56s - loss: 0.9642 - acc: 0.5470 - val_loss: 1.0039 - val_acc: 0.5081\n",
            "Epoch 10/150 - 0.59s - loss: 0.9547 - acc: 0.5445 - val_loss: 0.9974 - val_acc: 0.5101\n",
            "Epoch 11/150 - 0.57s - loss: 0.9469 - acc: 0.5470 - val_loss: 0.9929 - val_acc: 0.5020\n",
            "Epoch 12/150 - 0.59s - loss: 0.9626 - acc: 0.5452 - val_loss: 1.0085 - val_acc: 0.5324\n",
            "Epoch 13/150 - 0.55s - loss: 0.9359 - acc: 0.5493 - val_loss: 0.9854 - val_acc: 0.5121\n",
            "Epoch 14/150 - 0.61s - loss: 0.9206 - acc: 0.5668 - val_loss: 0.9736 - val_acc: 0.5425\n",
            "Epoch 15/150 - 0.56s - loss: 0.9119 - acc: 0.5722 - val_loss: 0.9663 - val_acc: 0.5283\n",
            "Epoch 16/150 - 0.60s - loss: 0.9152 - acc: 0.5789 - val_loss: 0.9719 - val_acc: 0.5547\n",
            "Epoch 17/150 - 0.55s - loss: 0.9243 - acc: 0.5558 - val_loss: 0.9919 - val_acc: 0.5040\n",
            "Epoch 18/150 - 0.54s - loss: 0.8983 - acc: 0.5805 - val_loss: 0.9706 - val_acc: 0.5304\n",
            "Epoch 19/150 - 0.55s - loss: 0.8926 - acc: 0.5913 - val_loss: 0.9597 - val_acc: 0.5567\n",
            "Epoch 20/150 - 0.56s - loss: 0.8967 - acc: 0.5940 - val_loss: 0.9675 - val_acc: 0.5709\n",
            "Epoch 21/150 - 0.56s - loss: 0.8863 - acc: 0.5868 - val_loss: 0.9663 - val_acc: 0.5243\n",
            "Epoch 22/150 - 0.56s - loss: 0.8719 - acc: 0.6023 - val_loss: 0.9556 - val_acc: 0.5547\n",
            "Epoch 23/150 - 0.57s - loss: 0.8706 - acc: 0.6073 - val_loss: 0.9549 - val_acc: 0.5607\n",
            "Epoch 24/150 - 0.56s - loss: 0.8656 - acc: 0.5990 - val_loss: 0.9541 - val_acc: 0.5101\n",
            "Epoch 25/150 - 0.55s - loss: 0.8632 - acc: 0.5987 - val_loss: 0.9580 - val_acc: 0.5121\n",
            "Epoch 26/150 - 0.52s - loss: 0.8555 - acc: 0.6152 - val_loss: 0.9562 - val_acc: 0.5445\n",
            "Epoch 27/150 - 0.54s - loss: 0.8575 - acc: 0.6026 - val_loss: 0.9596 - val_acc: 0.5223\n",
            "Epoch 28/150 - 0.58s - loss: 0.8383 - acc: 0.6300 - val_loss: 0.9439 - val_acc: 0.5587\n",
            "Epoch 29/150 - 0.53s - loss: 0.8332 - acc: 0.6163 - val_loss: 0.9476 - val_acc: 0.5243\n",
            "Epoch 30/150 - 0.53s - loss: 0.8773 - acc: 0.5852 - val_loss: 1.0044 - val_acc: 0.4939\n",
            "Epoch 31/150 - 0.53s - loss: 0.8272 - acc: 0.6248 - val_loss: 0.9467 - val_acc: 0.5405\n",
            "Epoch 32/150 - 0.52s - loss: 0.8112 - acc: 0.6439 - val_loss: 0.9376 - val_acc: 0.5567\n",
            "Epoch 33/150 - 0.54s - loss: 0.8160 - acc: 0.6352 - val_loss: 0.9479 - val_acc: 0.5425\n",
            "Epoch 34/150 - 0.56s - loss: 0.8058 - acc: 0.6424 - val_loss: 0.9385 - val_acc: 0.5425\n",
            "Epoch 35/150 - 0.52s - loss: 0.7975 - acc: 0.6439 - val_loss: 0.9402 - val_acc: 0.5547\n",
            "Epoch 36/150 - 0.52s - loss: 0.7966 - acc: 0.6428 - val_loss: 0.9440 - val_acc: 0.5587\n",
            "Epoch 37/150 - 0.52s - loss: 0.7933 - acc: 0.6516 - val_loss: 0.9464 - val_acc: 0.5364\n",
            "Epoch 38/150 - 0.51s - loss: 0.7972 - acc: 0.6457 - val_loss: 0.9465 - val_acc: 0.5709\n",
            "Epoch 39/150 - 0.54s - loss: 0.8614 - acc: 0.5877 - val_loss: 1.0336 - val_acc: 0.5202\n",
            "Epoch 40/150 - 0.64s - loss: 0.7770 - acc: 0.6601 - val_loss: 0.9530 - val_acc: 0.5344\n",
            "Epoch 41/150 - 0.56s - loss: 0.7674 - acc: 0.6696 - val_loss: 0.9473 - val_acc: 0.5648\n",
            "Epoch 42/150 - 0.56s - loss: 0.7870 - acc: 0.6570 - val_loss: 0.9618 - val_acc: 0.5567\n",
            "Epoch 43/150 - 0.61s - loss: 0.7527 - acc: 0.6743 - val_loss: 0.9418 - val_acc: 0.5648\n",
            "Epoch 44/150 - 0.57s - loss: 0.8051 - acc: 0.6516 - val_loss: 0.9798 - val_acc: 0.5688\n",
            "Epoch 45/150 - 0.58s - loss: 0.7440 - acc: 0.6907 - val_loss: 0.9450 - val_acc: 0.5607\n",
            "Epoch 46/150 - 0.53s - loss: 0.7657 - acc: 0.6583 - val_loss: 0.9779 - val_acc: 0.5162\n",
            "Epoch 47/150 - 0.56s - loss: 0.7345 - acc: 0.6930 - val_loss: 0.9415 - val_acc: 0.5607\n",
            "Epoch 48/150 - 0.54s - loss: 0.7292 - acc: 0.7038 - val_loss: 0.9392 - val_acc: 0.5769\n",
            "Epoch 49/150 - 0.59s - loss: 0.7181 - acc: 0.7013 - val_loss: 0.9402 - val_acc: 0.5628\n",
            "Epoch 50/150 - 0.59s - loss: 0.7846 - acc: 0.6332 - val_loss: 0.9886 - val_acc: 0.5506\n",
            "Epoch 51/150 - 0.70s - loss: 0.7117 - acc: 0.7060 - val_loss: 0.9495 - val_acc: 0.5445\n",
            "Epoch 52/150 - 0.70s - loss: 0.7124 - acc: 0.7042 - val_loss: 0.9500 - val_acc: 0.5709\n",
            "Epoch 53/150 - 0.69s - loss: 0.9030 - acc: 0.5697 - val_loss: 1.1102 - val_acc: 0.5364\n",
            "Epoch 54/150 - 0.67s - loss: 0.6995 - acc: 0.7081 - val_loss: 0.9509 - val_acc: 0.5567\n",
            "Epoch 55/150 - 0.65s - loss: 0.6866 - acc: 0.7168 - val_loss: 0.9400 - val_acc: 0.5709\n",
            "Epoch 56/150 - 0.65s - loss: 0.6985 - acc: 0.7056 - val_loss: 0.9485 - val_acc: 0.5729\n",
            "Epoch 57/150 - 0.66s - loss: 0.7179 - acc: 0.6736 - val_loss: 0.9733 - val_acc: 0.5567\n",
            "Epoch 58/150 - 0.59s - loss: 0.7607 - acc: 0.6520 - val_loss: 1.0543 - val_acc: 0.5162\n",
            "Epoch 59/150 - 0.64s - loss: 0.7395 - acc: 0.6628 - val_loss: 1.0292 - val_acc: 0.5121\n",
            "Epoch 60/150 - 0.63s - loss: 0.6555 - acc: 0.7380 - val_loss: 0.9508 - val_acc: 0.5648\n",
            "Epoch 61/150 - 0.62s - loss: 0.6717 - acc: 0.7200 - val_loss: 0.9802 - val_acc: 0.5486\n",
            "Epoch 62/150 - 0.54s - loss: 0.6668 - acc: 0.7204 - val_loss: 0.9728 - val_acc: 0.5729\n",
            "Epoch 63/150 - 0.56s - loss: 0.7215 - acc: 0.6649 - val_loss: 0.9948 - val_acc: 0.5547\n",
            "Epoch 64/150 - 0.52s - loss: 0.6405 - acc: 0.7456 - val_loss: 0.9512 - val_acc: 0.5628\n",
            "Epoch 65/150 - 0.53s - loss: 0.6342 - acc: 0.7431 - val_loss: 0.9498 - val_acc: 0.5547\n",
            "Epoch 66/150 - 0.52s - loss: 0.6453 - acc: 0.7274 - val_loss: 0.9718 - val_acc: 0.5729\n",
            "Epoch 67/150 - 0.53s - loss: 0.7848 - acc: 0.6138 - val_loss: 1.0946 - val_acc: 0.5344\n",
            "Epoch 68/150 - 0.52s - loss: 0.6395 - acc: 0.7411 - val_loss: 0.9905 - val_acc: 0.5526\n",
            "Epoch 69/150 - 0.56s - loss: 0.6231 - acc: 0.7463 - val_loss: 0.9708 - val_acc: 0.5688\n",
            "Epoch 70/150 - 0.53s - loss: 0.5975 - acc: 0.7611 - val_loss: 0.9672 - val_acc: 0.5729\n",
            "Epoch 71/150 - 0.57s - loss: 0.6127 - acc: 0.7535 - val_loss: 0.9771 - val_acc: 0.5668\n",
            "Epoch 72/150 - 0.74s - loss: 0.5651 - acc: 0.7924 - val_loss: 0.9567 - val_acc: 0.5668\n",
            "Epoch 73/150 - 0.55s - loss: 0.6508 - acc: 0.7258 - val_loss: 1.0679 - val_acc: 0.4980\n",
            "Epoch 74/150 - 0.61s - loss: 0.7360 - acc: 0.6759 - val_loss: 1.1253 - val_acc: 0.5283\n",
            "Epoch 75/150 - 0.56s - loss: 0.6102 - acc: 0.7436 - val_loss: 1.0423 - val_acc: 0.5445\n",
            "Epoch 76/150 - 0.59s - loss: 0.5512 - acc: 0.7942 - val_loss: 0.9513 - val_acc: 0.5668\n",
            "Epoch 77/150 - 0.54s - loss: 0.5350 - acc: 0.7976 - val_loss: 0.9531 - val_acc: 0.5749\n",
            "Epoch 78/150 - 0.70s - loss: 0.6105 - acc: 0.7416 - val_loss: 1.0641 - val_acc: 0.5182\n",
            "Epoch 79/150 - 0.62s - loss: 0.5415 - acc: 0.7933 - val_loss: 0.9918 - val_acc: 0.5648\n",
            "Epoch 80/150 - 0.62s - loss: 0.5953 - acc: 0.7413 - val_loss: 1.0495 - val_acc: 0.5628\n",
            "Epoch 81/150 - 0.78s - loss: 0.4965 - acc: 0.8291 - val_loss: 0.9567 - val_acc: 0.5709\n",
            "Epoch 82/150 - 0.70s - loss: 0.5095 - acc: 0.8075 - val_loss: 0.9790 - val_acc: 0.5709\n",
            "Epoch 83/150 - 0.63s - loss: 0.5354 - acc: 0.7814 - val_loss: 1.0098 - val_acc: 0.5729\n",
            "Epoch 84/150 - 0.68s - loss: 0.5638 - acc: 0.7629 - val_loss: 1.0713 - val_acc: 0.5304\n",
            "Epoch 85/150 - 0.64s - loss: 0.5495 - acc: 0.7686 - val_loss: 1.0274 - val_acc: 0.5688\n",
            "Epoch 86/150 - 0.62s - loss: 0.5018 - acc: 0.8124 - val_loss: 0.9933 - val_acc: 0.5688\n",
            "Epoch 87/150 - 0.64s - loss: 0.4759 - acc: 0.8241 - val_loss: 0.9940 - val_acc: 0.5810\n",
            "Epoch 88/150 - 0.55s - loss: 0.4592 - acc: 0.8387 - val_loss: 1.0102 - val_acc: 0.5628\n",
            "Epoch 89/150 - 0.52s - loss: 0.4385 - acc: 0.8480 - val_loss: 0.9616 - val_acc: 0.5729\n",
            "Epoch 90/150 - 0.56s - loss: 0.4507 - acc: 0.8437 - val_loss: 1.0038 - val_acc: 0.5668\n",
            "Epoch 91/150 - 0.55s - loss: 0.4227 - acc: 0.8587 - val_loss: 0.9680 - val_acc: 0.5668\n",
            "Epoch 92/150 - 0.54s - loss: 0.4765 - acc: 0.8113 - val_loss: 1.0420 - val_acc: 0.5547\n",
            "Epoch 93/150 - 0.57s - loss: 0.4204 - acc: 0.8563 - val_loss: 1.0020 - val_acc: 0.5870\n",
            "Epoch 94/150 - 0.55s - loss: 0.5262 - acc: 0.7625 - val_loss: 1.0793 - val_acc: 0.5688\n",
            "Epoch 95/150 - 0.57s - loss: 0.6065 - acc: 0.7265 - val_loss: 1.2534 - val_acc: 0.5040\n",
            "Epoch 96/150 - 0.53s - loss: 0.3982 - acc: 0.8650 - val_loss: 1.0147 - val_acc: 0.5749\n",
            "Epoch 97/150 - 0.55s - loss: 0.4240 - acc: 0.8538 - val_loss: 1.0042 - val_acc: 0.5931\n",
            "Epoch 98/150 - 0.52s - loss: 0.3782 - acc: 0.8736 - val_loss: 0.9823 - val_acc: 0.5870\n",
            "Epoch 99/150 - 0.59s - loss: 0.4348 - acc: 0.8255 - val_loss: 1.0834 - val_acc: 0.5648\n",
            "Epoch 100/150 - 0.55s - loss: 0.3810 - acc: 0.8756 - val_loss: 1.0243 - val_acc: 0.5648\n",
            "Epoch 101/150 - 0.53s - loss: 0.4239 - acc: 0.8327 - val_loss: 1.1196 - val_acc: 0.5668\n",
            "Epoch 102/150 - 0.53s - loss: 0.7455 - acc: 0.6329 - val_loss: 1.4943 - val_acc: 0.4615\n",
            "Epoch 103/150 - 0.53s - loss: 0.3544 - acc: 0.8909 - val_loss: 1.0229 - val_acc: 0.5749\n",
            "Epoch 104/150 - 0.52s - loss: 0.4823 - acc: 0.7935 - val_loss: 1.2006 - val_acc: 0.5081\n",
            "Epoch 105/150 - 0.60s - loss: 0.3043 - acc: 0.9123 - val_loss: 1.0198 - val_acc: 0.5951\n",
            "Epoch 106/150 - 0.57s - loss: 0.5390 - acc: 0.7483 - val_loss: 1.2336 - val_acc: 0.5425\n",
            "Epoch 107/150 - 0.54s - loss: 0.3901 - acc: 0.8525 - val_loss: 1.1495 - val_acc: 0.5283\n",
            "Epoch 108/150 - 0.52s - loss: 0.8504 - acc: 0.6201 - val_loss: 1.6949 - val_acc: 0.4980\n",
            "Epoch 109/150 - 0.57s - loss: 0.3071 - acc: 0.9015 - val_loss: 1.0939 - val_acc: 0.5709\n",
            "Epoch 110/150 - 0.54s - loss: 0.5185 - acc: 0.7731 - val_loss: 1.2553 - val_acc: 0.5405\n",
            "Epoch 111/150 - 0.57s - loss: 0.2676 - acc: 0.9233 - val_loss: 1.0550 - val_acc: 0.5789\n",
            "Epoch 112/150 - 0.57s - loss: 0.3064 - acc: 0.8968 - val_loss: 1.0602 - val_acc: 0.5648\n",
            "Epoch 113/150 - 0.55s - loss: 0.4844 - acc: 0.7697 - val_loss: 1.3764 - val_acc: 0.5425\n",
            "Epoch 114/150 - 0.54s - loss: 0.3068 - acc: 0.8851 - val_loss: 1.1171 - val_acc: 0.5709\n",
            "Epoch 115/150 - 0.59s - loss: 0.4466 - acc: 0.8099 - val_loss: 1.3086 - val_acc: 0.5445\n",
            "Epoch 116/150 - 0.52s - loss: 0.4539 - acc: 0.8039 - val_loss: 1.3927 - val_acc: 0.5344\n",
            "Epoch 117/150 - 0.59s - loss: 0.2287 - acc: 0.9447 - val_loss: 1.0742 - val_acc: 0.5830\n",
            "Epoch 118/150 - 0.52s - loss: 0.2275 - acc: 0.9399 - val_loss: 1.0658 - val_acc: 0.5810\n",
            "Epoch 119/150 - 0.54s - loss: 0.2058 - acc: 0.9559 - val_loss: 1.0406 - val_acc: 0.5911\n",
            "Epoch 120/150 - 0.52s - loss: 0.7250 - acc: 0.7267 - val_loss: 1.6115 - val_acc: 0.5020\n",
            "Epoch 121/150 - 0.58s - loss: 0.2201 - acc: 0.9422 - val_loss: 1.1246 - val_acc: 0.5789\n",
            "Epoch 122/150 - 0.54s - loss: 0.2406 - acc: 0.9296 - val_loss: 1.1578 - val_acc: 0.5891\n",
            "Epoch 123/150 - 0.57s - loss: 0.2445 - acc: 0.9242 - val_loss: 1.1602 - val_acc: 0.5870\n",
            "Epoch 124/150 - 0.55s - loss: 0.1851 - acc: 0.9584 - val_loss: 1.1196 - val_acc: 0.6012\n",
            "Epoch 125/150 - 0.56s - loss: 0.3262 - acc: 0.8552 - val_loss: 1.2824 - val_acc: 0.5486\n",
            "Epoch 126/150 - 0.57s - loss: 0.1908 - acc: 0.9570 - val_loss: 1.1225 - val_acc: 0.5951\n",
            "Epoch 127/150 - 0.53s - loss: 0.2536 - acc: 0.9141 - val_loss: 1.1806 - val_acc: 0.5628\n",
            "Epoch 128/150 - 0.56s - loss: 0.1744 - acc: 0.9566 - val_loss: 1.1868 - val_acc: 0.5709\n",
            "Epoch 129/150 - 0.61s - loss: 0.1461 - acc: 0.9737 - val_loss: 1.1368 - val_acc: 0.5951\n",
            "Epoch 130/150 - 0.55s - loss: 0.1843 - acc: 0.9521 - val_loss: 1.1521 - val_acc: 0.5891\n",
            "Epoch 131/150 - 0.56s - loss: 0.1419 - acc: 0.9750 - val_loss: 1.1213 - val_acc: 0.5688\n",
            "Epoch 132/150 - 0.53s - loss: 0.1641 - acc: 0.9586 - val_loss: 1.1824 - val_acc: 0.5729\n",
            "Epoch 133/150 - 0.55s - loss: 0.1750 - acc: 0.9496 - val_loss: 1.2084 - val_acc: 0.5648\n",
            "Epoch 134/150 - 0.53s - loss: 0.1743 - acc: 0.9505 - val_loss: 1.2495 - val_acc: 0.5870\n",
            "Epoch 135/150 - 0.56s - loss: 0.1165 - acc: 0.9820 - val_loss: 1.1738 - val_acc: 0.5911\n",
            "Epoch 136/150 - 0.62s - loss: 0.1163 - acc: 0.9807 - val_loss: 1.2022 - val_acc: 0.5870\n",
            "Epoch 137/150 - 0.72s - loss: 0.1083 - acc: 0.9804 - val_loss: 1.1789 - val_acc: 0.5992\n",
            "Epoch 138/150 - 0.57s - loss: 0.1170 - acc: 0.9831 - val_loss: 1.2306 - val_acc: 0.5951\n",
            "Epoch 139/150 - 0.54s - loss: 0.1272 - acc: 0.9710 - val_loss: 1.2579 - val_acc: 0.5850\n",
            "Epoch 140/150 - 0.56s - loss: 0.2114 - acc: 0.9251 - val_loss: 1.3935 - val_acc: 0.5688\n",
            "Epoch 141/150 - 0.60s - loss: 0.1242 - acc: 0.9800 - val_loss: 1.1717 - val_acc: 0.5628\n",
            "Epoch 142/150 - 0.58s - loss: 0.1115 - acc: 0.9795 - val_loss: 1.2553 - val_acc: 0.5972\n",
            "Epoch 143/150 - 0.55s - loss: 0.0819 - acc: 0.9890 - val_loss: 1.2344 - val_acc: 0.6012\n",
            "Epoch 144/150 - 0.55s - loss: 0.0856 - acc: 0.9843 - val_loss: 1.2424 - val_acc: 0.5850\n",
            "Epoch 145/150 - 0.58s - loss: 0.1029 - acc: 0.9768 - val_loss: 1.3171 - val_acc: 0.5729\n",
            "Epoch 146/150 - 0.58s - loss: 0.1038 - acc: 0.9775 - val_loss: 1.2708 - val_acc: 0.5911\n",
            "Epoch 147/150 - 0.64s - loss: 0.3045 - acc: 0.8680 - val_loss: 1.6585 - val_acc: 0.5648\n",
            "Epoch 148/150 - 0.59s - loss: 0.5674 - acc: 0.7555 - val_loss: 1.9737 - val_acc: 0.5162\n",
            "Epoch 149/150 - 0.68s - loss: 0.0701 - acc: 0.9897 - val_loss: 1.3102 - val_acc: 0.6093\n",
            "Epoch 150/150 - 0.60s - loss: 0.0866 - acc: 0.9894 - val_loss: 1.2587 - val_acc: 0.6113\n",
            "Model saved to models/best_model.npy\n",
            "New best model found! Validation accuracy: 0.6113\n",
            "\n",
            "Combination 220/252:\n",
            "Hidden Layers: [512, 256, 128], Activation: relu, Learning Rate: 0.01, Batch Size: 64, Epochs: 50\n",
            "Epoch 1/50 - 0.35s - loss: 1.0799 - acc: 0.4080 - val_loss: 1.0900 - val_acc: 0.3644\n",
            "Epoch 2/50 - 0.34s - loss: 1.0689 - acc: 0.4467 - val_loss: 1.0830 - val_acc: 0.3988\n",
            "Epoch 3/50 - 0.41s - loss: 1.0599 - acc: 0.4667 - val_loss: 1.0757 - val_acc: 0.4312\n",
            "Epoch 4/50 - 0.37s - loss: 1.0528 - acc: 0.4510 - val_loss: 1.0736 - val_acc: 0.4028\n",
            "Epoch 5/50 - 0.36s - loss: 1.0452 - acc: 0.4633 - val_loss: 1.0678 - val_acc: 0.4332\n",
            "Epoch 6/50 - 0.36s - loss: 1.0379 - acc: 0.4791 - val_loss: 1.0594 - val_acc: 0.4413\n",
            "Epoch 7/50 - 0.36s - loss: 1.0302 - acc: 0.4926 - val_loss: 1.0557 - val_acc: 0.4494\n",
            "Epoch 8/50 - 0.38s - loss: 1.0251 - acc: 0.4825 - val_loss: 1.0515 - val_acc: 0.4615\n",
            "Epoch 9/50 - 0.40s - loss: 1.0190 - acc: 0.4901 - val_loss: 1.0450 - val_acc: 0.4595\n",
            "Epoch 10/50 - 0.34s - loss: 1.0105 - acc: 0.5092 - val_loss: 1.0404 - val_acc: 0.4696\n",
            "Epoch 11/50 - 0.35s - loss: 1.0051 - acc: 0.5067 - val_loss: 1.0350 - val_acc: 0.4777\n",
            "Epoch 12/50 - 0.34s - loss: 0.9979 - acc: 0.5214 - val_loss: 1.0317 - val_acc: 0.4838\n",
            "Epoch 13/50 - 0.35s - loss: 1.0010 - acc: 0.5061 - val_loss: 1.0375 - val_acc: 0.4595\n",
            "Epoch 14/50 - 0.35s - loss: 0.9878 - acc: 0.5225 - val_loss: 1.0222 - val_acc: 0.5000\n",
            "Epoch 15/50 - 0.44s - loss: 0.9865 - acc: 0.5155 - val_loss: 1.0269 - val_acc: 0.4757\n",
            "Epoch 16/50 - 0.39s - loss: 0.9736 - acc: 0.5346 - val_loss: 1.0123 - val_acc: 0.4980\n",
            "Epoch 17/50 - 0.37s - loss: 0.9698 - acc: 0.5461 - val_loss: 1.0125 - val_acc: 0.5121\n",
            "Epoch 18/50 - 0.35s - loss: 0.9688 - acc: 0.5441 - val_loss: 1.0113 - val_acc: 0.5121\n",
            "Epoch 19/50 - 0.35s - loss: 0.9582 - acc: 0.5416 - val_loss: 1.0012 - val_acc: 0.5081\n",
            "Epoch 20/50 - 0.35s - loss: 0.9544 - acc: 0.5524 - val_loss: 1.0033 - val_acc: 0.5182\n",
            "Epoch 21/50 - 0.38s - loss: 0.9734 - acc: 0.5056 - val_loss: 1.0223 - val_acc: 0.4696\n",
            "Epoch 22/50 - 0.35s - loss: 0.9649 - acc: 0.5457 - val_loss: 1.0112 - val_acc: 0.5121\n",
            "Epoch 23/50 - 0.35s - loss: 0.9764 - acc: 0.5121 - val_loss: 1.0358 - val_acc: 0.4615\n",
            "Epoch 24/50 - 0.35s - loss: 0.9355 - acc: 0.5641 - val_loss: 0.9903 - val_acc: 0.5364\n",
            "Epoch 25/50 - 0.36s - loss: 0.9439 - acc: 0.5459 - val_loss: 1.0043 - val_acc: 0.5020\n",
            "Epoch 26/50 - 0.38s - loss: 0.9748 - acc: 0.5054 - val_loss: 1.0376 - val_acc: 0.4615\n",
            "Epoch 27/50 - 0.39s - loss: 0.9210 - acc: 0.5625 - val_loss: 0.9808 - val_acc: 0.5385\n",
            "Epoch 28/50 - 0.38s - loss: 0.9201 - acc: 0.5688 - val_loss: 0.9789 - val_acc: 0.5526\n",
            "Epoch 29/50 - 0.38s - loss: 0.9316 - acc: 0.5515 - val_loss: 0.9992 - val_acc: 0.5000\n",
            "Epoch 30/50 - 0.39s - loss: 0.9241 - acc: 0.5517 - val_loss: 0.9808 - val_acc: 0.5385\n",
            "Epoch 31/50 - 0.38s - loss: 0.9425 - acc: 0.5632 - val_loss: 1.0054 - val_acc: 0.5101\n",
            "Epoch 32/50 - 0.39s - loss: 0.9142 - acc: 0.5731 - val_loss: 0.9776 - val_acc: 0.5628\n",
            "Epoch 33/50 - 0.40s - loss: 0.9133 - acc: 0.5659 - val_loss: 0.9780 - val_acc: 0.5607\n",
            "Epoch 34/50 - 0.37s - loss: 0.8989 - acc: 0.5744 - val_loss: 0.9749 - val_acc: 0.5283\n",
            "Epoch 35/50 - 0.49s - loss: 0.8976 - acc: 0.5792 - val_loss: 0.9773 - val_acc: 0.5283\n",
            "Epoch 36/50 - 0.42s - loss: 0.9067 - acc: 0.5839 - val_loss: 0.9836 - val_acc: 0.5385\n",
            "Epoch 37/50 - 0.42s - loss: 0.8977 - acc: 0.5807 - val_loss: 0.9784 - val_acc: 0.5425\n",
            "Epoch 38/50 - 0.45s - loss: 0.8871 - acc: 0.5839 - val_loss: 0.9739 - val_acc: 0.5121\n",
            "Epoch 39/50 - 0.45s - loss: 0.8773 - acc: 0.5999 - val_loss: 0.9618 - val_acc: 0.5486\n",
            "Epoch 40/50 - 0.40s - loss: 0.8937 - acc: 0.5801 - val_loss: 0.9722 - val_acc: 0.5628\n",
            "Epoch 41/50 - 0.37s - loss: 0.8829 - acc: 0.5972 - val_loss: 0.9703 - val_acc: 0.5466\n",
            "Epoch 42/50 - 0.36s - loss: 0.8910 - acc: 0.5749 - val_loss: 0.9848 - val_acc: 0.5243\n",
            "Epoch 43/50 - 0.38s - loss: 0.8648 - acc: 0.6068 - val_loss: 0.9537 - val_acc: 0.5486\n",
            "Epoch 44/50 - 0.38s - loss: 0.8815 - acc: 0.5848 - val_loss: 0.9773 - val_acc: 0.5283\n",
            "Epoch 45/50 - 0.46s - loss: 0.9139 - acc: 0.5531 - val_loss: 1.0054 - val_acc: 0.5263\n",
            "Epoch 46/50 - 0.39s - loss: 0.9235 - acc: 0.5531 - val_loss: 1.0289 - val_acc: 0.5142\n",
            "Epoch 47/50 - 0.44s - loss: 0.8564 - acc: 0.6080 - val_loss: 0.9606 - val_acc: 0.5364\n",
            "Epoch 48/50 - 0.41s - loss: 0.8528 - acc: 0.6104 - val_loss: 0.9538 - val_acc: 0.5486\n",
            "Epoch 49/50 - 0.36s - loss: 0.8459 - acc: 0.6122 - val_loss: 0.9524 - val_acc: 0.5506\n",
            "Epoch 50/50 - 0.34s - loss: 0.8450 - acc: 0.6183 - val_loss: 0.9566 - val_acc: 0.5567\n",
            "\n",
            "Combination 221/252:\n",
            "Hidden Layers: [512, 256, 128], Activation: relu, Learning Rate: 0.01, Batch Size: 64, Epochs: 100\n",
            "Epoch 1/100 - 0.36s - loss: 1.0827 - acc: 0.4141 - val_loss: 1.0813 - val_acc: 0.4069\n",
            "Epoch 2/100 - 0.36s - loss: 1.0722 - acc: 0.4431 - val_loss: 1.0733 - val_acc: 0.4271\n",
            "Epoch 3/100 - 0.39s - loss: 1.0622 - acc: 0.4424 - val_loss: 1.0673 - val_acc: 0.4575\n",
            "Epoch 4/100 - 0.34s - loss: 1.0541 - acc: 0.4600 - val_loss: 1.0622 - val_acc: 0.4332\n",
            "Epoch 5/100 - 0.36s - loss: 1.0477 - acc: 0.4564 - val_loss: 1.0586 - val_acc: 0.4393\n",
            "Epoch 6/100 - 0.36s - loss: 1.0401 - acc: 0.4750 - val_loss: 1.0527 - val_acc: 0.4798\n",
            "Epoch 7/100 - 0.42s - loss: 1.0336 - acc: 0.4759 - val_loss: 1.0496 - val_acc: 0.4919\n",
            "Epoch 8/100 - 0.35s - loss: 1.0300 - acc: 0.4915 - val_loss: 1.0496 - val_acc: 0.4615\n",
            "Epoch 9/100 - 0.36s - loss: 1.0217 - acc: 0.4939 - val_loss: 1.0433 - val_acc: 0.4960\n",
            "Epoch 10/100 - 0.34s - loss: 1.0184 - acc: 0.5007 - val_loss: 1.0440 - val_acc: 0.4656\n",
            "Epoch 11/100 - 0.35s - loss: 1.0093 - acc: 0.5072 - val_loss: 1.0351 - val_acc: 0.4919\n",
            "Epoch 12/100 - 0.44s - loss: 1.0042 - acc: 0.5128 - val_loss: 1.0324 - val_acc: 0.4798\n",
            "Epoch 13/100 - 0.41s - loss: 1.0045 - acc: 0.5103 - val_loss: 1.0360 - val_acc: 0.4555\n",
            "Epoch 14/100 - 0.35s - loss: 0.9913 - acc: 0.5160 - val_loss: 1.0243 - val_acc: 0.4919\n",
            "Epoch 15/100 - 0.41s - loss: 0.9858 - acc: 0.5256 - val_loss: 1.0204 - val_acc: 0.4879\n",
            "Epoch 16/100 - 0.35s - loss: 0.9819 - acc: 0.5268 - val_loss: 1.0161 - val_acc: 0.5101\n",
            "Epoch 17/100 - 0.34s - loss: 0.9743 - acc: 0.5297 - val_loss: 1.0124 - val_acc: 0.5243\n",
            "Epoch 18/100 - 0.35s - loss: 0.9714 - acc: 0.5324 - val_loss: 1.0096 - val_acc: 0.5182\n",
            "Epoch 19/100 - 0.35s - loss: 0.9653 - acc: 0.5373 - val_loss: 1.0068 - val_acc: 0.5263\n",
            "Epoch 20/100 - 0.36s - loss: 0.9715 - acc: 0.5250 - val_loss: 1.0199 - val_acc: 0.4818\n",
            "Epoch 21/100 - 0.37s - loss: 0.9622 - acc: 0.5346 - val_loss: 1.0113 - val_acc: 0.4899\n",
            "Epoch 22/100 - 0.34s - loss: 0.9526 - acc: 0.5441 - val_loss: 1.0018 - val_acc: 0.5020\n",
            "Epoch 23/100 - 0.35s - loss: 0.9562 - acc: 0.5337 - val_loss: 1.0089 - val_acc: 0.4960\n",
            "Epoch 24/100 - 0.34s - loss: 0.9472 - acc: 0.5517 - val_loss: 0.9949 - val_acc: 0.5405\n",
            "Epoch 25/100 - 0.37s - loss: 0.9427 - acc: 0.5461 - val_loss: 0.9967 - val_acc: 0.5142\n",
            "Epoch 26/100 - 0.32s - loss: 0.9489 - acc: 0.5362 - val_loss: 1.0073 - val_acc: 0.4939\n",
            "Epoch 27/100 - 0.33s - loss: 0.9228 - acc: 0.5639 - val_loss: 0.9790 - val_acc: 0.5385\n",
            "Epoch 28/100 - 0.37s - loss: 0.9274 - acc: 0.5623 - val_loss: 0.9812 - val_acc: 0.5567\n",
            "Epoch 29/100 - 0.33s - loss: 0.9194 - acc: 0.5650 - val_loss: 0.9795 - val_acc: 0.5324\n",
            "Epoch 30/100 - 0.34s - loss: 0.9159 - acc: 0.5684 - val_loss: 0.9813 - val_acc: 0.5364\n",
            "Epoch 31/100 - 0.36s - loss: 0.9100 - acc: 0.5686 - val_loss: 0.9712 - val_acc: 0.5567\n",
            "Epoch 32/100 - 0.35s - loss: 0.9230 - acc: 0.5569 - val_loss: 0.9942 - val_acc: 0.5081\n",
            "Epoch 33/100 - 0.33s - loss: 0.9002 - acc: 0.5789 - val_loss: 0.9698 - val_acc: 0.5526\n",
            "Epoch 34/100 - 0.34s - loss: 0.9089 - acc: 0.5691 - val_loss: 0.9845 - val_acc: 0.5364\n",
            "Epoch 35/100 - 0.39s - loss: 0.9451 - acc: 0.5351 - val_loss: 1.0208 - val_acc: 0.4838\n",
            "Epoch 36/100 - 0.37s - loss: 0.8929 - acc: 0.5830 - val_loss: 0.9685 - val_acc: 0.5466\n",
            "Epoch 37/100 - 0.35s - loss: 0.9169 - acc: 0.5605 - val_loss: 1.0003 - val_acc: 0.4939\n",
            "Epoch 38/100 - 0.36s - loss: 0.8957 - acc: 0.5801 - val_loss: 0.9785 - val_acc: 0.5223\n",
            "Epoch 39/100 - 0.47s - loss: 0.8789 - acc: 0.5906 - val_loss: 0.9624 - val_acc: 0.5445\n",
            "Epoch 40/100 - 0.40s - loss: 0.8807 - acc: 0.5911 - val_loss: 0.9649 - val_acc: 0.5405\n",
            "Epoch 41/100 - 0.35s - loss: 0.8723 - acc: 0.5994 - val_loss: 0.9544 - val_acc: 0.5567\n",
            "Epoch 42/100 - 0.43s - loss: 0.8723 - acc: 0.5956 - val_loss: 0.9616 - val_acc: 0.5466\n",
            "Epoch 43/100 - 0.45s - loss: 0.8728 - acc: 0.5904 - val_loss: 0.9565 - val_acc: 0.5688\n",
            "Epoch 44/100 - 0.34s - loss: 0.8992 - acc: 0.5729 - val_loss: 0.9897 - val_acc: 0.5223\n",
            "Epoch 45/100 - 0.41s - loss: 0.9379 - acc: 0.5479 - val_loss: 1.0447 - val_acc: 0.4818\n",
            "Epoch 46/100 - 0.36s - loss: 0.8644 - acc: 0.6057 - val_loss: 0.9581 - val_acc: 0.5648\n",
            "Epoch 47/100 - 0.38s - loss: 0.9344 - acc: 0.5481 - val_loss: 1.0526 - val_acc: 0.4636\n",
            "Epoch 48/100 - 0.38s - loss: 0.8548 - acc: 0.6010 - val_loss: 0.9524 - val_acc: 0.5445\n",
            "Epoch 49/100 - 0.39s - loss: 0.9078 - acc: 0.5778 - val_loss: 0.9974 - val_acc: 0.5547\n",
            "Epoch 50/100 - 0.37s - loss: 0.9209 - acc: 0.5513 - val_loss: 1.0317 - val_acc: 0.4980\n",
            "Epoch 51/100 - 0.38s - loss: 0.8508 - acc: 0.6100 - val_loss: 0.9661 - val_acc: 0.5162\n",
            "Epoch 52/100 - 0.36s - loss: 0.8579 - acc: 0.6084 - val_loss: 0.9620 - val_acc: 0.5729\n",
            "Epoch 53/100 - 0.40s - loss: 0.8988 - acc: 0.5706 - val_loss: 0.9956 - val_acc: 0.5263\n",
            "Epoch 54/100 - 0.37s - loss: 0.8515 - acc: 0.6107 - val_loss: 0.9770 - val_acc: 0.5121\n",
            "Epoch 55/100 - 0.36s - loss: 0.8802 - acc: 0.5859 - val_loss: 1.0109 - val_acc: 0.5040\n",
            "Epoch 56/100 - 0.37s - loss: 0.8379 - acc: 0.6127 - val_loss: 0.9672 - val_acc: 0.5304\n",
            "Epoch 57/100 - 0.36s - loss: 0.8336 - acc: 0.6282 - val_loss: 0.9561 - val_acc: 0.5668\n",
            "Epoch 58/100 - 0.33s - loss: 0.8558 - acc: 0.6116 - val_loss: 0.9751 - val_acc: 0.5729\n",
            "Epoch 59/100 - 0.33s - loss: 0.8404 - acc: 0.6199 - val_loss: 0.9624 - val_acc: 0.5709\n",
            "Epoch 60/100 - 0.34s - loss: 0.8128 - acc: 0.6370 - val_loss: 0.9466 - val_acc: 0.5587\n",
            "Epoch 61/100 - 0.36s - loss: 0.8278 - acc: 0.6136 - val_loss: 0.9599 - val_acc: 0.5425\n",
            "Epoch 62/100 - 0.34s - loss: 0.8634 - acc: 0.5983 - val_loss: 1.0023 - val_acc: 0.5263\n",
            "Epoch 63/100 - 0.36s - loss: 0.8607 - acc: 0.6095 - val_loss: 0.9976 - val_acc: 0.5526\n",
            "Epoch 64/100 - 0.35s - loss: 0.8845 - acc: 0.5769 - val_loss: 1.0417 - val_acc: 0.5020\n",
            "Epoch 65/100 - 0.40s - loss: 0.8196 - acc: 0.6237 - val_loss: 0.9763 - val_acc: 0.5283\n",
            "Epoch 66/100 - 0.35s - loss: 0.8012 - acc: 0.6332 - val_loss: 0.9592 - val_acc: 0.5324\n",
            "Epoch 67/100 - 0.44s - loss: 0.7960 - acc: 0.6406 - val_loss: 0.9477 - val_acc: 0.5648\n",
            "Epoch 68/100 - 0.33s - loss: 0.7896 - acc: 0.6455 - val_loss: 0.9577 - val_acc: 0.5202\n",
            "Epoch 69/100 - 0.39s - loss: 0.8875 - acc: 0.5717 - val_loss: 1.0245 - val_acc: 0.5202\n",
            "Epoch 70/100 - 0.36s - loss: 0.7837 - acc: 0.6583 - val_loss: 0.9518 - val_acc: 0.5506\n",
            "Epoch 71/100 - 0.36s - loss: 0.8230 - acc: 0.6131 - val_loss: 0.9975 - val_acc: 0.5223\n",
            "Epoch 72/100 - 0.35s - loss: 0.7956 - acc: 0.6460 - val_loss: 0.9788 - val_acc: 0.5202\n",
            "Epoch 73/100 - 0.37s - loss: 0.7885 - acc: 0.6401 - val_loss: 0.9697 - val_acc: 0.5344\n",
            "Epoch 74/100 - 0.35s - loss: 0.7732 - acc: 0.6547 - val_loss: 0.9532 - val_acc: 0.5344\n",
            "Epoch 75/100 - 0.35s - loss: 0.7766 - acc: 0.6610 - val_loss: 0.9653 - val_acc: 0.5223\n",
            "Epoch 76/100 - 0.34s - loss: 0.8106 - acc: 0.6296 - val_loss: 1.0074 - val_acc: 0.5000\n",
            "Epoch 77/100 - 0.35s - loss: 0.8671 - acc: 0.6104 - val_loss: 1.0445 - val_acc: 0.5162\n",
            "Epoch 78/100 - 0.33s - loss: 0.7806 - acc: 0.6570 - val_loss: 0.9861 - val_acc: 0.5121\n",
            "Epoch 79/100 - 0.37s - loss: 0.7595 - acc: 0.6669 - val_loss: 0.9527 - val_acc: 0.5769\n",
            "Epoch 80/100 - 0.34s - loss: 0.8135 - acc: 0.6345 - val_loss: 1.0019 - val_acc: 0.5385\n",
            "Epoch 81/100 - 0.36s - loss: 0.9036 - acc: 0.5693 - val_loss: 1.1313 - val_acc: 0.4595\n",
            "Epoch 82/100 - 0.36s - loss: 0.7510 - acc: 0.6687 - val_loss: 0.9654 - val_acc: 0.5324\n",
            "Epoch 83/100 - 0.34s - loss: 0.7679 - acc: 0.6565 - val_loss: 0.9680 - val_acc: 0.5648\n",
            "Epoch 84/100 - 0.36s - loss: 0.9823 - acc: 0.5205 - val_loss: 1.1577 - val_acc: 0.4919\n",
            "Epoch 85/100 - 0.35s - loss: 0.7319 - acc: 0.6795 - val_loss: 0.9484 - val_acc: 0.5506\n",
            "Epoch 86/100 - 0.34s - loss: 0.7520 - acc: 0.6613 - val_loss: 0.9605 - val_acc: 0.5709\n",
            "Epoch 87/100 - 0.35s - loss: 0.7325 - acc: 0.6871 - val_loss: 0.9667 - val_acc: 0.5324\n",
            "Epoch 88/100 - 0.34s - loss: 0.7299 - acc: 0.6763 - val_loss: 0.9596 - val_acc: 0.5385\n",
            "Epoch 89/100 - 0.35s - loss: 0.7629 - acc: 0.6435 - val_loss: 0.9790 - val_acc: 0.5688\n",
            "Epoch 90/100 - 0.35s - loss: 0.7228 - acc: 0.7018 - val_loss: 0.9572 - val_acc: 0.5587\n",
            "Epoch 91/100 - 0.36s - loss: 0.7391 - acc: 0.6817 - val_loss: 0.9893 - val_acc: 0.5304\n",
            "Epoch 92/100 - 0.35s - loss: 0.7517 - acc: 0.6653 - val_loss: 1.0064 - val_acc: 0.5101\n",
            "Epoch 93/100 - 0.36s - loss: 0.8293 - acc: 0.6305 - val_loss: 1.0526 - val_acc: 0.5405\n",
            "Epoch 94/100 - 0.34s - loss: 0.7138 - acc: 0.6961 - val_loss: 0.9679 - val_acc: 0.5324\n",
            "Epoch 95/100 - 0.34s - loss: 0.6992 - acc: 0.7128 - val_loss: 0.9513 - val_acc: 0.5648\n",
            "Epoch 96/100 - 0.34s - loss: 0.7690 - acc: 0.6446 - val_loss: 1.0380 - val_acc: 0.5061\n",
            "Epoch 97/100 - 0.38s - loss: 0.7710 - acc: 0.6435 - val_loss: 1.0346 - val_acc: 0.5223\n",
            "Epoch 98/100 - 0.34s - loss: 0.6882 - acc: 0.7143 - val_loss: 0.9610 - val_acc: 0.5445\n",
            "Epoch 99/100 - 0.34s - loss: 0.8293 - acc: 0.6158 - val_loss: 1.1240 - val_acc: 0.4879\n",
            "Epoch 100/100 - 0.34s - loss: 0.6902 - acc: 0.7193 - val_loss: 0.9715 - val_acc: 0.5466\n",
            "\n",
            "Combination 222/252:\n",
            "Hidden Layers: [512, 256, 128], Activation: relu, Learning Rate: 0.01, Batch Size: 64, Epochs: 150\n",
            "Epoch 1/150 - 0.35s - loss: 1.0830 - acc: 0.4262 - val_loss: 1.0774 - val_acc: 0.4413\n",
            "Epoch 2/150 - 0.37s - loss: 1.0711 - acc: 0.4397 - val_loss: 1.0682 - val_acc: 0.4393\n",
            "Epoch 3/150 - 0.36s - loss: 1.0636 - acc: 0.4593 - val_loss: 1.0610 - val_acc: 0.4615\n",
            "Epoch 4/150 - 0.36s - loss: 1.0564 - acc: 0.4611 - val_loss: 1.0556 - val_acc: 0.4676\n",
            "Epoch 5/150 - 0.35s - loss: 1.0491 - acc: 0.4647 - val_loss: 1.0506 - val_acc: 0.4757\n",
            "Epoch 6/150 - 0.34s - loss: 1.0431 - acc: 0.4762 - val_loss: 1.0474 - val_acc: 0.4777\n",
            "Epoch 7/150 - 0.35s - loss: 1.0366 - acc: 0.4804 - val_loss: 1.0436 - val_acc: 0.4737\n",
            "Epoch 8/150 - 0.33s - loss: 1.0325 - acc: 0.4852 - val_loss: 1.0399 - val_acc: 0.4858\n",
            "Epoch 9/150 - 0.35s - loss: 1.0235 - acc: 0.4845 - val_loss: 1.0341 - val_acc: 0.5101\n",
            "Epoch 10/150 - 0.35s - loss: 1.0202 - acc: 0.4798 - val_loss: 1.0333 - val_acc: 0.4818\n",
            "Epoch 11/150 - 0.38s - loss: 1.0119 - acc: 0.4946 - val_loss: 1.0277 - val_acc: 0.5142\n",
            "Epoch 12/150 - 0.37s - loss: 1.0065 - acc: 0.4991 - val_loss: 1.0240 - val_acc: 0.5162\n",
            "Epoch 13/150 - 0.34s - loss: 1.0030 - acc: 0.5004 - val_loss: 1.0222 - val_acc: 0.5061\n",
            "Epoch 14/150 - 0.33s - loss: 0.9988 - acc: 0.5135 - val_loss: 1.0174 - val_acc: 0.5121\n",
            "Epoch 15/150 - 0.36s - loss: 0.9968 - acc: 0.5056 - val_loss: 1.0178 - val_acc: 0.4960\n",
            "Epoch 16/150 - 0.34s - loss: 0.9893 - acc: 0.5205 - val_loss: 1.0103 - val_acc: 0.5263\n",
            "Epoch 17/150 - 0.34s - loss: 0.9859 - acc: 0.5225 - val_loss: 1.0086 - val_acc: 0.5202\n",
            "Epoch 18/150 - 0.33s - loss: 0.9741 - acc: 0.5326 - val_loss: 1.0012 - val_acc: 0.5243\n",
            "Epoch 19/150 - 0.35s - loss: 0.9785 - acc: 0.5225 - val_loss: 1.0071 - val_acc: 0.5040\n",
            "Epoch 20/150 - 0.34s - loss: 0.9664 - acc: 0.5380 - val_loss: 0.9960 - val_acc: 0.5344\n",
            "Epoch 21/150 - 0.34s - loss: 0.9634 - acc: 0.5391 - val_loss: 0.9919 - val_acc: 0.5405\n",
            "Epoch 22/150 - 0.36s - loss: 0.9607 - acc: 0.5319 - val_loss: 0.9939 - val_acc: 0.5040\n",
            "Epoch 23/150 - 0.35s - loss: 0.9518 - acc: 0.5463 - val_loss: 0.9865 - val_acc: 0.5263\n",
            "Epoch 24/150 - 0.34s - loss: 0.9488 - acc: 0.5443 - val_loss: 0.9854 - val_acc: 0.5243\n",
            "Epoch 25/150 - 0.35s - loss: 0.9485 - acc: 0.5522 - val_loss: 0.9829 - val_acc: 0.5547\n",
            "Epoch 26/150 - 0.33s - loss: 0.9434 - acc: 0.5535 - val_loss: 0.9805 - val_acc: 0.5668\n",
            "Epoch 27/150 - 0.34s - loss: 0.9821 - acc: 0.5027 - val_loss: 1.0247 - val_acc: 0.4555\n",
            "Epoch 28/150 - 0.36s - loss: 0.9372 - acc: 0.5556 - val_loss: 0.9752 - val_acc: 0.5607\n",
            "Epoch 29/150 - 0.36s - loss: 0.9580 - acc: 0.5290 - val_loss: 1.0021 - val_acc: 0.5223\n",
            "Epoch 30/150 - 0.34s - loss: 0.9323 - acc: 0.5529 - val_loss: 0.9790 - val_acc: 0.5202\n",
            "Epoch 31/150 - 0.35s - loss: 0.9239 - acc: 0.5639 - val_loss: 0.9679 - val_acc: 0.5729\n",
            "Epoch 32/150 - 0.34s - loss: 0.9202 - acc: 0.5632 - val_loss: 0.9668 - val_acc: 0.5385\n",
            "Epoch 33/150 - 0.38s - loss: 0.9660 - acc: 0.5292 - val_loss: 1.0145 - val_acc: 0.5243\n",
            "Epoch 34/150 - 0.33s - loss: 0.9173 - acc: 0.5693 - val_loss: 0.9701 - val_acc: 0.5324\n",
            "Epoch 35/150 - 0.35s - loss: 0.9039 - acc: 0.5753 - val_loss: 0.9585 - val_acc: 0.5466\n",
            "Epoch 36/150 - 0.34s - loss: 0.9293 - acc: 0.5695 - val_loss: 0.9805 - val_acc: 0.5607\n",
            "Epoch 37/150 - 0.35s - loss: 0.9281 - acc: 0.5522 - val_loss: 0.9896 - val_acc: 0.4960\n",
            "Epoch 38/150 - 0.36s - loss: 0.8917 - acc: 0.5850 - val_loss: 0.9522 - val_acc: 0.5466\n",
            "Epoch 39/150 - 0.34s - loss: 0.8951 - acc: 0.5823 - val_loss: 0.9565 - val_acc: 0.5506\n",
            "Epoch 40/150 - 0.35s - loss: 0.8879 - acc: 0.5848 - val_loss: 0.9495 - val_acc: 0.5587\n",
            "Epoch 41/150 - 0.43s - loss: 0.8930 - acc: 0.5866 - val_loss: 0.9551 - val_acc: 0.5668\n",
            "Epoch 42/150 - 0.46s - loss: 0.8863 - acc: 0.5868 - val_loss: 0.9523 - val_acc: 0.5466\n",
            "Epoch 43/150 - 0.38s - loss: 0.8751 - acc: 0.5938 - val_loss: 0.9454 - val_acc: 0.5729\n",
            "Epoch 44/150 - 0.45s - loss: 0.8721 - acc: 0.5976 - val_loss: 0.9471 - val_acc: 0.5668\n",
            "Epoch 45/150 - 0.51s - loss: 0.9290 - acc: 0.5360 - val_loss: 1.0088 - val_acc: 0.5040\n",
            "Epoch 46/150 - 0.46s - loss: 0.9454 - acc: 0.5448 - val_loss: 1.0269 - val_acc: 0.4798\n",
            "Epoch 47/150 - 0.45s - loss: 0.8931 - acc: 0.5744 - val_loss: 0.9808 - val_acc: 0.4939\n",
            "Epoch 48/150 - 0.41s - loss: 0.8632 - acc: 0.6032 - val_loss: 0.9463 - val_acc: 0.5789\n",
            "Epoch 49/150 - 0.43s - loss: 0.9482 - acc: 0.5560 - val_loss: 1.0228 - val_acc: 0.5628\n",
            "Epoch 50/150 - 0.42s - loss: 0.8663 - acc: 0.6059 - val_loss: 0.9553 - val_acc: 0.5567\n",
            "Epoch 51/150 - 0.45s - loss: 0.8727 - acc: 0.5981 - val_loss: 0.9545 - val_acc: 0.5709\n",
            "Epoch 52/150 - 0.42s - loss: 0.8484 - acc: 0.6143 - val_loss: 0.9403 - val_acc: 0.5729\n",
            "Epoch 53/150 - 0.45s - loss: 0.8439 - acc: 0.6143 - val_loss: 0.9430 - val_acc: 0.5587\n",
            "Epoch 54/150 - 0.41s - loss: 0.8583 - acc: 0.6055 - val_loss: 0.9625 - val_acc: 0.5324\n",
            "Epoch 55/150 - 0.42s - loss: 0.8506 - acc: 0.6021 - val_loss: 0.9543 - val_acc: 0.5506\n",
            "Epoch 56/150 - 0.44s - loss: 0.9103 - acc: 0.5873 - val_loss: 1.0068 - val_acc: 0.5506\n",
            "Epoch 57/150 - 0.44s - loss: 0.8714 - acc: 0.5873 - val_loss: 0.9807 - val_acc: 0.5223\n",
            "Epoch 58/150 - 0.44s - loss: 0.8682 - acc: 0.5893 - val_loss: 0.9864 - val_acc: 0.5202\n",
            "Epoch 59/150 - 0.43s - loss: 0.8475 - acc: 0.6077 - val_loss: 0.9558 - val_acc: 0.5628\n",
            "Epoch 60/150 - 0.42s - loss: 0.8497 - acc: 0.5949 - val_loss: 0.9763 - val_acc: 0.5162\n",
            "Epoch 61/150 - 0.43s - loss: 0.8286 - acc: 0.6253 - val_loss: 0.9561 - val_acc: 0.5182\n",
            "Epoch 62/150 - 0.42s - loss: 0.8274 - acc: 0.6197 - val_loss: 0.9583 - val_acc: 0.5202\n",
            "Epoch 63/150 - 0.45s - loss: 0.8269 - acc: 0.6091 - val_loss: 0.9502 - val_acc: 0.5364\n",
            "Epoch 64/150 - 0.45s - loss: 0.8517 - acc: 0.6100 - val_loss: 0.9764 - val_acc: 0.5668\n",
            "Epoch 65/150 - 0.41s - loss: 0.8072 - acc: 0.6365 - val_loss: 0.9467 - val_acc: 0.5486\n",
            "Epoch 66/150 - 0.36s - loss: 0.8006 - acc: 0.6489 - val_loss: 0.9360 - val_acc: 0.5567\n",
            "Epoch 67/150 - 0.37s - loss: 0.7939 - acc: 0.6509 - val_loss: 0.9327 - val_acc: 0.5769\n",
            "Epoch 68/150 - 0.35s - loss: 0.8262 - acc: 0.6260 - val_loss: 0.9717 - val_acc: 0.5121\n",
            "Epoch 69/150 - 0.45s - loss: 0.7895 - acc: 0.6523 - val_loss: 0.9326 - val_acc: 0.5668\n",
            "Epoch 70/150 - 0.39s - loss: 0.9209 - acc: 0.5540 - val_loss: 1.0819 - val_acc: 0.4879\n",
            "Epoch 71/150 - 0.40s - loss: 0.8780 - acc: 0.5753 - val_loss: 1.0421 - val_acc: 0.4960\n",
            "Epoch 72/150 - 0.37s - loss: 0.7967 - acc: 0.6390 - val_loss: 0.9504 - val_acc: 0.5547\n",
            "Epoch 73/150 - 0.39s - loss: 0.7908 - acc: 0.6446 - val_loss: 0.9503 - val_acc: 0.5344\n",
            "Epoch 74/150 - 0.40s - loss: 0.7727 - acc: 0.6631 - val_loss: 0.9338 - val_acc: 0.5729\n",
            "Epoch 75/150 - 0.42s - loss: 0.7782 - acc: 0.6529 - val_loss: 0.9394 - val_acc: 0.5506\n",
            "Epoch 76/150 - 0.37s - loss: 0.8053 - acc: 0.6406 - val_loss: 0.9671 - val_acc: 0.5668\n",
            "Epoch 77/150 - 0.37s - loss: 0.7657 - acc: 0.6685 - val_loss: 0.9370 - val_acc: 0.5789\n",
            "Epoch 78/150 - 0.37s - loss: 0.8779 - acc: 0.5758 - val_loss: 1.0643 - val_acc: 0.4939\n",
            "Epoch 79/150 - 0.39s - loss: 0.8459 - acc: 0.6251 - val_loss: 1.0138 - val_acc: 0.5749\n",
            "Epoch 80/150 - 0.36s - loss: 0.7537 - acc: 0.6745 - val_loss: 0.9327 - val_acc: 0.5789\n",
            "Epoch 81/150 - 0.44s - loss: 0.7931 - acc: 0.6316 - val_loss: 0.9761 - val_acc: 0.5243\n",
            "Epoch 82/150 - 0.38s - loss: 0.7760 - acc: 0.6541 - val_loss: 0.9610 - val_acc: 0.5466\n",
            "Epoch 83/150 - 0.38s - loss: 0.7887 - acc: 0.6397 - val_loss: 0.9748 - val_acc: 0.5324\n",
            "Epoch 84/150 - 0.36s - loss: 0.7946 - acc: 0.6338 - val_loss: 0.9983 - val_acc: 0.4980\n",
            "Epoch 85/150 - 0.36s - loss: 0.8133 - acc: 0.6118 - val_loss: 0.9867 - val_acc: 0.5364\n",
            "Epoch 86/150 - 0.35s - loss: 0.7964 - acc: 0.6302 - val_loss: 0.9983 - val_acc: 0.5283\n",
            "Epoch 87/150 - 0.37s - loss: 0.7356 - acc: 0.6842 - val_loss: 0.9377 - val_acc: 0.5567\n",
            "Epoch 88/150 - 0.36s - loss: 0.7595 - acc: 0.6655 - val_loss: 0.9533 - val_acc: 0.5769\n",
            "Epoch 89/150 - 0.36s - loss: 0.8433 - acc: 0.6228 - val_loss: 1.0379 - val_acc: 0.5607\n",
            "Epoch 90/150 - 0.35s - loss: 0.7324 - acc: 0.6757 - val_loss: 0.9391 - val_acc: 0.5709\n",
            "Epoch 91/150 - 0.37s - loss: 0.7175 - acc: 0.6997 - val_loss: 0.9331 - val_acc: 0.5810\n",
            "Epoch 92/150 - 0.38s - loss: 0.9422 - acc: 0.5430 - val_loss: 1.1701 - val_acc: 0.4838\n",
            "Epoch 93/150 - 0.39s - loss: 0.7183 - acc: 0.7006 - val_loss: 0.9426 - val_acc: 0.5769\n",
            "Epoch 94/150 - 0.36s - loss: 0.8411 - acc: 0.5911 - val_loss: 1.0821 - val_acc: 0.4960\n",
            "Epoch 95/150 - 0.36s - loss: 0.7081 - acc: 0.7015 - val_loss: 0.9326 - val_acc: 0.5709\n",
            "Epoch 96/150 - 0.35s - loss: 0.8540 - acc: 0.5866 - val_loss: 1.0621 - val_acc: 0.5283\n",
            "Epoch 97/150 - 0.36s - loss: 0.7157 - acc: 0.6894 - val_loss: 0.9425 - val_acc: 0.5628\n",
            "Epoch 98/150 - 0.38s - loss: 0.7177 - acc: 0.6869 - val_loss: 0.9417 - val_acc: 0.5607\n",
            "Epoch 99/150 - 0.42s - loss: 0.7033 - acc: 0.7020 - val_loss: 0.9536 - val_acc: 0.5425\n",
            "Epoch 100/150 - 0.36s - loss: 0.8029 - acc: 0.6262 - val_loss: 1.0488 - val_acc: 0.5162\n",
            "Epoch 101/150 - 0.38s - loss: 0.7303 - acc: 0.6685 - val_loss: 0.9707 - val_acc: 0.5506\n",
            "Epoch 102/150 - 0.36s - loss: 1.0175 - acc: 0.5160 - val_loss: 1.2835 - val_acc: 0.4696\n",
            "Epoch 103/150 - 0.37s - loss: 0.7692 - acc: 0.6552 - val_loss: 1.0284 - val_acc: 0.5425\n",
            "Epoch 104/150 - 0.37s - loss: 0.7239 - acc: 0.6730 - val_loss: 0.9646 - val_acc: 0.5466\n",
            "Epoch 105/150 - 0.41s - loss: 0.7340 - acc: 0.6790 - val_loss: 0.9823 - val_acc: 0.5830\n",
            "Epoch 106/150 - 0.39s - loss: 0.6971 - acc: 0.7054 - val_loss: 0.9599 - val_acc: 0.5729\n",
            "Epoch 107/150 - 0.41s - loss: 0.6924 - acc: 0.7036 - val_loss: 0.9499 - val_acc: 0.5628\n",
            "Epoch 108/150 - 0.36s - loss: 0.6783 - acc: 0.7143 - val_loss: 0.9582 - val_acc: 0.5648\n",
            "Epoch 109/150 - 0.41s - loss: 0.6621 - acc: 0.7276 - val_loss: 0.9351 - val_acc: 0.5769\n",
            "Epoch 110/150 - 0.38s - loss: 0.8168 - acc: 0.6149 - val_loss: 1.1196 - val_acc: 0.5000\n",
            "Epoch 111/150 - 0.40s - loss: 0.7203 - acc: 0.6795 - val_loss: 1.0083 - val_acc: 0.5263\n",
            "Epoch 112/150 - 0.35s - loss: 0.7118 - acc: 0.6743 - val_loss: 1.0152 - val_acc: 0.5344\n",
            "Epoch 113/150 - 0.37s - loss: 0.7400 - acc: 0.6541 - val_loss: 1.0493 - val_acc: 0.4879\n",
            "Epoch 114/150 - 0.42s - loss: 0.6486 - acc: 0.7362 - val_loss: 0.9431 - val_acc: 0.5749\n",
            "Epoch 115/150 - 0.40s - loss: 0.7612 - acc: 0.6320 - val_loss: 1.0367 - val_acc: 0.5223\n",
            "Epoch 116/150 - 0.38s - loss: 0.8520 - acc: 0.5837 - val_loss: 1.1644 - val_acc: 0.4656\n",
            "Epoch 117/150 - 0.39s - loss: 0.7555 - acc: 0.6518 - val_loss: 1.0882 - val_acc: 0.5040\n",
            "Epoch 118/150 - 0.37s - loss: 0.6536 - acc: 0.7285 - val_loss: 0.9618 - val_acc: 0.5810\n",
            "Epoch 119/150 - 0.41s - loss: 0.9060 - acc: 0.5749 - val_loss: 1.1884 - val_acc: 0.5182\n",
            "Epoch 120/150 - 0.37s - loss: 0.6223 - acc: 0.7553 - val_loss: 0.9285 - val_acc: 0.5789\n",
            "Epoch 121/150 - 0.38s - loss: 0.6936 - acc: 0.6984 - val_loss: 1.0221 - val_acc: 0.5506\n",
            "Epoch 122/150 - 0.35s - loss: 0.7265 - acc: 0.6723 - val_loss: 1.0390 - val_acc: 0.5304\n",
            "Epoch 123/150 - 0.38s - loss: 0.9569 - acc: 0.5373 - val_loss: 1.3216 - val_acc: 0.4615\n",
            "Epoch 124/150 - 0.37s - loss: 0.6312 - acc: 0.7463 - val_loss: 0.9804 - val_acc: 0.5445\n",
            "Epoch 125/150 - 0.41s - loss: 1.3601 - acc: 0.4283 - val_loss: 1.6331 - val_acc: 0.4069\n",
            "Epoch 126/150 - 0.39s - loss: 0.5965 - acc: 0.7668 - val_loss: 0.9352 - val_acc: 0.5810\n",
            "Epoch 127/150 - 0.49s - loss: 0.6671 - acc: 0.7040 - val_loss: 1.0365 - val_acc: 0.5101\n",
            "Epoch 128/150 - 0.46s - loss: 0.6252 - acc: 0.7447 - val_loss: 0.9953 - val_acc: 0.5364\n",
            "Epoch 129/150 - 0.43s - loss: 0.6941 - acc: 0.6907 - val_loss: 1.0705 - val_acc: 0.5101\n",
            "Epoch 130/150 - 0.40s - loss: 0.5960 - acc: 0.7638 - val_loss: 0.9617 - val_acc: 0.5709\n",
            "Epoch 131/150 - 0.37s - loss: 0.5916 - acc: 0.7634 - val_loss: 0.9621 - val_acc: 0.5729\n",
            "Epoch 132/150 - 0.40s - loss: 0.9601 - acc: 0.5909 - val_loss: 1.3657 - val_acc: 0.4575\n",
            "Epoch 133/150 - 0.45s - loss: 0.7462 - acc: 0.6525 - val_loss: 1.1429 - val_acc: 0.5101\n",
            "Epoch 134/150 - 0.42s - loss: 0.8022 - acc: 0.6397 - val_loss: 1.1620 - val_acc: 0.5263\n",
            "Epoch 135/150 - 0.44s - loss: 0.6185 - acc: 0.7485 - val_loss: 1.0069 - val_acc: 0.5749\n",
            "Epoch 136/150 - 0.43s - loss: 0.5997 - acc: 0.7611 - val_loss: 1.0056 - val_acc: 0.5364\n",
            "Epoch 137/150 - 0.42s - loss: 0.5965 - acc: 0.7533 - val_loss: 1.0179 - val_acc: 0.5364\n",
            "Epoch 138/150 - 0.40s - loss: 1.1112 - acc: 0.4840 - val_loss: 1.5508 - val_acc: 0.4271\n",
            "Epoch 139/150 - 0.44s - loss: 0.7265 - acc: 0.6680 - val_loss: 1.1338 - val_acc: 0.5162\n",
            "Epoch 140/150 - 0.39s - loss: 0.5917 - acc: 0.7515 - val_loss: 1.0146 - val_acc: 0.5628\n",
            "Epoch 141/150 - 0.41s - loss: 0.5333 - acc: 0.8072 - val_loss: 0.9572 - val_acc: 0.5789\n",
            "Epoch 142/150 - 0.35s - loss: 0.5806 - acc: 0.7728 - val_loss: 1.0094 - val_acc: 0.5466\n",
            "Epoch 143/150 - 0.35s - loss: 0.5283 - acc: 0.8052 - val_loss: 0.9546 - val_acc: 0.5810\n",
            "Epoch 144/150 - 0.36s - loss: 0.5264 - acc: 0.8034 - val_loss: 0.9503 - val_acc: 0.5911\n",
            "Epoch 145/150 - 0.36s - loss: 0.5849 - acc: 0.7483 - val_loss: 1.0083 - val_acc: 0.5628\n",
            "Epoch 146/150 - 0.37s - loss: 0.7001 - acc: 0.6633 - val_loss: 1.1204 - val_acc: 0.5324\n",
            "Epoch 147/150 - 0.36s - loss: 0.6495 - acc: 0.7123 - val_loss: 1.1120 - val_acc: 0.5364\n",
            "Epoch 148/150 - 0.37s - loss: 0.5368 - acc: 0.7845 - val_loss: 0.9994 - val_acc: 0.5547\n",
            "Epoch 149/150 - 0.35s - loss: 0.6401 - acc: 0.7213 - val_loss: 1.1140 - val_acc: 0.5466\n",
            "Epoch 150/150 - 0.35s - loss: 0.6188 - acc: 0.7323 - val_loss: 1.1032 - val_acc: 0.5324\n",
            "\n",
            "Combination 223/252:\n",
            "Hidden Layers: [512, 256, 128], Activation: relu, Learning Rate: 0.001, Batch Size: 32, Epochs: 50\n",
            "Epoch 1/50 - 0.59s - loss: 1.1010 - acc: 0.3293 - val_loss: 1.0998 - val_acc: 0.3279\n",
            "Epoch 2/50 - 0.63s - loss: 1.0958 - acc: 0.3543 - val_loss: 1.0944 - val_acc: 0.3421\n",
            "Epoch 3/50 - 0.63s - loss: 1.0920 - acc: 0.3776 - val_loss: 1.0913 - val_acc: 0.3421\n",
            "Epoch 4/50 - 0.56s - loss: 1.0885 - acc: 0.3986 - val_loss: 1.0883 - val_acc: 0.3806\n",
            "Epoch 5/50 - 0.63s - loss: 1.0853 - acc: 0.4098 - val_loss: 1.0855 - val_acc: 0.3826\n",
            "Epoch 6/50 - 0.56s - loss: 1.0823 - acc: 0.4163 - val_loss: 1.0831 - val_acc: 0.4170\n",
            "Epoch 7/50 - 0.60s - loss: 1.0795 - acc: 0.4265 - val_loss: 1.0808 - val_acc: 0.4251\n",
            "Epoch 8/50 - 0.58s - loss: 1.0770 - acc: 0.4330 - val_loss: 1.0787 - val_acc: 0.4291\n",
            "Epoch 9/50 - 0.60s - loss: 1.0746 - acc: 0.4397 - val_loss: 1.0767 - val_acc: 0.4332\n",
            "Epoch 10/50 - 0.59s - loss: 1.0724 - acc: 0.4476 - val_loss: 1.0748 - val_acc: 0.4555\n",
            "Epoch 11/50 - 0.56s - loss: 1.0703 - acc: 0.4510 - val_loss: 1.0732 - val_acc: 0.4595\n",
            "Epoch 12/50 - 0.58s - loss: 1.0682 - acc: 0.4521 - val_loss: 1.0717 - val_acc: 0.4534\n",
            "Epoch 13/50 - 0.55s - loss: 1.0662 - acc: 0.4514 - val_loss: 1.0703 - val_acc: 0.4575\n",
            "Epoch 14/50 - 0.56s - loss: 1.0643 - acc: 0.4613 - val_loss: 1.0685 - val_acc: 0.4575\n",
            "Epoch 15/50 - 0.58s - loss: 1.0628 - acc: 0.4575 - val_loss: 1.0676 - val_acc: 0.4676\n",
            "Epoch 16/50 - 0.55s - loss: 1.0609 - acc: 0.4620 - val_loss: 1.0661 - val_acc: 0.4717\n",
            "Epoch 17/50 - 0.55s - loss: 1.0593 - acc: 0.4645 - val_loss: 1.0649 - val_acc: 0.4676\n",
            "Epoch 18/50 - 0.54s - loss: 1.0577 - acc: 0.4669 - val_loss: 1.0639 - val_acc: 0.4676\n",
            "Epoch 19/50 - 0.55s - loss: 1.0561 - acc: 0.4699 - val_loss: 1.0624 - val_acc: 0.4676\n",
            "Epoch 20/50 - 0.55s - loss: 1.0546 - acc: 0.4701 - val_loss: 1.0616 - val_acc: 0.4696\n",
            "Epoch 21/50 - 0.57s - loss: 1.0530 - acc: 0.4739 - val_loss: 1.0602 - val_acc: 0.4636\n",
            "Epoch 22/50 - 0.56s - loss: 1.0516 - acc: 0.4748 - val_loss: 1.0591 - val_acc: 0.4696\n",
            "Epoch 23/50 - 0.57s - loss: 1.0501 - acc: 0.4748 - val_loss: 1.0581 - val_acc: 0.4696\n",
            "Epoch 24/50 - 0.57s - loss: 1.0488 - acc: 0.4773 - val_loss: 1.0574 - val_acc: 0.4595\n",
            "Epoch 25/50 - 0.56s - loss: 1.0474 - acc: 0.4746 - val_loss: 1.0561 - val_acc: 0.4676\n",
            "Epoch 26/50 - 0.54s - loss: 1.0460 - acc: 0.4771 - val_loss: 1.0553 - val_acc: 0.4636\n",
            "Epoch 27/50 - 0.62s - loss: 1.0447 - acc: 0.4780 - val_loss: 1.0544 - val_acc: 0.4636\n",
            "Epoch 28/50 - 0.56s - loss: 1.0435 - acc: 0.4813 - val_loss: 1.0538 - val_acc: 0.4514\n",
            "Epoch 29/50 - 0.65s - loss: 1.0421 - acc: 0.4784 - val_loss: 1.0524 - val_acc: 0.4737\n",
            "Epoch 30/50 - 0.62s - loss: 1.0408 - acc: 0.4811 - val_loss: 1.0516 - val_acc: 0.4676\n",
            "Epoch 31/50 - 0.65s - loss: 1.0395 - acc: 0.4820 - val_loss: 1.0505 - val_acc: 0.4636\n",
            "Epoch 32/50 - 0.66s - loss: 1.0384 - acc: 0.4793 - val_loss: 1.0499 - val_acc: 0.4777\n",
            "Epoch 33/50 - 0.64s - loss: 1.0369 - acc: 0.4834 - val_loss: 1.0490 - val_acc: 0.4777\n",
            "Epoch 34/50 - 0.68s - loss: 1.0356 - acc: 0.4847 - val_loss: 1.0481 - val_acc: 0.4717\n",
            "Epoch 35/50 - 0.61s - loss: 1.0344 - acc: 0.4838 - val_loss: 1.0474 - val_acc: 0.4777\n",
            "Epoch 36/50 - 0.61s - loss: 1.0332 - acc: 0.4865 - val_loss: 1.0463 - val_acc: 0.4737\n",
            "Epoch 37/50 - 0.67s - loss: 1.0319 - acc: 0.4847 - val_loss: 1.0452 - val_acc: 0.4717\n",
            "Epoch 38/50 - 0.64s - loss: 1.0306 - acc: 0.4867 - val_loss: 1.0450 - val_acc: 0.4838\n",
            "Epoch 39/50 - 0.70s - loss: 1.0293 - acc: 0.4872 - val_loss: 1.0438 - val_acc: 0.4777\n",
            "Epoch 40/50 - 0.65s - loss: 1.0281 - acc: 0.4894 - val_loss: 1.0430 - val_acc: 0.4838\n",
            "Epoch 41/50 - 0.65s - loss: 1.0269 - acc: 0.4854 - val_loss: 1.0425 - val_acc: 0.4838\n",
            "Epoch 42/50 - 0.54s - loss: 1.0256 - acc: 0.4890 - val_loss: 1.0414 - val_acc: 0.4818\n",
            "Epoch 43/50 - 0.51s - loss: 1.0243 - acc: 0.4921 - val_loss: 1.0405 - val_acc: 0.4899\n",
            "Epoch 44/50 - 0.56s - loss: 1.0231 - acc: 0.4921 - val_loss: 1.0391 - val_acc: 0.4858\n",
            "Epoch 45/50 - 0.54s - loss: 1.0218 - acc: 0.4966 - val_loss: 1.0385 - val_acc: 0.4879\n",
            "Epoch 46/50 - 0.52s - loss: 1.0206 - acc: 0.4964 - val_loss: 1.0376 - val_acc: 0.4879\n",
            "Epoch 47/50 - 0.52s - loss: 1.0198 - acc: 0.4996 - val_loss: 1.0377 - val_acc: 0.4899\n",
            "Epoch 48/50 - 0.50s - loss: 1.0180 - acc: 0.4971 - val_loss: 1.0360 - val_acc: 0.4919\n",
            "Epoch 49/50 - 0.52s - loss: 1.0168 - acc: 0.4962 - val_loss: 1.0352 - val_acc: 0.4899\n",
            "Epoch 50/50 - 0.67s - loss: 1.0156 - acc: 0.4962 - val_loss: 1.0343 - val_acc: 0.4960\n",
            "\n",
            "Combination 224/252:\n",
            "Hidden Layers: [512, 256, 128], Activation: relu, Learning Rate: 0.001, Batch Size: 32, Epochs: 100\n",
            "Epoch 1/100 - 0.68s - loss: 1.1049 - acc: 0.3093 - val_loss: 1.1061 - val_acc: 0.3198\n",
            "Epoch 2/100 - 0.56s - loss: 1.0998 - acc: 0.3284 - val_loss: 1.1014 - val_acc: 0.3198\n",
            "Epoch 3/100 - 0.55s - loss: 1.0957 - acc: 0.3491 - val_loss: 1.0981 - val_acc: 0.3300\n",
            "Epoch 4/100 - 0.57s - loss: 1.0920 - acc: 0.3684 - val_loss: 1.0949 - val_acc: 0.3381\n",
            "Epoch 5/100 - 0.53s - loss: 1.0886 - acc: 0.3882 - val_loss: 1.0923 - val_acc: 0.3502\n",
            "Epoch 6/100 - 0.58s - loss: 1.0855 - acc: 0.3981 - val_loss: 1.0898 - val_acc: 0.3806\n",
            "Epoch 7/100 - 0.56s - loss: 1.0825 - acc: 0.4067 - val_loss: 1.0875 - val_acc: 0.3846\n",
            "Epoch 8/100 - 0.57s - loss: 1.0798 - acc: 0.4136 - val_loss: 1.0854 - val_acc: 0.3866\n",
            "Epoch 9/100 - 0.60s - loss: 1.0772 - acc: 0.4170 - val_loss: 1.0836 - val_acc: 0.3988\n",
            "Epoch 10/100 - 0.58s - loss: 1.0748 - acc: 0.4258 - val_loss: 1.0817 - val_acc: 0.4008\n",
            "Epoch 11/100 - 0.56s - loss: 1.0725 - acc: 0.4314 - val_loss: 1.0802 - val_acc: 0.4028\n",
            "Epoch 12/100 - 0.59s - loss: 1.0704 - acc: 0.4303 - val_loss: 1.0789 - val_acc: 0.4109\n",
            "Epoch 13/100 - 0.60s - loss: 1.0683 - acc: 0.4379 - val_loss: 1.0772 - val_acc: 0.4150\n",
            "Epoch 14/100 - 0.56s - loss: 1.0662 - acc: 0.4417 - val_loss: 1.0756 - val_acc: 0.4312\n",
            "Epoch 15/100 - 0.55s - loss: 1.0643 - acc: 0.4449 - val_loss: 1.0741 - val_acc: 0.4271\n",
            "Epoch 16/100 - 0.56s - loss: 1.0624 - acc: 0.4492 - val_loss: 1.0728 - val_acc: 0.4332\n",
            "Epoch 17/100 - 0.54s - loss: 1.0607 - acc: 0.4521 - val_loss: 1.0719 - val_acc: 0.4291\n",
            "Epoch 18/100 - 0.55s - loss: 1.0589 - acc: 0.4498 - val_loss: 1.0701 - val_acc: 0.4312\n",
            "Epoch 19/100 - 0.58s - loss: 1.0572 - acc: 0.4514 - val_loss: 1.0688 - val_acc: 0.4312\n",
            "Epoch 20/100 - 0.53s - loss: 1.0555 - acc: 0.4557 - val_loss: 1.0679 - val_acc: 0.4352\n",
            "Epoch 21/100 - 0.54s - loss: 1.0539 - acc: 0.4591 - val_loss: 1.0666 - val_acc: 0.4332\n",
            "Epoch 22/100 - 0.53s - loss: 1.0524 - acc: 0.4633 - val_loss: 1.0659 - val_acc: 0.4433\n",
            "Epoch 23/100 - 0.55s - loss: 1.0509 - acc: 0.4568 - val_loss: 1.0645 - val_acc: 0.4372\n",
            "Epoch 24/100 - 0.59s - loss: 1.0494 - acc: 0.4667 - val_loss: 1.0639 - val_acc: 0.4474\n",
            "Epoch 25/100 - 0.64s - loss: 1.0479 - acc: 0.4660 - val_loss: 1.0626 - val_acc: 0.4453\n",
            "Epoch 26/100 - 0.53s - loss: 1.0465 - acc: 0.4699 - val_loss: 1.0617 - val_acc: 0.4474\n",
            "Epoch 27/100 - 0.56s - loss: 1.0451 - acc: 0.4726 - val_loss: 1.0608 - val_acc: 0.4433\n",
            "Epoch 28/100 - 0.54s - loss: 1.0438 - acc: 0.4735 - val_loss: 1.0601 - val_acc: 0.4494\n",
            "Epoch 29/100 - 0.54s - loss: 1.0424 - acc: 0.4748 - val_loss: 1.0588 - val_acc: 0.4494\n",
            "Epoch 30/100 - 0.59s - loss: 1.0410 - acc: 0.4768 - val_loss: 1.0580 - val_acc: 0.4514\n",
            "Epoch 31/100 - 0.66s - loss: 1.0397 - acc: 0.4800 - val_loss: 1.0572 - val_acc: 0.4514\n",
            "Epoch 32/100 - 0.65s - loss: 1.0385 - acc: 0.4762 - val_loss: 1.0561 - val_acc: 0.4453\n",
            "Epoch 33/100 - 0.57s - loss: 1.0371 - acc: 0.4831 - val_loss: 1.0558 - val_acc: 0.4494\n",
            "Epoch 34/100 - 0.66s - loss: 1.0358 - acc: 0.4845 - val_loss: 1.0546 - val_acc: 0.4555\n",
            "Epoch 35/100 - 0.59s - loss: 1.0346 - acc: 0.4802 - val_loss: 1.0536 - val_acc: 0.4514\n",
            "Epoch 36/100 - 0.59s - loss: 1.0333 - acc: 0.4813 - val_loss: 1.0531 - val_acc: 0.4575\n",
            "Epoch 37/100 - 0.60s - loss: 1.0319 - acc: 0.4870 - val_loss: 1.0523 - val_acc: 0.4555\n",
            "Epoch 38/100 - 0.57s - loss: 1.0306 - acc: 0.4870 - val_loss: 1.0515 - val_acc: 0.4636\n",
            "Epoch 39/100 - 0.54s - loss: 1.0294 - acc: 0.4910 - val_loss: 1.0503 - val_acc: 0.4636\n",
            "Epoch 40/100 - 0.57s - loss: 1.0280 - acc: 0.4912 - val_loss: 1.0498 - val_acc: 0.4717\n",
            "Epoch 41/100 - 0.57s - loss: 1.0268 - acc: 0.4908 - val_loss: 1.0492 - val_acc: 0.4737\n",
            "Epoch 42/100 - 0.58s - loss: 1.0256 - acc: 0.4885 - val_loss: 1.0485 - val_acc: 0.4717\n",
            "Epoch 43/100 - 0.64s - loss: 1.0243 - acc: 0.4930 - val_loss: 1.0473 - val_acc: 0.4818\n",
            "Epoch 44/100 - 0.65s - loss: 1.0230 - acc: 0.4933 - val_loss: 1.0471 - val_acc: 0.4737\n",
            "Epoch 45/100 - 0.61s - loss: 1.0217 - acc: 0.4966 - val_loss: 1.0461 - val_acc: 0.4798\n",
            "Epoch 46/100 - 0.63s - loss: 1.0206 - acc: 0.4955 - val_loss: 1.0455 - val_acc: 0.4757\n",
            "Epoch 47/100 - 0.57s - loss: 1.0193 - acc: 0.4982 - val_loss: 1.0450 - val_acc: 0.4798\n",
            "Epoch 48/100 - 0.64s - loss: 1.0184 - acc: 0.5058 - val_loss: 1.0450 - val_acc: 0.4737\n",
            "Epoch 49/100 - 0.61s - loss: 1.0168 - acc: 0.5031 - val_loss: 1.0430 - val_acc: 0.4858\n",
            "Epoch 50/100 - 0.60s - loss: 1.0156 - acc: 0.5076 - val_loss: 1.0432 - val_acc: 0.4777\n",
            "Epoch 51/100 - 0.54s - loss: 1.0142 - acc: 0.5036 - val_loss: 1.0418 - val_acc: 0.4798\n",
            "Epoch 52/100 - 0.62s - loss: 1.0131 - acc: 0.5011 - val_loss: 1.0413 - val_acc: 0.4858\n",
            "Epoch 53/100 - 0.66s - loss: 1.0123 - acc: 0.5018 - val_loss: 1.0401 - val_acc: 0.4858\n",
            "Epoch 54/100 - 0.64s - loss: 1.0108 - acc: 0.5052 - val_loss: 1.0392 - val_acc: 0.4838\n",
            "Epoch 55/100 - 0.61s - loss: 1.0095 - acc: 0.5162 - val_loss: 1.0395 - val_acc: 0.4838\n",
            "Epoch 56/100 - 0.61s - loss: 1.0081 - acc: 0.5103 - val_loss: 1.0378 - val_acc: 0.4858\n",
            "Epoch 57/100 - 0.61s - loss: 1.0068 - acc: 0.5175 - val_loss: 1.0373 - val_acc: 0.4899\n",
            "Epoch 58/100 - 0.61s - loss: 1.0058 - acc: 0.5184 - val_loss: 1.0373 - val_acc: 0.4838\n",
            "Epoch 59/100 - 0.61s - loss: 1.0044 - acc: 0.5196 - val_loss: 1.0358 - val_acc: 0.4838\n",
            "Epoch 60/100 - 0.64s - loss: 1.0032 - acc: 0.5180 - val_loss: 1.0348 - val_acc: 0.4879\n",
            "Epoch 61/100 - 0.67s - loss: 1.0021 - acc: 0.5198 - val_loss: 1.0340 - val_acc: 0.4879\n",
            "Epoch 62/100 - 0.71s - loss: 1.0008 - acc: 0.5241 - val_loss: 1.0336 - val_acc: 0.4838\n",
            "Epoch 63/100 - 0.63s - loss: 0.9998 - acc: 0.5189 - val_loss: 1.0324 - val_acc: 0.4899\n",
            "Epoch 64/100 - 0.70s - loss: 0.9986 - acc: 0.5265 - val_loss: 1.0326 - val_acc: 0.4858\n",
            "Epoch 65/100 - 0.55s - loss: 0.9977 - acc: 0.5184 - val_loss: 1.0310 - val_acc: 0.4919\n",
            "Epoch 66/100 - 0.52s - loss: 0.9960 - acc: 0.5277 - val_loss: 1.0302 - val_acc: 0.4818\n",
            "Epoch 67/100 - 0.58s - loss: 0.9948 - acc: 0.5277 - val_loss: 1.0294 - val_acc: 0.4838\n",
            "Epoch 68/100 - 0.55s - loss: 0.9938 - acc: 0.5259 - val_loss: 1.0290 - val_acc: 0.4899\n",
            "Epoch 69/100 - 0.62s - loss: 0.9925 - acc: 0.5252 - val_loss: 1.0283 - val_acc: 0.4899\n",
            "Epoch 70/100 - 0.55s - loss: 0.9912 - acc: 0.5283 - val_loss: 1.0273 - val_acc: 0.4939\n",
            "Epoch 71/100 - 0.61s - loss: 0.9900 - acc: 0.5288 - val_loss: 1.0265 - val_acc: 0.4939\n",
            "Epoch 72/100 - 0.56s - loss: 0.9889 - acc: 0.5310 - val_loss: 1.0257 - val_acc: 0.5000\n",
            "Epoch 73/100 - 0.58s - loss: 0.9877 - acc: 0.5304 - val_loss: 1.0244 - val_acc: 0.4919\n",
            "Epoch 74/100 - 0.52s - loss: 0.9866 - acc: 0.5322 - val_loss: 1.0246 - val_acc: 0.4879\n",
            "Epoch 75/100 - 0.57s - loss: 0.9852 - acc: 0.5326 - val_loss: 1.0229 - val_acc: 0.4919\n",
            "Epoch 76/100 - 0.58s - loss: 0.9848 - acc: 0.5342 - val_loss: 1.0238 - val_acc: 0.4899\n",
            "Epoch 77/100 - 0.55s - loss: 0.9833 - acc: 0.5351 - val_loss: 1.0223 - val_acc: 0.4899\n",
            "Epoch 78/100 - 0.53s - loss: 0.9821 - acc: 0.5369 - val_loss: 1.0217 - val_acc: 0.4899\n",
            "Epoch 79/100 - 0.58s - loss: 0.9804 - acc: 0.5364 - val_loss: 1.0198 - val_acc: 0.5020\n",
            "Epoch 80/100 - 0.52s - loss: 0.9794 - acc: 0.5378 - val_loss: 1.0195 - val_acc: 0.4980\n",
            "Epoch 81/100 - 0.60s - loss: 0.9782 - acc: 0.5380 - val_loss: 1.0177 - val_acc: 0.4939\n",
            "Epoch 82/100 - 0.54s - loss: 0.9770 - acc: 0.5387 - val_loss: 1.0179 - val_acc: 0.5020\n",
            "Epoch 83/100 - 0.53s - loss: 0.9767 - acc: 0.5387 - val_loss: 1.0163 - val_acc: 0.4960\n",
            "Epoch 84/100 - 0.51s - loss: 0.9750 - acc: 0.5423 - val_loss: 1.0168 - val_acc: 0.4960\n",
            "Epoch 85/100 - 0.56s - loss: 0.9734 - acc: 0.5389 - val_loss: 1.0147 - val_acc: 0.4980\n",
            "Epoch 86/100 - 0.52s - loss: 0.9726 - acc: 0.5427 - val_loss: 1.0148 - val_acc: 0.5040\n",
            "Epoch 87/100 - 0.52s - loss: 0.9711 - acc: 0.5405 - val_loss: 1.0135 - val_acc: 0.5040\n",
            "Epoch 88/100 - 0.51s - loss: 0.9707 - acc: 0.5457 - val_loss: 1.0137 - val_acc: 0.5020\n",
            "Epoch 89/100 - 0.52s - loss: 0.9693 - acc: 0.5414 - val_loss: 1.0119 - val_acc: 0.5061\n",
            "Epoch 90/100 - 0.53s - loss: 0.9677 - acc: 0.5436 - val_loss: 1.0111 - val_acc: 0.5000\n",
            "Epoch 91/100 - 0.56s - loss: 0.9668 - acc: 0.5409 - val_loss: 1.0100 - val_acc: 0.5061\n",
            "Epoch 92/100 - 0.52s - loss: 0.9656 - acc: 0.5468 - val_loss: 1.0100 - val_acc: 0.5061\n",
            "Epoch 93/100 - 0.53s - loss: 0.9645 - acc: 0.5477 - val_loss: 1.0094 - val_acc: 0.5000\n",
            "Epoch 94/100 - 0.53s - loss: 0.9633 - acc: 0.5472 - val_loss: 1.0087 - val_acc: 0.4980\n",
            "Epoch 95/100 - 0.56s - loss: 0.9624 - acc: 0.5418 - val_loss: 1.0068 - val_acc: 0.5040\n",
            "Epoch 96/100 - 0.53s - loss: 0.9609 - acc: 0.5468 - val_loss: 1.0061 - val_acc: 0.5020\n",
            "Epoch 97/100 - 0.56s - loss: 0.9606 - acc: 0.5443 - val_loss: 1.0058 - val_acc: 0.5101\n",
            "Epoch 98/100 - 0.52s - loss: 0.9587 - acc: 0.5497 - val_loss: 1.0048 - val_acc: 0.5061\n",
            "Epoch 99/100 - 0.56s - loss: 0.9579 - acc: 0.5513 - val_loss: 1.0043 - val_acc: 0.5081\n",
            "Epoch 100/100 - 0.52s - loss: 0.9567 - acc: 0.5508 - val_loss: 1.0036 - val_acc: 0.5081\n",
            "\n",
            "Combination 225/252:\n",
            "Hidden Layers: [512, 256, 128], Activation: relu, Learning Rate: 0.001, Batch Size: 32, Epochs: 150\n",
            "Epoch 1/150 - 0.64s - loss: 1.0992 - acc: 0.3500 - val_loss: 1.0989 - val_acc: 0.3340\n",
            "Epoch 2/150 - 0.56s - loss: 1.0942 - acc: 0.3680 - val_loss: 1.0952 - val_acc: 0.3502\n",
            "Epoch 3/150 - 0.55s - loss: 1.0913 - acc: 0.3781 - val_loss: 1.0930 - val_acc: 0.3826\n",
            "Epoch 4/150 - 0.51s - loss: 1.0887 - acc: 0.3866 - val_loss: 1.0912 - val_acc: 0.4049\n",
            "Epoch 5/150 - 0.55s - loss: 1.0864 - acc: 0.3941 - val_loss: 1.0892 - val_acc: 0.4028\n",
            "Epoch 6/150 - 0.54s - loss: 1.0842 - acc: 0.4107 - val_loss: 1.0873 - val_acc: 0.4049\n",
            "Epoch 7/150 - 0.54s - loss: 1.0821 - acc: 0.4091 - val_loss: 1.0857 - val_acc: 0.4109\n",
            "Epoch 8/150 - 0.54s - loss: 1.0801 - acc: 0.4163 - val_loss: 1.0841 - val_acc: 0.4130\n",
            "Epoch 9/150 - 0.54s - loss: 1.0782 - acc: 0.4204 - val_loss: 1.0827 - val_acc: 0.4170\n",
            "Epoch 10/150 - 0.51s - loss: 1.0764 - acc: 0.4278 - val_loss: 1.0811 - val_acc: 0.4231\n",
            "Epoch 11/150 - 0.54s - loss: 1.0747 - acc: 0.4314 - val_loss: 1.0798 - val_acc: 0.4130\n",
            "Epoch 12/150 - 0.54s - loss: 1.0729 - acc: 0.4327 - val_loss: 1.0785 - val_acc: 0.4211\n",
            "Epoch 13/150 - 0.52s - loss: 1.0713 - acc: 0.4370 - val_loss: 1.0772 - val_acc: 0.4130\n",
            "Epoch 14/150 - 0.54s - loss: 1.0697 - acc: 0.4381 - val_loss: 1.0760 - val_acc: 0.4251\n",
            "Epoch 15/150 - 0.56s - loss: 1.0681 - acc: 0.4444 - val_loss: 1.0747 - val_acc: 0.4251\n",
            "Epoch 16/150 - 0.55s - loss: 1.0666 - acc: 0.4424 - val_loss: 1.0736 - val_acc: 0.4231\n",
            "Epoch 17/150 - 0.61s - loss: 1.0651 - acc: 0.4485 - val_loss: 1.0724 - val_acc: 0.4312\n",
            "Epoch 18/150 - 0.67s - loss: 1.0637 - acc: 0.4519 - val_loss: 1.0712 - val_acc: 0.4312\n",
            "Epoch 19/150 - 0.55s - loss: 1.0622 - acc: 0.4525 - val_loss: 1.0702 - val_acc: 0.4352\n",
            "Epoch 20/150 - 0.58s - loss: 1.0609 - acc: 0.4588 - val_loss: 1.0689 - val_acc: 0.4453\n",
            "Epoch 21/150 - 0.55s - loss: 1.0595 - acc: 0.4602 - val_loss: 1.0680 - val_acc: 0.4453\n",
            "Epoch 22/150 - 0.54s - loss: 1.0581 - acc: 0.4602 - val_loss: 1.0669 - val_acc: 0.4595\n",
            "Epoch 23/150 - 0.54s - loss: 1.0568 - acc: 0.4629 - val_loss: 1.0661 - val_acc: 0.4514\n",
            "Epoch 24/150 - 0.52s - loss: 1.0555 - acc: 0.4658 - val_loss: 1.0650 - val_acc: 0.4595\n",
            "Epoch 25/150 - 0.53s - loss: 1.0542 - acc: 0.4665 - val_loss: 1.0643 - val_acc: 0.4575\n",
            "Epoch 26/150 - 0.55s - loss: 1.0529 - acc: 0.4674 - val_loss: 1.0635 - val_acc: 0.4636\n",
            "Epoch 27/150 - 0.55s - loss: 1.0517 - acc: 0.4692 - val_loss: 1.0624 - val_acc: 0.4636\n",
            "Epoch 28/150 - 0.55s - loss: 1.0504 - acc: 0.4714 - val_loss: 1.0615 - val_acc: 0.4615\n",
            "Epoch 29/150 - 0.57s - loss: 1.0492 - acc: 0.4721 - val_loss: 1.0609 - val_acc: 0.4717\n",
            "Epoch 30/150 - 0.56s - loss: 1.0479 - acc: 0.4744 - val_loss: 1.0599 - val_acc: 0.4757\n",
            "Epoch 31/150 - 0.55s - loss: 1.0468 - acc: 0.4739 - val_loss: 1.0589 - val_acc: 0.4798\n",
            "Epoch 32/150 - 0.53s - loss: 1.0455 - acc: 0.4726 - val_loss: 1.0584 - val_acc: 0.4777\n",
            "Epoch 33/150 - 0.56s - loss: 1.0443 - acc: 0.4764 - val_loss: 1.0573 - val_acc: 0.4858\n",
            "Epoch 34/150 - 0.52s - loss: 1.0431 - acc: 0.4768 - val_loss: 1.0564 - val_acc: 0.4838\n",
            "Epoch 35/150 - 0.54s - loss: 1.0420 - acc: 0.4764 - val_loss: 1.0559 - val_acc: 0.4858\n",
            "Epoch 36/150 - 0.52s - loss: 1.0407 - acc: 0.4811 - val_loss: 1.0546 - val_acc: 0.4879\n",
            "Epoch 37/150 - 0.52s - loss: 1.0394 - acc: 0.4802 - val_loss: 1.0535 - val_acc: 0.4858\n",
            "Epoch 38/150 - 0.53s - loss: 1.0382 - acc: 0.4807 - val_loss: 1.0526 - val_acc: 0.4858\n",
            "Epoch 39/150 - 0.56s - loss: 1.0370 - acc: 0.4840 - val_loss: 1.0515 - val_acc: 0.4879\n",
            "Epoch 40/150 - 0.54s - loss: 1.0358 - acc: 0.4818 - val_loss: 1.0512 - val_acc: 0.4899\n",
            "Epoch 41/150 - 0.59s - loss: 1.0345 - acc: 0.4845 - val_loss: 1.0502 - val_acc: 0.4939\n",
            "Epoch 42/150 - 0.59s - loss: 1.0334 - acc: 0.4858 - val_loss: 1.0494 - val_acc: 0.4919\n",
            "Epoch 43/150 - 0.57s - loss: 1.0321 - acc: 0.4845 - val_loss: 1.0485 - val_acc: 0.4960\n",
            "Epoch 44/150 - 0.61s - loss: 1.0310 - acc: 0.4847 - val_loss: 1.0480 - val_acc: 0.5000\n",
            "Epoch 45/150 - 0.58s - loss: 1.0298 - acc: 0.4843 - val_loss: 1.0469 - val_acc: 0.4879\n",
            "Epoch 46/150 - 0.59s - loss: 1.0285 - acc: 0.4888 - val_loss: 1.0461 - val_acc: 0.4980\n",
            "Epoch 47/150 - 0.57s - loss: 1.0273 - acc: 0.4881 - val_loss: 1.0454 - val_acc: 0.5000\n",
            "Epoch 48/150 - 0.67s - loss: 1.0261 - acc: 0.4915 - val_loss: 1.0443 - val_acc: 0.4960\n",
            "Epoch 49/150 - 0.59s - loss: 1.0251 - acc: 0.4935 - val_loss: 1.0434 - val_acc: 0.4919\n",
            "Epoch 50/150 - 0.68s - loss: 1.0238 - acc: 0.4942 - val_loss: 1.0426 - val_acc: 0.4960\n",
            "Epoch 51/150 - 0.58s - loss: 1.0227 - acc: 0.4960 - val_loss: 1.0420 - val_acc: 0.4980\n",
            "Epoch 52/150 - 0.59s - loss: 1.0214 - acc: 0.4980 - val_loss: 1.0413 - val_acc: 0.5020\n",
            "Epoch 53/150 - 0.63s - loss: 1.0203 - acc: 0.4987 - val_loss: 1.0407 - val_acc: 0.5020\n",
            "Epoch 54/150 - 0.59s - loss: 1.0191 - acc: 0.5000 - val_loss: 1.0399 - val_acc: 0.5020\n",
            "Epoch 55/150 - 0.57s - loss: 1.0180 - acc: 0.4989 - val_loss: 1.0390 - val_acc: 0.5020\n",
            "Epoch 56/150 - 0.53s - loss: 1.0167 - acc: 0.5029 - val_loss: 1.0386 - val_acc: 0.5121\n",
            "Epoch 57/150 - 0.62s - loss: 1.0155 - acc: 0.5031 - val_loss: 1.0378 - val_acc: 0.5101\n",
            "Epoch 58/150 - 0.53s - loss: 1.0144 - acc: 0.4989 - val_loss: 1.0374 - val_acc: 0.5182\n",
            "Epoch 59/150 - 0.54s - loss: 1.0131 - acc: 0.5058 - val_loss: 1.0364 - val_acc: 0.5202\n",
            "Epoch 60/150 - 0.52s - loss: 1.0119 - acc: 0.5063 - val_loss: 1.0354 - val_acc: 0.5081\n",
            "Epoch 61/150 - 0.53s - loss: 1.0107 - acc: 0.5065 - val_loss: 1.0348 - val_acc: 0.5101\n",
            "Epoch 62/150 - 0.53s - loss: 1.0095 - acc: 0.5074 - val_loss: 1.0341 - val_acc: 0.5142\n",
            "Epoch 63/150 - 0.56s - loss: 1.0083 - acc: 0.5072 - val_loss: 1.0332 - val_acc: 0.5121\n",
            "Epoch 64/150 - 0.55s - loss: 1.0073 - acc: 0.5085 - val_loss: 1.0323 - val_acc: 0.5101\n",
            "Epoch 65/150 - 0.55s - loss: 1.0059 - acc: 0.5099 - val_loss: 1.0319 - val_acc: 0.5101\n",
            "Epoch 66/150 - 0.84s - loss: 1.0053 - acc: 0.5079 - val_loss: 1.0312 - val_acc: 0.5162\n",
            "Epoch 67/150 - 0.77s - loss: 1.0036 - acc: 0.5112 - val_loss: 1.0301 - val_acc: 0.5081\n",
            "Epoch 68/150 - 0.68s - loss: 1.0026 - acc: 0.5112 - val_loss: 1.0303 - val_acc: 0.5202\n",
            "Epoch 69/150 - 0.64s - loss: 1.0011 - acc: 0.5133 - val_loss: 1.0286 - val_acc: 0.5182\n",
            "Epoch 70/150 - 0.65s - loss: 0.9999 - acc: 0.5139 - val_loss: 1.0279 - val_acc: 0.5142\n",
            "Epoch 71/150 - 0.72s - loss: 0.9987 - acc: 0.5160 - val_loss: 1.0270 - val_acc: 0.5182\n",
            "Epoch 72/150 - 0.57s - loss: 0.9976 - acc: 0.5164 - val_loss: 1.0260 - val_acc: 0.5243\n",
            "Epoch 73/150 - 0.62s - loss: 0.9966 - acc: 0.5187 - val_loss: 1.0260 - val_acc: 0.5081\n",
            "Epoch 74/150 - 0.56s - loss: 0.9952 - acc: 0.5200 - val_loss: 1.0250 - val_acc: 0.5101\n",
            "Epoch 75/150 - 0.55s - loss: 0.9939 - acc: 0.5187 - val_loss: 1.0237 - val_acc: 0.5283\n",
            "Epoch 76/150 - 0.53s - loss: 0.9929 - acc: 0.5196 - val_loss: 1.0238 - val_acc: 0.5162\n",
            "Epoch 77/150 - 0.55s - loss: 0.9916 - acc: 0.5209 - val_loss: 1.0219 - val_acc: 0.5243\n",
            "Epoch 78/150 - 0.52s - loss: 0.9903 - acc: 0.5241 - val_loss: 1.0213 - val_acc: 0.5283\n",
            "Epoch 79/150 - 0.53s - loss: 0.9891 - acc: 0.5229 - val_loss: 1.0205 - val_acc: 0.5324\n",
            "Epoch 80/150 - 0.57s - loss: 0.9880 - acc: 0.5193 - val_loss: 1.0204 - val_acc: 0.5223\n",
            "Epoch 81/150 - 0.56s - loss: 0.9867 - acc: 0.5245 - val_loss: 1.0190 - val_acc: 0.5283\n",
            "Epoch 82/150 - 0.51s - loss: 0.9855 - acc: 0.5245 - val_loss: 1.0184 - val_acc: 0.5304\n",
            "Epoch 83/150 - 0.53s - loss: 0.9845 - acc: 0.5216 - val_loss: 1.0178 - val_acc: 0.5324\n",
            "Epoch 84/150 - 0.52s - loss: 0.9831 - acc: 0.5272 - val_loss: 1.0174 - val_acc: 0.5223\n",
            "Epoch 85/150 - 0.52s - loss: 0.9822 - acc: 0.5245 - val_loss: 1.0159 - val_acc: 0.5304\n",
            "Epoch 86/150 - 0.54s - loss: 0.9808 - acc: 0.5268 - val_loss: 1.0158 - val_acc: 0.5182\n",
            "Epoch 87/150 - 0.57s - loss: 0.9796 - acc: 0.5274 - val_loss: 1.0148 - val_acc: 0.5304\n",
            "Epoch 88/150 - 0.55s - loss: 0.9792 - acc: 0.5279 - val_loss: 1.0160 - val_acc: 0.5142\n",
            "Epoch 89/150 - 0.56s - loss: 0.9778 - acc: 0.5283 - val_loss: 1.0145 - val_acc: 0.5142\n",
            "Epoch 90/150 - 0.53s - loss: 0.9768 - acc: 0.5283 - val_loss: 1.0141 - val_acc: 0.5142\n",
            "Epoch 91/150 - 0.55s - loss: 0.9748 - acc: 0.5306 - val_loss: 1.0117 - val_acc: 0.5142\n",
            "Epoch 92/150 - 0.55s - loss: 0.9740 - acc: 0.5324 - val_loss: 1.0122 - val_acc: 0.5243\n",
            "Epoch 93/150 - 0.58s - loss: 0.9728 - acc: 0.5331 - val_loss: 1.0109 - val_acc: 0.5142\n",
            "Epoch 94/150 - 0.52s - loss: 0.9716 - acc: 0.5324 - val_loss: 1.0101 - val_acc: 0.5263\n",
            "Epoch 95/150 - 0.54s - loss: 0.9702 - acc: 0.5346 - val_loss: 1.0085 - val_acc: 0.5182\n",
            "Epoch 96/150 - 0.54s - loss: 0.9692 - acc: 0.5331 - val_loss: 1.0080 - val_acc: 0.5283\n",
            "Epoch 97/150 - 0.54s - loss: 0.9688 - acc: 0.5364 - val_loss: 1.0090 - val_acc: 0.5162\n",
            "Epoch 98/150 - 0.54s - loss: 0.9669 - acc: 0.5380 - val_loss: 1.0071 - val_acc: 0.5202\n",
            "Epoch 99/150 - 0.59s - loss: 0.9656 - acc: 0.5396 - val_loss: 1.0057 - val_acc: 0.5223\n",
            "Epoch 100/150 - 0.54s - loss: 0.9658 - acc: 0.5358 - val_loss: 1.0057 - val_acc: 0.5344\n",
            "Epoch 101/150 - 0.53s - loss: 0.9633 - acc: 0.5373 - val_loss: 1.0041 - val_acc: 0.5223\n",
            "Epoch 102/150 - 0.53s - loss: 0.9622 - acc: 0.5385 - val_loss: 1.0035 - val_acc: 0.5223\n",
            "Epoch 103/150 - 0.54s - loss: 0.9611 - acc: 0.5405 - val_loss: 1.0033 - val_acc: 0.5344\n",
            "Epoch 104/150 - 0.53s - loss: 0.9606 - acc: 0.5373 - val_loss: 1.0025 - val_acc: 0.5385\n",
            "Epoch 105/150 - 0.56s - loss: 0.9600 - acc: 0.5367 - val_loss: 1.0023 - val_acc: 0.5364\n",
            "Epoch 106/150 - 0.52s - loss: 0.9580 - acc: 0.5405 - val_loss: 1.0013 - val_acc: 0.5324\n",
            "Epoch 107/150 - 0.55s - loss: 0.9569 - acc: 0.5443 - val_loss: 0.9997 - val_acc: 0.5283\n",
            "Epoch 108/150 - 0.52s - loss: 0.9569 - acc: 0.5409 - val_loss: 1.0012 - val_acc: 0.5263\n",
            "Epoch 109/150 - 0.53s - loss: 0.9546 - acc: 0.5434 - val_loss: 0.9993 - val_acc: 0.5263\n",
            "Epoch 110/150 - 0.51s - loss: 0.9535 - acc: 0.5430 - val_loss: 0.9983 - val_acc: 0.5364\n",
            "Epoch 111/150 - 0.55s - loss: 0.9525 - acc: 0.5427 - val_loss: 0.9977 - val_acc: 0.5385\n",
            "Epoch 112/150 - 0.55s - loss: 0.9514 - acc: 0.5486 - val_loss: 0.9964 - val_acc: 0.5283\n",
            "Epoch 113/150 - 0.55s - loss: 0.9503 - acc: 0.5452 - val_loss: 0.9964 - val_acc: 0.5304\n",
            "Epoch 114/150 - 0.59s - loss: 0.9493 - acc: 0.5479 - val_loss: 0.9961 - val_acc: 0.5304\n",
            "Epoch 115/150 - 0.58s - loss: 0.9492 - acc: 0.5430 - val_loss: 0.9954 - val_acc: 0.5486\n",
            "Epoch 116/150 - 0.59s - loss: 0.9472 - acc: 0.5477 - val_loss: 0.9943 - val_acc: 0.5385\n",
            "Epoch 117/150 - 0.59s - loss: 0.9463 - acc: 0.5470 - val_loss: 0.9938 - val_acc: 0.5405\n",
            "Epoch 118/150 - 0.55s - loss: 0.9451 - acc: 0.5513 - val_loss: 0.9926 - val_acc: 0.5425\n",
            "Epoch 119/150 - 0.55s - loss: 0.9443 - acc: 0.5508 - val_loss: 0.9922 - val_acc: 0.5364\n",
            "Epoch 120/150 - 0.55s - loss: 0.9432 - acc: 0.5497 - val_loss: 0.9919 - val_acc: 0.5405\n",
            "Epoch 121/150 - 0.59s - loss: 0.9422 - acc: 0.5513 - val_loss: 0.9905 - val_acc: 0.5486\n",
            "Epoch 122/150 - 0.56s - loss: 0.9429 - acc: 0.5504 - val_loss: 0.9908 - val_acc: 0.5486\n",
            "Epoch 123/150 - 0.59s - loss: 0.9401 - acc: 0.5515 - val_loss: 0.9896 - val_acc: 0.5466\n",
            "Epoch 124/150 - 0.53s - loss: 0.9391 - acc: 0.5531 - val_loss: 0.9893 - val_acc: 0.5486\n",
            "Epoch 125/150 - 0.58s - loss: 0.9384 - acc: 0.5556 - val_loss: 0.9895 - val_acc: 0.5466\n",
            "Epoch 126/150 - 0.55s - loss: 0.9374 - acc: 0.5542 - val_loss: 0.9876 - val_acc: 0.5526\n",
            "Epoch 127/150 - 0.57s - loss: 0.9363 - acc: 0.5522 - val_loss: 0.9877 - val_acc: 0.5405\n",
            "Epoch 128/150 - 0.57s - loss: 0.9353 - acc: 0.5547 - val_loss: 0.9867 - val_acc: 0.5526\n",
            "Epoch 129/150 - 0.62s - loss: 0.9348 - acc: 0.5524 - val_loss: 0.9869 - val_acc: 0.5405\n",
            "Epoch 130/150 - 0.54s - loss: 0.9337 - acc: 0.5565 - val_loss: 0.9854 - val_acc: 0.5587\n",
            "Epoch 131/150 - 0.55s - loss: 0.9327 - acc: 0.5565 - val_loss: 0.9851 - val_acc: 0.5425\n",
            "Epoch 132/150 - 0.57s - loss: 0.9316 - acc: 0.5594 - val_loss: 0.9841 - val_acc: 0.5587\n",
            "Epoch 133/150 - 0.56s - loss: 0.9306 - acc: 0.5583 - val_loss: 0.9836 - val_acc: 0.5547\n",
            "Epoch 134/150 - 0.57s - loss: 0.9301 - acc: 0.5576 - val_loss: 0.9828 - val_acc: 0.5486\n",
            "Epoch 135/150 - 0.57s - loss: 0.9287 - acc: 0.5607 - val_loss: 0.9828 - val_acc: 0.5486\n",
            "Epoch 136/150 - 0.52s - loss: 0.9278 - acc: 0.5614 - val_loss: 0.9822 - val_acc: 0.5547\n",
            "Epoch 137/150 - 0.54s - loss: 0.9271 - acc: 0.5598 - val_loss: 0.9823 - val_acc: 0.5547\n",
            "Epoch 138/150 - 0.54s - loss: 0.9270 - acc: 0.5598 - val_loss: 0.9816 - val_acc: 0.5587\n",
            "Epoch 139/150 - 0.56s - loss: 0.9254 - acc: 0.5603 - val_loss: 0.9809 - val_acc: 0.5486\n",
            "Epoch 140/150 - 0.62s - loss: 0.9242 - acc: 0.5616 - val_loss: 0.9798 - val_acc: 0.5587\n",
            "Epoch 141/150 - 0.64s - loss: 0.9233 - acc: 0.5621 - val_loss: 0.9798 - val_acc: 0.5526\n",
            "Epoch 142/150 - 0.75s - loss: 0.9227 - acc: 0.5639 - val_loss: 0.9801 - val_acc: 0.5526\n",
            "Epoch 143/150 - 0.62s - loss: 0.9218 - acc: 0.5637 - val_loss: 0.9784 - val_acc: 0.5547\n",
            "Epoch 144/150 - 0.53s - loss: 0.9208 - acc: 0.5632 - val_loss: 0.9777 - val_acc: 0.5587\n",
            "Epoch 145/150 - 0.55s - loss: 0.9269 - acc: 0.5598 - val_loss: 0.9867 - val_acc: 0.5243\n",
            "Epoch 146/150 - 0.56s - loss: 0.9194 - acc: 0.5655 - val_loss: 0.9786 - val_acc: 0.5567\n",
            "Epoch 147/150 - 0.59s - loss: 0.9210 - acc: 0.5646 - val_loss: 0.9790 - val_acc: 0.5628\n",
            "Epoch 148/150 - 0.54s - loss: 0.9173 - acc: 0.5661 - val_loss: 0.9758 - val_acc: 0.5567\n",
            "Epoch 149/150 - 0.55s - loss: 0.9169 - acc: 0.5655 - val_loss: 0.9761 - val_acc: 0.5567\n",
            "Epoch 150/150 - 0.54s - loss: 0.9154 - acc: 0.5684 - val_loss: 0.9752 - val_acc: 0.5587\n",
            "\n",
            "Combination 226/252:\n",
            "Hidden Layers: [512, 256, 128], Activation: relu, Learning Rate: 0.001, Batch Size: 64, Epochs: 50\n",
            "Epoch 1/50 - 0.35s - loss: 1.1126 - acc: 0.3273 - val_loss: 1.1166 - val_acc: 0.3138\n",
            "Epoch 2/50 - 0.35s - loss: 1.1002 - acc: 0.3255 - val_loss: 1.1040 - val_acc: 0.3097\n",
            "Epoch 3/50 - 0.34s - loss: 1.0956 - acc: 0.3484 - val_loss: 1.0992 - val_acc: 0.3502\n",
            "Epoch 4/50 - 0.35s - loss: 1.0931 - acc: 0.3749 - val_loss: 1.0968 - val_acc: 0.3785\n",
            "Epoch 5/50 - 0.33s - loss: 1.0912 - acc: 0.3862 - val_loss: 1.0952 - val_acc: 0.3988\n",
            "Epoch 6/50 - 0.32s - loss: 1.0896 - acc: 0.3938 - val_loss: 1.0938 - val_acc: 0.4049\n",
            "Epoch 7/50 - 0.34s - loss: 1.0881 - acc: 0.3972 - val_loss: 1.0927 - val_acc: 0.4089\n",
            "Epoch 8/50 - 0.32s - loss: 1.0865 - acc: 0.4006 - val_loss: 1.0915 - val_acc: 0.4130\n",
            "Epoch 9/50 - 0.47s - loss: 1.0851 - acc: 0.4069 - val_loss: 1.0904 - val_acc: 0.4231\n",
            "Epoch 10/50 - 0.38s - loss: 1.0838 - acc: 0.4103 - val_loss: 1.0892 - val_acc: 0.4312\n",
            "Epoch 11/50 - 0.38s - loss: 1.0824 - acc: 0.4116 - val_loss: 1.0882 - val_acc: 0.4271\n",
            "Epoch 12/50 - 0.34s - loss: 1.0811 - acc: 0.4168 - val_loss: 1.0870 - val_acc: 0.4291\n",
            "Epoch 13/50 - 0.34s - loss: 1.0798 - acc: 0.4244 - val_loss: 1.0860 - val_acc: 0.4231\n",
            "Epoch 14/50 - 0.34s - loss: 1.0786 - acc: 0.4300 - val_loss: 1.0849 - val_acc: 0.4291\n",
            "Epoch 15/50 - 0.38s - loss: 1.0773 - acc: 0.4354 - val_loss: 1.0839 - val_acc: 0.4312\n",
            "Epoch 16/50 - 0.33s - loss: 1.0762 - acc: 0.4438 - val_loss: 1.0827 - val_acc: 0.4312\n",
            "Epoch 17/50 - 0.33s - loss: 1.0750 - acc: 0.4426 - val_loss: 1.0818 - val_acc: 0.4312\n",
            "Epoch 18/50 - 0.35s - loss: 1.0739 - acc: 0.4465 - val_loss: 1.0809 - val_acc: 0.4352\n",
            "Epoch 19/50 - 0.35s - loss: 1.0728 - acc: 0.4433 - val_loss: 1.0800 - val_acc: 0.4332\n",
            "Epoch 20/50 - 0.35s - loss: 1.0717 - acc: 0.4537 - val_loss: 1.0788 - val_acc: 0.4453\n",
            "Epoch 21/50 - 0.35s - loss: 1.0705 - acc: 0.4534 - val_loss: 1.0780 - val_acc: 0.4372\n",
            "Epoch 22/50 - 0.34s - loss: 1.0695 - acc: 0.4609 - val_loss: 1.0770 - val_acc: 0.4433\n",
            "Epoch 23/50 - 0.34s - loss: 1.0684 - acc: 0.4579 - val_loss: 1.0762 - val_acc: 0.4413\n",
            "Epoch 24/50 - 0.33s - loss: 1.0674 - acc: 0.4606 - val_loss: 1.0753 - val_acc: 0.4413\n",
            "Epoch 25/50 - 0.36s - loss: 1.0663 - acc: 0.4600 - val_loss: 1.0746 - val_acc: 0.4433\n",
            "Epoch 26/50 - 0.34s - loss: 1.0653 - acc: 0.4622 - val_loss: 1.0739 - val_acc: 0.4453\n",
            "Epoch 27/50 - 0.38s - loss: 1.0643 - acc: 0.4638 - val_loss: 1.0732 - val_acc: 0.4413\n",
            "Epoch 28/50 - 0.34s - loss: 1.0634 - acc: 0.4658 - val_loss: 1.0723 - val_acc: 0.4413\n",
            "Epoch 29/50 - 0.37s - loss: 1.0624 - acc: 0.4667 - val_loss: 1.0716 - val_acc: 0.4413\n",
            "Epoch 30/50 - 0.37s - loss: 1.0615 - acc: 0.4645 - val_loss: 1.0710 - val_acc: 0.4372\n",
            "Epoch 31/50 - 0.36s - loss: 1.0606 - acc: 0.4681 - val_loss: 1.0701 - val_acc: 0.4474\n",
            "Epoch 32/50 - 0.33s - loss: 1.0597 - acc: 0.4676 - val_loss: 1.0694 - val_acc: 0.4474\n",
            "Epoch 33/50 - 0.38s - loss: 1.0588 - acc: 0.4658 - val_loss: 1.0686 - val_acc: 0.4494\n",
            "Epoch 34/50 - 0.33s - loss: 1.0579 - acc: 0.4665 - val_loss: 1.0680 - val_acc: 0.4433\n",
            "Epoch 35/50 - 0.34s - loss: 1.0571 - acc: 0.4676 - val_loss: 1.0674 - val_acc: 0.4474\n",
            "Epoch 36/50 - 0.34s - loss: 1.0563 - acc: 0.4699 - val_loss: 1.0668 - val_acc: 0.4413\n",
            "Epoch 37/50 - 0.37s - loss: 1.0554 - acc: 0.4696 - val_loss: 1.0661 - val_acc: 0.4474\n",
            "Epoch 38/50 - 0.34s - loss: 1.0546 - acc: 0.4694 - val_loss: 1.0656 - val_acc: 0.4413\n",
            "Epoch 39/50 - 0.37s - loss: 1.0538 - acc: 0.4714 - val_loss: 1.0649 - val_acc: 0.4534\n",
            "Epoch 40/50 - 0.33s - loss: 1.0530 - acc: 0.4651 - val_loss: 1.0643 - val_acc: 0.4494\n",
            "Epoch 41/50 - 0.34s - loss: 1.0522 - acc: 0.4692 - val_loss: 1.0638 - val_acc: 0.4474\n",
            "Epoch 42/50 - 0.33s - loss: 1.0514 - acc: 0.4669 - val_loss: 1.0630 - val_acc: 0.4534\n",
            "Epoch 43/50 - 0.42s - loss: 1.0506 - acc: 0.4672 - val_loss: 1.0625 - val_acc: 0.4494\n",
            "Epoch 44/50 - 0.35s - loss: 1.0498 - acc: 0.4687 - val_loss: 1.0618 - val_acc: 0.4453\n",
            "Epoch 45/50 - 0.36s - loss: 1.0490 - acc: 0.4717 - val_loss: 1.0611 - val_acc: 0.4494\n",
            "Epoch 46/50 - 0.36s - loss: 1.0482 - acc: 0.4728 - val_loss: 1.0607 - val_acc: 0.4514\n",
            "Epoch 47/50 - 0.46s - loss: 1.0474 - acc: 0.4714 - val_loss: 1.0601 - val_acc: 0.4514\n",
            "Epoch 48/50 - 0.36s - loss: 1.0467 - acc: 0.4708 - val_loss: 1.0595 - val_acc: 0.4453\n",
            "Epoch 49/50 - 0.34s - loss: 1.0459 - acc: 0.4748 - val_loss: 1.0589 - val_acc: 0.4474\n",
            "Epoch 50/50 - 0.33s - loss: 1.0452 - acc: 0.4748 - val_loss: 1.0583 - val_acc: 0.4514\n",
            "\n",
            "Combination 227/252:\n",
            "Hidden Layers: [512, 256, 128], Activation: relu, Learning Rate: 0.001, Batch Size: 64, Epochs: 100\n",
            "Epoch 1/100 - 0.49s - loss: 1.1017 - acc: 0.3435 - val_loss: 1.0965 - val_acc: 0.3623\n",
            "Epoch 2/100 - 0.33s - loss: 1.0987 - acc: 0.3522 - val_loss: 1.0939 - val_acc: 0.3785\n",
            "Epoch 3/100 - 0.34s - loss: 1.0964 - acc: 0.3596 - val_loss: 1.0922 - val_acc: 0.3846\n",
            "Epoch 4/100 - 0.33s - loss: 1.0943 - acc: 0.3689 - val_loss: 1.0906 - val_acc: 0.3806\n",
            "Epoch 5/100 - 0.36s - loss: 1.0923 - acc: 0.3776 - val_loss: 1.0891 - val_acc: 0.3887\n",
            "Epoch 6/100 - 0.36s - loss: 1.0904 - acc: 0.3884 - val_loss: 1.0876 - val_acc: 0.3887\n",
            "Epoch 7/100 - 0.36s - loss: 1.0885 - acc: 0.3950 - val_loss: 1.0862 - val_acc: 0.3988\n",
            "Epoch 8/100 - 0.32s - loss: 1.0867 - acc: 0.4004 - val_loss: 1.0850 - val_acc: 0.3968\n",
            "Epoch 9/100 - 0.33s - loss: 1.0851 - acc: 0.4058 - val_loss: 1.0838 - val_acc: 0.4008\n",
            "Epoch 10/100 - 0.31s - loss: 1.0835 - acc: 0.4148 - val_loss: 1.0826 - val_acc: 0.4028\n",
            "Epoch 11/100 - 0.33s - loss: 1.0820 - acc: 0.4179 - val_loss: 1.0816 - val_acc: 0.4150\n",
            "Epoch 12/100 - 0.32s - loss: 1.0806 - acc: 0.4256 - val_loss: 1.0806 - val_acc: 0.4190\n",
            "Epoch 13/100 - 0.34s - loss: 1.0793 - acc: 0.4287 - val_loss: 1.0797 - val_acc: 0.4251\n",
            "Epoch 14/100 - 0.32s - loss: 1.0779 - acc: 0.4334 - val_loss: 1.0788 - val_acc: 0.4251\n",
            "Epoch 15/100 - 0.34s - loss: 1.0766 - acc: 0.4352 - val_loss: 1.0780 - val_acc: 0.4271\n",
            "Epoch 16/100 - 0.33s - loss: 1.0753 - acc: 0.4363 - val_loss: 1.0770 - val_acc: 0.4291\n",
            "Epoch 17/100 - 0.34s - loss: 1.0741 - acc: 0.4377 - val_loss: 1.0762 - val_acc: 0.4312\n",
            "Epoch 18/100 - 0.33s - loss: 1.0729 - acc: 0.4411 - val_loss: 1.0754 - val_acc: 0.4291\n",
            "Epoch 19/100 - 0.34s - loss: 1.0717 - acc: 0.4408 - val_loss: 1.0747 - val_acc: 0.4393\n",
            "Epoch 20/100 - 0.36s - loss: 1.0706 - acc: 0.4435 - val_loss: 1.0740 - val_acc: 0.4393\n",
            "Epoch 21/100 - 0.35s - loss: 1.0695 - acc: 0.4478 - val_loss: 1.0732 - val_acc: 0.4332\n",
            "Epoch 22/100 - 0.35s - loss: 1.0684 - acc: 0.4489 - val_loss: 1.0725 - val_acc: 0.4393\n",
            "Epoch 23/100 - 0.35s - loss: 1.0673 - acc: 0.4489 - val_loss: 1.0720 - val_acc: 0.4352\n",
            "Epoch 24/100 - 0.34s - loss: 1.0663 - acc: 0.4514 - val_loss: 1.0713 - val_acc: 0.4433\n",
            "Epoch 25/100 - 0.36s - loss: 1.0653 - acc: 0.4530 - val_loss: 1.0707 - val_acc: 0.4332\n",
            "Epoch 26/100 - 0.33s - loss: 1.0643 - acc: 0.4541 - val_loss: 1.0700 - val_acc: 0.4393\n",
            "Epoch 27/100 - 0.35s - loss: 1.0633 - acc: 0.4564 - val_loss: 1.0694 - val_acc: 0.4474\n",
            "Epoch 28/100 - 0.32s - loss: 1.0624 - acc: 0.4586 - val_loss: 1.0688 - val_acc: 0.4393\n",
            "Epoch 29/100 - 0.34s - loss: 1.0614 - acc: 0.4609 - val_loss: 1.0683 - val_acc: 0.4494\n",
            "Epoch 30/100 - 0.33s - loss: 1.0605 - acc: 0.4613 - val_loss: 1.0677 - val_acc: 0.4494\n",
            "Epoch 31/100 - 0.34s - loss: 1.0596 - acc: 0.4613 - val_loss: 1.0673 - val_acc: 0.4514\n",
            "Epoch 32/100 - 0.33s - loss: 1.0587 - acc: 0.4631 - val_loss: 1.0666 - val_acc: 0.4474\n",
            "Epoch 33/100 - 0.37s - loss: 1.0578 - acc: 0.4645 - val_loss: 1.0659 - val_acc: 0.4433\n",
            "Epoch 34/100 - 0.39s - loss: 1.0569 - acc: 0.4638 - val_loss: 1.0655 - val_acc: 0.4433\n",
            "Epoch 35/100 - 0.34s - loss: 1.0561 - acc: 0.4627 - val_loss: 1.0649 - val_acc: 0.4453\n",
            "Epoch 36/100 - 0.33s - loss: 1.0553 - acc: 0.4651 - val_loss: 1.0645 - val_acc: 0.4453\n",
            "Epoch 37/100 - 0.34s - loss: 1.0545 - acc: 0.4663 - val_loss: 1.0641 - val_acc: 0.4474\n",
            "Epoch 38/100 - 0.33s - loss: 1.0537 - acc: 0.4660 - val_loss: 1.0635 - val_acc: 0.4474\n",
            "Epoch 39/100 - 0.33s - loss: 1.0529 - acc: 0.4690 - val_loss: 1.0630 - val_acc: 0.4494\n",
            "Epoch 40/100 - 0.33s - loss: 1.0521 - acc: 0.4687 - val_loss: 1.0625 - val_acc: 0.4494\n",
            "Epoch 41/100 - 0.33s - loss: 1.0513 - acc: 0.4685 - val_loss: 1.0622 - val_acc: 0.4514\n",
            "Epoch 42/100 - 0.35s - loss: 1.0506 - acc: 0.4701 - val_loss: 1.0617 - val_acc: 0.4494\n",
            "Epoch 43/100 - 0.37s - loss: 1.0498 - acc: 0.4701 - val_loss: 1.0612 - val_acc: 0.4575\n",
            "Epoch 44/100 - 0.33s - loss: 1.0491 - acc: 0.4708 - val_loss: 1.0609 - val_acc: 0.4555\n",
            "Epoch 45/100 - 0.40s - loss: 1.0483 - acc: 0.4728 - val_loss: 1.0605 - val_acc: 0.4514\n",
            "Epoch 46/100 - 0.33s - loss: 1.0476 - acc: 0.4748 - val_loss: 1.0602 - val_acc: 0.4494\n",
            "Epoch 47/100 - 0.33s - loss: 1.0469 - acc: 0.4771 - val_loss: 1.0598 - val_acc: 0.4494\n",
            "Epoch 48/100 - 0.33s - loss: 1.0462 - acc: 0.4768 - val_loss: 1.0596 - val_acc: 0.4494\n",
            "Epoch 49/100 - 0.34s - loss: 1.0455 - acc: 0.4775 - val_loss: 1.0590 - val_acc: 0.4555\n",
            "Epoch 50/100 - 0.36s - loss: 1.0447 - acc: 0.4775 - val_loss: 1.0585 - val_acc: 0.4575\n",
            "Epoch 51/100 - 0.43s - loss: 1.0440 - acc: 0.4759 - val_loss: 1.0582 - val_acc: 0.4575\n",
            "Epoch 52/100 - 0.33s - loss: 1.0433 - acc: 0.4744 - val_loss: 1.0576 - val_acc: 0.4555\n",
            "Epoch 53/100 - 0.33s - loss: 1.0426 - acc: 0.4793 - val_loss: 1.0571 - val_acc: 0.4636\n",
            "Epoch 54/100 - 0.32s - loss: 1.0419 - acc: 0.4764 - val_loss: 1.0569 - val_acc: 0.4615\n",
            "Epoch 55/100 - 0.34s - loss: 1.0412 - acc: 0.4766 - val_loss: 1.0564 - val_acc: 0.4575\n",
            "Epoch 56/100 - 0.31s - loss: 1.0406 - acc: 0.4768 - val_loss: 1.0561 - val_acc: 0.4555\n",
            "Epoch 57/100 - 0.33s - loss: 1.0399 - acc: 0.4800 - val_loss: 1.0556 - val_acc: 0.4615\n",
            "Epoch 58/100 - 0.33s - loss: 1.0392 - acc: 0.4789 - val_loss: 1.0553 - val_acc: 0.4595\n",
            "Epoch 59/100 - 0.33s - loss: 1.0386 - acc: 0.4804 - val_loss: 1.0549 - val_acc: 0.4615\n",
            "Epoch 60/100 - 0.32s - loss: 1.0379 - acc: 0.4813 - val_loss: 1.0545 - val_acc: 0.4595\n",
            "Epoch 61/100 - 0.34s - loss: 1.0373 - acc: 0.4800 - val_loss: 1.0541 - val_acc: 0.4615\n",
            "Epoch 62/100 - 0.34s - loss: 1.0366 - acc: 0.4836 - val_loss: 1.0537 - val_acc: 0.4615\n",
            "Epoch 63/100 - 0.33s - loss: 1.0360 - acc: 0.4802 - val_loss: 1.0535 - val_acc: 0.4575\n",
            "Epoch 64/100 - 0.33s - loss: 1.0353 - acc: 0.4827 - val_loss: 1.0531 - val_acc: 0.4555\n",
            "Epoch 65/100 - 0.34s - loss: 1.0347 - acc: 0.4829 - val_loss: 1.0527 - val_acc: 0.4615\n",
            "Epoch 66/100 - 0.33s - loss: 1.0341 - acc: 0.4845 - val_loss: 1.0525 - val_acc: 0.4595\n",
            "Epoch 67/100 - 0.34s - loss: 1.0335 - acc: 0.4867 - val_loss: 1.0521 - val_acc: 0.4636\n",
            "Epoch 68/100 - 0.37s - loss: 1.0328 - acc: 0.4840 - val_loss: 1.0515 - val_acc: 0.4615\n",
            "Epoch 69/100 - 0.34s - loss: 1.0322 - acc: 0.4813 - val_loss: 1.0513 - val_acc: 0.4696\n",
            "Epoch 70/100 - 0.32s - loss: 1.0315 - acc: 0.4838 - val_loss: 1.0512 - val_acc: 0.4615\n",
            "Epoch 71/100 - 0.32s - loss: 1.0309 - acc: 0.4840 - val_loss: 1.0507 - val_acc: 0.4595\n",
            "Epoch 72/100 - 0.31s - loss: 1.0303 - acc: 0.4863 - val_loss: 1.0505 - val_acc: 0.4636\n",
            "Epoch 73/100 - 0.32s - loss: 1.0297 - acc: 0.4849 - val_loss: 1.0499 - val_acc: 0.4656\n",
            "Epoch 74/100 - 0.33s - loss: 1.0291 - acc: 0.4856 - val_loss: 1.0497 - val_acc: 0.4656\n",
            "Epoch 75/100 - 0.33s - loss: 1.0285 - acc: 0.4861 - val_loss: 1.0492 - val_acc: 0.4737\n",
            "Epoch 76/100 - 0.32s - loss: 1.0279 - acc: 0.4879 - val_loss: 1.0492 - val_acc: 0.4636\n",
            "Epoch 77/100 - 0.33s - loss: 1.0273 - acc: 0.4908 - val_loss: 1.0491 - val_acc: 0.4575\n",
            "Epoch 78/100 - 0.32s - loss: 1.0266 - acc: 0.4870 - val_loss: 1.0485 - val_acc: 0.4656\n",
            "Epoch 79/100 - 0.36s - loss: 1.0260 - acc: 0.4874 - val_loss: 1.0481 - val_acc: 0.4696\n",
            "Epoch 80/100 - 0.32s - loss: 1.0255 - acc: 0.4876 - val_loss: 1.0476 - val_acc: 0.4737\n",
            "Epoch 81/100 - 0.33s - loss: 1.0248 - acc: 0.4867 - val_loss: 1.0472 - val_acc: 0.4717\n",
            "Epoch 82/100 - 0.31s - loss: 1.0242 - acc: 0.4919 - val_loss: 1.0472 - val_acc: 0.4656\n",
            "Epoch 83/100 - 0.32s - loss: 1.0236 - acc: 0.4903 - val_loss: 1.0466 - val_acc: 0.4737\n",
            "Epoch 84/100 - 0.35s - loss: 1.0230 - acc: 0.4915 - val_loss: 1.0463 - val_acc: 0.4717\n",
            "Epoch 85/100 - 0.34s - loss: 1.0224 - acc: 0.4912 - val_loss: 1.0460 - val_acc: 0.4717\n",
            "Epoch 86/100 - 0.30s - loss: 1.0218 - acc: 0.4926 - val_loss: 1.0458 - val_acc: 0.4717\n",
            "Epoch 87/100 - 0.35s - loss: 1.0213 - acc: 0.4928 - val_loss: 1.0455 - val_acc: 0.4717\n",
            "Epoch 88/100 - 0.32s - loss: 1.0207 - acc: 0.4944 - val_loss: 1.0450 - val_acc: 0.4757\n",
            "Epoch 89/100 - 0.35s - loss: 1.0201 - acc: 0.4944 - val_loss: 1.0449 - val_acc: 0.4757\n",
            "Epoch 90/100 - 0.31s - loss: 1.0195 - acc: 0.4939 - val_loss: 1.0445 - val_acc: 0.4615\n",
            "Epoch 91/100 - 0.34s - loss: 1.0190 - acc: 0.4930 - val_loss: 1.0439 - val_acc: 0.4777\n",
            "Epoch 92/100 - 0.31s - loss: 1.0184 - acc: 0.4926 - val_loss: 1.0437 - val_acc: 0.4737\n",
            "Epoch 93/100 - 0.31s - loss: 1.0177 - acc: 0.4948 - val_loss: 1.0433 - val_acc: 0.4798\n",
            "Epoch 94/100 - 0.31s - loss: 1.0171 - acc: 0.4953 - val_loss: 1.0432 - val_acc: 0.4676\n",
            "Epoch 95/100 - 0.32s - loss: 1.0165 - acc: 0.4951 - val_loss: 1.0426 - val_acc: 0.4777\n",
            "Epoch 96/100 - 0.32s - loss: 1.0159 - acc: 0.4948 - val_loss: 1.0424 - val_acc: 0.4757\n",
            "Epoch 97/100 - 0.33s - loss: 1.0155 - acc: 0.4973 - val_loss: 1.0423 - val_acc: 0.4696\n",
            "Epoch 98/100 - 0.30s - loss: 1.0148 - acc: 0.4960 - val_loss: 1.0416 - val_acc: 0.4798\n",
            "Epoch 99/100 - 0.32s - loss: 1.0143 - acc: 0.4966 - val_loss: 1.0412 - val_acc: 0.4838\n",
            "Epoch 100/100 - 0.33s - loss: 1.0137 - acc: 0.4980 - val_loss: 1.0411 - val_acc: 0.4757\n",
            "\n",
            "Combination 228/252:\n",
            "Hidden Layers: [512, 256, 128], Activation: relu, Learning Rate: 0.001, Batch Size: 64, Epochs: 150\n",
            "Epoch 1/150 - 0.31s - loss: 1.1015 - acc: 0.3356 - val_loss: 1.1058 - val_acc: 0.2874\n",
            "Epoch 2/150 - 0.32s - loss: 1.0978 - acc: 0.3378 - val_loss: 1.1023 - val_acc: 0.2935\n",
            "Epoch 3/150 - 0.34s - loss: 1.0957 - acc: 0.3401 - val_loss: 1.1004 - val_acc: 0.3097\n",
            "Epoch 4/150 - 0.32s - loss: 1.0939 - acc: 0.3484 - val_loss: 1.0989 - val_acc: 0.3178\n",
            "Epoch 5/150 - 0.32s - loss: 1.0922 - acc: 0.3576 - val_loss: 1.0975 - val_acc: 0.3381\n",
            "Epoch 6/150 - 0.30s - loss: 1.0907 - acc: 0.3662 - val_loss: 1.0963 - val_acc: 0.3421\n",
            "Epoch 7/150 - 0.32s - loss: 1.0892 - acc: 0.3700 - val_loss: 1.0950 - val_acc: 0.3482\n",
            "Epoch 8/150 - 0.33s - loss: 1.0877 - acc: 0.3749 - val_loss: 1.0939 - val_acc: 0.3502\n",
            "Epoch 9/150 - 0.34s - loss: 1.0863 - acc: 0.3844 - val_loss: 1.0928 - val_acc: 0.3623\n",
            "Epoch 10/150 - 0.34s - loss: 1.0849 - acc: 0.3882 - val_loss: 1.0918 - val_acc: 0.3684\n",
            "Epoch 11/150 - 0.33s - loss: 1.0836 - acc: 0.3947 - val_loss: 1.0908 - val_acc: 0.3745\n",
            "Epoch 12/150 - 0.32s - loss: 1.0824 - acc: 0.4010 - val_loss: 1.0898 - val_acc: 0.3745\n",
            "Epoch 13/150 - 0.48s - loss: 1.0811 - acc: 0.4058 - val_loss: 1.0889 - val_acc: 0.3765\n",
            "Epoch 14/150 - 0.41s - loss: 1.0799 - acc: 0.4132 - val_loss: 1.0879 - val_acc: 0.3826\n",
            "Epoch 15/150 - 0.48s - loss: 1.0788 - acc: 0.4188 - val_loss: 1.0870 - val_acc: 0.3846\n",
            "Epoch 16/150 - 0.36s - loss: 1.0776 - acc: 0.4206 - val_loss: 1.0861 - val_acc: 0.3866\n",
            "Epoch 17/150 - 0.36s - loss: 1.0765 - acc: 0.4208 - val_loss: 1.0852 - val_acc: 0.3947\n",
            "Epoch 18/150 - 0.33s - loss: 1.0754 - acc: 0.4244 - val_loss: 1.0844 - val_acc: 0.3907\n",
            "Epoch 19/150 - 0.35s - loss: 1.0744 - acc: 0.4289 - val_loss: 1.0836 - val_acc: 0.3927\n",
            "Epoch 20/150 - 0.33s - loss: 1.0733 - acc: 0.4348 - val_loss: 1.0827 - val_acc: 0.3968\n",
            "Epoch 21/150 - 0.37s - loss: 1.0723 - acc: 0.4359 - val_loss: 1.0819 - val_acc: 0.3968\n",
            "Epoch 22/150 - 0.34s - loss: 1.0713 - acc: 0.4384 - val_loss: 1.0811 - val_acc: 0.3988\n",
            "Epoch 23/150 - 0.34s - loss: 1.0704 - acc: 0.4390 - val_loss: 1.0804 - val_acc: 0.3988\n",
            "Epoch 24/150 - 0.37s - loss: 1.0694 - acc: 0.4404 - val_loss: 1.0797 - val_acc: 0.4049\n",
            "Epoch 25/150 - 0.33s - loss: 1.0685 - acc: 0.4426 - val_loss: 1.0789 - val_acc: 0.4170\n",
            "Epoch 26/150 - 0.41s - loss: 1.0675 - acc: 0.4424 - val_loss: 1.0782 - val_acc: 0.4170\n",
            "Epoch 27/150 - 0.53s - loss: 1.0667 - acc: 0.4440 - val_loss: 1.0776 - val_acc: 0.4150\n",
            "Epoch 28/150 - 0.40s - loss: 1.0658 - acc: 0.4494 - val_loss: 1.0769 - val_acc: 0.4211\n",
            "Epoch 29/150 - 0.34s - loss: 1.0649 - acc: 0.4514 - val_loss: 1.0762 - val_acc: 0.4211\n",
            "Epoch 30/150 - 0.35s - loss: 1.0641 - acc: 0.4492 - val_loss: 1.0757 - val_acc: 0.4170\n",
            "Epoch 31/150 - 0.35s - loss: 1.0632 - acc: 0.4555 - val_loss: 1.0749 - val_acc: 0.4231\n",
            "Epoch 32/150 - 0.33s - loss: 1.0624 - acc: 0.4586 - val_loss: 1.0743 - val_acc: 0.4190\n",
            "Epoch 33/150 - 0.35s - loss: 1.0616 - acc: 0.4579 - val_loss: 1.0737 - val_acc: 0.4211\n",
            "Epoch 34/150 - 0.31s - loss: 1.0608 - acc: 0.4609 - val_loss: 1.0732 - val_acc: 0.4211\n",
            "Epoch 35/150 - 0.34s - loss: 1.0600 - acc: 0.4615 - val_loss: 1.0725 - val_acc: 0.4271\n",
            "Epoch 36/150 - 0.33s - loss: 1.0592 - acc: 0.4631 - val_loss: 1.0719 - val_acc: 0.4291\n",
            "Epoch 37/150 - 0.33s - loss: 1.0584 - acc: 0.4636 - val_loss: 1.0714 - val_acc: 0.4291\n",
            "Epoch 38/150 - 0.33s - loss: 1.0576 - acc: 0.4645 - val_loss: 1.0708 - val_acc: 0.4393\n",
            "Epoch 39/150 - 0.34s - loss: 1.0569 - acc: 0.4692 - val_loss: 1.0701 - val_acc: 0.4372\n",
            "Epoch 40/150 - 0.32s - loss: 1.0561 - acc: 0.4660 - val_loss: 1.0697 - val_acc: 0.4332\n",
            "Epoch 41/150 - 0.34s - loss: 1.0554 - acc: 0.4685 - val_loss: 1.0692 - val_acc: 0.4332\n",
            "Epoch 42/150 - 0.31s - loss: 1.0546 - acc: 0.4696 - val_loss: 1.0686 - val_acc: 0.4413\n",
            "Epoch 43/150 - 0.31s - loss: 1.0539 - acc: 0.4719 - val_loss: 1.0679 - val_acc: 0.4393\n",
            "Epoch 44/150 - 0.32s - loss: 1.0531 - acc: 0.4714 - val_loss: 1.0674 - val_acc: 0.4413\n",
            "Epoch 45/150 - 0.36s - loss: 1.0524 - acc: 0.4726 - val_loss: 1.0669 - val_acc: 0.4372\n",
            "Epoch 46/150 - 0.34s - loss: 1.0516 - acc: 0.4719 - val_loss: 1.0663 - val_acc: 0.4372\n",
            "Epoch 47/150 - 0.33s - loss: 1.0509 - acc: 0.4728 - val_loss: 1.0659 - val_acc: 0.4413\n",
            "Epoch 48/150 - 0.32s - loss: 1.0502 - acc: 0.4744 - val_loss: 1.0653 - val_acc: 0.4393\n",
            "Epoch 49/150 - 0.32s - loss: 1.0495 - acc: 0.4764 - val_loss: 1.0648 - val_acc: 0.4413\n",
            "Epoch 50/150 - 0.38s - loss: 1.0488 - acc: 0.4791 - val_loss: 1.0643 - val_acc: 0.4433\n",
            "Epoch 51/150 - 0.36s - loss: 1.0480 - acc: 0.4777 - val_loss: 1.0637 - val_acc: 0.4433\n",
            "Epoch 52/150 - 0.31s - loss: 1.0473 - acc: 0.4762 - val_loss: 1.0631 - val_acc: 0.4453\n",
            "Epoch 53/150 - 0.32s - loss: 1.0466 - acc: 0.4784 - val_loss: 1.0628 - val_acc: 0.4413\n",
            "Epoch 54/150 - 0.38s - loss: 1.0459 - acc: 0.4755 - val_loss: 1.0623 - val_acc: 0.4474\n",
            "Epoch 55/150 - 0.33s - loss: 1.0452 - acc: 0.4802 - val_loss: 1.0618 - val_acc: 0.4413\n",
            "Epoch 56/150 - 0.32s - loss: 1.0445 - acc: 0.4791 - val_loss: 1.0614 - val_acc: 0.4433\n",
            "Epoch 57/150 - 0.31s - loss: 1.0438 - acc: 0.4782 - val_loss: 1.0608 - val_acc: 0.4372\n",
            "Epoch 58/150 - 0.36s - loss: 1.0431 - acc: 0.4816 - val_loss: 1.0603 - val_acc: 0.4433\n",
            "Epoch 59/150 - 0.37s - loss: 1.0425 - acc: 0.4825 - val_loss: 1.0598 - val_acc: 0.4413\n",
            "Epoch 60/150 - 0.32s - loss: 1.0418 - acc: 0.4825 - val_loss: 1.0594 - val_acc: 0.4413\n",
            "Epoch 61/150 - 0.31s - loss: 1.0411 - acc: 0.4820 - val_loss: 1.0586 - val_acc: 0.4514\n",
            "Epoch 62/150 - 0.31s - loss: 1.0404 - acc: 0.4825 - val_loss: 1.0583 - val_acc: 0.4433\n",
            "Epoch 63/150 - 0.37s - loss: 1.0397 - acc: 0.4822 - val_loss: 1.0576 - val_acc: 0.4555\n",
            "Epoch 64/150 - 0.31s - loss: 1.0390 - acc: 0.4813 - val_loss: 1.0572 - val_acc: 0.4494\n",
            "Epoch 65/150 - 0.32s - loss: 1.0383 - acc: 0.4829 - val_loss: 1.0568 - val_acc: 0.4453\n",
            "Epoch 66/150 - 0.32s - loss: 1.0377 - acc: 0.4831 - val_loss: 1.0563 - val_acc: 0.4474\n",
            "Epoch 67/150 - 0.34s - loss: 1.0370 - acc: 0.4827 - val_loss: 1.0559 - val_acc: 0.4453\n",
            "Epoch 68/150 - 0.34s - loss: 1.0363 - acc: 0.4820 - val_loss: 1.0552 - val_acc: 0.4494\n",
            "Epoch 69/150 - 0.36s - loss: 1.0356 - acc: 0.4825 - val_loss: 1.0548 - val_acc: 0.4575\n",
            "Epoch 70/150 - 0.32s - loss: 1.0350 - acc: 0.4852 - val_loss: 1.0546 - val_acc: 0.4534\n",
            "Epoch 71/150 - 0.35s - loss: 1.0343 - acc: 0.4863 - val_loss: 1.0537 - val_acc: 0.4514\n",
            "Epoch 72/150 - 0.36s - loss: 1.0336 - acc: 0.4852 - val_loss: 1.0534 - val_acc: 0.4575\n",
            "Epoch 73/150 - 0.36s - loss: 1.0329 - acc: 0.4854 - val_loss: 1.0529 - val_acc: 0.4575\n",
            "Epoch 74/150 - 0.37s - loss: 1.0323 - acc: 0.4858 - val_loss: 1.0526 - val_acc: 0.4494\n",
            "Epoch 75/150 - 0.38s - loss: 1.0316 - acc: 0.4883 - val_loss: 1.0521 - val_acc: 0.4514\n",
            "Epoch 76/150 - 0.33s - loss: 1.0310 - acc: 0.4879 - val_loss: 1.0515 - val_acc: 0.4514\n",
            "Epoch 77/150 - 0.34s - loss: 1.0303 - acc: 0.4863 - val_loss: 1.0509 - val_acc: 0.4534\n",
            "Epoch 78/150 - 0.32s - loss: 1.0297 - acc: 0.4892 - val_loss: 1.0506 - val_acc: 0.4494\n",
            "Epoch 79/150 - 0.32s - loss: 1.0290 - acc: 0.4883 - val_loss: 1.0499 - val_acc: 0.4514\n",
            "Epoch 80/150 - 0.31s - loss: 1.0283 - acc: 0.4912 - val_loss: 1.0496 - val_acc: 0.4494\n",
            "Epoch 81/150 - 0.35s - loss: 1.0277 - acc: 0.4888 - val_loss: 1.0489 - val_acc: 0.4555\n",
            "Epoch 82/150 - 0.35s - loss: 1.0271 - acc: 0.4894 - val_loss: 1.0485 - val_acc: 0.4555\n",
            "Epoch 83/150 - 0.36s - loss: 1.0265 - acc: 0.4901 - val_loss: 1.0484 - val_acc: 0.4494\n",
            "Epoch 84/150 - 0.35s - loss: 1.0257 - acc: 0.4924 - val_loss: 1.0476 - val_acc: 0.4474\n",
            "Epoch 85/150 - 0.33s - loss: 1.0250 - acc: 0.4917 - val_loss: 1.0470 - val_acc: 0.4534\n",
            "Epoch 86/150 - 0.32s - loss: 1.0244 - acc: 0.4912 - val_loss: 1.0466 - val_acc: 0.4575\n",
            "Epoch 87/150 - 0.32s - loss: 1.0237 - acc: 0.4926 - val_loss: 1.0461 - val_acc: 0.4534\n",
            "Epoch 88/150 - 0.35s - loss: 1.0231 - acc: 0.4946 - val_loss: 1.0456 - val_acc: 0.4514\n",
            "Epoch 89/150 - 0.32s - loss: 1.0225 - acc: 0.4946 - val_loss: 1.0455 - val_acc: 0.4514\n",
            "Epoch 90/150 - 0.33s - loss: 1.0218 - acc: 0.4933 - val_loss: 1.0448 - val_acc: 0.4575\n",
            "Epoch 91/150 - 0.35s - loss: 1.0211 - acc: 0.4928 - val_loss: 1.0440 - val_acc: 0.4615\n",
            "Epoch 92/150 - 0.35s - loss: 1.0204 - acc: 0.4937 - val_loss: 1.0436 - val_acc: 0.4615\n",
            "Epoch 93/150 - 0.35s - loss: 1.0198 - acc: 0.4948 - val_loss: 1.0430 - val_acc: 0.4615\n",
            "Epoch 94/150 - 0.36s - loss: 1.0191 - acc: 0.4969 - val_loss: 1.0427 - val_acc: 0.4595\n",
            "Epoch 95/150 - 0.37s - loss: 1.0185 - acc: 0.4951 - val_loss: 1.0420 - val_acc: 0.4615\n",
            "Epoch 96/150 - 0.33s - loss: 1.0178 - acc: 0.4973 - val_loss: 1.0417 - val_acc: 0.4636\n",
            "Epoch 97/150 - 0.35s - loss: 1.0172 - acc: 0.4975 - val_loss: 1.0411 - val_acc: 0.4636\n",
            "Epoch 98/150 - 0.32s - loss: 1.0166 - acc: 0.4980 - val_loss: 1.0408 - val_acc: 0.4555\n",
            "Epoch 99/150 - 0.36s - loss: 1.0159 - acc: 0.5011 - val_loss: 1.0401 - val_acc: 0.4636\n",
            "Epoch 100/150 - 0.35s - loss: 1.0152 - acc: 0.4998 - val_loss: 1.0397 - val_acc: 0.4615\n",
            "Epoch 101/150 - 0.34s - loss: 1.0146 - acc: 0.5016 - val_loss: 1.0393 - val_acc: 0.4575\n",
            "Epoch 102/150 - 0.32s - loss: 1.0139 - acc: 0.5004 - val_loss: 1.0384 - val_acc: 0.4676\n",
            "Epoch 103/150 - 0.35s - loss: 1.0133 - acc: 0.5013 - val_loss: 1.0384 - val_acc: 0.4555\n",
            "Epoch 104/150 - 0.35s - loss: 1.0126 - acc: 0.5040 - val_loss: 1.0378 - val_acc: 0.4575\n",
            "Epoch 105/150 - 0.34s - loss: 1.0120 - acc: 0.5040 - val_loss: 1.0373 - val_acc: 0.4575\n",
            "Epoch 106/150 - 0.37s - loss: 1.0113 - acc: 0.5036 - val_loss: 1.0366 - val_acc: 0.4656\n",
            "Epoch 107/150 - 0.34s - loss: 1.0107 - acc: 0.5029 - val_loss: 1.0360 - val_acc: 0.4676\n",
            "Epoch 108/150 - 0.33s - loss: 1.0101 - acc: 0.5027 - val_loss: 1.0355 - val_acc: 0.4696\n",
            "Epoch 109/150 - 0.35s - loss: 1.0094 - acc: 0.5056 - val_loss: 1.0353 - val_acc: 0.4595\n",
            "Epoch 110/150 - 0.31s - loss: 1.0087 - acc: 0.5063 - val_loss: 1.0345 - val_acc: 0.4615\n",
            "Epoch 111/150 - 0.33s - loss: 1.0081 - acc: 0.5056 - val_loss: 1.0339 - val_acc: 0.4757\n",
            "Epoch 112/150 - 0.31s - loss: 1.0074 - acc: 0.5061 - val_loss: 1.0337 - val_acc: 0.4595\n",
            "Epoch 113/150 - 0.33s - loss: 1.0068 - acc: 0.5065 - val_loss: 1.0332 - val_acc: 0.4595\n",
            "Epoch 114/150 - 0.31s - loss: 1.0061 - acc: 0.5094 - val_loss: 1.0324 - val_acc: 0.4636\n",
            "Epoch 115/150 - 0.32s - loss: 1.0055 - acc: 0.5076 - val_loss: 1.0323 - val_acc: 0.4636\n",
            "Epoch 116/150 - 0.32s - loss: 1.0048 - acc: 0.5094 - val_loss: 1.0316 - val_acc: 0.4636\n",
            "Epoch 117/150 - 0.33s - loss: 1.0042 - acc: 0.5090 - val_loss: 1.0312 - val_acc: 0.4615\n",
            "Epoch 118/150 - 0.47s - loss: 1.0035 - acc: 0.5099 - val_loss: 1.0305 - val_acc: 0.4636\n",
            "Epoch 119/150 - 0.33s - loss: 1.0029 - acc: 0.5106 - val_loss: 1.0299 - val_acc: 0.4676\n",
            "Epoch 120/150 - 0.32s - loss: 1.0022 - acc: 0.5090 - val_loss: 1.0296 - val_acc: 0.4636\n",
            "Epoch 121/150 - 0.34s - loss: 1.0016 - acc: 0.5097 - val_loss: 1.0291 - val_acc: 0.4636\n",
            "Epoch 122/150 - 0.33s - loss: 1.0010 - acc: 0.5092 - val_loss: 1.0287 - val_acc: 0.4636\n",
            "Epoch 123/150 - 0.34s - loss: 1.0005 - acc: 0.5101 - val_loss: 1.0284 - val_acc: 0.4636\n",
            "Epoch 124/150 - 0.30s - loss: 0.9997 - acc: 0.5108 - val_loss: 1.0275 - val_acc: 0.4656\n",
            "Epoch 125/150 - 0.32s - loss: 0.9991 - acc: 0.5106 - val_loss: 1.0272 - val_acc: 0.4636\n",
            "Epoch 126/150 - 0.30s - loss: 0.9984 - acc: 0.5115 - val_loss: 1.0264 - val_acc: 0.4717\n",
            "Epoch 127/150 - 0.34s - loss: 0.9978 - acc: 0.5112 - val_loss: 1.0260 - val_acc: 0.4696\n",
            "Epoch 128/150 - 0.32s - loss: 0.9973 - acc: 0.5110 - val_loss: 1.0259 - val_acc: 0.4636\n",
            "Epoch 129/150 - 0.33s - loss: 0.9966 - acc: 0.5099 - val_loss: 1.0255 - val_acc: 0.4696\n",
            "Epoch 130/150 - 0.34s - loss: 0.9959 - acc: 0.5119 - val_loss: 1.0247 - val_acc: 0.4696\n",
            "Epoch 131/150 - 0.44s - loss: 0.9954 - acc: 0.5121 - val_loss: 1.0243 - val_acc: 0.4696\n",
            "Epoch 132/150 - 0.37s - loss: 0.9946 - acc: 0.5119 - val_loss: 1.0235 - val_acc: 0.4717\n",
            "Epoch 133/150 - 0.35s - loss: 0.9940 - acc: 0.5117 - val_loss: 1.0231 - val_acc: 0.4696\n",
            "Epoch 134/150 - 0.34s - loss: 0.9933 - acc: 0.5137 - val_loss: 1.0226 - val_acc: 0.4656\n",
            "Epoch 135/150 - 0.33s - loss: 0.9927 - acc: 0.5137 - val_loss: 1.0221 - val_acc: 0.4696\n",
            "Epoch 136/150 - 0.34s - loss: 0.9921 - acc: 0.5121 - val_loss: 1.0217 - val_acc: 0.4717\n",
            "Epoch 137/150 - 0.34s - loss: 0.9915 - acc: 0.5126 - val_loss: 1.0211 - val_acc: 0.4717\n",
            "Epoch 138/150 - 0.31s - loss: 0.9909 - acc: 0.5151 - val_loss: 1.0211 - val_acc: 0.4717\n",
            "Epoch 139/150 - 0.31s - loss: 0.9903 - acc: 0.5126 - val_loss: 1.0201 - val_acc: 0.4777\n",
            "Epoch 140/150 - 0.34s - loss: 0.9896 - acc: 0.5135 - val_loss: 1.0195 - val_acc: 0.4798\n",
            "Epoch 141/150 - 0.44s - loss: 0.9890 - acc: 0.5164 - val_loss: 1.0193 - val_acc: 0.4717\n",
            "Epoch 142/150 - 0.35s - loss: 0.9889 - acc: 0.5157 - val_loss: 1.0187 - val_acc: 0.4899\n",
            "Epoch 143/150 - 0.44s - loss: 0.9880 - acc: 0.5155 - val_loss: 1.0182 - val_acc: 0.4858\n",
            "Epoch 144/150 - 0.36s - loss: 0.9871 - acc: 0.5164 - val_loss: 1.0177 - val_acc: 0.4757\n",
            "Epoch 145/150 - 0.36s - loss: 0.9866 - acc: 0.5144 - val_loss: 1.0170 - val_acc: 0.4858\n",
            "Epoch 146/150 - 0.33s - loss: 0.9859 - acc: 0.5164 - val_loss: 1.0168 - val_acc: 0.4777\n",
            "Epoch 147/150 - 0.34s - loss: 0.9853 - acc: 0.5162 - val_loss: 1.0162 - val_acc: 0.4798\n",
            "Epoch 148/150 - 0.37s - loss: 0.9847 - acc: 0.5196 - val_loss: 1.0160 - val_acc: 0.4798\n",
            "Epoch 149/150 - 0.36s - loss: 0.9840 - acc: 0.5180 - val_loss: 1.0152 - val_acc: 0.4838\n",
            "Epoch 150/150 - 0.35s - loss: 0.9836 - acc: 0.5182 - val_loss: 1.0148 - val_acc: 0.4858\n",
            "\n",
            "Combination 229/252:\n",
            "Hidden Layers: [512, 256, 128], Activation: relu, Learning Rate: 0.0001, Batch Size: 32, Epochs: 50\n",
            "Epoch 1/50 - 0.52s - loss: 1.0966 - acc: 0.3552 - val_loss: 1.0988 - val_acc: 0.3482\n",
            "Epoch 2/50 - 0.53s - loss: 1.0961 - acc: 0.3574 - val_loss: 1.0983 - val_acc: 0.3462\n",
            "Epoch 3/50 - 0.59s - loss: 1.0956 - acc: 0.3596 - val_loss: 1.0978 - val_acc: 0.3462\n",
            "Epoch 4/50 - 0.52s - loss: 1.0952 - acc: 0.3623 - val_loss: 1.0974 - val_acc: 0.3441\n",
            "Epoch 5/50 - 0.52s - loss: 1.0948 - acc: 0.3641 - val_loss: 1.0970 - val_acc: 0.3502\n",
            "Epoch 6/50 - 0.51s - loss: 1.0944 - acc: 0.3668 - val_loss: 1.0966 - val_acc: 0.3482\n",
            "Epoch 7/50 - 0.55s - loss: 1.0940 - acc: 0.3689 - val_loss: 1.0963 - val_acc: 0.3462\n",
            "Epoch 8/50 - 0.52s - loss: 1.0936 - acc: 0.3689 - val_loss: 1.0960 - val_acc: 0.3502\n",
            "Epoch 9/50 - 0.54s - loss: 1.0933 - acc: 0.3709 - val_loss: 1.0957 - val_acc: 0.3563\n",
            "Epoch 10/50 - 0.50s - loss: 1.0930 - acc: 0.3720 - val_loss: 1.0954 - val_acc: 0.3603\n",
            "Epoch 11/50 - 0.52s - loss: 1.0926 - acc: 0.3749 - val_loss: 1.0951 - val_acc: 0.3644\n",
            "Epoch 12/50 - 0.61s - loss: 1.0923 - acc: 0.3752 - val_loss: 1.0949 - val_acc: 0.3704\n",
            "Epoch 13/50 - 0.53s - loss: 1.0920 - acc: 0.3738 - val_loss: 1.0946 - val_acc: 0.3745\n",
            "Epoch 14/50 - 0.50s - loss: 1.0917 - acc: 0.3752 - val_loss: 1.0943 - val_acc: 0.3785\n",
            "Epoch 15/50 - 0.57s - loss: 1.0914 - acc: 0.3754 - val_loss: 1.0941 - val_acc: 0.3806\n",
            "Epoch 16/50 - 0.53s - loss: 1.0911 - acc: 0.3772 - val_loss: 1.0938 - val_acc: 0.3785\n",
            "Epoch 17/50 - 0.59s - loss: 1.0908 - acc: 0.3790 - val_loss: 1.0936 - val_acc: 0.3785\n",
            "Epoch 18/50 - 0.49s - loss: 1.0905 - acc: 0.3808 - val_loss: 1.0933 - val_acc: 0.3806\n",
            "Epoch 19/50 - 0.53s - loss: 1.0902 - acc: 0.3817 - val_loss: 1.0931 - val_acc: 0.3745\n",
            "Epoch 20/50 - 0.55s - loss: 1.0899 - acc: 0.3835 - val_loss: 1.0928 - val_acc: 0.3806\n",
            "Epoch 21/50 - 0.57s - loss: 1.0896 - acc: 0.3842 - val_loss: 1.0926 - val_acc: 0.3826\n",
            "Epoch 22/50 - 0.50s - loss: 1.0894 - acc: 0.3848 - val_loss: 1.0924 - val_acc: 0.3826\n",
            "Epoch 23/50 - 0.53s - loss: 1.0891 - acc: 0.3842 - val_loss: 1.0922 - val_acc: 0.3806\n",
            "Epoch 24/50 - 0.51s - loss: 1.0888 - acc: 0.3839 - val_loss: 1.0919 - val_acc: 0.3826\n",
            "Epoch 25/50 - 0.50s - loss: 1.0885 - acc: 0.3857 - val_loss: 1.0917 - val_acc: 0.3866\n",
            "Epoch 26/50 - 0.53s - loss: 1.0883 - acc: 0.3873 - val_loss: 1.0915 - val_acc: 0.3846\n",
            "Epoch 27/50 - 0.59s - loss: 1.0880 - acc: 0.3902 - val_loss: 1.0913 - val_acc: 0.3846\n",
            "Epoch 28/50 - 0.51s - loss: 1.0877 - acc: 0.3927 - val_loss: 1.0910 - val_acc: 0.3866\n",
            "Epoch 29/50 - 0.56s - loss: 1.0874 - acc: 0.3927 - val_loss: 1.0908 - val_acc: 0.3866\n",
            "Epoch 30/50 - 0.56s - loss: 1.0872 - acc: 0.3934 - val_loss: 1.0906 - val_acc: 0.3907\n",
            "Epoch 31/50 - 0.53s - loss: 1.0869 - acc: 0.3934 - val_loss: 1.0904 - val_acc: 0.3907\n",
            "Epoch 32/50 - 0.55s - loss: 1.0866 - acc: 0.3945 - val_loss: 1.0902 - val_acc: 0.3927\n",
            "Epoch 33/50 - 0.61s - loss: 1.0864 - acc: 0.3950 - val_loss: 1.0900 - val_acc: 0.3947\n",
            "Epoch 34/50 - 0.50s - loss: 1.0861 - acc: 0.3952 - val_loss: 1.0898 - val_acc: 0.3988\n",
            "Epoch 35/50 - 0.52s - loss: 1.0859 - acc: 0.3954 - val_loss: 1.0896 - val_acc: 0.3968\n",
            "Epoch 36/50 - 0.53s - loss: 1.0856 - acc: 0.3968 - val_loss: 1.0894 - val_acc: 0.3947\n",
            "Epoch 37/50 - 0.58s - loss: 1.0854 - acc: 0.3983 - val_loss: 1.0892 - val_acc: 0.3947\n",
            "Epoch 38/50 - 0.53s - loss: 1.0851 - acc: 0.3990 - val_loss: 1.0890 - val_acc: 0.3968\n",
            "Epoch 39/50 - 0.53s - loss: 1.0849 - acc: 0.4006 - val_loss: 1.0888 - val_acc: 0.3988\n",
            "Epoch 40/50 - 0.50s - loss: 1.0846 - acc: 0.4017 - val_loss: 1.0886 - val_acc: 0.3988\n",
            "Epoch 41/50 - 0.49s - loss: 1.0844 - acc: 0.4024 - val_loss: 1.0884 - val_acc: 0.3988\n",
            "Epoch 42/50 - 0.49s - loss: 1.0841 - acc: 0.4037 - val_loss: 1.0882 - val_acc: 0.3988\n",
            "Epoch 43/50 - 0.51s - loss: 1.0839 - acc: 0.4037 - val_loss: 1.0880 - val_acc: 0.3988\n",
            "Epoch 44/50 - 0.53s - loss: 1.0837 - acc: 0.4042 - val_loss: 1.0878 - val_acc: 0.3988\n",
            "Epoch 45/50 - 0.66s - loss: 1.0834 - acc: 0.4049 - val_loss: 1.0876 - val_acc: 0.3968\n",
            "Epoch 46/50 - 0.62s - loss: 1.0832 - acc: 0.4046 - val_loss: 1.0874 - val_acc: 0.3947\n",
            "Epoch 47/50 - 0.53s - loss: 1.0830 - acc: 0.4062 - val_loss: 1.0872 - val_acc: 0.3968\n",
            "Epoch 48/50 - 0.52s - loss: 1.0827 - acc: 0.4073 - val_loss: 1.0871 - val_acc: 0.3968\n",
            "Epoch 49/50 - 0.55s - loss: 1.0825 - acc: 0.4085 - val_loss: 1.0869 - val_acc: 0.4008\n",
            "Epoch 50/50 - 0.55s - loss: 1.0823 - acc: 0.4105 - val_loss: 1.0867 - val_acc: 0.4028\n",
            "\n",
            "Combination 230/252:\n",
            "Hidden Layers: [512, 256, 128], Activation: relu, Learning Rate: 0.0001, Batch Size: 32, Epochs: 100\n",
            "Epoch 1/100 - 0.59s - loss: 1.1094 - acc: 0.3540 - val_loss: 1.1042 - val_acc: 0.3704\n",
            "Epoch 2/100 - 0.52s - loss: 1.1067 - acc: 0.3556 - val_loss: 1.1021 - val_acc: 0.3623\n",
            "Epoch 3/100 - 0.56s - loss: 1.1045 - acc: 0.3567 - val_loss: 1.1004 - val_acc: 0.3644\n",
            "Epoch 4/100 - 0.50s - loss: 1.1026 - acc: 0.3587 - val_loss: 1.0990 - val_acc: 0.3664\n",
            "Epoch 5/100 - 0.54s - loss: 1.1010 - acc: 0.3601 - val_loss: 1.0979 - val_acc: 0.3704\n",
            "Epoch 6/100 - 0.53s - loss: 1.0997 - acc: 0.3594 - val_loss: 1.0969 - val_acc: 0.3765\n",
            "Epoch 7/100 - 0.57s - loss: 1.0986 - acc: 0.3610 - val_loss: 1.0962 - val_acc: 0.3725\n",
            "Epoch 8/100 - 0.54s - loss: 1.0977 - acc: 0.3612 - val_loss: 1.0955 - val_acc: 0.3725\n",
            "Epoch 9/100 - 0.53s - loss: 1.0968 - acc: 0.3635 - val_loss: 1.0950 - val_acc: 0.3806\n",
            "Epoch 10/100 - 0.50s - loss: 1.0961 - acc: 0.3635 - val_loss: 1.0945 - val_acc: 0.3806\n",
            "Epoch 11/100 - 0.52s - loss: 1.0955 - acc: 0.3623 - val_loss: 1.0941 - val_acc: 0.3704\n",
            "Epoch 12/100 - 0.50s - loss: 1.0949 - acc: 0.3610 - val_loss: 1.0937 - val_acc: 0.3684\n",
            "Epoch 13/100 - 0.56s - loss: 1.0943 - acc: 0.3653 - val_loss: 1.0934 - val_acc: 0.3684\n",
            "Epoch 14/100 - 0.52s - loss: 1.0939 - acc: 0.3695 - val_loss: 1.0931 - val_acc: 0.3684\n",
            "Epoch 15/100 - 0.55s - loss: 1.0934 - acc: 0.3677 - val_loss: 1.0928 - val_acc: 0.3644\n",
            "Epoch 16/100 - 0.55s - loss: 1.0930 - acc: 0.3689 - val_loss: 1.0925 - val_acc: 0.3623\n",
            "Epoch 17/100 - 0.63s - loss: 1.0926 - acc: 0.3716 - val_loss: 1.0922 - val_acc: 0.3684\n",
            "Epoch 18/100 - 0.59s - loss: 1.0922 - acc: 0.3736 - val_loss: 1.0920 - val_acc: 0.3644\n",
            "Epoch 19/100 - 0.56s - loss: 1.0918 - acc: 0.3754 - val_loss: 1.0917 - val_acc: 0.3623\n",
            "Epoch 20/100 - 0.57s - loss: 1.0914 - acc: 0.3770 - val_loss: 1.0915 - val_acc: 0.3664\n",
            "Epoch 21/100 - 0.59s - loss: 1.0910 - acc: 0.3803 - val_loss: 1.0912 - val_acc: 0.3623\n",
            "Epoch 22/100 - 0.57s - loss: 1.0907 - acc: 0.3821 - val_loss: 1.0909 - val_acc: 0.3664\n",
            "Epoch 23/100 - 0.61s - loss: 1.0903 - acc: 0.3808 - val_loss: 1.0907 - val_acc: 0.3664\n",
            "Epoch 24/100 - 0.50s - loss: 1.0900 - acc: 0.3837 - val_loss: 1.0904 - val_acc: 0.3745\n",
            "Epoch 25/100 - 0.55s - loss: 1.0896 - acc: 0.3837 - val_loss: 1.0901 - val_acc: 0.3725\n",
            "Epoch 26/100 - 0.52s - loss: 1.0893 - acc: 0.3869 - val_loss: 1.0899 - val_acc: 0.3725\n",
            "Epoch 27/100 - 0.54s - loss: 1.0890 - acc: 0.3882 - val_loss: 1.0896 - val_acc: 0.3704\n",
            "Epoch 28/100 - 0.53s - loss: 1.0887 - acc: 0.3902 - val_loss: 1.0893 - val_acc: 0.3623\n",
            "Epoch 29/100 - 0.54s - loss: 1.0883 - acc: 0.3941 - val_loss: 1.0890 - val_acc: 0.3603\n",
            "Epoch 30/100 - 0.57s - loss: 1.0880 - acc: 0.3941 - val_loss: 1.0888 - val_acc: 0.3583\n",
            "Epoch 31/100 - 0.58s - loss: 1.0877 - acc: 0.3961 - val_loss: 1.0885 - val_acc: 0.3623\n",
            "Epoch 32/100 - 0.53s - loss: 1.0874 - acc: 0.3974 - val_loss: 1.0883 - val_acc: 0.3664\n",
            "Epoch 33/100 - 0.53s - loss: 1.0871 - acc: 0.3977 - val_loss: 1.0880 - val_acc: 0.3704\n",
            "Epoch 34/100 - 0.55s - loss: 1.0868 - acc: 0.4004 - val_loss: 1.0878 - val_acc: 0.3704\n",
            "Epoch 35/100 - 0.53s - loss: 1.0865 - acc: 0.4013 - val_loss: 1.0875 - val_acc: 0.3765\n",
            "Epoch 36/100 - 0.52s - loss: 1.0862 - acc: 0.4026 - val_loss: 1.0873 - val_acc: 0.3806\n",
            "Epoch 37/100 - 0.58s - loss: 1.0859 - acc: 0.4035 - val_loss: 1.0870 - val_acc: 0.3785\n",
            "Epoch 38/100 - 0.52s - loss: 1.0856 - acc: 0.4040 - val_loss: 1.0868 - val_acc: 0.3765\n",
            "Epoch 39/100 - 0.52s - loss: 1.0853 - acc: 0.4037 - val_loss: 1.0866 - val_acc: 0.3785\n",
            "Epoch 40/100 - 0.52s - loss: 1.0850 - acc: 0.4049 - val_loss: 1.0863 - val_acc: 0.3806\n",
            "Epoch 41/100 - 0.51s - loss: 1.0847 - acc: 0.4058 - val_loss: 1.0861 - val_acc: 0.3887\n",
            "Epoch 42/100 - 0.50s - loss: 1.0844 - acc: 0.4082 - val_loss: 1.0859 - val_acc: 0.3887\n",
            "Epoch 43/100 - 0.54s - loss: 1.0841 - acc: 0.4103 - val_loss: 1.0856 - val_acc: 0.3866\n",
            "Epoch 44/100 - 0.50s - loss: 1.0838 - acc: 0.4107 - val_loss: 1.0854 - val_acc: 0.3887\n",
            "Epoch 45/100 - 0.50s - loss: 1.0835 - acc: 0.4105 - val_loss: 1.0852 - val_acc: 0.3907\n",
            "Epoch 46/100 - 0.55s - loss: 1.0832 - acc: 0.4116 - val_loss: 1.0849 - val_acc: 0.3927\n",
            "Epoch 47/100 - 0.53s - loss: 1.0829 - acc: 0.4132 - val_loss: 1.0847 - val_acc: 0.3907\n",
            "Epoch 48/100 - 0.53s - loss: 1.0827 - acc: 0.4150 - val_loss: 1.0845 - val_acc: 0.3887\n",
            "Epoch 49/100 - 0.53s - loss: 1.0824 - acc: 0.4166 - val_loss: 1.0842 - val_acc: 0.3887\n",
            "Epoch 50/100 - 0.49s - loss: 1.0821 - acc: 0.4177 - val_loss: 1.0840 - val_acc: 0.3887\n",
            "Epoch 51/100 - 0.51s - loss: 1.0818 - acc: 0.4177 - val_loss: 1.0838 - val_acc: 0.3866\n",
            "Epoch 52/100 - 0.50s - loss: 1.0816 - acc: 0.4186 - val_loss: 1.0836 - val_acc: 0.3887\n",
            "Epoch 53/100 - 0.53s - loss: 1.0813 - acc: 0.4190 - val_loss: 1.0834 - val_acc: 0.3866\n",
            "Epoch 54/100 - 0.51s - loss: 1.0810 - acc: 0.4190 - val_loss: 1.0831 - val_acc: 0.3887\n",
            "Epoch 55/100 - 0.54s - loss: 1.0808 - acc: 0.4206 - val_loss: 1.0829 - val_acc: 0.3947\n",
            "Epoch 56/100 - 0.51s - loss: 1.0805 - acc: 0.4211 - val_loss: 1.0827 - val_acc: 0.3968\n",
            "Epoch 57/100 - 0.56s - loss: 1.0802 - acc: 0.4217 - val_loss: 1.0825 - val_acc: 0.3947\n",
            "Epoch 58/100 - 0.52s - loss: 1.0800 - acc: 0.4226 - val_loss: 1.0823 - val_acc: 0.3947\n",
            "Epoch 59/100 - 0.52s - loss: 1.0797 - acc: 0.4240 - val_loss: 1.0821 - val_acc: 0.3907\n",
            "Epoch 60/100 - 0.52s - loss: 1.0794 - acc: 0.4242 - val_loss: 1.0819 - val_acc: 0.3927\n",
            "Epoch 61/100 - 0.55s - loss: 1.0792 - acc: 0.4260 - val_loss: 1.0818 - val_acc: 0.3927\n",
            "Epoch 62/100 - 0.50s - loss: 1.0789 - acc: 0.4274 - val_loss: 1.0816 - val_acc: 0.3927\n",
            "Epoch 63/100 - 0.52s - loss: 1.0786 - acc: 0.4280 - val_loss: 1.0814 - val_acc: 0.3968\n",
            "Epoch 64/100 - 0.62s - loss: 1.0784 - acc: 0.4289 - val_loss: 1.0812 - val_acc: 0.3947\n",
            "Epoch 65/100 - 0.54s - loss: 1.0781 - acc: 0.4289 - val_loss: 1.0810 - val_acc: 0.3927\n",
            "Epoch 66/100 - 0.54s - loss: 1.0779 - acc: 0.4291 - val_loss: 1.0808 - val_acc: 0.3947\n",
            "Epoch 67/100 - 0.55s - loss: 1.0776 - acc: 0.4296 - val_loss: 1.0806 - val_acc: 0.3968\n",
            "Epoch 68/100 - 0.51s - loss: 1.0774 - acc: 0.4321 - val_loss: 1.0804 - val_acc: 0.3988\n",
            "Epoch 69/100 - 0.51s - loss: 1.0771 - acc: 0.4332 - val_loss: 1.0802 - val_acc: 0.3988\n",
            "Epoch 70/100 - 0.50s - loss: 1.0769 - acc: 0.4354 - val_loss: 1.0800 - val_acc: 0.4008\n",
            "Epoch 71/100 - 0.50s - loss: 1.0767 - acc: 0.4354 - val_loss: 1.0799 - val_acc: 0.4008\n",
            "Epoch 72/100 - 0.54s - loss: 1.0764 - acc: 0.4366 - val_loss: 1.0797 - val_acc: 0.4008\n",
            "Epoch 73/100 - 0.70s - loss: 1.0762 - acc: 0.4359 - val_loss: 1.0795 - val_acc: 0.4008\n",
            "Epoch 74/100 - 0.52s - loss: 1.0759 - acc: 0.4366 - val_loss: 1.0793 - val_acc: 0.4008\n",
            "Epoch 75/100 - 0.58s - loss: 1.0757 - acc: 0.4375 - val_loss: 1.0791 - val_acc: 0.4008\n",
            "Epoch 76/100 - 0.69s - loss: 1.0755 - acc: 0.4375 - val_loss: 1.0789 - val_acc: 0.4028\n",
            "Epoch 77/100 - 0.56s - loss: 1.0752 - acc: 0.4370 - val_loss: 1.0788 - val_acc: 0.4028\n",
            "Epoch 78/100 - 0.54s - loss: 1.0750 - acc: 0.4375 - val_loss: 1.0786 - val_acc: 0.4028\n",
            "Epoch 79/100 - 0.58s - loss: 1.0748 - acc: 0.4370 - val_loss: 1.0784 - val_acc: 0.4049\n",
            "Epoch 80/100 - 0.52s - loss: 1.0745 - acc: 0.4375 - val_loss: 1.0782 - val_acc: 0.4049\n",
            "Epoch 81/100 - 0.54s - loss: 1.0743 - acc: 0.4386 - val_loss: 1.0781 - val_acc: 0.4069\n",
            "Epoch 82/100 - 0.53s - loss: 1.0741 - acc: 0.4386 - val_loss: 1.0779 - val_acc: 0.4089\n",
            "Epoch 83/100 - 0.58s - loss: 1.0739 - acc: 0.4386 - val_loss: 1.0777 - val_acc: 0.4069\n",
            "Epoch 84/100 - 0.58s - loss: 1.0736 - acc: 0.4388 - val_loss: 1.0775 - val_acc: 0.4069\n",
            "Epoch 85/100 - 0.60s - loss: 1.0734 - acc: 0.4402 - val_loss: 1.0773 - val_acc: 0.4089\n",
            "Epoch 86/100 - 0.51s - loss: 1.0732 - acc: 0.4402 - val_loss: 1.0772 - val_acc: 0.4089\n",
            "Epoch 87/100 - 0.50s - loss: 1.0730 - acc: 0.4411 - val_loss: 1.0770 - val_acc: 0.4089\n",
            "Epoch 88/100 - 0.52s - loss: 1.0728 - acc: 0.4420 - val_loss: 1.0768 - val_acc: 0.4089\n",
            "Epoch 89/100 - 0.53s - loss: 1.0725 - acc: 0.4420 - val_loss: 1.0766 - val_acc: 0.4089\n",
            "Epoch 90/100 - 0.50s - loss: 1.0723 - acc: 0.4435 - val_loss: 1.0764 - val_acc: 0.4089\n",
            "Epoch 91/100 - 0.57s - loss: 1.0721 - acc: 0.4435 - val_loss: 1.0763 - val_acc: 0.4109\n",
            "Epoch 92/100 - 0.51s - loss: 1.0719 - acc: 0.4444 - val_loss: 1.0761 - val_acc: 0.4109\n",
            "Epoch 93/100 - 0.55s - loss: 1.0717 - acc: 0.4449 - val_loss: 1.0759 - val_acc: 0.4130\n",
            "Epoch 94/100 - 0.50s - loss: 1.0715 - acc: 0.4458 - val_loss: 1.0758 - val_acc: 0.4150\n",
            "Epoch 95/100 - 0.52s - loss: 1.0713 - acc: 0.4465 - val_loss: 1.0756 - val_acc: 0.4150\n",
            "Epoch 96/100 - 0.55s - loss: 1.0711 - acc: 0.4469 - val_loss: 1.0754 - val_acc: 0.4150\n",
            "Epoch 97/100 - 0.55s - loss: 1.0709 - acc: 0.4467 - val_loss: 1.0753 - val_acc: 0.4150\n",
            "Epoch 98/100 - 0.50s - loss: 1.0707 - acc: 0.4456 - val_loss: 1.0751 - val_acc: 0.4150\n",
            "Epoch 99/100 - 0.52s - loss: 1.0705 - acc: 0.4456 - val_loss: 1.0750 - val_acc: 0.4150\n",
            "Epoch 100/100 - 0.51s - loss: 1.0703 - acc: 0.4476 - val_loss: 1.0748 - val_acc: 0.4190\n",
            "\n",
            "Combination 231/252:\n",
            "Hidden Layers: [512, 256, 128], Activation: relu, Learning Rate: 0.0001, Batch Size: 32, Epochs: 150\n",
            "Epoch 1/150 - 0.55s - loss: 1.1421 - acc: 0.3459 - val_loss: 1.1465 - val_acc: 0.3462\n",
            "Epoch 2/150 - 0.52s - loss: 1.1327 - acc: 0.3448 - val_loss: 1.1369 - val_acc: 0.3401\n",
            "Epoch 3/150 - 0.72s - loss: 1.1259 - acc: 0.3408 - val_loss: 1.1298 - val_acc: 0.3360\n",
            "Epoch 4/150 - 0.59s - loss: 1.1208 - acc: 0.3349 - val_loss: 1.1245 - val_acc: 0.3279\n",
            "Epoch 5/150 - 0.54s - loss: 1.1170 - acc: 0.3313 - val_loss: 1.1205 - val_acc: 0.3279\n",
            "Epoch 6/150 - 0.50s - loss: 1.1140 - acc: 0.3275 - val_loss: 1.1176 - val_acc: 0.3239\n",
            "Epoch 7/150 - 0.51s - loss: 1.1118 - acc: 0.3248 - val_loss: 1.1152 - val_acc: 0.3259\n",
            "Epoch 8/150 - 0.56s - loss: 1.1099 - acc: 0.3205 - val_loss: 1.1134 - val_acc: 0.3077\n",
            "Epoch 9/150 - 0.57s - loss: 1.1084 - acc: 0.3196 - val_loss: 1.1118 - val_acc: 0.2935\n",
            "Epoch 10/150 - 0.51s - loss: 1.1072 - acc: 0.3203 - val_loss: 1.1106 - val_acc: 0.2814\n",
            "Epoch 11/150 - 0.54s - loss: 1.1061 - acc: 0.3205 - val_loss: 1.1095 - val_acc: 0.2814\n",
            "Epoch 12/150 - 0.59s - loss: 1.1052 - acc: 0.3219 - val_loss: 1.1086 - val_acc: 0.2834\n",
            "Epoch 13/150 - 0.61s - loss: 1.1043 - acc: 0.3261 - val_loss: 1.1078 - val_acc: 0.2854\n",
            "Epoch 14/150 - 0.53s - loss: 1.1035 - acc: 0.3288 - val_loss: 1.1071 - val_acc: 0.2895\n",
            "Epoch 15/150 - 0.54s - loss: 1.1028 - acc: 0.3333 - val_loss: 1.1064 - val_acc: 0.2854\n",
            "Epoch 16/150 - 0.58s - loss: 1.1021 - acc: 0.3372 - val_loss: 1.1058 - val_acc: 0.2854\n",
            "Epoch 17/150 - 0.62s - loss: 1.1015 - acc: 0.3405 - val_loss: 1.1052 - val_acc: 0.2895\n",
            "Epoch 18/150 - 0.71s - loss: 1.1008 - acc: 0.3408 - val_loss: 1.1046 - val_acc: 0.3016\n",
            "Epoch 19/150 - 0.65s - loss: 1.1002 - acc: 0.3441 - val_loss: 1.1041 - val_acc: 0.3057\n",
            "Epoch 20/150 - 0.70s - loss: 1.0996 - acc: 0.3477 - val_loss: 1.1036 - val_acc: 0.3077\n",
            "Epoch 21/150 - 0.66s - loss: 1.0991 - acc: 0.3511 - val_loss: 1.1031 - val_acc: 0.3158\n",
            "Epoch 22/150 - 0.67s - loss: 1.0985 - acc: 0.3543 - val_loss: 1.1026 - val_acc: 0.3219\n",
            "Epoch 23/150 - 0.61s - loss: 1.0979 - acc: 0.3558 - val_loss: 1.1021 - val_acc: 0.3219\n",
            "Epoch 24/150 - 0.58s - loss: 1.0974 - acc: 0.3605 - val_loss: 1.1017 - val_acc: 0.3219\n",
            "Epoch 25/150 - 0.70s - loss: 1.0968 - acc: 0.3623 - val_loss: 1.1012 - val_acc: 0.3300\n",
            "Epoch 26/150 - 0.66s - loss: 1.0963 - acc: 0.3650 - val_loss: 1.1007 - val_acc: 0.3360\n",
            "Epoch 27/150 - 0.61s - loss: 1.0958 - acc: 0.3671 - val_loss: 1.1003 - val_acc: 0.3381\n",
            "Epoch 28/150 - 0.58s - loss: 1.0953 - acc: 0.3704 - val_loss: 1.0999 - val_acc: 0.3421\n",
            "Epoch 29/150 - 0.56s - loss: 1.0948 - acc: 0.3727 - val_loss: 1.0995 - val_acc: 0.3441\n",
            "Epoch 30/150 - 0.53s - loss: 1.0943 - acc: 0.3727 - val_loss: 1.0990 - val_acc: 0.3401\n",
            "Epoch 31/150 - 0.55s - loss: 1.0938 - acc: 0.3754 - val_loss: 1.0986 - val_acc: 0.3401\n",
            "Epoch 32/150 - 0.53s - loss: 1.0933 - acc: 0.3772 - val_loss: 1.0982 - val_acc: 0.3482\n",
            "Epoch 33/150 - 0.70s - loss: 1.0928 - acc: 0.3788 - val_loss: 1.0978 - val_acc: 0.3563\n",
            "Epoch 34/150 - 0.60s - loss: 1.0923 - acc: 0.3837 - val_loss: 1.0974 - val_acc: 0.3563\n",
            "Epoch 35/150 - 0.57s - loss: 1.0918 - acc: 0.3862 - val_loss: 1.0969 - val_acc: 0.3603\n",
            "Epoch 36/150 - 0.53s - loss: 1.0913 - acc: 0.3889 - val_loss: 1.0965 - val_acc: 0.3664\n",
            "Epoch 37/150 - 0.55s - loss: 1.0909 - acc: 0.3941 - val_loss: 1.0961 - val_acc: 0.3745\n",
            "Epoch 38/150 - 0.56s - loss: 1.0904 - acc: 0.3956 - val_loss: 1.0957 - val_acc: 0.3806\n",
            "Epoch 39/150 - 0.58s - loss: 1.0899 - acc: 0.3995 - val_loss: 1.0954 - val_acc: 0.3846\n",
            "Epoch 40/150 - 0.53s - loss: 1.0895 - acc: 0.4004 - val_loss: 1.0950 - val_acc: 0.3846\n",
            "Epoch 41/150 - 0.53s - loss: 1.0890 - acc: 0.4024 - val_loss: 1.0946 - val_acc: 0.3846\n",
            "Epoch 42/150 - 0.52s - loss: 1.0886 - acc: 0.4046 - val_loss: 1.0943 - val_acc: 0.3826\n",
            "Epoch 43/150 - 0.54s - loss: 1.0881 - acc: 0.4067 - val_loss: 1.0939 - val_acc: 0.3785\n",
            "Epoch 44/150 - 0.52s - loss: 1.0877 - acc: 0.4067 - val_loss: 1.0935 - val_acc: 0.3846\n",
            "Epoch 45/150 - 0.55s - loss: 1.0873 - acc: 0.4069 - val_loss: 1.0932 - val_acc: 0.3846\n",
            "Epoch 46/150 - 0.52s - loss: 1.0868 - acc: 0.4076 - val_loss: 1.0929 - val_acc: 0.3846\n",
            "Epoch 47/150 - 0.54s - loss: 1.0864 - acc: 0.4100 - val_loss: 1.0925 - val_acc: 0.3866\n",
            "Epoch 48/150 - 0.52s - loss: 1.0860 - acc: 0.4094 - val_loss: 1.0922 - val_acc: 0.3846\n",
            "Epoch 49/150 - 0.53s - loss: 1.0856 - acc: 0.4112 - val_loss: 1.0919 - val_acc: 0.3887\n",
            "Epoch 50/150 - 0.52s - loss: 1.0852 - acc: 0.4134 - val_loss: 1.0916 - val_acc: 0.3866\n",
            "Epoch 51/150 - 0.55s - loss: 1.0848 - acc: 0.4163 - val_loss: 1.0912 - val_acc: 0.3927\n",
            "Epoch 52/150 - 0.52s - loss: 1.0844 - acc: 0.4170 - val_loss: 1.0909 - val_acc: 0.3988\n",
            "Epoch 53/150 - 0.53s - loss: 1.0840 - acc: 0.4175 - val_loss: 1.0906 - val_acc: 0.4049\n",
            "Epoch 54/150 - 0.55s - loss: 1.0836 - acc: 0.4202 - val_loss: 1.0903 - val_acc: 0.4069\n",
            "Epoch 55/150 - 0.56s - loss: 1.0832 - acc: 0.4220 - val_loss: 1.0900 - val_acc: 0.4089\n",
            "Epoch 56/150 - 0.57s - loss: 1.0828 - acc: 0.4247 - val_loss: 1.0897 - val_acc: 0.4150\n",
            "Epoch 57/150 - 0.60s - loss: 1.0824 - acc: 0.4256 - val_loss: 1.0894 - val_acc: 0.4130\n",
            "Epoch 58/150 - 0.54s - loss: 1.0821 - acc: 0.4258 - val_loss: 1.0891 - val_acc: 0.4150\n",
            "Epoch 59/150 - 0.57s - loss: 1.0817 - acc: 0.4278 - val_loss: 1.0888 - val_acc: 0.4150\n",
            "Epoch 60/150 - 0.56s - loss: 1.0813 - acc: 0.4296 - val_loss: 1.0885 - val_acc: 0.4190\n",
            "Epoch 61/150 - 0.58s - loss: 1.0810 - acc: 0.4305 - val_loss: 1.0882 - val_acc: 0.4150\n",
            "Epoch 62/150 - 0.55s - loss: 1.0806 - acc: 0.4312 - val_loss: 1.0879 - val_acc: 0.4170\n",
            "Epoch 63/150 - 0.54s - loss: 1.0802 - acc: 0.4330 - val_loss: 1.0876 - val_acc: 0.4211\n",
            "Epoch 64/150 - 0.52s - loss: 1.0799 - acc: 0.4332 - val_loss: 1.0873 - val_acc: 0.4231\n",
            "Epoch 65/150 - 0.55s - loss: 1.0795 - acc: 0.4345 - val_loss: 1.0871 - val_acc: 0.4251\n",
            "Epoch 66/150 - 0.54s - loss: 1.0792 - acc: 0.4336 - val_loss: 1.0868 - val_acc: 0.4231\n",
            "Epoch 67/150 - 0.59s - loss: 1.0788 - acc: 0.4336 - val_loss: 1.0865 - val_acc: 0.4231\n",
            "Epoch 68/150 - 0.55s - loss: 1.0785 - acc: 0.4341 - val_loss: 1.0862 - val_acc: 0.4231\n",
            "Epoch 69/150 - 0.59s - loss: 1.0782 - acc: 0.4366 - val_loss: 1.0860 - val_acc: 0.4271\n",
            "Epoch 70/150 - 0.57s - loss: 1.0778 - acc: 0.4366 - val_loss: 1.0857 - val_acc: 0.4271\n",
            "Epoch 71/150 - 0.56s - loss: 1.0775 - acc: 0.4359 - val_loss: 1.0854 - val_acc: 0.4271\n",
            "Epoch 72/150 - 0.56s - loss: 1.0772 - acc: 0.4372 - val_loss: 1.0852 - val_acc: 0.4271\n",
            "Epoch 73/150 - 0.65s - loss: 1.0768 - acc: 0.4388 - val_loss: 1.0849 - val_acc: 0.4251\n",
            "Epoch 74/150 - 0.54s - loss: 1.0765 - acc: 0.4395 - val_loss: 1.0847 - val_acc: 0.4251\n",
            "Epoch 75/150 - 0.62s - loss: 1.0762 - acc: 0.4399 - val_loss: 1.0844 - val_acc: 0.4251\n",
            "Epoch 76/150 - 0.55s - loss: 1.0759 - acc: 0.4406 - val_loss: 1.0842 - val_acc: 0.4251\n",
            "Epoch 77/150 - 0.63s - loss: 1.0756 - acc: 0.4408 - val_loss: 1.0839 - val_acc: 0.4271\n",
            "Epoch 78/150 - 0.55s - loss: 1.0753 - acc: 0.4420 - val_loss: 1.0837 - val_acc: 0.4271\n",
            "Epoch 79/150 - 0.54s - loss: 1.0749 - acc: 0.4424 - val_loss: 1.0834 - val_acc: 0.4271\n",
            "Epoch 80/150 - 0.53s - loss: 1.0746 - acc: 0.4431 - val_loss: 1.0832 - val_acc: 0.4271\n",
            "Epoch 81/150 - 0.58s - loss: 1.0743 - acc: 0.4440 - val_loss: 1.0829 - val_acc: 0.4291\n",
            "Epoch 82/150 - 0.60s - loss: 1.0740 - acc: 0.4449 - val_loss: 1.0827 - val_acc: 0.4271\n",
            "Epoch 83/150 - 0.57s - loss: 1.0737 - acc: 0.4451 - val_loss: 1.0825 - val_acc: 0.4271\n",
            "Epoch 84/150 - 0.53s - loss: 1.0734 - acc: 0.4440 - val_loss: 1.0822 - val_acc: 0.4231\n",
            "Epoch 85/150 - 0.55s - loss: 1.0731 - acc: 0.4449 - val_loss: 1.0820 - val_acc: 0.4211\n",
            "Epoch 86/150 - 0.54s - loss: 1.0728 - acc: 0.4449 - val_loss: 1.0818 - val_acc: 0.4231\n",
            "Epoch 87/150 - 0.57s - loss: 1.0725 - acc: 0.4458 - val_loss: 1.0815 - val_acc: 0.4251\n",
            "Epoch 88/150 - 0.54s - loss: 1.0723 - acc: 0.4447 - val_loss: 1.0813 - val_acc: 0.4231\n",
            "Epoch 89/150 - 0.57s - loss: 1.0720 - acc: 0.4449 - val_loss: 1.0811 - val_acc: 0.4231\n",
            "Epoch 90/150 - 0.55s - loss: 1.0717 - acc: 0.4440 - val_loss: 1.0808 - val_acc: 0.4251\n",
            "Epoch 91/150 - 0.58s - loss: 1.0714 - acc: 0.4442 - val_loss: 1.0806 - val_acc: 0.4251\n",
            "Epoch 92/150 - 0.58s - loss: 1.0711 - acc: 0.4449 - val_loss: 1.0804 - val_acc: 0.4251\n",
            "Epoch 93/150 - 0.56s - loss: 1.0708 - acc: 0.4444 - val_loss: 1.0802 - val_acc: 0.4231\n",
            "Epoch 94/150 - 0.53s - loss: 1.0705 - acc: 0.4444 - val_loss: 1.0800 - val_acc: 0.4211\n",
            "Epoch 95/150 - 0.57s - loss: 1.0703 - acc: 0.4458 - val_loss: 1.0797 - val_acc: 0.4251\n",
            "Epoch 96/150 - 0.56s - loss: 1.0700 - acc: 0.4460 - val_loss: 1.0795 - val_acc: 0.4271\n",
            "Epoch 97/150 - 0.55s - loss: 1.0697 - acc: 0.4465 - val_loss: 1.0793 - val_acc: 0.4271\n",
            "Epoch 98/150 - 0.57s - loss: 1.0694 - acc: 0.4460 - val_loss: 1.0791 - val_acc: 0.4251\n",
            "Epoch 99/150 - 0.58s - loss: 1.0692 - acc: 0.4476 - val_loss: 1.0789 - val_acc: 0.4251\n",
            "Epoch 100/150 - 0.54s - loss: 1.0689 - acc: 0.4485 - val_loss: 1.0786 - val_acc: 0.4251\n",
            "Epoch 101/150 - 0.56s - loss: 1.0686 - acc: 0.4485 - val_loss: 1.0784 - val_acc: 0.4231\n",
            "Epoch 102/150 - 0.54s - loss: 1.0683 - acc: 0.4498 - val_loss: 1.0782 - val_acc: 0.4291\n",
            "Epoch 103/150 - 0.56s - loss: 1.0681 - acc: 0.4501 - val_loss: 1.0780 - val_acc: 0.4291\n",
            "Epoch 104/150 - 0.59s - loss: 1.0678 - acc: 0.4501 - val_loss: 1.0778 - val_acc: 0.4231\n",
            "Epoch 105/150 - 0.58s - loss: 1.0676 - acc: 0.4505 - val_loss: 1.0776 - val_acc: 0.4231\n",
            "Epoch 106/150 - 0.54s - loss: 1.0673 - acc: 0.4519 - val_loss: 1.0774 - val_acc: 0.4231\n",
            "Epoch 107/150 - 0.57s - loss: 1.0670 - acc: 0.4521 - val_loss: 1.0772 - val_acc: 0.4271\n",
            "Epoch 108/150 - 0.52s - loss: 1.0668 - acc: 0.4519 - val_loss: 1.0771 - val_acc: 0.4271\n",
            "Epoch 109/150 - 0.53s - loss: 1.0665 - acc: 0.4516 - val_loss: 1.0769 - val_acc: 0.4271\n",
            "Epoch 110/150 - 0.54s - loss: 1.0663 - acc: 0.4519 - val_loss: 1.0767 - val_acc: 0.4271\n",
            "Epoch 111/150 - 0.57s - loss: 1.0660 - acc: 0.4514 - val_loss: 1.0765 - val_acc: 0.4291\n",
            "Epoch 112/150 - 0.52s - loss: 1.0658 - acc: 0.4512 - val_loss: 1.0763 - val_acc: 0.4291\n",
            "Epoch 113/150 - 0.53s - loss: 1.0655 - acc: 0.4512 - val_loss: 1.0761 - val_acc: 0.4251\n",
            "Epoch 114/150 - 0.54s - loss: 1.0653 - acc: 0.4516 - val_loss: 1.0759 - val_acc: 0.4251\n",
            "Epoch 115/150 - 0.70s - loss: 1.0650 - acc: 0.4521 - val_loss: 1.0758 - val_acc: 0.4271\n",
            "Epoch 116/150 - 0.74s - loss: 1.0648 - acc: 0.4514 - val_loss: 1.0756 - val_acc: 0.4332\n",
            "Epoch 117/150 - 0.62s - loss: 1.0645 - acc: 0.4514 - val_loss: 1.0754 - val_acc: 0.4312\n",
            "Epoch 118/150 - 0.73s - loss: 1.0643 - acc: 0.4523 - val_loss: 1.0752 - val_acc: 0.4291\n",
            "Epoch 119/150 - 0.64s - loss: 1.0641 - acc: 0.4528 - val_loss: 1.0750 - val_acc: 0.4312\n",
            "Epoch 120/150 - 0.59s - loss: 1.0638 - acc: 0.4525 - val_loss: 1.0749 - val_acc: 0.4312\n",
            "Epoch 121/150 - 0.82s - loss: 1.0636 - acc: 0.4532 - val_loss: 1.0747 - val_acc: 0.4312\n",
            "Epoch 122/150 - 0.60s - loss: 1.0633 - acc: 0.4548 - val_loss: 1.0745 - val_acc: 0.4312\n",
            "Epoch 123/150 - 0.79s - loss: 1.0631 - acc: 0.4552 - val_loss: 1.0744 - val_acc: 0.4312\n",
            "Epoch 124/150 - 0.61s - loss: 1.0629 - acc: 0.4557 - val_loss: 1.0742 - val_acc: 0.4332\n",
            "Epoch 125/150 - 0.53s - loss: 1.0626 - acc: 0.4566 - val_loss: 1.0740 - val_acc: 0.4332\n",
            "Epoch 126/150 - 0.50s - loss: 1.0624 - acc: 0.4570 - val_loss: 1.0738 - val_acc: 0.4372\n",
            "Epoch 127/150 - 0.52s - loss: 1.0621 - acc: 0.4570 - val_loss: 1.0737 - val_acc: 0.4393\n",
            "Epoch 128/150 - 0.53s - loss: 1.0619 - acc: 0.4573 - val_loss: 1.0735 - val_acc: 0.4393\n",
            "Epoch 129/150 - 0.56s - loss: 1.0617 - acc: 0.4586 - val_loss: 1.0733 - val_acc: 0.4393\n",
            "Epoch 130/150 - 0.52s - loss: 1.0615 - acc: 0.4591 - val_loss: 1.0732 - val_acc: 0.4393\n",
            "Epoch 131/150 - 0.51s - loss: 1.0612 - acc: 0.4595 - val_loss: 1.0730 - val_acc: 0.4393\n",
            "Epoch 132/150 - 0.51s - loss: 1.0610 - acc: 0.4600 - val_loss: 1.0728 - val_acc: 0.4393\n",
            "Epoch 133/150 - 0.51s - loss: 1.0608 - acc: 0.4602 - val_loss: 1.0726 - val_acc: 0.4393\n",
            "Epoch 134/150 - 0.59s - loss: 1.0605 - acc: 0.4609 - val_loss: 1.0724 - val_acc: 0.4413\n",
            "Epoch 135/150 - 0.59s - loss: 1.0603 - acc: 0.4600 - val_loss: 1.0723 - val_acc: 0.4372\n",
            "Epoch 136/150 - 0.53s - loss: 1.0601 - acc: 0.4602 - val_loss: 1.0721 - val_acc: 0.4372\n",
            "Epoch 137/150 - 0.56s - loss: 1.0598 - acc: 0.4606 - val_loss: 1.0719 - val_acc: 0.4393\n",
            "Epoch 138/150 - 0.50s - loss: 1.0596 - acc: 0.4613 - val_loss: 1.0717 - val_acc: 0.4393\n",
            "Epoch 139/150 - 0.51s - loss: 1.0594 - acc: 0.4615 - val_loss: 1.0716 - val_acc: 0.4433\n",
            "Epoch 140/150 - 0.53s - loss: 1.0592 - acc: 0.4615 - val_loss: 1.0714 - val_acc: 0.4433\n",
            "Epoch 141/150 - 0.53s - loss: 1.0589 - acc: 0.4620 - val_loss: 1.0712 - val_acc: 0.4433\n",
            "Epoch 142/150 - 0.50s - loss: 1.0587 - acc: 0.4622 - val_loss: 1.0710 - val_acc: 0.4453\n",
            "Epoch 143/150 - 0.50s - loss: 1.0585 - acc: 0.4624 - val_loss: 1.0709 - val_acc: 0.4433\n",
            "Epoch 144/150 - 0.52s - loss: 1.0583 - acc: 0.4629 - val_loss: 1.0707 - val_acc: 0.4433\n",
            "Epoch 145/150 - 0.53s - loss: 1.0581 - acc: 0.4631 - val_loss: 1.0705 - val_acc: 0.4433\n",
            "Epoch 146/150 - 0.55s - loss: 1.0578 - acc: 0.4638 - val_loss: 1.0704 - val_acc: 0.4433\n",
            "Epoch 147/150 - 0.55s - loss: 1.0576 - acc: 0.4638 - val_loss: 1.0702 - val_acc: 0.4433\n",
            "Epoch 148/150 - 0.50s - loss: 1.0574 - acc: 0.4636 - val_loss: 1.0700 - val_acc: 0.4433\n",
            "Epoch 149/150 - 0.52s - loss: 1.0572 - acc: 0.4633 - val_loss: 1.0699 - val_acc: 0.4433\n",
            "Epoch 150/150 - 0.52s - loss: 1.0570 - acc: 0.4638 - val_loss: 1.0697 - val_acc: 0.4433\n",
            "\n",
            "Combination 232/252:\n",
            "Hidden Layers: [512, 256, 128], Activation: relu, Learning Rate: 0.0001, Batch Size: 64, Epochs: 50\n",
            "Epoch 1/50 - 0.33s - loss: 1.0983 - acc: 0.3315 - val_loss: 1.1031 - val_acc: 0.3097\n",
            "Epoch 2/50 - 0.33s - loss: 1.0980 - acc: 0.3338 - val_loss: 1.1028 - val_acc: 0.3178\n",
            "Epoch 3/50 - 0.34s - loss: 1.0977 - acc: 0.3338 - val_loss: 1.1025 - val_acc: 0.3259\n",
            "Epoch 4/50 - 0.35s - loss: 1.0974 - acc: 0.3329 - val_loss: 1.1023 - val_acc: 0.3360\n",
            "Epoch 5/50 - 0.35s - loss: 1.0972 - acc: 0.3367 - val_loss: 1.1020 - val_acc: 0.3320\n",
            "Epoch 6/50 - 0.32s - loss: 1.0969 - acc: 0.3403 - val_loss: 1.1018 - val_acc: 0.3320\n",
            "Epoch 7/50 - 0.33s - loss: 1.0966 - acc: 0.3444 - val_loss: 1.1016 - val_acc: 0.3401\n",
            "Epoch 8/50 - 0.32s - loss: 1.0964 - acc: 0.3468 - val_loss: 1.1013 - val_acc: 0.3401\n",
            "Epoch 9/50 - 0.35s - loss: 1.0961 - acc: 0.3459 - val_loss: 1.1011 - val_acc: 0.3360\n",
            "Epoch 10/50 - 0.35s - loss: 1.0959 - acc: 0.3491 - val_loss: 1.1009 - val_acc: 0.3340\n",
            "Epoch 11/50 - 0.34s - loss: 1.0956 - acc: 0.3486 - val_loss: 1.1007 - val_acc: 0.3340\n",
            "Epoch 12/50 - 0.34s - loss: 1.0954 - acc: 0.3513 - val_loss: 1.1005 - val_acc: 0.3381\n",
            "Epoch 13/50 - 0.34s - loss: 1.0952 - acc: 0.3518 - val_loss: 1.1003 - val_acc: 0.3381\n",
            "Epoch 14/50 - 0.40s - loss: 1.0949 - acc: 0.3531 - val_loss: 1.1001 - val_acc: 0.3421\n",
            "Epoch 15/50 - 0.45s - loss: 1.0947 - acc: 0.3556 - val_loss: 1.0999 - val_acc: 0.3441\n",
            "Epoch 16/50 - 0.33s - loss: 1.0945 - acc: 0.3570 - val_loss: 1.0997 - val_acc: 0.3421\n",
            "Epoch 17/50 - 0.33s - loss: 1.0943 - acc: 0.3583 - val_loss: 1.0995 - val_acc: 0.3360\n",
            "Epoch 18/50 - 0.35s - loss: 1.0941 - acc: 0.3587 - val_loss: 1.0994 - val_acc: 0.3360\n",
            "Epoch 19/50 - 0.36s - loss: 1.0939 - acc: 0.3603 - val_loss: 1.0992 - val_acc: 0.3340\n",
            "Epoch 20/50 - 0.34s - loss: 1.0937 - acc: 0.3601 - val_loss: 1.0990 - val_acc: 0.3381\n",
            "Epoch 21/50 - 0.37s - loss: 1.0935 - acc: 0.3612 - val_loss: 1.0988 - val_acc: 0.3401\n",
            "Epoch 22/50 - 0.34s - loss: 1.0933 - acc: 0.3637 - val_loss: 1.0987 - val_acc: 0.3421\n",
            "Epoch 23/50 - 0.36s - loss: 1.0931 - acc: 0.3646 - val_loss: 1.0985 - val_acc: 0.3421\n",
            "Epoch 24/50 - 0.39s - loss: 1.0929 - acc: 0.3659 - val_loss: 1.0983 - val_acc: 0.3482\n",
            "Epoch 25/50 - 0.37s - loss: 1.0927 - acc: 0.3682 - val_loss: 1.0982 - val_acc: 0.3502\n",
            "Epoch 26/50 - 0.33s - loss: 1.0925 - acc: 0.3702 - val_loss: 1.0980 - val_acc: 0.3522\n",
            "Epoch 27/50 - 0.41s - loss: 1.0923 - acc: 0.3707 - val_loss: 1.0979 - val_acc: 0.3502\n",
            "Epoch 28/50 - 0.38s - loss: 1.0921 - acc: 0.3718 - val_loss: 1.0977 - val_acc: 0.3482\n",
            "Epoch 29/50 - 0.43s - loss: 1.0919 - acc: 0.3731 - val_loss: 1.0975 - val_acc: 0.3522\n",
            "Epoch 30/50 - 0.34s - loss: 1.0917 - acc: 0.3734 - val_loss: 1.0974 - val_acc: 0.3522\n",
            "Epoch 31/50 - 0.35s - loss: 1.0916 - acc: 0.3743 - val_loss: 1.0972 - val_acc: 0.3502\n",
            "Epoch 32/50 - 0.39s - loss: 1.0914 - acc: 0.3756 - val_loss: 1.0971 - val_acc: 0.3522\n",
            "Epoch 33/50 - 0.42s - loss: 1.0912 - acc: 0.3756 - val_loss: 1.0969 - val_acc: 0.3543\n",
            "Epoch 34/50 - 0.35s - loss: 1.0910 - acc: 0.3761 - val_loss: 1.0968 - val_acc: 0.3563\n",
            "Epoch 35/50 - 0.34s - loss: 1.0908 - acc: 0.3758 - val_loss: 1.0966 - val_acc: 0.3563\n",
            "Epoch 36/50 - 0.34s - loss: 1.0906 - acc: 0.3774 - val_loss: 1.0965 - val_acc: 0.3563\n",
            "Epoch 37/50 - 0.33s - loss: 1.0905 - acc: 0.3776 - val_loss: 1.0963 - val_acc: 0.3583\n",
            "Epoch 38/50 - 0.33s - loss: 1.0903 - acc: 0.3785 - val_loss: 1.0962 - val_acc: 0.3623\n",
            "Epoch 39/50 - 0.38s - loss: 1.0901 - acc: 0.3794 - val_loss: 1.0960 - val_acc: 0.3623\n",
            "Epoch 40/50 - 0.32s - loss: 1.0899 - acc: 0.3794 - val_loss: 1.0959 - val_acc: 0.3623\n",
            "Epoch 41/50 - 0.38s - loss: 1.0898 - acc: 0.3794 - val_loss: 1.0957 - val_acc: 0.3644\n",
            "Epoch 42/50 - 0.34s - loss: 1.0896 - acc: 0.3797 - val_loss: 1.0956 - val_acc: 0.3664\n",
            "Epoch 43/50 - 0.34s - loss: 1.0894 - acc: 0.3808 - val_loss: 1.0955 - val_acc: 0.3684\n",
            "Epoch 44/50 - 0.33s - loss: 1.0893 - acc: 0.3812 - val_loss: 1.0953 - val_acc: 0.3684\n",
            "Epoch 45/50 - 0.33s - loss: 1.0891 - acc: 0.3812 - val_loss: 1.0952 - val_acc: 0.3664\n",
            "Epoch 46/50 - 0.35s - loss: 1.0889 - acc: 0.3810 - val_loss: 1.0950 - val_acc: 0.3664\n",
            "Epoch 47/50 - 0.33s - loss: 1.0887 - acc: 0.3828 - val_loss: 1.0949 - val_acc: 0.3644\n",
            "Epoch 48/50 - 0.35s - loss: 1.0886 - acc: 0.3826 - val_loss: 1.0948 - val_acc: 0.3583\n",
            "Epoch 49/50 - 0.33s - loss: 1.0884 - acc: 0.3839 - val_loss: 1.0946 - val_acc: 0.3603\n",
            "Epoch 50/50 - 0.37s - loss: 1.0882 - acc: 0.3846 - val_loss: 1.0945 - val_acc: 0.3583\n",
            "\n",
            "Combination 233/252:\n",
            "Hidden Layers: [512, 256, 128], Activation: relu, Learning Rate: 0.0001, Batch Size: 64, Epochs: 100\n",
            "Epoch 1/100 - 0.37s - loss: 1.1289 - acc: 0.3484 - val_loss: 1.1342 - val_acc: 0.3522\n",
            "Epoch 2/100 - 0.33s - loss: 1.1260 - acc: 0.3480 - val_loss: 1.1312 - val_acc: 0.3482\n",
            "Epoch 3/100 - 0.34s - loss: 1.1233 - acc: 0.3477 - val_loss: 1.1284 - val_acc: 0.3421\n",
            "Epoch 4/100 - 0.34s - loss: 1.1210 - acc: 0.3466 - val_loss: 1.1260 - val_acc: 0.3401\n",
            "Epoch 5/100 - 0.37s - loss: 1.1188 - acc: 0.3457 - val_loss: 1.1238 - val_acc: 0.3401\n",
            "Epoch 6/100 - 0.41s - loss: 1.1169 - acc: 0.3455 - val_loss: 1.1218 - val_acc: 0.3360\n",
            "Epoch 7/100 - 0.38s - loss: 1.1152 - acc: 0.3448 - val_loss: 1.1200 - val_acc: 0.3401\n",
            "Epoch 8/100 - 0.33s - loss: 1.1136 - acc: 0.3455 - val_loss: 1.1183 - val_acc: 0.3421\n",
            "Epoch 9/100 - 0.34s - loss: 1.1121 - acc: 0.3444 - val_loss: 1.1168 - val_acc: 0.3401\n",
            "Epoch 10/100 - 0.33s - loss: 1.1108 - acc: 0.3432 - val_loss: 1.1154 - val_acc: 0.3381\n",
            "Epoch 11/100 - 0.32s - loss: 1.1096 - acc: 0.3432 - val_loss: 1.1142 - val_acc: 0.3401\n",
            "Epoch 12/100 - 0.34s - loss: 1.1085 - acc: 0.3421 - val_loss: 1.1130 - val_acc: 0.3421\n",
            "Epoch 13/100 - 0.37s - loss: 1.1075 - acc: 0.3428 - val_loss: 1.1120 - val_acc: 0.3360\n",
            "Epoch 14/100 - 0.33s - loss: 1.1065 - acc: 0.3414 - val_loss: 1.1110 - val_acc: 0.3340\n",
            "Epoch 15/100 - 0.32s - loss: 1.1057 - acc: 0.3408 - val_loss: 1.1101 - val_acc: 0.3360\n",
            "Epoch 16/100 - 0.33s - loss: 1.1049 - acc: 0.3430 - val_loss: 1.1092 - val_acc: 0.3381\n",
            "Epoch 17/100 - 0.48s - loss: 1.1041 - acc: 0.3428 - val_loss: 1.1084 - val_acc: 0.3401\n",
            "Epoch 18/100 - 0.32s - loss: 1.1034 - acc: 0.3430 - val_loss: 1.1077 - val_acc: 0.3462\n",
            "Epoch 19/100 - 0.34s - loss: 1.1028 - acc: 0.3439 - val_loss: 1.1070 - val_acc: 0.3462\n",
            "Epoch 20/100 - 0.34s - loss: 1.1022 - acc: 0.3428 - val_loss: 1.1063 - val_acc: 0.3462\n",
            "Epoch 21/100 - 0.36s - loss: 1.1016 - acc: 0.3448 - val_loss: 1.1057 - val_acc: 0.3462\n",
            "Epoch 22/100 - 0.37s - loss: 1.1011 - acc: 0.3448 - val_loss: 1.1052 - val_acc: 0.3462\n",
            "Epoch 23/100 - 0.35s - loss: 1.1006 - acc: 0.3455 - val_loss: 1.1046 - val_acc: 0.3482\n",
            "Epoch 24/100 - 0.36s - loss: 1.1001 - acc: 0.3457 - val_loss: 1.1041 - val_acc: 0.3482\n",
            "Epoch 25/100 - 0.39s - loss: 1.0996 - acc: 0.3468 - val_loss: 1.1036 - val_acc: 0.3502\n",
            "Epoch 26/100 - 0.34s - loss: 1.0992 - acc: 0.3466 - val_loss: 1.1031 - val_acc: 0.3522\n",
            "Epoch 27/100 - 0.54s - loss: 1.0988 - acc: 0.3468 - val_loss: 1.1027 - val_acc: 0.3522\n",
            "Epoch 28/100 - 0.45s - loss: 1.0984 - acc: 0.3484 - val_loss: 1.1022 - val_acc: 0.3522\n",
            "Epoch 29/100 - 0.36s - loss: 1.0980 - acc: 0.3495 - val_loss: 1.1018 - val_acc: 0.3522\n",
            "Epoch 30/100 - 0.36s - loss: 1.0977 - acc: 0.3511 - val_loss: 1.1015 - val_acc: 0.3543\n",
            "Epoch 31/100 - 0.36s - loss: 1.0973 - acc: 0.3493 - val_loss: 1.1011 - val_acc: 0.3482\n",
            "Epoch 32/100 - 0.33s - loss: 1.0970 - acc: 0.3484 - val_loss: 1.1007 - val_acc: 0.3502\n",
            "Epoch 33/100 - 0.33s - loss: 1.0967 - acc: 0.3475 - val_loss: 1.1004 - val_acc: 0.3522\n",
            "Epoch 34/100 - 0.32s - loss: 1.0964 - acc: 0.3529 - val_loss: 1.1001 - val_acc: 0.3462\n",
            "Epoch 35/100 - 0.35s - loss: 1.0961 - acc: 0.3547 - val_loss: 1.0998 - val_acc: 0.3441\n",
            "Epoch 36/100 - 0.34s - loss: 1.0958 - acc: 0.3556 - val_loss: 1.0995 - val_acc: 0.3441\n",
            "Epoch 37/100 - 0.34s - loss: 1.0955 - acc: 0.3574 - val_loss: 1.0992 - val_acc: 0.3462\n",
            "Epoch 38/100 - 0.34s - loss: 1.0952 - acc: 0.3590 - val_loss: 1.0989 - val_acc: 0.3502\n",
            "Epoch 39/100 - 0.31s - loss: 1.0950 - acc: 0.3623 - val_loss: 1.0986 - val_acc: 0.3563\n",
            "Epoch 40/100 - 0.31s - loss: 1.0947 - acc: 0.3650 - val_loss: 1.0984 - val_acc: 0.3543\n",
            "Epoch 41/100 - 0.32s - loss: 1.0945 - acc: 0.3648 - val_loss: 1.0981 - val_acc: 0.3543\n",
            "Epoch 42/100 - 0.35s - loss: 1.0942 - acc: 0.3662 - val_loss: 1.0979 - val_acc: 0.3563\n",
            "Epoch 43/100 - 0.33s - loss: 1.0940 - acc: 0.3675 - val_loss: 1.0976 - val_acc: 0.3583\n",
            "Epoch 44/100 - 0.36s - loss: 1.0937 - acc: 0.3675 - val_loss: 1.0974 - val_acc: 0.3623\n",
            "Epoch 45/100 - 0.34s - loss: 1.0935 - acc: 0.3675 - val_loss: 1.0972 - val_acc: 0.3623\n",
            "Epoch 46/100 - 0.32s - loss: 1.0933 - acc: 0.3680 - val_loss: 1.0969 - val_acc: 0.3704\n",
            "Epoch 47/100 - 0.34s - loss: 1.0931 - acc: 0.3684 - val_loss: 1.0967 - val_acc: 0.3684\n",
            "Epoch 48/100 - 0.32s - loss: 1.0928 - acc: 0.3689 - val_loss: 1.0965 - val_acc: 0.3745\n",
            "Epoch 49/100 - 0.35s - loss: 1.0926 - acc: 0.3698 - val_loss: 1.0963 - val_acc: 0.3725\n",
            "Epoch 50/100 - 0.32s - loss: 1.0924 - acc: 0.3718 - val_loss: 1.0960 - val_acc: 0.3765\n",
            "Epoch 51/100 - 0.32s - loss: 1.0922 - acc: 0.3707 - val_loss: 1.0958 - val_acc: 0.3765\n",
            "Epoch 52/100 - 0.33s - loss: 1.0920 - acc: 0.3738 - val_loss: 1.0956 - val_acc: 0.3806\n",
            "Epoch 53/100 - 0.34s - loss: 1.0918 - acc: 0.3745 - val_loss: 1.0954 - val_acc: 0.3846\n",
            "Epoch 54/100 - 0.32s - loss: 1.0916 - acc: 0.3740 - val_loss: 1.0952 - val_acc: 0.3866\n",
            "Epoch 55/100 - 0.34s - loss: 1.0914 - acc: 0.3738 - val_loss: 1.0950 - val_acc: 0.3846\n",
            "Epoch 56/100 - 0.33s - loss: 1.0912 - acc: 0.3747 - val_loss: 1.0948 - val_acc: 0.3846\n",
            "Epoch 57/100 - 0.35s - loss: 1.0910 - acc: 0.3756 - val_loss: 1.0946 - val_acc: 0.3866\n",
            "Epoch 58/100 - 0.33s - loss: 1.0908 - acc: 0.3758 - val_loss: 1.0944 - val_acc: 0.3887\n",
            "Epoch 59/100 - 0.36s - loss: 1.0906 - acc: 0.3779 - val_loss: 1.0943 - val_acc: 0.3866\n",
            "Epoch 60/100 - 0.32s - loss: 1.0904 - acc: 0.3776 - val_loss: 1.0941 - val_acc: 0.3887\n",
            "Epoch 61/100 - 0.38s - loss: 1.0902 - acc: 0.3788 - val_loss: 1.0939 - val_acc: 0.3826\n",
            "Epoch 62/100 - 0.36s - loss: 1.0900 - acc: 0.3779 - val_loss: 1.0937 - val_acc: 0.3806\n",
            "Epoch 63/100 - 0.34s - loss: 1.0898 - acc: 0.3779 - val_loss: 1.0935 - val_acc: 0.3826\n",
            "Epoch 64/100 - 0.34s - loss: 1.0897 - acc: 0.3785 - val_loss: 1.0934 - val_acc: 0.3846\n",
            "Epoch 65/100 - 0.35s - loss: 1.0895 - acc: 0.3803 - val_loss: 1.0932 - val_acc: 0.3846\n",
            "Epoch 66/100 - 0.36s - loss: 1.0893 - acc: 0.3808 - val_loss: 1.0930 - val_acc: 0.3846\n",
            "Epoch 67/100 - 0.50s - loss: 1.0891 - acc: 0.3806 - val_loss: 1.0928 - val_acc: 0.3846\n",
            "Epoch 68/100 - 0.35s - loss: 1.0889 - acc: 0.3817 - val_loss: 1.0927 - val_acc: 0.3846\n",
            "Epoch 69/100 - 0.41s - loss: 1.0888 - acc: 0.3815 - val_loss: 1.0925 - val_acc: 0.3866\n",
            "Epoch 70/100 - 0.39s - loss: 1.0886 - acc: 0.3817 - val_loss: 1.0923 - val_acc: 0.3846\n",
            "Epoch 71/100 - 0.39s - loss: 1.0884 - acc: 0.3810 - val_loss: 1.0922 - val_acc: 0.3846\n",
            "Epoch 72/100 - 0.40s - loss: 1.0883 - acc: 0.3817 - val_loss: 1.0920 - val_acc: 0.3846\n",
            "Epoch 73/100 - 0.37s - loss: 1.0881 - acc: 0.3819 - val_loss: 1.0918 - val_acc: 0.3826\n",
            "Epoch 74/100 - 0.35s - loss: 1.0879 - acc: 0.3842 - val_loss: 1.0917 - val_acc: 0.3846\n",
            "Epoch 75/100 - 0.34s - loss: 1.0877 - acc: 0.3860 - val_loss: 1.0915 - val_acc: 0.3866\n",
            "Epoch 76/100 - 0.33s - loss: 1.0876 - acc: 0.3871 - val_loss: 1.0914 - val_acc: 0.3968\n",
            "Epoch 77/100 - 0.42s - loss: 1.0874 - acc: 0.3884 - val_loss: 1.0912 - val_acc: 0.3947\n",
            "Epoch 78/100 - 0.38s - loss: 1.0872 - acc: 0.3884 - val_loss: 1.0911 - val_acc: 0.3968\n",
            "Epoch 79/100 - 0.34s - loss: 1.0871 - acc: 0.3882 - val_loss: 1.0909 - val_acc: 0.3968\n",
            "Epoch 80/100 - 0.34s - loss: 1.0869 - acc: 0.3893 - val_loss: 1.0908 - val_acc: 0.4008\n",
            "Epoch 81/100 - 0.37s - loss: 1.0867 - acc: 0.3905 - val_loss: 1.0906 - val_acc: 0.4049\n",
            "Epoch 82/100 - 0.39s - loss: 1.0866 - acc: 0.3918 - val_loss: 1.0905 - val_acc: 0.4028\n",
            "Epoch 83/100 - 0.36s - loss: 1.0864 - acc: 0.3932 - val_loss: 1.0903 - val_acc: 0.4028\n",
            "Epoch 84/100 - 0.35s - loss: 1.0863 - acc: 0.3927 - val_loss: 1.0902 - val_acc: 0.4069\n",
            "Epoch 85/100 - 0.37s - loss: 1.0861 - acc: 0.3918 - val_loss: 1.0900 - val_acc: 0.4069\n",
            "Epoch 86/100 - 0.37s - loss: 1.0859 - acc: 0.3929 - val_loss: 1.0899 - val_acc: 0.4109\n",
            "Epoch 87/100 - 0.37s - loss: 1.0858 - acc: 0.3934 - val_loss: 1.0897 - val_acc: 0.4170\n",
            "Epoch 88/100 - 0.32s - loss: 1.0856 - acc: 0.3943 - val_loss: 1.0896 - val_acc: 0.4150\n",
            "Epoch 89/100 - 0.36s - loss: 1.0855 - acc: 0.3954 - val_loss: 1.0894 - val_acc: 0.4150\n",
            "Epoch 90/100 - 0.34s - loss: 1.0853 - acc: 0.3954 - val_loss: 1.0893 - val_acc: 0.4150\n",
            "Epoch 91/100 - 0.35s - loss: 1.0851 - acc: 0.3965 - val_loss: 1.0891 - val_acc: 0.4190\n",
            "Epoch 92/100 - 0.38s - loss: 1.0850 - acc: 0.3952 - val_loss: 1.0890 - val_acc: 0.4170\n",
            "Epoch 93/100 - 0.38s - loss: 1.0848 - acc: 0.3963 - val_loss: 1.0888 - val_acc: 0.4190\n",
            "Epoch 94/100 - 0.33s - loss: 1.0847 - acc: 0.3965 - val_loss: 1.0887 - val_acc: 0.4211\n",
            "Epoch 95/100 - 0.33s - loss: 1.0845 - acc: 0.3965 - val_loss: 1.0886 - val_acc: 0.4211\n",
            "Epoch 96/100 - 0.33s - loss: 1.0844 - acc: 0.3972 - val_loss: 1.0884 - val_acc: 0.4231\n",
            "Epoch 97/100 - 0.35s - loss: 1.0842 - acc: 0.3979 - val_loss: 1.0883 - val_acc: 0.4231\n",
            "Epoch 98/100 - 0.32s - loss: 1.0841 - acc: 0.3995 - val_loss: 1.0881 - val_acc: 0.4211\n",
            "Epoch 99/100 - 0.34s - loss: 1.0839 - acc: 0.4017 - val_loss: 1.0880 - val_acc: 0.4190\n",
            "Epoch 100/100 - 0.32s - loss: 1.0838 - acc: 0.4026 - val_loss: 1.0879 - val_acc: 0.4211\n",
            "\n",
            "Combination 234/252:\n",
            "Hidden Layers: [512, 256, 128], Activation: relu, Learning Rate: 0.0001, Batch Size: 64, Epochs: 150\n",
            "Epoch 1/150 - 0.33s - loss: 1.1179 - acc: 0.3360 - val_loss: 1.1071 - val_acc: 0.3543\n",
            "Epoch 2/150 - 0.39s - loss: 1.1160 - acc: 0.3336 - val_loss: 1.1055 - val_acc: 0.3522\n",
            "Epoch 3/150 - 0.35s - loss: 1.1143 - acc: 0.3356 - val_loss: 1.1040 - val_acc: 0.3563\n",
            "Epoch 4/150 - 0.39s - loss: 1.1129 - acc: 0.3367 - val_loss: 1.1028 - val_acc: 0.3522\n",
            "Epoch 5/150 - 0.36s - loss: 1.1115 - acc: 0.3378 - val_loss: 1.1017 - val_acc: 0.3522\n",
            "Epoch 6/150 - 0.33s - loss: 1.1104 - acc: 0.3351 - val_loss: 1.1008 - val_acc: 0.3563\n",
            "Epoch 7/150 - 0.34s - loss: 1.1093 - acc: 0.3322 - val_loss: 1.0999 - val_acc: 0.3583\n",
            "Epoch 8/150 - 0.34s - loss: 1.1084 - acc: 0.3336 - val_loss: 1.0992 - val_acc: 0.3684\n",
            "Epoch 9/150 - 0.39s - loss: 1.1075 - acc: 0.3320 - val_loss: 1.0985 - val_acc: 0.3664\n",
            "Epoch 10/150 - 0.37s - loss: 1.1068 - acc: 0.3329 - val_loss: 1.0979 - val_acc: 0.3765\n",
            "Epoch 11/150 - 0.35s - loss: 1.1061 - acc: 0.3282 - val_loss: 1.0973 - val_acc: 0.3785\n",
            "Epoch 12/150 - 0.32s - loss: 1.1055 - acc: 0.3277 - val_loss: 1.0969 - val_acc: 0.3765\n",
            "Epoch 13/150 - 0.33s - loss: 1.1049 - acc: 0.3268 - val_loss: 1.0965 - val_acc: 0.3866\n",
            "Epoch 14/150 - 0.32s - loss: 1.1044 - acc: 0.3255 - val_loss: 1.0961 - val_acc: 0.3826\n",
            "Epoch 15/150 - 0.34s - loss: 1.1039 - acc: 0.3300 - val_loss: 1.0957 - val_acc: 0.3826\n",
            "Epoch 16/150 - 0.47s - loss: 1.1035 - acc: 0.3331 - val_loss: 1.0954 - val_acc: 0.3806\n",
            "Epoch 17/150 - 0.36s - loss: 1.1031 - acc: 0.3333 - val_loss: 1.0951 - val_acc: 0.3887\n",
            "Epoch 18/150 - 0.34s - loss: 1.1027 - acc: 0.3324 - val_loss: 1.0948 - val_acc: 0.3806\n",
            "Epoch 19/150 - 0.34s - loss: 1.1023 - acc: 0.3365 - val_loss: 1.0946 - val_acc: 0.3806\n",
            "Epoch 20/150 - 0.32s - loss: 1.1020 - acc: 0.3399 - val_loss: 1.0944 - val_acc: 0.3684\n",
            "Epoch 21/150 - 0.36s - loss: 1.1017 - acc: 0.3408 - val_loss: 1.0941 - val_acc: 0.3725\n",
            "Epoch 22/150 - 0.33s - loss: 1.1014 - acc: 0.3390 - val_loss: 1.0939 - val_acc: 0.3664\n",
            "Epoch 23/150 - 0.36s - loss: 1.1011 - acc: 0.3399 - val_loss: 1.0937 - val_acc: 0.3603\n",
            "Epoch 24/150 - 0.33s - loss: 1.1008 - acc: 0.3365 - val_loss: 1.0935 - val_acc: 0.3644\n",
            "Epoch 25/150 - 0.33s - loss: 1.1006 - acc: 0.3372 - val_loss: 1.0934 - val_acc: 0.3745\n",
            "Epoch 26/150 - 0.35s - loss: 1.1003 - acc: 0.3396 - val_loss: 1.0932 - val_acc: 0.3745\n",
            "Epoch 27/150 - 0.36s - loss: 1.1001 - acc: 0.3432 - val_loss: 1.0930 - val_acc: 0.3684\n",
            "Epoch 28/150 - 0.33s - loss: 1.0998 - acc: 0.3446 - val_loss: 1.0929 - val_acc: 0.3704\n",
            "Epoch 29/150 - 0.32s - loss: 1.0996 - acc: 0.3457 - val_loss: 1.0927 - val_acc: 0.3725\n",
            "Epoch 30/150 - 0.32s - loss: 1.0994 - acc: 0.3471 - val_loss: 1.0926 - val_acc: 0.3765\n",
            "Epoch 31/150 - 0.33s - loss: 1.0992 - acc: 0.3486 - val_loss: 1.0924 - val_acc: 0.3806\n",
            "Epoch 32/150 - 0.32s - loss: 1.0989 - acc: 0.3552 - val_loss: 1.0923 - val_acc: 0.3826\n",
            "Epoch 33/150 - 0.35s - loss: 1.0987 - acc: 0.3561 - val_loss: 1.0921 - val_acc: 0.3785\n",
            "Epoch 34/150 - 0.32s - loss: 1.0985 - acc: 0.3554 - val_loss: 1.0920 - val_acc: 0.3785\n",
            "Epoch 35/150 - 0.35s - loss: 1.0983 - acc: 0.3570 - val_loss: 1.0918 - val_acc: 0.3806\n",
            "Epoch 36/150 - 0.33s - loss: 1.0981 - acc: 0.3578 - val_loss: 1.0917 - val_acc: 0.3785\n",
            "Epoch 37/150 - 0.34s - loss: 1.0979 - acc: 0.3590 - val_loss: 1.0916 - val_acc: 0.3826\n",
            "Epoch 38/150 - 0.31s - loss: 1.0977 - acc: 0.3603 - val_loss: 1.0914 - val_acc: 0.3846\n",
            "Epoch 39/150 - 0.37s - loss: 1.0975 - acc: 0.3612 - val_loss: 1.0913 - val_acc: 0.3826\n",
            "Epoch 40/150 - 0.33s - loss: 1.0973 - acc: 0.3635 - val_loss: 1.0912 - val_acc: 0.3846\n",
            "Epoch 41/150 - 0.33s - loss: 1.0971 - acc: 0.3653 - val_loss: 1.0910 - val_acc: 0.3887\n",
            "Epoch 42/150 - 0.32s - loss: 1.0969 - acc: 0.3671 - val_loss: 1.0909 - val_acc: 0.3927\n",
            "Epoch 43/150 - 0.34s - loss: 1.0968 - acc: 0.3673 - val_loss: 1.0907 - val_acc: 0.3947\n",
            "Epoch 44/150 - 0.34s - loss: 1.0966 - acc: 0.3677 - val_loss: 1.0906 - val_acc: 0.3947\n",
            "Epoch 45/150 - 0.38s - loss: 1.0964 - acc: 0.3675 - val_loss: 1.0905 - val_acc: 0.3968\n",
            "Epoch 46/150 - 0.33s - loss: 1.0962 - acc: 0.3680 - val_loss: 1.0904 - val_acc: 0.3968\n",
            "Epoch 47/150 - 0.33s - loss: 1.0960 - acc: 0.3682 - val_loss: 1.0902 - val_acc: 0.3988\n",
            "Epoch 48/150 - 0.33s - loss: 1.0958 - acc: 0.3695 - val_loss: 1.0901 - val_acc: 0.4028\n",
            "Epoch 49/150 - 0.36s - loss: 1.0956 - acc: 0.3713 - val_loss: 1.0900 - val_acc: 0.4008\n",
            "Epoch 50/150 - 0.34s - loss: 1.0954 - acc: 0.3725 - val_loss: 1.0898 - val_acc: 0.3988\n",
            "Epoch 51/150 - 0.35s - loss: 1.0953 - acc: 0.3736 - val_loss: 1.0897 - val_acc: 0.3988\n",
            "Epoch 52/150 - 0.32s - loss: 1.0951 - acc: 0.3738 - val_loss: 1.0896 - val_acc: 0.3988\n",
            "Epoch 53/150 - 0.34s - loss: 1.0949 - acc: 0.3754 - val_loss: 1.0895 - val_acc: 0.3968\n",
            "Epoch 54/150 - 0.33s - loss: 1.0947 - acc: 0.3747 - val_loss: 1.0893 - val_acc: 0.3968\n",
            "Epoch 55/150 - 0.33s - loss: 1.0945 - acc: 0.3738 - val_loss: 1.0892 - val_acc: 0.3947\n",
            "Epoch 56/150 - 0.31s - loss: 1.0944 - acc: 0.3752 - val_loss: 1.0891 - val_acc: 0.3947\n",
            "Epoch 57/150 - 0.32s - loss: 1.0942 - acc: 0.3763 - val_loss: 1.0889 - val_acc: 0.3907\n",
            "Epoch 58/150 - 0.34s - loss: 1.0940 - acc: 0.3763 - val_loss: 1.0888 - val_acc: 0.3907\n",
            "Epoch 59/150 - 0.32s - loss: 1.0938 - acc: 0.3779 - val_loss: 1.0887 - val_acc: 0.3907\n",
            "Epoch 60/150 - 0.32s - loss: 1.0936 - acc: 0.3783 - val_loss: 1.0886 - val_acc: 0.3927\n",
            "Epoch 61/150 - 0.34s - loss: 1.0935 - acc: 0.3781 - val_loss: 1.0885 - val_acc: 0.3927\n",
            "Epoch 62/150 - 0.32s - loss: 1.0933 - acc: 0.3783 - val_loss: 1.0883 - val_acc: 0.3947\n",
            "Epoch 63/150 - 0.34s - loss: 1.0931 - acc: 0.3788 - val_loss: 1.0882 - val_acc: 0.3947\n",
            "Epoch 64/150 - 0.33s - loss: 1.0929 - acc: 0.3794 - val_loss: 1.0881 - val_acc: 0.3947\n",
            "Epoch 65/150 - 0.32s - loss: 1.0928 - acc: 0.3790 - val_loss: 1.0880 - val_acc: 0.3968\n",
            "Epoch 66/150 - 0.33s - loss: 1.0926 - acc: 0.3803 - val_loss: 1.0879 - val_acc: 0.3968\n",
            "Epoch 67/150 - 0.33s - loss: 1.0924 - acc: 0.3815 - val_loss: 1.0877 - val_acc: 0.3988\n",
            "Epoch 68/150 - 0.32s - loss: 1.0922 - acc: 0.3821 - val_loss: 1.0876 - val_acc: 0.3988\n",
            "Epoch 69/150 - 0.35s - loss: 1.0921 - acc: 0.3824 - val_loss: 1.0875 - val_acc: 0.4008\n",
            "Epoch 70/150 - 0.33s - loss: 1.0919 - acc: 0.3824 - val_loss: 1.0874 - val_acc: 0.3988\n",
            "Epoch 71/150 - 0.34s - loss: 1.0917 - acc: 0.3826 - val_loss: 1.0873 - val_acc: 0.4028\n",
            "Epoch 72/150 - 0.31s - loss: 1.0916 - acc: 0.3830 - val_loss: 1.0872 - val_acc: 0.3988\n",
            "Epoch 73/150 - 0.34s - loss: 1.0914 - acc: 0.3833 - val_loss: 1.0870 - val_acc: 0.3988\n",
            "Epoch 74/150 - 0.33s - loss: 1.0912 - acc: 0.3830 - val_loss: 1.0869 - val_acc: 0.4008\n",
            "Epoch 75/150 - 0.36s - loss: 1.0910 - acc: 0.3830 - val_loss: 1.0868 - val_acc: 0.4028\n",
            "Epoch 76/150 - 0.33s - loss: 1.0909 - acc: 0.3830 - val_loss: 1.0867 - val_acc: 0.4049\n",
            "Epoch 77/150 - 0.34s - loss: 1.0907 - acc: 0.3833 - val_loss: 1.0866 - val_acc: 0.4069\n",
            "Epoch 78/150 - 0.34s - loss: 1.0905 - acc: 0.3842 - val_loss: 1.0865 - val_acc: 0.4089\n",
            "Epoch 79/150 - 0.33s - loss: 1.0904 - acc: 0.3853 - val_loss: 1.0864 - val_acc: 0.4089\n",
            "Epoch 80/150 - 0.31s - loss: 1.0902 - acc: 0.3857 - val_loss: 1.0862 - val_acc: 0.4089\n",
            "Epoch 81/150 - 0.34s - loss: 1.0900 - acc: 0.3855 - val_loss: 1.0861 - val_acc: 0.4150\n",
            "Epoch 82/150 - 0.32s - loss: 1.0899 - acc: 0.3866 - val_loss: 1.0860 - val_acc: 0.4170\n",
            "Epoch 83/150 - 0.36s - loss: 1.0897 - acc: 0.3862 - val_loss: 1.0859 - val_acc: 0.4170\n",
            "Epoch 84/150 - 0.33s - loss: 1.0895 - acc: 0.3871 - val_loss: 1.0858 - val_acc: 0.4170\n",
            "Epoch 85/150 - 0.33s - loss: 1.0894 - acc: 0.3871 - val_loss: 1.0857 - val_acc: 0.4170\n",
            "Epoch 86/150 - 0.31s - loss: 1.0892 - acc: 0.3873 - val_loss: 1.0855 - val_acc: 0.4170\n",
            "Epoch 87/150 - 0.35s - loss: 1.0890 - acc: 0.3884 - val_loss: 1.0854 - val_acc: 0.4170\n",
            "Epoch 88/150 - 0.33s - loss: 1.0889 - acc: 0.3882 - val_loss: 1.0853 - val_acc: 0.4170\n",
            "Epoch 89/150 - 0.34s - loss: 1.0887 - acc: 0.3887 - val_loss: 1.0852 - val_acc: 0.4170\n",
            "Epoch 90/150 - 0.32s - loss: 1.0886 - acc: 0.3889 - val_loss: 1.0851 - val_acc: 0.4170\n",
            "Epoch 91/150 - 0.34s - loss: 1.0884 - acc: 0.3907 - val_loss: 1.0850 - val_acc: 0.4190\n",
            "Epoch 92/150 - 0.33s - loss: 1.0882 - acc: 0.3916 - val_loss: 1.0849 - val_acc: 0.4190\n",
            "Epoch 93/150 - 0.34s - loss: 1.0881 - acc: 0.3918 - val_loss: 1.0848 - val_acc: 0.4170\n",
            "Epoch 94/150 - 0.34s - loss: 1.0879 - acc: 0.3923 - val_loss: 1.0846 - val_acc: 0.4170\n",
            "Epoch 95/150 - 0.35s - loss: 1.0878 - acc: 0.3916 - val_loss: 1.0845 - val_acc: 0.4150\n",
            "Epoch 96/150 - 0.34s - loss: 1.0876 - acc: 0.3923 - val_loss: 1.0844 - val_acc: 0.4150\n",
            "Epoch 97/150 - 0.35s - loss: 1.0874 - acc: 0.3934 - val_loss: 1.0843 - val_acc: 0.4130\n",
            "Epoch 98/150 - 0.35s - loss: 1.0873 - acc: 0.3947 - val_loss: 1.0842 - val_acc: 0.4150\n",
            "Epoch 99/150 - 0.36s - loss: 1.0871 - acc: 0.3952 - val_loss: 1.0841 - val_acc: 0.4130\n",
            "Epoch 100/150 - 0.35s - loss: 1.0870 - acc: 0.3950 - val_loss: 1.0840 - val_acc: 0.4130\n",
            "Epoch 101/150 - 0.34s - loss: 1.0868 - acc: 0.3959 - val_loss: 1.0839 - val_acc: 0.4109\n",
            "Epoch 102/150 - 0.35s - loss: 1.0867 - acc: 0.3954 - val_loss: 1.0838 - val_acc: 0.4109\n",
            "Epoch 103/150 - 0.38s - loss: 1.0865 - acc: 0.3972 - val_loss: 1.0837 - val_acc: 0.4109\n",
            "Epoch 104/150 - 0.37s - loss: 1.0864 - acc: 0.3972 - val_loss: 1.0836 - val_acc: 0.4130\n",
            "Epoch 105/150 - 0.50s - loss: 1.0862 - acc: 0.3970 - val_loss: 1.0835 - val_acc: 0.4130\n",
            "Epoch 106/150 - 0.40s - loss: 1.0861 - acc: 0.3977 - val_loss: 1.0834 - val_acc: 0.4150\n",
            "Epoch 107/150 - 0.44s - loss: 1.0859 - acc: 0.3986 - val_loss: 1.0833 - val_acc: 0.4150\n",
            "Epoch 108/150 - 0.39s - loss: 1.0858 - acc: 0.3995 - val_loss: 1.0832 - val_acc: 0.4150\n",
            "Epoch 109/150 - 0.38s - loss: 1.0856 - acc: 0.4006 - val_loss: 1.0830 - val_acc: 0.4150\n",
            "Epoch 110/150 - 0.36s - loss: 1.0855 - acc: 0.4010 - val_loss: 1.0829 - val_acc: 0.4130\n",
            "Epoch 111/150 - 0.35s - loss: 1.0853 - acc: 0.4015 - val_loss: 1.0828 - val_acc: 0.4089\n",
            "Epoch 112/150 - 0.35s - loss: 1.0852 - acc: 0.4019 - val_loss: 1.0827 - val_acc: 0.4089\n",
            "Epoch 113/150 - 0.35s - loss: 1.0850 - acc: 0.4031 - val_loss: 1.0826 - val_acc: 0.4109\n",
            "Epoch 114/150 - 0.33s - loss: 1.0849 - acc: 0.4024 - val_loss: 1.0825 - val_acc: 0.4130\n",
            "Epoch 115/150 - 0.34s - loss: 1.0847 - acc: 0.4026 - val_loss: 1.0824 - val_acc: 0.4130\n",
            "Epoch 116/150 - 0.36s - loss: 1.0846 - acc: 0.4031 - val_loss: 1.0823 - val_acc: 0.4130\n",
            "Epoch 117/150 - 0.33s - loss: 1.0844 - acc: 0.4033 - val_loss: 1.0822 - val_acc: 0.4130\n",
            "Epoch 118/150 - 0.33s - loss: 1.0843 - acc: 0.4051 - val_loss: 1.0821 - val_acc: 0.4130\n",
            "Epoch 119/150 - 0.34s - loss: 1.0842 - acc: 0.4055 - val_loss: 1.0820 - val_acc: 0.4150\n",
            "Epoch 120/150 - 0.34s - loss: 1.0840 - acc: 0.4060 - val_loss: 1.0819 - val_acc: 0.4211\n",
            "Epoch 121/150 - 0.35s - loss: 1.0839 - acc: 0.4058 - val_loss: 1.0818 - val_acc: 0.4211\n",
            "Epoch 122/150 - 0.33s - loss: 1.0837 - acc: 0.4067 - val_loss: 1.0817 - val_acc: 0.4211\n",
            "Epoch 123/150 - 0.34s - loss: 1.0836 - acc: 0.4080 - val_loss: 1.0816 - val_acc: 0.4190\n",
            "Epoch 124/150 - 0.37s - loss: 1.0834 - acc: 0.4094 - val_loss: 1.0815 - val_acc: 0.4211\n",
            "Epoch 125/150 - 0.36s - loss: 1.0833 - acc: 0.4098 - val_loss: 1.0815 - val_acc: 0.4211\n",
            "Epoch 126/150 - 0.33s - loss: 1.0832 - acc: 0.4100 - val_loss: 1.0814 - val_acc: 0.4211\n",
            "Epoch 127/150 - 0.35s - loss: 1.0830 - acc: 0.4100 - val_loss: 1.0813 - val_acc: 0.4211\n",
            "Epoch 128/150 - 0.33s - loss: 1.0829 - acc: 0.4109 - val_loss: 1.0812 - val_acc: 0.4211\n",
            "Epoch 129/150 - 0.43s - loss: 1.0827 - acc: 0.4116 - val_loss: 1.0811 - val_acc: 0.4251\n",
            "Epoch 130/150 - 0.36s - loss: 1.0826 - acc: 0.4125 - val_loss: 1.0810 - val_acc: 0.4251\n",
            "Epoch 131/150 - 0.34s - loss: 1.0825 - acc: 0.4130 - val_loss: 1.0809 - val_acc: 0.4251\n",
            "Epoch 132/150 - 0.33s - loss: 1.0823 - acc: 0.4123 - val_loss: 1.0808 - val_acc: 0.4271\n",
            "Epoch 133/150 - 0.39s - loss: 1.0822 - acc: 0.4136 - val_loss: 1.0807 - val_acc: 0.4271\n",
            "Epoch 134/150 - 0.35s - loss: 1.0821 - acc: 0.4152 - val_loss: 1.0806 - val_acc: 0.4271\n",
            "Epoch 135/150 - 0.36s - loss: 1.0819 - acc: 0.4152 - val_loss: 1.0805 - val_acc: 0.4271\n",
            "Epoch 136/150 - 0.33s - loss: 1.0818 - acc: 0.4148 - val_loss: 1.0804 - val_acc: 0.4271\n",
            "Epoch 137/150 - 0.35s - loss: 1.0816 - acc: 0.4154 - val_loss: 1.0803 - val_acc: 0.4291\n",
            "Epoch 138/150 - 0.34s - loss: 1.0815 - acc: 0.4161 - val_loss: 1.0802 - val_acc: 0.4312\n",
            "Epoch 139/150 - 0.35s - loss: 1.0814 - acc: 0.4168 - val_loss: 1.0801 - val_acc: 0.4312\n",
            "Epoch 140/150 - 0.36s - loss: 1.0812 - acc: 0.4168 - val_loss: 1.0800 - val_acc: 0.4291\n",
            "Epoch 141/150 - 0.36s - loss: 1.0811 - acc: 0.4172 - val_loss: 1.0799 - val_acc: 0.4312\n",
            "Epoch 142/150 - 0.34s - loss: 1.0810 - acc: 0.4177 - val_loss: 1.0798 - val_acc: 0.4312\n",
            "Epoch 143/150 - 0.37s - loss: 1.0809 - acc: 0.4181 - val_loss: 1.0797 - val_acc: 0.4291\n",
            "Epoch 144/150 - 0.35s - loss: 1.0807 - acc: 0.4195 - val_loss: 1.0796 - val_acc: 0.4291\n",
            "Epoch 145/150 - 0.36s - loss: 1.0806 - acc: 0.4199 - val_loss: 1.0795 - val_acc: 0.4312\n",
            "Epoch 146/150 - 0.37s - loss: 1.0805 - acc: 0.4208 - val_loss: 1.0795 - val_acc: 0.4312\n",
            "Epoch 147/150 - 0.36s - loss: 1.0803 - acc: 0.4204 - val_loss: 1.0794 - val_acc: 0.4352\n",
            "Epoch 148/150 - 0.34s - loss: 1.0802 - acc: 0.4211 - val_loss: 1.0793 - val_acc: 0.4352\n",
            "Epoch 149/150 - 0.36s - loss: 1.0801 - acc: 0.4202 - val_loss: 1.0792 - val_acc: 0.4352\n",
            "Epoch 150/150 - 0.35s - loss: 1.0799 - acc: 0.4197 - val_loss: 1.0791 - val_acc: 0.4352\n",
            "\n",
            "Combination 235/252:\n",
            "Hidden Layers: [512, 256, 128], Activation: tanh, Learning Rate: 0.01, Batch Size: 32, Epochs: 50\n",
            "Epoch 1/50 - 0.68s - loss: 1.0697 - acc: 0.4276 - val_loss: 1.0716 - val_acc: 0.4271\n",
            "Epoch 2/50 - 0.71s - loss: 1.0517 - acc: 0.4629 - val_loss: 1.0540 - val_acc: 0.4433\n",
            "Epoch 3/50 - 0.68s - loss: 1.0354 - acc: 0.4786 - val_loss: 1.0440 - val_acc: 0.4798\n",
            "Epoch 4/50 - 0.69s - loss: 1.0230 - acc: 0.4930 - val_loss: 1.0341 - val_acc: 0.5020\n",
            "Epoch 5/50 - 0.69s - loss: 1.0119 - acc: 0.5013 - val_loss: 1.0274 - val_acc: 0.5142\n",
            "Epoch 6/50 - 0.69s - loss: 1.0126 - acc: 0.4897 - val_loss: 1.0289 - val_acc: 0.5000\n",
            "Epoch 7/50 - 0.70s - loss: 0.9907 - acc: 0.5202 - val_loss: 1.0077 - val_acc: 0.5304\n",
            "Epoch 8/50 - 0.71s - loss: 0.9806 - acc: 0.5328 - val_loss: 0.9985 - val_acc: 0.5304\n",
            "Epoch 9/50 - 0.70s - loss: 0.9935 - acc: 0.4975 - val_loss: 1.0186 - val_acc: 0.4737\n",
            "Epoch 10/50 - 0.68s - loss: 0.9627 - acc: 0.5425 - val_loss: 0.9845 - val_acc: 0.5486\n",
            "Epoch 11/50 - 0.72s - loss: 0.9585 - acc: 0.5364 - val_loss: 0.9794 - val_acc: 0.5385\n",
            "Epoch 12/50 - 0.67s - loss: 0.9508 - acc: 0.5479 - val_loss: 0.9764 - val_acc: 0.5445\n",
            "Epoch 13/50 - 0.69s - loss: 0.9911 - acc: 0.5135 - val_loss: 1.0112 - val_acc: 0.5243\n",
            "Epoch 14/50 - 0.70s - loss: 0.9692 - acc: 0.5394 - val_loss: 0.9940 - val_acc: 0.5405\n",
            "Epoch 15/50 - 0.67s - loss: 0.9400 - acc: 0.5515 - val_loss: 0.9754 - val_acc: 0.5283\n",
            "Epoch 16/50 - 0.68s - loss: 0.9326 - acc: 0.5538 - val_loss: 0.9620 - val_acc: 0.5425\n",
            "Epoch 17/50 - 0.68s - loss: 0.9321 - acc: 0.5605 - val_loss: 0.9643 - val_acc: 0.5567\n",
            "Epoch 18/50 - 0.67s - loss: 0.9238 - acc: 0.5625 - val_loss: 0.9641 - val_acc: 0.5324\n",
            "Epoch 19/50 - 0.70s - loss: 0.9710 - acc: 0.5430 - val_loss: 1.0045 - val_acc: 0.5304\n",
            "Epoch 20/50 - 0.70s - loss: 0.9125 - acc: 0.5778 - val_loss: 0.9535 - val_acc: 0.5648\n",
            "Epoch 21/50 - 0.68s - loss: 0.9132 - acc: 0.5789 - val_loss: 0.9543 - val_acc: 0.5729\n",
            "Epoch 22/50 - 0.67s - loss: 0.9116 - acc: 0.5758 - val_loss: 0.9579 - val_acc: 0.5587\n",
            "Epoch 23/50 - 0.69s - loss: 0.9282 - acc: 0.5551 - val_loss: 0.9780 - val_acc: 0.5182\n",
            "Epoch 24/50 - 0.65s - loss: 0.9194 - acc: 0.5630 - val_loss: 0.9754 - val_acc: 0.5142\n",
            "Epoch 25/50 - 0.67s - loss: 0.9131 - acc: 0.5637 - val_loss: 0.9707 - val_acc: 0.5081\n",
            "Epoch 26/50 - 0.69s - loss: 0.9059 - acc: 0.5765 - val_loss: 0.9619 - val_acc: 0.5283\n",
            "Epoch 27/50 - 0.66s - loss: 0.8895 - acc: 0.5884 - val_loss: 0.9472 - val_acc: 0.5607\n",
            "Epoch 28/50 - 0.67s - loss: 0.9029 - acc: 0.5740 - val_loss: 0.9690 - val_acc: 0.5020\n",
            "Epoch 29/50 - 0.68s - loss: 0.9170 - acc: 0.5574 - val_loss: 0.9824 - val_acc: 0.5000\n",
            "Epoch 30/50 - 0.69s - loss: 0.8828 - acc: 0.5909 - val_loss: 0.9457 - val_acc: 0.5587\n",
            "Epoch 31/50 - 0.67s - loss: 0.8787 - acc: 0.5969 - val_loss: 0.9482 - val_acc: 0.5648\n",
            "Epoch 32/50 - 0.70s - loss: 0.8784 - acc: 0.6028 - val_loss: 0.9523 - val_acc: 0.5668\n",
            "Epoch 33/50 - 0.66s - loss: 0.8816 - acc: 0.5963 - val_loss: 0.9507 - val_acc: 0.5607\n",
            "Epoch 34/50 - 0.66s - loss: 0.8755 - acc: 0.5949 - val_loss: 0.9465 - val_acc: 0.5547\n",
            "Epoch 35/50 - 0.66s - loss: 0.8848 - acc: 0.5945 - val_loss: 0.9597 - val_acc: 0.5607\n",
            "Epoch 36/50 - 0.65s - loss: 0.8784 - acc: 0.5866 - val_loss: 0.9510 - val_acc: 0.5567\n",
            "Epoch 37/50 - 0.75s - loss: 0.8708 - acc: 0.5904 - val_loss: 0.9489 - val_acc: 0.5425\n",
            "Epoch 38/50 - 0.69s - loss: 0.8806 - acc: 0.5861 - val_loss: 0.9571 - val_acc: 0.5445\n",
            "Epoch 39/50 - 0.67s - loss: 0.9270 - acc: 0.5470 - val_loss: 1.0102 - val_acc: 0.5061\n",
            "Epoch 40/50 - 0.65s - loss: 0.8652 - acc: 0.6021 - val_loss: 0.9499 - val_acc: 0.5486\n",
            "Epoch 41/50 - 0.66s - loss: 0.8653 - acc: 0.5992 - val_loss: 0.9537 - val_acc: 0.5607\n",
            "Epoch 42/50 - 0.65s - loss: 0.8864 - acc: 0.5992 - val_loss: 0.9759 - val_acc: 0.5324\n",
            "Epoch 43/50 - 0.66s - loss: 0.8979 - acc: 0.5751 - val_loss: 0.9900 - val_acc: 0.5344\n",
            "Epoch 44/50 - 0.68s - loss: 0.8711 - acc: 0.5974 - val_loss: 0.9719 - val_acc: 0.5324\n",
            "Epoch 45/50 - 0.66s - loss: 0.8591 - acc: 0.6125 - val_loss: 0.9589 - val_acc: 0.5466\n",
            "Epoch 46/50 - 0.67s - loss: 0.8601 - acc: 0.6030 - val_loss: 0.9560 - val_acc: 0.5567\n",
            "Epoch 47/50 - 0.66s - loss: 0.8744 - acc: 0.5951 - val_loss: 0.9676 - val_acc: 0.5668\n",
            "Epoch 48/50 - 0.64s - loss: 0.8811 - acc: 0.5897 - val_loss: 0.9917 - val_acc: 0.5101\n",
            "Epoch 49/50 - 0.71s - loss: 0.9255 - acc: 0.5490 - val_loss: 1.0104 - val_acc: 0.5243\n",
            "Epoch 50/50 - 0.70s - loss: 0.8605 - acc: 0.6073 - val_loss: 0.9596 - val_acc: 0.5628\n",
            "\n",
            "Combination 236/252:\n",
            "Hidden Layers: [512, 256, 128], Activation: tanh, Learning Rate: 0.01, Batch Size: 32, Epochs: 100\n",
            "Epoch 1/100 - 0.66s - loss: 1.0753 - acc: 0.4424 - val_loss: 1.0801 - val_acc: 0.4211\n",
            "Epoch 2/100 - 0.66s - loss: 1.0567 - acc: 0.4672 - val_loss: 1.0667 - val_acc: 0.4312\n",
            "Epoch 3/100 - 0.68s - loss: 1.0437 - acc: 0.4876 - val_loss: 1.0571 - val_acc: 0.4615\n",
            "Epoch 4/100 - 0.70s - loss: 1.0286 - acc: 0.4975 - val_loss: 1.0458 - val_acc: 0.4899\n",
            "Epoch 5/100 - 0.66s - loss: 1.0235 - acc: 0.4883 - val_loss: 1.0412 - val_acc: 0.4798\n",
            "Epoch 6/100 - 0.68s - loss: 1.0074 - acc: 0.5130 - val_loss: 1.0289 - val_acc: 0.5142\n",
            "Epoch 7/100 - 0.65s - loss: 0.9947 - acc: 0.5241 - val_loss: 1.0197 - val_acc: 0.5344\n",
            "Epoch 8/100 - 0.68s - loss: 0.9907 - acc: 0.5139 - val_loss: 1.0172 - val_acc: 0.5000\n",
            "Epoch 9/100 - 0.65s - loss: 0.9756 - acc: 0.5349 - val_loss: 1.0033 - val_acc: 0.5405\n",
            "Epoch 10/100 - 0.67s - loss: 0.9683 - acc: 0.5394 - val_loss: 0.9954 - val_acc: 0.5445\n",
            "Epoch 11/100 - 0.66s - loss: 0.9730 - acc: 0.5355 - val_loss: 0.9992 - val_acc: 0.5385\n",
            "Epoch 12/100 - 0.66s - loss: 0.9640 - acc: 0.5324 - val_loss: 0.9989 - val_acc: 0.5182\n",
            "Epoch 13/100 - 0.67s - loss: 0.9507 - acc: 0.5427 - val_loss: 0.9818 - val_acc: 0.5364\n",
            "Epoch 14/100 - 0.67s - loss: 0.9590 - acc: 0.5452 - val_loss: 0.9898 - val_acc: 0.5445\n",
            "Epoch 15/100 - 0.66s - loss: 0.9376 - acc: 0.5531 - val_loss: 0.9740 - val_acc: 0.5526\n",
            "Epoch 16/100 - 0.64s - loss: 0.9315 - acc: 0.5598 - val_loss: 0.9670 - val_acc: 0.5769\n",
            "Epoch 17/100 - 0.64s - loss: 0.9598 - acc: 0.5499 - val_loss: 0.9936 - val_acc: 0.5324\n",
            "Epoch 18/100 - 0.66s - loss: 0.9220 - acc: 0.5655 - val_loss: 0.9622 - val_acc: 0.5729\n",
            "Epoch 19/100 - 0.67s - loss: 0.9223 - acc: 0.5711 - val_loss: 0.9596 - val_acc: 0.5668\n",
            "Epoch 20/100 - 0.64s - loss: 0.9359 - acc: 0.5619 - val_loss: 0.9758 - val_acc: 0.5628\n",
            "Epoch 21/100 - 0.64s - loss: 0.9251 - acc: 0.5596 - val_loss: 0.9733 - val_acc: 0.5304\n",
            "Epoch 22/100 - 0.64s - loss: 0.9087 - acc: 0.5767 - val_loss: 0.9575 - val_acc: 0.5567\n",
            "Epoch 23/100 - 0.65s - loss: 0.9073 - acc: 0.5738 - val_loss: 0.9546 - val_acc: 0.5567\n",
            "Epoch 24/100 - 0.66s - loss: 0.9142 - acc: 0.5684 - val_loss: 0.9687 - val_acc: 0.5405\n",
            "Epoch 25/100 - 0.64s - loss: 0.9526 - acc: 0.5292 - val_loss: 1.0041 - val_acc: 0.5020\n",
            "Epoch 26/100 - 0.63s - loss: 0.9151 - acc: 0.5695 - val_loss: 0.9648 - val_acc: 0.5607\n",
            "Epoch 27/100 - 0.65s - loss: 0.9191 - acc: 0.5619 - val_loss: 0.9695 - val_acc: 0.5486\n",
            "Epoch 28/100 - 0.63s - loss: 0.8928 - acc: 0.5888 - val_loss: 0.9574 - val_acc: 0.5547\n",
            "Epoch 29/100 - 0.65s - loss: 0.8900 - acc: 0.5825 - val_loss: 0.9542 - val_acc: 0.5364\n",
            "Epoch 30/100 - 0.66s - loss: 0.9043 - acc: 0.5825 - val_loss: 0.9706 - val_acc: 0.5506\n",
            "Epoch 31/100 - 0.65s - loss: 0.8828 - acc: 0.5882 - val_loss: 0.9476 - val_acc: 0.5648\n",
            "Epoch 32/100 - 0.67s - loss: 0.8850 - acc: 0.5904 - val_loss: 0.9574 - val_acc: 0.5466\n",
            "Epoch 33/100 - 0.64s - loss: 0.8782 - acc: 0.5918 - val_loss: 0.9471 - val_acc: 0.5526\n",
            "Epoch 34/100 - 0.63s - loss: 0.8844 - acc: 0.5837 - val_loss: 0.9543 - val_acc: 0.5648\n",
            "Epoch 35/100 - 0.74s - loss: 0.8792 - acc: 0.5879 - val_loss: 0.9524 - val_acc: 0.5445\n",
            "Epoch 36/100 - 0.72s - loss: 0.8878 - acc: 0.5920 - val_loss: 0.9656 - val_acc: 0.5567\n",
            "Epoch 37/100 - 0.72s - loss: 0.8867 - acc: 0.5902 - val_loss: 0.9630 - val_acc: 0.5526\n",
            "Epoch 38/100 - 0.66s - loss: 0.8765 - acc: 0.6012 - val_loss: 0.9610 - val_acc: 0.5628\n",
            "Epoch 39/100 - 0.71s - loss: 0.8744 - acc: 0.5967 - val_loss: 0.9615 - val_acc: 0.5223\n",
            "Epoch 40/100 - 0.66s - loss: 0.8667 - acc: 0.6035 - val_loss: 0.9523 - val_acc: 0.5547\n",
            "Epoch 41/100 - 0.77s - loss: 0.8998 - acc: 0.5785 - val_loss: 0.9814 - val_acc: 0.5344\n",
            "Epoch 42/100 - 0.69s - loss: 0.8726 - acc: 0.5918 - val_loss: 0.9583 - val_acc: 0.5385\n",
            "Epoch 43/100 - 0.67s - loss: 0.8862 - acc: 0.5747 - val_loss: 0.9714 - val_acc: 0.5486\n",
            "Epoch 44/100 - 0.67s - loss: 0.8653 - acc: 0.5990 - val_loss: 0.9572 - val_acc: 0.5304\n",
            "Epoch 45/100 - 0.71s - loss: 0.8575 - acc: 0.6107 - val_loss: 0.9516 - val_acc: 0.5628\n",
            "Epoch 46/100 - 0.66s - loss: 0.8607 - acc: 0.5999 - val_loss: 0.9554 - val_acc: 0.5547\n",
            "Epoch 47/100 - 0.68s - loss: 0.8677 - acc: 0.5929 - val_loss: 0.9667 - val_acc: 0.5283\n",
            "Epoch 48/100 - 0.67s - loss: 0.8638 - acc: 0.6077 - val_loss: 0.9691 - val_acc: 0.5385\n",
            "Epoch 49/100 - 0.67s - loss: 0.8548 - acc: 0.6131 - val_loss: 0.9555 - val_acc: 0.5668\n",
            "Epoch 50/100 - 0.72s - loss: 0.9085 - acc: 0.5679 - val_loss: 0.9961 - val_acc: 0.5445\n",
            "Epoch 51/100 - 0.72s - loss: 0.8720 - acc: 0.5940 - val_loss: 0.9779 - val_acc: 0.5283\n",
            "Epoch 52/100 - 0.70s - loss: 0.8530 - acc: 0.6122 - val_loss: 0.9578 - val_acc: 0.5445\n",
            "Epoch 53/100 - 0.73s - loss: 0.8643 - acc: 0.6010 - val_loss: 0.9649 - val_acc: 0.5587\n",
            "Epoch 54/100 - 0.70s - loss: 0.8572 - acc: 0.6077 - val_loss: 0.9625 - val_acc: 0.5283\n",
            "Epoch 55/100 - 0.66s - loss: 0.8540 - acc: 0.6095 - val_loss: 0.9630 - val_acc: 0.5344\n",
            "Epoch 56/100 - 0.66s - loss: 1.0906 - acc: 0.4802 - val_loss: 1.1712 - val_acc: 0.4636\n",
            "Epoch 57/100 - 0.69s - loss: 0.8629 - acc: 0.6026 - val_loss: 0.9792 - val_acc: 0.5283\n",
            "Epoch 58/100 - 0.70s - loss: 0.8522 - acc: 0.6111 - val_loss: 0.9683 - val_acc: 0.5466\n",
            "Epoch 59/100 - 0.66s - loss: 0.8548 - acc: 0.6116 - val_loss: 0.9704 - val_acc: 0.5506\n",
            "Epoch 60/100 - 0.67s - loss: 0.8496 - acc: 0.6091 - val_loss: 0.9610 - val_acc: 0.5526\n",
            "Epoch 61/100 - 0.67s - loss: 0.8659 - acc: 0.6080 - val_loss: 0.9755 - val_acc: 0.5587\n",
            "Epoch 62/100 - 0.66s - loss: 0.9239 - acc: 0.5700 - val_loss: 1.0266 - val_acc: 0.5364\n",
            "Epoch 63/100 - 0.66s - loss: 0.8648 - acc: 0.6032 - val_loss: 0.9873 - val_acc: 0.5324\n",
            "Epoch 64/100 - 0.66s - loss: 0.8658 - acc: 0.5956 - val_loss: 0.9805 - val_acc: 0.5263\n",
            "Epoch 65/100 - 0.68s - loss: 0.8472 - acc: 0.6093 - val_loss: 0.9639 - val_acc: 0.5486\n",
            "Epoch 66/100 - 0.71s - loss: 0.8619 - acc: 0.6044 - val_loss: 0.9863 - val_acc: 0.5283\n",
            "Epoch 67/100 - 0.70s - loss: 0.9443 - acc: 0.5562 - val_loss: 1.0433 - val_acc: 0.5223\n",
            "Epoch 68/100 - 0.78s - loss: 0.8483 - acc: 0.6098 - val_loss: 0.9676 - val_acc: 0.5425\n",
            "Epoch 69/100 - 0.71s - loss: 0.8422 - acc: 0.6197 - val_loss: 0.9616 - val_acc: 0.5526\n",
            "Epoch 70/100 - 0.69s - loss: 0.9450 - acc: 0.5387 - val_loss: 1.0437 - val_acc: 0.5162\n",
            "Epoch 71/100 - 0.66s - loss: 0.8416 - acc: 0.6140 - val_loss: 0.9619 - val_acc: 0.5486\n",
            "Epoch 72/100 - 0.71s - loss: 0.8448 - acc: 0.6174 - val_loss: 0.9604 - val_acc: 0.5466\n",
            "Epoch 73/100 - 0.66s - loss: 0.8558 - acc: 0.6084 - val_loss: 0.9835 - val_acc: 0.5385\n",
            "Epoch 74/100 - 0.65s - loss: 0.8469 - acc: 0.6197 - val_loss: 0.9768 - val_acc: 0.5425\n",
            "Epoch 75/100 - 0.67s - loss: 0.9103 - acc: 0.5771 - val_loss: 1.0177 - val_acc: 0.5344\n",
            "Epoch 76/100 - 0.76s - loss: 0.8743 - acc: 0.5938 - val_loss: 0.9838 - val_acc: 0.5466\n",
            "Epoch 77/100 - 0.76s - loss: 0.8423 - acc: 0.6194 - val_loss: 0.9612 - val_acc: 0.5749\n",
            "Epoch 78/100 - 0.74s - loss: 0.8587 - acc: 0.6012 - val_loss: 0.9775 - val_acc: 0.5364\n",
            "Epoch 79/100 - 0.68s - loss: 0.8369 - acc: 0.6237 - val_loss: 0.9608 - val_acc: 0.5688\n",
            "Epoch 80/100 - 0.68s - loss: 0.9138 - acc: 0.5614 - val_loss: 1.0496 - val_acc: 0.4879\n",
            "Epoch 81/100 - 0.80s - loss: 0.8352 - acc: 0.6221 - val_loss: 0.9602 - val_acc: 0.5668\n",
            "Epoch 82/100 - 0.73s - loss: 0.8717 - acc: 0.5967 - val_loss: 1.0037 - val_acc: 0.5162\n",
            "Epoch 83/100 - 0.67s - loss: 0.8734 - acc: 0.5929 - val_loss: 1.0099 - val_acc: 0.4879\n",
            "Epoch 84/100 - 0.78s - loss: 0.8372 - acc: 0.6228 - val_loss: 0.9718 - val_acc: 0.5628\n",
            "Epoch 85/100 - 0.68s - loss: 0.8727 - acc: 0.5947 - val_loss: 0.9930 - val_acc: 0.5324\n",
            "Epoch 86/100 - 0.68s - loss: 0.8431 - acc: 0.6185 - val_loss: 0.9663 - val_acc: 0.5709\n",
            "Epoch 87/100 - 0.66s - loss: 0.8405 - acc: 0.6154 - val_loss: 0.9724 - val_acc: 0.5445\n",
            "Epoch 88/100 - 0.69s - loss: 0.8569 - acc: 0.6118 - val_loss: 0.9866 - val_acc: 0.5425\n",
            "Epoch 89/100 - 0.66s - loss: 0.8696 - acc: 0.6010 - val_loss: 0.9978 - val_acc: 0.5324\n",
            "Epoch 90/100 - 0.69s - loss: 0.8334 - acc: 0.6309 - val_loss: 0.9601 - val_acc: 0.5587\n",
            "Epoch 91/100 - 0.68s - loss: 0.8337 - acc: 0.6264 - val_loss: 0.9620 - val_acc: 0.5668\n",
            "Epoch 92/100 - 0.71s - loss: 0.8786 - acc: 0.6003 - val_loss: 0.9995 - val_acc: 0.5547\n",
            "Epoch 93/100 - 0.79s - loss: 0.8329 - acc: 0.6221 - val_loss: 0.9645 - val_acc: 0.5789\n",
            "Epoch 94/100 - 0.78s - loss: 0.8438 - acc: 0.6163 - val_loss: 0.9816 - val_acc: 0.5425\n",
            "Epoch 95/100 - 0.79s - loss: 0.8736 - acc: 0.5958 - val_loss: 1.0152 - val_acc: 0.5243\n",
            "Epoch 96/100 - 0.74s - loss: 0.8464 - acc: 0.6199 - val_loss: 0.9824 - val_acc: 0.5506\n",
            "Epoch 97/100 - 0.69s - loss: 0.8313 - acc: 0.6221 - val_loss: 0.9613 - val_acc: 0.5688\n",
            "Epoch 98/100 - 0.65s - loss: 0.8729 - acc: 0.5942 - val_loss: 0.9974 - val_acc: 0.5344\n",
            "Epoch 99/100 - 0.65s - loss: 0.8528 - acc: 0.6005 - val_loss: 0.9833 - val_acc: 0.5304\n",
            "Epoch 100/100 - 0.63s - loss: 0.8384 - acc: 0.6233 - val_loss: 0.9738 - val_acc: 0.5526\n",
            "\n",
            "Combination 237/252:\n",
            "Hidden Layers: [512, 256, 128], Activation: tanh, Learning Rate: 0.01, Batch Size: 32, Epochs: 150\n",
            "Epoch 1/150 - 0.61s - loss: 1.0667 - acc: 0.4381 - val_loss: 1.0778 - val_acc: 0.4453\n",
            "Epoch 2/150 - 0.76s - loss: 1.0505 - acc: 0.4669 - val_loss: 1.0661 - val_acc: 0.4575\n",
            "Epoch 3/150 - 0.63s - loss: 1.0358 - acc: 0.4888 - val_loss: 1.0543 - val_acc: 0.4939\n",
            "Epoch 4/150 - 0.68s - loss: 1.0294 - acc: 0.4753 - val_loss: 1.0489 - val_acc: 0.4737\n",
            "Epoch 5/150 - 0.63s - loss: 1.0119 - acc: 0.5117 - val_loss: 1.0373 - val_acc: 0.5061\n",
            "Epoch 6/150 - 0.61s - loss: 1.0027 - acc: 0.5137 - val_loss: 1.0290 - val_acc: 0.5223\n",
            "Epoch 7/150 - 0.61s - loss: 0.9980 - acc: 0.5234 - val_loss: 1.0276 - val_acc: 0.5182\n",
            "Epoch 8/150 - 0.62s - loss: 0.9835 - acc: 0.5238 - val_loss: 1.0133 - val_acc: 0.5101\n",
            "Epoch 9/150 - 0.68s - loss: 0.9752 - acc: 0.5367 - val_loss: 1.0109 - val_acc: 0.5081\n",
            "Epoch 10/150 - 0.61s - loss: 0.9634 - acc: 0.5479 - val_loss: 0.9990 - val_acc: 0.5243\n",
            "Epoch 11/150 - 0.66s - loss: 0.9621 - acc: 0.5376 - val_loss: 0.9962 - val_acc: 0.5202\n",
            "Epoch 12/150 - 0.71s - loss: 0.9691 - acc: 0.5385 - val_loss: 1.0047 - val_acc: 0.5364\n",
            "Epoch 13/150 - 0.63s - loss: 0.9443 - acc: 0.5587 - val_loss: 0.9869 - val_acc: 0.5304\n",
            "Epoch 14/150 - 0.65s - loss: 0.9409 - acc: 0.5511 - val_loss: 0.9852 - val_acc: 0.5304\n",
            "Epoch 15/150 - 0.75s - loss: 0.9621 - acc: 0.5299 - val_loss: 1.0102 - val_acc: 0.4980\n",
            "Epoch 16/150 - 0.65s - loss: 0.9412 - acc: 0.5484 - val_loss: 0.9872 - val_acc: 0.5223\n",
            "Epoch 17/150 - 0.68s - loss: 0.9301 - acc: 0.5569 - val_loss: 0.9745 - val_acc: 0.5304\n",
            "Epoch 18/150 - 0.62s - loss: 0.9456 - acc: 0.5463 - val_loss: 0.9999 - val_acc: 0.4980\n",
            "Epoch 19/150 - 0.65s - loss: 0.9191 - acc: 0.5744 - val_loss: 0.9735 - val_acc: 0.5486\n",
            "Epoch 20/150 - 0.72s - loss: 0.9144 - acc: 0.5677 - val_loss: 0.9688 - val_acc: 0.5486\n",
            "Epoch 21/150 - 0.64s - loss: 0.9192 - acc: 0.5607 - val_loss: 0.9764 - val_acc: 0.5283\n",
            "Epoch 22/150 - 0.66s - loss: 0.9179 - acc: 0.5756 - val_loss: 0.9739 - val_acc: 0.5628\n",
            "Epoch 23/150 - 0.67s - loss: 0.9023 - acc: 0.5762 - val_loss: 0.9620 - val_acc: 0.5587\n",
            "Epoch 24/150 - 0.68s - loss: 0.9041 - acc: 0.5758 - val_loss: 0.9681 - val_acc: 0.5344\n",
            "Epoch 25/150 - 0.62s - loss: 0.9132 - acc: 0.5796 - val_loss: 0.9762 - val_acc: 0.5567\n",
            "Epoch 26/150 - 0.68s - loss: 0.9007 - acc: 0.5859 - val_loss: 0.9646 - val_acc: 0.5628\n",
            "Epoch 27/150 - 0.62s - loss: 0.9065 - acc: 0.5846 - val_loss: 0.9717 - val_acc: 0.5567\n",
            "Epoch 28/150 - 0.62s - loss: 0.9551 - acc: 0.5328 - val_loss: 1.0339 - val_acc: 0.4858\n",
            "Epoch 29/150 - 0.63s - loss: 0.8965 - acc: 0.5886 - val_loss: 0.9678 - val_acc: 0.5628\n",
            "Epoch 30/150 - 0.61s - loss: 0.8920 - acc: 0.5767 - val_loss: 0.9608 - val_acc: 0.5445\n",
            "Epoch 31/150 - 0.65s - loss: 0.8886 - acc: 0.5900 - val_loss: 0.9641 - val_acc: 0.5587\n",
            "Epoch 32/150 - 0.71s - loss: 0.9180 - acc: 0.5565 - val_loss: 0.9978 - val_acc: 0.5101\n",
            "Epoch 33/150 - 0.66s - loss: 0.8939 - acc: 0.5729 - val_loss: 0.9698 - val_acc: 0.5324\n",
            "Epoch 34/150 - 0.62s - loss: 0.9268 - acc: 0.5704 - val_loss: 1.0031 - val_acc: 0.5364\n",
            "Epoch 35/150 - 0.72s - loss: 0.8972 - acc: 0.5812 - val_loss: 0.9817 - val_acc: 0.5486\n",
            "Epoch 36/150 - 0.63s - loss: 0.9547 - acc: 0.5342 - val_loss: 1.0503 - val_acc: 0.4676\n",
            "Epoch 37/150 - 0.64s - loss: 0.8783 - acc: 0.5877 - val_loss: 0.9637 - val_acc: 0.5587\n",
            "Epoch 38/150 - 0.66s - loss: 0.8752 - acc: 0.5882 - val_loss: 0.9626 - val_acc: 0.5506\n",
            "Epoch 39/150 - 0.66s - loss: 0.8786 - acc: 0.5882 - val_loss: 0.9684 - val_acc: 0.5283\n",
            "Epoch 40/150 - 0.62s - loss: 0.8746 - acc: 0.5879 - val_loss: 0.9694 - val_acc: 0.5304\n",
            "Epoch 41/150 - 0.66s - loss: 0.8698 - acc: 0.5938 - val_loss: 0.9660 - val_acc: 0.5324\n",
            "Epoch 42/150 - 0.66s - loss: 0.8769 - acc: 0.5902 - val_loss: 0.9765 - val_acc: 0.5202\n",
            "Epoch 43/150 - 0.65s - loss: 0.8775 - acc: 0.5857 - val_loss: 0.9705 - val_acc: 0.5425\n",
            "Epoch 44/150 - 0.77s - loss: 0.8606 - acc: 0.5992 - val_loss: 0.9576 - val_acc: 0.5466\n",
            "Epoch 45/150 - 0.72s - loss: 0.8997 - acc: 0.5650 - val_loss: 1.0033 - val_acc: 0.5040\n",
            "Epoch 46/150 - 0.68s - loss: 0.8612 - acc: 0.6102 - val_loss: 0.9600 - val_acc: 0.5466\n",
            "Epoch 47/150 - 0.75s - loss: 0.8605 - acc: 0.6019 - val_loss: 0.9647 - val_acc: 0.5243\n",
            "Epoch 48/150 - 0.68s - loss: 0.9050 - acc: 0.5661 - val_loss: 1.0156 - val_acc: 0.4879\n",
            "Epoch 49/150 - 0.69s - loss: 0.8969 - acc: 0.5778 - val_loss: 1.0120 - val_acc: 0.4939\n",
            "Epoch 50/150 - 0.68s - loss: 0.8603 - acc: 0.6091 - val_loss: 0.9680 - val_acc: 0.5506\n",
            "Epoch 51/150 - 0.65s - loss: 0.8541 - acc: 0.6032 - val_loss: 0.9582 - val_acc: 0.5506\n",
            "Epoch 52/150 - 0.63s - loss: 0.9224 - acc: 0.5574 - val_loss: 1.0184 - val_acc: 0.5162\n",
            "Epoch 53/150 - 0.64s - loss: 0.8773 - acc: 0.5884 - val_loss: 0.9922 - val_acc: 0.5101\n",
            "Epoch 54/150 - 0.62s - loss: 0.8600 - acc: 0.5994 - val_loss: 0.9644 - val_acc: 0.5567\n",
            "Epoch 55/150 - 0.62s - loss: 0.8732 - acc: 0.5983 - val_loss: 0.9785 - val_acc: 0.5506\n",
            "Epoch 56/150 - 0.63s - loss: 0.9009 - acc: 0.5866 - val_loss: 1.0058 - val_acc: 0.5344\n",
            "Epoch 57/150 - 0.62s - loss: 0.9013 - acc: 0.5747 - val_loss: 1.0255 - val_acc: 0.4879\n",
            "Epoch 58/150 - 0.62s - loss: 0.8841 - acc: 0.5994 - val_loss: 0.9952 - val_acc: 0.5405\n",
            "Epoch 59/150 - 0.61s - loss: 0.8729 - acc: 0.5967 - val_loss: 0.9943 - val_acc: 0.5202\n",
            "Epoch 60/150 - 0.60s - loss: 0.8934 - acc: 0.5864 - val_loss: 1.0071 - val_acc: 0.5324\n",
            "Epoch 61/150 - 0.62s - loss: 0.8632 - acc: 0.6046 - val_loss: 0.9862 - val_acc: 0.5223\n",
            "Epoch 62/150 - 0.64s - loss: 0.8556 - acc: 0.6104 - val_loss: 0.9653 - val_acc: 0.5628\n",
            "Epoch 63/150 - 0.60s - loss: 0.8702 - acc: 0.5886 - val_loss: 0.9764 - val_acc: 0.5648\n",
            "Epoch 64/150 - 0.59s - loss: 0.8741 - acc: 0.5873 - val_loss: 0.9942 - val_acc: 0.5061\n",
            "Epoch 65/150 - 0.63s - loss: 0.8567 - acc: 0.6023 - val_loss: 0.9771 - val_acc: 0.5283\n",
            "Epoch 66/150 - 0.61s - loss: 0.8792 - acc: 0.5940 - val_loss: 0.9884 - val_acc: 0.5547\n",
            "Epoch 67/150 - 0.67s - loss: 0.8458 - acc: 0.6163 - val_loss: 0.9601 - val_acc: 0.5587\n",
            "Epoch 68/150 - 0.66s - loss: 0.8511 - acc: 0.6046 - val_loss: 0.9737 - val_acc: 0.5324\n",
            "Epoch 69/150 - 0.63s - loss: 0.8622 - acc: 0.5967 - val_loss: 0.9750 - val_acc: 0.5709\n",
            "Epoch 70/150 - 0.62s - loss: 0.8808 - acc: 0.5879 - val_loss: 1.0095 - val_acc: 0.5101\n",
            "Epoch 71/150 - 0.70s - loss: 0.8548 - acc: 0.6014 - val_loss: 0.9750 - val_acc: 0.5547\n",
            "Epoch 72/150 - 0.62s - loss: 0.8403 - acc: 0.6122 - val_loss: 0.9630 - val_acc: 0.5506\n",
            "Epoch 73/150 - 0.66s - loss: 1.0131 - acc: 0.5072 - val_loss: 1.1538 - val_acc: 0.4453\n",
            "Epoch 74/150 - 0.69s - loss: 0.8451 - acc: 0.6199 - val_loss: 0.9653 - val_acc: 0.5567\n",
            "Epoch 75/150 - 0.66s - loss: 0.8482 - acc: 0.6208 - val_loss: 0.9720 - val_acc: 0.5668\n",
            "Epoch 76/150 - 0.65s - loss: 0.8385 - acc: 0.6208 - val_loss: 0.9611 - val_acc: 0.5688\n",
            "Epoch 77/150 - 0.63s - loss: 0.8623 - acc: 0.5969 - val_loss: 0.9964 - val_acc: 0.5202\n",
            "Epoch 78/150 - 0.67s - loss: 0.8436 - acc: 0.6143 - val_loss: 0.9668 - val_acc: 0.5547\n",
            "Epoch 79/150 - 0.68s - loss: 0.8388 - acc: 0.6158 - val_loss: 0.9676 - val_acc: 0.5506\n",
            "Epoch 80/150 - 0.65s - loss: 0.8953 - acc: 0.5848 - val_loss: 1.0094 - val_acc: 0.5344\n",
            "Epoch 81/150 - 0.63s - loss: 0.8387 - acc: 0.6158 - val_loss: 0.9719 - val_acc: 0.5486\n",
            "Epoch 82/150 - 0.63s - loss: 0.8660 - acc: 0.5897 - val_loss: 0.9924 - val_acc: 0.5223\n",
            "Epoch 83/150 - 0.65s - loss: 0.8450 - acc: 0.6161 - val_loss: 0.9820 - val_acc: 0.5385\n",
            "Epoch 84/150 - 0.62s - loss: 0.8456 - acc: 0.6147 - val_loss: 0.9711 - val_acc: 0.5466\n",
            "Epoch 85/150 - 0.65s - loss: 0.8690 - acc: 0.5958 - val_loss: 1.0047 - val_acc: 0.5283\n",
            "Epoch 86/150 - 0.63s - loss: 0.8347 - acc: 0.6212 - val_loss: 0.9681 - val_acc: 0.5526\n",
            "Epoch 87/150 - 0.62s - loss: 0.8402 - acc: 0.6246 - val_loss: 0.9683 - val_acc: 0.5648\n",
            "Epoch 88/150 - 0.61s - loss: 0.8431 - acc: 0.6118 - val_loss: 0.9704 - val_acc: 0.5466\n",
            "Epoch 89/150 - 0.63s - loss: 0.8596 - acc: 0.5958 - val_loss: 0.9812 - val_acc: 0.5567\n",
            "Epoch 90/150 - 0.63s - loss: 0.8399 - acc: 0.6156 - val_loss: 0.9782 - val_acc: 0.5425\n",
            "Epoch 91/150 - 0.62s - loss: 0.8484 - acc: 0.6120 - val_loss: 0.9753 - val_acc: 0.5526\n",
            "Epoch 92/150 - 0.65s - loss: 0.8789 - acc: 0.5783 - val_loss: 0.9984 - val_acc: 0.5405\n",
            "Epoch 93/150 - 0.62s - loss: 0.8429 - acc: 0.6093 - val_loss: 0.9740 - val_acc: 0.5324\n",
            "Epoch 94/150 - 0.62s - loss: 0.8841 - acc: 0.5866 - val_loss: 1.0352 - val_acc: 0.4980\n",
            "Epoch 95/150 - 0.61s - loss: 0.8510 - acc: 0.6185 - val_loss: 0.9937 - val_acc: 0.5324\n",
            "Epoch 96/150 - 0.60s - loss: 0.8483 - acc: 0.6260 - val_loss: 0.9857 - val_acc: 0.5547\n",
            "Epoch 97/150 - 0.62s - loss: 0.8754 - acc: 0.5904 - val_loss: 1.0151 - val_acc: 0.5040\n",
            "Epoch 98/150 - 0.63s - loss: 0.8657 - acc: 0.6082 - val_loss: 1.0013 - val_acc: 0.5364\n",
            "Epoch 99/150 - 0.72s - loss: 0.8299 - acc: 0.6280 - val_loss: 0.9661 - val_acc: 0.5547\n",
            "Epoch 100/150 - 0.64s - loss: 0.8656 - acc: 0.5918 - val_loss: 1.0074 - val_acc: 0.5101\n",
            "Epoch 101/150 - 0.62s - loss: 0.8286 - acc: 0.6242 - val_loss: 0.9704 - val_acc: 0.5526\n",
            "Epoch 102/150 - 0.67s - loss: 0.8313 - acc: 0.6206 - val_loss: 0.9648 - val_acc: 0.5587\n",
            "Epoch 103/150 - 0.75s - loss: 0.8361 - acc: 0.6192 - val_loss: 0.9818 - val_acc: 0.5405\n",
            "Epoch 104/150 - 0.76s - loss: 0.8480 - acc: 0.6012 - val_loss: 0.9808 - val_acc: 0.5486\n",
            "Epoch 105/150 - 0.71s - loss: 0.8338 - acc: 0.6300 - val_loss: 0.9788 - val_acc: 0.5506\n",
            "Epoch 106/150 - 0.69s - loss: 0.8729 - acc: 0.5855 - val_loss: 1.0055 - val_acc: 0.5324\n",
            "Epoch 107/150 - 0.69s - loss: 0.8294 - acc: 0.6320 - val_loss: 0.9688 - val_acc: 0.5567\n",
            "Epoch 108/150 - 0.69s - loss: 0.8299 - acc: 0.6327 - val_loss: 0.9667 - val_acc: 0.5648\n",
            "Epoch 109/150 - 0.65s - loss: 0.8411 - acc: 0.6152 - val_loss: 0.9720 - val_acc: 0.5445\n",
            "Epoch 110/150 - 0.71s - loss: 0.8253 - acc: 0.6262 - val_loss: 0.9647 - val_acc: 0.5506\n",
            "Epoch 111/150 - 0.73s - loss: 0.8280 - acc: 0.6219 - val_loss: 0.9740 - val_acc: 0.5425\n",
            "Epoch 112/150 - 0.66s - loss: 0.8265 - acc: 0.6320 - val_loss: 0.9655 - val_acc: 0.5648\n",
            "Epoch 113/150 - 0.66s - loss: 0.8447 - acc: 0.6206 - val_loss: 0.9971 - val_acc: 0.5344\n",
            "Epoch 114/150 - 0.67s - loss: 0.8236 - acc: 0.6311 - val_loss: 0.9622 - val_acc: 0.5526\n",
            "Epoch 115/150 - 0.77s - loss: 0.8204 - acc: 0.6329 - val_loss: 0.9668 - val_acc: 0.5506\n",
            "Epoch 116/150 - 0.76s - loss: 0.8617 - acc: 0.6095 - val_loss: 0.9973 - val_acc: 0.5628\n",
            "Epoch 117/150 - 0.69s - loss: 0.8224 - acc: 0.6298 - val_loss: 0.9674 - val_acc: 0.5607\n",
            "Epoch 118/150 - 0.66s - loss: 0.8198 - acc: 0.6325 - val_loss: 0.9638 - val_acc: 0.5506\n",
            "Epoch 119/150 - 0.67s - loss: 0.8385 - acc: 0.6136 - val_loss: 0.9964 - val_acc: 0.5182\n",
            "Epoch 120/150 - 0.68s - loss: 0.8528 - acc: 0.5981 - val_loss: 0.9917 - val_acc: 0.5385\n",
            "Epoch 121/150 - 0.68s - loss: 0.8302 - acc: 0.6260 - val_loss: 0.9834 - val_acc: 0.5466\n",
            "Epoch 122/150 - 0.67s - loss: 0.8188 - acc: 0.6307 - val_loss: 0.9698 - val_acc: 0.5486\n",
            "Epoch 123/150 - 0.65s - loss: 0.8177 - acc: 0.6345 - val_loss: 0.9695 - val_acc: 0.5607\n",
            "Epoch 124/150 - 0.69s - loss: 0.8383 - acc: 0.6215 - val_loss: 0.9796 - val_acc: 0.5607\n",
            "Epoch 125/150 - 0.75s - loss: 0.8393 - acc: 0.6221 - val_loss: 0.9963 - val_acc: 0.5304\n",
            "Epoch 126/150 - 0.67s - loss: 0.8456 - acc: 0.6035 - val_loss: 0.9871 - val_acc: 0.5486\n",
            "Epoch 127/150 - 0.66s - loss: 0.8149 - acc: 0.6345 - val_loss: 0.9682 - val_acc: 0.5567\n",
            "Epoch 128/150 - 0.76s - loss: 0.8196 - acc: 0.6361 - val_loss: 0.9723 - val_acc: 0.5607\n",
            "Epoch 129/150 - 0.73s - loss: 0.8309 - acc: 0.6282 - val_loss: 0.9893 - val_acc: 0.5364\n",
            "Epoch 130/150 - 0.78s - loss: 0.8395 - acc: 0.6095 - val_loss: 1.0029 - val_acc: 0.5243\n",
            "Epoch 131/150 - 0.70s - loss: 0.8271 - acc: 0.6327 - val_loss: 0.9757 - val_acc: 0.5607\n",
            "Epoch 132/150 - 0.66s - loss: 0.8323 - acc: 0.6140 - val_loss: 0.9838 - val_acc: 0.5526\n",
            "Epoch 133/150 - 0.67s - loss: 0.8356 - acc: 0.6138 - val_loss: 1.0048 - val_acc: 0.5283\n",
            "Epoch 134/150 - 0.69s - loss: 0.8111 - acc: 0.6383 - val_loss: 0.9660 - val_acc: 0.5648\n",
            "Epoch 135/150 - 0.66s - loss: 0.8325 - acc: 0.6280 - val_loss: 0.9915 - val_acc: 0.5466\n",
            "Epoch 136/150 - 0.63s - loss: 0.8453 - acc: 0.6084 - val_loss: 1.0136 - val_acc: 0.5162\n",
            "Epoch 137/150 - 0.63s - loss: 0.8440 - acc: 0.6003 - val_loss: 0.9842 - val_acc: 0.5405\n",
            "Epoch 138/150 - 0.64s - loss: 0.8177 - acc: 0.6309 - val_loss: 0.9788 - val_acc: 0.5688\n",
            "Epoch 139/150 - 0.65s - loss: 0.8126 - acc: 0.6401 - val_loss: 0.9701 - val_acc: 0.5587\n",
            "Epoch 140/150 - 0.66s - loss: 0.8222 - acc: 0.6298 - val_loss: 0.9960 - val_acc: 0.5385\n",
            "Epoch 141/150 - 0.62s - loss: 0.8205 - acc: 0.6309 - val_loss: 0.9750 - val_acc: 0.5385\n",
            "Epoch 142/150 - 0.61s - loss: 0.8205 - acc: 0.6192 - val_loss: 0.9779 - val_acc: 0.5445\n",
            "Epoch 143/150 - 0.65s - loss: 0.8162 - acc: 0.6383 - val_loss: 0.9754 - val_acc: 0.5506\n",
            "Epoch 144/150 - 0.63s - loss: 0.8115 - acc: 0.6318 - val_loss: 0.9741 - val_acc: 0.5466\n",
            "Epoch 145/150 - 0.63s - loss: 0.8082 - acc: 0.6446 - val_loss: 0.9733 - val_acc: 0.5587\n",
            "Epoch 146/150 - 0.66s - loss: 0.8465 - acc: 0.6095 - val_loss: 1.0235 - val_acc: 0.5142\n",
            "Epoch 147/150 - 0.64s - loss: 0.8045 - acc: 0.6446 - val_loss: 0.9691 - val_acc: 0.5547\n",
            "Epoch 148/150 - 0.65s - loss: 0.8181 - acc: 0.6266 - val_loss: 0.9916 - val_acc: 0.5445\n",
            "Epoch 149/150 - 0.64s - loss: 0.8123 - acc: 0.6296 - val_loss: 0.9795 - val_acc: 0.5506\n",
            "Epoch 150/150 - 0.64s - loss: 0.8052 - acc: 0.6406 - val_loss: 0.9721 - val_acc: 0.5567\n",
            "\n",
            "Combination 238/252:\n",
            "Hidden Layers: [512, 256, 128], Activation: tanh, Learning Rate: 0.01, Batch Size: 64, Epochs: 50\n",
            "Epoch 1/50 - 0.46s - loss: 1.0854 - acc: 0.4345 - val_loss: 1.0869 - val_acc: 0.4190\n",
            "Epoch 2/50 - 0.45s - loss: 1.0762 - acc: 0.3749 - val_loss: 1.0813 - val_acc: 0.3785\n",
            "Epoch 3/50 - 0.46s - loss: 1.0596 - acc: 0.4649 - val_loss: 1.0682 - val_acc: 0.4312\n",
            "Epoch 4/50 - 0.48s - loss: 1.0498 - acc: 0.4861 - val_loss: 1.0601 - val_acc: 0.4474\n",
            "Epoch 5/50 - 0.46s - loss: 1.0439 - acc: 0.4816 - val_loss: 1.0576 - val_acc: 0.4413\n",
            "Epoch 6/50 - 0.45s - loss: 1.0348 - acc: 0.4908 - val_loss: 1.0493 - val_acc: 0.4696\n",
            "Epoch 7/50 - 0.48s - loss: 1.0293 - acc: 0.4989 - val_loss: 1.0460 - val_acc: 0.4717\n",
            "Epoch 8/50 - 0.47s - loss: 1.0247 - acc: 0.4872 - val_loss: 1.0412 - val_acc: 0.4737\n",
            "Epoch 9/50 - 0.45s - loss: 1.0204 - acc: 0.4865 - val_loss: 1.0413 - val_acc: 0.4777\n",
            "Epoch 10/50 - 0.44s - loss: 1.0120 - acc: 0.5103 - val_loss: 1.0357 - val_acc: 0.4919\n",
            "Epoch 11/50 - 0.47s - loss: 1.0094 - acc: 0.5058 - val_loss: 1.0349 - val_acc: 0.4737\n",
            "Epoch 12/50 - 0.46s - loss: 1.0016 - acc: 0.5101 - val_loss: 1.0283 - val_acc: 0.5000\n",
            "Epoch 13/50 - 0.45s - loss: 0.9983 - acc: 0.5101 - val_loss: 1.0230 - val_acc: 0.5101\n",
            "Epoch 14/50 - 0.46s - loss: 0.9900 - acc: 0.5200 - val_loss: 1.0164 - val_acc: 0.5223\n",
            "Epoch 15/50 - 0.46s - loss: 0.9832 - acc: 0.5313 - val_loss: 1.0140 - val_acc: 0.5101\n",
            "Epoch 16/50 - 0.45s - loss: 0.9803 - acc: 0.5250 - val_loss: 1.0083 - val_acc: 0.5243\n",
            "Epoch 17/50 - 0.46s - loss: 0.9720 - acc: 0.5299 - val_loss: 1.0020 - val_acc: 0.5283\n",
            "Epoch 18/50 - 0.46s - loss: 0.9757 - acc: 0.5324 - val_loss: 1.0101 - val_acc: 0.5162\n",
            "Epoch 19/50 - 0.45s - loss: 0.9673 - acc: 0.5319 - val_loss: 0.9974 - val_acc: 0.5243\n",
            "Epoch 20/50 - 0.47s - loss: 0.9593 - acc: 0.5423 - val_loss: 0.9914 - val_acc: 0.5445\n",
            "Epoch 21/50 - 0.45s - loss: 0.9609 - acc: 0.5421 - val_loss: 0.9933 - val_acc: 0.5526\n",
            "Epoch 22/50 - 0.45s - loss: 0.9516 - acc: 0.5495 - val_loss: 0.9872 - val_acc: 0.5324\n",
            "Epoch 23/50 - 0.45s - loss: 0.9522 - acc: 0.5479 - val_loss: 0.9861 - val_acc: 0.5506\n",
            "Epoch 24/50 - 0.45s - loss: 0.9447 - acc: 0.5515 - val_loss: 0.9807 - val_acc: 0.5364\n",
            "Epoch 25/50 - 0.46s - loss: 0.9490 - acc: 0.5529 - val_loss: 0.9865 - val_acc: 0.5547\n",
            "Epoch 26/50 - 0.44s - loss: 0.9373 - acc: 0.5585 - val_loss: 0.9761 - val_acc: 0.5526\n",
            "Epoch 27/50 - 0.44s - loss: 0.9368 - acc: 0.5542 - val_loss: 0.9760 - val_acc: 0.5628\n",
            "Epoch 28/50 - 0.44s - loss: 0.9342 - acc: 0.5601 - val_loss: 0.9758 - val_acc: 0.5364\n",
            "Epoch 29/50 - 0.45s - loss: 0.9297 - acc: 0.5655 - val_loss: 0.9723 - val_acc: 0.5425\n",
            "Epoch 30/50 - 0.47s - loss: 0.9415 - acc: 0.5425 - val_loss: 0.9834 - val_acc: 0.5324\n",
            "Epoch 31/50 - 0.45s - loss: 0.9452 - acc: 0.5457 - val_loss: 0.9932 - val_acc: 0.5081\n",
            "Epoch 32/50 - 0.46s - loss: 0.9267 - acc: 0.5603 - val_loss: 0.9735 - val_acc: 0.5405\n",
            "Epoch 33/50 - 0.45s - loss: 0.9416 - acc: 0.5475 - val_loss: 0.9826 - val_acc: 0.5425\n",
            "Epoch 34/50 - 0.46s - loss: 0.9170 - acc: 0.5729 - val_loss: 0.9640 - val_acc: 0.5648\n",
            "Epoch 35/50 - 0.44s - loss: 0.9350 - acc: 0.5679 - val_loss: 0.9807 - val_acc: 0.5466\n",
            "Epoch 36/50 - 0.45s - loss: 0.9415 - acc: 0.5670 - val_loss: 0.9885 - val_acc: 0.5466\n",
            "Epoch 37/50 - 0.44s - loss: 0.9308 - acc: 0.5711 - val_loss: 0.9791 - val_acc: 0.5547\n",
            "Epoch 38/50 - 0.46s - loss: 0.9618 - acc: 0.5389 - val_loss: 1.0049 - val_acc: 0.5385\n",
            "Epoch 39/50 - 0.45s - loss: 0.9085 - acc: 0.5859 - val_loss: 0.9614 - val_acc: 0.5628\n",
            "Epoch 40/50 - 0.44s - loss: 0.9164 - acc: 0.5661 - val_loss: 0.9663 - val_acc: 0.5668\n",
            "Epoch 41/50 - 0.44s - loss: 0.9374 - acc: 0.5470 - val_loss: 0.9858 - val_acc: 0.5142\n",
            "Epoch 42/50 - 0.46s - loss: 0.8991 - acc: 0.5839 - val_loss: 0.9547 - val_acc: 0.5688\n",
            "Epoch 43/50 - 0.46s - loss: 0.9087 - acc: 0.5650 - val_loss: 0.9675 - val_acc: 0.5283\n",
            "Epoch 44/50 - 0.47s - loss: 0.9691 - acc: 0.5360 - val_loss: 1.0183 - val_acc: 0.5304\n",
            "Epoch 45/50 - 0.45s - loss: 0.9050 - acc: 0.5796 - val_loss: 0.9696 - val_acc: 0.5506\n",
            "Epoch 46/50 - 0.50s - loss: 0.8959 - acc: 0.5828 - val_loss: 0.9554 - val_acc: 0.5628\n",
            "Epoch 47/50 - 0.49s - loss: 0.8919 - acc: 0.5922 - val_loss: 0.9589 - val_acc: 0.5587\n",
            "Epoch 48/50 - 0.47s - loss: 0.9189 - acc: 0.5547 - val_loss: 0.9854 - val_acc: 0.5000\n",
            "Epoch 49/50 - 0.48s - loss: 0.9093 - acc: 0.5700 - val_loss: 0.9806 - val_acc: 0.5061\n",
            "Epoch 50/50 - 0.48s - loss: 0.8920 - acc: 0.5819 - val_loss: 0.9622 - val_acc: 0.5526\n",
            "\n",
            "Combination 239/252:\n",
            "Hidden Layers: [512, 256, 128], Activation: tanh, Learning Rate: 0.01, Batch Size: 64, Epochs: 100\n",
            "Epoch 1/100 - 0.49s - loss: 1.0826 - acc: 0.4145 - val_loss: 1.0801 - val_acc: 0.4170\n",
            "Epoch 2/100 - 0.48s - loss: 1.0676 - acc: 0.4532 - val_loss: 1.0684 - val_acc: 0.4393\n",
            "Epoch 3/100 - 0.48s - loss: 1.0592 - acc: 0.4539 - val_loss: 1.0631 - val_acc: 0.4453\n",
            "Epoch 4/100 - 0.46s - loss: 1.0544 - acc: 0.4600 - val_loss: 1.0623 - val_acc: 0.4393\n",
            "Epoch 5/100 - 0.49s - loss: 1.0485 - acc: 0.4777 - val_loss: 1.0545 - val_acc: 0.4676\n",
            "Epoch 6/100 - 0.51s - loss: 1.0411 - acc: 0.4748 - val_loss: 1.0513 - val_acc: 0.4636\n",
            "Epoch 7/100 - 0.49s - loss: 1.0314 - acc: 0.4935 - val_loss: 1.0451 - val_acc: 0.4777\n",
            "Epoch 8/100 - 0.46s - loss: 1.0300 - acc: 0.4703 - val_loss: 1.0424 - val_acc: 0.4676\n",
            "Epoch 9/100 - 0.46s - loss: 1.0244 - acc: 0.4789 - val_loss: 1.0371 - val_acc: 0.4717\n",
            "Epoch 10/100 - 0.47s - loss: 1.0133 - acc: 0.5079 - val_loss: 1.0303 - val_acc: 0.5020\n",
            "Epoch 11/100 - 0.48s - loss: 1.0090 - acc: 0.5164 - val_loss: 1.0282 - val_acc: 0.4899\n",
            "Epoch 12/100 - 0.47s - loss: 1.0034 - acc: 0.5139 - val_loss: 1.0234 - val_acc: 0.5121\n",
            "Epoch 13/100 - 0.46s - loss: 0.9975 - acc: 0.5211 - val_loss: 1.0208 - val_acc: 0.5142\n",
            "Epoch 14/100 - 0.46s - loss: 0.9944 - acc: 0.5238 - val_loss: 1.0182 - val_acc: 0.4939\n",
            "Epoch 15/100 - 0.45s - loss: 0.9962 - acc: 0.5079 - val_loss: 1.0178 - val_acc: 0.5101\n",
            "Epoch 16/100 - 0.45s - loss: 1.0033 - acc: 0.4917 - val_loss: 1.0345 - val_acc: 0.4393\n",
            "Epoch 17/100 - 0.47s - loss: 0.9873 - acc: 0.5191 - val_loss: 1.0138 - val_acc: 0.5020\n",
            "Epoch 18/100 - 0.49s - loss: 0.9756 - acc: 0.5362 - val_loss: 1.0022 - val_acc: 0.5283\n",
            "Epoch 19/100 - 0.47s - loss: 0.9699 - acc: 0.5389 - val_loss: 1.0011 - val_acc: 0.5425\n",
            "Epoch 20/100 - 0.46s - loss: 0.9653 - acc: 0.5448 - val_loss: 0.9956 - val_acc: 0.5486\n",
            "Epoch 21/100 - 0.44s - loss: 0.9692 - acc: 0.5326 - val_loss: 1.0038 - val_acc: 0.5020\n",
            "Epoch 22/100 - 0.45s - loss: 0.9732 - acc: 0.5250 - val_loss: 1.0112 - val_acc: 0.4798\n",
            "Epoch 23/100 - 0.45s - loss: 0.9647 - acc: 0.5407 - val_loss: 0.9965 - val_acc: 0.5486\n",
            "Epoch 24/100 - 0.45s - loss: 0.9521 - acc: 0.5511 - val_loss: 0.9872 - val_acc: 0.5648\n",
            "Epoch 25/100 - 0.44s - loss: 0.9526 - acc: 0.5459 - val_loss: 0.9875 - val_acc: 0.5223\n",
            "Epoch 26/100 - 0.44s - loss: 0.9431 - acc: 0.5531 - val_loss: 0.9802 - val_acc: 0.5648\n",
            "Epoch 27/100 - 0.45s - loss: 0.9441 - acc: 0.5522 - val_loss: 0.9820 - val_acc: 0.5223\n",
            "Epoch 28/100 - 0.45s - loss: 0.9468 - acc: 0.5499 - val_loss: 0.9899 - val_acc: 0.5142\n",
            "Epoch 29/100 - 0.46s - loss: 0.9410 - acc: 0.5513 - val_loss: 0.9808 - val_acc: 0.5182\n",
            "Epoch 30/100 - 0.45s - loss: 0.9377 - acc: 0.5558 - val_loss: 0.9794 - val_acc: 0.5243\n",
            "Epoch 31/100 - 0.43s - loss: 0.9308 - acc: 0.5610 - val_loss: 0.9706 - val_acc: 0.5648\n",
            "Epoch 32/100 - 0.45s - loss: 0.9266 - acc: 0.5679 - val_loss: 0.9722 - val_acc: 0.5668\n",
            "Epoch 33/100 - 0.44s - loss: 0.9340 - acc: 0.5558 - val_loss: 0.9825 - val_acc: 0.5202\n",
            "Epoch 34/100 - 0.44s - loss: 0.9202 - acc: 0.5632 - val_loss: 0.9650 - val_acc: 0.5547\n",
            "Epoch 35/100 - 0.46s - loss: 0.9197 - acc: 0.5679 - val_loss: 0.9652 - val_acc: 0.5607\n",
            "Epoch 36/100 - 0.47s - loss: 0.9498 - acc: 0.5504 - val_loss: 0.9898 - val_acc: 0.5486\n",
            "Epoch 37/100 - 0.45s - loss: 0.9609 - acc: 0.5360 - val_loss: 1.0003 - val_acc: 0.5364\n",
            "Epoch 38/100 - 0.45s - loss: 0.9110 - acc: 0.5722 - val_loss: 0.9600 - val_acc: 0.5506\n",
            "Epoch 39/100 - 0.44s - loss: 0.9129 - acc: 0.5778 - val_loss: 0.9632 - val_acc: 0.5466\n",
            "Epoch 40/100 - 0.45s - loss: 0.9074 - acc: 0.5742 - val_loss: 0.9578 - val_acc: 0.5587\n",
            "Epoch 41/100 - 0.45s - loss: 0.9076 - acc: 0.5709 - val_loss: 0.9610 - val_acc: 0.5466\n",
            "Epoch 42/100 - 0.45s - loss: 0.9114 - acc: 0.5796 - val_loss: 0.9633 - val_acc: 0.5769\n",
            "Epoch 43/100 - 0.46s - loss: 0.9047 - acc: 0.5722 - val_loss: 0.9601 - val_acc: 0.5364\n",
            "Epoch 44/100 - 0.43s - loss: 0.9019 - acc: 0.5848 - val_loss: 0.9581 - val_acc: 0.5648\n",
            "Epoch 45/100 - 0.45s - loss: 0.9449 - acc: 0.5589 - val_loss: 0.9980 - val_acc: 0.5445\n",
            "Epoch 46/100 - 0.44s - loss: 0.8947 - acc: 0.5819 - val_loss: 0.9540 - val_acc: 0.5445\n",
            "Epoch 47/100 - 0.43s - loss: 0.9159 - acc: 0.5679 - val_loss: 0.9700 - val_acc: 0.5587\n",
            "Epoch 48/100 - 0.46s - loss: 0.8986 - acc: 0.5807 - val_loss: 0.9657 - val_acc: 0.5223\n",
            "Epoch 49/100 - 0.52s - loss: 0.8960 - acc: 0.5805 - val_loss: 0.9661 - val_acc: 0.5162\n",
            "Epoch 50/100 - 0.44s - loss: 0.9344 - acc: 0.5592 - val_loss: 0.9951 - val_acc: 0.5283\n",
            "Epoch 51/100 - 0.45s - loss: 0.8953 - acc: 0.5902 - val_loss: 0.9629 - val_acc: 0.5668\n",
            "Epoch 52/100 - 0.45s - loss: 0.9015 - acc: 0.5684 - val_loss: 0.9712 - val_acc: 0.5344\n",
            "Epoch 53/100 - 0.45s - loss: 0.9065 - acc: 0.5625 - val_loss: 0.9705 - val_acc: 0.5364\n",
            "Epoch 54/100 - 0.48s - loss: 0.9054 - acc: 0.5789 - val_loss: 0.9752 - val_acc: 0.5263\n",
            "Epoch 55/100 - 0.44s - loss: 0.8837 - acc: 0.5877 - val_loss: 0.9575 - val_acc: 0.5324\n",
            "Epoch 56/100 - 0.43s - loss: 0.8920 - acc: 0.5776 - val_loss: 0.9722 - val_acc: 0.5040\n",
            "Epoch 57/100 - 0.43s - loss: 0.8775 - acc: 0.5981 - val_loss: 0.9526 - val_acc: 0.5466\n",
            "Epoch 58/100 - 0.45s - loss: 0.8902 - acc: 0.5769 - val_loss: 0.9619 - val_acc: 0.5425\n",
            "Epoch 59/100 - 0.45s - loss: 0.9370 - acc: 0.5544 - val_loss: 1.0023 - val_acc: 0.5364\n",
            "Epoch 60/100 - 0.48s - loss: 0.8763 - acc: 0.5924 - val_loss: 0.9522 - val_acc: 0.5506\n",
            "Epoch 61/100 - 0.46s - loss: 0.8887 - acc: 0.5747 - val_loss: 0.9716 - val_acc: 0.5121\n",
            "Epoch 62/100 - 0.50s - loss: 0.8780 - acc: 0.5958 - val_loss: 0.9597 - val_acc: 0.5526\n",
            "Epoch 63/100 - 0.49s - loss: 0.9023 - acc: 0.5819 - val_loss: 0.9855 - val_acc: 0.5344\n",
            "Epoch 64/100 - 0.44s - loss: 0.9012 - acc: 0.5731 - val_loss: 0.9949 - val_acc: 0.4980\n",
            "Epoch 65/100 - 0.45s - loss: 0.8839 - acc: 0.5796 - val_loss: 0.9623 - val_acc: 0.5425\n",
            "Epoch 66/100 - 0.48s - loss: 0.8731 - acc: 0.5969 - val_loss: 0.9650 - val_acc: 0.5283\n",
            "Epoch 67/100 - 0.47s - loss: 0.8868 - acc: 0.5956 - val_loss: 0.9679 - val_acc: 0.5445\n",
            "Epoch 68/100 - 0.46s - loss: 0.8696 - acc: 0.5945 - val_loss: 0.9548 - val_acc: 0.5587\n",
            "Epoch 69/100 - 0.46s - loss: 0.9279 - acc: 0.5513 - val_loss: 1.0266 - val_acc: 0.5121\n",
            "Epoch 70/100 - 0.51s - loss: 0.8836 - acc: 0.5902 - val_loss: 0.9698 - val_acc: 0.5466\n",
            "Epoch 71/100 - 0.44s - loss: 0.9153 - acc: 0.5812 - val_loss: 1.0021 - val_acc: 0.5324\n",
            "Epoch 72/100 - 0.46s - loss: 1.0484 - acc: 0.4892 - val_loss: 1.1633 - val_acc: 0.4393\n",
            "Epoch 73/100 - 0.43s - loss: 0.9033 - acc: 0.5825 - val_loss: 0.9909 - val_acc: 0.5466\n",
            "Epoch 74/100 - 0.44s - loss: 0.8608 - acc: 0.6104 - val_loss: 0.9562 - val_acc: 0.5526\n",
            "Epoch 75/100 - 0.45s - loss: 0.9365 - acc: 0.5403 - val_loss: 1.0365 - val_acc: 0.5020\n",
            "Epoch 76/100 - 0.43s - loss: 0.9717 - acc: 0.5252 - val_loss: 1.0887 - val_acc: 0.4555\n",
            "Epoch 77/100 - 0.45s - loss: 0.8746 - acc: 0.5918 - val_loss: 0.9819 - val_acc: 0.5040\n",
            "Epoch 78/100 - 0.48s - loss: 0.8791 - acc: 0.5933 - val_loss: 0.9851 - val_acc: 0.5405\n",
            "Epoch 79/100 - 0.44s - loss: 0.8752 - acc: 0.5963 - val_loss: 0.9813 - val_acc: 0.5364\n",
            "Epoch 80/100 - 0.46s - loss: 0.8741 - acc: 0.5855 - val_loss: 0.9715 - val_acc: 0.5466\n",
            "Epoch 81/100 - 0.43s - loss: 0.8923 - acc: 0.5711 - val_loss: 1.0021 - val_acc: 0.4960\n",
            "Epoch 82/100 - 0.43s - loss: 0.8632 - acc: 0.5969 - val_loss: 0.9620 - val_acc: 0.5526\n",
            "Epoch 83/100 - 0.43s - loss: 0.8808 - acc: 0.5807 - val_loss: 0.9771 - val_acc: 0.5425\n",
            "Epoch 84/100 - 0.45s - loss: 0.8792 - acc: 0.5902 - val_loss: 0.9780 - val_acc: 0.5486\n",
            "Epoch 85/100 - 0.44s - loss: 0.8547 - acc: 0.6082 - val_loss: 0.9593 - val_acc: 0.5425\n",
            "Epoch 86/100 - 0.46s - loss: 0.8560 - acc: 0.6053 - val_loss: 0.9601 - val_acc: 0.5648\n",
            "Epoch 87/100 - 0.45s - loss: 0.9045 - acc: 0.5724 - val_loss: 1.0257 - val_acc: 0.4939\n",
            "Epoch 88/100 - 0.48s - loss: 0.8547 - acc: 0.6055 - val_loss: 0.9652 - val_acc: 0.5324\n",
            "Epoch 89/100 - 0.44s - loss: 0.9074 - acc: 0.5666 - val_loss: 1.0052 - val_acc: 0.5445\n",
            "Epoch 90/100 - 0.47s - loss: 0.8719 - acc: 0.5987 - val_loss: 0.9925 - val_acc: 0.5061\n",
            "Epoch 91/100 - 0.43s - loss: 0.8624 - acc: 0.6019 - val_loss: 0.9776 - val_acc: 0.5142\n",
            "Epoch 92/100 - 0.45s - loss: 0.8919 - acc: 0.5828 - val_loss: 1.0100 - val_acc: 0.5101\n",
            "Epoch 93/100 - 0.46s - loss: 0.8695 - acc: 0.5974 - val_loss: 0.9738 - val_acc: 0.5567\n",
            "Epoch 94/100 - 0.45s - loss: 0.8554 - acc: 0.6111 - val_loss: 0.9733 - val_acc: 0.5486\n",
            "Epoch 95/100 - 0.43s - loss: 0.8916 - acc: 0.5740 - val_loss: 1.0131 - val_acc: 0.5061\n",
            "Epoch 96/100 - 0.46s - loss: 0.8491 - acc: 0.6170 - val_loss: 0.9635 - val_acc: 0.5628\n",
            "Epoch 97/100 - 0.50s - loss: 0.8581 - acc: 0.6118 - val_loss: 0.9683 - val_acc: 0.5648\n",
            "Epoch 98/100 - 0.49s - loss: 0.8461 - acc: 0.6104 - val_loss: 0.9638 - val_acc: 0.5547\n",
            "Epoch 99/100 - 0.48s - loss: 0.8701 - acc: 0.5960 - val_loss: 0.9924 - val_acc: 0.5243\n",
            "Epoch 100/100 - 0.46s - loss: 0.8679 - acc: 0.5884 - val_loss: 0.9789 - val_acc: 0.5324\n",
            "\n",
            "Combination 240/252:\n",
            "Hidden Layers: [512, 256, 128], Activation: tanh, Learning Rate: 0.01, Batch Size: 64, Epochs: 150\n",
            "Epoch 1/150 - 0.47s - loss: 1.0830 - acc: 0.4233 - val_loss: 1.0829 - val_acc: 0.4069\n",
            "Epoch 2/150 - 0.49s - loss: 1.0701 - acc: 0.4366 - val_loss: 1.0739 - val_acc: 0.4211\n",
            "Epoch 3/150 - 0.46s - loss: 1.0610 - acc: 0.4647 - val_loss: 1.0659 - val_acc: 0.4453\n",
            "Epoch 4/150 - 0.45s - loss: 1.0544 - acc: 0.4613 - val_loss: 1.0607 - val_acc: 0.4534\n",
            "Epoch 5/150 - 0.57s - loss: 1.0494 - acc: 0.4636 - val_loss: 1.0609 - val_acc: 0.4352\n",
            "Epoch 6/150 - 0.48s - loss: 1.0376 - acc: 0.4843 - val_loss: 1.0485 - val_acc: 0.4980\n",
            "Epoch 7/150 - 0.51s - loss: 1.0321 - acc: 0.4870 - val_loss: 1.0440 - val_acc: 0.4818\n",
            "Epoch 8/150 - 0.48s - loss: 1.0242 - acc: 0.4946 - val_loss: 1.0384 - val_acc: 0.5000\n",
            "Epoch 9/150 - 0.50s - loss: 1.0321 - acc: 0.4530 - val_loss: 1.0497 - val_acc: 0.4393\n",
            "Epoch 10/150 - 0.48s - loss: 1.0126 - acc: 0.5031 - val_loss: 1.0308 - val_acc: 0.4879\n",
            "Epoch 11/150 - 0.46s - loss: 1.0052 - acc: 0.5115 - val_loss: 1.0248 - val_acc: 0.5202\n",
            "Epoch 12/150 - 0.47s - loss: 1.0021 - acc: 0.4955 - val_loss: 1.0241 - val_acc: 0.4939\n",
            "Epoch 13/150 - 0.46s - loss: 0.9977 - acc: 0.5137 - val_loss: 1.0179 - val_acc: 0.5263\n",
            "Epoch 14/150 - 0.54s - loss: 0.9909 - acc: 0.5279 - val_loss: 1.0149 - val_acc: 0.5364\n",
            "Epoch 15/150 - 0.47s - loss: 0.9866 - acc: 0.5133 - val_loss: 1.0104 - val_acc: 0.4939\n",
            "Epoch 16/150 - 0.48s - loss: 0.9833 - acc: 0.5178 - val_loss: 1.0072 - val_acc: 0.4858\n",
            "Epoch 17/150 - 0.53s - loss: 0.9756 - acc: 0.5256 - val_loss: 0.9998 - val_acc: 0.5283\n",
            "Epoch 18/150 - 0.47s - loss: 0.9767 - acc: 0.5128 - val_loss: 1.0045 - val_acc: 0.5061\n",
            "Epoch 19/150 - 0.46s - loss: 0.9673 - acc: 0.5337 - val_loss: 0.9941 - val_acc: 0.5324\n",
            "Epoch 20/150 - 0.48s - loss: 0.9669 - acc: 0.5414 - val_loss: 0.9943 - val_acc: 0.5567\n",
            "Epoch 21/150 - 0.46s - loss: 0.9660 - acc: 0.5418 - val_loss: 0.9939 - val_acc: 0.5648\n",
            "Epoch 22/150 - 0.45s - loss: 0.9660 - acc: 0.5394 - val_loss: 0.9941 - val_acc: 0.5628\n",
            "Epoch 23/150 - 0.45s - loss: 0.9532 - acc: 0.5441 - val_loss: 0.9824 - val_acc: 0.5405\n",
            "Epoch 24/150 - 0.45s - loss: 0.9531 - acc: 0.5499 - val_loss: 0.9834 - val_acc: 0.5466\n",
            "Epoch 25/150 - 0.43s - loss: 0.9601 - acc: 0.5317 - val_loss: 0.9917 - val_acc: 0.4939\n",
            "Epoch 26/150 - 0.49s - loss: 0.9438 - acc: 0.5502 - val_loss: 0.9753 - val_acc: 0.5547\n",
            "Epoch 27/150 - 0.46s - loss: 0.9428 - acc: 0.5493 - val_loss: 0.9753 - val_acc: 0.5506\n",
            "Epoch 28/150 - 0.45s - loss: 0.9434 - acc: 0.5533 - val_loss: 0.9762 - val_acc: 0.5688\n",
            "Epoch 29/150 - 0.44s - loss: 0.9677 - acc: 0.5382 - val_loss: 0.9951 - val_acc: 0.5466\n",
            "Epoch 30/150 - 0.46s - loss: 0.9420 - acc: 0.5486 - val_loss: 0.9753 - val_acc: 0.5263\n",
            "Epoch 31/150 - 0.45s - loss: 0.9309 - acc: 0.5592 - val_loss: 0.9653 - val_acc: 0.5587\n",
            "Epoch 32/150 - 0.48s - loss: 0.9406 - acc: 0.5616 - val_loss: 0.9736 - val_acc: 0.5709\n",
            "Epoch 33/150 - 0.48s - loss: 0.9365 - acc: 0.5643 - val_loss: 0.9711 - val_acc: 0.5810\n",
            "Epoch 34/150 - 0.50s - loss: 0.9248 - acc: 0.5623 - val_loss: 0.9629 - val_acc: 0.5486\n",
            "Epoch 35/150 - 0.47s - loss: 0.9570 - acc: 0.5524 - val_loss: 0.9922 - val_acc: 0.5688\n",
            "Epoch 36/150 - 0.46s - loss: 0.9243 - acc: 0.5616 - val_loss: 0.9644 - val_acc: 0.5466\n",
            "Epoch 37/150 - 0.48s - loss: 0.9238 - acc: 0.5587 - val_loss: 0.9656 - val_acc: 0.5364\n",
            "Epoch 38/150 - 0.49s - loss: 0.9213 - acc: 0.5634 - val_loss: 0.9636 - val_acc: 0.5283\n",
            "Epoch 39/150 - 0.46s - loss: 0.9374 - acc: 0.5625 - val_loss: 0.9744 - val_acc: 0.5547\n",
            "Epoch 40/150 - 0.45s - loss: 0.9140 - acc: 0.5634 - val_loss: 0.9562 - val_acc: 0.5526\n",
            "Epoch 41/150 - 0.50s - loss: 0.9190 - acc: 0.5742 - val_loss: 0.9600 - val_acc: 0.5688\n",
            "Epoch 42/150 - 0.45s - loss: 0.9412 - acc: 0.5603 - val_loss: 0.9825 - val_acc: 0.5607\n",
            "Epoch 43/150 - 0.45s - loss: 0.9067 - acc: 0.5760 - val_loss: 0.9529 - val_acc: 0.5506\n",
            "Epoch 44/150 - 0.48s - loss: 0.9288 - acc: 0.5544 - val_loss: 0.9817 - val_acc: 0.5101\n",
            "Epoch 45/150 - 0.45s - loss: 0.9146 - acc: 0.5720 - val_loss: 0.9563 - val_acc: 0.5547\n",
            "Epoch 46/150 - 0.43s - loss: 0.9163 - acc: 0.5848 - val_loss: 0.9638 - val_acc: 0.5729\n",
            "Epoch 47/150 - 0.45s - loss: 0.9100 - acc: 0.5648 - val_loss: 0.9567 - val_acc: 0.5385\n",
            "Epoch 48/150 - 0.44s - loss: 0.9098 - acc: 0.5700 - val_loss: 0.9559 - val_acc: 0.5547\n",
            "Epoch 49/150 - 0.50s - loss: 0.8994 - acc: 0.5884 - val_loss: 0.9510 - val_acc: 0.5648\n",
            "Epoch 50/150 - 0.50s - loss: 0.9103 - acc: 0.5747 - val_loss: 0.9675 - val_acc: 0.5344\n",
            "Epoch 51/150 - 0.47s - loss: 0.9683 - acc: 0.5479 - val_loss: 1.0126 - val_acc: 0.5405\n",
            "Epoch 52/150 - 0.46s - loss: 0.9100 - acc: 0.5666 - val_loss: 0.9673 - val_acc: 0.5182\n",
            "Epoch 53/150 - 0.46s - loss: 0.9141 - acc: 0.5816 - val_loss: 0.9662 - val_acc: 0.5668\n",
            "Epoch 54/150 - 0.46s - loss: 0.8879 - acc: 0.5906 - val_loss: 0.9469 - val_acc: 0.5668\n",
            "Epoch 55/150 - 0.49s - loss: 0.9075 - acc: 0.5697 - val_loss: 0.9722 - val_acc: 0.5162\n",
            "Epoch 56/150 - 0.50s - loss: 0.9855 - acc: 0.5160 - val_loss: 1.0599 - val_acc: 0.4696\n",
            "Epoch 57/150 - 0.47s - loss: 0.9086 - acc: 0.5843 - val_loss: 0.9647 - val_acc: 0.5648\n",
            "Epoch 58/150 - 0.47s - loss: 0.9051 - acc: 0.5724 - val_loss: 0.9758 - val_acc: 0.4980\n",
            "Epoch 59/150 - 0.46s - loss: 0.9011 - acc: 0.5893 - val_loss: 0.9607 - val_acc: 0.5668\n",
            "Epoch 60/150 - 0.45s - loss: 0.9641 - acc: 0.5430 - val_loss: 1.0182 - val_acc: 0.5202\n",
            "Epoch 61/150 - 0.47s - loss: 0.8934 - acc: 0.5776 - val_loss: 0.9541 - val_acc: 0.5445\n",
            "Epoch 62/150 - 0.48s - loss: 0.9063 - acc: 0.5634 - val_loss: 0.9764 - val_acc: 0.5263\n",
            "Epoch 63/150 - 0.47s - loss: 0.9255 - acc: 0.5522 - val_loss: 1.0055 - val_acc: 0.4858\n",
            "Epoch 64/150 - 0.54s - loss: 0.8810 - acc: 0.5936 - val_loss: 0.9558 - val_acc: 0.5385\n",
            "Epoch 65/150 - 0.60s - loss: 0.8820 - acc: 0.5850 - val_loss: 0.9518 - val_acc: 0.5466\n",
            "Epoch 66/150 - 0.61s - loss: 0.8862 - acc: 0.5933 - val_loss: 0.9588 - val_acc: 0.5547\n",
            "Epoch 67/150 - 0.61s - loss: 0.8888 - acc: 0.5843 - val_loss: 0.9675 - val_acc: 0.5182\n",
            "Epoch 68/150 - 0.63s - loss: 0.9052 - acc: 0.5738 - val_loss: 0.9708 - val_acc: 0.5445\n",
            "Epoch 69/150 - 0.59s - loss: 0.8748 - acc: 0.6039 - val_loss: 0.9477 - val_acc: 0.5729\n",
            "Epoch 70/150 - 0.47s - loss: 0.8767 - acc: 0.6055 - val_loss: 0.9532 - val_acc: 0.5648\n",
            "Epoch 71/150 - 0.49s - loss: 0.8948 - acc: 0.5868 - val_loss: 0.9655 - val_acc: 0.5587\n",
            "Epoch 72/150 - 0.50s - loss: 0.8704 - acc: 0.6017 - val_loss: 0.9471 - val_acc: 0.5709\n",
            "Epoch 73/150 - 0.48s - loss: 0.8968 - acc: 0.5828 - val_loss: 0.9704 - val_acc: 0.5567\n",
            "Epoch 74/150 - 0.56s - loss: 0.9011 - acc: 0.5715 - val_loss: 0.9734 - val_acc: 0.5364\n",
            "Epoch 75/150 - 0.53s - loss: 0.8661 - acc: 0.5985 - val_loss: 0.9484 - val_acc: 0.5567\n",
            "Epoch 76/150 - 0.47s - loss: 0.8644 - acc: 0.6023 - val_loss: 0.9489 - val_acc: 0.5486\n",
            "Epoch 77/150 - 0.48s - loss: 0.9362 - acc: 0.5452 - val_loss: 1.0206 - val_acc: 0.4980\n",
            "Epoch 78/150 - 0.47s - loss: 0.8633 - acc: 0.6021 - val_loss: 0.9504 - val_acc: 0.5486\n",
            "Epoch 79/150 - 0.51s - loss: 0.8645 - acc: 0.6075 - val_loss: 0.9506 - val_acc: 0.5648\n",
            "Epoch 80/150 - 0.48s - loss: 0.8625 - acc: 0.6012 - val_loss: 0.9501 - val_acc: 0.5486\n",
            "Epoch 81/150 - 0.47s - loss: 0.8673 - acc: 0.5947 - val_loss: 0.9526 - val_acc: 0.5648\n",
            "Epoch 82/150 - 0.55s - loss: 0.8660 - acc: 0.6048 - val_loss: 0.9562 - val_acc: 0.5567\n",
            "Epoch 83/150 - 0.46s - loss: 0.9915 - acc: 0.5126 - val_loss: 1.0895 - val_acc: 0.4737\n",
            "Epoch 84/150 - 0.48s - loss: 0.8690 - acc: 0.6055 - val_loss: 0.9588 - val_acc: 0.5587\n",
            "Epoch 85/150 - 0.50s - loss: 0.9500 - acc: 0.5634 - val_loss: 1.0319 - val_acc: 0.5304\n",
            "Epoch 86/150 - 0.50s - loss: 0.8634 - acc: 0.6046 - val_loss: 0.9626 - val_acc: 0.5405\n",
            "Epoch 87/150 - 0.50s - loss: 0.9321 - acc: 0.5495 - val_loss: 1.0408 - val_acc: 0.4858\n",
            "Epoch 88/150 - 0.55s - loss: 0.8569 - acc: 0.6053 - val_loss: 0.9557 - val_acc: 0.5486\n",
            "Epoch 89/150 - 0.55s - loss: 0.8630 - acc: 0.5987 - val_loss: 0.9613 - val_acc: 0.5405\n",
            "Epoch 90/150 - 0.56s - loss: 0.8647 - acc: 0.6098 - val_loss: 0.9622 - val_acc: 0.5567\n",
            "Epoch 91/150 - 0.55s - loss: 0.8555 - acc: 0.6104 - val_loss: 0.9582 - val_acc: 0.5526\n",
            "Epoch 92/150 - 0.52s - loss: 0.8788 - acc: 0.5949 - val_loss: 0.9747 - val_acc: 0.5547\n",
            "Epoch 93/150 - 0.52s - loss: 0.8615 - acc: 0.6046 - val_loss: 0.9561 - val_acc: 0.5648\n",
            "Epoch 94/150 - 0.52s - loss: 0.8843 - acc: 0.5879 - val_loss: 0.9949 - val_acc: 0.5142\n",
            "Epoch 95/150 - 0.51s - loss: 0.8729 - acc: 0.5861 - val_loss: 0.9693 - val_acc: 0.5587\n",
            "Epoch 96/150 - 0.50s - loss: 1.0826 - acc: 0.4791 - val_loss: 1.1587 - val_acc: 0.4656\n",
            "Epoch 97/150 - 0.54s - loss: 0.9401 - acc: 0.5479 - val_loss: 1.0573 - val_acc: 0.4696\n",
            "Epoch 98/150 - 0.58s - loss: 0.8600 - acc: 0.5981 - val_loss: 0.9578 - val_acc: 0.5648\n",
            "Epoch 99/150 - 0.50s - loss: 0.8562 - acc: 0.6131 - val_loss: 0.9648 - val_acc: 0.5547\n",
            "Epoch 100/150 - 0.50s - loss: 0.8688 - acc: 0.5990 - val_loss: 0.9671 - val_acc: 0.5628\n",
            "Epoch 101/150 - 0.60s - loss: 0.8678 - acc: 0.5974 - val_loss: 0.9819 - val_acc: 0.5182\n",
            "Epoch 102/150 - 0.51s - loss: 0.8608 - acc: 0.6116 - val_loss: 0.9717 - val_acc: 0.5425\n",
            "Epoch 103/150 - 0.53s - loss: 0.8583 - acc: 0.6075 - val_loss: 0.9734 - val_acc: 0.5283\n",
            "Epoch 104/150 - 0.54s - loss: 0.8554 - acc: 0.6048 - val_loss: 0.9667 - val_acc: 0.5466\n",
            "Epoch 105/150 - 0.51s - loss: 0.9215 - acc: 0.5598 - val_loss: 1.0156 - val_acc: 0.5344\n",
            "Epoch 106/150 - 0.50s - loss: 0.8491 - acc: 0.6122 - val_loss: 0.9562 - val_acc: 0.5607\n",
            "Epoch 107/150 - 0.49s - loss: 0.9068 - acc: 0.5641 - val_loss: 1.0031 - val_acc: 0.5283\n",
            "Epoch 108/150 - 0.43s - loss: 0.8741 - acc: 0.5933 - val_loss: 0.9982 - val_acc: 0.5162\n",
            "Epoch 109/150 - 0.45s - loss: 0.8479 - acc: 0.6100 - val_loss: 0.9615 - val_acc: 0.5526\n",
            "Epoch 110/150 - 0.47s - loss: 0.8773 - acc: 0.5868 - val_loss: 0.9826 - val_acc: 0.5344\n",
            "Epoch 111/150 - 0.49s - loss: 0.8435 - acc: 0.6170 - val_loss: 0.9578 - val_acc: 0.5729\n",
            "Epoch 112/150 - 0.47s - loss: 0.8648 - acc: 0.5983 - val_loss: 0.9872 - val_acc: 0.5283\n",
            "Epoch 113/150 - 0.46s - loss: 0.8488 - acc: 0.6113 - val_loss: 0.9657 - val_acc: 0.5425\n",
            "Epoch 114/150 - 0.47s - loss: 0.8678 - acc: 0.6077 - val_loss: 0.9756 - val_acc: 0.5526\n",
            "Epoch 115/150 - 0.44s - loss: 0.8533 - acc: 0.6107 - val_loss: 0.9660 - val_acc: 0.5668\n",
            "Epoch 116/150 - 0.47s - loss: 0.8895 - acc: 0.5828 - val_loss: 1.0112 - val_acc: 0.5101\n",
            "Epoch 117/150 - 0.47s - loss: 0.8557 - acc: 0.6062 - val_loss: 0.9798 - val_acc: 0.5283\n",
            "Epoch 118/150 - 0.49s - loss: 0.8630 - acc: 0.6068 - val_loss: 0.9757 - val_acc: 0.5567\n",
            "Epoch 119/150 - 0.46s - loss: 0.8920 - acc: 0.5787 - val_loss: 1.0162 - val_acc: 0.5040\n",
            "Epoch 120/150 - 0.48s - loss: 0.8500 - acc: 0.6125 - val_loss: 0.9657 - val_acc: 0.5607\n",
            "Epoch 121/150 - 0.46s - loss: 0.8513 - acc: 0.6149 - val_loss: 0.9731 - val_acc: 0.5506\n",
            "Epoch 122/150 - 0.51s - loss: 0.8415 - acc: 0.6176 - val_loss: 0.9655 - val_acc: 0.5526\n",
            "Epoch 123/150 - 0.52s - loss: 0.8465 - acc: 0.6172 - val_loss: 0.9651 - val_acc: 0.5729\n",
            "Epoch 124/150 - 0.53s - loss: 0.9006 - acc: 0.5742 - val_loss: 1.0227 - val_acc: 0.5061\n",
            "Epoch 125/150 - 0.50s - loss: 0.8707 - acc: 0.5859 - val_loss: 0.9790 - val_acc: 0.5668\n",
            "Epoch 126/150 - 0.48s - loss: 0.8849 - acc: 0.5877 - val_loss: 0.9935 - val_acc: 0.5466\n",
            "Epoch 127/150 - 0.55s - loss: 0.9146 - acc: 0.5621 - val_loss: 1.0463 - val_acc: 0.4879\n",
            "Epoch 128/150 - 0.48s - loss: 0.8821 - acc: 0.5891 - val_loss: 1.0078 - val_acc: 0.5263\n",
            "Epoch 129/150 - 0.48s - loss: 0.8437 - acc: 0.6161 - val_loss: 0.9709 - val_acc: 0.5405\n",
            "Epoch 130/150 - 0.49s - loss: 0.9075 - acc: 0.5864 - val_loss: 1.0207 - val_acc: 0.5445\n",
            "Epoch 131/150 - 0.56s - loss: 1.0569 - acc: 0.4863 - val_loss: 1.1496 - val_acc: 0.4696\n",
            "Epoch 132/150 - 0.48s - loss: 0.8425 - acc: 0.6208 - val_loss: 0.9627 - val_acc: 0.5648\n",
            "Epoch 133/150 - 0.46s - loss: 0.8495 - acc: 0.6055 - val_loss: 0.9767 - val_acc: 0.5283\n",
            "Epoch 134/150 - 0.46s - loss: 0.8552 - acc: 0.6028 - val_loss: 0.9796 - val_acc: 0.5202\n",
            "Epoch 135/150 - 0.43s - loss: 0.8624 - acc: 0.6037 - val_loss: 0.9972 - val_acc: 0.5263\n",
            "Epoch 136/150 - 0.44s - loss: 0.8600 - acc: 0.6012 - val_loss: 0.9925 - val_acc: 0.5162\n",
            "Epoch 137/150 - 0.43s - loss: 0.8409 - acc: 0.6176 - val_loss: 0.9694 - val_acc: 0.5486\n",
            "Epoch 138/150 - 0.47s - loss: 0.8480 - acc: 0.6152 - val_loss: 0.9777 - val_acc: 0.5506\n",
            "Epoch 139/150 - 0.44s - loss: 0.8685 - acc: 0.5958 - val_loss: 1.0080 - val_acc: 0.5081\n",
            "Epoch 140/150 - 0.48s - loss: 0.9369 - acc: 0.5592 - val_loss: 1.0435 - val_acc: 0.5304\n",
            "Epoch 141/150 - 0.45s - loss: 0.8346 - acc: 0.6230 - val_loss: 0.9608 - val_acc: 0.5628\n",
            "Epoch 142/150 - 0.47s - loss: 0.8381 - acc: 0.6179 - val_loss: 0.9668 - val_acc: 0.5526\n",
            "Epoch 143/150 - 0.51s - loss: 0.8531 - acc: 0.6055 - val_loss: 0.9784 - val_acc: 0.5364\n",
            "Epoch 144/150 - 0.47s - loss: 0.8392 - acc: 0.6172 - val_loss: 0.9717 - val_acc: 0.5526\n",
            "Epoch 145/150 - 0.46s - loss: 0.8388 - acc: 0.6199 - val_loss: 0.9655 - val_acc: 0.5607\n",
            "Epoch 146/150 - 0.50s - loss: 0.8801 - acc: 0.5816 - val_loss: 1.0133 - val_acc: 0.5000\n",
            "Epoch 147/150 - 0.45s - loss: 0.8536 - acc: 0.6023 - val_loss: 0.9897 - val_acc: 0.5202\n",
            "Epoch 148/150 - 0.51s - loss: 0.8433 - acc: 0.6167 - val_loss: 0.9653 - val_acc: 0.5526\n",
            "Epoch 149/150 - 0.46s - loss: 0.8465 - acc: 0.6082 - val_loss: 0.9682 - val_acc: 0.5506\n",
            "Epoch 150/150 - 0.47s - loss: 0.8887 - acc: 0.5990 - val_loss: 1.0132 - val_acc: 0.5466\n",
            "\n",
            "Combination 241/252:\n",
            "Hidden Layers: [512, 256, 128], Activation: tanh, Learning Rate: 0.001, Batch Size: 32, Epochs: 50\n",
            "Epoch 1/50 - 0.65s - loss: 1.1004 - acc: 0.3345 - val_loss: 1.1011 - val_acc: 0.3401\n",
            "Epoch 2/50 - 0.67s - loss: 1.0943 - acc: 0.3747 - val_loss: 1.0954 - val_acc: 0.3664\n",
            "Epoch 3/50 - 0.74s - loss: 1.0893 - acc: 0.4015 - val_loss: 1.0912 - val_acc: 0.3988\n",
            "Epoch 4/50 - 0.68s - loss: 1.0849 - acc: 0.4211 - val_loss: 1.0877 - val_acc: 0.4049\n",
            "Epoch 5/50 - 0.69s - loss: 1.0810 - acc: 0.4318 - val_loss: 1.0846 - val_acc: 0.4008\n",
            "Epoch 6/50 - 0.62s - loss: 1.0776 - acc: 0.4386 - val_loss: 1.0817 - val_acc: 0.4231\n",
            "Epoch 7/50 - 0.64s - loss: 1.0745 - acc: 0.4431 - val_loss: 1.0793 - val_acc: 0.4312\n",
            "Epoch 8/50 - 0.67s - loss: 1.0717 - acc: 0.4381 - val_loss: 1.0773 - val_acc: 0.4312\n",
            "Epoch 9/50 - 0.66s - loss: 1.0690 - acc: 0.4557 - val_loss: 1.0751 - val_acc: 0.4433\n",
            "Epoch 10/50 - 0.67s - loss: 1.0665 - acc: 0.4573 - val_loss: 1.0733 - val_acc: 0.4393\n",
            "Epoch 11/50 - 0.67s - loss: 1.0643 - acc: 0.4593 - val_loss: 1.0715 - val_acc: 0.4514\n",
            "Epoch 12/50 - 0.66s - loss: 1.0620 - acc: 0.4631 - val_loss: 1.0697 - val_acc: 0.4595\n",
            "Epoch 13/50 - 0.65s - loss: 1.0599 - acc: 0.4593 - val_loss: 1.0683 - val_acc: 0.4494\n",
            "Epoch 14/50 - 0.65s - loss: 1.0579 - acc: 0.4674 - val_loss: 1.0666 - val_acc: 0.4595\n",
            "Epoch 15/50 - 0.63s - loss: 1.0560 - acc: 0.4703 - val_loss: 1.0656 - val_acc: 0.4636\n",
            "Epoch 16/50 - 0.63s - loss: 1.0541 - acc: 0.4708 - val_loss: 1.0641 - val_acc: 0.4595\n",
            "Epoch 17/50 - 0.64s - loss: 1.0523 - acc: 0.4699 - val_loss: 1.0626 - val_acc: 0.4595\n",
            "Epoch 18/50 - 0.65s - loss: 1.0506 - acc: 0.4719 - val_loss: 1.0617 - val_acc: 0.4636\n",
            "Epoch 19/50 - 0.67s - loss: 1.0489 - acc: 0.4726 - val_loss: 1.0599 - val_acc: 0.4595\n",
            "Epoch 20/50 - 0.77s - loss: 1.0473 - acc: 0.4757 - val_loss: 1.0588 - val_acc: 0.4615\n",
            "Epoch 21/50 - 0.63s - loss: 1.0456 - acc: 0.4737 - val_loss: 1.0577 - val_acc: 0.4656\n",
            "Epoch 22/50 - 0.63s - loss: 1.0441 - acc: 0.4746 - val_loss: 1.0563 - val_acc: 0.4656\n",
            "Epoch 23/50 - 0.63s - loss: 1.0424 - acc: 0.4777 - val_loss: 1.0552 - val_acc: 0.4615\n",
            "Epoch 24/50 - 0.62s - loss: 1.0410 - acc: 0.4786 - val_loss: 1.0542 - val_acc: 0.4696\n",
            "Epoch 25/50 - 0.73s - loss: 1.0394 - acc: 0.4804 - val_loss: 1.0529 - val_acc: 0.4696\n",
            "Epoch 26/50 - 0.67s - loss: 1.0381 - acc: 0.4798 - val_loss: 1.0522 - val_acc: 0.4656\n",
            "Epoch 27/50 - 0.67s - loss: 1.0365 - acc: 0.4820 - val_loss: 1.0511 - val_acc: 0.4757\n",
            "Epoch 28/50 - 0.66s - loss: 1.0350 - acc: 0.4831 - val_loss: 1.0500 - val_acc: 0.4757\n",
            "Epoch 29/50 - 0.66s - loss: 1.0336 - acc: 0.4847 - val_loss: 1.0490 - val_acc: 0.4696\n",
            "Epoch 30/50 - 0.62s - loss: 1.0322 - acc: 0.4854 - val_loss: 1.0476 - val_acc: 0.4838\n",
            "Epoch 31/50 - 0.68s - loss: 1.0309 - acc: 0.4865 - val_loss: 1.0471 - val_acc: 0.4777\n",
            "Epoch 32/50 - 0.63s - loss: 1.0294 - acc: 0.4863 - val_loss: 1.0457 - val_acc: 0.4899\n",
            "Epoch 33/50 - 0.61s - loss: 1.0280 - acc: 0.4883 - val_loss: 1.0447 - val_acc: 0.4899\n",
            "Epoch 34/50 - 0.67s - loss: 1.0269 - acc: 0.4917 - val_loss: 1.0444 - val_acc: 0.4777\n",
            "Epoch 35/50 - 0.62s - loss: 1.0254 - acc: 0.4910 - val_loss: 1.0425 - val_acc: 0.4980\n",
            "Epoch 36/50 - 0.63s - loss: 1.0241 - acc: 0.4942 - val_loss: 1.0418 - val_acc: 0.4980\n",
            "Epoch 37/50 - 0.61s - loss: 1.0229 - acc: 0.4912 - val_loss: 1.0408 - val_acc: 0.4980\n",
            "Epoch 38/50 - 0.64s - loss: 1.0215 - acc: 0.4964 - val_loss: 1.0395 - val_acc: 0.5020\n",
            "Epoch 39/50 - 0.68s - loss: 1.0203 - acc: 0.4971 - val_loss: 1.0385 - val_acc: 0.5020\n",
            "Epoch 40/50 - 0.63s - loss: 1.0190 - acc: 0.4980 - val_loss: 1.0378 - val_acc: 0.5061\n",
            "Epoch 41/50 - 0.70s - loss: 1.0177 - acc: 0.4966 - val_loss: 1.0371 - val_acc: 0.5040\n",
            "Epoch 42/50 - 0.77s - loss: 1.0164 - acc: 0.5016 - val_loss: 1.0360 - val_acc: 0.5020\n",
            "Epoch 43/50 - 0.73s - loss: 1.0152 - acc: 0.5025 - val_loss: 1.0349 - val_acc: 0.5020\n",
            "Epoch 44/50 - 0.74s - loss: 1.0142 - acc: 0.5049 - val_loss: 1.0337 - val_acc: 0.4980\n",
            "Epoch 45/50 - 0.69s - loss: 1.0127 - acc: 0.5047 - val_loss: 1.0332 - val_acc: 0.5020\n",
            "Epoch 46/50 - 0.77s - loss: 1.0114 - acc: 0.5049 - val_loss: 1.0322 - val_acc: 0.5121\n",
            "Epoch 47/50 - 0.68s - loss: 1.0103 - acc: 0.5045 - val_loss: 1.0315 - val_acc: 0.5121\n",
            "Epoch 48/50 - 0.70s - loss: 1.0090 - acc: 0.5094 - val_loss: 1.0302 - val_acc: 0.5142\n",
            "Epoch 49/50 - 0.69s - loss: 1.0078 - acc: 0.5054 - val_loss: 1.0296 - val_acc: 0.5182\n",
            "Epoch 50/50 - 0.81s - loss: 1.0066 - acc: 0.5065 - val_loss: 1.0286 - val_acc: 0.5162\n",
            "\n",
            "Combination 242/252:\n",
            "Hidden Layers: [512, 256, 128], Activation: tanh, Learning Rate: 0.001, Batch Size: 32, Epochs: 100\n",
            "Epoch 1/100 - 0.75s - loss: 1.0967 - acc: 0.3583 - val_loss: 1.0968 - val_acc: 0.3846\n",
            "Epoch 2/100 - 0.68s - loss: 1.0912 - acc: 0.3824 - val_loss: 1.0929 - val_acc: 0.4069\n",
            "Epoch 3/100 - 0.74s - loss: 1.0863 - acc: 0.4008 - val_loss: 1.0885 - val_acc: 0.4150\n",
            "Epoch 4/100 - 0.73s - loss: 1.0823 - acc: 0.4154 - val_loss: 1.0847 - val_acc: 0.4372\n",
            "Epoch 5/100 - 0.71s - loss: 1.0785 - acc: 0.4314 - val_loss: 1.0820 - val_acc: 0.4312\n",
            "Epoch 6/100 - 0.75s - loss: 1.0752 - acc: 0.4433 - val_loss: 1.0793 - val_acc: 0.4332\n",
            "Epoch 7/100 - 0.73s - loss: 1.0724 - acc: 0.4507 - val_loss: 1.0765 - val_acc: 0.4534\n",
            "Epoch 8/100 - 0.76s - loss: 1.0696 - acc: 0.4613 - val_loss: 1.0745 - val_acc: 0.4555\n",
            "Epoch 9/100 - 0.77s - loss: 1.0672 - acc: 0.4568 - val_loss: 1.0730 - val_acc: 0.4555\n",
            "Epoch 10/100 - 0.71s - loss: 1.0648 - acc: 0.4654 - val_loss: 1.0713 - val_acc: 0.4555\n",
            "Epoch 11/100 - 0.69s - loss: 1.0629 - acc: 0.4687 - val_loss: 1.0701 - val_acc: 0.4575\n",
            "Epoch 12/100 - 0.72s - loss: 1.0606 - acc: 0.4739 - val_loss: 1.0678 - val_acc: 0.4575\n",
            "Epoch 13/100 - 0.67s - loss: 1.0589 - acc: 0.4728 - val_loss: 1.0662 - val_acc: 0.4676\n",
            "Epoch 14/100 - 0.71s - loss: 1.0574 - acc: 0.4701 - val_loss: 1.0651 - val_acc: 0.4636\n",
            "Epoch 15/100 - 0.78s - loss: 1.0552 - acc: 0.4762 - val_loss: 1.0635 - val_acc: 0.4757\n",
            "Epoch 16/100 - 0.74s - loss: 1.0538 - acc: 0.4804 - val_loss: 1.0632 - val_acc: 0.4636\n",
            "Epoch 17/100 - 0.75s - loss: 1.0520 - acc: 0.4820 - val_loss: 1.0619 - val_acc: 0.4676\n",
            "Epoch 18/100 - 0.89s - loss: 1.0505 - acc: 0.4777 - val_loss: 1.0603 - val_acc: 0.4798\n",
            "Epoch 19/100 - 0.79s - loss: 1.0487 - acc: 0.4802 - val_loss: 1.0588 - val_acc: 0.4899\n",
            "Epoch 20/100 - 0.66s - loss: 1.0472 - acc: 0.4816 - val_loss: 1.0579 - val_acc: 0.4899\n",
            "Epoch 21/100 - 0.67s - loss: 1.0457 - acc: 0.4809 - val_loss: 1.0570 - val_acc: 0.4838\n",
            "Epoch 22/100 - 0.66s - loss: 1.0443 - acc: 0.4838 - val_loss: 1.0556 - val_acc: 0.4919\n",
            "Epoch 23/100 - 0.66s - loss: 1.0430 - acc: 0.4840 - val_loss: 1.0544 - val_acc: 0.5020\n",
            "Epoch 24/100 - 0.67s - loss: 1.0415 - acc: 0.4843 - val_loss: 1.0537 - val_acc: 0.4899\n",
            "Epoch 25/100 - 0.65s - loss: 1.0401 - acc: 0.4840 - val_loss: 1.0527 - val_acc: 0.4960\n",
            "Epoch 26/100 - 0.65s - loss: 1.0388 - acc: 0.4870 - val_loss: 1.0516 - val_acc: 0.5020\n",
            "Epoch 27/100 - 0.66s - loss: 1.0377 - acc: 0.4863 - val_loss: 1.0507 - val_acc: 0.5000\n",
            "Epoch 28/100 - 0.66s - loss: 1.0361 - acc: 0.4903 - val_loss: 1.0497 - val_acc: 0.5101\n",
            "Epoch 29/100 - 0.67s - loss: 1.0349 - acc: 0.4908 - val_loss: 1.0491 - val_acc: 0.5020\n",
            "Epoch 30/100 - 0.75s - loss: 1.0338 - acc: 0.4919 - val_loss: 1.0485 - val_acc: 0.4919\n",
            "Epoch 31/100 - 0.69s - loss: 1.0324 - acc: 0.4919 - val_loss: 1.0472 - val_acc: 0.5121\n",
            "Epoch 32/100 - 0.77s - loss: 1.0314 - acc: 0.4915 - val_loss: 1.0463 - val_acc: 0.5061\n",
            "Epoch 33/100 - 0.68s - loss: 1.0298 - acc: 0.4928 - val_loss: 1.0449 - val_acc: 0.5162\n",
            "Epoch 34/100 - 0.67s - loss: 1.0288 - acc: 0.4957 - val_loss: 1.0445 - val_acc: 0.5101\n",
            "Epoch 35/100 - 0.69s - loss: 1.0275 - acc: 0.4957 - val_loss: 1.0432 - val_acc: 0.5223\n",
            "Epoch 36/100 - 0.69s - loss: 1.0263 - acc: 0.4964 - val_loss: 1.0425 - val_acc: 0.5202\n",
            "Epoch 37/100 - 0.67s - loss: 1.0252 - acc: 0.4964 - val_loss: 1.0410 - val_acc: 0.5162\n",
            "Epoch 38/100 - 0.66s - loss: 1.0239 - acc: 0.5002 - val_loss: 1.0404 - val_acc: 0.5243\n",
            "Epoch 39/100 - 0.71s - loss: 1.0228 - acc: 0.4996 - val_loss: 1.0392 - val_acc: 0.5142\n",
            "Epoch 40/100 - 0.67s - loss: 1.0216 - acc: 0.5007 - val_loss: 1.0391 - val_acc: 0.5202\n",
            "Epoch 41/100 - 0.67s - loss: 1.0205 - acc: 0.5018 - val_loss: 1.0379 - val_acc: 0.5283\n",
            "Epoch 42/100 - 0.72s - loss: 1.0195 - acc: 0.5029 - val_loss: 1.0373 - val_acc: 0.5182\n",
            "Epoch 43/100 - 0.72s - loss: 1.0181 - acc: 0.5040 - val_loss: 1.0362 - val_acc: 0.5263\n",
            "Epoch 44/100 - 0.68s - loss: 1.0169 - acc: 0.5063 - val_loss: 1.0350 - val_acc: 0.5223\n",
            "Epoch 45/100 - 0.70s - loss: 1.0158 - acc: 0.5065 - val_loss: 1.0344 - val_acc: 0.5324\n",
            "Epoch 46/100 - 0.66s - loss: 1.0149 - acc: 0.5081 - val_loss: 1.0337 - val_acc: 0.5243\n",
            "Epoch 47/100 - 0.71s - loss: 1.0138 - acc: 0.5090 - val_loss: 1.0331 - val_acc: 0.5162\n",
            "Epoch 48/100 - 0.77s - loss: 1.0124 - acc: 0.5094 - val_loss: 1.0314 - val_acc: 0.5283\n",
            "Epoch 49/100 - 0.71s - loss: 1.0115 - acc: 0.5072 - val_loss: 1.0304 - val_acc: 0.5202\n",
            "Epoch 50/100 - 0.73s - loss: 1.0104 - acc: 0.5128 - val_loss: 1.0300 - val_acc: 0.5263\n",
            "Epoch 51/100 - 0.73s - loss: 1.0094 - acc: 0.5142 - val_loss: 1.0295 - val_acc: 0.5162\n",
            "Epoch 52/100 - 0.67s - loss: 1.0083 - acc: 0.5121 - val_loss: 1.0278 - val_acc: 0.5202\n",
            "Epoch 53/100 - 0.70s - loss: 1.0072 - acc: 0.5124 - val_loss: 1.0268 - val_acc: 0.5223\n",
            "Epoch 54/100 - 0.74s - loss: 1.0059 - acc: 0.5119 - val_loss: 1.0264 - val_acc: 0.5364\n",
            "Epoch 55/100 - 0.75s - loss: 1.0052 - acc: 0.5144 - val_loss: 1.0256 - val_acc: 0.5263\n",
            "Epoch 56/100 - 0.69s - loss: 1.0043 - acc: 0.5110 - val_loss: 1.0244 - val_acc: 0.5324\n",
            "Epoch 57/100 - 0.68s - loss: 1.0028 - acc: 0.5137 - val_loss: 1.0234 - val_acc: 0.5283\n",
            "Epoch 58/100 - 0.69s - loss: 1.0017 - acc: 0.5144 - val_loss: 1.0225 - val_acc: 0.5283\n",
            "Epoch 59/100 - 0.65s - loss: 1.0010 - acc: 0.5175 - val_loss: 1.0220 - val_acc: 0.5304\n",
            "Epoch 60/100 - 0.77s - loss: 1.0002 - acc: 0.5151 - val_loss: 1.0213 - val_acc: 0.5243\n",
            "Epoch 61/100 - 0.73s - loss: 0.9986 - acc: 0.5189 - val_loss: 1.0203 - val_acc: 0.5283\n",
            "Epoch 62/100 - 0.71s - loss: 0.9977 - acc: 0.5173 - val_loss: 1.0190 - val_acc: 0.5324\n",
            "Epoch 63/100 - 0.66s - loss: 0.9966 - acc: 0.5205 - val_loss: 1.0189 - val_acc: 0.5263\n",
            "Epoch 64/100 - 0.70s - loss: 0.9967 - acc: 0.5184 - val_loss: 1.0183 - val_acc: 0.5405\n",
            "Epoch 65/100 - 0.76s - loss: 0.9945 - acc: 0.5211 - val_loss: 1.0171 - val_acc: 0.5324\n",
            "Epoch 66/100 - 0.77s - loss: 0.9935 - acc: 0.5232 - val_loss: 1.0162 - val_acc: 0.5364\n",
            "Epoch 67/100 - 0.64s - loss: 0.9924 - acc: 0.5236 - val_loss: 1.0151 - val_acc: 0.5405\n",
            "Epoch 68/100 - 0.61s - loss: 0.9918 - acc: 0.5250 - val_loss: 1.0142 - val_acc: 0.5445\n",
            "Epoch 69/100 - 0.62s - loss: 0.9905 - acc: 0.5268 - val_loss: 1.0131 - val_acc: 0.5445\n",
            "Epoch 70/100 - 0.70s - loss: 0.9894 - acc: 0.5245 - val_loss: 1.0125 - val_acc: 0.5445\n",
            "Epoch 71/100 - 0.70s - loss: 0.9884 - acc: 0.5259 - val_loss: 1.0115 - val_acc: 0.5506\n",
            "Epoch 72/100 - 0.64s - loss: 0.9876 - acc: 0.5238 - val_loss: 1.0112 - val_acc: 0.5324\n",
            "Epoch 73/100 - 0.67s - loss: 0.9865 - acc: 0.5272 - val_loss: 1.0103 - val_acc: 0.5385\n",
            "Epoch 74/100 - 0.65s - loss: 0.9856 - acc: 0.5283 - val_loss: 1.0091 - val_acc: 0.5526\n",
            "Epoch 75/100 - 0.68s - loss: 0.9848 - acc: 0.5252 - val_loss: 1.0086 - val_acc: 0.5405\n",
            "Epoch 76/100 - 0.66s - loss: 0.9837 - acc: 0.5274 - val_loss: 1.0075 - val_acc: 0.5466\n",
            "Epoch 77/100 - 0.68s - loss: 0.9829 - acc: 0.5268 - val_loss: 1.0073 - val_acc: 0.5324\n",
            "Epoch 78/100 - 0.67s - loss: 0.9827 - acc: 0.5277 - val_loss: 1.0078 - val_acc: 0.5202\n",
            "Epoch 79/100 - 0.63s - loss: 0.9812 - acc: 0.5279 - val_loss: 1.0054 - val_acc: 0.5324\n",
            "Epoch 80/100 - 0.64s - loss: 0.9804 - acc: 0.5335 - val_loss: 1.0057 - val_acc: 0.5425\n",
            "Epoch 81/100 - 0.64s - loss: 0.9794 - acc: 0.5317 - val_loss: 1.0047 - val_acc: 0.5385\n",
            "Epoch 82/100 - 0.65s - loss: 0.9788 - acc: 0.5353 - val_loss: 1.0035 - val_acc: 0.5547\n",
            "Epoch 83/100 - 0.61s - loss: 0.9773 - acc: 0.5331 - val_loss: 1.0025 - val_acc: 0.5385\n",
            "Epoch 84/100 - 0.64s - loss: 0.9763 - acc: 0.5355 - val_loss: 1.0016 - val_acc: 0.5466\n",
            "Epoch 85/100 - 0.61s - loss: 0.9756 - acc: 0.5358 - val_loss: 1.0013 - val_acc: 0.5405\n",
            "Epoch 86/100 - 0.60s - loss: 0.9747 - acc: 0.5315 - val_loss: 1.0002 - val_acc: 0.5385\n",
            "Epoch 87/100 - 0.62s - loss: 0.9737 - acc: 0.5322 - val_loss: 0.9991 - val_acc: 0.5445\n",
            "Epoch 88/100 - 0.61s - loss: 0.9728 - acc: 0.5335 - val_loss: 0.9984 - val_acc: 0.5425\n",
            "Epoch 89/100 - 0.61s - loss: 0.9720 - acc: 0.5362 - val_loss: 0.9978 - val_acc: 0.5385\n",
            "Epoch 90/100 - 0.69s - loss: 0.9712 - acc: 0.5353 - val_loss: 0.9968 - val_acc: 0.5385\n",
            "Epoch 91/100 - 0.64s - loss: 0.9704 - acc: 0.5344 - val_loss: 0.9962 - val_acc: 0.5567\n",
            "Epoch 92/100 - 0.72s - loss: 0.9695 - acc: 0.5367 - val_loss: 0.9955 - val_acc: 0.5567\n",
            "Epoch 93/100 - 0.63s - loss: 0.9687 - acc: 0.5400 - val_loss: 0.9954 - val_acc: 0.5385\n",
            "Epoch 94/100 - 0.65s - loss: 0.9677 - acc: 0.5373 - val_loss: 0.9940 - val_acc: 0.5445\n",
            "Epoch 95/100 - 0.65s - loss: 0.9671 - acc: 0.5425 - val_loss: 0.9938 - val_acc: 0.5547\n",
            "Epoch 96/100 - 0.73s - loss: 0.9660 - acc: 0.5387 - val_loss: 0.9925 - val_acc: 0.5445\n",
            "Epoch 97/100 - 0.74s - loss: 0.9652 - acc: 0.5412 - val_loss: 0.9919 - val_acc: 0.5445\n",
            "Epoch 98/100 - 0.62s - loss: 0.9652 - acc: 0.5403 - val_loss: 0.9923 - val_acc: 0.5324\n",
            "Epoch 99/100 - 0.61s - loss: 0.9637 - acc: 0.5434 - val_loss: 0.9905 - val_acc: 0.5607\n",
            "Epoch 100/100 - 0.64s - loss: 0.9629 - acc: 0.5427 - val_loss: 0.9901 - val_acc: 0.5607\n",
            "\n",
            "Combination 243/252:\n",
            "Hidden Layers: [512, 256, 128], Activation: tanh, Learning Rate: 0.001, Batch Size: 32, Epochs: 150\n",
            "Epoch 1/150 - 0.62s - loss: 1.0910 - acc: 0.3666 - val_loss: 1.0959 - val_acc: 0.3421\n",
            "Epoch 2/150 - 0.64s - loss: 1.0868 - acc: 0.3817 - val_loss: 1.0920 - val_acc: 0.3968\n",
            "Epoch 3/150 - 0.62s - loss: 1.0834 - acc: 0.3972 - val_loss: 1.0891 - val_acc: 0.4130\n",
            "Epoch 4/150 - 0.61s - loss: 1.0804 - acc: 0.4080 - val_loss: 1.0865 - val_acc: 0.4028\n",
            "Epoch 5/150 - 0.62s - loss: 1.0776 - acc: 0.4168 - val_loss: 1.0844 - val_acc: 0.4150\n",
            "Epoch 6/150 - 0.64s - loss: 1.0751 - acc: 0.4240 - val_loss: 1.0823 - val_acc: 0.4231\n",
            "Epoch 7/150 - 0.62s - loss: 1.0727 - acc: 0.4318 - val_loss: 1.0807 - val_acc: 0.4271\n",
            "Epoch 8/150 - 0.72s - loss: 1.0705 - acc: 0.4332 - val_loss: 1.0789 - val_acc: 0.4332\n",
            "Epoch 9/150 - 0.63s - loss: 1.0684 - acc: 0.4366 - val_loss: 1.0771 - val_acc: 0.4393\n",
            "Epoch 10/150 - 0.76s - loss: 1.0665 - acc: 0.4381 - val_loss: 1.0758 - val_acc: 0.4433\n",
            "Epoch 11/150 - 0.63s - loss: 1.0646 - acc: 0.4417 - val_loss: 1.0745 - val_acc: 0.4453\n",
            "Epoch 12/150 - 0.62s - loss: 1.0629 - acc: 0.4426 - val_loss: 1.0733 - val_acc: 0.4453\n",
            "Epoch 13/150 - 0.62s - loss: 1.0612 - acc: 0.4438 - val_loss: 1.0718 - val_acc: 0.4494\n",
            "Epoch 14/150 - 0.65s - loss: 1.0596 - acc: 0.4424 - val_loss: 1.0706 - val_acc: 0.4494\n",
            "Epoch 15/150 - 0.62s - loss: 1.0581 - acc: 0.4507 - val_loss: 1.0697 - val_acc: 0.4534\n",
            "Epoch 16/150 - 0.61s - loss: 1.0567 - acc: 0.4521 - val_loss: 1.0684 - val_acc: 0.4514\n",
            "Epoch 17/150 - 0.62s - loss: 1.0551 - acc: 0.4489 - val_loss: 1.0677 - val_acc: 0.4656\n",
            "Epoch 18/150 - 0.61s - loss: 1.0537 - acc: 0.4485 - val_loss: 1.0663 - val_acc: 0.4534\n",
            "Epoch 19/150 - 0.62s - loss: 1.0523 - acc: 0.4510 - val_loss: 1.0652 - val_acc: 0.4534\n",
            "Epoch 20/150 - 0.68s - loss: 1.0509 - acc: 0.4514 - val_loss: 1.0644 - val_acc: 0.4555\n",
            "Epoch 21/150 - 0.61s - loss: 1.0496 - acc: 0.4600 - val_loss: 1.0637 - val_acc: 0.4656\n",
            "Epoch 22/150 - 0.62s - loss: 1.0484 - acc: 0.4586 - val_loss: 1.0625 - val_acc: 0.4656\n",
            "Epoch 23/150 - 0.60s - loss: 1.0470 - acc: 0.4627 - val_loss: 1.0619 - val_acc: 0.4717\n",
            "Epoch 24/150 - 0.61s - loss: 1.0458 - acc: 0.4615 - val_loss: 1.0611 - val_acc: 0.4777\n",
            "Epoch 25/150 - 0.63s - loss: 1.0446 - acc: 0.4636 - val_loss: 1.0600 - val_acc: 0.4656\n",
            "Epoch 26/150 - 0.62s - loss: 1.0434 - acc: 0.4660 - val_loss: 1.0594 - val_acc: 0.4757\n",
            "Epoch 27/150 - 0.61s - loss: 1.0422 - acc: 0.4665 - val_loss: 1.0582 - val_acc: 0.4717\n",
            "Epoch 28/150 - 0.61s - loss: 1.0410 - acc: 0.4676 - val_loss: 1.0575 - val_acc: 0.4717\n",
            "Epoch 29/150 - 0.64s - loss: 1.0399 - acc: 0.4701 - val_loss: 1.0567 - val_acc: 0.4696\n",
            "Epoch 30/150 - 0.66s - loss: 1.0387 - acc: 0.4699 - val_loss: 1.0558 - val_acc: 0.4696\n",
            "Epoch 31/150 - 0.66s - loss: 1.0376 - acc: 0.4737 - val_loss: 1.0554 - val_acc: 0.4777\n",
            "Epoch 32/150 - 0.66s - loss: 1.0364 - acc: 0.4737 - val_loss: 1.0543 - val_acc: 0.4757\n",
            "Epoch 33/150 - 0.64s - loss: 1.0353 - acc: 0.4771 - val_loss: 1.0537 - val_acc: 0.4798\n",
            "Epoch 34/150 - 0.65s - loss: 1.0342 - acc: 0.4777 - val_loss: 1.0529 - val_acc: 0.4838\n",
            "Epoch 35/150 - 0.66s - loss: 1.0332 - acc: 0.4773 - val_loss: 1.0524 - val_acc: 0.4737\n",
            "Epoch 36/150 - 0.65s - loss: 1.0321 - acc: 0.4768 - val_loss: 1.0516 - val_acc: 0.4696\n",
            "Epoch 37/150 - 0.66s - loss: 1.0309 - acc: 0.4804 - val_loss: 1.0506 - val_acc: 0.4818\n",
            "Epoch 38/150 - 0.67s - loss: 1.0298 - acc: 0.4816 - val_loss: 1.0498 - val_acc: 0.4818\n",
            "Epoch 39/150 - 0.64s - loss: 1.0287 - acc: 0.4822 - val_loss: 1.0490 - val_acc: 0.4818\n",
            "Epoch 40/150 - 0.64s - loss: 1.0277 - acc: 0.4822 - val_loss: 1.0481 - val_acc: 0.4798\n",
            "Epoch 41/150 - 0.66s - loss: 1.0266 - acc: 0.4845 - val_loss: 1.0475 - val_acc: 0.4858\n",
            "Epoch 42/150 - 0.73s - loss: 1.0255 - acc: 0.4903 - val_loss: 1.0470 - val_acc: 0.4939\n",
            "Epoch 43/150 - 0.76s - loss: 1.0244 - acc: 0.4861 - val_loss: 1.0460 - val_acc: 0.4939\n",
            "Epoch 44/150 - 0.70s - loss: 1.0234 - acc: 0.4908 - val_loss: 1.0457 - val_acc: 0.4939\n",
            "Epoch 45/150 - 0.68s - loss: 1.0223 - acc: 0.4894 - val_loss: 1.0445 - val_acc: 0.4960\n",
            "Epoch 46/150 - 0.68s - loss: 1.0213 - acc: 0.4917 - val_loss: 1.0440 - val_acc: 0.4939\n",
            "Epoch 47/150 - 0.66s - loss: 1.0202 - acc: 0.4955 - val_loss: 1.0434 - val_acc: 0.4980\n",
            "Epoch 48/150 - 0.66s - loss: 1.0191 - acc: 0.4930 - val_loss: 1.0424 - val_acc: 0.4980\n",
            "Epoch 49/150 - 0.66s - loss: 1.0181 - acc: 0.4969 - val_loss: 1.0419 - val_acc: 0.5020\n",
            "Epoch 50/150 - 0.71s - loss: 1.0172 - acc: 0.4971 - val_loss: 1.0416 - val_acc: 0.5121\n",
            "Epoch 51/150 - 0.67s - loss: 1.0160 - acc: 0.5002 - val_loss: 1.0405 - val_acc: 0.5040\n",
            "Epoch 52/150 - 0.69s - loss: 1.0149 - acc: 0.4957 - val_loss: 1.0392 - val_acc: 0.5020\n",
            "Epoch 53/150 - 0.71s - loss: 1.0138 - acc: 0.4982 - val_loss: 1.0387 - val_acc: 0.5040\n",
            "Epoch 54/150 - 0.75s - loss: 1.0128 - acc: 0.4987 - val_loss: 1.0378 - val_acc: 0.5061\n",
            "Epoch 55/150 - 0.69s - loss: 1.0117 - acc: 0.5056 - val_loss: 1.0373 - val_acc: 0.5121\n",
            "Epoch 56/150 - 0.70s - loss: 1.0107 - acc: 0.5004 - val_loss: 1.0362 - val_acc: 0.5020\n",
            "Epoch 57/150 - 0.66s - loss: 1.0096 - acc: 0.5054 - val_loss: 1.0356 - val_acc: 0.5081\n",
            "Epoch 58/150 - 0.66s - loss: 1.0088 - acc: 0.5002 - val_loss: 1.0348 - val_acc: 0.5020\n",
            "Epoch 59/150 - 0.68s - loss: 1.0076 - acc: 0.5063 - val_loss: 1.0339 - val_acc: 0.5121\n",
            "Epoch 60/150 - 0.68s - loss: 1.0066 - acc: 0.5061 - val_loss: 1.0331 - val_acc: 0.5142\n",
            "Epoch 61/150 - 0.66s - loss: 1.0054 - acc: 0.5090 - val_loss: 1.0324 - val_acc: 0.5061\n",
            "Epoch 62/150 - 0.66s - loss: 1.0044 - acc: 0.5117 - val_loss: 1.0320 - val_acc: 0.5162\n",
            "Epoch 63/150 - 0.63s - loss: 1.0034 - acc: 0.5130 - val_loss: 1.0315 - val_acc: 0.5243\n",
            "Epoch 64/150 - 0.60s - loss: 1.0023 - acc: 0.5137 - val_loss: 1.0304 - val_acc: 0.5202\n",
            "Epoch 65/150 - 0.64s - loss: 1.0012 - acc: 0.5142 - val_loss: 1.0294 - val_acc: 0.5121\n",
            "Epoch 66/150 - 0.60s - loss: 1.0003 - acc: 0.5157 - val_loss: 1.0287 - val_acc: 0.5142\n",
            "Epoch 67/150 - 0.62s - loss: 0.9991 - acc: 0.5151 - val_loss: 1.0280 - val_acc: 0.5202\n",
            "Epoch 68/150 - 0.64s - loss: 0.9982 - acc: 0.5157 - val_loss: 1.0274 - val_acc: 0.5223\n",
            "Epoch 69/150 - 0.61s - loss: 0.9974 - acc: 0.5153 - val_loss: 1.0269 - val_acc: 0.5142\n",
            "Epoch 70/150 - 0.61s - loss: 0.9961 - acc: 0.5144 - val_loss: 1.0256 - val_acc: 0.5101\n",
            "Epoch 71/150 - 0.61s - loss: 0.9950 - acc: 0.5160 - val_loss: 1.0249 - val_acc: 0.5182\n",
            "Epoch 72/150 - 0.68s - loss: 0.9940 - acc: 0.5182 - val_loss: 1.0239 - val_acc: 0.5182\n",
            "Epoch 73/150 - 0.66s - loss: 0.9930 - acc: 0.5205 - val_loss: 1.0236 - val_acc: 0.5182\n",
            "Epoch 74/150 - 0.69s - loss: 0.9920 - acc: 0.5189 - val_loss: 1.0227 - val_acc: 0.5223\n",
            "Epoch 75/150 - 0.65s - loss: 0.9909 - acc: 0.5207 - val_loss: 1.0220 - val_acc: 0.5182\n",
            "Epoch 76/150 - 0.63s - loss: 0.9901 - acc: 0.5178 - val_loss: 1.0210 - val_acc: 0.5283\n",
            "Epoch 77/150 - 0.64s - loss: 0.9890 - acc: 0.5209 - val_loss: 1.0204 - val_acc: 0.5142\n",
            "Epoch 78/150 - 0.66s - loss: 0.9880 - acc: 0.5211 - val_loss: 1.0200 - val_acc: 0.5223\n",
            "Epoch 79/150 - 0.63s - loss: 0.9870 - acc: 0.5193 - val_loss: 1.0191 - val_acc: 0.5202\n",
            "Epoch 80/150 - 0.63s - loss: 0.9860 - acc: 0.5211 - val_loss: 1.0177 - val_acc: 0.5223\n",
            "Epoch 81/150 - 0.62s - loss: 0.9849 - acc: 0.5238 - val_loss: 1.0174 - val_acc: 0.5182\n",
            "Epoch 82/150 - 0.66s - loss: 0.9841 - acc: 0.5245 - val_loss: 1.0169 - val_acc: 0.5182\n",
            "Epoch 83/150 - 0.68s - loss: 0.9829 - acc: 0.5234 - val_loss: 1.0156 - val_acc: 0.5182\n",
            "Epoch 84/150 - 0.61s - loss: 0.9820 - acc: 0.5265 - val_loss: 1.0150 - val_acc: 0.5142\n",
            "Epoch 85/150 - 0.62s - loss: 0.9810 - acc: 0.5268 - val_loss: 1.0144 - val_acc: 0.5162\n",
            "Epoch 86/150 - 0.68s - loss: 0.9803 - acc: 0.5241 - val_loss: 1.0133 - val_acc: 0.5324\n",
            "Epoch 87/150 - 0.64s - loss: 0.9795 - acc: 0.5254 - val_loss: 1.0136 - val_acc: 0.5202\n",
            "Epoch 88/150 - 0.62s - loss: 0.9782 - acc: 0.5272 - val_loss: 1.0124 - val_acc: 0.5223\n",
            "Epoch 89/150 - 0.61s - loss: 0.9773 - acc: 0.5279 - val_loss: 1.0112 - val_acc: 0.5263\n",
            "Epoch 90/150 - 0.61s - loss: 0.9765 - acc: 0.5268 - val_loss: 1.0113 - val_acc: 0.5223\n",
            "Epoch 91/150 - 0.62s - loss: 0.9762 - acc: 0.5268 - val_loss: 1.0113 - val_acc: 0.5182\n",
            "Epoch 92/150 - 0.62s - loss: 0.9748 - acc: 0.5270 - val_loss: 1.0092 - val_acc: 0.5385\n",
            "Epoch 93/150 - 0.61s - loss: 0.9734 - acc: 0.5299 - val_loss: 1.0085 - val_acc: 0.5223\n",
            "Epoch 94/150 - 0.61s - loss: 0.9736 - acc: 0.5281 - val_loss: 1.0081 - val_acc: 0.5445\n",
            "Epoch 95/150 - 0.61s - loss: 0.9723 - acc: 0.5319 - val_loss: 1.0078 - val_acc: 0.5223\n",
            "Epoch 96/150 - 0.60s - loss: 0.9710 - acc: 0.5283 - val_loss: 1.0068 - val_acc: 0.5304\n",
            "Epoch 97/150 - 0.68s - loss: 0.9700 - acc: 0.5333 - val_loss: 1.0066 - val_acc: 0.5304\n",
            "Epoch 98/150 - 0.71s - loss: 0.9690 - acc: 0.5333 - val_loss: 1.0055 - val_acc: 0.5304\n",
            "Epoch 99/150 - 0.67s - loss: 0.9681 - acc: 0.5337 - val_loss: 1.0044 - val_acc: 0.5304\n",
            "Epoch 100/150 - 0.64s - loss: 0.9677 - acc: 0.5310 - val_loss: 1.0044 - val_acc: 0.5364\n",
            "Epoch 101/150 - 0.63s - loss: 0.9667 - acc: 0.5310 - val_loss: 1.0035 - val_acc: 0.5344\n",
            "Epoch 102/150 - 0.66s - loss: 0.9655 - acc: 0.5351 - val_loss: 1.0032 - val_acc: 0.5324\n",
            "Epoch 103/150 - 0.67s - loss: 0.9657 - acc: 0.5358 - val_loss: 1.0028 - val_acc: 0.5425\n",
            "Epoch 104/150 - 0.63s - loss: 0.9637 - acc: 0.5353 - val_loss: 1.0016 - val_acc: 0.5324\n",
            "Epoch 105/150 - 0.63s - loss: 0.9628 - acc: 0.5369 - val_loss: 1.0008 - val_acc: 0.5283\n",
            "Epoch 106/150 - 0.62s - loss: 0.9620 - acc: 0.5362 - val_loss: 1.0004 - val_acc: 0.5304\n",
            "Epoch 107/150 - 0.62s - loss: 0.9613 - acc: 0.5364 - val_loss: 0.9999 - val_acc: 0.5263\n",
            "Epoch 108/150 - 0.62s - loss: 0.9608 - acc: 0.5362 - val_loss: 0.9993 - val_acc: 0.5243\n",
            "Epoch 109/150 - 0.65s - loss: 0.9602 - acc: 0.5382 - val_loss: 0.9995 - val_acc: 0.5263\n",
            "Epoch 110/150 - 0.63s - loss: 0.9588 - acc: 0.5389 - val_loss: 0.9980 - val_acc: 0.5283\n",
            "Epoch 111/150 - 0.62s - loss: 0.9580 - acc: 0.5398 - val_loss: 0.9973 - val_acc: 0.5283\n",
            "Epoch 112/150 - 0.62s - loss: 0.9572 - acc: 0.5407 - val_loss: 0.9965 - val_acc: 0.5304\n",
            "Epoch 113/150 - 0.62s - loss: 0.9569 - acc: 0.5425 - val_loss: 0.9963 - val_acc: 0.5506\n",
            "Epoch 114/150 - 0.61s - loss: 0.9567 - acc: 0.5385 - val_loss: 0.9971 - val_acc: 0.5243\n",
            "Epoch 115/150 - 0.66s - loss: 0.9550 - acc: 0.5403 - val_loss: 0.9954 - val_acc: 0.5324\n",
            "Epoch 116/150 - 0.62s - loss: 0.9544 - acc: 0.5445 - val_loss: 0.9946 - val_acc: 0.5466\n",
            "Epoch 117/150 - 0.62s - loss: 0.9533 - acc: 0.5441 - val_loss: 0.9938 - val_acc: 0.5324\n",
            "Epoch 118/150 - 0.62s - loss: 0.9526 - acc: 0.5441 - val_loss: 0.9933 - val_acc: 0.5364\n",
            "Epoch 119/150 - 0.62s - loss: 0.9519 - acc: 0.5423 - val_loss: 0.9932 - val_acc: 0.5304\n",
            "Epoch 120/150 - 0.61s - loss: 0.9518 - acc: 0.5448 - val_loss: 0.9932 - val_acc: 0.5445\n",
            "Epoch 121/150 - 0.64s - loss: 0.9509 - acc: 0.5441 - val_loss: 0.9921 - val_acc: 0.5466\n",
            "Epoch 122/150 - 0.60s - loss: 0.9498 - acc: 0.5466 - val_loss: 0.9912 - val_acc: 0.5466\n",
            "Epoch 123/150 - 0.61s - loss: 0.9492 - acc: 0.5459 - val_loss: 0.9911 - val_acc: 0.5364\n",
            "Epoch 124/150 - 0.60s - loss: 0.9485 - acc: 0.5452 - val_loss: 0.9906 - val_acc: 0.5364\n",
            "Epoch 125/150 - 0.62s - loss: 0.9476 - acc: 0.5434 - val_loss: 0.9906 - val_acc: 0.5405\n",
            "Epoch 126/150 - 0.62s - loss: 0.9473 - acc: 0.5463 - val_loss: 0.9899 - val_acc: 0.5344\n",
            "Epoch 127/150 - 0.63s - loss: 0.9463 - acc: 0.5463 - val_loss: 0.9894 - val_acc: 0.5385\n",
            "Epoch 128/150 - 0.60s - loss: 0.9454 - acc: 0.5472 - val_loss: 0.9887 - val_acc: 0.5405\n",
            "Epoch 129/150 - 0.61s - loss: 0.9453 - acc: 0.5454 - val_loss: 0.9887 - val_acc: 0.5364\n",
            "Epoch 130/150 - 0.60s - loss: 0.9460 - acc: 0.5425 - val_loss: 0.9908 - val_acc: 0.5344\n",
            "Epoch 131/150 - 0.61s - loss: 0.9434 - acc: 0.5504 - val_loss: 0.9868 - val_acc: 0.5466\n",
            "Epoch 132/150 - 0.61s - loss: 0.9426 - acc: 0.5484 - val_loss: 0.9866 - val_acc: 0.5466\n",
            "Epoch 133/150 - 0.64s - loss: 0.9420 - acc: 0.5490 - val_loss: 0.9861 - val_acc: 0.5445\n",
            "Epoch 134/150 - 0.62s - loss: 0.9413 - acc: 0.5522 - val_loss: 0.9859 - val_acc: 0.5445\n",
            "Epoch 135/150 - 0.62s - loss: 0.9408 - acc: 0.5488 - val_loss: 0.9862 - val_acc: 0.5425\n",
            "Epoch 136/150 - 0.61s - loss: 0.9403 - acc: 0.5488 - val_loss: 0.9856 - val_acc: 0.5405\n",
            "Epoch 137/150 - 0.62s - loss: 0.9397 - acc: 0.5524 - val_loss: 0.9857 - val_acc: 0.5304\n",
            "Epoch 138/150 - 0.60s - loss: 0.9393 - acc: 0.5495 - val_loss: 0.9858 - val_acc: 0.5324\n",
            "Epoch 139/150 - 0.64s - loss: 0.9383 - acc: 0.5506 - val_loss: 0.9848 - val_acc: 0.5385\n",
            "Epoch 140/150 - 0.60s - loss: 0.9378 - acc: 0.5558 - val_loss: 0.9831 - val_acc: 0.5547\n",
            "Epoch 141/150 - 0.61s - loss: 0.9377 - acc: 0.5551 - val_loss: 0.9840 - val_acc: 0.5445\n",
            "Epoch 142/150 - 0.62s - loss: 0.9366 - acc: 0.5524 - val_loss: 0.9833 - val_acc: 0.5324\n",
            "Epoch 143/150 - 0.62s - loss: 0.9357 - acc: 0.5544 - val_loss: 0.9826 - val_acc: 0.5385\n",
            "Epoch 144/150 - 0.61s - loss: 0.9355 - acc: 0.5556 - val_loss: 0.9818 - val_acc: 0.5425\n",
            "Epoch 145/150 - 0.64s - loss: 0.9347 - acc: 0.5565 - val_loss: 0.9818 - val_acc: 0.5425\n",
            "Epoch 146/150 - 0.77s - loss: 0.9340 - acc: 0.5571 - val_loss: 0.9807 - val_acc: 0.5547\n",
            "Epoch 147/150 - 0.71s - loss: 0.9339 - acc: 0.5574 - val_loss: 0.9805 - val_acc: 0.5587\n",
            "Epoch 148/150 - 0.79s - loss: 0.9326 - acc: 0.5565 - val_loss: 0.9807 - val_acc: 0.5486\n",
            "Epoch 149/150 - 0.76s - loss: 0.9324 - acc: 0.5526 - val_loss: 0.9812 - val_acc: 0.5364\n",
            "Epoch 150/150 - 0.80s - loss: 0.9322 - acc: 0.5526 - val_loss: 0.9809 - val_acc: 0.5385\n",
            "\n",
            "Combination 244/252:\n",
            "Hidden Layers: [512, 256, 128], Activation: tanh, Learning Rate: 0.001, Batch Size: 64, Epochs: 50\n",
            "Epoch 1/50 - 0.72s - loss: 1.1079 - acc: 0.2946 - val_loss: 1.1092 - val_acc: 0.2976\n",
            "Epoch 2/50 - 0.61s - loss: 1.1049 - acc: 0.3070 - val_loss: 1.1063 - val_acc: 0.2996\n",
            "Epoch 3/50 - 0.62s - loss: 1.1022 - acc: 0.3149 - val_loss: 1.1040 - val_acc: 0.3077\n",
            "Epoch 4/50 - 0.64s - loss: 1.0997 - acc: 0.3194 - val_loss: 1.1020 - val_acc: 0.3178\n",
            "Epoch 5/50 - 0.63s - loss: 1.0973 - acc: 0.3383 - val_loss: 1.0999 - val_acc: 0.3300\n",
            "Epoch 6/50 - 0.63s - loss: 1.0950 - acc: 0.3585 - val_loss: 1.0981 - val_acc: 0.3219\n",
            "Epoch 7/50 - 0.68s - loss: 1.0929 - acc: 0.3763 - val_loss: 1.0962 - val_acc: 0.3482\n",
            "Epoch 8/50 - 0.61s - loss: 1.0908 - acc: 0.3878 - val_loss: 1.0945 - val_acc: 0.3745\n",
            "Epoch 9/50 - 0.56s - loss: 1.0890 - acc: 0.3968 - val_loss: 1.0931 - val_acc: 0.3785\n",
            "Epoch 10/50 - 0.53s - loss: 1.0871 - acc: 0.4067 - val_loss: 1.0914 - val_acc: 0.3866\n",
            "Epoch 11/50 - 0.57s - loss: 1.0854 - acc: 0.4150 - val_loss: 1.0900 - val_acc: 0.3866\n",
            "Epoch 12/50 - 0.59s - loss: 1.0838 - acc: 0.4197 - val_loss: 1.0887 - val_acc: 0.4089\n",
            "Epoch 13/50 - 0.62s - loss: 1.0822 - acc: 0.4233 - val_loss: 1.0874 - val_acc: 0.4008\n",
            "Epoch 14/50 - 0.57s - loss: 1.0807 - acc: 0.4244 - val_loss: 1.0862 - val_acc: 0.4130\n",
            "Epoch 15/50 - 0.54s - loss: 1.0792 - acc: 0.4294 - val_loss: 1.0850 - val_acc: 0.4271\n",
            "Epoch 16/50 - 0.46s - loss: 1.0778 - acc: 0.4274 - val_loss: 1.0841 - val_acc: 0.4150\n",
            "Epoch 17/50 - 0.45s - loss: 1.0764 - acc: 0.4309 - val_loss: 1.0830 - val_acc: 0.4211\n",
            "Epoch 18/50 - 0.46s - loss: 1.0751 - acc: 0.4330 - val_loss: 1.0820 - val_acc: 0.4211\n",
            "Epoch 19/50 - 0.46s - loss: 1.0739 - acc: 0.4390 - val_loss: 1.0809 - val_acc: 0.4251\n",
            "Epoch 20/50 - 0.44s - loss: 1.0726 - acc: 0.4393 - val_loss: 1.0800 - val_acc: 0.4271\n",
            "Epoch 21/50 - 0.45s - loss: 1.0714 - acc: 0.4426 - val_loss: 1.0792 - val_acc: 0.4271\n",
            "Epoch 22/50 - 0.44s - loss: 1.0703 - acc: 0.4462 - val_loss: 1.0783 - val_acc: 0.4372\n",
            "Epoch 23/50 - 0.45s - loss: 1.0692 - acc: 0.4471 - val_loss: 1.0774 - val_acc: 0.4393\n",
            "Epoch 24/50 - 0.46s - loss: 1.0681 - acc: 0.4480 - val_loss: 1.0765 - val_acc: 0.4352\n",
            "Epoch 25/50 - 0.47s - loss: 1.0670 - acc: 0.4496 - val_loss: 1.0757 - val_acc: 0.4332\n",
            "Epoch 26/50 - 0.44s - loss: 1.0660 - acc: 0.4476 - val_loss: 1.0750 - val_acc: 0.4393\n",
            "Epoch 27/50 - 0.45s - loss: 1.0650 - acc: 0.4523 - val_loss: 1.0739 - val_acc: 0.4312\n",
            "Epoch 28/50 - 0.45s - loss: 1.0640 - acc: 0.4530 - val_loss: 1.0732 - val_acc: 0.4372\n",
            "Epoch 29/50 - 0.50s - loss: 1.0630 - acc: 0.4566 - val_loss: 1.0725 - val_acc: 0.4393\n",
            "Epoch 30/50 - 0.45s - loss: 1.0621 - acc: 0.4568 - val_loss: 1.0717 - val_acc: 0.4352\n",
            "Epoch 31/50 - 0.47s - loss: 1.0611 - acc: 0.4557 - val_loss: 1.0710 - val_acc: 0.4352\n",
            "Epoch 32/50 - 0.46s - loss: 1.0602 - acc: 0.4575 - val_loss: 1.0704 - val_acc: 0.4393\n",
            "Epoch 33/50 - 0.44s - loss: 1.0592 - acc: 0.4582 - val_loss: 1.0698 - val_acc: 0.4413\n",
            "Epoch 34/50 - 0.45s - loss: 1.0584 - acc: 0.4609 - val_loss: 1.0690 - val_acc: 0.4393\n",
            "Epoch 35/50 - 0.45s - loss: 1.0575 - acc: 0.4609 - val_loss: 1.0685 - val_acc: 0.4453\n",
            "Epoch 36/50 - 0.47s - loss: 1.0566 - acc: 0.4618 - val_loss: 1.0678 - val_acc: 0.4433\n",
            "Epoch 37/50 - 0.48s - loss: 1.0557 - acc: 0.4640 - val_loss: 1.0671 - val_acc: 0.4453\n",
            "Epoch 38/50 - 0.44s - loss: 1.0549 - acc: 0.4647 - val_loss: 1.0666 - val_acc: 0.4494\n",
            "Epoch 39/50 - 0.44s - loss: 1.0541 - acc: 0.4618 - val_loss: 1.0662 - val_acc: 0.4534\n",
            "Epoch 40/50 - 0.45s - loss: 1.0532 - acc: 0.4656 - val_loss: 1.0655 - val_acc: 0.4575\n",
            "Epoch 41/50 - 0.44s - loss: 1.0524 - acc: 0.4656 - val_loss: 1.0648 - val_acc: 0.4534\n",
            "Epoch 42/50 - 0.44s - loss: 1.0516 - acc: 0.4667 - val_loss: 1.0640 - val_acc: 0.4494\n",
            "Epoch 43/50 - 0.46s - loss: 1.0508 - acc: 0.4692 - val_loss: 1.0635 - val_acc: 0.4555\n",
            "Epoch 44/50 - 0.44s - loss: 1.0500 - acc: 0.4681 - val_loss: 1.0629 - val_acc: 0.4534\n",
            "Epoch 45/50 - 0.45s - loss: 1.0492 - acc: 0.4687 - val_loss: 1.0623 - val_acc: 0.4575\n",
            "Epoch 46/50 - 0.44s - loss: 1.0485 - acc: 0.4710 - val_loss: 1.0616 - val_acc: 0.4636\n",
            "Epoch 47/50 - 0.44s - loss: 1.0477 - acc: 0.4728 - val_loss: 1.0612 - val_acc: 0.4676\n",
            "Epoch 48/50 - 0.46s - loss: 1.0470 - acc: 0.4701 - val_loss: 1.0609 - val_acc: 0.4636\n",
            "Epoch 49/50 - 0.47s - loss: 1.0462 - acc: 0.4714 - val_loss: 1.0601 - val_acc: 0.4615\n",
            "Epoch 50/50 - 0.43s - loss: 1.0455 - acc: 0.4721 - val_loss: 1.0597 - val_acc: 0.4636\n",
            "\n",
            "Combination 245/252:\n",
            "Hidden Layers: [512, 256, 128], Activation: tanh, Learning Rate: 0.001, Batch Size: 64, Epochs: 100\n",
            "Epoch 1/100 - 0.45s - loss: 1.0963 - acc: 0.3686 - val_loss: 1.0998 - val_acc: 0.3684\n",
            "Epoch 2/100 - 0.45s - loss: 1.0935 - acc: 0.3758 - val_loss: 1.0969 - val_acc: 0.3684\n",
            "Epoch 3/100 - 0.45s - loss: 1.0910 - acc: 0.3844 - val_loss: 1.0948 - val_acc: 0.3745\n",
            "Epoch 4/100 - 0.47s - loss: 1.0887 - acc: 0.3905 - val_loss: 1.0929 - val_acc: 0.3907\n",
            "Epoch 5/100 - 0.46s - loss: 1.0866 - acc: 0.3963 - val_loss: 1.0911 - val_acc: 0.4028\n",
            "Epoch 6/100 - 0.45s - loss: 1.0845 - acc: 0.4022 - val_loss: 1.0893 - val_acc: 0.4069\n",
            "Epoch 7/100 - 0.44s - loss: 1.0825 - acc: 0.4042 - val_loss: 1.0877 - val_acc: 0.4150\n",
            "Epoch 8/100 - 0.44s - loss: 1.0806 - acc: 0.4096 - val_loss: 1.0862 - val_acc: 0.4150\n",
            "Epoch 9/100 - 0.44s - loss: 1.0788 - acc: 0.4184 - val_loss: 1.0848 - val_acc: 0.4130\n",
            "Epoch 10/100 - 0.46s - loss: 1.0771 - acc: 0.4184 - val_loss: 1.0836 - val_acc: 0.4028\n",
            "Epoch 11/100 - 0.45s - loss: 1.0755 - acc: 0.4226 - val_loss: 1.0822 - val_acc: 0.4130\n",
            "Epoch 12/100 - 0.44s - loss: 1.0738 - acc: 0.4267 - val_loss: 1.0808 - val_acc: 0.4231\n",
            "Epoch 13/100 - 0.45s - loss: 1.0723 - acc: 0.4348 - val_loss: 1.0795 - val_acc: 0.4231\n",
            "Epoch 14/100 - 0.46s - loss: 1.0708 - acc: 0.4366 - val_loss: 1.0784 - val_acc: 0.4271\n",
            "Epoch 15/100 - 0.45s - loss: 1.0695 - acc: 0.4440 - val_loss: 1.0771 - val_acc: 0.4413\n",
            "Epoch 16/100 - 0.43s - loss: 1.0680 - acc: 0.4465 - val_loss: 1.0762 - val_acc: 0.4231\n",
            "Epoch 17/100 - 0.46s - loss: 1.0667 - acc: 0.4478 - val_loss: 1.0751 - val_acc: 0.4271\n",
            "Epoch 18/100 - 0.44s - loss: 1.0654 - acc: 0.4456 - val_loss: 1.0740 - val_acc: 0.4312\n",
            "Epoch 19/100 - 0.45s - loss: 1.0642 - acc: 0.4465 - val_loss: 1.0730 - val_acc: 0.4372\n",
            "Epoch 20/100 - 0.44s - loss: 1.0629 - acc: 0.4541 - val_loss: 1.0721 - val_acc: 0.4393\n",
            "Epoch 21/100 - 0.45s - loss: 1.0617 - acc: 0.4566 - val_loss: 1.0712 - val_acc: 0.4352\n",
            "Epoch 22/100 - 0.47s - loss: 1.0606 - acc: 0.4604 - val_loss: 1.0704 - val_acc: 0.4312\n",
            "Epoch 23/100 - 0.47s - loss: 1.0595 - acc: 0.4591 - val_loss: 1.0693 - val_acc: 0.4433\n",
            "Epoch 24/100 - 0.45s - loss: 1.0584 - acc: 0.4627 - val_loss: 1.0685 - val_acc: 0.4393\n",
            "Epoch 25/100 - 0.44s - loss: 1.0573 - acc: 0.4642 - val_loss: 1.0679 - val_acc: 0.4312\n",
            "Epoch 26/100 - 0.44s - loss: 1.0562 - acc: 0.4651 - val_loss: 1.0670 - val_acc: 0.4332\n",
            "Epoch 27/100 - 0.45s - loss: 1.0552 - acc: 0.4649 - val_loss: 1.0660 - val_acc: 0.4352\n",
            "Epoch 28/100 - 0.45s - loss: 1.0541 - acc: 0.4665 - val_loss: 1.0654 - val_acc: 0.4332\n",
            "Epoch 29/100 - 0.48s - loss: 1.0532 - acc: 0.4667 - val_loss: 1.0644 - val_acc: 0.4372\n",
            "Epoch 30/100 - 0.46s - loss: 1.0523 - acc: 0.4683 - val_loss: 1.0637 - val_acc: 0.4413\n",
            "Epoch 31/100 - 0.44s - loss: 1.0513 - acc: 0.4717 - val_loss: 1.0631 - val_acc: 0.4372\n",
            "Epoch 32/100 - 0.44s - loss: 1.0503 - acc: 0.4726 - val_loss: 1.0625 - val_acc: 0.4453\n",
            "Epoch 33/100 - 0.44s - loss: 1.0494 - acc: 0.4730 - val_loss: 1.0619 - val_acc: 0.4433\n",
            "Epoch 34/100 - 0.45s - loss: 1.0485 - acc: 0.4737 - val_loss: 1.0609 - val_acc: 0.4413\n",
            "Epoch 35/100 - 0.47s - loss: 1.0476 - acc: 0.4775 - val_loss: 1.0604 - val_acc: 0.4433\n",
            "Epoch 36/100 - 0.45s - loss: 1.0468 - acc: 0.4773 - val_loss: 1.0596 - val_acc: 0.4494\n",
            "Epoch 37/100 - 0.45s - loss: 1.0459 - acc: 0.4780 - val_loss: 1.0590 - val_acc: 0.4474\n",
            "Epoch 38/100 - 0.46s - loss: 1.0450 - acc: 0.4802 - val_loss: 1.0584 - val_acc: 0.4494\n",
            "Epoch 39/100 - 0.45s - loss: 1.0442 - acc: 0.4825 - val_loss: 1.0581 - val_acc: 0.4514\n",
            "Epoch 40/100 - 0.44s - loss: 1.0433 - acc: 0.4816 - val_loss: 1.0572 - val_acc: 0.4453\n",
            "Epoch 41/100 - 0.47s - loss: 1.0425 - acc: 0.4831 - val_loss: 1.0566 - val_acc: 0.4474\n",
            "Epoch 42/100 - 0.44s - loss: 1.0417 - acc: 0.4845 - val_loss: 1.0560 - val_acc: 0.4453\n",
            "Epoch 43/100 - 0.44s - loss: 1.0409 - acc: 0.4840 - val_loss: 1.0555 - val_acc: 0.4494\n",
            "Epoch 44/100 - 0.45s - loss: 1.0401 - acc: 0.4845 - val_loss: 1.0547 - val_acc: 0.4514\n",
            "Epoch 45/100 - 0.44s - loss: 1.0393 - acc: 0.4865 - val_loss: 1.0542 - val_acc: 0.4575\n",
            "Epoch 46/100 - 0.47s - loss: 1.0386 - acc: 0.4870 - val_loss: 1.0538 - val_acc: 0.4676\n",
            "Epoch 47/100 - 0.50s - loss: 1.0378 - acc: 0.4874 - val_loss: 1.0532 - val_acc: 0.4676\n",
            "Epoch 48/100 - 0.46s - loss: 1.0371 - acc: 0.4872 - val_loss: 1.0527 - val_acc: 0.4453\n",
            "Epoch 49/100 - 0.44s - loss: 1.0363 - acc: 0.4899 - val_loss: 1.0520 - val_acc: 0.4595\n",
            "Epoch 50/100 - 0.44s - loss: 1.0355 - acc: 0.4899 - val_loss: 1.0515 - val_acc: 0.4656\n",
            "Epoch 51/100 - 0.45s - loss: 1.0348 - acc: 0.4917 - val_loss: 1.0509 - val_acc: 0.4595\n",
            "Epoch 52/100 - 0.44s - loss: 1.0340 - acc: 0.4915 - val_loss: 1.0503 - val_acc: 0.4595\n",
            "Epoch 53/100 - 0.46s - loss: 1.0334 - acc: 0.4937 - val_loss: 1.0497 - val_acc: 0.4696\n",
            "Epoch 54/100 - 0.45s - loss: 1.0326 - acc: 0.4933 - val_loss: 1.0493 - val_acc: 0.4656\n",
            "Epoch 55/100 - 0.45s - loss: 1.0319 - acc: 0.4942 - val_loss: 1.0488 - val_acc: 0.4656\n",
            "Epoch 56/100 - 0.44s - loss: 1.0312 - acc: 0.4951 - val_loss: 1.0483 - val_acc: 0.4696\n",
            "Epoch 57/100 - 0.45s - loss: 1.0305 - acc: 0.4960 - val_loss: 1.0478 - val_acc: 0.4676\n",
            "Epoch 58/100 - 0.44s - loss: 1.0298 - acc: 0.4948 - val_loss: 1.0471 - val_acc: 0.4737\n",
            "Epoch 59/100 - 0.46s - loss: 1.0291 - acc: 0.4953 - val_loss: 1.0467 - val_acc: 0.4757\n",
            "Epoch 60/100 - 0.44s - loss: 1.0284 - acc: 0.4964 - val_loss: 1.0462 - val_acc: 0.4737\n",
            "Epoch 61/100 - 0.44s - loss: 1.0277 - acc: 0.4969 - val_loss: 1.0456 - val_acc: 0.4717\n",
            "Epoch 62/100 - 0.46s - loss: 1.0270 - acc: 0.4978 - val_loss: 1.0451 - val_acc: 0.4636\n",
            "Epoch 63/100 - 0.44s - loss: 1.0263 - acc: 0.4964 - val_loss: 1.0447 - val_acc: 0.4636\n",
            "Epoch 64/100 - 0.44s - loss: 1.0256 - acc: 0.4978 - val_loss: 1.0443 - val_acc: 0.4676\n",
            "Epoch 65/100 - 0.47s - loss: 1.0251 - acc: 0.4969 - val_loss: 1.0437 - val_acc: 0.4777\n",
            "Epoch 66/100 - 0.44s - loss: 1.0243 - acc: 0.4989 - val_loss: 1.0432 - val_acc: 0.4717\n",
            "Epoch 67/100 - 0.45s - loss: 1.0236 - acc: 0.4991 - val_loss: 1.0428 - val_acc: 0.4696\n",
            "Epoch 68/100 - 0.44s - loss: 1.0230 - acc: 0.4982 - val_loss: 1.0422 - val_acc: 0.4717\n",
            "Epoch 69/100 - 0.44s - loss: 1.0224 - acc: 0.5009 - val_loss: 1.0420 - val_acc: 0.4757\n",
            "Epoch 70/100 - 0.46s - loss: 1.0217 - acc: 0.5016 - val_loss: 1.0413 - val_acc: 0.4757\n",
            "Epoch 71/100 - 0.46s - loss: 1.0211 - acc: 0.5020 - val_loss: 1.0410 - val_acc: 0.4737\n",
            "Epoch 72/100 - 0.45s - loss: 1.0204 - acc: 0.4998 - val_loss: 1.0403 - val_acc: 0.4757\n",
            "Epoch 73/100 - 0.45s - loss: 1.0197 - acc: 0.5018 - val_loss: 1.0397 - val_acc: 0.4717\n",
            "Epoch 74/100 - 0.45s - loss: 1.0192 - acc: 0.5018 - val_loss: 1.0395 - val_acc: 0.4757\n",
            "Epoch 75/100 - 0.45s - loss: 1.0185 - acc: 0.5027 - val_loss: 1.0389 - val_acc: 0.4737\n",
            "Epoch 76/100 - 0.46s - loss: 1.0178 - acc: 0.5038 - val_loss: 1.0385 - val_acc: 0.4757\n",
            "Epoch 77/100 - 0.45s - loss: 1.0172 - acc: 0.5045 - val_loss: 1.0379 - val_acc: 0.4757\n",
            "Epoch 78/100 - 0.46s - loss: 1.0166 - acc: 0.5047 - val_loss: 1.0375 - val_acc: 0.4838\n",
            "Epoch 79/100 - 0.44s - loss: 1.0159 - acc: 0.5061 - val_loss: 1.0372 - val_acc: 0.4798\n",
            "Epoch 80/100 - 0.44s - loss: 1.0153 - acc: 0.5029 - val_loss: 1.0364 - val_acc: 0.4757\n",
            "Epoch 81/100 - 0.44s - loss: 1.0147 - acc: 0.5031 - val_loss: 1.0359 - val_acc: 0.4737\n",
            "Epoch 82/100 - 0.45s - loss: 1.0140 - acc: 0.5061 - val_loss: 1.0355 - val_acc: 0.4858\n",
            "Epoch 83/100 - 0.47s - loss: 1.0135 - acc: 0.5047 - val_loss: 1.0349 - val_acc: 0.4858\n",
            "Epoch 84/100 - 0.45s - loss: 1.0128 - acc: 0.5070 - val_loss: 1.0345 - val_acc: 0.4858\n",
            "Epoch 85/100 - 0.45s - loss: 1.0122 - acc: 0.5065 - val_loss: 1.0342 - val_acc: 0.4960\n",
            "Epoch 86/100 - 0.46s - loss: 1.0115 - acc: 0.5081 - val_loss: 1.0338 - val_acc: 0.4960\n",
            "Epoch 87/100 - 0.44s - loss: 1.0109 - acc: 0.5101 - val_loss: 1.0331 - val_acc: 0.4879\n",
            "Epoch 88/100 - 0.43s - loss: 1.0103 - acc: 0.5094 - val_loss: 1.0328 - val_acc: 0.4980\n",
            "Epoch 89/100 - 0.46s - loss: 1.0097 - acc: 0.5108 - val_loss: 1.0322 - val_acc: 0.4980\n",
            "Epoch 90/100 - 0.43s - loss: 1.0091 - acc: 0.5106 - val_loss: 1.0320 - val_acc: 0.4980\n",
            "Epoch 91/100 - 0.46s - loss: 1.0085 - acc: 0.5119 - val_loss: 1.0313 - val_acc: 0.5020\n",
            "Epoch 92/100 - 0.44s - loss: 1.0079 - acc: 0.5115 - val_loss: 1.0307 - val_acc: 0.4960\n",
            "Epoch 93/100 - 0.45s - loss: 1.0073 - acc: 0.5121 - val_loss: 1.0304 - val_acc: 0.5000\n",
            "Epoch 94/100 - 0.47s - loss: 1.0067 - acc: 0.5135 - val_loss: 1.0299 - val_acc: 0.5000\n",
            "Epoch 95/100 - 0.45s - loss: 1.0062 - acc: 0.5099 - val_loss: 1.0297 - val_acc: 0.4980\n",
            "Epoch 96/100 - 0.43s - loss: 1.0055 - acc: 0.5117 - val_loss: 1.0291 - val_acc: 0.4899\n",
            "Epoch 97/100 - 0.45s - loss: 1.0048 - acc: 0.5153 - val_loss: 1.0284 - val_acc: 0.5000\n",
            "Epoch 98/100 - 0.45s - loss: 1.0043 - acc: 0.5144 - val_loss: 1.0278 - val_acc: 0.5000\n",
            "Epoch 99/100 - 0.45s - loss: 1.0036 - acc: 0.5171 - val_loss: 1.0275 - val_acc: 0.5000\n",
            "Epoch 100/100 - 0.45s - loss: 1.0031 - acc: 0.5155 - val_loss: 1.0270 - val_acc: 0.5040\n",
            "\n",
            "Combination 246/252:\n",
            "Hidden Layers: [512, 256, 128], Activation: tanh, Learning Rate: 0.001, Batch Size: 64, Epochs: 150\n",
            "Epoch 1/150 - 0.47s - loss: 1.1012 - acc: 0.3432 - val_loss: 1.1039 - val_acc: 0.3300\n",
            "Epoch 2/150 - 0.45s - loss: 1.0984 - acc: 0.3549 - val_loss: 1.1017 - val_acc: 0.3381\n",
            "Epoch 3/150 - 0.45s - loss: 1.0961 - acc: 0.3623 - val_loss: 1.0998 - val_acc: 0.3421\n",
            "Epoch 4/150 - 0.43s - loss: 1.0940 - acc: 0.3707 - val_loss: 1.0979 - val_acc: 0.3543\n",
            "Epoch 5/150 - 0.45s - loss: 1.0920 - acc: 0.3799 - val_loss: 1.0962 - val_acc: 0.3623\n",
            "Epoch 6/150 - 0.44s - loss: 1.0901 - acc: 0.3878 - val_loss: 1.0944 - val_acc: 0.3664\n",
            "Epoch 7/150 - 0.47s - loss: 1.0882 - acc: 0.3878 - val_loss: 1.0933 - val_acc: 0.3684\n",
            "Epoch 8/150 - 0.44s - loss: 1.0865 - acc: 0.3965 - val_loss: 1.0917 - val_acc: 0.3684\n",
            "Epoch 9/150 - 0.45s - loss: 1.0848 - acc: 0.4004 - val_loss: 1.0901 - val_acc: 0.3704\n",
            "Epoch 10/150 - 0.45s - loss: 1.0832 - acc: 0.4055 - val_loss: 1.0891 - val_acc: 0.3704\n",
            "Epoch 11/150 - 0.44s - loss: 1.0817 - acc: 0.4114 - val_loss: 1.0877 - val_acc: 0.3684\n",
            "Epoch 12/150 - 0.45s - loss: 1.0802 - acc: 0.4163 - val_loss: 1.0863 - val_acc: 0.3745\n",
            "Epoch 13/150 - 0.46s - loss: 1.0787 - acc: 0.4197 - val_loss: 1.0852 - val_acc: 0.3725\n",
            "Epoch 14/150 - 0.45s - loss: 1.0774 - acc: 0.4285 - val_loss: 1.0839 - val_acc: 0.3927\n",
            "Epoch 15/150 - 0.44s - loss: 1.0761 - acc: 0.4341 - val_loss: 1.0828 - val_acc: 0.4049\n",
            "Epoch 16/150 - 0.43s - loss: 1.0748 - acc: 0.4332 - val_loss: 1.0820 - val_acc: 0.3947\n",
            "Epoch 17/150 - 0.43s - loss: 1.0735 - acc: 0.4408 - val_loss: 1.0807 - val_acc: 0.4130\n",
            "Epoch 18/150 - 0.46s - loss: 1.0723 - acc: 0.4372 - val_loss: 1.0800 - val_acc: 0.4049\n",
            "Epoch 19/150 - 0.43s - loss: 1.0711 - acc: 0.4386 - val_loss: 1.0791 - val_acc: 0.4049\n",
            "Epoch 20/150 - 0.44s - loss: 1.0700 - acc: 0.4404 - val_loss: 1.0785 - val_acc: 0.3947\n",
            "Epoch 21/150 - 0.44s - loss: 1.0689 - acc: 0.4438 - val_loss: 1.0773 - val_acc: 0.4150\n",
            "Epoch 22/150 - 0.42s - loss: 1.0678 - acc: 0.4507 - val_loss: 1.0763 - val_acc: 0.4251\n",
            "Epoch 23/150 - 0.43s - loss: 1.0667 - acc: 0.4516 - val_loss: 1.0755 - val_acc: 0.4271\n",
            "Epoch 24/150 - 0.42s - loss: 1.0657 - acc: 0.4516 - val_loss: 1.0749 - val_acc: 0.4312\n",
            "Epoch 25/150 - 0.45s - loss: 1.0647 - acc: 0.4541 - val_loss: 1.0741 - val_acc: 0.4211\n",
            "Epoch 26/150 - 0.44s - loss: 1.0637 - acc: 0.4566 - val_loss: 1.0732 - val_acc: 0.4352\n",
            "Epoch 27/150 - 0.44s - loss: 1.0627 - acc: 0.4582 - val_loss: 1.0724 - val_acc: 0.4372\n",
            "Epoch 28/150 - 0.43s - loss: 1.0618 - acc: 0.4595 - val_loss: 1.0717 - val_acc: 0.4433\n",
            "Epoch 29/150 - 0.43s - loss: 1.0609 - acc: 0.4597 - val_loss: 1.0712 - val_acc: 0.4433\n",
            "Epoch 30/150 - 0.43s - loss: 1.0599 - acc: 0.4642 - val_loss: 1.0703 - val_acc: 0.4494\n",
            "Epoch 31/150 - 0.44s - loss: 1.0591 - acc: 0.4622 - val_loss: 1.0694 - val_acc: 0.4393\n",
            "Epoch 32/150 - 0.43s - loss: 1.0582 - acc: 0.4647 - val_loss: 1.0687 - val_acc: 0.4393\n",
            "Epoch 33/150 - 0.44s - loss: 1.0574 - acc: 0.4674 - val_loss: 1.0680 - val_acc: 0.4413\n",
            "Epoch 34/150 - 0.44s - loss: 1.0565 - acc: 0.4685 - val_loss: 1.0677 - val_acc: 0.4514\n",
            "Epoch 35/150 - 0.44s - loss: 1.0556 - acc: 0.4685 - val_loss: 1.0670 - val_acc: 0.4474\n",
            "Epoch 36/150 - 0.43s - loss: 1.0548 - acc: 0.4683 - val_loss: 1.0663 - val_acc: 0.4494\n",
            "Epoch 37/150 - 0.45s - loss: 1.0540 - acc: 0.4705 - val_loss: 1.0658 - val_acc: 0.4494\n",
            "Epoch 38/150 - 0.44s - loss: 1.0532 - acc: 0.4714 - val_loss: 1.0650 - val_acc: 0.4534\n",
            "Epoch 39/150 - 0.43s - loss: 1.0524 - acc: 0.4717 - val_loss: 1.0645 - val_acc: 0.4534\n",
            "Epoch 40/150 - 0.44s - loss: 1.0516 - acc: 0.4723 - val_loss: 1.0638 - val_acc: 0.4575\n",
            "Epoch 41/150 - 0.45s - loss: 1.0508 - acc: 0.4759 - val_loss: 1.0634 - val_acc: 0.4575\n",
            "Epoch 42/150 - 0.45s - loss: 1.0501 - acc: 0.4750 - val_loss: 1.0630 - val_acc: 0.4595\n",
            "Epoch 43/150 - 0.47s - loss: 1.0494 - acc: 0.4741 - val_loss: 1.0623 - val_acc: 0.4555\n",
            "Epoch 44/150 - 0.42s - loss: 1.0486 - acc: 0.4753 - val_loss: 1.0620 - val_acc: 0.4636\n",
            "Epoch 45/150 - 0.44s - loss: 1.0479 - acc: 0.4764 - val_loss: 1.0611 - val_acc: 0.4696\n",
            "Epoch 46/150 - 0.44s - loss: 1.0471 - acc: 0.4775 - val_loss: 1.0608 - val_acc: 0.4656\n",
            "Epoch 47/150 - 0.43s - loss: 1.0464 - acc: 0.4777 - val_loss: 1.0604 - val_acc: 0.4656\n",
            "Epoch 48/150 - 0.43s - loss: 1.0457 - acc: 0.4775 - val_loss: 1.0598 - val_acc: 0.4676\n",
            "Epoch 49/150 - 0.46s - loss: 1.0450 - acc: 0.4798 - val_loss: 1.0590 - val_acc: 0.4696\n",
            "Epoch 50/150 - 0.44s - loss: 1.0443 - acc: 0.4802 - val_loss: 1.0586 - val_acc: 0.4717\n",
            "Epoch 51/150 - 0.44s - loss: 1.0437 - acc: 0.4804 - val_loss: 1.0584 - val_acc: 0.4737\n",
            "Epoch 52/150 - 0.44s - loss: 1.0429 - acc: 0.4820 - val_loss: 1.0575 - val_acc: 0.4717\n",
            "Epoch 53/150 - 0.44s - loss: 1.0423 - acc: 0.4813 - val_loss: 1.0573 - val_acc: 0.4798\n",
            "Epoch 54/150 - 0.44s - loss: 1.0416 - acc: 0.4813 - val_loss: 1.0569 - val_acc: 0.4798\n",
            "Epoch 55/150 - 0.45s - loss: 1.0410 - acc: 0.4829 - val_loss: 1.0567 - val_acc: 0.4818\n",
            "Epoch 56/150 - 0.42s - loss: 1.0403 - acc: 0.4829 - val_loss: 1.0559 - val_acc: 0.4798\n",
            "Epoch 57/150 - 0.44s - loss: 1.0396 - acc: 0.4849 - val_loss: 1.0555 - val_acc: 0.4777\n",
            "Epoch 58/150 - 0.44s - loss: 1.0390 - acc: 0.4845 - val_loss: 1.0550 - val_acc: 0.4818\n",
            "Epoch 59/150 - 0.43s - loss: 1.0383 - acc: 0.4856 - val_loss: 1.0544 - val_acc: 0.4818\n",
            "Epoch 60/150 - 0.43s - loss: 1.0377 - acc: 0.4847 - val_loss: 1.0537 - val_acc: 0.4798\n",
            "Epoch 61/150 - 0.43s - loss: 1.0370 - acc: 0.4881 - val_loss: 1.0535 - val_acc: 0.4879\n",
            "Epoch 62/150 - 0.43s - loss: 1.0364 - acc: 0.4872 - val_loss: 1.0530 - val_acc: 0.4858\n",
            "Epoch 63/150 - 0.45s - loss: 1.0358 - acc: 0.4874 - val_loss: 1.0525 - val_acc: 0.4818\n",
            "Epoch 64/150 - 0.42s - loss: 1.0352 - acc: 0.4890 - val_loss: 1.0521 - val_acc: 0.4858\n",
            "Epoch 65/150 - 0.43s - loss: 1.0346 - acc: 0.4890 - val_loss: 1.0517 - val_acc: 0.4879\n",
            "Epoch 66/150 - 0.43s - loss: 1.0340 - acc: 0.4863 - val_loss: 1.0511 - val_acc: 0.4858\n",
            "Epoch 67/150 - 0.46s - loss: 1.0333 - acc: 0.4883 - val_loss: 1.0508 - val_acc: 0.4858\n",
            "Epoch 68/150 - 0.42s - loss: 1.0327 - acc: 0.4892 - val_loss: 1.0505 - val_acc: 0.4899\n",
            "Epoch 69/150 - 0.43s - loss: 1.0321 - acc: 0.4883 - val_loss: 1.0499 - val_acc: 0.4818\n",
            "Epoch 70/150 - 0.43s - loss: 1.0315 - acc: 0.4901 - val_loss: 1.0495 - val_acc: 0.4858\n",
            "Epoch 71/150 - 0.43s - loss: 1.0310 - acc: 0.4897 - val_loss: 1.0490 - val_acc: 0.4858\n",
            "Epoch 72/150 - 0.44s - loss: 1.0304 - acc: 0.4897 - val_loss: 1.0486 - val_acc: 0.4838\n",
            "Epoch 73/150 - 0.43s - loss: 1.0298 - acc: 0.4921 - val_loss: 1.0482 - val_acc: 0.4838\n",
            "Epoch 74/150 - 0.46s - loss: 1.0292 - acc: 0.4908 - val_loss: 1.0478 - val_acc: 0.4818\n",
            "Epoch 75/150 - 0.42s - loss: 1.0286 - acc: 0.4921 - val_loss: 1.0475 - val_acc: 0.4879\n",
            "Epoch 76/150 - 0.43s - loss: 1.0280 - acc: 0.4919 - val_loss: 1.0469 - val_acc: 0.4838\n",
            "Epoch 77/150 - 0.44s - loss: 1.0274 - acc: 0.4935 - val_loss: 1.0466 - val_acc: 0.4858\n",
            "Epoch 78/150 - 0.43s - loss: 1.0269 - acc: 0.4962 - val_loss: 1.0463 - val_acc: 0.4858\n",
            "Epoch 79/150 - 0.45s - loss: 1.0263 - acc: 0.4951 - val_loss: 1.0460 - val_acc: 0.4879\n",
            "Epoch 80/150 - 0.43s - loss: 1.0257 - acc: 0.4951 - val_loss: 1.0456 - val_acc: 0.4879\n",
            "Epoch 81/150 - 0.44s - loss: 1.0252 - acc: 0.4928 - val_loss: 1.0451 - val_acc: 0.4858\n",
            "Epoch 82/150 - 0.44s - loss: 1.0246 - acc: 0.4937 - val_loss: 1.0445 - val_acc: 0.4858\n",
            "Epoch 83/150 - 0.43s - loss: 1.0241 - acc: 0.4973 - val_loss: 1.0440 - val_acc: 0.4818\n",
            "Epoch 84/150 - 0.44s - loss: 1.0235 - acc: 0.4971 - val_loss: 1.0438 - val_acc: 0.4818\n",
            "Epoch 85/150 - 0.44s - loss: 1.0229 - acc: 0.4991 - val_loss: 1.0435 - val_acc: 0.4858\n",
            "Epoch 86/150 - 0.42s - loss: 1.0224 - acc: 0.4975 - val_loss: 1.0433 - val_acc: 0.4960\n",
            "Epoch 87/150 - 0.43s - loss: 1.0218 - acc: 0.4993 - val_loss: 1.0425 - val_acc: 0.4858\n",
            "Epoch 88/150 - 0.43s - loss: 1.0214 - acc: 0.4982 - val_loss: 1.0427 - val_acc: 0.4960\n",
            "Epoch 89/150 - 0.43s - loss: 1.0207 - acc: 0.4984 - val_loss: 1.0416 - val_acc: 0.4858\n",
            "Epoch 90/150 - 0.45s - loss: 1.0201 - acc: 0.5016 - val_loss: 1.0414 - val_acc: 0.4980\n",
            "Epoch 91/150 - 0.44s - loss: 1.0196 - acc: 0.5004 - val_loss: 1.0408 - val_acc: 0.4879\n",
            "Epoch 92/150 - 0.43s - loss: 1.0190 - acc: 0.5029 - val_loss: 1.0406 - val_acc: 0.4939\n",
            "Epoch 93/150 - 0.43s - loss: 1.0185 - acc: 0.5027 - val_loss: 1.0400 - val_acc: 0.4899\n",
            "Epoch 94/150 - 0.43s - loss: 1.0180 - acc: 0.5040 - val_loss: 1.0400 - val_acc: 0.5020\n",
            "Epoch 95/150 - 0.43s - loss: 1.0174 - acc: 0.5009 - val_loss: 1.0395 - val_acc: 0.4899\n",
            "Epoch 96/150 - 0.44s - loss: 1.0169 - acc: 0.5034 - val_loss: 1.0391 - val_acc: 0.4980\n",
            "Epoch 97/150 - 0.47s - loss: 1.0163 - acc: 0.5025 - val_loss: 1.0386 - val_acc: 0.4919\n",
            "Epoch 98/150 - 0.43s - loss: 1.0158 - acc: 0.5056 - val_loss: 1.0383 - val_acc: 0.5040\n",
            "Epoch 99/150 - 0.44s - loss: 1.0152 - acc: 0.5049 - val_loss: 1.0377 - val_acc: 0.5081\n",
            "Epoch 100/150 - 0.42s - loss: 1.0147 - acc: 0.5063 - val_loss: 1.0375 - val_acc: 0.5061\n",
            "Epoch 101/150 - 0.44s - loss: 1.0142 - acc: 0.5047 - val_loss: 1.0370 - val_acc: 0.5101\n",
            "Epoch 102/150 - 0.44s - loss: 1.0136 - acc: 0.5072 - val_loss: 1.0366 - val_acc: 0.4980\n",
            "Epoch 103/150 - 0.44s - loss: 1.0131 - acc: 0.5076 - val_loss: 1.0362 - val_acc: 0.5061\n",
            "Epoch 104/150 - 0.42s - loss: 1.0125 - acc: 0.5065 - val_loss: 1.0358 - val_acc: 0.5101\n",
            "Epoch 105/150 - 0.44s - loss: 1.0120 - acc: 0.5058 - val_loss: 1.0352 - val_acc: 0.5061\n",
            "Epoch 106/150 - 0.45s - loss: 1.0115 - acc: 0.5085 - val_loss: 1.0352 - val_acc: 0.5121\n",
            "Epoch 107/150 - 0.44s - loss: 1.0109 - acc: 0.5099 - val_loss: 1.0346 - val_acc: 0.5101\n",
            "Epoch 108/150 - 0.42s - loss: 1.0105 - acc: 0.5117 - val_loss: 1.0342 - val_acc: 0.5000\n",
            "Epoch 109/150 - 0.45s - loss: 1.0099 - acc: 0.5088 - val_loss: 1.0336 - val_acc: 0.5040\n",
            "Epoch 110/150 - 0.43s - loss: 1.0093 - acc: 0.5103 - val_loss: 1.0334 - val_acc: 0.5142\n",
            "Epoch 111/150 - 0.43s - loss: 1.0088 - acc: 0.5121 - val_loss: 1.0329 - val_acc: 0.5081\n",
            "Epoch 112/150 - 0.43s - loss: 1.0083 - acc: 0.5126 - val_loss: 1.0327 - val_acc: 0.5162\n",
            "Epoch 113/150 - 0.45s - loss: 1.0078 - acc: 0.5124 - val_loss: 1.0322 - val_acc: 0.5162\n",
            "Epoch 114/150 - 0.45s - loss: 1.0072 - acc: 0.5124 - val_loss: 1.0317 - val_acc: 0.5142\n",
            "Epoch 115/150 - 0.46s - loss: 1.0067 - acc: 0.5144 - val_loss: 1.0314 - val_acc: 0.5162\n",
            "Epoch 116/150 - 0.43s - loss: 1.0062 - acc: 0.5135 - val_loss: 1.0309 - val_acc: 0.5162\n",
            "Epoch 117/150 - 0.43s - loss: 1.0056 - acc: 0.5117 - val_loss: 1.0303 - val_acc: 0.5121\n",
            "Epoch 118/150 - 0.43s - loss: 1.0052 - acc: 0.5144 - val_loss: 1.0305 - val_acc: 0.5263\n",
            "Epoch 119/150 - 0.43s - loss: 1.0046 - acc: 0.5137 - val_loss: 1.0295 - val_acc: 0.5101\n",
            "Epoch 120/150 - 0.43s - loss: 1.0041 - acc: 0.5151 - val_loss: 1.0292 - val_acc: 0.5142\n",
            "Epoch 121/150 - 0.48s - loss: 1.0035 - acc: 0.5157 - val_loss: 1.0288 - val_acc: 0.5121\n",
            "Epoch 122/150 - 0.43s - loss: 1.0030 - acc: 0.5157 - val_loss: 1.0285 - val_acc: 0.5121\n",
            "Epoch 123/150 - 0.44s - loss: 1.0025 - acc: 0.5164 - val_loss: 1.0281 - val_acc: 0.5142\n",
            "Epoch 124/150 - 0.44s - loss: 1.0021 - acc: 0.5171 - val_loss: 1.0279 - val_acc: 0.5223\n",
            "Epoch 125/150 - 0.43s - loss: 1.0015 - acc: 0.5173 - val_loss: 1.0270 - val_acc: 0.5121\n",
            "Epoch 126/150 - 0.44s - loss: 1.0010 - acc: 0.5189 - val_loss: 1.0268 - val_acc: 0.5121\n",
            "Epoch 127/150 - 0.44s - loss: 1.0004 - acc: 0.5175 - val_loss: 1.0261 - val_acc: 0.5121\n",
            "Epoch 128/150 - 0.44s - loss: 0.9999 - acc: 0.5184 - val_loss: 1.0260 - val_acc: 0.5202\n",
            "Epoch 129/150 - 0.43s - loss: 0.9996 - acc: 0.5189 - val_loss: 1.0262 - val_acc: 0.5223\n",
            "Epoch 130/150 - 0.44s - loss: 0.9989 - acc: 0.5191 - val_loss: 1.0252 - val_acc: 0.5162\n",
            "Epoch 131/150 - 0.44s - loss: 0.9984 - acc: 0.5187 - val_loss: 1.0245 - val_acc: 0.5101\n",
            "Epoch 132/150 - 0.43s - loss: 0.9979 - acc: 0.5187 - val_loss: 1.0242 - val_acc: 0.5223\n",
            "Epoch 133/150 - 0.46s - loss: 0.9973 - acc: 0.5196 - val_loss: 1.0236 - val_acc: 0.5142\n",
            "Epoch 134/150 - 0.43s - loss: 0.9968 - acc: 0.5196 - val_loss: 1.0234 - val_acc: 0.5182\n",
            "Epoch 135/150 - 0.44s - loss: 0.9963 - acc: 0.5209 - val_loss: 1.0228 - val_acc: 0.5101\n",
            "Epoch 136/150 - 0.44s - loss: 0.9958 - acc: 0.5198 - val_loss: 1.0223 - val_acc: 0.5162\n",
            "Epoch 137/150 - 0.44s - loss: 0.9953 - acc: 0.5227 - val_loss: 1.0219 - val_acc: 0.5182\n",
            "Epoch 138/150 - 0.45s - loss: 0.9948 - acc: 0.5209 - val_loss: 1.0215 - val_acc: 0.5182\n",
            "Epoch 139/150 - 0.47s - loss: 0.9942 - acc: 0.5209 - val_loss: 1.0211 - val_acc: 0.5182\n",
            "Epoch 140/150 - 0.43s - loss: 0.9937 - acc: 0.5209 - val_loss: 1.0207 - val_acc: 0.5182\n",
            "Epoch 141/150 - 0.43s - loss: 0.9933 - acc: 0.5241 - val_loss: 1.0206 - val_acc: 0.5263\n",
            "Epoch 142/150 - 0.43s - loss: 0.9927 - acc: 0.5247 - val_loss: 1.0199 - val_acc: 0.5162\n",
            "Epoch 143/150 - 0.43s - loss: 0.9922 - acc: 0.5250 - val_loss: 1.0195 - val_acc: 0.5223\n",
            "Epoch 144/150 - 0.43s - loss: 0.9919 - acc: 0.5229 - val_loss: 1.0189 - val_acc: 0.5121\n",
            "Epoch 145/150 - 0.47s - loss: 0.9914 - acc: 0.5234 - val_loss: 1.0185 - val_acc: 0.5182\n",
            "Epoch 146/150 - 0.45s - loss: 0.9907 - acc: 0.5261 - val_loss: 1.0183 - val_acc: 0.5263\n",
            "Epoch 147/150 - 0.42s - loss: 0.9902 - acc: 0.5265 - val_loss: 1.0179 - val_acc: 0.5263\n",
            "Epoch 148/150 - 0.43s - loss: 0.9897 - acc: 0.5265 - val_loss: 1.0175 - val_acc: 0.5304\n",
            "Epoch 149/150 - 0.43s - loss: 0.9892 - acc: 0.5268 - val_loss: 1.0171 - val_acc: 0.5324\n",
            "Epoch 150/150 - 0.43s - loss: 0.9887 - acc: 0.5263 - val_loss: 1.0164 - val_acc: 0.5243\n",
            "\n",
            "Combination 247/252:\n",
            "Hidden Layers: [512, 256, 128], Activation: tanh, Learning Rate: 0.0001, Batch Size: 32, Epochs: 50\n",
            "Epoch 1/50 - 0.67s - loss: 1.1128 - acc: 0.3282 - val_loss: 1.1136 - val_acc: 0.3259\n",
            "Epoch 2/50 - 0.60s - loss: 1.1094 - acc: 0.3255 - val_loss: 1.1108 - val_acc: 0.3239\n",
            "Epoch 3/50 - 0.61s - loss: 1.1071 - acc: 0.3237 - val_loss: 1.1090 - val_acc: 0.3138\n",
            "Epoch 4/50 - 0.62s - loss: 1.1054 - acc: 0.3207 - val_loss: 1.1077 - val_acc: 0.3016\n",
            "Epoch 5/50 - 0.60s - loss: 1.1041 - acc: 0.3214 - val_loss: 1.1067 - val_acc: 0.3138\n",
            "Epoch 6/50 - 0.65s - loss: 1.1030 - acc: 0.3228 - val_loss: 1.1060 - val_acc: 0.3198\n",
            "Epoch 7/50 - 0.66s - loss: 1.1022 - acc: 0.3250 - val_loss: 1.1054 - val_acc: 0.3300\n",
            "Epoch 8/50 - 0.60s - loss: 1.1015 - acc: 0.3232 - val_loss: 1.1049 - val_acc: 0.3401\n",
            "Epoch 9/50 - 0.60s - loss: 1.1008 - acc: 0.3264 - val_loss: 1.1044 - val_acc: 0.3259\n",
            "Epoch 10/50 - 0.59s - loss: 1.1002 - acc: 0.3318 - val_loss: 1.1040 - val_acc: 0.3259\n",
            "Epoch 11/50 - 0.61s - loss: 1.0996 - acc: 0.3311 - val_loss: 1.1035 - val_acc: 0.3198\n",
            "Epoch 12/50 - 0.61s - loss: 1.0990 - acc: 0.3340 - val_loss: 1.1031 - val_acc: 0.3239\n",
            "Epoch 13/50 - 0.63s - loss: 1.0985 - acc: 0.3336 - val_loss: 1.1027 - val_acc: 0.3279\n",
            "Epoch 14/50 - 0.61s - loss: 1.0980 - acc: 0.3349 - val_loss: 1.1023 - val_acc: 0.3381\n",
            "Epoch 15/50 - 0.60s - loss: 1.0975 - acc: 0.3363 - val_loss: 1.1019 - val_acc: 0.3360\n",
            "Epoch 16/50 - 0.60s - loss: 1.0970 - acc: 0.3392 - val_loss: 1.1015 - val_acc: 0.3340\n",
            "Epoch 17/50 - 0.61s - loss: 1.0965 - acc: 0.3401 - val_loss: 1.1011 - val_acc: 0.3320\n",
            "Epoch 18/50 - 0.59s - loss: 1.0960 - acc: 0.3430 - val_loss: 1.1008 - val_acc: 0.3360\n",
            "Epoch 19/50 - 0.64s - loss: 1.0955 - acc: 0.3457 - val_loss: 1.1004 - val_acc: 0.3320\n",
            "Epoch 20/50 - 0.61s - loss: 1.0951 - acc: 0.3475 - val_loss: 1.1000 - val_acc: 0.3320\n",
            "Epoch 21/50 - 0.61s - loss: 1.0946 - acc: 0.3507 - val_loss: 1.0996 - val_acc: 0.3300\n",
            "Epoch 22/50 - 0.60s - loss: 1.0941 - acc: 0.3534 - val_loss: 1.0992 - val_acc: 0.3300\n",
            "Epoch 23/50 - 0.60s - loss: 1.0937 - acc: 0.3558 - val_loss: 1.0988 - val_acc: 0.3340\n",
            "Epoch 24/50 - 0.60s - loss: 1.0932 - acc: 0.3581 - val_loss: 1.0985 - val_acc: 0.3340\n",
            "Epoch 25/50 - 0.64s - loss: 1.0928 - acc: 0.3608 - val_loss: 1.0981 - val_acc: 0.3381\n",
            "Epoch 26/50 - 0.60s - loss: 1.0924 - acc: 0.3623 - val_loss: 1.0977 - val_acc: 0.3421\n",
            "Epoch 27/50 - 0.61s - loss: 1.0919 - acc: 0.3639 - val_loss: 1.0974 - val_acc: 0.3421\n",
            "Epoch 28/50 - 0.61s - loss: 1.0915 - acc: 0.3653 - val_loss: 1.0970 - val_acc: 0.3421\n",
            "Epoch 29/50 - 0.60s - loss: 1.0911 - acc: 0.3671 - val_loss: 1.0966 - val_acc: 0.3502\n",
            "Epoch 30/50 - 0.60s - loss: 1.0906 - acc: 0.3691 - val_loss: 1.0963 - val_acc: 0.3502\n",
            "Epoch 31/50 - 0.63s - loss: 1.0902 - acc: 0.3711 - val_loss: 1.0959 - val_acc: 0.3522\n",
            "Epoch 32/50 - 0.60s - loss: 1.0898 - acc: 0.3722 - val_loss: 1.0956 - val_acc: 0.3522\n",
            "Epoch 33/50 - 0.61s - loss: 1.0894 - acc: 0.3736 - val_loss: 1.0953 - val_acc: 0.3543\n",
            "Epoch 34/50 - 0.60s - loss: 1.0890 - acc: 0.3754 - val_loss: 1.0949 - val_acc: 0.3563\n",
            "Epoch 35/50 - 0.60s - loss: 1.0886 - acc: 0.3767 - val_loss: 1.0946 - val_acc: 0.3603\n",
            "Epoch 36/50 - 0.61s - loss: 1.0882 - acc: 0.3783 - val_loss: 1.0942 - val_acc: 0.3583\n",
            "Epoch 37/50 - 0.63s - loss: 1.0878 - acc: 0.3774 - val_loss: 1.0939 - val_acc: 0.3583\n",
            "Epoch 38/50 - 0.59s - loss: 1.0874 - acc: 0.3790 - val_loss: 1.0936 - val_acc: 0.3583\n",
            "Epoch 39/50 - 0.60s - loss: 1.0870 - acc: 0.3790 - val_loss: 1.0933 - val_acc: 0.3644\n",
            "Epoch 40/50 - 0.60s - loss: 1.0866 - acc: 0.3819 - val_loss: 1.0930 - val_acc: 0.3704\n",
            "Epoch 41/50 - 0.60s - loss: 1.0863 - acc: 0.3815 - val_loss: 1.0926 - val_acc: 0.3704\n",
            "Epoch 42/50 - 0.60s - loss: 1.0859 - acc: 0.3828 - val_loss: 1.0923 - val_acc: 0.3704\n",
            "Epoch 43/50 - 0.63s - loss: 1.0855 - acc: 0.3817 - val_loss: 1.0920 - val_acc: 0.3684\n",
            "Epoch 44/50 - 0.66s - loss: 1.0852 - acc: 0.3830 - val_loss: 1.0917 - val_acc: 0.3684\n",
            "Epoch 45/50 - 0.67s - loss: 1.0848 - acc: 0.3848 - val_loss: 1.0914 - val_acc: 0.3704\n",
            "Epoch 46/50 - 0.65s - loss: 1.0844 - acc: 0.3875 - val_loss: 1.0911 - val_acc: 0.3684\n",
            "Epoch 47/50 - 0.63s - loss: 1.0841 - acc: 0.3884 - val_loss: 1.0908 - val_acc: 0.3684\n",
            "Epoch 48/50 - 0.65s - loss: 1.0837 - acc: 0.3911 - val_loss: 1.0905 - val_acc: 0.3684\n",
            "Epoch 49/50 - 0.63s - loss: 1.0834 - acc: 0.3911 - val_loss: 1.0902 - val_acc: 0.3684\n",
            "Epoch 50/50 - 0.64s - loss: 1.0830 - acc: 0.3927 - val_loss: 1.0899 - val_acc: 0.3704\n",
            "\n",
            "Combination 248/252:\n",
            "Hidden Layers: [512, 256, 128], Activation: tanh, Learning Rate: 0.0001, Batch Size: 32, Epochs: 100\n",
            "Epoch 1/100 - 0.69s - loss: 1.1204 - acc: 0.3495 - val_loss: 1.1169 - val_acc: 0.3502\n",
            "Epoch 2/100 - 0.66s - loss: 1.1104 - acc: 0.3498 - val_loss: 1.1075 - val_acc: 0.3502\n",
            "Epoch 3/100 - 0.63s - loss: 1.1035 - acc: 0.3531 - val_loss: 1.1011 - val_acc: 0.3482\n",
            "Epoch 4/100 - 0.63s - loss: 1.0988 - acc: 0.3538 - val_loss: 1.0968 - val_acc: 0.3502\n",
            "Epoch 5/100 - 0.62s - loss: 1.0954 - acc: 0.3603 - val_loss: 1.0938 - val_acc: 0.3543\n",
            "Epoch 6/100 - 0.64s - loss: 1.0929 - acc: 0.3635 - val_loss: 1.0917 - val_acc: 0.3623\n",
            "Epoch 7/100 - 0.66s - loss: 1.0911 - acc: 0.3704 - val_loss: 1.0902 - val_acc: 0.3765\n",
            "Epoch 8/100 - 0.66s - loss: 1.0898 - acc: 0.3806 - val_loss: 1.0892 - val_acc: 0.3927\n",
            "Epoch 9/100 - 0.64s - loss: 1.0888 - acc: 0.3848 - val_loss: 1.0883 - val_acc: 0.3988\n",
            "Epoch 10/100 - 0.63s - loss: 1.0880 - acc: 0.3884 - val_loss: 1.0877 - val_acc: 0.4008\n",
            "Epoch 11/100 - 0.62s - loss: 1.0873 - acc: 0.3914 - val_loss: 1.0873 - val_acc: 0.4008\n",
            "Epoch 12/100 - 0.61s - loss: 1.0867 - acc: 0.3972 - val_loss: 1.0868 - val_acc: 0.3947\n",
            "Epoch 13/100 - 0.64s - loss: 1.0862 - acc: 0.4006 - val_loss: 1.0865 - val_acc: 0.3866\n",
            "Epoch 14/100 - 0.61s - loss: 1.0858 - acc: 0.4010 - val_loss: 1.0862 - val_acc: 0.3927\n",
            "Epoch 15/100 - 0.62s - loss: 1.0853 - acc: 0.4033 - val_loss: 1.0859 - val_acc: 0.3988\n",
            "Epoch 16/100 - 0.61s - loss: 1.0849 - acc: 0.4085 - val_loss: 1.0856 - val_acc: 0.3968\n",
            "Epoch 17/100 - 0.63s - loss: 1.0846 - acc: 0.4112 - val_loss: 1.0853 - val_acc: 0.3947\n",
            "Epoch 18/100 - 0.62s - loss: 1.0842 - acc: 0.4121 - val_loss: 1.0850 - val_acc: 0.3968\n",
            "Epoch 19/100 - 0.65s - loss: 1.0838 - acc: 0.4123 - val_loss: 1.0848 - val_acc: 0.3968\n",
            "Epoch 20/100 - 0.62s - loss: 1.0835 - acc: 0.4132 - val_loss: 1.0845 - val_acc: 0.3927\n",
            "Epoch 21/100 - 0.62s - loss: 1.0831 - acc: 0.4168 - val_loss: 1.0842 - val_acc: 0.3947\n",
            "Epoch 22/100 - 0.61s - loss: 1.0828 - acc: 0.4197 - val_loss: 1.0840 - val_acc: 0.3927\n",
            "Epoch 23/100 - 0.62s - loss: 1.0824 - acc: 0.4206 - val_loss: 1.0837 - val_acc: 0.3907\n",
            "Epoch 24/100 - 0.61s - loss: 1.0821 - acc: 0.4204 - val_loss: 1.0834 - val_acc: 0.3927\n",
            "Epoch 25/100 - 0.65s - loss: 1.0818 - acc: 0.4233 - val_loss: 1.0832 - val_acc: 0.3947\n",
            "Epoch 26/100 - 0.63s - loss: 1.0814 - acc: 0.4249 - val_loss: 1.0829 - val_acc: 0.3927\n",
            "Epoch 27/100 - 0.62s - loss: 1.0811 - acc: 0.4251 - val_loss: 1.0827 - val_acc: 0.3968\n",
            "Epoch 28/100 - 0.61s - loss: 1.0808 - acc: 0.4249 - val_loss: 1.0824 - val_acc: 0.3968\n",
            "Epoch 29/100 - 0.61s - loss: 1.0805 - acc: 0.4253 - val_loss: 1.0822 - val_acc: 0.3988\n",
            "Epoch 30/100 - 0.61s - loss: 1.0802 - acc: 0.4267 - val_loss: 1.0819 - val_acc: 0.4008\n",
            "Epoch 31/100 - 0.65s - loss: 1.0799 - acc: 0.4271 - val_loss: 1.0817 - val_acc: 0.3988\n",
            "Epoch 32/100 - 0.61s - loss: 1.0796 - acc: 0.4274 - val_loss: 1.0814 - val_acc: 0.4008\n",
            "Epoch 33/100 - 0.62s - loss: 1.0792 - acc: 0.4276 - val_loss: 1.0812 - val_acc: 0.4008\n",
            "Epoch 34/100 - 0.62s - loss: 1.0789 - acc: 0.4287 - val_loss: 1.0810 - val_acc: 0.4028\n",
            "Epoch 35/100 - 0.62s - loss: 1.0786 - acc: 0.4296 - val_loss: 1.0807 - val_acc: 0.4028\n",
            "Epoch 36/100 - 0.61s - loss: 1.0784 - acc: 0.4305 - val_loss: 1.0805 - val_acc: 0.4069\n",
            "Epoch 37/100 - 0.64s - loss: 1.0781 - acc: 0.4309 - val_loss: 1.0803 - val_acc: 0.4028\n",
            "Epoch 38/100 - 0.61s - loss: 1.0778 - acc: 0.4323 - val_loss: 1.0800 - val_acc: 0.4049\n",
            "Epoch 39/100 - 0.63s - loss: 1.0775 - acc: 0.4334 - val_loss: 1.0798 - val_acc: 0.4069\n",
            "Epoch 40/100 - 0.61s - loss: 1.0772 - acc: 0.4327 - val_loss: 1.0796 - val_acc: 0.4069\n",
            "Epoch 41/100 - 0.63s - loss: 1.0769 - acc: 0.4339 - val_loss: 1.0794 - val_acc: 0.4049\n",
            "Epoch 42/100 - 0.62s - loss: 1.0766 - acc: 0.4345 - val_loss: 1.0792 - val_acc: 0.4008\n",
            "Epoch 43/100 - 0.65s - loss: 1.0763 - acc: 0.4350 - val_loss: 1.0789 - val_acc: 0.4028\n",
            "Epoch 44/100 - 0.61s - loss: 1.0761 - acc: 0.4352 - val_loss: 1.0787 - val_acc: 0.4049\n",
            "Epoch 45/100 - 0.63s - loss: 1.0758 - acc: 0.4357 - val_loss: 1.0785 - val_acc: 0.4069\n",
            "Epoch 46/100 - 0.61s - loss: 1.0755 - acc: 0.4363 - val_loss: 1.0783 - val_acc: 0.4069\n",
            "Epoch 47/100 - 0.63s - loss: 1.0753 - acc: 0.4379 - val_loss: 1.0781 - val_acc: 0.4069\n",
            "Epoch 48/100 - 0.61s - loss: 1.0750 - acc: 0.4386 - val_loss: 1.0779 - val_acc: 0.4069\n",
            "Epoch 49/100 - 0.66s - loss: 1.0747 - acc: 0.4384 - val_loss: 1.0777 - val_acc: 0.4069\n",
            "Epoch 50/100 - 0.63s - loss: 1.0745 - acc: 0.4402 - val_loss: 1.0775 - val_acc: 0.4049\n",
            "Epoch 51/100 - 0.64s - loss: 1.0742 - acc: 0.4404 - val_loss: 1.0773 - val_acc: 0.4069\n",
            "Epoch 52/100 - 0.69s - loss: 1.0739 - acc: 0.4408 - val_loss: 1.0771 - val_acc: 0.4069\n",
            "Epoch 53/100 - 0.64s - loss: 1.0737 - acc: 0.4426 - val_loss: 1.0769 - val_acc: 0.4089\n",
            "Epoch 54/100 - 0.64s - loss: 1.0734 - acc: 0.4435 - val_loss: 1.0767 - val_acc: 0.4069\n",
            "Epoch 55/100 - 0.67s - loss: 1.0732 - acc: 0.4442 - val_loss: 1.0765 - val_acc: 0.4069\n",
            "Epoch 56/100 - 0.63s - loss: 1.0729 - acc: 0.4453 - val_loss: 1.0763 - val_acc: 0.4049\n",
            "Epoch 57/100 - 0.62s - loss: 1.0727 - acc: 0.4467 - val_loss: 1.0761 - val_acc: 0.4028\n",
            "Epoch 58/100 - 0.69s - loss: 1.0724 - acc: 0.4476 - val_loss: 1.0759 - val_acc: 0.4028\n",
            "Epoch 59/100 - 0.64s - loss: 1.0722 - acc: 0.4485 - val_loss: 1.0757 - val_acc: 0.4008\n",
            "Epoch 60/100 - 0.62s - loss: 1.0719 - acc: 0.4489 - val_loss: 1.0755 - val_acc: 0.4008\n",
            "Epoch 61/100 - 0.63s - loss: 1.0717 - acc: 0.4501 - val_loss: 1.0753 - val_acc: 0.4008\n",
            "Epoch 62/100 - 0.66s - loss: 1.0714 - acc: 0.4496 - val_loss: 1.0751 - val_acc: 0.4049\n",
            "Epoch 63/100 - 0.69s - loss: 1.0712 - acc: 0.4503 - val_loss: 1.0749 - val_acc: 0.4049\n",
            "Epoch 64/100 - 0.71s - loss: 1.0709 - acc: 0.4530 - val_loss: 1.0747 - val_acc: 0.4049\n",
            "Epoch 65/100 - 0.64s - loss: 1.0707 - acc: 0.4516 - val_loss: 1.0746 - val_acc: 0.4069\n",
            "Epoch 66/100 - 0.65s - loss: 1.0705 - acc: 0.4537 - val_loss: 1.0744 - val_acc: 0.4069\n",
            "Epoch 67/100 - 0.66s - loss: 1.0702 - acc: 0.4548 - val_loss: 1.0742 - val_acc: 0.4089\n",
            "Epoch 68/100 - 0.76s - loss: 1.0700 - acc: 0.4539 - val_loss: 1.0740 - val_acc: 0.4069\n",
            "Epoch 69/100 - 0.65s - loss: 1.0698 - acc: 0.4534 - val_loss: 1.0738 - val_acc: 0.4069\n",
            "Epoch 70/100 - 0.69s - loss: 1.0695 - acc: 0.4530 - val_loss: 1.0737 - val_acc: 0.4069\n",
            "Epoch 71/100 - 0.66s - loss: 1.0693 - acc: 0.4539 - val_loss: 1.0735 - val_acc: 0.4069\n",
            "Epoch 72/100 - 0.75s - loss: 1.0691 - acc: 0.4548 - val_loss: 1.0733 - val_acc: 0.4069\n",
            "Epoch 73/100 - 0.70s - loss: 1.0689 - acc: 0.4557 - val_loss: 1.0732 - val_acc: 0.4069\n",
            "Epoch 74/100 - 0.80s - loss: 1.0686 - acc: 0.4564 - val_loss: 1.0730 - val_acc: 0.4049\n",
            "Epoch 75/100 - 0.69s - loss: 1.0684 - acc: 0.4559 - val_loss: 1.0728 - val_acc: 0.4069\n",
            "Epoch 76/100 - 0.77s - loss: 1.0682 - acc: 0.4557 - val_loss: 1.0727 - val_acc: 0.4130\n",
            "Epoch 77/100 - 0.67s - loss: 1.0680 - acc: 0.4557 - val_loss: 1.0725 - val_acc: 0.4130\n",
            "Epoch 78/100 - 0.69s - loss: 1.0677 - acc: 0.4561 - val_loss: 1.0723 - val_acc: 0.4150\n",
            "Epoch 79/100 - 0.67s - loss: 1.0675 - acc: 0.4568 - val_loss: 1.0722 - val_acc: 0.4150\n",
            "Epoch 80/100 - 0.63s - loss: 1.0673 - acc: 0.4561 - val_loss: 1.0720 - val_acc: 0.4150\n",
            "Epoch 81/100 - 0.65s - loss: 1.0671 - acc: 0.4568 - val_loss: 1.0718 - val_acc: 0.4170\n",
            "Epoch 82/100 - 0.68s - loss: 1.0669 - acc: 0.4570 - val_loss: 1.0717 - val_acc: 0.4170\n",
            "Epoch 83/100 - 0.65s - loss: 1.0666 - acc: 0.4573 - val_loss: 1.0715 - val_acc: 0.4150\n",
            "Epoch 84/100 - 0.64s - loss: 1.0664 - acc: 0.4573 - val_loss: 1.0713 - val_acc: 0.4170\n",
            "Epoch 85/100 - 0.65s - loss: 1.0662 - acc: 0.4570 - val_loss: 1.0712 - val_acc: 0.4190\n",
            "Epoch 86/100 - 0.64s - loss: 1.0660 - acc: 0.4575 - val_loss: 1.0710 - val_acc: 0.4170\n",
            "Epoch 87/100 - 0.65s - loss: 1.0658 - acc: 0.4570 - val_loss: 1.0709 - val_acc: 0.4170\n",
            "Epoch 88/100 - 0.82s - loss: 1.0656 - acc: 0.4575 - val_loss: 1.0707 - val_acc: 0.4190\n",
            "Epoch 89/100 - 0.67s - loss: 1.0654 - acc: 0.4584 - val_loss: 1.0706 - val_acc: 0.4170\n",
            "Epoch 90/100 - 0.72s - loss: 1.0652 - acc: 0.4586 - val_loss: 1.0704 - val_acc: 0.4190\n",
            "Epoch 91/100 - 0.70s - loss: 1.0650 - acc: 0.4582 - val_loss: 1.0702 - val_acc: 0.4211\n",
            "Epoch 92/100 - 0.67s - loss: 1.0648 - acc: 0.4600 - val_loss: 1.0701 - val_acc: 0.4251\n",
            "Epoch 93/100 - 0.67s - loss: 1.0646 - acc: 0.4602 - val_loss: 1.0699 - val_acc: 0.4271\n",
            "Epoch 94/100 - 0.68s - loss: 1.0644 - acc: 0.4600 - val_loss: 1.0698 - val_acc: 0.4291\n",
            "Epoch 95/100 - 0.64s - loss: 1.0641 - acc: 0.4591 - val_loss: 1.0696 - val_acc: 0.4312\n",
            "Epoch 96/100 - 0.61s - loss: 1.0639 - acc: 0.4595 - val_loss: 1.0695 - val_acc: 0.4312\n",
            "Epoch 97/100 - 0.62s - loss: 1.0637 - acc: 0.4595 - val_loss: 1.0693 - val_acc: 0.4332\n",
            "Epoch 98/100 - 0.67s - loss: 1.0635 - acc: 0.4602 - val_loss: 1.0692 - val_acc: 0.4291\n",
            "Epoch 99/100 - 0.65s - loss: 1.0633 - acc: 0.4602 - val_loss: 1.0690 - val_acc: 0.4291\n",
            "Epoch 100/100 - 0.66s - loss: 1.0631 - acc: 0.4606 - val_loss: 1.0689 - val_acc: 0.4291\n",
            "\n",
            "Combination 249/252:\n",
            "Hidden Layers: [512, 256, 128], Activation: tanh, Learning Rate: 0.0001, Batch Size: 32, Epochs: 150\n",
            "Epoch 1/150 - 0.65s - loss: 1.1138 - acc: 0.3428 - val_loss: 1.1109 - val_acc: 0.3502\n",
            "Epoch 2/150 - 0.61s - loss: 1.1105 - acc: 0.3383 - val_loss: 1.1080 - val_acc: 0.3462\n",
            "Epoch 3/150 - 0.64s - loss: 1.1081 - acc: 0.3401 - val_loss: 1.1058 - val_acc: 0.3421\n",
            "Epoch 4/150 - 0.60s - loss: 1.1063 - acc: 0.3378 - val_loss: 1.1043 - val_acc: 0.3401\n",
            "Epoch 5/150 - 0.62s - loss: 1.1049 - acc: 0.3365 - val_loss: 1.1031 - val_acc: 0.3381\n",
            "Epoch 6/150 - 0.68s - loss: 1.1038 - acc: 0.3340 - val_loss: 1.1021 - val_acc: 0.3320\n",
            "Epoch 7/150 - 0.64s - loss: 1.1029 - acc: 0.3363 - val_loss: 1.1014 - val_acc: 0.3401\n",
            "Epoch 8/150 - 0.64s - loss: 1.1021 - acc: 0.3385 - val_loss: 1.1007 - val_acc: 0.3441\n",
            "Epoch 9/150 - 0.63s - loss: 1.1014 - acc: 0.3363 - val_loss: 1.1001 - val_acc: 0.3462\n",
            "Epoch 10/150 - 0.64s - loss: 1.1008 - acc: 0.3347 - val_loss: 1.0996 - val_acc: 0.3522\n",
            "Epoch 11/150 - 0.62s - loss: 1.1002 - acc: 0.3378 - val_loss: 1.0991 - val_acc: 0.3522\n",
            "Epoch 12/150 - 0.65s - loss: 1.0996 - acc: 0.3414 - val_loss: 1.0987 - val_acc: 0.3502\n",
            "Epoch 13/150 - 0.61s - loss: 1.0991 - acc: 0.3394 - val_loss: 1.0982 - val_acc: 0.3441\n",
            "Epoch 14/150 - 0.62s - loss: 1.0986 - acc: 0.3408 - val_loss: 1.0978 - val_acc: 0.3522\n",
            "Epoch 15/150 - 0.66s - loss: 1.0981 - acc: 0.3403 - val_loss: 1.0974 - val_acc: 0.3664\n",
            "Epoch 16/150 - 0.63s - loss: 1.0977 - acc: 0.3401 - val_loss: 1.0970 - val_acc: 0.3765\n",
            "Epoch 17/150 - 0.64s - loss: 1.0972 - acc: 0.3414 - val_loss: 1.0966 - val_acc: 0.3765\n",
            "Epoch 18/150 - 0.73s - loss: 1.0968 - acc: 0.3477 - val_loss: 1.0962 - val_acc: 0.3785\n",
            "Epoch 19/150 - 0.66s - loss: 1.0963 - acc: 0.3509 - val_loss: 1.0958 - val_acc: 0.3846\n",
            "Epoch 20/150 - 0.63s - loss: 1.0959 - acc: 0.3529 - val_loss: 1.0955 - val_acc: 0.3826\n",
            "Epoch 21/150 - 0.63s - loss: 1.0954 - acc: 0.3547 - val_loss: 1.0951 - val_acc: 0.3765\n",
            "Epoch 22/150 - 0.63s - loss: 1.0950 - acc: 0.3572 - val_loss: 1.0947 - val_acc: 0.3785\n",
            "Epoch 23/150 - 0.62s - loss: 1.0946 - acc: 0.3594 - val_loss: 1.0944 - val_acc: 0.3745\n",
            "Epoch 24/150 - 0.66s - loss: 1.0942 - acc: 0.3585 - val_loss: 1.0940 - val_acc: 0.3664\n",
            "Epoch 25/150 - 0.62s - loss: 1.0938 - acc: 0.3596 - val_loss: 1.0937 - val_acc: 0.3684\n",
            "Epoch 26/150 - 0.59s - loss: 1.0934 - acc: 0.3617 - val_loss: 1.0933 - val_acc: 0.3704\n",
            "Epoch 27/150 - 0.60s - loss: 1.0930 - acc: 0.3635 - val_loss: 1.0930 - val_acc: 0.3704\n",
            "Epoch 28/150 - 0.60s - loss: 1.0926 - acc: 0.3644 - val_loss: 1.0926 - val_acc: 0.3725\n",
            "Epoch 29/150 - 0.63s - loss: 1.0922 - acc: 0.3673 - val_loss: 1.0923 - val_acc: 0.3785\n",
            "Epoch 30/150 - 0.65s - loss: 1.0918 - acc: 0.3711 - val_loss: 1.0919 - val_acc: 0.3806\n",
            "Epoch 31/150 - 0.61s - loss: 1.0914 - acc: 0.3736 - val_loss: 1.0916 - val_acc: 0.3765\n",
            "Epoch 32/150 - 0.60s - loss: 1.0910 - acc: 0.3758 - val_loss: 1.0913 - val_acc: 0.3806\n",
            "Epoch 33/150 - 0.60s - loss: 1.0906 - acc: 0.3774 - val_loss: 1.0909 - val_acc: 0.3806\n",
            "Epoch 34/150 - 0.61s - loss: 1.0902 - acc: 0.3803 - val_loss: 1.0906 - val_acc: 0.3846\n",
            "Epoch 35/150 - 0.62s - loss: 1.0899 - acc: 0.3803 - val_loss: 1.0903 - val_acc: 0.3866\n",
            "Epoch 36/150 - 0.73s - loss: 1.0895 - acc: 0.3835 - val_loss: 1.0900 - val_acc: 0.3866\n",
            "Epoch 37/150 - 0.66s - loss: 1.0891 - acc: 0.3848 - val_loss: 1.0897 - val_acc: 0.3887\n",
            "Epoch 38/150 - 0.62s - loss: 1.0888 - acc: 0.3878 - val_loss: 1.0894 - val_acc: 0.3927\n",
            "Epoch 39/150 - 0.64s - loss: 1.0884 - acc: 0.3902 - val_loss: 1.0891 - val_acc: 0.3907\n",
            "Epoch 40/150 - 0.67s - loss: 1.0881 - acc: 0.3911 - val_loss: 1.0888 - val_acc: 0.3907\n",
            "Epoch 41/150 - 0.63s - loss: 1.0877 - acc: 0.3932 - val_loss: 1.0885 - val_acc: 0.3866\n",
            "Epoch 42/150 - 0.65s - loss: 1.0874 - acc: 0.3952 - val_loss: 1.0882 - val_acc: 0.3866\n",
            "Epoch 43/150 - 0.68s - loss: 1.0870 - acc: 0.3959 - val_loss: 1.0879 - val_acc: 0.3927\n",
            "Epoch 44/150 - 0.63s - loss: 1.0867 - acc: 0.4008 - val_loss: 1.0876 - val_acc: 0.3947\n",
            "Epoch 45/150 - 0.62s - loss: 1.0864 - acc: 0.4015 - val_loss: 1.0873 - val_acc: 0.3988\n",
            "Epoch 46/150 - 0.64s - loss: 1.0860 - acc: 0.4033 - val_loss: 1.0870 - val_acc: 0.4008\n",
            "Epoch 47/150 - 0.65s - loss: 1.0857 - acc: 0.4042 - val_loss: 1.0868 - val_acc: 0.4069\n",
            "Epoch 48/150 - 0.64s - loss: 1.0854 - acc: 0.4069 - val_loss: 1.0865 - val_acc: 0.4109\n",
            "Epoch 49/150 - 0.65s - loss: 1.0850 - acc: 0.4080 - val_loss: 1.0862 - val_acc: 0.4089\n",
            "Epoch 50/150 - 0.62s - loss: 1.0847 - acc: 0.4094 - val_loss: 1.0859 - val_acc: 0.4089\n",
            "Epoch 51/150 - 0.62s - loss: 1.0844 - acc: 0.4114 - val_loss: 1.0857 - val_acc: 0.4109\n",
            "Epoch 52/150 - 0.60s - loss: 1.0841 - acc: 0.4143 - val_loss: 1.0854 - val_acc: 0.4089\n",
            "Epoch 53/150 - 0.61s - loss: 1.0838 - acc: 0.4157 - val_loss: 1.0851 - val_acc: 0.4089\n",
            "Epoch 54/150 - 0.64s - loss: 1.0834 - acc: 0.4179 - val_loss: 1.0849 - val_acc: 0.4130\n",
            "Epoch 55/150 - 0.61s - loss: 1.0831 - acc: 0.4181 - val_loss: 1.0846 - val_acc: 0.4211\n",
            "Epoch 56/150 - 0.60s - loss: 1.0828 - acc: 0.4186 - val_loss: 1.0844 - val_acc: 0.4231\n",
            "Epoch 57/150 - 0.65s - loss: 1.0825 - acc: 0.4175 - val_loss: 1.0841 - val_acc: 0.4211\n",
            "Epoch 58/150 - 0.74s - loss: 1.0822 - acc: 0.4186 - val_loss: 1.0838 - val_acc: 0.4211\n",
            "Epoch 59/150 - 0.69s - loss: 1.0819 - acc: 0.4199 - val_loss: 1.0836 - val_acc: 0.4211\n",
            "Epoch 60/150 - 0.68s - loss: 1.0816 - acc: 0.4217 - val_loss: 1.0834 - val_acc: 0.4231\n",
            "Epoch 61/150 - 0.72s - loss: 1.0813 - acc: 0.4217 - val_loss: 1.0831 - val_acc: 0.4251\n",
            "Epoch 62/150 - 0.67s - loss: 1.0811 - acc: 0.4217 - val_loss: 1.0829 - val_acc: 0.4251\n",
            "Epoch 63/150 - 0.68s - loss: 1.0808 - acc: 0.4224 - val_loss: 1.0826 - val_acc: 0.4251\n",
            "Epoch 64/150 - 0.71s - loss: 1.0805 - acc: 0.4226 - val_loss: 1.0824 - val_acc: 0.4271\n",
            "Epoch 65/150 - 0.75s - loss: 1.0802 - acc: 0.4229 - val_loss: 1.0821 - val_acc: 0.4271\n",
            "Epoch 66/150 - 0.71s - loss: 1.0799 - acc: 0.4233 - val_loss: 1.0819 - val_acc: 0.4312\n",
            "Epoch 67/150 - 0.68s - loss: 1.0796 - acc: 0.4238 - val_loss: 1.0817 - val_acc: 0.4332\n",
            "Epoch 68/150 - 0.65s - loss: 1.0794 - acc: 0.4242 - val_loss: 1.0814 - val_acc: 0.4332\n",
            "Epoch 69/150 - 0.70s - loss: 1.0791 - acc: 0.4253 - val_loss: 1.0812 - val_acc: 0.4312\n",
            "Epoch 70/150 - 0.66s - loss: 1.0788 - acc: 0.4253 - val_loss: 1.0810 - val_acc: 0.4312\n",
            "Epoch 71/150 - 0.69s - loss: 1.0785 - acc: 0.4251 - val_loss: 1.0808 - val_acc: 0.4291\n",
            "Epoch 72/150 - 0.67s - loss: 1.0783 - acc: 0.4258 - val_loss: 1.0805 - val_acc: 0.4312\n",
            "Epoch 73/150 - 0.66s - loss: 1.0780 - acc: 0.4278 - val_loss: 1.0803 - val_acc: 0.4312\n",
            "Epoch 74/150 - 0.65s - loss: 1.0777 - acc: 0.4294 - val_loss: 1.0801 - val_acc: 0.4312\n",
            "Epoch 75/150 - 0.69s - loss: 1.0775 - acc: 0.4305 - val_loss: 1.0799 - val_acc: 0.4291\n",
            "Epoch 76/150 - 0.69s - loss: 1.0772 - acc: 0.4316 - val_loss: 1.0797 - val_acc: 0.4231\n",
            "Epoch 77/150 - 0.67s - loss: 1.0769 - acc: 0.4316 - val_loss: 1.0795 - val_acc: 0.4211\n",
            "Epoch 78/150 - 0.76s - loss: 1.0767 - acc: 0.4314 - val_loss: 1.0792 - val_acc: 0.4251\n",
            "Epoch 79/150 - 0.67s - loss: 1.0764 - acc: 0.4305 - val_loss: 1.0790 - val_acc: 0.4231\n",
            "Epoch 80/150 - 0.70s - loss: 1.0762 - acc: 0.4309 - val_loss: 1.0788 - val_acc: 0.4271\n",
            "Epoch 81/150 - 0.66s - loss: 1.0759 - acc: 0.4307 - val_loss: 1.0786 - val_acc: 0.4312\n",
            "Epoch 82/150 - 0.72s - loss: 1.0757 - acc: 0.4321 - val_loss: 1.0784 - val_acc: 0.4312\n",
            "Epoch 83/150 - 0.67s - loss: 1.0754 - acc: 0.4314 - val_loss: 1.0782 - val_acc: 0.4312\n",
            "Epoch 84/150 - 0.71s - loss: 1.0752 - acc: 0.4312 - val_loss: 1.0780 - val_acc: 0.4352\n",
            "Epoch 85/150 - 0.79s - loss: 1.0749 - acc: 0.4305 - val_loss: 1.0778 - val_acc: 0.4372\n",
            "Epoch 86/150 - 0.79s - loss: 1.0747 - acc: 0.4316 - val_loss: 1.0776 - val_acc: 0.4393\n",
            "Epoch 87/150 - 0.78s - loss: 1.0744 - acc: 0.4318 - val_loss: 1.0774 - val_acc: 0.4393\n",
            "Epoch 88/150 - 0.81s - loss: 1.0742 - acc: 0.4312 - val_loss: 1.0772 - val_acc: 0.4393\n",
            "Epoch 89/150 - 0.79s - loss: 1.0740 - acc: 0.4325 - val_loss: 1.0770 - val_acc: 0.4393\n",
            "Epoch 90/150 - 0.79s - loss: 1.0737 - acc: 0.4330 - val_loss: 1.0768 - val_acc: 0.4393\n",
            "Epoch 91/150 - 0.74s - loss: 1.0735 - acc: 0.4330 - val_loss: 1.0766 - val_acc: 0.4312\n",
            "Epoch 92/150 - 0.76s - loss: 1.0733 - acc: 0.4345 - val_loss: 1.0764 - val_acc: 0.4312\n",
            "Epoch 93/150 - 0.75s - loss: 1.0730 - acc: 0.4348 - val_loss: 1.0762 - val_acc: 0.4312\n",
            "Epoch 94/150 - 0.73s - loss: 1.0728 - acc: 0.4363 - val_loss: 1.0761 - val_acc: 0.4312\n",
            "Epoch 95/150 - 0.70s - loss: 1.0726 - acc: 0.4377 - val_loss: 1.0759 - val_acc: 0.4312\n",
            "Epoch 96/150 - 0.72s - loss: 1.0723 - acc: 0.4386 - val_loss: 1.0757 - val_acc: 0.4332\n",
            "Epoch 97/150 - 0.67s - loss: 1.0721 - acc: 0.4386 - val_loss: 1.0755 - val_acc: 0.4332\n",
            "Epoch 98/150 - 0.61s - loss: 1.0719 - acc: 0.4397 - val_loss: 1.0753 - val_acc: 0.4312\n",
            "Epoch 99/150 - 0.62s - loss: 1.0716 - acc: 0.4399 - val_loss: 1.0751 - val_acc: 0.4332\n",
            "Epoch 100/150 - 0.61s - loss: 1.0714 - acc: 0.4397 - val_loss: 1.0750 - val_acc: 0.4352\n",
            "Epoch 101/150 - 0.61s - loss: 1.0712 - acc: 0.4402 - val_loss: 1.0748 - val_acc: 0.4372\n",
            "Epoch 102/150 - 0.66s - loss: 1.0710 - acc: 0.4402 - val_loss: 1.0746 - val_acc: 0.4393\n",
            "Epoch 103/150 - 0.61s - loss: 1.0708 - acc: 0.4408 - val_loss: 1.0744 - val_acc: 0.4393\n",
            "Epoch 104/150 - 0.61s - loss: 1.0705 - acc: 0.4415 - val_loss: 1.0742 - val_acc: 0.4393\n",
            "Epoch 105/150 - 0.62s - loss: 1.0703 - acc: 0.4415 - val_loss: 1.0741 - val_acc: 0.4393\n",
            "Epoch 106/150 - 0.77s - loss: 1.0701 - acc: 0.4415 - val_loss: 1.0739 - val_acc: 0.4372\n",
            "Epoch 107/150 - 0.73s - loss: 1.0699 - acc: 0.4429 - val_loss: 1.0737 - val_acc: 0.4372\n",
            "Epoch 108/150 - 0.71s - loss: 1.0697 - acc: 0.4438 - val_loss: 1.0736 - val_acc: 0.4393\n",
            "Epoch 109/150 - 0.67s - loss: 1.0695 - acc: 0.4451 - val_loss: 1.0734 - val_acc: 0.4372\n",
            "Epoch 110/150 - 0.69s - loss: 1.0693 - acc: 0.4456 - val_loss: 1.0732 - val_acc: 0.4393\n",
            "Epoch 111/150 - 0.63s - loss: 1.0690 - acc: 0.4462 - val_loss: 1.0730 - val_acc: 0.4372\n",
            "Epoch 112/150 - 0.61s - loss: 1.0688 - acc: 0.4467 - val_loss: 1.0729 - val_acc: 0.4372\n",
            "Epoch 113/150 - 0.65s - loss: 1.0686 - acc: 0.4469 - val_loss: 1.0727 - val_acc: 0.4413\n",
            "Epoch 114/150 - 0.67s - loss: 1.0684 - acc: 0.4465 - val_loss: 1.0725 - val_acc: 0.4413\n",
            "Epoch 115/150 - 0.61s - loss: 1.0682 - acc: 0.4471 - val_loss: 1.0724 - val_acc: 0.4453\n",
            "Epoch 116/150 - 0.61s - loss: 1.0680 - acc: 0.4476 - val_loss: 1.0722 - val_acc: 0.4453\n",
            "Epoch 117/150 - 0.71s - loss: 1.0678 - acc: 0.4478 - val_loss: 1.0721 - val_acc: 0.4453\n",
            "Epoch 118/150 - 0.66s - loss: 1.0676 - acc: 0.4492 - val_loss: 1.0719 - val_acc: 0.4453\n",
            "Epoch 119/150 - 0.62s - loss: 1.0674 - acc: 0.4492 - val_loss: 1.0717 - val_acc: 0.4453\n",
            "Epoch 120/150 - 0.64s - loss: 1.0672 - acc: 0.4494 - val_loss: 1.0716 - val_acc: 0.4453\n",
            "Epoch 121/150 - 0.65s - loss: 1.0670 - acc: 0.4494 - val_loss: 1.0714 - val_acc: 0.4474\n",
            "Epoch 122/150 - 0.63s - loss: 1.0668 - acc: 0.4505 - val_loss: 1.0713 - val_acc: 0.4494\n",
            "Epoch 123/150 - 0.63s - loss: 1.0666 - acc: 0.4505 - val_loss: 1.0711 - val_acc: 0.4474\n",
            "Epoch 124/150 - 0.63s - loss: 1.0664 - acc: 0.4512 - val_loss: 1.0709 - val_acc: 0.4453\n",
            "Epoch 125/150 - 0.68s - loss: 1.0662 - acc: 0.4512 - val_loss: 1.0708 - val_acc: 0.4474\n",
            "Epoch 126/150 - 0.70s - loss: 1.0660 - acc: 0.4507 - val_loss: 1.0706 - val_acc: 0.4474\n",
            "Epoch 127/150 - 0.66s - loss: 1.0658 - acc: 0.4514 - val_loss: 1.0705 - val_acc: 0.4474\n",
            "Epoch 128/150 - 0.66s - loss: 1.0656 - acc: 0.4521 - val_loss: 1.0703 - val_acc: 0.4494\n",
            "Epoch 129/150 - 0.66s - loss: 1.0654 - acc: 0.4528 - val_loss: 1.0702 - val_acc: 0.4494\n",
            "Epoch 130/150 - 0.69s - loss: 1.0652 - acc: 0.4528 - val_loss: 1.0700 - val_acc: 0.4494\n",
            "Epoch 131/150 - 0.73s - loss: 1.0651 - acc: 0.4532 - val_loss: 1.0699 - val_acc: 0.4494\n",
            "Epoch 132/150 - 0.71s - loss: 1.0649 - acc: 0.4534 - val_loss: 1.0697 - val_acc: 0.4514\n",
            "Epoch 133/150 - 0.65s - loss: 1.0647 - acc: 0.4534 - val_loss: 1.0696 - val_acc: 0.4514\n",
            "Epoch 134/150 - 0.71s - loss: 1.0645 - acc: 0.4550 - val_loss: 1.0694 - val_acc: 0.4514\n",
            "Epoch 135/150 - 0.68s - loss: 1.0643 - acc: 0.4552 - val_loss: 1.0693 - val_acc: 0.4514\n",
            "Epoch 136/150 - 0.66s - loss: 1.0641 - acc: 0.4559 - val_loss: 1.0691 - val_acc: 0.4494\n",
            "Epoch 137/150 - 0.69s - loss: 1.0639 - acc: 0.4559 - val_loss: 1.0690 - val_acc: 0.4474\n",
            "Epoch 138/150 - 0.65s - loss: 1.0637 - acc: 0.4561 - val_loss: 1.0688 - val_acc: 0.4494\n",
            "Epoch 139/150 - 0.67s - loss: 1.0636 - acc: 0.4555 - val_loss: 1.0687 - val_acc: 0.4453\n",
            "Epoch 140/150 - 0.70s - loss: 1.0634 - acc: 0.4557 - val_loss: 1.0686 - val_acc: 0.4453\n",
            "Epoch 141/150 - 0.69s - loss: 1.0632 - acc: 0.4561 - val_loss: 1.0684 - val_acc: 0.4453\n",
            "Epoch 142/150 - 0.71s - loss: 1.0630 - acc: 0.4566 - val_loss: 1.0683 - val_acc: 0.4433\n",
            "Epoch 143/150 - 0.67s - loss: 1.0628 - acc: 0.4561 - val_loss: 1.0681 - val_acc: 0.4433\n",
            "Epoch 144/150 - 0.67s - loss: 1.0627 - acc: 0.4561 - val_loss: 1.0680 - val_acc: 0.4433\n",
            "Epoch 145/150 - 0.66s - loss: 1.0625 - acc: 0.4566 - val_loss: 1.0678 - val_acc: 0.4453\n",
            "Epoch 146/150 - 0.63s - loss: 1.0623 - acc: 0.4564 - val_loss: 1.0677 - val_acc: 0.4453\n",
            "Epoch 147/150 - 0.65s - loss: 1.0621 - acc: 0.4570 - val_loss: 1.0676 - val_acc: 0.4453\n",
            "Epoch 148/150 - 0.66s - loss: 1.0619 - acc: 0.4573 - val_loss: 1.0674 - val_acc: 0.4453\n",
            "Epoch 149/150 - 0.63s - loss: 1.0618 - acc: 0.4577 - val_loss: 1.0673 - val_acc: 0.4453\n",
            "Epoch 150/150 - 0.68s - loss: 1.0616 - acc: 0.4579 - val_loss: 1.0672 - val_acc: 0.4453\n",
            "\n",
            "Combination 250/252:\n",
            "Hidden Layers: [512, 256, 128], Activation: tanh, Learning Rate: 0.0001, Batch Size: 64, Epochs: 50\n",
            "Epoch 1/50 - 0.50s - loss: 1.1238 - acc: 0.3214 - val_loss: 1.1185 - val_acc: 0.3340\n",
            "Epoch 2/50 - 0.45s - loss: 1.1197 - acc: 0.3210 - val_loss: 1.1150 - val_acc: 0.3320\n",
            "Epoch 3/50 - 0.46s - loss: 1.1163 - acc: 0.3198 - val_loss: 1.1121 - val_acc: 0.3279\n",
            "Epoch 4/50 - 0.44s - loss: 1.1134 - acc: 0.3180 - val_loss: 1.1097 - val_acc: 0.3219\n",
            "Epoch 5/50 - 0.46s - loss: 1.1111 - acc: 0.3203 - val_loss: 1.1078 - val_acc: 0.3158\n",
            "Epoch 6/50 - 0.48s - loss: 1.1091 - acc: 0.3223 - val_loss: 1.1062 - val_acc: 0.3198\n",
            "Epoch 7/50 - 0.45s - loss: 1.1074 - acc: 0.3194 - val_loss: 1.1049 - val_acc: 0.3117\n",
            "Epoch 8/50 - 0.45s - loss: 1.1060 - acc: 0.3174 - val_loss: 1.1038 - val_acc: 0.3158\n",
            "Epoch 9/50 - 0.45s - loss: 1.1048 - acc: 0.3183 - val_loss: 1.1029 - val_acc: 0.3279\n",
            "Epoch 10/50 - 0.44s - loss: 1.1038 - acc: 0.3192 - val_loss: 1.1022 - val_acc: 0.3300\n",
            "Epoch 11/50 - 0.48s - loss: 1.1029 - acc: 0.3185 - val_loss: 1.1015 - val_acc: 0.3320\n",
            "Epoch 12/50 - 0.51s - loss: 1.1021 - acc: 0.3205 - val_loss: 1.1010 - val_acc: 0.3462\n",
            "Epoch 13/50 - 0.45s - loss: 1.1015 - acc: 0.3162 - val_loss: 1.1005 - val_acc: 0.3563\n",
            "Epoch 14/50 - 0.44s - loss: 1.1009 - acc: 0.3205 - val_loss: 1.1001 - val_acc: 0.3644\n",
            "Epoch 15/50 - 0.47s - loss: 1.1003 - acc: 0.3210 - val_loss: 1.0998 - val_acc: 0.3623\n",
            "Epoch 16/50 - 0.48s - loss: 1.0999 - acc: 0.3273 - val_loss: 1.0995 - val_acc: 0.3684\n",
            "Epoch 17/50 - 0.48s - loss: 1.0994 - acc: 0.3300 - val_loss: 1.0992 - val_acc: 0.3603\n",
            "Epoch 18/50 - 0.48s - loss: 1.0990 - acc: 0.3327 - val_loss: 1.0990 - val_acc: 0.3623\n",
            "Epoch 19/50 - 0.47s - loss: 1.0987 - acc: 0.3367 - val_loss: 1.0988 - val_acc: 0.3725\n",
            "Epoch 20/50 - 0.46s - loss: 1.0984 - acc: 0.3412 - val_loss: 1.0986 - val_acc: 0.3785\n",
            "Epoch 21/50 - 0.48s - loss: 1.0980 - acc: 0.3448 - val_loss: 1.0984 - val_acc: 0.3826\n",
            "Epoch 22/50 - 0.44s - loss: 1.0978 - acc: 0.3448 - val_loss: 1.0982 - val_acc: 0.3785\n",
            "Epoch 23/50 - 0.45s - loss: 1.0975 - acc: 0.3471 - val_loss: 1.0980 - val_acc: 0.3704\n",
            "Epoch 24/50 - 0.50s - loss: 1.0972 - acc: 0.3502 - val_loss: 1.0979 - val_acc: 0.3623\n",
            "Epoch 25/50 - 0.45s - loss: 1.0970 - acc: 0.3522 - val_loss: 1.0977 - val_acc: 0.3644\n",
            "Epoch 26/50 - 0.45s - loss: 1.0967 - acc: 0.3540 - val_loss: 1.0976 - val_acc: 0.3623\n",
            "Epoch 27/50 - 0.47s - loss: 1.0965 - acc: 0.3574 - val_loss: 1.0974 - val_acc: 0.3644\n",
            "Epoch 28/50 - 0.46s - loss: 1.0963 - acc: 0.3572 - val_loss: 1.0973 - val_acc: 0.3664\n",
            "Epoch 29/50 - 0.46s - loss: 1.0960 - acc: 0.3605 - val_loss: 1.0971 - val_acc: 0.3664\n",
            "Epoch 30/50 - 0.46s - loss: 1.0958 - acc: 0.3630 - val_loss: 1.0970 - val_acc: 0.3664\n",
            "Epoch 31/50 - 0.45s - loss: 1.0956 - acc: 0.3644 - val_loss: 1.0968 - val_acc: 0.3623\n",
            "Epoch 32/50 - 0.46s - loss: 1.0954 - acc: 0.3648 - val_loss: 1.0967 - val_acc: 0.3664\n",
            "Epoch 33/50 - 0.45s - loss: 1.0952 - acc: 0.3677 - val_loss: 1.0966 - val_acc: 0.3644\n",
            "Epoch 34/50 - 0.44s - loss: 1.0950 - acc: 0.3680 - val_loss: 1.0964 - val_acc: 0.3623\n",
            "Epoch 35/50 - 0.45s - loss: 1.0948 - acc: 0.3689 - val_loss: 1.0963 - val_acc: 0.3623\n",
            "Epoch 36/50 - 0.49s - loss: 1.0946 - acc: 0.3691 - val_loss: 1.0961 - val_acc: 0.3684\n",
            "Epoch 37/50 - 0.45s - loss: 1.0944 - acc: 0.3693 - val_loss: 1.0960 - val_acc: 0.3704\n",
            "Epoch 38/50 - 0.45s - loss: 1.0942 - acc: 0.3709 - val_loss: 1.0959 - val_acc: 0.3725\n",
            "Epoch 39/50 - 0.45s - loss: 1.0940 - acc: 0.3704 - val_loss: 1.0957 - val_acc: 0.3725\n",
            "Epoch 40/50 - 0.46s - loss: 1.0939 - acc: 0.3695 - val_loss: 1.0956 - val_acc: 0.3704\n",
            "Epoch 41/50 - 0.45s - loss: 1.0937 - acc: 0.3718 - val_loss: 1.0954 - val_acc: 0.3704\n",
            "Epoch 42/50 - 0.46s - loss: 1.0935 - acc: 0.3729 - val_loss: 1.0953 - val_acc: 0.3684\n",
            "Epoch 43/50 - 0.45s - loss: 1.0933 - acc: 0.3736 - val_loss: 1.0952 - val_acc: 0.3684\n",
            "Epoch 44/50 - 0.45s - loss: 1.0931 - acc: 0.3738 - val_loss: 1.0950 - val_acc: 0.3704\n",
            "Epoch 45/50 - 0.45s - loss: 1.0929 - acc: 0.3758 - val_loss: 1.0949 - val_acc: 0.3704\n",
            "Epoch 46/50 - 0.45s - loss: 1.0928 - acc: 0.3767 - val_loss: 1.0947 - val_acc: 0.3704\n",
            "Epoch 47/50 - 0.45s - loss: 1.0926 - acc: 0.3774 - val_loss: 1.0946 - val_acc: 0.3704\n",
            "Epoch 48/50 - 0.46s - loss: 1.0924 - acc: 0.3774 - val_loss: 1.0945 - val_acc: 0.3725\n",
            "Epoch 49/50 - 0.44s - loss: 1.0922 - acc: 0.3785 - val_loss: 1.0943 - val_acc: 0.3725\n",
            "Epoch 50/50 - 0.45s - loss: 1.0920 - acc: 0.3783 - val_loss: 1.0942 - val_acc: 0.3684\n",
            "\n",
            "Combination 251/252:\n",
            "Hidden Layers: [512, 256, 128], Activation: tanh, Learning Rate: 0.0001, Batch Size: 64, Epochs: 100\n",
            "Epoch 1/100 - 0.43s - loss: 1.1054 - acc: 0.3340 - val_loss: 1.1054 - val_acc: 0.3138\n",
            "Epoch 2/100 - 0.43s - loss: 1.1048 - acc: 0.3331 - val_loss: 1.1047 - val_acc: 0.3239\n",
            "Epoch 3/100 - 0.44s - loss: 1.1042 - acc: 0.3333 - val_loss: 1.1042 - val_acc: 0.3239\n",
            "Epoch 4/100 - 0.47s - loss: 1.1036 - acc: 0.3336 - val_loss: 1.1037 - val_acc: 0.3279\n",
            "Epoch 5/100 - 0.45s - loss: 1.1031 - acc: 0.3311 - val_loss: 1.1032 - val_acc: 0.3300\n",
            "Epoch 6/100 - 0.45s - loss: 1.1027 - acc: 0.3320 - val_loss: 1.1028 - val_acc: 0.3300\n",
            "Epoch 7/100 - 0.43s - loss: 1.1022 - acc: 0.3320 - val_loss: 1.1024 - val_acc: 0.3360\n",
            "Epoch 8/100 - 0.44s - loss: 1.1018 - acc: 0.3311 - val_loss: 1.1020 - val_acc: 0.3320\n",
            "Epoch 9/100 - 0.45s - loss: 1.1015 - acc: 0.3313 - val_loss: 1.1017 - val_acc: 0.3239\n",
            "Epoch 10/100 - 0.45s - loss: 1.1011 - acc: 0.3347 - val_loss: 1.1014 - val_acc: 0.3198\n",
            "Epoch 11/100 - 0.44s - loss: 1.1007 - acc: 0.3387 - val_loss: 1.1010 - val_acc: 0.3178\n",
            "Epoch 12/100 - 0.44s - loss: 1.1004 - acc: 0.3405 - val_loss: 1.1008 - val_acc: 0.3138\n",
            "Epoch 13/100 - 0.45s - loss: 1.1001 - acc: 0.3439 - val_loss: 1.1005 - val_acc: 0.3239\n",
            "Epoch 14/100 - 0.46s - loss: 1.0998 - acc: 0.3473 - val_loss: 1.1002 - val_acc: 0.3279\n",
            "Epoch 15/100 - 0.44s - loss: 1.0995 - acc: 0.3484 - val_loss: 1.1000 - val_acc: 0.3340\n",
            "Epoch 16/100 - 0.47s - loss: 1.0992 - acc: 0.3516 - val_loss: 1.0997 - val_acc: 0.3441\n",
            "Epoch 17/100 - 0.46s - loss: 1.0989 - acc: 0.3545 - val_loss: 1.0995 - val_acc: 0.3441\n",
            "Epoch 18/100 - 0.48s - loss: 1.0986 - acc: 0.3578 - val_loss: 1.0992 - val_acc: 0.3462\n",
            "Epoch 19/100 - 0.49s - loss: 1.0983 - acc: 0.3605 - val_loss: 1.0990 - val_acc: 0.3522\n",
            "Epoch 20/100 - 0.51s - loss: 1.0980 - acc: 0.3623 - val_loss: 1.0987 - val_acc: 0.3543\n",
            "Epoch 21/100 - 0.46s - loss: 1.0978 - acc: 0.3635 - val_loss: 1.0985 - val_acc: 0.3623\n",
            "Epoch 22/100 - 0.47s - loss: 1.0975 - acc: 0.3641 - val_loss: 1.0983 - val_acc: 0.3664\n",
            "Epoch 23/100 - 0.47s - loss: 1.0972 - acc: 0.3673 - val_loss: 1.0980 - val_acc: 0.3704\n",
            "Epoch 24/100 - 0.49s - loss: 1.0970 - acc: 0.3673 - val_loss: 1.0978 - val_acc: 0.3704\n",
            "Epoch 25/100 - 0.46s - loss: 1.0967 - acc: 0.3673 - val_loss: 1.0976 - val_acc: 0.3704\n",
            "Epoch 26/100 - 0.44s - loss: 1.0964 - acc: 0.3711 - val_loss: 1.0974 - val_acc: 0.3644\n",
            "Epoch 27/100 - 0.54s - loss: 1.0962 - acc: 0.3736 - val_loss: 1.0971 - val_acc: 0.3664\n",
            "Epoch 28/100 - 0.48s - loss: 1.0959 - acc: 0.3761 - val_loss: 1.0969 - val_acc: 0.3664\n",
            "Epoch 29/100 - 0.50s - loss: 1.0957 - acc: 0.3774 - val_loss: 1.0967 - val_acc: 0.3603\n",
            "Epoch 30/100 - 0.48s - loss: 1.0954 - acc: 0.3815 - val_loss: 1.0965 - val_acc: 0.3603\n",
            "Epoch 31/100 - 0.45s - loss: 1.0951 - acc: 0.3846 - val_loss: 1.0963 - val_acc: 0.3664\n",
            "Epoch 32/100 - 0.50s - loss: 1.0949 - acc: 0.3866 - val_loss: 1.0961 - val_acc: 0.3623\n",
            "Epoch 33/100 - 0.48s - loss: 1.0946 - acc: 0.3884 - val_loss: 1.0959 - val_acc: 0.3664\n",
            "Epoch 34/100 - 0.50s - loss: 1.0944 - acc: 0.3909 - val_loss: 1.0957 - val_acc: 0.3684\n",
            "Epoch 35/100 - 0.51s - loss: 1.0941 - acc: 0.3918 - val_loss: 1.0955 - val_acc: 0.3684\n",
            "Epoch 36/100 - 0.49s - loss: 1.0939 - acc: 0.3925 - val_loss: 1.0953 - val_acc: 0.3664\n",
            "Epoch 37/100 - 0.47s - loss: 1.0937 - acc: 0.3936 - val_loss: 1.0951 - val_acc: 0.3684\n",
            "Epoch 38/100 - 0.55s - loss: 1.0934 - acc: 0.3965 - val_loss: 1.0949 - val_acc: 0.3684\n",
            "Epoch 39/100 - 0.50s - loss: 1.0932 - acc: 0.3983 - val_loss: 1.0947 - val_acc: 0.3704\n",
            "Epoch 40/100 - 0.50s - loss: 1.0929 - acc: 0.3983 - val_loss: 1.0945 - val_acc: 0.3745\n",
            "Epoch 41/100 - 0.53s - loss: 1.0927 - acc: 0.3997 - val_loss: 1.0943 - val_acc: 0.3785\n",
            "Epoch 42/100 - 0.48s - loss: 1.0925 - acc: 0.3999 - val_loss: 1.0941 - val_acc: 0.3806\n",
            "Epoch 43/100 - 0.47s - loss: 1.0922 - acc: 0.4022 - val_loss: 1.0939 - val_acc: 0.3887\n",
            "Epoch 44/100 - 0.48s - loss: 1.0920 - acc: 0.4028 - val_loss: 1.0937 - val_acc: 0.3866\n",
            "Epoch 45/100 - 0.50s - loss: 1.0918 - acc: 0.4031 - val_loss: 1.0935 - val_acc: 0.3866\n",
            "Epoch 46/100 - 0.51s - loss: 1.0915 - acc: 0.4053 - val_loss: 1.0933 - val_acc: 0.3846\n",
            "Epoch 47/100 - 0.52s - loss: 1.0913 - acc: 0.4051 - val_loss: 1.0931 - val_acc: 0.3846\n",
            "Epoch 48/100 - 0.49s - loss: 1.0911 - acc: 0.4055 - val_loss: 1.0929 - val_acc: 0.3826\n",
            "Epoch 49/100 - 0.52s - loss: 1.0909 - acc: 0.4067 - val_loss: 1.0928 - val_acc: 0.3846\n",
            "Epoch 50/100 - 0.51s - loss: 1.0906 - acc: 0.4067 - val_loss: 1.0926 - val_acc: 0.3785\n",
            "Epoch 51/100 - 0.52s - loss: 1.0904 - acc: 0.4064 - val_loss: 1.0924 - val_acc: 0.3785\n",
            "Epoch 52/100 - 0.56s - loss: 1.0902 - acc: 0.4085 - val_loss: 1.0922 - val_acc: 0.3765\n",
            "Epoch 53/100 - 0.54s - loss: 1.0900 - acc: 0.4076 - val_loss: 1.0920 - val_acc: 0.3745\n",
            "Epoch 54/100 - 0.53s - loss: 1.0898 - acc: 0.4085 - val_loss: 1.0918 - val_acc: 0.3704\n",
            "Epoch 55/100 - 0.51s - loss: 1.0896 - acc: 0.4082 - val_loss: 1.0917 - val_acc: 0.3704\n",
            "Epoch 56/100 - 0.47s - loss: 1.0893 - acc: 0.4087 - val_loss: 1.0915 - val_acc: 0.3745\n",
            "Epoch 57/100 - 0.47s - loss: 1.0891 - acc: 0.4091 - val_loss: 1.0913 - val_acc: 0.3725\n",
            "Epoch 58/100 - 0.46s - loss: 1.0889 - acc: 0.4080 - val_loss: 1.0912 - val_acc: 0.3765\n",
            "Epoch 59/100 - 0.52s - loss: 1.0887 - acc: 0.4103 - val_loss: 1.0910 - val_acc: 0.3785\n",
            "Epoch 60/100 - 0.47s - loss: 1.0885 - acc: 0.4096 - val_loss: 1.0908 - val_acc: 0.3826\n",
            "Epoch 61/100 - 0.49s - loss: 1.0883 - acc: 0.4103 - val_loss: 1.0906 - val_acc: 0.3785\n",
            "Epoch 62/100 - 0.50s - loss: 1.0881 - acc: 0.4121 - val_loss: 1.0904 - val_acc: 0.3826\n",
            "Epoch 63/100 - 0.49s - loss: 1.0879 - acc: 0.4136 - val_loss: 1.0903 - val_acc: 0.3866\n",
            "Epoch 64/100 - 0.46s - loss: 1.0877 - acc: 0.4154 - val_loss: 1.0901 - val_acc: 0.3866\n",
            "Epoch 65/100 - 0.49s - loss: 1.0875 - acc: 0.4161 - val_loss: 1.0900 - val_acc: 0.3947\n",
            "Epoch 66/100 - 0.47s - loss: 1.0873 - acc: 0.4195 - val_loss: 1.0898 - val_acc: 0.3947\n",
            "Epoch 67/100 - 0.48s - loss: 1.0870 - acc: 0.4197 - val_loss: 1.0896 - val_acc: 0.3988\n",
            "Epoch 68/100 - 0.48s - loss: 1.0869 - acc: 0.4193 - val_loss: 1.0895 - val_acc: 0.4028\n",
            "Epoch 69/100 - 0.49s - loss: 1.0867 - acc: 0.4199 - val_loss: 1.0893 - val_acc: 0.4028\n",
            "Epoch 70/100 - 0.49s - loss: 1.0865 - acc: 0.4211 - val_loss: 1.0891 - val_acc: 0.4008\n",
            "Epoch 71/100 - 0.50s - loss: 1.0863 - acc: 0.4220 - val_loss: 1.0890 - val_acc: 0.4069\n",
            "Epoch 72/100 - 0.47s - loss: 1.0861 - acc: 0.4222 - val_loss: 1.0888 - val_acc: 0.4069\n",
            "Epoch 73/100 - 0.49s - loss: 1.0859 - acc: 0.4224 - val_loss: 1.0887 - val_acc: 0.4069\n",
            "Epoch 74/100 - 0.49s - loss: 1.0857 - acc: 0.4233 - val_loss: 1.0885 - val_acc: 0.4109\n",
            "Epoch 75/100 - 0.52s - loss: 1.0855 - acc: 0.4242 - val_loss: 1.0883 - val_acc: 0.4089\n",
            "Epoch 76/100 - 0.50s - loss: 1.0853 - acc: 0.4233 - val_loss: 1.0882 - val_acc: 0.4109\n",
            "Epoch 77/100 - 0.53s - loss: 1.0851 - acc: 0.4242 - val_loss: 1.0880 - val_acc: 0.4109\n",
            "Epoch 78/100 - 0.49s - loss: 1.0849 - acc: 0.4238 - val_loss: 1.0879 - val_acc: 0.4130\n",
            "Epoch 79/100 - 0.49s - loss: 1.0847 - acc: 0.4240 - val_loss: 1.0877 - val_acc: 0.4109\n",
            "Epoch 80/100 - 0.50s - loss: 1.0845 - acc: 0.4238 - val_loss: 1.0876 - val_acc: 0.4130\n",
            "Epoch 81/100 - 0.49s - loss: 1.0844 - acc: 0.4235 - val_loss: 1.0874 - val_acc: 0.4109\n",
            "Epoch 82/100 - 0.46s - loss: 1.0842 - acc: 0.4240 - val_loss: 1.0873 - val_acc: 0.4109\n",
            "Epoch 83/100 - 0.50s - loss: 1.0840 - acc: 0.4240 - val_loss: 1.0871 - val_acc: 0.4130\n",
            "Epoch 84/100 - 0.46s - loss: 1.0838 - acc: 0.4253 - val_loss: 1.0870 - val_acc: 0.4150\n",
            "Epoch 85/100 - 0.48s - loss: 1.0836 - acc: 0.4267 - val_loss: 1.0868 - val_acc: 0.4170\n",
            "Epoch 86/100 - 0.50s - loss: 1.0834 - acc: 0.4267 - val_loss: 1.0867 - val_acc: 0.4150\n",
            "Epoch 87/100 - 0.47s - loss: 1.0833 - acc: 0.4267 - val_loss: 1.0865 - val_acc: 0.4130\n",
            "Epoch 88/100 - 0.46s - loss: 1.0831 - acc: 0.4274 - val_loss: 1.0864 - val_acc: 0.4150\n",
            "Epoch 89/100 - 0.52s - loss: 1.0829 - acc: 0.4276 - val_loss: 1.0863 - val_acc: 0.4170\n",
            "Epoch 90/100 - 0.47s - loss: 1.0827 - acc: 0.4278 - val_loss: 1.0861 - val_acc: 0.4211\n",
            "Epoch 91/100 - 0.48s - loss: 1.0826 - acc: 0.4283 - val_loss: 1.0860 - val_acc: 0.4211\n",
            "Epoch 92/100 - 0.47s - loss: 1.0824 - acc: 0.4287 - val_loss: 1.0858 - val_acc: 0.4211\n",
            "Epoch 93/100 - 0.47s - loss: 1.0822 - acc: 0.4291 - val_loss: 1.0857 - val_acc: 0.4211\n",
            "Epoch 94/100 - 0.50s - loss: 1.0820 - acc: 0.4298 - val_loss: 1.0856 - val_acc: 0.4211\n",
            "Epoch 95/100 - 0.49s - loss: 1.0819 - acc: 0.4298 - val_loss: 1.0854 - val_acc: 0.4251\n",
            "Epoch 96/100 - 0.46s - loss: 1.0817 - acc: 0.4303 - val_loss: 1.0853 - val_acc: 0.4211\n",
            "Epoch 97/100 - 0.47s - loss: 1.0815 - acc: 0.4291 - val_loss: 1.0851 - val_acc: 0.4190\n",
            "Epoch 98/100 - 0.47s - loss: 1.0813 - acc: 0.4296 - val_loss: 1.0850 - val_acc: 0.4190\n",
            "Epoch 99/100 - 0.47s - loss: 1.0812 - acc: 0.4312 - val_loss: 1.0849 - val_acc: 0.4211\n",
            "Epoch 100/100 - 0.49s - loss: 1.0810 - acc: 0.4312 - val_loss: 1.0847 - val_acc: 0.4211\n",
            "\n",
            "Combination 252/252:\n",
            "Hidden Layers: [512, 256, 128], Activation: tanh, Learning Rate: 0.0001, Batch Size: 64, Epochs: 150\n",
            "Epoch 1/150 - 0.55s - loss: 1.1058 - acc: 0.3426 - val_loss: 1.1093 - val_acc: 0.3138\n",
            "Epoch 2/150 - 0.51s - loss: 1.1049 - acc: 0.3437 - val_loss: 1.1087 - val_acc: 0.3117\n",
            "Epoch 3/150 - 0.50s - loss: 1.1042 - acc: 0.3435 - val_loss: 1.1082 - val_acc: 0.3036\n",
            "Epoch 4/150 - 0.47s - loss: 1.1035 - acc: 0.3439 - val_loss: 1.1077 - val_acc: 0.3036\n",
            "Epoch 5/150 - 0.47s - loss: 1.1029 - acc: 0.3462 - val_loss: 1.1073 - val_acc: 0.3077\n",
            "Epoch 6/150 - 0.49s - loss: 1.1024 - acc: 0.3455 - val_loss: 1.1070 - val_acc: 0.3117\n",
            "Epoch 7/150 - 0.50s - loss: 1.1019 - acc: 0.3453 - val_loss: 1.1066 - val_acc: 0.3097\n",
            "Epoch 8/150 - 0.47s - loss: 1.1014 - acc: 0.3464 - val_loss: 1.1063 - val_acc: 0.3138\n",
            "Epoch 9/150 - 0.48s - loss: 1.1009 - acc: 0.3459 - val_loss: 1.1060 - val_acc: 0.3077\n",
            "Epoch 10/150 - 0.48s - loss: 1.1005 - acc: 0.3466 - val_loss: 1.1057 - val_acc: 0.3097\n",
            "Epoch 11/150 - 0.49s - loss: 1.1001 - acc: 0.3480 - val_loss: 1.1055 - val_acc: 0.3036\n",
            "Epoch 12/150 - 0.47s - loss: 1.0998 - acc: 0.3482 - val_loss: 1.1052 - val_acc: 0.3036\n",
            "Epoch 13/150 - 0.50s - loss: 1.0994 - acc: 0.3480 - val_loss: 1.1050 - val_acc: 0.3036\n",
            "Epoch 14/150 - 0.47s - loss: 1.0991 - acc: 0.3486 - val_loss: 1.1048 - val_acc: 0.3036\n",
            "Epoch 15/150 - 0.48s - loss: 1.0988 - acc: 0.3502 - val_loss: 1.1045 - val_acc: 0.3016\n",
            "Epoch 16/150 - 0.49s - loss: 1.0985 - acc: 0.3495 - val_loss: 1.1043 - val_acc: 0.2976\n",
            "Epoch 17/150 - 0.49s - loss: 1.0982 - acc: 0.3516 - val_loss: 1.1041 - val_acc: 0.2976\n",
            "Epoch 18/150 - 0.49s - loss: 1.0979 - acc: 0.3527 - val_loss: 1.1039 - val_acc: 0.3016\n",
            "Epoch 19/150 - 0.51s - loss: 1.0976 - acc: 0.3543 - val_loss: 1.1037 - val_acc: 0.3057\n",
            "Epoch 20/150 - 0.48s - loss: 1.0973 - acc: 0.3547 - val_loss: 1.1035 - val_acc: 0.3036\n",
            "Epoch 21/150 - 0.50s - loss: 1.0970 - acc: 0.3563 - val_loss: 1.1033 - val_acc: 0.3077\n",
            "Epoch 22/150 - 0.47s - loss: 1.0967 - acc: 0.3576 - val_loss: 1.1031 - val_acc: 0.3077\n",
            "Epoch 23/150 - 0.48s - loss: 1.0965 - acc: 0.3585 - val_loss: 1.1030 - val_acc: 0.3077\n",
            "Epoch 24/150 - 0.51s - loss: 1.0962 - acc: 0.3601 - val_loss: 1.1028 - val_acc: 0.3097\n",
            "Epoch 25/150 - 0.53s - loss: 1.0960 - acc: 0.3592 - val_loss: 1.1026 - val_acc: 0.3097\n",
            "Epoch 26/150 - 0.47s - loss: 1.0957 - acc: 0.3599 - val_loss: 1.1024 - val_acc: 0.3138\n",
            "Epoch 27/150 - 0.47s - loss: 1.0955 - acc: 0.3637 - val_loss: 1.1022 - val_acc: 0.3178\n",
            "Epoch 28/150 - 0.48s - loss: 1.0952 - acc: 0.3646 - val_loss: 1.1020 - val_acc: 0.3198\n",
            "Epoch 29/150 - 0.50s - loss: 1.0950 - acc: 0.3664 - val_loss: 1.1018 - val_acc: 0.3239\n",
            "Epoch 30/150 - 0.52s - loss: 1.0948 - acc: 0.3664 - val_loss: 1.1016 - val_acc: 0.3198\n",
            "Epoch 31/150 - 0.52s - loss: 1.0945 - acc: 0.3673 - val_loss: 1.1015 - val_acc: 0.3239\n",
            "Epoch 32/150 - 0.50s - loss: 1.0943 - acc: 0.3671 - val_loss: 1.1013 - val_acc: 0.3219\n",
            "Epoch 33/150 - 0.50s - loss: 1.0941 - acc: 0.3693 - val_loss: 1.1011 - val_acc: 0.3198\n",
            "Epoch 34/150 - 0.50s - loss: 1.0938 - acc: 0.3722 - val_loss: 1.1009 - val_acc: 0.3178\n",
            "Epoch 35/150 - 0.50s - loss: 1.0936 - acc: 0.3734 - val_loss: 1.1008 - val_acc: 0.3158\n",
            "Epoch 36/150 - 0.50s - loss: 1.0934 - acc: 0.3749 - val_loss: 1.1006 - val_acc: 0.3158\n",
            "Epoch 37/150 - 0.53s - loss: 1.0932 - acc: 0.3763 - val_loss: 1.1004 - val_acc: 0.3158\n",
            "Epoch 38/150 - 0.50s - loss: 1.0929 - acc: 0.3772 - val_loss: 1.1002 - val_acc: 0.3178\n",
            "Epoch 39/150 - 0.53s - loss: 1.0927 - acc: 0.3785 - val_loss: 1.1000 - val_acc: 0.3178\n",
            "Epoch 40/150 - 0.50s - loss: 1.0925 - acc: 0.3806 - val_loss: 1.0999 - val_acc: 0.3198\n",
            "Epoch 41/150 - 0.49s - loss: 1.0923 - acc: 0.3817 - val_loss: 1.0997 - val_acc: 0.3198\n",
            "Epoch 42/150 - 0.55s - loss: 1.0921 - acc: 0.3830 - val_loss: 1.0995 - val_acc: 0.3198\n",
            "Epoch 43/150 - 0.50s - loss: 1.0918 - acc: 0.3857 - val_loss: 1.0993 - val_acc: 0.3198\n",
            "Epoch 44/150 - 0.49s - loss: 1.0916 - acc: 0.3869 - val_loss: 1.0992 - val_acc: 0.3239\n",
            "Epoch 45/150 - 0.50s - loss: 1.0914 - acc: 0.3878 - val_loss: 1.0990 - val_acc: 0.3279\n",
            "Epoch 46/150 - 0.52s - loss: 1.0912 - acc: 0.3878 - val_loss: 1.0988 - val_acc: 0.3259\n",
            "Epoch 47/150 - 0.51s - loss: 1.0910 - acc: 0.3880 - val_loss: 1.0986 - val_acc: 0.3279\n",
            "Epoch 48/150 - 0.53s - loss: 1.0908 - acc: 0.3891 - val_loss: 1.0985 - val_acc: 0.3320\n",
            "Epoch 49/150 - 0.52s - loss: 1.0906 - acc: 0.3909 - val_loss: 1.0983 - val_acc: 0.3360\n",
            "Epoch 50/150 - 0.49s - loss: 1.0904 - acc: 0.3923 - val_loss: 1.0981 - val_acc: 0.3360\n",
            "Epoch 51/150 - 0.49s - loss: 1.0902 - acc: 0.3938 - val_loss: 1.0980 - val_acc: 0.3360\n",
            "Epoch 52/150 - 0.48s - loss: 1.0900 - acc: 0.3952 - val_loss: 1.0978 - val_acc: 0.3320\n",
            "Epoch 53/150 - 0.49s - loss: 1.0898 - acc: 0.3968 - val_loss: 1.0976 - val_acc: 0.3360\n",
            "Epoch 54/150 - 0.50s - loss: 1.0896 - acc: 0.3972 - val_loss: 1.0974 - val_acc: 0.3360\n",
            "Epoch 55/150 - 0.52s - loss: 1.0894 - acc: 0.3983 - val_loss: 1.0973 - val_acc: 0.3360\n",
            "Epoch 56/150 - 0.49s - loss: 1.0892 - acc: 0.3983 - val_loss: 1.0971 - val_acc: 0.3340\n",
            "Epoch 57/150 - 0.49s - loss: 1.0890 - acc: 0.3988 - val_loss: 1.0970 - val_acc: 0.3360\n",
            "Epoch 58/150 - 0.50s - loss: 1.0888 - acc: 0.4010 - val_loss: 1.0968 - val_acc: 0.3340\n",
            "Epoch 59/150 - 0.49s - loss: 1.0886 - acc: 0.3999 - val_loss: 1.0966 - val_acc: 0.3360\n",
            "Epoch 60/150 - 0.51s - loss: 1.0884 - acc: 0.4022 - val_loss: 1.0965 - val_acc: 0.3381\n",
            "Epoch 61/150 - 0.50s - loss: 1.0882 - acc: 0.4024 - val_loss: 1.0963 - val_acc: 0.3401\n",
            "Epoch 62/150 - 0.53s - loss: 1.0880 - acc: 0.4031 - val_loss: 1.0962 - val_acc: 0.3421\n",
            "Epoch 63/150 - 0.50s - loss: 1.0878 - acc: 0.4037 - val_loss: 1.0960 - val_acc: 0.3462\n",
            "Epoch 64/150 - 0.55s - loss: 1.0876 - acc: 0.4028 - val_loss: 1.0959 - val_acc: 0.3502\n",
            "Epoch 65/150 - 0.54s - loss: 1.0874 - acc: 0.4042 - val_loss: 1.0957 - val_acc: 0.3502\n",
            "Epoch 66/150 - 0.60s - loss: 1.0873 - acc: 0.4060 - val_loss: 1.0955 - val_acc: 0.3522\n",
            "Epoch 67/150 - 0.59s - loss: 1.0871 - acc: 0.4071 - val_loss: 1.0954 - val_acc: 0.3543\n",
            "Epoch 68/150 - 0.51s - loss: 1.0869 - acc: 0.4094 - val_loss: 1.0952 - val_acc: 0.3563\n",
            "Epoch 69/150 - 0.50s - loss: 1.0867 - acc: 0.4091 - val_loss: 1.0951 - val_acc: 0.3563\n",
            "Epoch 70/150 - 0.52s - loss: 1.0865 - acc: 0.4096 - val_loss: 1.0949 - val_acc: 0.3583\n",
            "Epoch 71/150 - 0.54s - loss: 1.0863 - acc: 0.4082 - val_loss: 1.0948 - val_acc: 0.3583\n",
            "Epoch 72/150 - 0.54s - loss: 1.0862 - acc: 0.4094 - val_loss: 1.0946 - val_acc: 0.3583\n",
            "Epoch 73/150 - 0.60s - loss: 1.0860 - acc: 0.4100 - val_loss: 1.0945 - val_acc: 0.3623\n",
            "Epoch 74/150 - 0.53s - loss: 1.0858 - acc: 0.4105 - val_loss: 1.0943 - val_acc: 0.3644\n",
            "Epoch 75/150 - 0.54s - loss: 1.0856 - acc: 0.4112 - val_loss: 1.0942 - val_acc: 0.3623\n",
            "Epoch 76/150 - 0.50s - loss: 1.0854 - acc: 0.4116 - val_loss: 1.0940 - val_acc: 0.3684\n",
            "Epoch 77/150 - 0.48s - loss: 1.0853 - acc: 0.4125 - val_loss: 1.0939 - val_acc: 0.3684\n",
            "Epoch 78/150 - 0.47s - loss: 1.0851 - acc: 0.4139 - val_loss: 1.0937 - val_acc: 0.3704\n",
            "Epoch 79/150 - 0.52s - loss: 1.0849 - acc: 0.4143 - val_loss: 1.0936 - val_acc: 0.3704\n",
            "Epoch 80/150 - 0.48s - loss: 1.0847 - acc: 0.4143 - val_loss: 1.0934 - val_acc: 0.3704\n",
            "Epoch 81/150 - 0.48s - loss: 1.0846 - acc: 0.4145 - val_loss: 1.0933 - val_acc: 0.3704\n",
            "Epoch 82/150 - 0.48s - loss: 1.0844 - acc: 0.4145 - val_loss: 1.0932 - val_acc: 0.3664\n",
            "Epoch 83/150 - 0.48s - loss: 1.0842 - acc: 0.4145 - val_loss: 1.0930 - val_acc: 0.3684\n",
            "Epoch 84/150 - 0.51s - loss: 1.0840 - acc: 0.4148 - val_loss: 1.0929 - val_acc: 0.3644\n",
            "Epoch 85/150 - 0.60s - loss: 1.0839 - acc: 0.4148 - val_loss: 1.0927 - val_acc: 0.3664\n",
            "Epoch 86/150 - 0.54s - loss: 1.0837 - acc: 0.4143 - val_loss: 1.0926 - val_acc: 0.3644\n",
            "Epoch 87/150 - 0.51s - loss: 1.0835 - acc: 0.4148 - val_loss: 1.0925 - val_acc: 0.3704\n",
            "Epoch 88/150 - 0.51s - loss: 1.0834 - acc: 0.4157 - val_loss: 1.0923 - val_acc: 0.3684\n",
            "Epoch 89/150 - 0.52s - loss: 1.0832 - acc: 0.4152 - val_loss: 1.0922 - val_acc: 0.3725\n",
            "Epoch 90/150 - 0.51s - loss: 1.0830 - acc: 0.4161 - val_loss: 1.0921 - val_acc: 0.3704\n",
            "Epoch 91/150 - 0.51s - loss: 1.0829 - acc: 0.4175 - val_loss: 1.0919 - val_acc: 0.3704\n",
            "Epoch 92/150 - 0.50s - loss: 1.0827 - acc: 0.4181 - val_loss: 1.0918 - val_acc: 0.3684\n",
            "Epoch 93/150 - 0.49s - loss: 1.0825 - acc: 0.4186 - val_loss: 1.0916 - val_acc: 0.3684\n",
            "Epoch 94/150 - 0.46s - loss: 1.0824 - acc: 0.4184 - val_loss: 1.0915 - val_acc: 0.3684\n",
            "Epoch 95/150 - 0.50s - loss: 1.0822 - acc: 0.4188 - val_loss: 1.0914 - val_acc: 0.3725\n",
            "Epoch 96/150 - 0.47s - loss: 1.0820 - acc: 0.4193 - val_loss: 1.0912 - val_acc: 0.3725\n",
            "Epoch 97/150 - 0.49s - loss: 1.0819 - acc: 0.4181 - val_loss: 1.0911 - val_acc: 0.3684\n",
            "Epoch 98/150 - 0.47s - loss: 1.0817 - acc: 0.4193 - val_loss: 1.0910 - val_acc: 0.3664\n",
            "Epoch 99/150 - 0.48s - loss: 1.0816 - acc: 0.4186 - val_loss: 1.0908 - val_acc: 0.3664\n",
            "Epoch 100/150 - 0.47s - loss: 1.0814 - acc: 0.4202 - val_loss: 1.0907 - val_acc: 0.3664\n",
            "Epoch 101/150 - 0.48s - loss: 1.0812 - acc: 0.4206 - val_loss: 1.0906 - val_acc: 0.3684\n",
            "Epoch 102/150 - 0.49s - loss: 1.0811 - acc: 0.4208 - val_loss: 1.0904 - val_acc: 0.3725\n",
            "Epoch 103/150 - 0.50s - loss: 1.0809 - acc: 0.4215 - val_loss: 1.0903 - val_acc: 0.3704\n",
            "Epoch 104/150 - 0.46s - loss: 1.0808 - acc: 0.4222 - val_loss: 1.0902 - val_acc: 0.3704\n",
            "Epoch 105/150 - 0.47s - loss: 1.0806 - acc: 0.4229 - val_loss: 1.0901 - val_acc: 0.3704\n",
            "Epoch 106/150 - 0.47s - loss: 1.0805 - acc: 0.4244 - val_loss: 1.0899 - val_acc: 0.3704\n",
            "Epoch 107/150 - 0.48s - loss: 1.0803 - acc: 0.4251 - val_loss: 1.0898 - val_acc: 0.3664\n",
            "Epoch 108/150 - 0.46s - loss: 1.0802 - acc: 0.4260 - val_loss: 1.0897 - val_acc: 0.3684\n",
            "Epoch 109/150 - 0.47s - loss: 1.0800 - acc: 0.4262 - val_loss: 1.0896 - val_acc: 0.3684\n",
            "Epoch 110/150 - 0.48s - loss: 1.0799 - acc: 0.4262 - val_loss: 1.0894 - val_acc: 0.3684\n",
            "Epoch 111/150 - 0.47s - loss: 1.0797 - acc: 0.4271 - val_loss: 1.0893 - val_acc: 0.3704\n",
            "Epoch 112/150 - 0.46s - loss: 1.0796 - acc: 0.4274 - val_loss: 1.0892 - val_acc: 0.3704\n",
            "Epoch 113/150 - 0.48s - loss: 1.0794 - acc: 0.4271 - val_loss: 1.0891 - val_acc: 0.3725\n",
            "Epoch 114/150 - 0.48s - loss: 1.0793 - acc: 0.4278 - val_loss: 1.0889 - val_acc: 0.3725\n",
            "Epoch 115/150 - 0.49s - loss: 1.0791 - acc: 0.4283 - val_loss: 1.0888 - val_acc: 0.3765\n",
            "Epoch 116/150 - 0.48s - loss: 1.0790 - acc: 0.4283 - val_loss: 1.0887 - val_acc: 0.3765\n",
            "Epoch 117/150 - 0.53s - loss: 1.0788 - acc: 0.4289 - val_loss: 1.0886 - val_acc: 0.3765\n",
            "Epoch 118/150 - 0.52s - loss: 1.0787 - acc: 0.4287 - val_loss: 1.0885 - val_acc: 0.3785\n",
            "Epoch 119/150 - 0.51s - loss: 1.0785 - acc: 0.4296 - val_loss: 1.0883 - val_acc: 0.3765\n",
            "Epoch 120/150 - 0.52s - loss: 1.0784 - acc: 0.4309 - val_loss: 1.0882 - val_acc: 0.3765\n",
            "Epoch 121/150 - 0.52s - loss: 1.0782 - acc: 0.4314 - val_loss: 1.0881 - val_acc: 0.3785\n",
            "Epoch 122/150 - 0.50s - loss: 1.0781 - acc: 0.4309 - val_loss: 1.0880 - val_acc: 0.3785\n",
            "Epoch 123/150 - 0.49s - loss: 1.0779 - acc: 0.4330 - val_loss: 1.0879 - val_acc: 0.3806\n",
            "Epoch 124/150 - 0.50s - loss: 1.0778 - acc: 0.4332 - val_loss: 1.0878 - val_acc: 0.3806\n",
            "Epoch 125/150 - 0.49s - loss: 1.0777 - acc: 0.4339 - val_loss: 1.0876 - val_acc: 0.3846\n",
            "Epoch 126/150 - 0.50s - loss: 1.0775 - acc: 0.4336 - val_loss: 1.0875 - val_acc: 0.3866\n",
            "Epoch 127/150 - 0.52s - loss: 1.0774 - acc: 0.4334 - val_loss: 1.0874 - val_acc: 0.3846\n",
            "Epoch 128/150 - 0.48s - loss: 1.0772 - acc: 0.4348 - val_loss: 1.0873 - val_acc: 0.3846\n",
            "Epoch 129/150 - 0.49s - loss: 1.0771 - acc: 0.4350 - val_loss: 1.0872 - val_acc: 0.3866\n",
            "Epoch 130/150 - 0.50s - loss: 1.0769 - acc: 0.4354 - val_loss: 1.0871 - val_acc: 0.3866\n",
            "Epoch 131/150 - 0.49s - loss: 1.0768 - acc: 0.4350 - val_loss: 1.0870 - val_acc: 0.3846\n",
            "Epoch 132/150 - 0.50s - loss: 1.0767 - acc: 0.4350 - val_loss: 1.0869 - val_acc: 0.3846\n",
            "Epoch 133/150 - 0.51s - loss: 1.0765 - acc: 0.4352 - val_loss: 1.0867 - val_acc: 0.3866\n",
            "Epoch 134/150 - 0.47s - loss: 1.0764 - acc: 0.4359 - val_loss: 1.0866 - val_acc: 0.3866\n",
            "Epoch 135/150 - 0.48s - loss: 1.0763 - acc: 0.4361 - val_loss: 1.0865 - val_acc: 0.3887\n",
            "Epoch 136/150 - 0.52s - loss: 1.0761 - acc: 0.4359 - val_loss: 1.0864 - val_acc: 0.3887\n",
            "Epoch 137/150 - 0.47s - loss: 1.0760 - acc: 0.4361 - val_loss: 1.0863 - val_acc: 0.3907\n",
            "Epoch 138/150 - 0.48s - loss: 1.0758 - acc: 0.4375 - val_loss: 1.0862 - val_acc: 0.3927\n",
            "Epoch 139/150 - 0.53s - loss: 1.0757 - acc: 0.4366 - val_loss: 1.0861 - val_acc: 0.3927\n",
            "Epoch 140/150 - 0.48s - loss: 1.0756 - acc: 0.4368 - val_loss: 1.0860 - val_acc: 0.3947\n",
            "Epoch 141/150 - 0.47s - loss: 1.0754 - acc: 0.4361 - val_loss: 1.0859 - val_acc: 0.3947\n",
            "Epoch 142/150 - 0.51s - loss: 1.0753 - acc: 0.4363 - val_loss: 1.0857 - val_acc: 0.3947\n",
            "Epoch 143/150 - 0.49s - loss: 1.0752 - acc: 0.4357 - val_loss: 1.0856 - val_acc: 0.3947\n",
            "Epoch 144/150 - 0.56s - loss: 1.0750 - acc: 0.4350 - val_loss: 1.0855 - val_acc: 0.3947\n",
            "Epoch 145/150 - 0.57s - loss: 1.0749 - acc: 0.4343 - val_loss: 1.0854 - val_acc: 0.3968\n",
            "Epoch 146/150 - 0.54s - loss: 1.0748 - acc: 0.4343 - val_loss: 1.0853 - val_acc: 0.3968\n",
            "Epoch 147/150 - 0.49s - loss: 1.0746 - acc: 0.4357 - val_loss: 1.0852 - val_acc: 0.3968\n",
            "Epoch 148/150 - 0.50s - loss: 1.0745 - acc: 0.4363 - val_loss: 1.0851 - val_acc: 0.3968\n",
            "Epoch 149/150 - 0.52s - loss: 1.0744 - acc: 0.4350 - val_loss: 1.0850 - val_acc: 0.3947\n",
            "Epoch 150/150 - 0.51s - loss: 1.0743 - acc: 0.4352 - val_loss: 1.0849 - val_acc: 0.3947\n",
            "\n",
            "Grid search completed in 4068.02 seconds.\n",
            "\n",
            "Top 5 Parameter Combinations:\n",
            "       hidden_layers activation  learning_rate  batch_size  epochs  \\\n",
            "218  [512, 256, 128]       relu           0.01          32     150   \n",
            "217  [512, 256, 128]       relu           0.01          32     100   \n",
            "148    [128, 64, 32]       relu           0.01          64     100   \n",
            "41         [128, 64]       relu           0.01          64     150   \n",
            "182   [256, 128, 64]       relu           0.01          32     150   \n",
            "\n",
            "     val_accuracy  test_accuracy  \n",
            "218      0.611336       0.621862  \n",
            "217      0.589069       0.591903  \n",
            "148      0.587045       0.549798  \n",
            "41       0.585020       0.566802  \n",
            "182      0.580972       0.597571  \n",
            "\n",
            "Best parameters:\n",
            "hidden_layers: [512, 256, 128]\n",
            "activation: relu\n",
            "learning_rate: 0.01\n",
            "batch_size: 32\n",
            "epochs: 150\n",
            "val_accuracy: 0.611336032388664\n",
            "test_accuracy: 0.6218623481781377\n",
            "\n",
            "Final evaluation of best model on test set:\n",
            "Test Accuracy: 0.6219\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score      support\n",
            "anger          0.583133  0.600496  0.591687   403.000000\n",
            "happiness      0.664234  0.631944  0.647687   432.000000\n",
            "sadness        0.618582  0.632500  0.625464   400.000000\n",
            "accuracy       0.621862  0.621862  0.621862     0.621862\n",
            "macro avg      0.621983  0.621647  0.621612  1235.000000\n",
            "weighted avg   0.622983  0.621862  0.622215  1235.000000\n",
            "\n",
            "Training completed!\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "data_preprocessing_tools.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
